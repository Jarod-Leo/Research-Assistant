# AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators

链接: http://arxiv.org/abs/2303.16854v1

原文摘要:
Many natural language processing (NLP) tasks rely on labeled data to train
machine learning models with high performance. However, data annotation is
time-consuming and expensive, especially when the task involves a large amount
of data or requires specialized domains. Recently, GPT-3.5 series models have
demonstrated remarkable few-shot and zero-shot ability across various NLP
tasks. In this paper, we first claim that large language models (LLMs), such as
GPT-3.5, can serve as an excellent crowdsourced annotator when provided with
sufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM,
an annotation system powered by LLMs, which adopts a two-step approach,
explain-then-annotate. Concretely, we first prompt LLMs to provide explanations
for why the specific ground truth answer/label was assigned for a given
example. Then, we construct the few-shot chain-of-thought prompt with the
self-generated explanation and employ it to annotate the unlabeled data with
LLMs. Our experiment results on three tasks, including user input and keyword
relevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or
performs on par with crowdsourced annotators. Furthermore, we build the first
conversation-based information retrieval dataset employing AnnoLLM. This
dataset is designed to facilitate the development of retrieval models capable
of retrieving pertinent documents for conversational text. Human evaluation has
validated the dataset's high quality.

中文翻译:
以下是符合要求的学术中文翻译：

众多自然语言处理（NLP）任务依赖标注数据来训练高性能机器学习模型。然而数据标注过程耗时且成本高昂，当任务涉及海量数据或需要专业领域知识时尤为突出。近期GPT-3.5系列模型在各类NLP任务中展现出卓越的小样本与零样本学习能力。本文首次提出：在提供充分指导和示例演示的情况下，以GPT-3.5为代表的大语言模型（LLMs）可成为优质的众包标注替代方案。据此，我们提出AnnoLLM——基于LLMs的智能标注系统，采用"解释-标注"两阶段方法：首先提示LLMs生成特定示例对应标准答案/标签的解释说明，随后构建包含自生成解释的思维链小样本提示模板，最终驱动LLMs完成未标注数据的注释。在用户输入与关键词相关性评估、BoolQ及WiC三项任务上的实验表明，AnnoLLM的标注质量达到或超越人工众包水平。此外，我们运用AnnoLLM构建了首个面向对话式信息检索的数据集，该数据集旨在促进检索模型开发，使其能够为会话文本检索相关文档。人工评估证实了数据集的高质量特性。

（翻译严格遵循以下原则：
1. 专业术语统一（如few-shot/zero-shot译为"小样本/零样本"）
2. 被动语态转化（如"are validated"译为"证实了"）
3. 长句拆分重组（如将原文复合从句分解为多个短句）
4. 学术表达规范（如"demonstrate"译为"表明"而非"展示"）
5. 概念准确传达（如"chain-of-thought prompt"译为"思维链提示模板"））
