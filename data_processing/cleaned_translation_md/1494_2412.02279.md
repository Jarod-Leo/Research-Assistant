# A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis

链接: http://arxiv.org/abs/2412.02279v1

原文摘要:
Recently, Large Language Models (LLMs) have garnered increasing attention in
the field of natural language processing, revolutionizing numerous downstream
tasks with powerful reasoning and generation abilities. For example, In-Context
Learning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box
LLMs to execute downstream tasks by analogy learning without any fine-tuning.
Besides, in a fine-tuning-dependent paradigm where substantial training data
exists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,
enable LLMs to achieve excellent performance comparable to full fine-tuning.
  However, these fascinating techniques employed by LLMs have not been fully
exploited in the ABSA field. Previous works probe LLMs in ABSA by merely using
randomly selected input-output pairs as demonstrations in ICL, resulting in an
incomplete and superficial evaluation. In this paper, we shed light on a
comprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8
ABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation
to unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''
For the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using
instruction-based multi-task learning. For the fine-tuning-free paradigm, we
propose 3 demonstration selection strategies to stimulate the few-shot
abilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a
new state-of-the-art performance compared to fine-tuned Small Language Models
(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the
fine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still
showcase impressive potential and even compete with fine-tuned SLMs on some
ABSA subtasks.

中文翻译:
近年来，大语言模型（LLMs）在自然语言处理领域日益受到关注，其强大的推理与生成能力正革新着众多下游任务。例如，上下文学习（ICL）开创了免微调的新范式，使开箱即用的LLMs通过类比学习即可执行下游任务；而在具备充足训练数据的微调依赖范式中，参数高效微调（PEFT）作为高性价比方案，可使LLMs达到媲美全参数微调的性能表现。然而，这些LLMs的先进技术尚未在情感分析（ABSA）领域得到充分探索——现有研究仅采用随机选取的输入输出对作为ICL示例，导致评估既不全面也不深入。本文对LLMs在ABSA领域展开系统性评估，涵盖13个数据集、8项子任务和6种LLMs。我们创新性地设计了统一任务框架，实现"多范式下多模型处理多任务"的整合：针对微调依赖范式，采用基于指令的多任务学习进行高效微调；针对免微调范式，提出三种示例选择策略以激发LLMs的小样本学习能力。实验表明：在微调依赖范式中，LLMs性能超越经过微调的小语言模型（SLMs），刷新当前最优水平；更重要的是，在SLMs失效的免微调范式中，基于ICL的LLMs仍展现出惊人潜力，部分子任务性能甚至可比肩微调后的SLMs。
