# Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge

链接: http://arxiv.org/abs/2412.01377v1

原文摘要:
The increasing complexity of computer systems necessitates innovative
approaches to fault and error management, going beyond traditional manual log
analysis. While existing solutions using large language models (LLMs) show
promise, they are limited by a gap between natural and domain-specific
languages, which restricts their effectiveness in real-world applications. Our
approach addresses these limitations by integrating interpretable domain
knowledge into open-source LLMs through continual pre-training (CPT), enhancing
performance on log tasks while retaining natural language processing
capabilities. We created a comprehensive dataset, NLPLog, with over 250,000
question-answer pairs to facilitate this integration. Our model, SuperLog,
trained with this dataset, achieves the best performance across four log
analysis tasks, surpassing the second-best model by an average of 12.01%. Our
contributions include a novel CPT paradigm that significantly improves model
performance, the development of SuperLog with state-of-the-art results, and the
release of a large-scale dataset to support further research in this domain.

中文翻译:
随着计算机系统日益复杂，传统的日志人工分析方法已无法满足需求，亟需创新的故障与错误管理方法。尽管现有基于大语言模型（LLMs）的解决方案展现出潜力，但由于自然语言与领域专用语言之间的鸿沟，其在实际应用中的有效性受到限制。本研究通过持续预训练（CPT）将可解释的领域知识整合到开源大语言模型中，在保持自然语言处理能力的同时显著提升了日志任务性能。为此，我们构建了包含25万组问答对的综合数据集NLPLog以支持模型训练。基于该数据集开发的SuperLog模型在四项日志分析任务中均取得最优表现，平均超越次优模型12.01%。本研究的创新点包括：提出显著提升模型性能的新型CPT范式，开发具有最先进性能的SuperLog模型，以及发布支持该领域后续研究的大规模数据集。
