# ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models

链接: http://arxiv.org/abs/2403.20158v1

原文摘要:
In our rapidly evolving digital sphere, the ability to discern media bias
becomes crucial as it can shape public sentiment and influence pivotal
decisions. The advent of large language models (LLMs), such as ChatGPT, noted
for their broad utility in various natural language processing (NLP) tasks,
invites exploration of their efficacy in media bias detection. Can ChatGPT
detect media bias? This study seeks to answer this question by leveraging the
Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in
distinguishing six categories of media bias, juxtaposed against fine-tuned
models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy:
ChatGPT performs at par with fine-tuned models in detecting hate speech and
text-level context bias, yet faces difficulties with subtler elements of other
bias detections, namely, fake news, racial, gender, and cognitive biases.

中文翻译:
在我们快速发展的数字领域中，辨别媒体偏见的能力变得至关重要，因为它能塑造公众情绪并影响关键决策。以ChatGPT为代表的大语言模型（LLMs）因其在各种自然语言处理（NLP）任务中的广泛适用性而备受关注，这促使我们探索其在媒体偏见检测中的效能。ChatGPT能否识别媒体偏见？本研究通过利用媒体偏见识别基准（MBIB）来评估ChatGPT在区分六类媒体偏见方面的能力，并与经过微调的模型（如BART、ConvBERT和GPT-2）进行对比，试图回答这一问题。研究结果呈现出双重性：ChatGPT在检测仇恨言论和文本层面语境偏见方面与微调模型表现相当，但在识别其他更微妙的偏见（即虚假新闻、种族、性别和认知偏见）时存在困难。
