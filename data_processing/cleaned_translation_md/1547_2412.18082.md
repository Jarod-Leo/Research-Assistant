# Prompt Tuning for Item Cold-start Recommendation

链接: http://arxiv.org/abs/2412.18082v1

原文摘要:
The item cold-start problem is crucial for online recommender systems, as the
success of the cold-start phase determines whether items can transition into
popular ones. Prompt learning, a powerful technique used in natural language
processing (NLP) to address zero- or few-shot problems, has been adapted for
recommender systems to tackle similar challenges. However, existing methods
typically rely on content-based properties or text descriptions for prompting,
which we argue may be suboptimal for cold-start recommendations due to 1)
semantic gaps with recommender tasks, 2) model bias caused by warm-up items
contribute most of the positive feedback to the model, which is the core of the
cold-start problem that hinders the recommender quality on cold-start items. We
propose to leverage high-value positive feedback, termed pinnacle feedback as
prompt information, to simultaneously resolve the above two problems. We
experimentally prove that compared to the content description proposed in
existing works, the positive feedback is more suitable to serve as prompt
information by bridging the semantic gaps. Besides, we propose item-wise
personalized prompt networks to encode pinnaclce feedback to relieve the model
bias by the positive feedback dominance problem. Extensive experiments on four
real-world datasets demonstrate the superiority of our model over
state-of-the-art methods. Moreover, PROMO has been successfully deployed on a
popular short-video sharing platform, a billion-user scale commercial
short-video application, achieving remarkable performance gains across various
commercial metrics within cold-start scenarios

中文翻译:
以下是符合您要求的中文翻译：

项目冷启动问题对在线推荐系统至关重要，因为冷启动阶段的成功与否直接决定了新物品能否转化为热门商品。提示学习作为自然语言处理（NLP）领域解决零样本/少样本问题的强大技术，已被引入推荐系统以应对类似挑战。然而现有方法通常依赖基于内容的属性或文本描述作为提示，我们认为这种方案对冷启动推荐可能并非最优选择，原因在于：1）与推荐任务存在语义鸿沟；2）由热启物品主导的模型偏差问题（这些物品贡献了模型接收的大部分正向反馈），而这正是阻碍冷启动物品推荐质量的核心问题。我们提出利用高价值正向反馈（称为巅峰反馈）作为提示信息，以同步解决上述两个问题。实验证明，相较于现有研究中提出的内容描述，正向反馈通过弥合语义鸿沟更适合作为提示信息。此外，我们提出物品级个性化提示网络来编码巅峰反馈，从而缓解由正向反馈主导引起的模型偏差问题。在四个真实数据集上的大量实验表明，我们的模型优于当前最先进方法。值得一提的是，PROMO模型已成功部署于某亿级用户规模的商业短视频平台，在冷启动场景下各项商业指标均取得显著提升。

（译文严格遵循学术规范，采用专业术语统一原则："cold-start"译为"冷启动"、"prompt learning"译为"提示学习"等。通过拆分英语长句为中文短句结构（如将"which we argue..."处理为独立分句），保留被动语态体现客观性（如"已被引入"），并运用"鸿沟""巅峰"等符合中文科技论文风格的词汇。最后补充"值得一提的是"作为段落衔接，使技术陈述更符合中文表达习惯。）
