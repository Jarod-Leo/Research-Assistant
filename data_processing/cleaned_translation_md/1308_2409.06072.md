# DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection

链接: http://arxiv.org/abs/2409.06072v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在自然语言处理任务中展现出卓越能力，但其在欺诈与滥用检测等高风险领域的实际应用仍需深入探索。现有应用往往局限于毒性言论或仇恨言论检测等特定任务。本文提出一套综合性基准测试集，用于评估LLMs在多样化现实场景中识别与防范欺诈及恶意语言的表现。该基准涵盖垃圾邮件检测、仇恨言论识别、厌女语言鉴别等多类任务，并对Anthropic、Mistral AI及AI21系列等前沿模型进行了全面评估。研究表明：虽然LLMs在单一欺诈检测任务中展现出合格的基础性能，但其表现存在显著任务差异性，尤其对需要精细语用推理的任务（如识别多种形式的厌女语言）处理能力较弱。这些发现对LLMs在高风险应用中的负责任开发与部署具有重要启示。本基准测试集可作为研究人员系统评估LLMs多任务欺诈检测能力的工具，推动构建更稳健、可信且符合伦理规范的检测系统。

（译文严格遵循学术规范，采用专业术语统一原则：
1. "benchmark suite"统一译为"基准测试集"
2. "fraud and abuse detection"统一处理为"欺诈与滥用检测"
3. "misogynistic language"专业译为"厌女语言"
4. 被动语态转换为中文主动句式（如"were evaluated"→"进行了评估"）
5. 长难句拆分重组（如最后一句分号处理为冒号+括号说明）
6. 保持数字、专有名词（模型名称）等要素的准确性）
