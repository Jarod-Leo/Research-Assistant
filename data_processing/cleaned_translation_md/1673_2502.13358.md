# Bridging the Editing Gap in LLMs: FineEdit for Precise and Targeted Text Modifications

链接: http://arxiv.org/abs/2502.13358v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing,
yet they still struggle with direct text editing tasks that demand precise,
context-aware modifications. While models like ChatGPT excel in text generation
and analysis, their editing abilities often fall short, addressing only
superficial issues rather than deeper structural or logical inconsistencies. In
this work, we introduce a dual approach to enhance LLMs editing performance.
First, we present InstrEditBench, a high-quality benchmark dataset comprising
over 20,000 structured editing tasks spanning Wiki articles, LaTeX documents,
code, and database Domain-specific Languages (DSL). InstrEditBench is generated
using an innovative automated workflow that accurately identifies and evaluates
targeted edits, ensuring that modifications adhere strictly to specified
instructions without altering unrelated content. Second, we propose FineEdit, a
specialized model trained on this curated benchmark. Experimental results
demonstrate that FineEdit achieves significant improvements around {10\%}
compared with Gemini on direct editing tasks, convincingly validating its
effectiveness.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）已革新了自然语言处理领域，但在需要精准、上下文感知修改的直接文本编辑任务中仍存在不足。尽管ChatGPT等模型在文本生成与分析方面表现优异，其编辑能力往往仅能处理表层问题，而难以解决深层次的结构性或逻辑不一致问题。本研究提出一种双重优化方案来提升LLMs的编辑性能：首先，我们构建了InstrEditBench——一个包含20,000余项结构化编辑任务的高质量基准数据集，涵盖维基百科条目、LaTeX文档、代码及数据库领域特定语言（DSL）。该数据集通过创新的自动化工作流程生成，能精准识别并评估目标编辑内容，确保修改严格遵循指令要求且不涉及无关内容。其次，我们提出了基于该基准训练的专用模型FineEdit。实验结果表明，在直接编辑任务中FineEdit相较Gemini模型实现了约10%的性能提升，有力验证了其有效性。

（说明：译文严格遵循学术论文摘要的文体特征，采用专业术语统一（如"Domain-specific Languages"译为"领域特定语言"）、被动语态转换（英文被动结构转为中文主动表述）、长句拆分（将原文复合句按中文习惯分解为多个短句）、概念准确传达（如"dual approach"译为"双重优化方案"）等策略，同时保持数据精度（保留具体百分比）和技术细节的完整呈现。）
