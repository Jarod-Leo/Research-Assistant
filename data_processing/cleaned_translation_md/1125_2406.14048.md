# Prompt Injection Attacks in Defended Systems

链接: http://arxiv.org/abs/2406.14048v1

原文摘要:
Large language models play a crucial role in modern natural language
processing technologies. However, their extensive use also introduces potential
security risks, such as the possibility of black-box attacks. These attacks can
embed hidden malicious features into the model, leading to adverse consequences
during its deployment.
  This paper investigates methods for black-box attacks on large language
models with a three-tiered defense mechanism. It analyzes the challenges and
significance of these attacks, highlighting their potential implications for
language processing system security. Existing attack and defense methods are
examined, evaluating their effectiveness and applicability across various
scenarios.
  Special attention is given to the detection algorithm for black-box attacks,
identifying hazardous vulnerabilities in language models and retrieving
sensitive information. This research presents a methodology for vulnerability
detection and the development of defensive strategies against black-box attacks
on large language models.

中文翻译:
以下是符合您要求的学术摘要翻译：

大型语言模型在现代自然语言处理技术中发挥着关键作用。然而其广泛应用也带来了潜在安全风险，例如可能遭受的黑盒攻击。此类攻击能够将隐藏的恶意特征植入模型，导致其在部署阶段产生不良后果。

本文研究针对具有三重防御机制的大型语言模型实施黑盒攻击的方法，分析了此类攻击面临的挑战与重要意义，并阐明了其对语言处理系统安全的潜在影响。通过对现有攻防方法的系统考察，评估了不同场景下各类方法的有效性与适用性。

研究重点聚焦于黑盒攻击检测算法，旨在识别语言模型中的高危漏洞并检索敏感信息。本研究提出了一套针对大型语言模型的漏洞检测方法学，并构建了相应的黑盒攻击防御策略体系。

（翻译说明：采用学术文本的严谨句式结构，保留"black-box attacks"等专业术语的统一译法；将英文被动语态转换为中文主动表述；通过"例如""旨在"等连接词保持逻辑连贯性；对长句进行合理切分，符合中文表达习惯；使用"方法论""体系"等术语体现研究深度）
