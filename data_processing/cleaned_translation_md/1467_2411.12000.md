# ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity

链接: http://arxiv.org/abs/2411.12000v1

原文摘要:
Natural Language Processing (NLP) is widely used to supply summarization
ability from long context to structured information. However, extracting
structured knowledge from scientific text by NLP models remains a challenge
because of its domain-specific nature to complex data preprocessing and the
granularity of multi-layered device-level information. To address this, we
introduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language
Model (LLM) platform, which is designed to extract structured scientific data
and synthesize new scientific knowledge from vast scientific corpora. The
platform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to
natural science. The platform was built on Amazon Web Services (AWS) and
provides an automated, user-friendly workflow for custom model development and
data extraction. The platform achieves remarkable accuracy with only a small
amount of well-annotated articles. This innovative tool streamlines the
transition from the science literature to structured knowledge and data and
benefits the advancements in natural informatics.

中文翻译:
自然语言处理（NLP）技术被广泛用于从长篇文本中提取结构化摘要信息。然而，由于科学文本的领域专业性、复杂的数据预处理需求以及多层设备级信息的细粒度特性，利用NLP模型从科学文献中提取结构化知识仍存在挑战。为此，我们推出ByteScience——一个非营利性云端自动微调大语言模型（LLM）平台，该平台专为从海量科学语料中提取结构化数据并合成新科学知识而设计。该平台基于DARWIN（一个专注于自然科学领域的开源微调LLM）构建，依托亚马逊云服务（AWS）基础设施，为用户提供自动化、低门槛的定制模型开发与数据提取工作流。实验表明，该平台仅需少量精准标注的文献即可实现卓越的准确率。这一创新工具显著简化了从科学文献到结构化知识与数据的转化流程，为自然信息学的发展提供了有力支撑。

（翻译说明：采用学术论文摘要的标准表述方式，在保持专业性的同时确保可读性。关键术语如"fine-tuned"译为"微调"符合机器学习领域惯例，"well-annotated"译为"精准标注"准确传达原文含义。通过拆分英文长句为符合中文表达习惯的短句结构，如将"because of..."因果从句转换为独立分句。保留"DARWIN"等专有名词原称，并添加括号说明其属性。最后一句"benefits the advancements..."采用主动语态转译，更符合中文论述习惯。）
