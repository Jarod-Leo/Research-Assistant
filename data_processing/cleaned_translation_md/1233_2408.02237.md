# Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings

链接: http://arxiv.org/abs/2408.02237v1

原文摘要:
Large language models (LLMs) have garnered significant interest in natural
language processing (NLP), particularly their remarkable performance in various
downstream tasks in resource-rich languages. Recent studies have highlighted
the limitations of LLMs in low-resource languages, primarily focusing on binary
classification tasks and giving minimal attention to South Asian languages.
These limitations are primarily attributed to constraints such as dataset
scarcity, computational costs, and research gaps specific to low-resource
languages. To address this gap, we present datasets for sentiment and hate
speech tasks by translating from English to Bangla, Hindi, and Urdu,
facilitating research in low-resource language processing. Further, we
comprehensively examine zero-shot learning using multiple LLMs in English and
widely spoken South Asian languages. Our findings indicate that GPT-4
consistently outperforms Llama 2 and Gemini, with English consistently
demonstrating superior performance across diverse tasks compared to
low-resource languages. Furthermore, our analysis reveals that natural language
inference (NLI) exhibits the highest performance among the evaluated tasks,
with GPT-4 demonstrating superior capabilities.

中文翻译:
大语言模型（LLMs）在自然语言处理（NLP）领域引发了广泛关注，尤其在资源丰富语言的各种下游任务中展现出卓越性能。近期研究揭示了LLMs在低资源语言中的局限性，这些研究主要集中在二元分类任务上，且对南亚语言的关注严重不足。这些限制主要源于数据集稀缺、计算成本高昂以及低资源语言特有的研究空白等问题。为弥补这一缺口，我们通过将英语数据翻译为孟加拉语、印地语和乌尔都语，构建了情感分析和仇恨言论任务数据集，以促进低资源语言处理的研究。此外，我们系统考察了多种LLMs在英语及南亚主要语言中的零样本学习表现。研究发现：GPT-4在各项任务中持续优于Llama 2和Gemini；与低资源语言相比，英语在所有任务中始终保持着性能优势；在评估的各项任务中，自然语言推理（NLI）表现最为突出，其中GPT-4展现出最强的处理能力。
