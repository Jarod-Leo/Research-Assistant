# GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models

链接: http://arxiv.org/abs/2306.17519v1

原文摘要:
Relation extraction (RE) is a crucial task in natural language processing
(NLP) that aims to identify and classify relationships between entities
mentioned in text. In the financial domain, relation extraction plays a vital
role in extracting valuable information from financial documents, such as news
articles, earnings reports, and company filings. This paper describes our
solution to relation extraction on one such dataset REFinD. The dataset was
released along with shared task as a part of the Fourth Workshop on Knowledge
Discovery from Unstructured Data in Financial Services, co-located with SIGIR
2023. In this paper, we employed OpenAI models under the framework of
in-context learning (ICL). We utilized two retrieval strategies to find top K
relevant in-context learning demonstrations / examples from training data for a
given test example. The first retrieval mechanism, we employed, is a
learning-free dense retriever and the other system is a learning-based
retriever. We were able to achieve 3rd rank overall. Our best F1-score is
0.718.

中文翻译:
关系抽取（Relation Extraction, RE）是自然语言处理（NLP）中的核心任务，旨在识别并分类文本中提及的实体间关系。在金融领域，关系抽取对从新闻文章、财报、公司备案等金融文档中提取有价值信息具有关键作用。本文阐述了我们在金融关系抽取数据集REFINd上的解决方案，该数据集随同第四届"金融服务非结构化数据知识发现研讨会"（与SIGIR 2023联合举办）的共享任务发布。本研究采用上下文学习（ICL）框架下的OpenAI模型，运用两种检索策略从训练数据中为测试样本筛选Top K相关示例：第一种是无监督稠密检索器，第二种是基于学习的检索系统。我们的方法最终获得总排名第三，最佳F1值达0.718。

（翻译说明：
1. 专业术语规范处理："dense retriever"译为"稠密检索器"符合NLP领域术语习惯
2. 机构名称完整呈现：SIGIR 2023保留国际会议标识，补充说明"联合举办"体现会议层级
3. 技术概念准确转化："in-context learning"译为"上下文学习"是学界通用译法
4. 数据指标清晰传达：F1-score保留原值0.718，符合学术论文表述规范
5. 句式结构调整：将英文长句拆分为符合中文表达习惯的短句，如将方法描述部分重组为分号连接的并列结构
6. 被动语态转化："was released"转换为主动式"随...发布"，更符合中文叙事逻辑）
