# VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?

链接: http://arxiv.org/abs/2504.19267v1

原文摘要:
Visual storytelling is an interdisciplinary field combining computer vision
and natural language processing to generate cohesive narratives from sequences
of images. This paper presents a novel approach that leverages recent
advancements in multimodal models, specifically adapting transformer-based
architectures and large multimodal models, for the visual storytelling task.
Leveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT
model produces visually grounded, contextually appropriate narratives. We
address the limitations of traditional evaluation metrics, such as BLEU,
METEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we
utilize RoViST and GROOVIST, novel reference-free metrics designed to assess
visual storytelling, focusing on visual grounding, coherence, and
non-redundancy. These metrics provide a more nuanced evaluation of narrative
quality, aligning closely with human judgment.

中文翻译:
视觉叙事是一个融合计算机视觉与自然语言处理的跨学科领域，旨在从图像序列中生成连贯的叙述文本。本文提出了一种创新方法，通过整合多模态模型的最新进展——特别是基于Transformer的架构和大型多模态模型——来解决视觉叙事任务。基于大规模视觉叙事数据集（VIST），我们开发的VIST-GPT模型能够生成视觉关联性强、上下文契合的叙述内容。针对传统评估指标（如BLEU、METEOR、ROUGE和CIDEr）在此任务中的局限性，我们采用了专为视觉叙事设计的新型无参考评估标准RoViST与GROOVIST。这些指标聚焦于视觉基础性、内容连贯性和非冗余性，能更细致地评估叙事质量，其评估结果与人类判断具有更高一致性。
