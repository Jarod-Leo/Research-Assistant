# HP-BERT: A framework for longitudinal study of Hinduphobia on social media via LLMs

链接: http://arxiv.org/abs/2501.05482v1

原文摘要:
During the COVID-19 pandemic, community tensions intensified, fuelling
Hinduphobic sentiments and discrimination against individuals of Hindu descent
within India and worldwide. Large language models (LLMs) have become prominent
in natural language processing (NLP) tasks and social media analysis, enabling
longitudinal studies of platforms like X (formerly Twitter) for specific issues
during COVID-19. We present an abuse detection and sentiment analysis framework
that offers a longitudinal analysis of Hinduphobia on X (Twitter) during and
after the COVID-19 pandemic. This framework assesses the prevalence and
intensity of Hinduphobic discourse, capturing elements such as derogatory jokes
and racist remarks through sentiment analysis and abuse detection from
pre-trained and fine-tuned LLMs. Additionally, we curate and publish a
"Hinduphobic COVID-19 X (Twitter) Dataset" of 8,000 tweets annotated for
Hinduphobic abuse detection, which is used to fine-tune a BERT model, resulting
in the development of the Hinduphobic BERT (HP-BERT) model. We then further
fine-tune HP-BERT using the SenWave dataset for multi-label sentiment analysis.
Our study encompasses approximately 27.4 million tweets from six countries,
including Australia, Brazil, India, Indonesia, Japan, and the United Kingdom.
Our findings reveal a strong correlation between spikes in COVID-19 cases and
surges in Hinduphobic rhetoric, highlighting how political narratives,
misinformation, and targeted jokes contributed to communal polarisation. These
insights provide valuable guidance for developing strategies to mitigate
communal tensions in future crises, both locally and globally. We advocate
implementing automated monitoring and removal of such content on social media
to curb divisive discourse.

中文翻译:
【译文】  
新冠疫情期间，社区紧张局势加剧，印度本土及全球范围内针对印度教裔群体的敌视情绪与歧视行为持续升级。大型语言模型（LLMs）在自然语言处理（NLP）任务和社交媒体分析领域表现突出，使得针对X平台（原Twitter）开展疫情相关议题的纵向研究成为可能。本研究构建了一个结合辱骂检测与情感分析的框架，对疫情期间及后期X平台上的印度教敌视现象进行历时性分析。该框架通过预训练及微调LLMs模型的情感分析与辱骂检测功能，系统评估印度教敌视言论的普遍性与激烈程度，涵盖贬损性玩笑、种族主义言论等要素。研究团队还整理并发布了包含8,000条标注推文的"新冠疫情印度教敌视X平台数据集"，用于微调BERT模型，最终开发出印度教敌视检测专用模型HP-BERT。该模型进一步结合SenWave数据集进行多标签情感分析微调。研究共采集来自澳大利亚、巴西、印度、印尼、日本和英国六国的约2,740万条推文。研究发现：新冠病例激增与印度教敌视言论高峰存在显著相关性，政治叙事、虚假信息及针对性玩笑加剧了社群对立。这些发现为制定本地及全球性危机中的社群矛盾缓解策略提供了重要依据。我们主张在社交媒体实施自动化监测与内容清除机制，以遏制分裂性言论。  

【翻译要点说明】  
1. 术语处理：  
- "Hinduphobic"译为"印度教敌视"，采用"敌视"而非直译"恐惧"，更符合中文对歧视性态度的表述习惯  
- "LLMs/BERT"等专业术语保留英文缩写并添加括号说明，符合学术翻译规范  

2. 长句拆分：  
- 将原文复合句按中文表达习惯拆分为多个短句（如框架描述部分），通过"该框架"保持指代清晰  
- 方法学部分采用"研究团队"作为主语，避免被动语态堆砌  

3. 文化适配：  
- "communal tensions/polarisation"译为"社群紧张局势/对立"，准确反映宗教社群冲突语境  
- "derogatory jokes"译为"贬损性玩笑"，"racist remarks"译为"种族主义言论"，体现程度差异  

4. 数据呈现：  
- "27.4 million"转换为中文数字单位"2,740万"，符合中文阅读习惯  
- 国家列表按中文惯例调整为顿号分隔  

5. 学术风格：  
- 使用"历时性分析""微调""预训练"等标准学术用语  
- 结论部分"主张"替代"建议"，体现研究立场强度
