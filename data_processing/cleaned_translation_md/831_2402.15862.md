# SportQA: A Benchmark for Sports Understanding in Large Language Models

链接: http://arxiv.org/abs/2402.15862v1

原文摘要:
A deep understanding of sports, a field rich in strategic and dynamic
content, is crucial for advancing Natural Language Processing (NLP). This holds
particular significance in the context of evaluating and advancing Large
Language Models (LLMs), given the existing gap in specialized benchmarks. To
bridge this gap, we introduce SportQA, a novel benchmark specifically designed
for evaluating LLMs in the context of sports understanding. SportQA encompasses
over 70,000 multiple-choice questions across three distinct difficulty levels,
each targeting different aspects of sports knowledge from basic historical
facts to intricate, scenario-based reasoning tasks. We conducted a thorough
evaluation of prevalent LLMs, mainly utilizing few-shot learning paradigms
supplemented by chain-of-thought (CoT) prompting. Our results reveal that while
LLMs exhibit competent performance in basic sports knowledge, they struggle
with more complex, scenario-based sports reasoning, lagging behind human
expertise. The introduction of SportQA marks a significant step forward in NLP,
offering a tool for assessing and enhancing sports understanding in LLMs.

中文翻译:
以下是符合您要求的中文翻译：

深入理解富含策略性与动态特征的体育领域，对于推动自然语言处理（NLP）发展至关重要。鉴于当前专业评估基准的缺失，这项工作对大型语言模型（LLMs）的评估与能力提升具有特殊意义。为此，我们推出SportQA——一个专为评估LLMs体育理解能力设计的新型基准测试。该数据集包含超过70,000道多选题，划分为三个难度层级，涵盖从基础历史知识到复杂情境推理等不同维度的体育认知能力。

我们采用小样本学习范式并结合思维链（CoT）提示技术，对主流LLMs进行了全面评估。研究发现：虽然模型在基础体育知识层面表现合格，但在需要复杂情境推理的体育问题上仍显不足，与人类专家水平存在明显差距。SportQA的推出标志着NLP领域的重要进展，为系统评估和提升LLMs的体育理解能力提供了标准化工具。


2. 长句拆分重组（如将原文首句拆分为两个逻辑单元）
3. 被动语态转化（如"were evaluated"译为"进行了全面评估"）
4. 概念显化处理（如"scenario-based"译为"需要复杂情境推理的"）
5. 数据呈现方式本地化（保留阿拉伯数字但添加中文量词"道"））
