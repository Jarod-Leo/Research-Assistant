# EVIT: Event-Oriented Instruction Tuning for Event Reasoning

链接: http://arxiv.org/abs/2404.11978v1

原文摘要:
Events refer to specific occurrences, incidents, or happenings that take
place under a particular background. Event reasoning aims to infer events
according to certain relations and predict future events. The cutting-edge
techniques for event reasoning play a crucial role in various natural language
processing applications. Large language models (LLMs) have made significant
advancements in event reasoning owing to their wealth of knowledge and
reasoning capabilities. However, smaller instruction-tuned models currently in
use do not consistently demonstrate exceptional proficiency in managing these
tasks. This discrepancy arises from the absence of explicit modeling of events
and the interconnections of them within their instruction data. Consequently,
these models face challenges in comprehending event structures and semantics
while struggling to bridge the gap between their interpretations and human
understanding of events. Additionally, their limitations in grasping event
relations lead to constrained event reasoning abilities to effectively deduce
and incorporate pertinent event knowledge. In this paper, we propose
Event-Oriented Instruction Tuning (EvIT) to train our LLM. Specifically, we
first propose a novel structure named event quadruple which contains the
structure and semantics of events and is complete in the event representation.
We then design event-relation learning based on the structures. We encapsulate
the learning into the instruction-tuning formulation to better stimulate the
event reasoning capacity of our model. We design a heuristic unsupervised
method to mine event quadruple from a large-scale corpus. At last, we finetune
a Llama model on our Event-Oriented Instruction Tuning. We conduct extensive
experiments on event reasoning tasks on several datasets. Automatic and human
evaluations demonstrate EvIT achieves competitive performances on event
reasoning.

中文翻译:
事件是指在特定背景下发生的具体活动、事态或现象。事件推理旨在依据特定关联关系进行事件推演并预测未来事件，其前沿技术在各类自然语言处理应用中具有关键作用。得益于丰富的知识储备与推理能力，大语言模型（LLMs）在事件推理领域取得了显著进展。然而当前广泛使用的指令微调小模型在处理此类任务时，尚未展现出稳定的卓越性能。这种差距源于其指令数据中缺乏对事件及其关联关系的显式建模，导致模型在理解事件结构与语义时面临挑战，难以弥合机器解读与人类事件认知之间的鸿沟。此外，对事件关联关系的把握不足也限制了其事件推理能力，使其无法有效推导并整合相关事件知识。

本文提出面向事件的指令微调方法（EvIT）来训练大语言模型。具体而言，我们首先设计了一种新颖的事件四元组结构，该结构完整涵盖事件表征中的结构与语义信息；继而基于该结构设计事件关系学习框架，并将学习过程封装为指令微调形式以充分激发模型的事件推理能力。我们开发了一种启发式无监督方法从大规模语料库中挖掘事件四元组，最终基于Llama模型实施面向事件的指令微调。通过在多个数据集上开展广泛的事件推理任务实验，自动评估与人工评测结果均表明EvIT在事件推理方面具有竞争优势。
