# Make A Long Image Short: Adaptive Token Length for Vision Transformers

链接: http://arxiv.org/abs/2307.02092v1

原文摘要:
The vision transformer is a model that breaks down each image into a sequence
of tokens with a fixed length and processes them similarly to words in natural
language processing. Although increasing the number of tokens typically results
in better performance, it also leads to a considerable increase in
computational cost. Motivated by the saying "A picture is worth a thousand
words," we propose an innovative approach to accelerate the ViT model by
shortening long images. Specifically, we introduce a method for adaptively
assigning token length for each image at test time to accelerate inference
speed. First, we train a Resizable-ViT (ReViT) model capable of processing
input with diverse token lengths. Next, we extract token-length labels from
ReViT that indicate the minimum number of tokens required to achieve accurate
predictions. We then use these labels to train a lightweight Token-Length
Assigner (TLA) that allocates the optimal token length for each image during
inference. The TLA enables ReViT to process images with the minimum sufficient
number of tokens, reducing token numbers in the ViT model and improving
inference speed. Our approach is general and compatible with modern vision
transformer architectures, significantly reducing computational costs. We
verified the effectiveness of our methods on multiple representative ViT models
on image classification and action recognition.

中文翻译:
视觉Transformer是一种将每幅图像分解为固定长度的标记序列，并采用类似自然语言处理中词语处理方式对其进行操作的模型。尽管增加标记数量通常能提升性能，但也会导致计算成本显著增加。受"一图胜千言"的启发，我们提出了一种通过缩短长图像来加速ViT模型的创新方法。具体而言，我们引入了一种在测试时自适应分配每幅图像标记长度以加速推理的技术。首先，我们训练了一个能够处理不同标记长度输入的Resizable-ViT（ReViT）模型；其次，从ReViT中提取标记长度标签，这些标签指示了达到准确预测所需的最小标记数量；随后利用这些标签训练轻量级的标记长度分配器（TLA），在推理过程中为每幅图像分配合适的标记长度。TLA使ReViT能够以最低限度的足够标记数量处理图像，从而减少ViT模型中的标记数量并提升推理速度。我们的方法具有通用性，可与现代视觉Transformer架构兼容，显著降低计算成本。我们在图像分类和行为识别任务中，通过多个代表性ViT模型验证了该方法的有效性。
