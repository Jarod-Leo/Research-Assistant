# E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models

链接: http://arxiv.org/abs/2401.15927v1

原文摘要:
With the accelerating development of Large Language Models (LLMs), many LLMs
are beginning to be used in the Chinese K-12 education domain. The integration
of LLMs and education is getting closer and closer, however, there is currently
no benchmark for evaluating LLMs that focuses on the Chinese K-12 education
domain. Therefore, there is an urgent need for a comprehensive natural language
processing benchmark to accurately assess the capabilities of various LLMs in
the Chinese K-12 education domain. To address this, we introduce the E-EVAL,
the first comprehensive evaluation benchmark specifically designed for the
Chinese K-12 education field. The E-EVAL consists of 4,351 multiple-choice
questions at the primary, middle, and high school levels across a wide range of
subjects, including Chinese, English, Politics, History, Ethics, Physics,
Chemistry, Mathematics, and Geography. We conducted a comprehensive evaluation
of E-EVAL on advanced LLMs, including both English-dominant and
Chinese-dominant models. Findings show that Chinese-dominant models perform
well compared to English-dominant models, with many scoring even above the GPT
4.0. However, almost all models perform poorly in complex subjects such as
mathematics. We also found that most Chinese-dominant LLMs did not achieve
higher scores at the primary school level compared to the middle school level.
We observe that the mastery of higher-order knowledge by the model does not
necessarily imply the mastery of lower-order knowledge as well. Additionally,
the experimental results indicate that the Chain of Thought (CoT) technique is
effective only for the challenging science subjects, while Few-shot prompting
is more beneficial for liberal arts subjects. With E-EVAL, we aim to analyze
the strengths and limitations of LLMs in educational applications, and to
contribute to the progress and development of Chinese K-12 education and LLMs.

中文翻译:
随着大语言模型（LLM）的加速发展，许多模型开始应用于中国K-12教育领域。LLM与教育的融合日益紧密，但目前缺乏针对中国K-12教育领域的评估基准。因此，亟需一个全面的自然语言处理基准来准确评估各类LLM在中国K-12教育领域的能力。为此，我们推出首个专为中国K-12教育领域设计的综合评估基准E-EVAL。该基准包含4,351道涵盖小学、初中和高中阶段的多选题，涉及语文、英语、政治、历史、道德与法治、物理、化学、数学和地理等多门学科。我们对主流LLM（包括英文主导型和中文主导型模型）进行了全面评估。研究发现：中文主导模型整体表现优于英文主导模型，部分模型得分甚至超过GPT-4.0；但几乎所有模型在数学等复杂学科表现欠佳。值得注意的是，多数中文LLM在小学阶段的得分并未显著高于初中阶段，这表明模型对高阶知识的掌握并不必然意味着对低阶知识的精通。实验还显示：思维链（CoT）技术仅对理科难题有效，而少样本提示（Few-shot prompting）更适用于文科学科。通过E-EVAL，我们旨在分析LLM在教育应用中的优势与局限，为中国K-12教育与LLM的共同发展提供助力。
