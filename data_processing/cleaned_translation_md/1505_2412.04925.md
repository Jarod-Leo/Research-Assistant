# $S^3$: Synonymous Semantic Space for Improving Zero-Shot Generalization of Vision-Language Models

链接: http://arxiv.org/abs/2412.04925v1

原文摘要:
Recently, many studies have been conducted to enhance the zero-shot
generalization ability of vision-language models (e.g., CLIP) by addressing the
semantic misalignment between image and text embeddings in downstream tasks.
Although many efforts have been made, existing methods barely consider the fact
that a class of images can be described by notably different textual concepts
due to well-known lexical variation in natural language processing, which
heavily affects the zero-shot generalization of CLIP. Therefore, this paper
proposes a \textbf{S}ynonymous \textbf{S}emantic \textbf{S}pace ($S^3$) for
each image class, rather than relying on a single textual concept, achieving
more stable semantic alignment and improving the zero-shot generalization of
CLIP. Specifically, our $S^3$ method first generates several synonymous
concepts based on the label of each class by using large language models, and
constructs a continuous yet compact synonymous semantic space based on the
Vietoris-Rips complex of the generated synonymous concepts. Furthermore, we
explore the effect of several point-to-space metrics on our $S^3$, while
presenting a point-to-local-center metric to compute similarity between image
embeddings and the synonymous semantic space of each class, accomplishing
effective zero-shot predictions. Extensive experiments are conducted across 17
benchmarks, including fine-grained zero-shot classification, natural
distribution zero-shot classification, and open-vocabulary segmentation, and
the results show that our $S^3$ outperforms state-of-the-art methods.

中文翻译:
近年来，为提升视觉语言模型（如CLIP）在下游任务中的零样本泛化能力，众多研究致力于解决图像与文本嵌入间的语义错位问题。尽管已有诸多探索，现有方法普遍忽视了一个关键事实：由于自然语言处理中众所周知的词汇变异现象，同一图像类别可能对应差异显著的文本概念描述，这严重制约了CLIP的零样本泛化性能。为此，本文提出为每个图像类别构建\textbf{同义语义空间}（$S^3$），而非依赖单一文本概念，从而实现更稳定的语义对齐并增强CLIP的零样本泛化能力。具体而言，$S^3$方法首先利用大语言模型基于类别标签生成若干同义概念，随后根据Vietoris-Rips复形理论构建连续且紧凑的同义语义空间。此外，我们系统研究了多种点-空间度量在$S^3$上的效果，并提出点-局部中心度量来计算图像嵌入与各类别同义语义空间的相似度，实现高效的零样本预测。我们在17个基准测试（涵盖细粒度零样本分类、自然分布零样本分类和开放词汇分割）上进行了广泛实验，结果表明$S^3$显著优于现有最先进方法。


2. 被动语态转换为主动句式（如"many studies have been conducted"处理为"众多研究致力于"）
3. 长难句合理切分（如将原文复合从句拆解为符合中文表达习惯的短句）
4. 数学符号与专业概念保留原意（如$S^3$保留格式并添加中文注释）
5. 学术风格保持一致，避免口语化表达）
