# The Quo Vadis of the Relationship between Language and Large Language Models

链接: http://arxiv.org/abs/2310.11146v1

原文摘要:
In the field of Artificial (General) Intelligence (AI), the several recent
advancements in Natural language processing (NLP) activities relying on Large
Language Models (LLMs) have come to encourage the adoption of LLMs as
scientific models of language. While the terminology employed for the
characterization of LLMs favors their embracing as such, it is not clear that
they are in a place to offer insights into the target system they seek to
represent. After identifying the most important theoretical and empirical risks
brought about by the adoption of scientific models that lack transparency, we
discuss LLMs relating them to every scientific model's fundamental components:
the object, the medium, the meaning and the user. We conclude that, at their
current stage of development, LLMs hardly offer any explanations for language,
and then we provide an outlook for more informative future research directions
on this topic.

中文翻译:
在人工智能（通用智能）领域，近年来基于大语言模型（LLMs）的自然语言处理（NLP）研究进展，正推动学界将LLMs视为语言的科学模型加以采用。尽管当前用于描述LLMs的术语体系倾向于支持这种定位，但尚不清楚这些模型是否真能为其试图表征的目标系统提供深层洞见。本文首先剖析了采用缺乏透明度的科学模型所引发的重大理论与实证风险，继而将LLMs与科学模型的四大核心要素——对象、媒介、意义和使用者——逐一对照分析。我们的结论是：在现有发展阶段，LLMs几乎无法为语言现象提供任何解释性认知。最后，本文展望了该领域未来更具启发性的研究方向。

（翻译说明：
1. 专业术语处理：采用"大语言模型（LLMs）"等学界通用译法，括号保留英文原词确保专业性
2. 学术风格保持：使用"剖析""表征""洞见"等学术用语，保留原文严谨性
3. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将"relating them to..."译为独立分句
4. 逻辑显化处理：通过"首先""继而""最后"等连接词强化论证脉络
5. 文化适应性调整："outlook"译为"展望"而非字面直译，更符合中文论文结论部分表述惯例）
