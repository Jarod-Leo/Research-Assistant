# ViTCN: Vision Transformer Contrastive Network For Reasoning

链接: http://arxiv.org/abs/2403.09962v1

原文摘要:
Machine learning models have achieved significant milestones in various
domains, for example, computer vision models have an exceptional result in
object recognition, and in natural language processing, where Large Language
Models (LLM) like GPT can start a conversation with human-like proficiency.
However, abstract reasoning remains a challenge for these models, Can AI really
thinking like a human? still be a question yet to be answered. Raven
Progressive Matrices (RPM) is a metric designed to assess human reasoning
capabilities. It presents a series of eight images as a problem set, where the
participant should try to discover the underlying rules among these images and
select the most appropriate image from eight possible options that best
completes the sequence. This task always be used to test human reasoning
abilities and IQ. Zhang et al proposed a dataset called RAVEN which can be used
to test Machine Learning model abstract reasoning ability. In this paper, we
purposed Vision Transformer Contrastive Network which build on previous work
with the Contrastive Perceptual Inference network (CoPiNet), which set a new
benchmark for permutationinvariant models Raven Progressive Matrices by
incorporating contrast effects from psychology, cognition, and education, and
extends this foundation by leveraging the cutting-edge Vision Transformer
architecture. This integration aims to further refine the machine ability to
process and reason about spatial-temporal information from pixel-level inputs
and global wise features on RAVEN dataset.

中文翻译:
以下是符合学术规范的中文翻译：

机器学习模型已在多个领域取得重大突破，例如计算机视觉模型在物体识别方面表现卓越，而自然语言处理领域如GPT之类的大语言模型（LLM）已能实现类人流畅的对话。然而抽象推理仍是这些模型面临的挑战，"人工智能能否真正像人类一样思考"仍是一个悬而未决的问题。瑞文渐进矩阵（RPM）是专为评估人类推理能力设计的测试工具，它通过呈现包含八张图片的问题集，要求受试者发现其中隐含的规则，并从八个备选答案中选出最符合序列逻辑的图片。该测试长期被用于衡量人类推理能力与智商水平。张等人提出的RAVEN数据集为机器学习模型的抽象推理能力评估提供了新基准。本文基于对比感知推理网络（CoPiNet）的研究成果——该框架通过整合心理学、认知科学及教育领域的对比效应，为排列不变模型处理瑞文渐进矩阵设立了新标准——进一步提出视觉Transformer对比网络。通过采用前沿的视觉Transformer架构，我们的方法旨在增强机器从像素级输入中处理时空信息的能力，并在RAVEN数据集上实现全局特征推理的优化。

（翻译说明：
1. 专业术语采用学界通用译法，如"permutationinvariant models"译为"排列不变模型"
2. 长难句按中文表达习惯拆分重组，如原文第四句拆分为两个逻辑清晰的短句
3. 被动语态转换为主动表述，如"should be used"译为"被用于"
4. 保留关键术语的英文缩写（RPM/LLM）及首字母缩写词（GPT）的首次出现
5. 学术机构名称"Zhang et al"规范译为"张等人"
6. 技术名词"Vision Transformer"等新兴概念保持原文大写格式）
