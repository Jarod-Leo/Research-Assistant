# Minimal Time Series Transformer

链接: http://arxiv.org/abs/2503.09791v1

原文摘要:
Transformer is the state-of-the-art model for many natural language
processing, computer vision, and audio analysis problems. Transformer
effectively combines information from the past input and output samples in
auto-regressive manner so that each sample becomes aware of all inputs and
outputs. In sequence-to-sequence (Seq2Seq) modeling, the transformer processed
samples become effective in predicting the next output. Time series forecasting
is a Seq2Seq problem. The original architecture is defined for discrete input
and output sequence tokens, but to adopt it for time series, the model must be
adapted for continuous data. This work introduces minimal adaptations to make
the original transformer architecture suitable for continuous value time series
data.

中文翻译:
Transformer（Transformer模型）是当前自然语言处理、计算机视觉及音频分析等诸多领域的先进模型。它通过自回归方式高效整合历史输入与输出样本的信息，使每个样本都能感知全部输入输出内容。在序列到序列（Seq2Seq）建模中，经Transformer处理的样本能有效预测下一输出。时间序列预测本质上属于Seq2Seq问题。原始架构本是为离散的输入输出序列标记设计，但为适应时间序列预测需求，必须将其改造以处理连续型数据。本研究通过最简化的架构调整，使原始Transformer能够适用于连续值时间序列数据的建模需求。

（翻译说明：
1. 专业术语保留英文原名"Transformer"并补充中文注释，符合技术文献惯例
2. "auto-regressive manner"译为"自回归方式"准确传达时序依赖特性
3. "becomes aware of"意译为"感知"更符合中文表达习惯
4. 将英文长句拆分为符合中文阅读节奏的短句，如最后一句的拆分处理
5. "minimal adaptations"译为"最简化的架构调整"既准确又体现研究价值
6. 统一"sequence-to-sequence"与"Seq2Seq"的译法，保持术语一致性
7. 补充"本质上"等连接词使逻辑更清晰，符合中文论述风格）
