# DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning

链接: http://arxiv.org/abs/2305.02607v1

原文摘要:
In recent years, sentiment analysis has gained significant importance in
natural language processing. However, most existing models and datasets for
sentiment analysis are developed for high-resource languages, such as English
and Chinese, leaving low-resource languages, particularly African languages,
largely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this
gap by evaluating sentiment analysis models on low-resource African languages.
In this paper, we present our solution to the shared task, where we employed
different multilingual XLM-R models with classification head trained on various
data, including those retrained in African dialects and fine-tuned on target
languages. Our team achieved the third-best results in Subtask B, Track 16:
Multilingual, demonstrating the effectiveness of our approach. While our model
showed relatively good results on multilingual data, it performed poorly in
some languages. Our findings highlight the importance of developing more
comprehensive datasets and models for low-resource African languages to advance
sentiment analysis research. We also provided the solution on the github
repository.

中文翻译:
近年来，情感分析在自然语言处理领域的重要性日益凸显。然而现有大多数情感分析模型和数据集都是针对英语、汉语等高资源语言开发的，对低资源语言（尤其是非洲语言）的研究仍处于空白状态。AfriSenti-SemEval 2023共享任务12旨在通过评估非洲低资源语言的情感分析模型来填补这一空白。本文介绍了我们针对该任务的解决方案：我们采用了多种经过非洲方言重训练和目标语言微调的XLM-R多语言分类模型。在子任务B（赛道16：多语言）中，我们的团队取得了第三名的成绩，验证了该方法的有效性。尽管模型在多语言数据上表现良好，但在某些语言中效果欠佳。研究结果凸显了为非洲低资源语言开发更全面数据集和模型的重要性，以推动情感分析研究的发展。相关解决方案已发布于GitHub代码库。

，使中文更符合阅读习惯
4. 专业术语（如XLM-R、SemEval）保留原名确保准确性
5. 补充"仍处于空白状态"等表述增强逻辑连贯性）
