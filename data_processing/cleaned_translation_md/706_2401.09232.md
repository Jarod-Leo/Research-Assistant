# Dynamic Relation Transformer for Contextual Text Block Detection

链接: http://arxiv.org/abs/2401.09232v1

原文摘要:
Contextual Text Block Detection (CTBD) is the task of identifying coherent
text blocks within the complexity of natural scenes. Previous methodologies
have treated CTBD as either a visual relation extraction challenge within
computer vision or as a sequence modeling problem from the perspective of
natural language processing. We introduce a new framework that frames CTBD as a
graph generation problem. This methodology consists of two essential
procedures: identifying individual text units as graph nodes and discerning the
sequential reading order relationships among these units as graph edges.
Leveraging the cutting-edge capabilities of DQ-DETR for node detection, our
framework innovates further by integrating a novel mechanism, a Dynamic
Relation Transformer (DRFormer), dedicated to edge generation. DRFormer
incorporates a dual interactive transformer decoder that deftly manages a
dynamic graph structure refinement process. Through this iterative process, the
model systematically enhances the graph's fidelity, ultimately resulting in
improved precision in detecting contextual text blocks. Comprehensive
experimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Context
datasets substantiate that our method achieves state-of-the-art results,
underscoring the effectiveness and potential of our graph generation framework
in advancing the field of CTBD.

中文翻译:
**上下文文本块检测（CTBD）**旨在自然场景的复杂环境中识别具有连贯语义的文本块。传统方法或将CTBD视为计算机视觉领域的视觉关系抽取任务，或从自然语言处理角度将其建模为序列预测问题。我们提出了一种创新框架，将CTBD重新定义为图结构生成问题。该框架包含两个核心流程：将独立文本单元识别为图节点，以及判定这些单元间阅读顺序关系作为图边。基于DQ-DETR先进的节点检测能力，我们进一步设计了动态关系变换器（DRFormer）这一新型边生成机制。DRFormer采用双交互式变换器解码器架构，通过动态图结构优化过程实现精准建模。这种迭代机制持续提升图结构的表征精度，从而显著提高上下文文本块的检测准确率。在SCUT-CTW-Context和ReCTS-Context数据集上的全面实验表明，本方法取得了最先进的性能，验证了所提图生成框架在推动CTBD领域发展方面的有效性和潜力。  

，并运用"旨在""视为""所提"等学术用语保持文体正式性。关键创新点"dual interactive transformer decoder"译为"双交互式变换器解码器架构"以准确传达技术内涵，同时确保符合中文科技文献表达习惯。）
