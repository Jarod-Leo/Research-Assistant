# Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting

链接: http://arxiv.org/abs/2408.00161v1

原文摘要:
Recent work in behavioral testing for natural language processing (NLP)
models, such as Checklist, is inspired by related paradigms in software
engineering testing. They allow evaluation of general linguistic capabilities
and domain understanding, hence can help evaluate conceptual soundness and
identify model weaknesses. However, a major challenge is the creation of test
cases. The current packages rely on semi-automated approach using manual
development which requires domain expertise and can be time consuming. This
paper introduces an automated approach to develop test cases by exploiting the
power of large language models and statistical techniques. It clusters the text
representations to carefully construct meaningful groups and then apply
prompting techniques to automatically generate Minimal Functionality Tests
(MFT). The well-known Amazon Reviews corpus is used to demonstrate our
approach. We analyze the behavioral test profiles across four different
classification algorithms and discuss the limitations and strengths of those
models.

中文翻译:
近期在自然语言处理（NLP）模型行为测试方面的研究（如Checklist方法）受到软件工程测试相关范式的启发。这类测试能评估模型的通用语言能力和领域理解水平，从而帮助验证概念合理性并识别模型缺陷。然而，测试用例的创建存在重大挑战——现有工具包采用半自动化方法，依赖需要领域专业知识的手动开发流程，耗时费力。本文提出一种自动化测试用例生成方法，通过结合大语言模型与统计技术，对文本表征进行聚类以构建有意义的语义分组，进而运用提示工程技术自动生成最小功能测试（MFT）。研究以知名亚马逊评论数据集为实验对象，分析了四种不同分类算法的行为测试特征，并探讨了各模型的优势与局限性。  

（翻译说明：  
1. 专业术语处理："behavioral testing"译为"行为测试"，"Minimal Functionality Tests"保留专业缩写MFT并补充全称  
2. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句，如第二句拆分为两个逻辑单元  
3. 被动语态转换："are inspired by"译为主动式"受到...启发"  
4. 概念显化："prompting techniques"译为"提示工程技术"以突出技术属性  
5. 学术风格保持：使用"范式""表征""聚类"等学术用语确保专业性  
6. 逻辑衔接：通过"从而""进而"等连接词保持论证链条清晰）
