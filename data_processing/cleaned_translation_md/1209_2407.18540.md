# A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models

链接: http://arxiv.org/abs/2407.18540v1

原文摘要:
Over the past decade, extensive research efforts have been dedicated to the
extraction of information from textual process descriptions. Despite the
remarkable progress witnessed in natural language processing (NLP), information
extraction within the Business Process Management domain remains predominantly
reliant on rule-based systems and machine learning methodologies. Data scarcity
has so far prevented the successful application of deep learning techniques.
However, the rapid progress in generative large language models (LLMs) makes it
possible to solve many NLP tasks with very high quality without the need for
extensive data. Therefore, we systematically investigate the potential of LLMs
for extracting information from textual process descriptions, targeting the
detection of process elements such as activities and actors, and relations
between them. Using a heuristic algorithm, we demonstrate the suitability of
the extracted information for process model generation. Based on a novel
prompting strategy, we show that LLMs are able to outperform state-of-the-art
machine learning approaches with absolute performance improvements of up to 8\%
$F_1$ score across three different datasets. We evaluate our prompting strategy
on eight different LLMs, showing it is universally applicable, while also
analyzing the impact of certain prompt parts on extraction quality. The number
of example texts, the specificity of definitions, and the rigour of format
instructions are identified as key for improving the accuracy of extracted
information. Our code, prompts, and data are publicly available.

中文翻译:
在过去十年中，大量研究工作致力于从文本化流程描述中提取信息。尽管自然语言处理（NLP）领域取得了显著进展，但商业流程管理领域的信息提取仍主要依赖基于规则的系统与机器学习方法。数据稀缺问题迄今阻碍了深度学习技术的成功应用。然而，生成式大语言模型（LLMs）的快速发展使得无需大量数据即可高质量解决诸多NLP任务成为可能。为此，我们系统性地探究了LLMs在文本流程描述信息提取中的潜力，重点检测流程要素（如活动、执行者）及其相互关系。通过启发式算法，我们验证了所提取信息对流程模型生成的适用性。基于创新的提示策略，研究表明LLMs能够超越现有最优机器学习方法，在三个不同数据集上实现最高8%的F1分数绝对性能提升。我们在八种不同LLMs上评估了该提示策略，证明其具有普适性，同时分析了特定提示组件对提取质量的影响。研究发现示例文本数量、定义精确度以及格式指令的严谨性是提升信息提取准确性的关键因素。相关代码、提示模板及数据已公开。
