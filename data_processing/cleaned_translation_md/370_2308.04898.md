# An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures

链接: http://arxiv.org/abs/2308.04898v1

原文摘要:
As we increasingly depend on software systems, the consequences of breaches
in the software supply chain become more severe. High-profile cyber attacks
like those on SolarWinds and ShadowHammer have resulted in significant
financial and data losses, underlining the need for stronger cybersecurity. One
way to prevent future breaches is by studying past failures. However,
traditional methods of analyzing these failures require manually reading and
summarizing reports about them. Automated support could reduce costs and allow
analysis of more failures. Natural Language Processing (NLP) techniques such as
Large Language Models (LLMs) could be leveraged to assist the analysis of
failures. In this study, we assessed the ability of Large Language Models
(LLMs) to analyze historical software supply chain breaches. We used LLMs to
replicate the manual analysis of 69 software supply chain security failures
performed by members of the Cloud Native Computing Foundation (CNCF). We
developed prompts for LLMs to categorize these by four dimensions: type of
compromise, intent, nature, and impact. GPT 3.5s categorizations had an average
accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We
report that LLMs effectively characterize software supply chain failures when
the source articles are detailed enough for consensus among manual analysts,
but cannot yet replace human analysts. Future work can improve LLM performance
in this context, and study a broader range of articles and failures.

中文翻译:
随着我们对软件系统的依赖日益加深，软件供应链遭受破坏所带来的后果也愈发严重。SolarWinds和ShadowHammer等高调网络攻击事件已造成重大财务损失和数据泄露，这凸显了加强网络安全的必要性。研究历史安全事件是预防未来漏洞的一种有效途径。然而，传统的事件分析方法需要人工阅读并总结相关报告。自动化技术支持可以降低成本，并允许分析更多安全事件。自然语言处理（NLP）技术（如大语言模型LLMs）可被用于辅助安全事件分析。本研究评估了大语言模型分析历史软件供应链安全事件的能力。我们使用LLMs复现了云原生计算基金会（CNCF）成员对69起软件供应链安全事件的人工分析过程，开发了提示词引导LLMs从四个维度（破坏类型、攻击意图、事件性质和影响程度）对这些事件进行分类。GPT-3.5在这些维度的平均分类准确率为68%，Bard的准确率为58%。研究发现：当原始文章包含足够细节且能达成人工分析共识时，LLMs能有效描述软件供应链安全事件，但目前尚无法完全替代人工分析。未来工作可提升LLMs在此场景下的表现，并拓展研究更广泛的安全事件和文献。
