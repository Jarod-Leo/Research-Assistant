# LaVin-DiT: Large Vision Diffusion Transformer

链接: http://arxiv.org/abs/2411.11505v1

原文摘要:
This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a
scalable and unified foundation model designed to tackle over 20 computer
vision tasks in a generative framework. Unlike existing large vision models
directly adapted from natural language processing architectures, which rely on
less efficient autoregressive techniques and disrupt spatial relationships
essential for vision data, LaVin-DiT introduces key innovations to optimize
generative performance for vision tasks. First, to address the high
dimensionality of visual data, we incorporate a spatial-temporal variational
autoencoder that encodes data into a continuous latent space. Second, for
generative modeling, we develop a joint diffusion transformer that
progressively produces vision outputs. Third, for unified multi-task training,
in-context learning is implemented. Input-target pairs serve as task context,
which guides the diffusion transformer to align outputs with specific tasks
within the latent space. During inference, a task-specific context set and test
data as queries allow LaVin-DiT to generalize across tasks without fine-tuning.
Trained on extensive vision datasets, the model is scaled from 0.1B to 3.4B
parameters, demonstrating substantial scalability and state-of-the-art
performance across diverse vision tasks. This work introduces a novel pathway
for large vision foundation models, underscoring the promising potential of
diffusion transformers. The code and models are available.

中文翻译:
本文提出大视觉扩散变换器（LaVin-DiT）——一个可扩展的统一基础模型，旨在生成式框架下解决超过20项计算机视觉任务。与现有直接从自然语言处理架构改造的大视觉模型不同（这类模型依赖效率较低的自回归技术，且会破坏视觉数据关键的空间关系），LaVin-DiT通过三项关键创新优化视觉任务的生成性能：首先，针对视觉数据的高维特性，我们引入时空变分自编码器将数据编码至连续潜在空间；其次，在生成建模方面，开发了联合扩散变换器逐步生成视觉输出；第三，为实现统一多任务训练，采用上下文学习方法——以输入-目标对作为任务上下文，引导扩散变换器在潜在空间中将输出与特定任务对齐。推理阶段，通过任务专属上下文集和测试数据查询，LaVin-DiT无需微调即可实现跨任务泛化。该模型在大量视觉数据集上训练，参数量从0.1B扩展至3.4B，展现出卓越的可扩展性，并在多样化视觉任务中实现最先进性能。本研究为大视觉基础模型开辟了新路径，彰显了扩散变换器的巨大潜力。代码与模型均已开源。

（翻译说明：
1. 专业术语处理："variational autoencoder"译为"变分自编码器"，"diffusion transformer"保留核心概念译为"扩散变换器"
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如创新点部分采用总分结构
3. 被动语态转换："is implemented"译为主动式"采用"
4. 概念显化："in-context learning"增译为"上下文学习方法"以明确技术属性
5. 数据规范：统一用"B"表示十亿级参数规模
6. 学术风格：使用"彰显""开辟""泛化"等符合学术论文表达的词汇
7. 逻辑衔接：通过破折号、冒号等标点保持原文论证层次）
