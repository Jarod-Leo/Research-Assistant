# Linguistic Intelligence in Large Language Models for Telecommunications

链接: http://arxiv.org/abs/2402.15818v1

原文摘要:
Large Language Models (LLMs) have emerged as a significant advancement in the
field of Natural Language Processing (NLP), demonstrating remarkable
capabilities in language generation and other language-centric tasks. Despite
their evaluation across a multitude of analytical and reasoning tasks in
various scientific domains, a comprehensive exploration of their knowledge and
understanding within the realm of natural language tasks in the
telecommunications domain is still needed. This study, therefore, seeks to
evaluate the knowledge and understanding capabilities of LLMs within this
domain. To achieve this, we conduct an exhaustive zero-shot evaluation of four
prominent LLMs-Llama-2, Falcon, Mistral, and Zephyr. These models require fewer
resources than ChatGPT, making them suitable for resource-constrained
environments. Their performance is compared with state-of-the-art, fine-tuned
models. To the best of our knowledge, this is the first work to extensively
evaluate and compare the understanding of LLMs across multiple language-centric
tasks in this domain. Our evaluation reveals that zero-shot LLMs can achieve
performance levels comparable to the current state-of-the-art fine-tuned
models. This indicates that pretraining on extensive text corpora equips LLMs
with a degree of specialization, even within the telecommunications domain. We
also observe that no single LLM consistently outperforms others, and the
performance of different LLMs can fluctuate. Although their performance lags
behind fine-tuned models, our findings underscore the potential of LLMs as a
valuable resource for understanding various aspects of this field that lack
large annotated data.

中文翻译:
以下是符合您要求的中文翻译：

大语言模型（LLMs）已成为自然语言处理（NLP）领域的重大突破，在文本生成及其他语言相关任务中展现出卓越能力。尽管这些模型已在多个科学领域的分析和推理任务中得到评估，但针对电信领域自然语言任务的知识理解能力仍缺乏系统性探究。为此，本研究旨在评估LLMs在该领域的知识理解能力。我们采用零样本评估方法，对Llama-2、Falcon、Mistral和Zephyr四款主流LLMs进行全方位测试——这些模型较ChatGPT资源需求更低，适合资源受限环境，并将其性能与微调后的最先进模型进行对比。据我们所知，这是首个在电信领域对多款LLMs执行多语言任务理解能力的系统化评估研究。实验结果表明：零样本LLMs能达到与当前最优微调模型相当的性能水平，这说明海量文本的预训练能使LLMs获得一定程度的领域特异性。我们还发现没有单一LLM能持续保持优势，不同模型表现存在波动。虽然其性能仍落后于微调模型，但本研究证实了LLMs可作为理解该领域缺乏标注数据问题的宝贵资源。

（翻译严格遵循以下原则：
1. 专业术语准确统一："zero-shot"译为"零样本"，"fine-tuned"译为"微调"
2. 长句合理切分：将原文复合句拆解为符合中文表达习惯的短句结构
3. 被动语态转化："are compared with"译为主动式"与...进行对比"
4. 逻辑显化处理："This indicates..."增译为"这说明..."使因果关系更明确
5. 学术风格保持：使用"系统性探究""领域特异性"等符合论文摘要的规范表达
6. 文化适配调整："resource-constrained environments"译为"资源受限环境"更符合中文技术文献表述）
