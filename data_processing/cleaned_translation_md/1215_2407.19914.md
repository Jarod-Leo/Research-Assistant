# Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models

链接: http://arxiv.org/abs/2407.19914v1

原文摘要:
Sentiment analysis is a widely researched area within Natural Language
Processing (NLP), attracting significant interest due to the advent of
automated solutions. Despite this, the task remains challenging because of the
inherent complexity of languages and the subjective nature of sentiments. It is
even more challenging for less-studied and less-resourced languages such as
Lithuanian. Our review of existing Lithuanian NLP research reveals that
traditional machine learning methods and classification algorithms have limited
effectiveness for the task. In this work, we address sentiment analysis of
Lithuanian five-star-based online reviews from multiple domains that we collect
and clean. We apply transformer models to this task for the first time,
exploring the capabilities of pre-trained multilingual Large Language Models
(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the
inherent difficulty of the task, the fine-tuned models perform quite well,
especially when the sentiments themselves are less ambiguous: 80.74% and 89.61%
testing recognition accuracy of the most popular one- and five-star reviews
respectively. They significantly outperform current commercial state-of-the-art
general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.

中文翻译:
情感分析是自然语言处理（NLP）领域的重要研究方向，随着自动化解决方案的出现而备受关注。然而由于语言固有的复杂性和情感的主观性，这项任务仍具挑战性，对于立陶宛语等研究较少且资源匮乏的语言而言尤为困难。我们通过梳理现有立陶宛语NLP研究发现，传统机器学习方法和分类算法在此任务上效果有限。本研究针对自主采集并清洗的多领域立陶宛语五星制在线评论展开情感分析，首次将Transformer模型应用于该任务，重点探索预训练多语言大模型（LLMs）的潜力——特别是对BERT和T5模型进行微调。鉴于任务本身的高难度，微调模型表现优异（对最典型的一星和五星评论的测试识别准确率分别达到80.74%和89.61%），尤其在情感表达明确的场景下显著优于当前最先进的通用大模型GPT-4。我们已将微调后的大模型在线公开共享。


