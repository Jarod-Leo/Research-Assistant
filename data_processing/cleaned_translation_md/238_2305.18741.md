# Grokking of Hierarchical Structure in Vanilla Transformers

链接: http://arxiv.org/abs/2305.18741v1

原文摘要:
For humans, language production and comprehension is sensitive to the
hierarchical structure of sentences. In natural language processing, past work
has questioned how effectively neural sequence models like transformers capture
this hierarchical structure when generalizing to structurally novel inputs. We
show that transformer language models can learn to generalize hierarchically
after training for extremely long periods -- far beyond the point when
in-domain accuracy has saturated. We call this phenomenon \emph{structural
grokking}. On multiple datasets, structural grokking exhibits inverted U-shaped
scaling in model depth: intermediate-depth models generalize better than both
very deep and very shallow transformers. When analyzing the relationship
between model-internal properties and grokking, we find that optimal depth for
grokking can be identified using the tree-structuredness metric of
\citet{murty2023projections}. Overall, our work provides strong evidence that,
with extended training, vanilla transformers discover and use hierarchical
structure.

中文翻译:
对人类而言，语言生成与理解能力对句子的层次结构具有敏感性。在自然语言处理领域，先前研究曾质疑像Transformer这样的神经序列模型在泛化至结构新颖的输入时，能否有效捕捉这种层次结构。我们的研究表明，经过超长周期训练后（远超过域内准确率饱和的阶段），Transformer语言模型确实能够学会按层次结构进行泛化。我们将这种现象称为"结构顿悟"。在多个数据集上的实验显示，结构顿悟现象呈现倒U型的模型深度缩放规律：中等深度模型的泛化能力优于极深或极浅的Transformer架构。通过分析模型内部特性与顿悟现象的关系，我们发现\citet{murty2023projections}提出的树形结构化度量指标可有效识别最优顿悟深度。总体而言，本研究提供了有力证据：经过充分训练后，标准Transformer模型能够自主发现并利用层次化结构。


