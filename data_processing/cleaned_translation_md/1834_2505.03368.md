# Geospatial Mechanistic Interpretability of Large Language Models

链接: http://arxiv.org/abs/2505.03368v1

原文摘要:
Large Language Models (LLMs) have demonstrated unprecedented capabilities
across various natural language processing tasks. Their ability to process and
generate viable text and code has made them ubiquitous in many fields, while
their deployment as knowledge bases and "reasoning" tools remains an area of
ongoing research. In geography, a growing body of literature has been focusing
on evaluating LLMs' geographical knowledge and their ability to perform spatial
reasoning. However, very little is still known about the internal functioning
of these models, especially about how they process geographical information.
  In this chapter, we establish a novel framework for the study of geospatial
mechanistic interpretability - using spatial analysis to reverse engineer how
LLMs handle geographical information. Our aim is to advance our understanding
of the internal representations that these complex models generate while
processing geographical information - what one might call "how LLMs think about
geographic information" if such phrasing was not an undue anthropomorphism.
  We first outline the use of probing in revealing internal structures within
LLMs. We then introduce the field of mechanistic interpretability, discussing
the superposition hypothesis and the role of sparse autoencoders in
disentangling polysemantic internal representations of LLMs into more
interpretable, monosemantic features. In our experiments, we use spatial
autocorrelation to show how features obtained for placenames display spatial
patterns related to their geographic location and can thus be interpreted
geospatially, providing insights into how these models process geographical
information. We conclude by discussing how our framework can help shape the
study and use of foundation models in geography.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）在各类自然语言处理任务中展现出前所未有的能力。其处理与生成可用文本及代码的普适性使其广泛应用于多领域，但作为知识库和"推理"工具的应用仍属持续探索的范畴。地理学界日益关注对LLMs地理知识水平与空间推理能力的评估，然而关于模型内部工作机制——尤其是地理信息处理方式——的认知仍存在显著空白。

本章构建了一个研究地理空间机制可解释性的创新框架，通过空间分析方法逆向解析LLMs处理地理信息的机制。我们的目标是深化理解这些复杂模型在处理地理信息时生成的内部表征——若不以拟人化表述为悖的话，可称之为"LLMs对地理信息的认知方式"。

首先阐述探针技术在揭示LLMs内部结构中的应用，继而系统介绍机制可解释性领域，讨论叠加假说及稀疏自编码器在解构LLMs多义性内部表征为可解释单义特征中的作用。实验环节通过空间自相关分析，证明地名特征呈现与其地理位置相关的空间模式，从而可实现地理空间维度的解读，为理解模型处理地理信息的机制提供新视角。最后探讨本框架如何推动地理学中基础模型的研究与应用范式革新。

（翻译严格遵循：1.专业术语统一 2.被动语态转换 3.长句拆分 4.学术风格保持 5.关键概念精准传达 6.避免文化负载表述）
