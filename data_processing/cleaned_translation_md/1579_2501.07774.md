# Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors

链接: http://arxiv.org/abs/2501.07774v1

原文摘要:
Indoor localization in challenging non-line-of-sight (NLOS) environments
often leads to mediocre accuracy with traditional approaches. Deep learning
(DL) has been applied to tackle these challenges; however, many DL approaches
overlook computational complexity, especially for floating-point operations
(FLOPs), making them unsuitable for resource-limited devices. Transformer-based
models have achieved remarkable success in natural language processing (NLP)
and computer vision (CV) tasks, motivating their use in wireless applications.
However, their use in indoor localization remains nascent, and directly
applying Transformers for indoor localization can be both computationally
intensive and exhibit limitations in accuracy. To address these challenges, in
this work, we introduce a novel tokenization approach, referred to as Sensor
Snapshot Tokenization (SST), which preserves variable-specific representations
of power delay profile (PDP) and enhances attention mechanisms by effectively
capturing multi-variate correlation. Complementing this, we propose a
lightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)
model, designed to reduce computational complexity without compromising
localization accuracy. Together, these contributions mitigate the computational
burden and dependency on large datasets, making Transformer models more
efficient and suitable for resource-constrained scenarios. The proposed
tokenization method enables the Vanilla Transformer to achieve a 90th
percentile positioning error of 0.388 m in a highly NLOS indoor factory,
surpassing conventional tokenization methods. The L-SwiGLU ViT further reduces
the error to 0.355 m, achieving an 8.51% improvement. Additionally, the
proposed model outperforms a 14.1 times larger model with a 46.13% improvement,
underscoring its computational efficiency.

中文翻译:
在具有挑战性的非视距（NLOS）室内定位环境中，传统方法往往精度欠佳。深度学习（DL）虽被应用于解决此类难题，但许多DL方法忽略了计算复杂度（尤其是浮点运算量FLOPs），导致其难以适配资源受限设备。基于Transformer的模型在自然语言处理（NLP）和计算机视觉（CV）任务中表现卓越，这启发了其在无线领域的应用。然而该模型在室内定位中的应用尚处萌芽阶段，直接使用Transformer不仅计算密集，还存在精度局限。为此，本研究提出一种创新的信号标记化方法——传感器快照标记化（SST），该方法通过保留功率延迟分布（PDP）的变量特异性表征，有效捕捉多变量相关性以增强注意力机制。同时，我们设计了一种基于Swish门控线性单元的轻量化Transformer模型（L-SwiGLU Transformer），在保证定位精度的前提下显著降低计算复杂度。这些创新共同缓解了计算负担和大数据依赖问题，使Transformer模型更高效地适用于资源受限场景。实验表明：所提标记化方法使标准Transformer在强NLOS工厂环境中实现0.388米的90%分位数定位误差，优于传统标记化方法；L-SwiGLU ViT进一步将误差降至0.355米，提升幅度达8.51%。此外，该模型以14.1倍的体积优势超越大模型性能达46.13%，充分验证了其计算效率优势。
