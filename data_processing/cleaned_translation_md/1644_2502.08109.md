# HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses

链接: http://arxiv.org/abs/2502.08109v1

原文摘要:
Recent advances in large language models (LLMs) have shown promising
improvements, often surpassing existing methods across a wide range of
downstream tasks in natural language processing. However, these models still
face challenges, which may hinder their practical applicability. For example,
the phenomenon of hallucination is known to compromise the reliability of LLMs,
especially in fields that demand high factual precision. Current benchmarks
primarily focus on hallucination detection and factuality evaluation but do not
extend beyond identification. This paper proposes an explanation enhanced
hallucination-detection model, coined as HuDEx, aimed at enhancing the
reliability of LLM-generated responses by both detecting hallucinations and
providing detailed explanations. The proposed model provides a novel approach
to integrate detection with explanations, and enable both users and the LLM
itself to understand and reduce errors. Our measurement results demonstrate
that the proposed model surpasses larger LLMs, such as Llama3 70B and GPT-4, in
hallucination detection accuracy, while maintaining reliable explanations.
Furthermore, the proposed model performs well in both zero-shot and other test
environments, showcasing its adaptability across diverse benchmark datasets.
The proposed approach further enhances the hallucination detection research by
introducing a novel approach to integrating interpretability with hallucination
detection, which further enhances the performance and reliability of evaluating
hallucinations in language models.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）的最新研究进展显示出显著的性能提升，在自然语言处理众多下游任务中往往超越现有方法。然而，这些模型仍面临可能影响实际应用效果的挑战。例如，众所周知的幻觉现象会损害LLMs的可靠性，特别是在需要高事实准确性的领域。现有基准测试主要聚焦于幻觉检测和事实性评估，但未能突破单纯识别的范畴。本文提出一种解释增强型幻觉检测模型HuDEx，通过同步实现幻觉检测与详细解释生成来提升LLM生成内容的可靠性。该模型创新性地将检测与解释机制相结合，使用户和LLM自身都能理解并减少错误。实验结果表明，所提模型在幻觉检测准确率上超越了Llama3 70B和GPT-4等更大规模的LLMs，同时保持可靠的解释能力。此外，该模型在零样本及其他测试环境中均表现优异，展现了跨不同基准数据集的强适应性。本研究通过开创性地将可解释性与幻觉检测相融合，不仅提升了检测性能，更为语言模型幻觉评估的可靠性研究开辟了新路径。

翻译说明：
1. 专业术语处理：LLMs统一译为"大型语言模型"，"hallucination"译为行业通用术语"幻觉"
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如将"surpassing existing methods..."处理为独立分句
3. 被动语态转换："are known to..."译为主动句式"众所周知...会"
4. 概念显化："zero-shot"译为"零样本"并保留专业特征
5. 逻辑连接：通过"不仅...更..."等连接词强化学术文本的论证关系
6. 术语一致性：全篇保持"幻觉检测"、"事实性评估"等核心术语的统一
7. 学术风格：使用"所提模型"、"展现"等符合学术论文表达的措辞
