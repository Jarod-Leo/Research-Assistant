# Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos

链接: http://arxiv.org/abs/2406.19217v1

原文摘要:
Despite significant advancements in robotic systems and surgical data
science, ensuring safe and optimal execution in robot-assisted minimally
invasive surgery (RMIS) remains a complex challenge. Current surgical error
detection methods involve two parts: identifying surgical gestures and then
detecting errors within each gesture clip. These methods seldom consider the
rich contextual and semantic information inherent in surgical videos, limiting
their performance due to reliance on accurate gesture identification. Motivated
by the chain-of-thought prompting in natural language processing, this letter
presents a novel and real-time end-to-end error detection framework,
Chain-of-Thought (COG) prompting, leveraging contextual information from
surgical videos. This encompasses two reasoning modules designed to mimic the
decision-making processes of expert surgeons. Concretely, we first design a
Gestural-Visual Reasoning module, which utilizes transformer and attention
architectures for gesture prompting, while the second, a Multi-Scale Temporal
Reasoning module, employs a multi-stage temporal convolutional network with
both slow and fast paths for temporal information extraction. We extensively
validate our method on the public benchmark RMIS dataset JIGSAWS. Our method
encapsulates the reasoning processes inherent to surgical activities enabling
it to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,
and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on
average, demonstrating the great potential of our approach in enhancing the
safety and efficacy of RMIS procedures and surgical education. The code will be
available.

中文翻译:
尽管机器人系统和外科数据科学已取得显著进展，但在机器人辅助微创手术（RMIS）中确保安全且最优化的操作执行仍是一项复杂挑战。现有手术错误检测方法包含两个环节：先识别手术手势，再检测每个手势片段中的错误。这些方法很少考虑手术视频中固有的丰富上下文与语义信息，由于依赖精确的手势识别而限制了性能表现。受自然语言处理中思维链提示的启发，本文提出了一种新颖的实时端到端错误检测框架——思维链（COG）提示法，通过利用手术视频的上下文信息，构建了两个模拟外科专家决策过程的推理模块。具体而言，我们首先设计了手势-视觉推理模块，采用Transformer和注意力架构进行手势提示；其次构建了多尺度时序推理模块，通过包含快慢路径的多级时序卷积网络提取时序信息。我们在公开基准RMIS数据集JIGSAWS上进行了全面验证。该方法通过封装手术活动固有的推理过程，在F1分数上超越现有最佳方法4.6%，准确率提升4.6%，杰卡德指数提高5.9%，同时平均每帧处理仅需6.69毫秒，充分证明了其在提升RMIS手术安全性、有效性及外科教育方面的巨大潜力。相关代码将公开提供。
