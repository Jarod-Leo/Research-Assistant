# Leveraging Foundation Models for Zero-Shot IoT Sensing

链接: http://arxiv.org/abs/2407.19893v1

原文摘要:
Deep learning models are increasingly deployed on edge Internet of Things
(IoT) devices. However, these models typically operate under supervised
conditions and fail to recognize unseen classes different from training. To
address this, zero-shot learning (ZSL) aims to classify data of unseen classes
with the help of semantic information. Foundation models (FMs) trained on
web-scale data have shown impressive ZSL capability in natural language
processing and visual understanding. However, leveraging FMs' generalized
knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and
Wi-Fi has not been fully investigated. In this work, we align the IoT data
embeddings with the semantic embeddings generated by an FM's text encoder for
zero-shot IoT sensing. To utilize the physics principles governing the
generation of IoT sensor signals to derive more effective prompts for semantic
embedding extraction, we propose to use cross-attention to combine a learnable
soft prompt that is optimized automatically on training data and an auxiliary
hard prompt that encodes domain knowledge of the IoT sensing task. To address
the problem of IoT embeddings biasing to seen classes due to the lack of unseen
class data during training, we propose using data augmentation to synthesize
unseen class IoT data for fine-tuning the IoT feature extractor and embedding
projector. We evaluate our approach on multiple IoT sensing tasks. Results show
that our approach achieves superior open-set detection and generalized
zero-shot learning performance compared with various baselines. Our code is
available at 