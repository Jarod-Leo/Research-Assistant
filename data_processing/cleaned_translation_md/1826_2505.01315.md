# Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System

链接: http://arxiv.org/abs/2505.01315v1

原文摘要:
The recent growth in the use of Large Language Models has made them
vulnerable to sophisticated adversarial assaults, manipulative prompts, and
encoded malicious inputs. Existing countermeasures frequently necessitate
retraining models, which is computationally costly and impracticable for
deployment. Without the need for retraining or fine-tuning, this study presents
a unique defense paradigm that allows LLMs to recognize, filter, and defend
against adversarial or malicious inputs on their own. There are two main parts
to the suggested framework: (1) A prompt filtering module that uses
sophisticated Natural Language Processing (NLP) techniques, including zero-shot
classification, keyword analysis, and encoded content detection (e.g. base64,
hexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and
(2) A summarization module that processes and summarizes adversarial research
literature to give the LLM context-aware defense knowledge. This approach
strengthens LLMs' resistance to adversarial exploitation by fusing text
extraction, summarization, and harmful prompt analysis. According to
experimental results, this integrated technique has a 98.71% success rate in
identifying harmful patterns, manipulative language structures, and encoded
prompts. By employing a modest amount of adversarial research literature as
context, the methodology also allows the model to react correctly to harmful
inputs with a larger percentage of jailbreak resistance and refusal rate. While
maintaining the quality of LLM responses, the framework dramatically increases
LLM's resistance to hostile misuse, demonstrating its efficacy as a quick and
easy substitute for time-consuming, retraining-based defenses.

中文翻译:
近年来，大型语言模型（LLM）的广泛应用使其面临复杂对抗攻击、操纵性提示和编码恶意输入的威胁。现有防御方案通常需要重新训练模型，不仅计算成本高昂，且在实际部署中可行性较低。本研究提出了一种无需重新训练或微调的创新防御范式，使LLM能够自主识别、过滤并抵御对抗性/恶意输入。该框架包含两大核心模块：（1）提示过滤模块：运用零样本分类、关键词分析及编码内容检测（如base64、十六进制、URL编码）等先进自然语言处理技术，实现对有害输入的检测、解码与分类；（2）文献综述模块：通过处理并总结对抗性研究文献，为LLM提供情境感知的防御知识。该方法融合文本提取、内容摘要和恶意提示分析，显著增强了LLM的抗对抗利用能力。实验表明，该集成技术在识别恶意模式、操纵性语言结构和编码提示方面成功率高达98.71%。通过引入少量对抗研究文献作为上下文，该方法使模型能以更高的越狱抵抗率和拒绝率正确应对有害输入。该框架在保持LLM响应质量的同时，极大提升了模型抗恶意滥用的能力，证明其可作为耗时重训练防御方案的高效替代方案。

（翻译说明：采用学术论文摘要的规范表述，通过以下处理实现专业性与可读性平衡：
1. 专业术语统一："adversarial assaults"译为"对抗攻击"符合计算机安全领域术语
2. 长句拆分：将原文复合长句分解为符合中文表达习惯的短句结构
3. 被动语态转化："are frequently necessitated"转为主动语态"通常需要"
4. 概念显化："jailbreak resistance"译为"越狱抵抗率"并补充说明性表达
5. 数据强调：98.71%保留原格式突出研究成果
6. 逻辑连接：使用"（1）""（2）"保持原文模块化结构清晰度）
