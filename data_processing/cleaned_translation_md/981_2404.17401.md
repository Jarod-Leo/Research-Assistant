# Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations

链接: http://arxiv.org/abs/2404.17401v1

原文摘要:
Language models now constitute essential tools for improving efficiency for
many professional tasks such as writing, coding, or learning. For this reason,
it is imperative to identify inherent biases. In the field of Natural Language
Processing, five sources of bias are well-identified: data, annotation,
representation, models, and research design. This study focuses on biases
related to geographical knowledge. We explore the connection between geography
and language models by highlighting their tendency to misrepresent spatial
information, thus leading to distortions in the representation of geographical
distances. This study introduces four indicators to assess these distortions,
by comparing geographical and semantic distances. Experiments are conducted
from these four indicators with ten widely used language models. Results
underscore the critical necessity of inspecting and rectifying spatial biases
in language models to ensure accurate and equitable representations.

中文翻译:
语言模型如今已成为提升写作、编程、学习等专业任务效率的核心工具。正因如此，识别其内在偏见至关重要。在自然语言处理领域，学界已明确界定了五类偏见来源：数据偏差、标注偏差、表征偏差、模型偏差和研究设计偏差。本研究聚焦于地理知识相关的偏见，通过揭示语言模型误判空间信息的倾向（进而导致地理距离表征失真），探讨了地理学与语言模型的关联。研究提出四项基于地理距离与语义距离比对的评估指标，并据此对十种常用语言模型展开实验。结果凸显了检测与修正语言模型中空间偏见的紧迫性，以确保表征的准确性与公平性。

（翻译说明：采用学术论文摘要的规范表述，通过拆分英文长句为中文短句、转换被动语态为主动语态（如"are well-identified"译为"学界已明确界定"）、补充逻辑连接词（如"进而导致"）等手段提升可读性。关键术语如"bias"统一译为"偏见"，"representation"根据语境分别处理为"表征/表示"。最后通过"凸显...紧迫性"的句式强化研究结论的警示意义。）
