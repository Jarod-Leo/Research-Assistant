# Difficulty in learning chirality for Transformer fed with SMILES

链接: http://arxiv.org/abs/2303.11593v1

原文摘要:
Recent years have seen rapid development of descriptor generation based on
representation learning of extremely diverse molecules, especially those that
apply natural language processing (NLP) models to SMILES, a literal
representation of molecular structure. However, little research has been done
on how these models understand chemical structure. To address this black box,
we investigated the relationship between the learning progress of SMILES and
chemical structure using a representative NLP model, the Transformer. We show
that while the Transformer learns partial structures of molecules quickly, it
requires extended training to understand overall structures. Consistently, the
accuracy of molecular property predictions using descriptors generated from
models at different learning steps was similar from the beginning to the end of
training. Furthermore, we found that the Transformer requires particularly long
training to learn chirality and sometimes stagnates with low performance due to
misunderstanding of enantiomers. These findings are expected to deepen the
understanding of NLP models in chemistry.

中文翻译:
近年来，基于海量分子表征学习的描述符生成技术发展迅猛，尤其是将自然语言处理（NLP）模型应用于SMILES（分子结构的字符串表示）的研究。然而，关于这些模型如何理解化学结构的研究却鲜有报道。为揭示这一"黑箱"机制，我们采用代表性NLP模型Transformer探究了SMILES学习进程与化学结构理解的关系。研究表明：Transformer能快速掌握分子的局部结构特征，但需要更长时间训练才能理解整体结构。相应地，在不同训练阶段生成的描述符进行分子性质预测时，其准确率从训练初期到后期始终维持相近水平。此外，我们发现Transformer需要特别长的训练周期才能掌握手性特征，有时甚至会因对映异构体的误判而陷入低性能停滞状态。这些发现有望深化对化学领域NLP模型工作机制的认知。

（翻译说明：
1. 专业术语处理：SMILES保留英文原名并添加括号解释，"descriptor"译为"描述符"，"enantiomers"译为"对映异构体"
2. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句，如"we investigated..."长句拆分为两个分句
3. 被动语态转换："little research has been done"转为主动式"研究却鲜有报道"
4. 概念显化："black box"译为"黑箱"并添加引号强调其隐喻含义
5. 逻辑连接词优化："Consistently"译为"相应地"更符合中文论文表述习惯
6. 学术风格保持：使用"研究表明""发现"等科研论文常用表述
7. 文化适应性调整：将"extended training"译为"更长时间训练"而非直译"延长训练"，更符合中文表达）
