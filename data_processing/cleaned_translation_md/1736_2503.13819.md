# LLM-Empowered IoT for 6G Networks: Architecture, Challenges, and Solutions

链接: http://arxiv.org/abs/2503.13819v1

原文摘要:
The Internet of Things (IoT) in the sixth generation (6G) era is envisioned
to evolve towards intelligence, ubiquity, and self-optimization. Large language
models (LLMs) have demonstrated remarkable generalization capabilities across
diverse domains, including natural language processing (NLP), computer vision
(CV), and beyond. In this article, we propose an LLM-empowered IoT architecture
for 6G networks to achieve intelligent autonomy while supporting advanced IoT
applications. LLMs are pushed to the edge of the 6G network to support the
synergy of LLMs and IoT. LLM solutions are tailored to both IoT application
requirements and IoT management needs, i.e., LLM for IoT. On the other hand,
edge inference and edge fine-tuning are discussed to support the deployment of
LLMs, i.e., LLM on IoT. Furthermore, we propose a memory-efficient split
federated learning (SFL) framework for LLM fine-tuning on heterogeneous IoT
devices that alleviates memory pressures on both IoT devices and the edge
server while achieving comparable performance and convergence time. Finally, a
case study is presented, followed by a discussion about open issues of
LLM-empowered IoT for 6G networks.

中文翻译:
第六代移动通信（6G）时代的物联网（IoT）将向智能化、泛在化与自主优化方向演进。大语言模型（LLMs）已在自然语言处理（NLP）、计算机视觉（CV）等多领域展现出卓越的泛化能力。本文提出一种面向6G网络的LLM赋能的物联网架构，在支持高级物联网应用的同时实现智能自治。通过将LLMs部署至6G网络边缘，促进大语言模型与物联网的协同发展：一方面针对物联网应用需求与管理需求定制LLM解决方案（LLM for IoT）；另一方面探讨支持LLM部署的边缘推理与边缘微调技术（LLM on IoT）。此外，我们提出基于异构物联网设备的内存高效型分割联邦学习（SFL）框架，在保持性能与收敛时间相当的同时，有效缓解物联网设备与边缘服务器的内存压力。最后通过案例研究，探讨了6G网络中LLM赋能物联网面临的开放性问题。

（翻译说明：
1. 专业术语处理："sixth generation"译为行业标准术语"第六代移动通信"并简称"6G"，"split federated learning"译为"分割联邦学习"并标注英文缩写
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"LLMs are pushed..."处理为主动语态"通过将LLMs部署至..."
3. 概念对应："intelligent autonomy"译为"智能自治"以准确传达技术内涵
4. 逻辑显化：使用冒号和括号明确"LLM for IoT"与"LLM on IoT"的并列关系
5. 技术表述："memory pressures"译为"内存压力"符合计算机领域术语规范）
