# ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity

链接: http://arxiv.org/abs/2404.12010v1

原文摘要:
Paraphrase generation is a pivotal task in natural language processing (NLP).
Existing datasets in the domain lack syntactic and lexical diversity, resulting
in paraphrases that closely resemble the source sentences. Moreover, these
datasets often contain hate speech and noise, and may unintentionally include
non-English language sentences. This research introduces ParaFusion, a
large-scale, high-quality English paraphrase dataset developed using Large
Language Models (LLM) to address these challenges. ParaFusion augments existing
datasets with high-quality data, significantly enhancing both lexical and
syntactic diversity while maintaining close semantic similarity. It also
mitigates the presence of hate speech and reduces noise, ensuring a cleaner and
more focused English dataset. Results show that ParaFusion offers at least a
25% improvement in both syntactic and lexical diversity, measured across
several metrics for each data source. The paper also aims to set a gold
standard for paraphrase evaluation as it contains one of the most comprehensive
evaluation strategies to date. The results underscore the potential of
ParaFusion as a valuable resource for improving NLP applications.

中文翻译:
以下是符合要求的学术中文翻译：

复述生成是自然语言处理（NLP）领域的核心任务。当前该领域的现有数据集存在句法和词汇多样性不足的问题，导致生成的复述文本与源句子高度相似。此外，这些数据集常包含仇恨言论与噪声干扰，并可能混杂非英语语句。本研究提出ParaFusion——一个通过大语言模型（LLM）构建的大规模高质量英语复述数据集，以解决上述问题。该数据集通过高质量数据增强现有语料，在保持紧密语义关联的同时，显著提升了词汇与句法层面的多样性。它还能有效抑制仇恨言论并降低噪声干扰，确保构建出更纯净的英语专用数据集。实验结果表明，针对每个数据源的多项评估指标测量，ParaFusion在句法和词汇多样性上均实现了至少25%的提升。本文还致力于建立复述评估的新基准，其所包含的评估策略体系是迄今最全面的研究之一。最终结果印证了ParaFusion作为提升NLP应用效能的宝贵资源价值。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如"paraphrase generation"译为"复述生成"）
2. 被动语态转化（"are measured"译为"测量"）
3. 长句拆分重组（将原文复合句按中文习惯分解）
4. 学术用语规范（"mitigates"译为"抑制"而非口语化表达）
5. 逻辑关系显化（通过"此外""并""以"等连接词确保行文连贯）
6. 数据呈现完整（精确保留"25%"等关键数值））
