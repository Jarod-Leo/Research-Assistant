# Dissecting Multiplication in Transformers: Insights into LLMs

链接: http://arxiv.org/abs/2407.15360v1

原文摘要:
Transformer-based large language models have achieved remarkable performance
across various natural language processing tasks. However, they often struggle
with seemingly easy tasks like arithmetic despite their vast capabilities. This
stark disparity raise human's concerns about their safe and ethical use, hinder
their widespread adoption.In this paper, we focus on a typical arithmetic task,
integer multiplication, to explore and explain the imperfection of transformers
in this domain. We provide comprehensive analysis of a vanilla transformer
trained to perform n-digit integer multiplication. Our observations indicate
that the model decomposes multiplication task into multiple parallel subtasks,
sequentially optimizing each subtask for each digit to complete the final
multiplication. Based on observation and analysis, we infer the reasons of
transformers deficiencies in multiplication tasks lies in their difficulty in
calculating successive carryovers and caching intermediate results, and
confirmed this inference through experiments. Guided by these findings, we
propose improvements to enhance transformers performance on multiplication
tasks. These enhancements are validated through rigorous testing and
mathematical modeling, not only enhance transformer's interpretability, but
also improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit
integer multiplication with a tiny transformer, outperform LLMs GPT-4. Our
method contributes to the broader fields of model understanding and
interpretability, paving the way for analyzing more complex tasks and
Transformer models. This work underscores the importance of explainable AI,
helping to build trust in large language models and promoting their adoption in
critical applications.

中文翻译:
基于Transformer架构的大规模语言模型在各类自然语言处理任务中展现出卓越性能，但其在算术运算等看似简单的任务上却表现欠佳。这种能力反差不仅引发人类对其安全伦理应用的担忧，也阻碍了其广泛应用。本文以典型算术任务——整数乘法为研究对象，系统探究并阐释Transformer模型在此领域的缺陷。我们对训练执行n位数整数乘法的基准Transformer模型进行了全面分析，发现该模型将乘法任务分解为多个并行子任务，通过逐位优化各子任务来完成最终运算。基于观察分析，我们推断Transformer在乘法任务中的不足源于其难以连续处理进位运算及缓存中间结果，并通过实验验证了这一推论。基于这些发现，我们提出针对性改进方案以提升模型乘法性能。经严格测试与数学建模验证，这些改进不仅增强了模型可解释性，更显著提升了运算精度——例如使用微型Transformer即可实现5位数乘法99.9%以上的准确率，超越GPT-4等大型语言模型。本方法为模型理解与可解释性研究提供了新思路，为分析更复杂任务及Transformer模型开辟了路径。该研究强调了可解释人工智能的重要性，有助于建立对大语言模型的信任，推动其在关键领域的应用落地。

（译文特点说明：
1. 专业术语统一："Transformer"保留英文，"进位运算"对应"carryovers"
2. 长句拆分：将原文复合句按中文习惯分解为多个短句
3. 逻辑显化：添加"基于观察分析"等连接词强化论证链条
4. 动态对等："paving the way"译为"开辟了路径"而非字面直译
5. 学术风格：使用"阐释""探究""推断"等规范学术用语
6. 数据强调：99.9%精度表述保留原文数字增强说服力
7. 文化适配："ethical use"译为"安全伦理应用"符合中文语境）
