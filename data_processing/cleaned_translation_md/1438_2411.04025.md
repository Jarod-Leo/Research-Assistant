# Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages

链接: http://arxiv.org/abs/2411.04025v1

原文摘要:
Language Identification (LI) is crucial for various natural language
processing tasks, serving as a foundational step in applications such as
sentiment analysis, machine translation, and information retrieval. In
multilingual societies like India, particularly among the youth engaging on
social media, text often exhibits code-mixing, blending local languages with
English at different linguistic levels. This phenomenon presents formidable
challenges for LI systems, especially when languages intermingle within single
words. Dravidian languages, prevalent in southern India, possess rich
morphological structures yet suffer from under-representation in digital
platforms, leading to the adoption of Roman or hybrid scripts for
communication. This paper introduces a prompt based method for a shared task
aimed at addressing word-level LI challenges in Dravidian languages. In this
work, we leveraged GPT-3.5 Turbo to understand whether the large language
models is able to correctly classify words into correct categories. Our
findings show that the Kannada model consistently outperformed the Tamil model
across most metrics, indicating a higher accuracy and reliability in
identifying and categorizing Kannada language instances. In contrast, the Tamil
model showed moderate performance, particularly needing improvement in
precision and recall.

中文翻译:
语言识别（LI）作为自然语言处理的基础环节，对于情感分析、机器翻译和信息检索等应用至关重要。在印度等多语言社会环境中，尤其是活跃于社交媒体的年轻群体，文本常呈现语码混合现象——本地语言与英语在不同语言层级上相互交融。这种特性为语言识别系统带来了严峻挑战，特别是当不同语言在单词层面发生混合时。德拉维达语系作为印度南部主流语言，虽具有丰富的形态结构，却在数字平台存在表征不足的问题，导致人们普遍采用罗马字母或混合文字进行交流。本文针对德拉维达语系单词级语言识别任务，提出了一种基于提示词的方法。本研究利用GPT-3.5 Turbo大语言模型，探究其能否准确完成单词分类任务。实验结果表明：在多数评估指标中，卡纳达语模型的表现持续优于泰米尔语模型，显示出更高的识别准确率和分类可靠性；相较而言，泰米尔语模型仅达到中等性能水平，尤其在精确率和召回率等指标上亟待提升。
