# Can LLMs be Fooled? Investigating Vulnerabilities in LLMs

链接: http://arxiv.org/abs/2407.20529v1

原文摘要:
The advent of Large Language Models (LLMs) has garnered significant
popularity and wielded immense power across various domains within Natural
Language Processing (NLP). While their capabilities are undeniably impressive,
it is crucial to identify and scrutinize their vulnerabilities especially when
those vulnerabilities can have costly consequences. One such LLM, trained to
provide a concise summarization from medical documents could unequivocally leak
personal patient data when prompted surreptitiously. This is just one of many
unfortunate examples that have been unveiled and further research is necessary
to comprehend the underlying reasons behind such vulnerabilities. In this
study, we delve into multiple sections of vulnerabilities which are
model-based, training-time, inference-time vulnerabilities, and discuss
mitigation strategies including "Model Editing" which aims at modifying LLMs
behavior, and "Chroma Teaming" which incorporates synergy of multiple teaming
strategies to enhance LLMs' resilience. This paper will synthesize the findings
from each vulnerability section and propose new directions of research and
development. By understanding the focal points of current vulnerabilities, we
can better anticipate and mitigate future risks, paving the road for more
robust and secure LLMs.

中文翻译:
大型语言模型（LLM）的出现获得了广泛关注，并在自然语言处理（NLP）各领域展现出强大能力。尽管其性能令人瞩目，但识别并审视其脆弱性至关重要——尤其是当这些漏洞可能造成重大损失时。例如，某款经过训练可从医疗文档生成摘要的LLM，在被恶意诱导时竟会泄露患者隐私数据。这只是已曝光的众多典型案例之一，我们仍需深入研究其底层成因。  

本研究系统剖析了多维度脆弱性：基于模型架构的缺陷、训练阶段的漏洞及推理环节的风险，并探讨了包括"模型编辑"（通过参数修正改变LLM行为）和"协同染色"（融合多重团队策略增强模型鲁棒性）在内的防御方案。本文综合各脆弱性维度的研究发现，提出未来研发的新方向。通过厘清当前脆弱性的核心症结，我们能够更有效地预测和防范潜在风险，为构建更安全、更健壮的大型语言模型铺平道路。  

（翻译说明：  
1. 专业术语处理："Model Editing"译为行业通用表述"模型编辑"，"Chroma Teaming"采用意译"协同染色"并括号注解  
2. 句式重构：将英文长句拆解为符合中文表达习惯的短句，如首段复合句分解为因果逻辑链  
3. 学术风格保留：使用"剖析""症结""鲁棒性"等学术用语，保持原文严谨性  
4. 文化适配："wielded immense power"译为"展现出强大能力"而非字面翻译，更符合中文技术文献表述习惯  
5. 逻辑显化：通过破折号和"例如"等标记，强化原文隐含的例证关系）
