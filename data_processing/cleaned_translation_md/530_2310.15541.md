# Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary

链接: http://arxiv.org/abs/2310.15541v1

原文摘要:
The non-humanlike behaviour of contemporary pre-trained language models
(PLMs) is a leading cause undermining their trustworthiness. A striking
phenomenon of such faulty behaviours is the generation of inconsistent
predictions, which produces logically contradictory results, such as generating
different predictions for texts delivering the same meaning or violating
logical properties. Previous studies exploited data augmentation or implemented
specialised loss functions to alleviate the issue. However, their usage is
limited, because they consume expensive training resources for large-sized PLMs
and can only handle a certain consistency type. To this end, we propose a
practical approach that alleviates the inconsistent behaviour issue by
fundamentally improving PLMs' meaning awareness. Based on the conceptual role
theory, our method allows PLMs to capture accurate meaning by learning precise
interrelationships between concepts from word-definition pairs in a dictionary.
Next, we propose an efficient parameter integration technique that updates only
a few additional parameters to combine the learned interrelationship with PLMs'
pre-trained knowledge. Our experimental results reveal that the approach can
concurrently improve multiple types of consistency, enables efficient knowledge
integration, and easily applies to other languages.

中文翻译:
当代预训练语言模型（PLMs）的非类人行为是削弱其可信度的主要原因。此类缺陷行为的一个突出表现是生成不一致的预测结果——即产生逻辑矛盾的输出，例如对表达相同语义的文本给出不同预测，或违反基本逻辑属性。现有研究主要通过数据增强或设计特殊损失函数来缓解该问题，但这些方法存在明显局限：它们需要为大型PLMs消耗昂贵训练资源，且仅能处理特定类型的一致性。为此，我们提出一种实用方法，通过根本性提升PLMs的语义感知能力来解决行为不一致问题。基于概念角色理论，我们的方法使PLMs能够通过词典中的词-定义对来学习概念间的精确关联关系，从而捕捉准确语义。继而，我们提出高效的参数集成技术，仅需更新少量附加参数即可将习得的概念关联与PLMs的预训练知识相融合。实验结果表明，该方法能同步提升多种一致性类型，实现高效知识整合，并可轻松迁移至其他语言。
