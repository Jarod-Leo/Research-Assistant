# BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering

链接: http://arxiv.org/abs/2307.15335v1

原文摘要:
Visual Question Answering (VQA) is an intricate and demanding task that
integrates natural language processing (NLP) and computer vision (CV),
capturing the interest of researchers. The English language, renowned for its
wealth of resources, has witnessed notable advancements in both datasets and
models designed for VQA. However, there is a lack of models that target
specific countries such as Vietnam. To address this limitation, we introduce a
transformer-based Vietnamese model named BARTPhoBEiT. This model includes
pre-trained Sequence-to-Sequence and bidirectional encoder representation from
Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets.
Experimental results demonstrate that our proposed model outperforms the strong
baseline and improves the state-of-the-art in six metrics: Accuracy, Precision,
Recall, F1-score, WUPS 0.0, and WUPS 0.9.

中文翻译:
视觉问答（Visual Question Answering，VQA）是一项融合自然语言处理（NLP）与计算机视觉（CV）的复杂且富有挑战性的任务，持续吸引着研究者的关注。英语凭借其丰富的资源优势，在VQA数据集和模型研发领域已取得显著进展。然而针对越南等特定国家的专用模型仍存在空白。为弥补这一不足，我们提出基于Transformer的越南语模型BARTPhoBEiT，该模型整合了越南语序列到序列预训练架构与图像Transformer双向编码表征，并在越南语VQA数据集上进行评估。实验结果表明，我们所提出的模型在准确率、精确率、召回率、F1值、WUPS 0.0及WUPS 0.9六项指标上均超越强基线模型，实现了当前最优性能的提升。

（翻译说明：
1. 专业术语处理：采用"视觉问答"标准译法，保留"Transformer"等技术名词原称
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如实验指标部分
3. 被动语态转换："has witnessed"译为主动式"取得"，"is renowned for"处理为"凭借"
4. 文化适配："strong baseline"译为"强基线模型"符合机器学习领域表述
5. 数据指标保留：WUPS等专业评估指标名称维持英文原称
6. 逻辑显化：通过"为弥补这一不足"等连接词强化段落衔接
7. 术语统一性：全篇保持"越南语"与"越南"的地理称谓一致性）
