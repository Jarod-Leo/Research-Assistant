# Large Language Models Meet Computer Vision: A Brief Survey

链接: http://arxiv.org/abs/2311.16673v1

原文摘要:
Recently, the intersection of Large Language Models (LLMs) and Computer
Vision (CV) has emerged as a pivotal area of research, driving significant
advancements in the field of Artificial Intelligence (AI). As transformers have
become the backbone of many state-of-the-art models in both Natural Language
Processing (NLP) and CV, understanding their evolution and potential
enhancements is crucial. This survey paper delves into the latest progressions
in the domain of transformers and their subsequent successors, emphasizing
their potential to revolutionize Vision Transformers (ViTs) and LLMs. This
survey also presents a comparative analysis, juxtaposing the performance
metrics of several leading paid and open-source LLMs, shedding light on their
strengths and areas of improvement as well as a literature review on how LLMs
are being used to tackle vision related tasks. Furthermore, the survey presents
a comprehensive collection of datasets employed to train LLMs, offering
insights into the diverse data available to achieve high performance in various
pre-training and downstream tasks of LLMs. The survey is concluded by
highlighting open directions in the field, suggesting potential venues for
future research and development. This survey aims to underscores the profound
intersection of LLMs on CV, leading to a new era of integrated and advanced AI
models.

中文翻译:
近年来，大语言模型（LLMs）与计算机视觉（CV）的交叉领域已成为人工智能（AI）研究的关键方向，推动着该领域的重大进展。随着Transformer架构逐渐成为自然语言处理（NLP）和计算机视觉领域众多前沿模型的基石，深入理解其演进路径与优化潜力显得尤为重要。本综述论文系统梳理了Transformer及其后续衍生模型的最新研究进展，重点探讨了这些技术在视觉Transformer（ViT）和大语言模型领域的革命性潜力。通过对比分析多款主流商业与开源大语言模型的性能指标，本研究揭示了各模型的优势所在及待改进空间，同时针对大语言模型处理视觉任务的相关研究进行了文献综述。此外，本文全面汇总了用于训练大语言模型的数据集资源，为研究者实现不同预训练任务与下游任务的高性能表现提供了数据层面的参考。在总结部分，本文指明了该领域尚未解决的研究方向，为未来技术发展提出了建设性建议。本综述旨在强调大语言模型与计算机视觉的深度融合，预示着人工智能即将进入集成化与高阶化发展的新纪元。

（译文特点说明：
1. 专业术语处理：采用"大语言模型/视觉Transformer"等学界通用译法，保留"Transformer"等专有名词原称
2. 长句拆分重构：将英文复合句转换为符合中文表达习惯的短句结构（如将"as transformers..."状语从句转化为独立陈述句）
3. 学术风格保持：使用"系统梳理/探讨/揭示"等学术用语，维持原文严谨性
4. 逻辑显化处理：通过"通过/针对/此外"等连接词强化段落间的逻辑关系
5. 文化适配调整：将"paid models"译为"商业模型"更符合中文技术文献表述习惯）
