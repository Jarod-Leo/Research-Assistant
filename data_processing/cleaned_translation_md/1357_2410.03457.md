# CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds

链接: http://arxiv.org/abs/2410.03457v1

原文摘要:
Detecting logical fallacies in texts can help users spot argument flaws, but
automating this detection is not easy. Manually annotating fallacies in
large-scale, real-world text data to create datasets for developing and
validating detection models is costly. This paper introduces CoCoLoFa, the
largest known logical fallacy dataset, containing 7,706 comments for 648 news
articles, with each comment labeled for fallacy presence and type. We recruited
143 crowd workers to write comments embodying specific fallacy types (e.g.,
slippery slope) in response to news articles. Recognizing the complexity of
this writing task, we built an LLM-powered assistant into the workers'
interface to aid in drafting and refining their comments. Experts rated the
writing quality and labeling validity of CoCoLoFa as high and reliable.
BERT-based models fine-tuned using CoCoLoFa achieved the highest fallacy
detection (F1=0.86) and classification (F1=0.87) performance on its test set,
outperforming the state-of-the-art LLMs. Our work shows that combining
crowdsourcing and LLMs enables us to more effectively construct datasets for
complex linguistic phenomena that crowd workers find challenging to produce on
their own.

中文翻译:
检测文本中的逻辑谬误有助于用户发现论证缺陷，但实现自动化检测并非易事。通过人工标注大规模真实文本数据中的谬误来构建数据集，用于开发和验证检测模型，这一过程成本高昂。本文介绍了目前已知规模最大的逻辑谬误数据集CoCoLoFa，该数据集包含针对648篇新闻文章的7,706条评论，每条评论均标注了谬误存在与否及其具体类型。我们招募了143名众包工作者，要求他们根据新闻文章撰写体现特定谬误类型（如滑坡谬误）的评论。鉴于此项写作任务的复杂性，我们在工作者界面中嵌入了基于大语言模型的智能助手，协助他们起草和修改评论。专家评估表明，CoCoLoFa数据集在写作质量和标注有效性方面均表现出色且可靠。基于该数据集微调的BERT模型在测试集上取得了最优异的谬误检测（F1=0.86）和分类（F1=0.87）性能，超越了当前最先进的大语言模型。本研究证明，通过结合众包与大语言模型，我们能够更有效地构建针对复杂语言现象的数据集——这类数据若仅依靠众包工作者独立完成将极具挑战性。

（翻译说明：  
1. 专业术语处理："logical fallacies"统一译为"逻辑谬误"，"slippery slope"采用学界通用译名"滑坡谬误"  
2. 被动语态转换：将英文被动结构转换为中文主动表达（如"were recruited"译为"招募了"）  
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句  
4. 概念显化："LLM-powered assistant"译为"基于大语言模型的智能助手"以明确技术属性  
5. 指标保留：F1值等专业指标保留原格式确保学术严谨性  
6. 逻辑连接：通过"鉴于""证明"等词强化论证逻辑的连贯性）
