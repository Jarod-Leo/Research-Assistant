# Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese

链接: http://arxiv.org/abs/2309.04175v1

原文摘要:
Large Language Models (LLMs) have demonstrated remarkable success in diverse
natural language processing (NLP) tasks in general domains. However, LLMs
sometimes generate responses with the hallucination about medical facts due to
limited domain knowledge. Such shortcomings pose potential risks in the
utilization of LLMs within medical contexts. To address this challenge, we
propose knowledge-tuning, which leverages structured medical knowledge bases
for the LLMs to grasp domain knowledge efficiently and facilitate reliable
response generation. We also release cMedKnowQA, a Chinese medical knowledge
question-answering dataset constructed from medical knowledge bases to assess
the medical knowledge proficiency of LLMs. Experimental results show that the
LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of
accuracy in response generation compared with vanilla instruction-tuning and
offer a new reliable way for the domain adaptation of LLMs.

中文翻译:
大型语言模型（LLMs）在通用领域的多样化自然语言处理（NLP）任务中已展现出卓越成效。然而，由于领域知识储备有限，LLMs在医疗场景中可能生成包含事实性幻觉的回应，这种缺陷为其在医疗领域的应用带来了潜在风险。为应对这一挑战，我们提出知识调优方法——通过结构化医学知识库使LLMs高效掌握领域知识，从而生成可靠回答。同时，我们发布中文医疗知识问答数据集cMedKnowQA（基于医学知识库构建），用于评估LLMs的医学知识掌握程度。实验结果表明：相较于基础指令调优，采用cMedKnowQA进行知识调优的LLMs能显著提升回答准确率，为LLMs的领域适配提供了新的可靠路径。

（翻译说明：采用学术论文摘要的规范表达，处理了专业术语统一性（如"hallucination"译为"事实性幻觉"）、被动语态转换（如"are constructed"译为"基于...构建"）、长句拆分（如将原文最后复合句拆分为两个中文短句）等问题，同时保持"知识调优"、"领域适配"等核心概念的准确传达。）
