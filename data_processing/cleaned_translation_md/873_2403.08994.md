# Ethos: Rectifying Language Models in Orthogonal Parameter Space

链接: http://arxiv.org/abs/2403.08994v1

原文摘要:
Language models (LMs) have greatly propelled the research on natural language
processing. However, LMs also raise concerns regarding the generation of biased
or toxic content and the potential disclosure of private information from the
training dataset. In this work, we present a new efficient approach, Ethos,
that rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy
leakage. Ethos is built on task arithmetic. However, unlike current task
arithmetic algorithms, Ethos distinguishes general beneficial and undesired
knowledge when reconstructing task vectors. Specifically, Ethos first obtains a
set of principal components from the pre-trained models using singular value
decomposition. Then, by projecting the task vector onto principal components,
Ethos identifies the principal components that encode general or undesired
knowledge. Ethos performs negating using the task vector with undesired
knowledge only, thereby minimizing collateral damage on general model utility.
We demonstrate the efficacy of our approach on three different tasks:
debiasing, detoxification, and memorization unlearning. Evaluations show Ethos
is more effective in removing undesired knowledge and maintaining the overall
model performance compared to current task arithmetic methods.

中文翻译:
语言模型（LMs）极大地推动了自然语言处理领域的研究进展。然而，这类模型也引发了诸多担忧，包括可能生成带有偏见或有害的内容，以及从训练数据中泄露隐私信息的风险。本研究提出了一种名为Ethos的新型高效修正方法，通过改造语言模型来降低输出内容的毒性与偏见，同时避免隐私泄露问题。

Ethos基于任务算术框架构建，但与现有算法不同，其在重构任务向量时能够区分通用有益知识与不良知识。具体而言，该方法首先通过奇异值分解从预训练模型中提取一组主成分，随后将任务向量投影至这些主成分上，从而识别出编码通用知识或不良知识的主成分。Ethos仅对包含不良知识的任务向量执行否定操作，最大限度减少对模型整体性能的附带损害。

我们在去偏置、去毒化和遗忘记忆三项任务上验证了该方法的有效性。评估结果表明，与现有任务算术方法相比，Ethos在消除不良知识的同时，能更好地保持模型的整体性能。
