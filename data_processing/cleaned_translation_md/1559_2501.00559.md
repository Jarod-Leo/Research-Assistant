# AraSTEM: A Native Arabic Multiple Choice Question Benchmark for Evaluating LLMs Knowledge In STEM Subjects

链接: http://arxiv.org/abs/2501.00559v1

原文摘要:
Large Language Models (LLMs) have shown remarkable capabilities, not only in
generating human-like text, but also in acquiring knowledge. This highlights
the need to go beyond the typical Natural Language Processing downstream
benchmarks and asses the various aspects of LLMs including knowledge and
reasoning. Numerous benchmarks have been developed to evaluate LLMs knowledge,
but they predominantly focus on the English language. Given that many LLMs are
multilingual, relying solely on benchmarking English knowledge is insufficient.
To address this issue, we introduce AraSTEM, a new Arabic multiple-choice
question dataset aimed at evaluating LLMs knowledge in STEM subjects. The
dataset spans a range of topics at different levels which requires models to
demonstrate a deep understanding of scientific Arabic in order to achieve high
accuracy. Our findings show that publicly available models of varying sizes
struggle with this dataset, and underscores the need for more localized
language models. The dataset is freely accessible on Hugging Face.

中文翻译:
大型语言模型（LLMs）不仅展现出类人文本生成的卓越能力，还表现出知识获取的显著特性。这一现象凸显了超越传统自然语言处理下游基准测试的必要性，亟需对LLMs的知识储备与推理能力等多维度进行系统评估。尽管目前已涌现大量针对LLMs知识水平的评测基准，但这些基准主要聚焦英语语种。鉴于多数LLMs具备多语言处理能力，仅通过英语知识评估显然不够全面。

为此，我们推出AraSTEM——一个全新的阿拉伯语多项选择题数据集，专门用于评估LLMs在STEM（科学、技术、工程、数学）领域的知识掌握度。该数据集涵盖多层级主题内容，要求模型必须对阿拉伯科学术语具备深度理解才能获得高准确率。实验结果表明，当前公开的不同规模模型在该数据集上均表现欠佳，这印证了开发本土化语言模型的迫切需求。本数据集已在Hugging Face平台开源发布。

（翻译说明：采用学术论文摘要的标准表述方式，通过拆分英文长句为中文短句结构，保留"benchmarking"等专业术语的准确译法，将"localized"译为"本土化"更符合中文技术文献表述习惯，同时确保"multiple-choice question dataset"等专业表述的准确性。最后补充平台名称"Hugging Face"的官方中文译名以保持专业性。）
