# Extracting Definienda in Mathematical Scholarly Articles with Transformers

链接: http://arxiv.org/abs/2311.12448v1

原文摘要:
We consider automatically identifying the defined term within a mathematical
definition from the text of an academic article. Inspired by the development of
transformer-based natural language processing applications, we pose the problem
as (a) a token-level classification task using fine-tuned pre-trained
transformers; and (b) a question-answering task using a generalist large
language model (GPT). We also propose a rule-based approach to build a labeled
dataset from the LATEX source of papers. Experimental results show that it is
possible to reach high levels of precision and recall using either recent (and
expensive) GPT 4 or simpler pre-trained models fine-tuned on our task.

中文翻译:
本文研究如何从学术论文文本中自动识别数学定义中的被定义项。受基于Transformer的自然语言处理应用发展的启发，我们将该问题转化为：(a) 使用微调预训练Transformer的token级分类任务；(b) 采用通用大语言模型(GPT)的问答任务。我们还提出了一种基于规则的方法，可从论文的LATEX源码构建标注数据集。实验结果表明，无论是使用最新（且昂贵）的GPT-4，还是采用针对本任务微调的简单预训练模型，都能实现较高的精确率与召回率。

（翻译说明：1. 专业术语处理："defined term"译为"被定义项"符合数学文献惯例；2. 句式重构：将英文长句拆分为符合中文表达习惯的短句；3. 被动语态转换："it is possible"译为主动句式"能实现"；4. 技术术语统一："fine-tuned"始终译为"微调"；5. 补充说明：用括号处理"expensive"的附加信息，保持行文流畅；6. 学术风格保留：保持"精确率与召回率"等专业表述方式）
