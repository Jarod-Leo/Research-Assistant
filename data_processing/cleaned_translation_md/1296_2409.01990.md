# Contemporary Model Compression on Large Language Models Inference

链接: http://arxiv.org/abs/2409.01990v1

原文摘要:
This paper focuses on modern efficient training and inference technologies on
foundation models and illustrates them from two perspectives: model and system
design. Model and System Design optimize LLM training and inference from
different aspects to save computational resources, making LLMs more efficient,
affordable, and more accessible. The paper list repository is available at
