# Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges

链接: http://arxiv.org/abs/2311.15766v1

原文摘要:
In recent years, large language models (LLMs) have spurred a new research
paradigm in natural language processing. Despite their excellent capability in
knowledge-based question answering and reasoning, their potential to retain
faulty or even harmful knowledge poses risks of malicious application. The
challenge of mitigating this issue and transforming these models into purer
assistants is crucial for their widespread applicability. Unfortunately,
Retraining LLMs repeatedly to eliminate undesirable knowledge is impractical
due to their immense parameters. Knowledge unlearning, derived from analogous
studies on machine unlearning, presents a promising avenue to address this
concern and is notably advantageous in the context of LLMs. It allows for the
removal of harmful knowledge in an efficient manner, without affecting
unrelated knowledge in the model. To this end, we provide a survey of knowledge
unlearning in the era of LLMs. Firstly, we formally define the knowledge
unlearning problem and distinguish it from related works. Subsequently, we
categorize existing knowledge unlearning methods into three classes: those
based on parameter optimization, parameter merging, and in-context learning,
and introduce details of these unlearning methods. We further present
evaluation datasets used in existing methods, and finally conclude this survey
by presenting the ongoing challenges and future directions.

中文翻译:
近年来，大语言模型（LLMs）推动了自然语言处理领域的新研究范式。尽管其在知识问答与推理任务中展现出卓越能力，但模型可能保留错误甚至有害知识的特点，带来了恶意应用的风险。如何缓解这一问题并将这些模型转化为更纯净的智能助手，对其广泛应用至关重要。然而，由于大语言模型参数量庞大，通过反复重训练来消除不良知识显然不切实际。知识遗忘技术——源自机器学习中遗忘学习的类似研究——为解决这一难题提供了可行路径，尤其在大语言模型场景中具有显著优势。该技术能以高效方式定向清除有害知识，同时不影响模型中其他无关知识。为此，本文系统梳理了大语言模型时代的知识遗忘研究进展：首先正式定义知识遗忘问题并厘清其与相关工作的区别；继而将现有方法划分为基于参数优化、参数融合和上下文学习三大类，并详解各类遗忘方法；进一步汇总现有研究采用的评估数据集；最后指出该领域面临的持续挑战与未来发展方向。
