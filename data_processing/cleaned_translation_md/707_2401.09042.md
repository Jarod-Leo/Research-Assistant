# LLMs for Relational Reasoning: How Far are We?

链接: http://arxiv.org/abs/2401.09042v1

原文摘要:
Large language models (LLMs) have revolutionized many areas (e.g. natural
language processing, software engineering, etc.) by achieving state-of-the-art
performance on extensive downstream tasks. Aiming to achieve robust and general
artificial intelligence, there has been a surge of interest in investigating
the reasoning ability of the LLMs. Whereas the textual and numerical reasoning
benchmarks adopted by previous works are rather shallow and simple, it is hard
to conclude that the LLMs possess strong reasoning ability by merely achieving
positive results on these benchmarks. Recent efforts have demonstrated that the
LLMs are poor at solving sequential decision-making problems that require
common-sense planning by evaluating their performance on the reinforcement
learning benchmarks. In this work, we conduct an in-depth assessment of several
state-of-the-art LLMs' reasoning ability based on the inductive logic
programming (ILP) benchmark, which is broadly recognized as a representative
and challenging measurement for evaluating logic program induction/synthesis
systems as it requires inducing strict cause-effect logic to achieve robust
deduction on independent and identically distributed (IID) and
out-of-distribution (OOD) test samples. Our evaluations illustrate that
compared with the neural program induction systems which are much smaller in
model size, the state-of-the-art LLMs are much poorer in terms of reasoning
ability by achieving much lower performance and generalization using either
natural language prompting or truth-value matrix prompting.

中文翻译:
大型语言模型（LLMs）通过在众多下游任务中实现最先进的性能，彻底改变了自然语言处理、软件工程等多个领域。为追求稳健且通用的人工智能，学界对LLMs推理能力的研究兴趣激增。然而既有工作采用的文本与数值推理基准测试较为浅显简单，仅凭这些基准的优异表现难以断言LLMs具备强大推理能力。最新研究表明，通过强化学习基准测试评估发现，LLMs在需要常识规划的序列决策问题上表现欠佳。本研究基于归纳逻辑编程（ILP）基准对多个前沿LLMs进行深度评估——该基准被广泛视为评估逻辑程序归纳/合成系统的代表性挑战，因其要求通过严格的因果逻辑归纳，在独立同分布（IID）和分布外（OOD）测试样本上实现稳健演绎。评估结果表明：相较于模型规模小得多的神经程序归纳系统，当前最先进的LLMs无论是采用自然语言提示还是真值矩阵提示，其推理能力都显著逊色，表现为更低的性能与泛化能力。
