# Towards Reasoning in Large Language Models: A Survey

链接: http://arxiv.org/abs/2212.10403v1

原文摘要:
Reasoning is a fundamental aspect of human intelligence that plays a crucial
role in activities such as problem solving, decision making, and critical
thinking. In recent years, large language models (LLMs) have made significant
progress in natural language processing, and there is observation that these
models may exhibit reasoning abilities when they are sufficiently large.
However, it is not yet clear to what extent LLMs are capable of reasoning. This
paper provides a comprehensive overview of the current state of knowledge on
reasoning in LLMs, including techniques for improving and eliciting reasoning
in these models, methods and benchmarks for evaluating reasoning abilities,
findings and implications of previous research in this field, and suggestions
on future directions. Our aim is to provide a detailed and up-to-date review of
this topic and stimulate meaningful discussion and future work.

中文翻译:
推理是人类智能的核心要素，在问题解决、决策制定和批判性思维等活动中发挥着关键作用。近年来，大型语言模型（LLMs）在自然语言处理领域取得显著进展，有观察表明当模型规模足够大时可能展现出推理能力。然而，目前尚不清楚LLMs具备何种程度的推理能力。本文全面梳理了LLMs推理研究的现状，包括：提升和激发模型推理能力的技术手段、推理能力评估方法与基准测试、该领域已有研究的发现与启示，以及对未来方向的建议。我们旨在提供一份详尽且前沿的综述，以促进深入讨论和后续研究。

（翻译说明：采用学术论文摘要的规范表述，通过以下处理实现专业性与可读性平衡：
1. 将"fundamental aspect"译为"核心要素"而非字面翻译，突出重要性
2. "exhibit reasoning abilities"译为"展现出推理能力"符合中文主动语态习惯
3. 长句拆分重组，如将原文包含5个并列成分的长句分解为中文更易接受的逗号分隔短句
4. 专业术语统一处理："benchmarks"统一译为"基准测试"而非"基准"或"标杆"
5. 保持学术文本客观性，避免添加原文没有的主观评价
6. 结尾"stimulate..."译为"促进深入讨论和后续研究"既准确传达原意，又符合中文摘要结尾惯例）
