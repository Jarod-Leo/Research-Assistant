# Language Model Knowledge Distillation for Efficient Question Answering in Spanish

链接: http://arxiv.org/abs/2312.04193v1

原文摘要:
Recent advances in the development of pre-trained Spanish language models has
led to significant progress in many Natural Language Processing (NLP) tasks,
such as question answering. However, the lack of efficient models imposes a
barrier for the adoption of such models in resource-constrained environments.
Therefore, smaller distilled models for the Spanish language could be proven to
be highly scalable and facilitate their further adoption on a variety of tasks
and scenarios. In this work, we take one step in this direction by developing
SpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient
question answering in Spanish. To achieve this, we employ knowledge
distillation from a large model onto a lighter model that allows for a wider
implementation, even in areas with limited computational resources, whilst
attaining negligible performance sacrifice. Our experiments show that the dense
distilled model can still preserve the performance of its larger counterpart,
while significantly increasing inference speedup. This work serves as a
starting point for further research and investigation of model compression
efforts for Spanish language models across various NLP tasks.

中文翻译:
以下是您提供的英文论文摘要的中文翻译：

【中文译文】  
近年来，西班牙语预训练语言模型的发展取得了显著进展，推动了许多自然语言处理（NLP）任务的突破，例如问答系统。然而，高效模型的缺失为这些模型在资源受限环境中的实际应用设置了障碍。因此，针对西班牙语开发的轻量化蒸馏模型可能具备高度可扩展性，有助于在多样化任务和场景中进一步推广。本研究通过开发SpanishTinyRoBERTa（一种基于RoBERTa的压缩语言模型）迈出了探索性一步，旨在实现西班牙语高效问答。我们采用知识蒸馏技术，将大模型的能力迁移至更轻量的模型中，从而使其能够在计算资源有限的领域广泛部署，同时保持性能损失可忽略不计。实验表明，这种稠密蒸馏模型在显著提升推理速度的同时，仍能保留原大模型的性能表现。本工作为西班牙语模型在不同NLP任务中的压缩研究提供了基础，可推动后续相关探索。

【翻译要点说明】  
1. 术语处理：  
   - "knowledge distillation"译为"知识蒸馏"（NLP领域标准译法）  
   - "inference speedup"译为"推理速度提升"（兼顾专业性与可读性）  

2. 句式重构：  
   - 将英语长句拆解为符合中文表达习惯的短句（如原文第二句拆分后通过"因此"衔接逻辑）  
   - 被动语态转换（如"could be proven to..."译为主动句式"可能具备..."）  

3. 技术概念传达：  
   - "compressed language model"译为"压缩语言模型"而非直译"压缩的"，更符合技术文献表述  
   - "dense distilled model"保留"稠密蒸馏模型"的专业表述，通过上下文确保理解  

4. 学术风格保持：  
   - 使用"本研究""本工作"等学术用语  
   - "whilst attaining..."译为"同时保持..."，避免口语化  

5. 文化适应性：  
   - "resource-constrained environments"译为"资源受限环境"而非字面直译，符合中文技术文献惯例
