# Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting

链接: http://arxiv.org/abs/2408.01423v1

原文摘要:
Large Language Models (LLMs) exhibit remarkable proficiency in addressing a
diverse array of tasks within the Natural Language Processing (NLP) domain,
with various prompt design strategies significantly augmenting their
capabilities. However, these prompts, while beneficial, each possess inherent
limitations. The primary prompt design methodologies are twofold: The first,
exemplified by the Chain of Thought (CoT), involves manually crafting prompts
specific to individual datasets, hence termed Expert-Designed Prompts (EDPs).
Once these prompts are established, they are unalterable, and their
effectiveness is capped by the expertise of the human designers. When applied
to LLMs, the static nature of EDPs results in a uniform approach to both simple
and complex problems within the same dataset, leading to the inefficient use of
tokens for straightforward issues. The second method involves prompts
autonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which
provide tailored solutions to specific problems, mitigating the limitations of
EDPs. However, LDPs may encounter a decline in performance when tackling
complex problems due to the potential for error accumulation during the
solution planning process. To address these challenges, we have conceived a
novel Prompt Recursive Search (PRS) framework that leverages the LLM to
generate solutions specific to the problem, thereby conserving tokens. The
framework incorporates an assessment of problem complexity and an adjustable
structure, ensuring a reduction in the likelihood of errors. We have
substantiated the efficacy of PRS framework through extensive experiments using
LLMs with different numbers of parameters across a spectrum of datasets in
various domains. Compared to the CoT method, the PRS method has increased the
accuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%
improvement.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）在自然语言处理（NLP）领域展现出解决多样化任务的卓越能力，其中各类提示设计策略显著增强了其性能。然而现有提示方法均存在固有局限性：主流设计方法可分为两类——第一类以思维链（CoT）为代表，通过人工为特定数据集定制提示模板（专家设计提示，EDPs）。这类提示一旦确立便不可修改，其效果受限于设计者的专业水平。当应用于LLMs时，EDPs的静态特性导致其对同一数据集中简单与复杂问题采用统一处理方式，造成简单问题的令牌使用效率低下。第二类是由LLM自主生成的提示（LLM衍生提示，LDPs），虽能针对具体问题提供定制化解决方案以克服EDPs的局限，但在处理复杂问题时可能因解决方案规划过程中的错误累积而导致性能下降。

为应对这些挑战，我们提出新型提示递归搜索（PRS）框架：通过LLM生成问题专属解决方案以节省令牌消耗，该框架集成问题复杂度评估机制与可调节结构，能有效降低错误发生概率。我们采用不同参数规模的LLM在跨领域数据集上进行了广泛实验，验证了PRS框架的有效性。相较于CoT方法，使用Llama3-7B模型时PRS在BBH数据集上的准确率提升8%，总体改进幅度达22%。

（翻译说明：1. 专业术语保留英文缩写并首次出现时标注全称 2. 长句按中文习惯拆分为逻辑连贯的短句 3. 被动语态转换为主动表述 4. 关键概念如"token"译为业界通用译法"令牌" 5. 数据指标表述符合中文科技论文规范）
