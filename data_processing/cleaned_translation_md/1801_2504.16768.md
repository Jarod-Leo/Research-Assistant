# How Effective are Generative Large Language Models in Performing Requirements Classification?

链接: http://arxiv.org/abs/2504.16768v1

原文摘要:
In recent years, transformer-based large language models (LLMs) have
revolutionised natural language processing (NLP), with generative models
opening new possibilities for tasks that require context-aware text generation.
Requirements engineering (RE) has also seen a surge in the experimentation of
LLMs for different tasks, including trace-link detection, regulatory
compliance, and others. Requirements classification is a common task in RE.
While non-generative LLMs like BERT have been successfully applied to this
task, there has been limited exploration of generative LLMs. This gap raises an
important question: how well can generative LLMs, which produce context-aware
outputs, perform in requirements classification? In this study, we explore the
effectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing
both binary and multi-class requirements classification. We design an extensive
experimental study involving over 400 experiments across three widely used
datasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes
that while factors like prompt design and LLM architecture are universally
important, others-such as dataset variations-have a more situational impact,
depending on the complexity of the classification task. This insight can guide
future model development and deployment strategies, focusing on optimising
prompt structures and aligning model architectures with task-specific needs for
improved performance.

中文翻译:
近年来，基于Transformer架构的大语言模型（LLMs）彻底改变了自然语言处理（NLP）领域，其中生成式模型为需要上下文感知文本生成的任务开辟了新可能。在需求工程（RE）领域，LLMs在不同任务中的实验应用也呈现激增态势，包括追踪链接检测、法规合规性验证等。需求分类作为RE中的常规任务，虽然BERT等非生成式LLMs已成功应用于此，但针对生成式LLMs的探索仍显不足。这一空白引出了一个关键问题：具有上下文感知输出能力的生成式LLMs在需求分类任务中表现如何？本研究系统评估了三种生成式LLMs（Bloom、Gemma和Llama）在二元及多元需求分类中的有效性。我们设计了涵盖三个广泛使用数据集（PROMISE NFR、Functional-Quality和SecReq）的400余次实验的综合性研究。研究表明：虽然提示词设计和LLM架构等要素具有普适重要性，但数据集差异等因素的影响则更具情境依赖性，其作用程度与分类任务的复杂度相关。这一发现可为未来模型开发与部署策略提供指导，建议通过优化提示结构和使模型架构适配特定任务需求来提升性能。

（翻译说明：采用学术论文摘要的规范表述方式，通过以下处理实现专业性与可读性平衡：
1. 术语统一："context-aware"译为"上下文感知"，"trace-link detection"保留专业表述"追踪链接检测"
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句，如将实验设计部分重组为两个层次
3. 逻辑显化：增加"系统评估"等动词强化研究动作，使用"这一空白"等指代词保持上下文衔接
4. 被动语态转换：将英文被动式改为中文主动式，如"has been successfully applied"译为"已成功应用"
5. 数字规范：保留阿拉伯数字"400"符合中文科技文献惯例）
