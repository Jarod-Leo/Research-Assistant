# GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models

链接: http://arxiv.org/abs/2408.04905v1

原文摘要:
Large language models (LLMs) have achieved unprecedented success in the field
of natural language processing. However, the black-box nature of their internal
mechanisms has brought many concerns about their trustworthiness and
interpretability. Recent research has discovered a class of abnormal tokens in
the model's vocabulary space and named them "glitch tokens". Those tokens, once
included in the input, may induce the model to produce incorrect, irrelevant,
or even harmful results, drastically undermining the reliability and
practicality of LLMs.
  In this work, we aim to enhance the understanding of glitch tokens and
propose techniques for their detection and mitigation. We first reveal the
characteristic features induced by glitch tokens on LLMs, which are evidenced
by significant deviations in the distributions of attention patterns and
dynamic information from intermediate model layers. Based on the insights, we
develop GlitchProber, a tool for efficient glitch token detection and
mitigation. GlitchProber utilizes small-scale sampling, principal component
analysis for accelerated feature extraction, and a simple classifier for
efficient vocabulary screening. Taking one step further, GlitchProber rectifies
abnormal model intermediate layer values to mitigate the destructive effects of
glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber
demonstrates higher efficiency, precision, and recall compared to existing
approaches, with an average F1 score of 0.86 and an average repair rate of
50.06%. GlitchProber unveils a novel path to address the challenges posed by
glitch tokens and inspires future research toward more robust and interpretable
LLMs.

中文翻译:
以下是符合要求的学术中文翻译：

大语言模型（LLMs）在自然语言处理领域取得了前所未有的成功。然而，其内部机制的黑箱特性引发了关于模型可信度与可解释性的诸多担忧。最新研究发现模型词汇空间中存在一类异常标记，并将其命名为"故障标记（glitch tokens）"。这些标记一旦出现在输入中，可能诱导模型产生错误、无关甚至有害的输出，严重损害大语言模型的可靠性与实用性。

本研究旨在深化对故障标记的理解，并提出相应的检测与缓解技术。我们首先揭示了故障标记在大语言模型中诱发的特征现象，通过中间层注意力模式分布与动态信息的显著偏差提供了实证依据。基于这些发现，我们开发了GlitchProber工具，用于高效检测和缓解故障标记。该工具采用小规模采样策略，结合主成分分析加速特征提取，并运用简单分类器实现高效词汇筛查。进一步地，GlitchProber通过修正模型中间层的异常数值来消除故障标记的破坏性影响。在五个主流开源大语言模型上的评估表明，相较于现有方法，GlitchProber具有更高的效率、精确率与召回率，平均F1值达到0.86，平均修复率为50.06%。本研究为解决故障标记带来的挑战开辟了新路径，为构建更具鲁棒性和可解释性的大语言模型提供了启示。


