# How Good are Commercial Large Language Models on African Languages?

链接: http://arxiv.org/abs/2305.06530v1

原文摘要:
Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.

中文翻译:
自然语言处理（NLP）领域的最新进展促使大规模预训练语言模型激增。研究表明，即使面对未见过的任务和语言，这些模型通过上下文学习仍能表现出色。它们还以语言模型即服务（LMaaS）的形式作为商业API开放，获得了广泛应用。然而，这些模型在非洲语言上的表现仍属未知领域。本文针对八种分属不同语系和地理区域的非洲语言，对商用大语言模型在机器翻译和文本分类两项任务上的表现进行了初步分析。结果表明，当前商用语言模型对非洲语言的处理能力普遍低于基准水平，且在文本分类任务上的表现优于机器翻译。鉴于这类模型的日益普及，我们的研究发现呼吁业界采取行动，确保非洲语言在商用大语言模型中获得充分表征。  

  
2. 专业术语准确对应（"in-context learning"译作"上下文学习"，"language-model-as-a-service"保留英文缩写并补充中文全称）  
3. 长句拆分重组（如最后一句拆分为因果关系的两个分句）  
4. 文化适配："call-to-action"译为"呼吁采取行动"而非字面直译  
5. 保持学术文本的客观性，避免添加原文没有的情感色彩）
