# Toxicity in ChatGPT: Analyzing Persona-assigned Language Models

链接: http://arxiv.org/abs/2304.05335v1

原文摘要:
Large language models (LLMs) have shown incredible capabilities and
transcended the natural language processing (NLP) community, with adoption
throughout many services like healthcare, therapy, education, and customer
service. Since users include people with critical information needs like
students or patients engaging with chatbots, the safety of these systems is of
prime importance. Therefore, a clear understanding of the capabilities and
limitations of LLMs is necessary. To this end, we systematically evaluate
toxicity in over half a million generations of ChatGPT, a popular
dialogue-based LLM. We find that setting the system parameter of ChatGPT by
assigning it a persona, say that of the boxer Muhammad Ali, significantly
increases the toxicity of generations. Depending on the persona assigned to
ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect
stereotypes, harmful dialogue, and hurtful opinions. This may be potentially
defamatory to the persona and harmful to an unsuspecting user. Furthermore, we
find concerning patterns where specific entities (e.g., certain races) are
targeted more than others (3x more) irrespective of the assigned persona, that
reflect inherent discriminatory biases in the model. We hope that our findings
inspire the broader AI community to rethink the efficacy of current safety
guardrails and develop better techniques that lead to robust, safe, and
trustworthy AI systems.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）已展现出卓越的能力并超越自然语言处理（NLP）领域，广泛应用于医疗保健、心理治疗、教育及客服等诸多服务场景。由于用户群体包含学生、患者等通过聊天机器人获取关键信息的群体，这类系统的安全性至关重要。因此，必须清晰认知大型语言模型的能力边界与局限性。为此，我们系统评估了基于对话的流行LLM模型ChatGPT逾50万次生成内容中的毒性现象。研究发现：通过角色设定（如拳击手穆罕默德·阿里）调整ChatGPT系统参数会显著增加生成内容的毒性。根据所赋予角色的不同，其毒性输出最高可增长6倍，表现为错误刻板印象、有害对话及伤害性观点，既可能对角色构成诽谤，也可能对无戒备的用户造成伤害。更值得注意的是，我们发现了特定实体（如某些种族）无论被赋予何种角色都会遭受3倍于其他群体的针对性攻击，这反映出模型固有的歧视性偏见。本研究期望能推动AI学界重新审视现有安全防护机制的有效性，并开发出更强大的技术以构建稳健、安全、可信的人工智能系统。

翻译说明：
1. 专业术语处理：LLMs/NLP等缩写保留英文并首次标注全称，专业表述如"toxicity"译为学术惯用的"毒性"
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句（如第一句拆分为两个逻辑层），同时保持学术严谨性
3. 概念对等："persona"译为"角色设定"而非字面直译，准确传达技术含义
4. 数据呈现：精确转换数量级表述（"over half a million"译为"逾50万"），保持6x/3x等倍数关系的学术规范
5. 学术风格：使用"研究发现""值得注意的是"等学术用语，避免口语化表达
6. 文化适配："Muhammad Ali"采用通用译名"穆罕默德·阿里"并补充说明身份
