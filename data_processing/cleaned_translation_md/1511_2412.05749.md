# A Comparative Study on Code Generation with Transformers

链接: http://arxiv.org/abs/2412.05749v1

原文摘要:
In an era of widespread influence of Natural Language Processing (NLP), there
have been multiple research efforts to supplant traditional manual coding
techniques with automated systems capable of generating solutions autonomously.
With rapid research for code generation and a sole focus on large language
models, there emerges a need to compare and evaluate the performance of
transformer architectures based on several complexities of the model. This
paper introduces the concept of a "A Comparative Study on Code Generation with
Transformers," a model based on Transformer architecture, and NLP methodologies
to automatically generate C++ source code for different varieties of problems.
Here, a comparative study is performed to evaluate the robustness of
transformer-based models on the basis of their architecture complexities and
their capability to handle diverse problem sets, from basic arithmetic to
complex computations.

中文翻译:
在自然语言处理（NLP）技术广泛影响的时代，已有诸多研究致力于用能够自主生成解决方案的自动化系统取代传统人工编码技术。随着代码生成研究的快速推进以及研究焦点完全集中于大语言模型，有必要基于模型的多重复杂性对Transformer架构的性能进行比较与评估。本文提出"基于Transformer的代码生成对比研究"概念，该模型依托Transformer架构与NLP方法学，能针对不同类型问题自动生成C++源代码。研究通过对比实验评估了不同Transformer模型的鲁棒性，分析重点包括架构复杂度差异以及模型处理多样化问题集（从基础算术到复杂计算）的能力表现。

（翻译说明：采用技术文本专业表述，通过拆分英文长句为中文短句增强可读性；将"several complexities"译为"多重复杂性"以准确传达原意；"diverse problem sets"处理为"多样化问题集"既保留专业术语特征又符合中文表达习惯；通过增译"分析重点包括"使逻辑衔接更自然；整体保持学术论文摘要的严谨风格，同时确保术语统一性）
