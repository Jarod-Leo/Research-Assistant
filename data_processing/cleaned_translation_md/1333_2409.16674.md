# A Prompting-Based Representation Learning Method for Recommendation with Large Language Models

链接: http://arxiv.org/abs/2409.16674v1

原文摘要:
In recent years, Recommender Systems (RS) have witnessed a transformative
shift with the advent of Large Language Models (LLMs) in the field of Natural
Language Processing (NLP). Models such as GPT-3.5/4, Llama, have demonstrated
unprecedented capabilities in understanding and generating human-like text. The
extensive information pre-trained by these LLMs allows for the potential to
capture a more profound semantic representation from different contextual
information of users and items.
  While the great potential lies behind the thriving of LLMs, the challenge of
leveraging user-item preferences from contextual information and its alignment
with the improvement of Recommender Systems needs to be addressed. Believing
that a better understanding of the user or item itself can be the key factor in
improving recommendation performance, we conduct research on generating
informative profiles using state-of-the-art LLMs.
  To boost the linguistic abilities of LLMs in Recommender Systems, we
introduce the Prompting-Based Representation Learning Method for Recommendation
(P4R). In our P4R framework, we utilize the LLM prompting strategy to create
personalized item profiles. These profiles are then transformed into semantic
representation spaces using a pre-trained BERT model for text embedding.
Furthermore, we incorporate a Graph Convolution Network (GCN) for collaborative
filtering representation. The P4R framework aligns these two embedding spaces
in order to address the general recommendation tasks. In our evaluation, we
compare P4R with state-of-the-art Recommender models and assess the quality of
prompt-based profile generation.

中文翻译:
近年来，随着自然语言处理（NLP）领域大型语言模型（LLMs）的出现，推荐系统（RS）经历了革命性变革。以GPT-3.5/4、Llama为代表的模型在理解和生成类人文本方面展现出前所未有的能力。这些LLMs通过海量信息预训练，有望从用户与项目的多维度上下文信息中捕获更深层次的语义表征。

尽管LLMs的蓬勃发展蕴含着巨大潜力，但如何从上下文信息中挖掘用户-项目偏好，并将其与推荐系统优化相融合仍面临挑战。我们认为，深入理解用户或项目本质可能是提升推荐性能的关键因素，因此致力于运用前沿LLMs生成信息丰富的用户画像。

为增强LLMs在推荐系统中的语言处理能力，我们提出基于提示学习的推荐表征学习方法（P4R）。该框架采用LLM提示策略生成个性化项目画像，通过预训练BERT模型将这些画像转化为语义表征空间。同时引入图卷积网络（GCN）获取协同过滤表征，通过双空间对齐机制完成通用推荐任务。实验评估中，我们将P4R与前沿推荐模型进行对比，并对基于提示的画像生成质量进行系统评估。
