# mChartQA: A universal benchmark for multimodal Chart Question Answer based on Vision-Language Alignment and Reasoning

链接: http://arxiv.org/abs/2404.01548v1

原文摘要:
In the fields of computer vision and natural language processing, multimodal
chart question-answering, especially involving color, structure, and textless
charts, poses significant challenges. Traditional methods, which typically
involve either direct multimodal processing or a table-to-text conversion
followed by language model analysis, have limitations in effectively handling
these complex scenarios. This paper introduces a novel multimodal chart
question-answering model, specifically designed to address these intricate
tasks. Our model integrates visual and linguistic processing, overcoming the
constraints of existing methods. We adopt a dual-phase training approach: the
initial phase focuses on aligning image and text representations, while the
subsequent phase concentrates on optimizing the model's interpretative and
analytical abilities in chart-related queries. This approach has demonstrated
superior performance on multiple public datasets, particularly in handling
color, structure, and textless chart questions, indicating its effectiveness in
complex multimodal tasks.

中文翻译:
在计算机视觉与自然语言处理领域，多模态图表问答（特别是涉及颜色、结构及无文本图表的情形）提出了重大挑战。传统方法通常采用直接多模态处理或"表格转文本+语言模型分析"的流程，但在应对这类复杂场景时存在明显局限。本文提出一种新型多模态图表问答模型，专门针对这些复杂任务设计。该模型通过融合视觉与语言处理，有效突破了现有方法的约束。我们采用双阶段训练策略：初始阶段专注于图像与文本表征的对齐，后续阶段则重点优化模型在图表相关查询中的解析与分析能力。实验表明，该模型在多个公开数据集上展现出卓越性能，尤其在处理颜色、结构及无文本图表问题时表现突出，印证了其在复杂多模态任务中的有效性。

（翻译说明：
1. 专业术语处理："multimodal"统一译为"多模态"，"textless charts"译为"无文本图表"以保持学术准确性
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如将"which typically involve..."处理为独立分句
3. 被动语态转换："have demonstrated"译为主动式"实验表明"，符合中文论述习惯
4. 概念显化："dual-phase training approach"译为"双阶段训练策略"，通过增补"策略"使专业概念更清晰
5. 逻辑连接：使用"通过"、"尤其"等连接词保持论证连贯性，同时保留"initial phase/subsequent phase"的时序逻辑）
