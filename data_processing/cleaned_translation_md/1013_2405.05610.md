# Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM

链接: http://arxiv.org/abs/2405.05610v1

原文摘要:
Large language models (LLMs) have achieved remarkable performance in various
natural language processing tasks, especially in dialogue systems. However, LLM
may also pose security and moral threats, especially in multi round
conversations where large models are more easily guided by contextual content,
resulting in harmful or biased responses. In this paper, we present a novel
method to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack).
CoA is a semantic-driven contextual multi-turn attack method that adaptively
adjusts the attack policy through contextual feedback and semantic relevance
during multi-turn of dialogue with a large model, resulting in the model
producing unreasonable or harmful content. We evaluate CoA on different LLMs
and datasets, and show that it can effectively expose the vulnerabilities of
LLMs, and outperform existing attack methods. Our work provides a new
perspective and tool for attacking and defending LLMs, and contributes to the
security and ethical assessment of dialogue systems.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在各种自然语言处理任务中展现出卓越性能，尤其在对话系统领域表现突出。然而这类模型也可能引发安全与道德风险，特别是在多轮对话场景中，大模型更容易受到上下文内容的引导，从而产生有害或带有偏见的回复。本文提出了一种新型的多轮对话攻击方法CoA（攻击链），该方法通过语义驱动的上下文多轮攻击策略，在与大模型的多轮交互中根据上下文反馈和语义相关性自适应调整攻击策略，最终诱导模型生成不合理或有害内容。我们在不同LLMs和数据集上评估了CoA方法，结果表明其能有效暴露LLMs的脆弱性，且性能优于现有攻击方法。本研究为LLMs的攻防提供了新视角和工具，对对话系统的安全与伦理评估具有重要贡献。

翻译说明：
1. 专业术语处理：LLMs统一译为"大型语言模型"，CoA采用"攻击链"译法并保留英文缩写
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"adaptively adjusts..."处理为"自适应调整..."的分句结构
3. 被动语态转换："are more easily guided"译为主动式"更容易受到...引导"
4. 学术用语规范："outperform"译为"性能优于"而非字面直译
5. 逻辑显化：通过"从而/最终"等连接词明确原文隐含的因果关系
6. 术语一致性：全文保持"多轮对话"、"语义驱动"等术语的统一译法
