# Zero-shot sampling of adversarial entities in biomedical question answering

链接: http://arxiv.org/abs/2402.10527v1

原文摘要:
The increasing depth of parametric domain knowledge in large language models
(LLMs) is fueling their rapid deployment in real-world applications.
Understanding model vulnerabilities in high-stakes and knowledge-intensive
tasks is essential for quantifying the trustworthiness of model predictions and
regulating their use. The recent discovery of named entities as adversarial
examples (i.e. adversarial entities) in natural language processing tasks
raises questions about their potential impact on the knowledge robustness of
pre-trained and finetuned LLMs in high-stakes and specialized domains. We
examined the use of type-consistent entity substitution as a template for
collecting adversarial entities for billion-parameter LLMs with biomedical
knowledge. To this end, we developed an embedding-space attack based on
powerscaled distance-weighted sampling to assess the robustness of their
biomedical knowledge with a low query budget and controllable coverage. Our
method has favorable query efficiency and scaling over alternative approaches
based on random sampling and blackbox gradient-guided search, which we
demonstrated for adversarial distractor generation in biomedical question
answering. Subsequent failure mode analysis uncovered two regimes of
adversarial entities on the attack surface with distinct characteristics and we
showed that entity substitution attacks can manipulate token-wise Shapley value
explanations, which become deceptive in this setting. Our approach complements
standard evaluations for high-capacity models and the results highlight the
brittleness of domain knowledge in LLMs.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）参数化领域知识的不断深化正推动其在现实应用中的快速部署。理解模型在高风险与知识密集型任务中的脆弱性，对于量化预测结果的可信度及规范其使用至关重要。近期在自然语言处理任务中发现命名实体可作为对抗样本（即对抗性实体），这引发了关于其对预训练和微调LLMs在高风险专业领域知识鲁棒性潜在影响的思考。我们研究了类型一致性实体替换作为模板的可行性，用于为具有生物医学知识的百亿参数LLMs收集对抗性实体。为此，我们开发了一种基于幂次缩放距离加权采样的嵌入空间攻击方法，以低查询预算和可控覆盖范围评估其生物医学知识鲁棒性。相较于基于随机采样和黑盒梯度引导搜索的替代方案，我们的方法在生物医学问答的对抗干扰项生成中展现出更优的查询效率与扩展性。后续故障模式分析揭示了攻击面上两类特性迥异的对抗性实体机制，并证明实体替换攻击可操纵基于token的Shapley值解释，导致其在此情境下产生误导性。该方法为高容量模型提供了标准评估之外的补充视角，结果凸显了LLMs领域知识的脆弱性。

翻译说明：
1. 专业术语处理：采用"对抗样本/对抗性实体"统一翻译"adversarial examples/entities"；"Shapley值"等机器学习术语保留专业译法
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如将"which we demonstrated..."独立成句
3. 被动语态转换：将英文被动结构转换为中文主动表述，如"was examined"译为"我们研究了"
4. 概念显化：将"powerscaled"等技术概念译为"幂次缩放"以准确传达数学含义
5. 逻辑衔接：通过"为此""相较于""后续"等连接词保持论证逻辑的连贯性
6. 学术风格：保持"鲁棒性""微调""参数化"等学术用语，符合计算机领域论文摘要规范
