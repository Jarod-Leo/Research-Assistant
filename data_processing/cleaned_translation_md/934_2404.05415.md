# Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations

链接: http://arxiv.org/abs/2404.05415v1

原文摘要:
In acupuncture therapy, the accurate location of acupoints is essential for
its effectiveness. The advanced language understanding capabilities of large
language models (LLMs) like Generative Pre-trained Transformers (GPT) present a
significant opportunity for extracting relations related to acupoint locations
from textual knowledge sources. This study aims to compare the performance of
GPT with traditional deep learning models (Long Short-Term Memory (LSTM) and
Bidirectional Encoder Representations from Transformers for Biomedical Text
Mining (BioBERT)) in extracting acupoint-related location relations and assess
the impact of pretraining and fine-tuning on GPT's performance. We utilized the
World Health Organization Standard Acupuncture Point Locations in the Western
Pacific Region (WHO Standard) as our corpus, which consists of descriptions of
361 acupoints. Five types of relations ('direction_of,' 'distance_of,'
'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints
were annotated. Five models were compared: BioBERT, LSTM, pre-trained GPT-3.5,
fine-tuned GPT-3.5, as well as pre-trained GPT-4. Performance metrics included
micro-average exact match precision, recall, and F1 scores. Our results
demonstrate that fine-tuned GPT-3.5 consistently outperformed other models in
F1 scores across all relation types. Overall, it achieved the highest
micro-average F1 score of 0.92. This study underscores the effectiveness of
LLMs like GPT in extracting relations related to acupoint locations, with
implications for accurately modeling acupuncture knowledge and promoting
standard implementation in acupuncture training and practice. The findings also
contribute to advancing informatics applications in traditional and
complementary medicine, showcasing the potential of LLMs in natural language
processing.

中文翻译:
在针灸治疗中，穴位的准确定位对其疗效至关重要。以生成式预训练转换器（GPT）为代表的大语言模型（LLM）凭借其卓越的语言理解能力，为从文本知识源中提取穴位位置关系提供了重要机遇。本研究旨在比较GPT与传统深度学习模型（长短期记忆网络LSTM、生物医学文本挖掘双向编码器表征模型BioBERT）在提取穴位位置关系方面的性能，并评估预训练与微调对GPT表现的影响。我们采用《世界卫生组织西太平洋地区标准针灸穴位定位》（WHO标准）作为语料库，该文献包含361个穴位的描述性文本。研究团队标注了穴位间五种关系类型（"方向"、"距离"、"所属部位"、"邻近穴位"和"毗邻位置"）（n=3,174）。对比了五种模型表现：BioBERT、LSTM、预训练GPT-3.5、微调GPT-3.5以及预训练GPT-4，评估指标包括微观平均精确匹配的精确率、召回率和F1值。结果表明，经微调的GPT-3.5在所有关系类型的F1值上均持续优于其他模型，总体微观平均F1值最高达0.92。本研究证实了GPT等大语言模型在提取穴位位置关系方面的有效性，对精准构建针灸知识模型、推动针灸教学与临床实践标准化具有重要意义。这些发现同时推动了传统医学与补充医学信息学应用的发展，彰显了大语言模型在自然语言处理领域的潜力。  


