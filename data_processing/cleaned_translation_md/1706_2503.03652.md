# Token-Level Privacy in Large Language Models

链接: http://arxiv.org/abs/2503.03652v1

原文摘要:
The use of language models as remote services requires transmitting private
information to external providers, raising significant privacy concerns. This
process not only risks exposing sensitive data to untrusted service providers
but also leaves it vulnerable to interception by eavesdroppers. Existing
privacy-preserving methods for natural language processing (NLP) interactions
primarily rely on semantic similarity, overlooking the role of contextual
information. In this work, we introduce dchi-stencil, a novel token-level
privacy-preserving mechanism that integrates contextual and semantic
information while ensuring strong privacy guarantees under the dchi
differential privacy framework, achieving 2epsilon-dchi-privacy. By
incorporating both semantic and contextual nuances, dchi-stencil achieves a
robust balance between privacy and utility. We evaluate dchi-stencil using
state-of-the-art language models and diverse datasets, achieving comparable and
even better trade-off between utility and privacy compared to existing methods.
This work highlights the potential of dchi-stencil to set a new standard for
privacy-preserving NLP in modern, high-risk applications.

中文翻译:
将语言模型作为远程服务使用时，需要向外部提供商传输隐私信息，这引发了重大的隐私安全问题。该过程不仅可能将敏感数据暴露给不可信的服务提供商，还容易遭受窃听者的截获。现有的自然语言处理（NLP）隐私保护方法主要依赖语义相似性，而忽略了上下文信息的作用。本文提出dchi-stencil——一种新颖的令牌级隐私保护机制，该机制在dchi差分隐私框架下（实现2ε-dchi隐私）整合了上下文与语义信息，同时确保严格的隐私保护。通过融合语义和上下文细微差异，dchi-stencil在隐私保护与实用性之间实现了稳健平衡。我们采用前沿语言模型和多样化数据集对dchi-stencil进行评估，结果显示其较现有方法实现了相当甚至更优的隐私-效用平衡。这项研究彰显了dchi-stencil为高风险现代应用场景下的隐私保护NLP树立新标准的潜力。

（翻译说明：采用学术论文摘要的规范表达，处理了技术术语的准确对应（如"differential privacy"译为"差分隐私"）；将长句合理切分为符合中文表达习惯的短句；保留技术缩写"dchi-stencil"及数学符号"2ε"的原始形式；通过"稳健平衡""前沿""彰显"等措辞体现学术文本的严谨性与前瞻性。）
