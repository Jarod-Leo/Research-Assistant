# Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models

链接: http://arxiv.org/abs/2308.11764v2

原文摘要:
Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP). Although convenient for research and practical applications, open-source
LLMs with fewer parameters often suffer from severe hallucinations compared to
their larger counterparts. This paper focuses on measuring and reducing
hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs
that are publicly available for research and commercial applications. We
introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed
to quantify the severity of hallucinations in LLMs. Additionally, we explore
techniques like knowledge injection and teacher-student approaches to alleviate
hallucinations in low-parameter LLMs. Our experiments effectively demonstrate
the reduction of hallucinations in challenging domains for these LLMs.

中文翻译:
大型语言模型（LLMs）为自然语言处理（NLP）领域带来了革命性变革。尽管开源的小参数规模LLMs为研究和实际应用提供了便利，但与大规模模型相比，这类模型往往存在严重的幻觉问题。本文以BLOOM 7B这一典型弱能力开源LLM为研究对象——该模型公开可用于科研与商业应用——重点探讨其幻觉现象的量化与缓解方案。我们提出HaloCheck，一个轻量级免知识黑箱框架，专门用于量化LLMs的幻觉严重程度。同时，我们探索了知识注入和师生学习等技术在低参数LLMs中缓解幻觉的效果。实验证明，这些方法能有效降低此类模型在复杂领域中的幻觉表现。

（翻译说明：
1. 专业术语处理："hallucinations"统一译为"幻觉"（NLP领域标准译法），"knowledge-free"译为"免知识"（突出无需外部知识库的特性）
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如原文第一句拆分为因果关系的两个分句
3. 被动语态转换："are publicly available"译为主动式"公开可用于"
4. 概念显化："weaker"译为"弱能力"以明确指代模型性能
5. 技术术语保留："BlackBox"保留英文形式并添加"框架"作为范畴词
6. 逻辑衔接：通过破折号和括号保持原文的补充说明语气
7. 学术风格：使用"量化""缓解""实证"等符合论文摘要的正式用语）
