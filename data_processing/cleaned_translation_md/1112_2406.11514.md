# Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs

链接: http://arxiv.org/abs/2406.11514v1

原文摘要:
Large Language Models (LLMs) excel in various natural language processing
tasks but struggle with hallucination issues. Existing solutions have
considered utilizing LLMs' inherent reasoning abilities to alleviate
hallucination, such as self-correction and diverse sampling methods. However,
these methods often overtrust LLMs' initial answers due to inherent biases. The
key to alleviating this issue lies in overriding LLMs' inherent biases for
answer inspection. To this end, we propose a CounterFactual Multi-Agent Debate
(CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent
biases by compelling LLMs to generate justifications for a predetermined
answer's correctness. The LLMs with different predetermined stances are engaged
with a skeptical critic for counterfactual debate on the rationality of
generated justifications. Finally, the debate process is evaluated by a
third-party judge to determine the final answer. Extensive experiments on four
datasets of three tasks demonstrate the superiority of CFMAD over existing
methods.

中文翻译:
以下是符合要求的学术中文翻译：

大语言模型（LLMs）在各类自然语言处理任务中表现卓越，但存在幻觉问题。现有解决方案尝试利用LLMs固有的推理能力来缓解幻觉现象，例如自我校正和多样性采样方法。然而，由于模型固有偏见，这些方法往往过度信赖LLMs的初始答案。解决该问题的关键在于覆盖LLMs的固有偏见以进行答案检验。为此，我们提出反事实多智能体辩论框架（CFMAD）。该框架通过预设LLMs的立场来覆盖其固有偏见，强制模型为预设答案的正确性生成论证依据。具有不同预设立场的LLMs将与持怀疑态度的评论者展开反事实辩论，对生成论证的合理性进行讨论。最终由第三方裁判评估辩论过程以确定最终答案。在三个任务的四个数据集上的大量实验表明，CFMAD显著优于现有方法。

翻译说明：
1. 专业术语处理：保留LLMs、CFMAD等专业缩写，首次出现时标注全称
2. 学术风格：使用"为此"替代"所以"，"显著优于"替代"比...好得多"等学术表达
3. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如将"compelling LLMs to..."译为独立分句
4. 概念对应："hallucination"译为业界通用术语"幻觉"，"inherent biases"译为"固有偏见"
5. 被动语态转换：将"are engaged"等被动式转为"将与...展开"的主动句式
6. 逻辑显化：通过"该框架"等指代保持段落连贯性，避免重复英文主语
