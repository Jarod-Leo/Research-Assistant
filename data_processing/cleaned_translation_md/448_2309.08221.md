# Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study

链接: http://arxiv.org/abs/2309.08221v1

原文摘要:
Code review is an essential activity for ensuring the quality and
maintainability of software projects. However, it is a time-consuming and often
error-prone task that can significantly impact the development process.
Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive
performance in various natural language processing tasks, suggesting its
potential to automate code review processes. However, it is still unclear how
well ChatGPT performs in code review tasks. To fill this gap, in this paper, we
conduct the first empirical study to understand the capabilities of ChatGPT in
code review tasks, specifically focusing on automated code refinement based on
given code reviews. To conduct the study, we select the existing benchmark
CodeReview and construct a new code review dataset with high quality. We use
CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison
with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code
refinement tasks. Specifically, our results show that ChatGPT achieves higher
EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art
method achieves only 15.50 and 62.88 on a high-quality code review dataset. We
further identify the root causes for ChatGPT's underperformance and propose
several strategies to mitigate these challenges. Our study provides insights
into the potential of ChatGPT in automating the code review process, and
highlights the potential research directions.

中文翻译:
代码审查是保障软件项目质量与可维护性的关键活动。然而这项任务耗时耗力且易出错，可能对开发流程产生显著影响。近期，前沿语言模型ChatGPT在多项自然语言处理任务中展现出卓越性能，表明其具备自动化代码审查流程的潜力。但ChatGPT在代码审查任务中的实际表现仍不明确。为填补这一研究空白，本文首次开展实证研究，重点探究ChatGPT在基于给定审查意见的自动化代码改进任务中的能力。研究过程中，我们选取现有基准数据集CodeReview并构建了高质量的新代码审查数据集，以最先进的代码审查工具CodeReviewer作为基线进行对比。实验结果表明：在高质量代码审查数据集上，ChatGPT以22.78的EM分数和76.44的BLEU分数显著优于基线方法的15.50和62.88。我们进一步分析了ChatGPT的不足根源，并提出若干改进策略。本研究为代码审查自动化提供了新见解，并指明了潜在的研究方向。
