# TWSSenti: A Novel Hybrid Framework for Topic-Wise Sentiment Analysis on Social Media Using Transformer Models

链接: http://arxiv.org/abs/2504.09896v1

原文摘要:
Sentiment analysis is a crucial task in natural language processing (NLP)
that enables the extraction of meaningful insights from textual data,
particularly from dynamic platforms like Twitter and IMDB. This study explores
a hybrid framework combining transformer-based models, specifically BERT,
GPT-2, RoBERTa, XLNet, and DistilBERT, to improve sentiment classification
accuracy and robustness. The framework addresses challenges such as noisy data,
contextual ambiguity, and generalization across diverse datasets by leveraging
the unique strengths of these models. BERT captures bidirectional context,
GPT-2 enhances generative capabilities, RoBERTa optimizes contextual
understanding with larger corpora and dynamic masking, XLNet models dependency
through permutation-based learning, and DistilBERT offers efficiency with
reduced computational overhead while maintaining high accuracy. We demonstrate
text cleaning, tokenization, and feature extraction using Term Frequency
Inverse Document Frequency (TF-IDF) and Bag of Words (BoW), ensure high-quality
input data for the models. The hybrid approach was evaluated on benchmark
datasets Sentiment140 and IMDB, achieving superior accuracy rates of 94\% and
95\%, respectively, outperforming standalone models. The results validate the
effectiveness of combining multiple transformer models in ensemble-like setups
to address the limitations of individual architectures. This research
highlights its applicability to real-world tasks such as social media
monitoring, customer sentiment analysis, and public opinion tracking which
offers a pathway for future advancements in hybrid NLP frameworks.

中文翻译:
情感分析是自然语言处理（NLP）中的关键任务，能够从文本数据（尤其是Twitter和IMDB等动态平台）中提取有价值的见解。本研究提出了一种结合多种基于Transformer模型的混合框架（包括BERT、GPT-2、RoBERTa、XLNet和DistilBERT），旨在提升情感分类的准确性与鲁棒性。该框架通过整合各模型的独特优势，有效应对噪声数据、语境歧义以及跨数据集泛化等挑战：BERT捕捉双向语境，GPT-2增强生成能力，RoBERTa通过更大语料库和动态掩码优化语境理解，XLNet采用基于排列的学习建模依赖关系，而DistilBERT在保持高精度的同时显著降低计算开销。研究采用文本清洗、分词以及词频-逆文档频率（TF-IDF）和词袋模型（BoW）进行特征提取，确保模型输入数据的高质量。在Sentiment140和IMDB基准数据集上的评估显示，该混合框架分别取得94%和95%的准确率，显著优于单一模型。实验结果验证了在类集成架构中组合多Transformer模型能有效弥补单一架构的局限性。本研究不仅适用于社交媒体监控、客户情感分析和舆情追踪等实际场景，更为混合NLP框架的未来发展提供了可行路径。
