# A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning

链接: http://arxiv.org/abs/2502.09086v1

原文摘要:
With the continuous development of natural language processing (NLP)
technology, text classification tasks have been widely used in multiple
application fields. However, obtaining labeled data is often expensive and
difficult, especially in few-shot learning scenarios. To solve this problem,
this paper proposes a few-shot text classification model based on transfer
learning and meta-learning. The model uses the knowledge of the pre-trained
model for transfer and optimizes the model's rapid adaptability in few-sample
tasks through a meta-learning mechanism. Through a series of comparative
experiments and ablation experiments, we verified the effectiveness of the
proposed method. The experimental results show that under the conditions of few
samples and medium samples, the model based on transfer learning and
meta-learning significantly outperforms traditional machine learning and deep
learning methods. In addition, ablation experiments further analyzed the
contribution of each component to the model performance and confirmed the key
role of transfer learning and meta-learning in improving model accuracy.
Finally, this paper discusses future research directions and looks forward to
the potential of this method in practical applications.

中文翻译:
随着自然语言处理（NLP）技术的持续发展，文本分类任务已在多个应用领域得到广泛运用。然而获取标注数据往往成本高昂且困难重重，尤其在少样本学习场景下更为突出。为解决这一问题，本文提出一种融合迁移学习与元学习的少样本文本分类模型。该模型利用预训练模型的知识进行迁移，并通过元学习机制优化模型在少样本任务中的快速适应能力。通过系列对比实验与消融实验，我们验证了所提方法的有效性。实验结果表明，在少样本及中样本条件下，基于迁移学习与元学习的模型性能显著优于传统机器学习与深度学习方法。此外，消融实验进一步解析了各组件对模型性能的贡献，证实了迁移学习与元学习对提升模型准确率的关键作用。最后，本文探讨了未来研究方向，并展望了该方法在实际应用中的潜力。
