# Introspective Tips: Large Language Model for In-Context Decision Making

链接: http://arxiv.org/abs/2305.11598v1

原文摘要:
The emergence of large language models (LLMs) has substantially influenced
natural language processing, demonstrating exceptional results across various
tasks. In this study, we employ ``Introspective Tips" to facilitate LLMs in
self-optimizing their decision-making. By introspectively examining
trajectories, LLM refines its policy by generating succinct and valuable tips.
Our method enhances the agent's performance in both few-shot and zero-shot
learning situations by considering three essential scenarios: learning from the
agent's past experiences, integrating expert demonstrations, and generalizing
across diverse games. Importantly, we accomplish these improvements without
fine-tuning the LLM parameters; rather, we adjust the prompt to generalize
insights from the three aforementioned situations. Our framework not only
supports but also emphasizes the advantage of employing LLM in in-contxt
decision-making. Experiments involving over 100 games in TextWorld illustrate
the superior performance of our approach.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）的出现深刻影响了自然语言处理领域，其在多项任务中展现出卓越性能。本研究采用"自省提示"方法，促使LLMs通过自我优化提升决策能力。该技术通过内省式轨迹分析，使模型能生成简明而有价值的策略提示来优化决策方案。我们的方法通过以下三种核心场景提升智能体在少样本和零样本学习中的表现：从智能体历史经验中学习、整合专家示范数据，以及跨游戏泛化能力。值得注意的是，这些改进无需微调LLM参数，而是通过调整提示模板来整合上述三种情境的认知。本框架不仅验证了LLM在上下文决策中的适用性，更突显其独特优势。在TextWorld平台上超过100款游戏的实验表明，该方法具有显著的性能优势。

（翻译说明：根据学术摘要的简洁性要求，对原文进行了适当重组但保持原意；"Introspective Tips"采用意译；专业术语如"few-shot/zero-shot"遵循领域标准译法；长句按中文习惯拆分；被动语态转为主动表达；实验数据保留完整信息）
