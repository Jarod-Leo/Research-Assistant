# All in One: An Empirical Study of GPT for Few-Shot Aspect-Based Sentiment Anlaysis

链接: http://arxiv.org/abs/2404.06063v1

原文摘要:
Few-Shot Aspect-Based Sentiment Analysis (FSABSA) is an indispensable and
highly challenging task in natural language processing. However, methods based
on Pre-trained Language Models (PLMs) struggle to accommodate multiple
sub-tasks, and methods based on Generative Pre-trained Transformers (GPTs)
perform poorly. To address the above issues, the paper designs a
Heuristic-enhanced Candidates Selection (HCS) strategy and further proposes All
in One (AiO) model based on it. The model works in a two-stage, which
simultaneously accommodates the accuracy of PLMs and the generalization
capability of GPTs. Specifically, in the first stage, a backbone model based on
PLMs generates rough heuristic candidates for the input sentence. In the second
stage, AiO leverages LLMs' contextual learning capabilities to generate precise
predictions. The study conducted comprehensive comparative and ablation
experiments on five benchmark datasets. The experimental results demonstrate
that the proposed model can better adapt to multiple sub-tasks, and also
outperforms the methods that directly utilize GPTs.

中文翻译:
以下是符合要求的学术中文翻译：

少样本方面级情感分析（FSABSA）是自然语言处理中不可或缺且极具挑战性的任务。然而，基于预训练语言模型（PLMs）的方法难以适配多重子任务，而基于生成式预训练变换器（GPTs）的方法表现欠佳。针对上述问题，本文设计了一种启发式增强候选选择（HCS）策略，并进一步提出基于该策略的All in One（AiO）模型。该模型采用两阶段工作模式，同时兼顾PLMs的精确性与GPTs的泛化能力。具体而言：第一阶段通过PLMs骨干网络为输入语句生成粗粒度启发式候选；第二阶段AiO利用大语言模型的上下文学习能力生成精确预测。研究在五个基准数据集上进行了全面的对比实验与消融实验，结果表明所提模型能更好适应多重子任务，其性能也显著优于直接使用GPTs的方法。


