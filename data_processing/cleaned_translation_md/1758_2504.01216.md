# Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models

链接: http://arxiv.org/abs/2504.01216v1

原文摘要:
Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical
settings, presenting opportunities for automated detection to identify
patients. This study evaluates natural language processing approaches for
detecting PTSD from clinical interview transcripts. We compared general and
mental health-specific transformer models (BERT/RoBERTa), embedding-based
methods (SentenceBERT/LLaMA), and large language model prompting strategies
(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.
Domain-specific models significantly outperformed general models
(Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485). LLaMA embeddings with neural
networks achieved the highest performance (F1=0.700). Zero-shot prompting using
DSM-5 criteria yielded competitive results without training data (F1=0.657).
Performance varied significantly across symptom severity and comorbidity
status, with higher accuracy for severe PTSD cases and patients with comorbid
depression. Our findings highlight the potential of domain-adapted embeddings
and LLMs for scalable screening while underscoring the need for improved
detection of nuanced presentations and offering insights for developing
clinically viable AI tools for PTSD assessment.

中文翻译:
创伤后应激障碍（PTSD）在临床环境中仍存在漏诊现象，这为通过自动化检测识别患者提供了机遇。本研究评估了从临床访谈文本中检测PTSD的自然语言处理方法。基于DAIC-WOZ数据集，我们对比了通用与心理健康领域专用Transformer模型（BERT/RoBERTa）、基于嵌入的方法（SentenceBERT/LLaMA）以及大语言模型提示策略（零样本/少样本/思维链）。领域专用模型显著优于通用模型（Mental-RoBERTa F1=0.643 vs RoBERTa-base 0.485）。结合神经网络使用的LLaMA嵌入方法取得最佳性能（F1=0.700）。采用DSM-5诊断标准的零样本提示策略在无需训练数据情况下获得有竞争力的结果（F1=0.657）。模型表现随症状严重程度和共病状态存在显著差异，对重度PTSD病例和伴有抑郁症共病的患者检测准确率更高。本研究揭示了领域适配嵌入方法和大语言模型在可扩展筛查中的应用潜力，同时强调需要提升对复杂症状表现的检测能力，为开发具有临床实用性的PTSD评估AI工具提供了重要启示。

（翻译说明：采用学术论文摘要的标准表述方式，通过以下处理确保专业性与可读性：
1. 专业术语规范处理（如"comorbidity"译为"共病"）
2. 技术概念准确转化（如"zero-shot prompting"译为"零样本提示策略"）
3. 长句合理切分，符合中文表达习惯
4. 关键指标数据完整保留
5. 研究价值通过"揭示了""强调""提供了"等动词体现层次感
6. 使用"机遇""潜力""启示"等词汇保持学术文本的严谨性）
