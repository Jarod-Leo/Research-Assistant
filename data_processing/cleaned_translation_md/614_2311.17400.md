# Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention

链接: http://arxiv.org/abs/2311.17400v1

原文摘要:
Transformer-based models, such as BERT and GPT, have been widely adopted in
natural language processing (NLP) due to their exceptional performance.
However, recent studies show their vulnerability to textual adversarial attacks
where the model's output can be misled by intentionally manipulating the text
inputs. Despite various methods that have been proposed to enhance the model's
robustness and mitigate this vulnerability, many require heavy consumption
resources (e.g., adversarial training) or only provide limited protection
(e.g., defensive dropout). In this paper, we propose a novel method called
dynamic attention, tailored for the transformer architecture, to enhance the
inherent robustness of the model itself against various adversarial attacks.
Our method requires no downstream task knowledge and does not incur additional
costs. The proposed dynamic attention consists of two modules: (I) attention
rectification, which masks or weakens the attention value of the chosen tokens,
and (ii) dynamic modeling, which dynamically builds the set of candidate
tokens. Extensive experiments demonstrate that dynamic attention significantly
mitigates the impact of adversarial attacks, improving up to 33\% better
performance than previous methods against widely-used adversarial attacks. The
model-level design of dynamic attention enables it to be easily combined with
other defense methods (e.g., adversarial training) to further enhance the
model's robustness. Furthermore, we demonstrate that dynamic attention
preserves the state-of-the-art robustness space of the original model compared
to other dynamic modeling methods.

中文翻译:
基于Transformer的模型（如BERT和GPT）凭借卓越性能已在自然语言处理领域广泛应用。然而最新研究表明，这类模型易受文本对抗攻击影响——通过人为操纵文本输入即可误导模型输出。尽管目前已提出多种增强模型鲁棒性的方法（如对抗训练）或有限防护手段（如防御性丢弃），但这些方案往往需要消耗大量资源，或仅能提供有限保护。本文创新性地提出一种专为Transformer架构设计的动态注意力机制，通过增强模型自身固有鲁棒性来抵御各类对抗攻击。该方法无需下游任务先验知识，且不会产生额外成本。所提出的动态注意力包含两大模块：（I）注意力校正——对选定标记的注意力值进行掩蔽或弱化；（II）动态建模——动态构建候选标记集合。大量实验表明，动态注意力能显著降低对抗攻击影响，在应对常见攻击时较现有方法最高可提升33%的防御性能。该模型级设计方案可轻松与其他防御方法（如对抗训练）结合以进一步增强鲁棒性。此外，相较于其他动态建模方法，动态注意力能更好地保持原始模型的前沿鲁棒性特征空间。
