# QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities

链接: http://arxiv.org/abs/2406.12399v1

原文摘要:
With the increasing role of Natural Language Processing (NLP) in various
applications, challenges concerning bias and stereotype perpetuation are
accentuated, which often leads to hate speech and harm. Despite existing
studies on sexism and misogyny, issues like homophobia and transphobia remain
underexplored and often adopt binary perspectives, putting the safety of
LGBTQIA+ individuals at high risk in online spaces. In this paper, we assess
the potential harm caused by sentence completions generated by English large
language models (LLMs) concerning LGBTQIA+ individuals. This is achieved using
QueerBench, our new assessment framework, which employs a template-based
approach and a Masked Language Modeling (MLM) task. The analysis indicates that
large language models tend to exhibit discriminatory behaviour more frequently
towards individuals within the LGBTQIA+ community, reaching a difference gap of
7.2% in the QueerBench score of harmfulness.

中文翻译:
随着自然语言处理（NLP）在各领域应用日益广泛，其潜在的偏见与刻板印象延续问题愈发凸显，往往诱发仇恨言论与伤害行为。尽管现有研究已关注性别歧视与厌女现象，但针对恐同症与跨性别恐惧的探讨仍显不足，且多采用二元对立视角，致使LGBTQIA+群体在网络空间面临极高安全风险。本文通过新型评估框架QueerBench（采用模板化方法与掩码语言建模任务），系统评估了英语大语言模型（LLMs）在句子补全任务中对LGBTQIA+群体可能造成的伤害。分析表明，大语言模型对该群体表现出更高频的歧视性行为，其有害性评分差异幅度达7.2%。  

（翻译说明：  
1. 专业术语处理：保留"NLP"、"LLMs"等专业缩写，首次出现时标注全称；"QueerBench"作为专有名词保留不译  
2. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句，如将"which often leads to..."独立成短句  
3. 被动语态转换："are accentuated"转为主动态"愈发凸显"  
4. 文化适配："binary perspectives"译为"二元对立视角"以符合社科领域表述习惯  
5. 数据呈现：精确保留"7.2%"数值及"QueerBench score of harmfulness"概念  
6. 敏感词处理："homophobia/transphobia"采用学界通用译法"恐同症/跨性别恐惧"）
