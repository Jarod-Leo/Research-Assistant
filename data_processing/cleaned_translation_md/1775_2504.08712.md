# Beyond Black-Box Predictions: Identifying Marginal Feature Effects in Tabular Transformer Networks

链接: http://arxiv.org/abs/2504.08712v1

原文摘要:
In recent years, deep neural networks have showcased their predictive power
across a variety of tasks. Beyond natural language processing, the transformer
architecture has proven efficient in addressing tabular data problems and
challenges the previously dominant gradient-based decision trees in these
areas. However, this predictive power comes at the cost of intelligibility:
Marginal feature effects are almost completely lost in the black-box nature of
deep tabular transformer networks. Alternative architectures that use the
additivity constraints of classical statistical regression models can maintain
intelligible marginal feature effects, but often fall short in predictive power
compared to their more complex counterparts. To bridge the gap between
intelligibility and performance, we propose an adaptation of tabular
transformer networks designed to identify marginal feature effects. We provide
theoretical justifications that marginal feature effects can be accurately
identified, and our ablation study demonstrates that the proposed model
efficiently detects these effects, even amidst complex feature interactions. To
demonstrate the model's predictive capabilities, we compare it to several
interpretable as well as black-box models and find that it can match black-box
performances while maintaining intelligibility. The source code is available at
