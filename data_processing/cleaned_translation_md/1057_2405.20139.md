# GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning

链接: http://arxiv.org/abs/2405.20139v1

原文摘要:
Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form
of triplets (head, relation, tail), which collectively form a graph. Question
Answering over KGs (KGQA) is the task of answering natural questions grounding
the reasoning to the information provided by the KG. Large Language Models
(LLMs) are the state-of-the-art models for QA tasks due to their remarkable
ability to understand natural language. On the other hand, Graph Neural
Networks (GNNs) have been widely used for KGQA as they can handle the complex
graph information stored in the KG. In this work, we introduce GNN-RAG, a novel
method for combining language understanding abilities of LLMs with the
reasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.
First, a GNN reasons over a dense KG subgraph to retrieve answer candidates for
a given question. Second, the shortest paths in the KG that connect question
entities and answer candidates are extracted to represent KG reasoning paths.
The extracted paths are verbalized and given as input for LLM reasoning with
RAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to
extract useful graph information, while the LLM leverages its natural language
processing ability for ultimate KGQA. Furthermore, we develop a retrieval
augmentation (RA) technique to further boost KGQA performance with GNN-RAG.
Experimental results show that GNN-RAG achieves state-of-the-art performance in
two widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching
GPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop
and multi-entity questions outperforming competing approaches by 8.9--15.5%
points at answer F1.

中文翻译:
知识图谱（Knowledge Graphs, KGs）以三元组（头实体，关系，尾实体）的形式表示人工构建的事实知识，这些三元组共同构成一个图结构。基于知识图谱的问答（KGQA）任务旨在通过对KG信息进行推理来回答自然语言问题。大型语言模型（LLMs）凭借其卓越的自然语言理解能力，已成为问答任务的最先进模型。另一方面，图神经网络（GNNs）因其能有效处理KG中复杂的图结构信息，被广泛用于KGQA任务。本研究提出GNN-RAG——一种以检索增强生成（RAG）方式融合LLMs语言理解能力与GNNs推理能力的新方法。首先，GNN对稠密KG子图进行推理以检索给定问题的候选答案；其次，提取KG中连接问题实体与候选答案的最短路径来表示KG推理路径；最后将这些路径文本化后作为RAG框架下LLM推理的输入。在GNN-RAG框架中，GNN充当稠密子图推理器来提取有效图信息，而LLM则发挥其自然语言处理能力完成最终KGQA。我们还开发了检索增强（RA）技术来进一步提升GNN-RAG的KGQA性能。实验结果表明，GNN-RAG在两个广泛使用的KGQA基准测试（WebQSP和CWQ）中达到最先进水平，使用70亿参数的微调LLM即可超越或匹配GPT-4的表现。此外，在多跳和多实体问题上，GNN-RAG以8.9%-15.5%的答案F1值优势显著优于其他方法。


2. "verbalized"译为"文本化"（更符合NLP领域表述）
3. 保持"GNN-RAG"等模型名称原文形式
4. 将"8.9--15.5%"调整为中文惯用的"8.9%-15.5%"）
