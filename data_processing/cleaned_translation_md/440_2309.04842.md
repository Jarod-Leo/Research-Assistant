# Leveraging Large Language Models for Exploiting ASR Uncertainty

链接: http://arxiv.org/abs/2309.04842v1

原文摘要:
While large language models excel in a variety of natural language processing
(NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they
must either rely on off-the-shelf automatic speech recognition (ASR) systems
for transcription, or be equipped with an in-built speech modality. This work
focuses on the former scenario, where LLM's accuracy on SLU tasks is
constrained by the accuracy of a fixed ASR system on the spoken input.
Specifically, we tackle speech-intent classification task, where a high
word-error-rate can limit the LLM's ability to understand the spoken intent.
Instead of chasing a high accuracy by designing complex or specialized
architectures regardless of deployment costs, we seek to answer how far we can
go without substantially changing the underlying ASR and LLM, which can
potentially be shared by multiple unrelated tasks. To this end, we propose
prompting the LLM with an n-best list of ASR hypotheses instead of only the
error-prone 1-best hypothesis. We explore prompt-engineering to explain the
concept of n-best lists to the LLM; followed by the finetuning of Low-Rank
Adapters on the downstream tasks. Our approach using n-best lists proves to be
effective on a device-directed speech detection task as well as on a keyword
spotting task, where systems using n-best list prompts outperform those using
1-best ASR hypothesis; thus paving the way for an efficient method to exploit
ASR uncertainty via LLMs for speech-based applications.

中文翻译:
尽管大语言模型在各类自然语言处理任务中表现卓越，但在口语理解任务上要实现优异性能，它们要么依赖现成的自动语音识别系统进行转写，要么需要内置语音处理模块。本研究聚焦于前一种情况，即大语言模型在口语理解任务中的准确率受限于固定语音识别系统对语音输入的转写精度。具体而言，我们针对语音意图分类任务展开研究——当语音识别词错误率较高时，会严重制约大语言模型理解口语意图的能力。不同于不计部署成本地设计复杂专用架构来追求高准确率，我们致力于探索在基本保持现有语音识别系统和大语言模型架构不变（这些组件可被多个无关任务共享）的前提下，性能提升的极限空间。为此，我们提出向大语言模型输入语音识别系统生成的n-best候选列表（而非仅提供存在错误的1-best转写结果），并通过提示工程向大语言模型解释n-best列表的概念，继而针对下游任务对低秩适配器进行微调。实验证明，在设备指向性语音检测和关键词唤醒任务中，采用n-best列表提示的系统性能显著优于仅使用1-best转写结果的系统。这为通过大语言模型有效利用语音识别不确定性提供了一条高效路径，为语音应用开辟了新方向。
