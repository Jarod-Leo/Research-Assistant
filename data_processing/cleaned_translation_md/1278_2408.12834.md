# CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition

链接: http://arxiv.org/abs/2408.12834v1

原文摘要:
Few-shot Named Entity Recognition (NER), the task of identifying named
entities with only a limited amount of labeled data, has gained increasing
significance in natural language processing. While existing methodologies have
shown some effectiveness, such as enriching label semantics through various
prompting modes or employing metric learning techniques, their performance
exhibits limited robustness across diverse domains due to the lack of rich
knowledge in their pre-trained models. To address this issue, we propose
CLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework
for Few-Shot Named Entity Recognition, achieving promising results with limited
training data. Considering the impact of LLM's internal representations on
downstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive
learning mechanisms specifically tailored for few-shot NER. By enhancing the
model's internal representations, CLLMFS effectively improves both entity
boundary awareness ability and entity recognition accuracy. Our method has
achieved state-of-the-art performance improvements on F1-score ranging from
2.58\% to 97.74\% over existing best-performing methods across several
recognized benchmarks. Furthermore, through cross-domain NER experiments
conducted on multiple datasets, we have further validated the robust
generalization capability of our method. Our code will be released in the near
future.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

【小样本命名实体识别研究新突破：基于对比学习增强的大语言模型框架】

小样本命名实体识别（NER）作为在有限标注数据条件下识别命名实体的任务，在自然语言处理领域日益凸显其重要性。尽管现有方法（如通过多样化提示模式丰富标签语义或采用度量学习技术）已展现一定效果，但由于预训练模型缺乏丰富知识，其跨领域性能鲁棒性仍显不足。针对这一挑战，本文提出CLLMFS——一种基于对比学习增强的大语言模型（LLM）小样本命名实体识别框架，在有限训练数据条件下取得了显著效果。

考虑到大语言模型内部表征对下游任务的影响，CLLMFS创新性地整合了专为小样本NER设计的低秩自适应（LoRA）和对比学习机制。通过优化模型内部表征，该框架有效提升了实体边界感知能力与识别准确率。在多个权威基准测试中，我们的方法相较现有最优方法实现了F1值2.58%至97.74%的性能提升，达到当前最先进水平。此外，基于多数据集的跨领域NER实验进一步验证了本方法具有强大的泛化能力。相关代码将于近期开源。


