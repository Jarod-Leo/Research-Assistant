# Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models

链接: http://arxiv.org/abs/2408.00197v1

原文摘要:
Generative Pre-Trained Transformer models have been shown to be surprisingly
effective at a variety of natural language processing tasks -- including
generating computer code. We evaluate the effectiveness of open source GPT
models for the task of automatic identification of the presence of vulnerable
code syntax (specifically targeting C and C++ source code). This task is
evaluated on a selection of 36 source code examples from the NIST SARD dataset,
which are specifically curated to not contain natural English that indicates
the presence, or lack thereof, of a particular vulnerability. The NIST SARD
source code dataset contains identified vulnerable lines of source code that
are examples of one out of the 839 distinct Common Weakness Enumerations (CWE),
allowing for exact quantification of the GPT output classification error rate.
A total of 5 GPT models are evaluated, using 10 different inference
temperatures and 100 repetitions at each setting, resulting in 5,000 GPT
queries per vulnerable source code analyzed. Ultimately, we find that the GPT
models that we evaluated are not suitable for fully automated vulnerability
scanning because the false positive and false negative rates are too high to
likely be useful in practice. However, we do find that the GPT models perform
surprisingly well at automated vulnerability detection for some of the test
cases, in particular surpassing random sampling, and being able to identify the
exact lines of code that are vulnerable albeit at a low success rate. The best
performing GPT model result found was Llama-2-70b-chat-hf with inference
temperature of 0.1 applied to NIST SARD test case 149165 (which is an example
of a buffer overflow vulnerability), which had a binary classification recall
score of 1.0 and a precision of 1.0 for correctly and uniquely identifying the
vulnerable line of code and the correct CWE number.

中文翻译:
研究表明，生成式预训练Transformer模型在各类自然语言处理任务中展现出惊人效能——包括计算机代码生成。本研究针对开源GPT模型在自动识别漏洞代码语法（特指C/C++源代码）任务中的有效性展开评估。测试选用NIST SARD数据集中36个源代码样本，这些样本经特殊设计不含任何提示漏洞存在与否的自然英语描述。该数据集包含839种不同通用缺陷枚举（CWE）的已标记漏洞代码行，可精确量化GPT输出分类错误率。

我们共评估5个GPT模型，采用10种不同推理温度参数，每个参数设置下重复100次实验，最终对每个漏洞源代码样本执行5,000次GPT查询。研究发现：由于误报率和漏报率过高，所评估的GPT模型尚不适合全自动漏洞扫描；但在部分测试案例中，其自动化漏洞检测表现远超随机抽样水平，甚至能以较低成功率精确定位漏洞代码行及对应CWE编号。最佳表现为Llama-2-70b-chat-hf模型（推理温度0.1）处理NIST SARD测试案例149165（缓冲区溢出漏洞）时，二分类召回率与精确率均达1.0，成功唯一识别漏洞代码行及正确CWE编号。
