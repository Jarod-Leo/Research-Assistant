# A Survey on Large Language Models from Concept to Implementation

链接: http://arxiv.org/abs/2403.18969v1

原文摘要:
Recent advancements in Large Language Models (LLMs), particularly those built
on Transformer architectures, have significantly broadened the scope of natural
language processing (NLP) applications, transcending their initial use in
chatbot technology. This paper investigates the multifaceted applications of
these models, with an emphasis on the GPT series. This exploration focuses on
the transformative impact of artificial intelligence (AI) driven tools in
revolutionizing traditional tasks like coding and problem-solving, while also
paving new paths in research and development across diverse industries. From
code interpretation and image captioning to facilitating the construction of
interactive systems and advancing computational domains, Transformer models
exemplify a synergy of deep learning, data analysis, and neural network design.
This survey provides an in-depth look at the latest research in Transformer
models, highlighting their versatility and the potential they hold for
transforming diverse application sectors, thereby offering readers a
comprehensive understanding of the current and future landscape of
Transformer-based LLMs in practical applications.

中文翻译:
近年来，大型语言模型（LLMs）——尤其是基于Transformer架构的模型——取得了显著进展，极大地拓展了自然语言处理（NLP）的应用范畴，其影响力已远超最初在聊天机器人技术中的应用边界。本文以GPT系列模型为重点，系统探究了这类模型的多维应用场景：既聚焦人工智能（AI）驱动工具如何颠覆代码编写与问题求解等传统任务，又揭示其在跨行业研发领域中开辟的创新路径。从代码解析、图像描述生成，到交互式系统构建支持，再到计算科学领域的突破性进展，Transformer模型完美诠释了深度学习、数据分析与神经网络设计的协同效应。本综述深入剖析了Transformer模型的最新研究进展，着重展现其多功能特性及对各应用领域的变革潜力，旨在为读者提供关于基于Transformer的LLMs在当前及未来实际应用中的全景认知。  

。通过拆分英文长句为中文短句结构（如将"transcending..."处理为独立分句），并运用四字格（"系统探究""多维应用"）增强可读性。关键概念如"synergy"译为"协同效应"既准确传达技术内涵又符合中文表达习惯，被动语态转换为主动表述（如"highlighting..."译为"着重展现"）更贴合中文科技文献风格。）
