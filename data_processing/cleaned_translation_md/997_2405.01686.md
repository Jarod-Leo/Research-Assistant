# Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models

链接: http://arxiv.org/abs/2405.01686v1

原文摘要:
Meta-analyses statistically aggregate the findings of different randomized
controlled trials (RCTs) to assess treatment effectiveness. Because this yields
robust estimates of treatment effectiveness, results from meta-analyses are
considered the strongest form of evidence. However, rigorous evidence syntheses
are time-consuming and labor-intensive, requiring manual extraction of data
from individual trials to be synthesized. Ideally, language technologies would
permit fully automatic meta-analysis, on demand. This requires accurately
extracting numerical results from individual trials, which has been beyond the
capabilities of natural language processing (NLP) models to date. In this work,
we evaluate whether modern large language models (LLMs) can reliably perform
this task. We annotate (and release) a modest but granular evaluation dataset
of clinical trial reports with numerical findings attached to interventions,
comparators, and outcomes. Using this dataset, we evaluate the performance of
seven LLMs applied zero-shot for the task of conditionally extracting numerical
findings from trial reports. We find that massive LLMs that can accommodate
lengthy inputs are tantalizingly close to realizing fully automatic
meta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).
However, LLMs -- including ones trained on biomedical texts -- perform poorly
when the outcome measures are complex and tallying the results requires
inference. This work charts a path toward fully automatic meta-analysis of RCTs
via LLMs, while also highlighting the limitations of existing models for this
aim.

中文翻译:
以下是符合您要求的中文翻译：

元分析通过统计学方法整合不同随机对照试验（RCT）的研究结果以评估治疗效果。由于这种方法能产生稳健的治疗效果估计值，元分析结果被视为最有力的证据形式。然而，严谨的证据合成过程耗时费力，需要人工从单个试验中提取数据再进行整合。理想情况下，语言技术可以实现按需全自动元分析，这要求从单个试验中准确提取数值结果——这一任务至今仍超出自然语言处理（NLP）模型的能力范围。本研究评估了现代大语言模型（LLM）能否可靠完成该任务。我们标注并发布了一个规模适中但粒度精细的临床试验报告评估数据集，其中包含与干预措施、对照项和结局指标相关联的数值结果。基于该数据集，我们评估了七种LLM在零样本条件下从试验报告中提取数值结果的表现。研究发现，能够处理长文本输入的大规模LLM已接近实现全自动元分析的目标，特别是对于二分类结局指标（如死亡率）。然而当结局指标较复杂且需要推理计算时（包括接受过生物医学文本训练的模型在内）所有LLM表现均不理想。本研究为通过LLM实现RCT全自动元分析指明了路径，同时也揭示了现有模型在此目标上的局限性。

翻译说明：
1. 专业术语处理：严格遵循医学术语规范，如"RCT"译为"随机对照试验"、"dichotomous outcomes"译为"二分类结局指标"
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如将"Because this yields..."处理为因果关系的分句
3. 被动语态转换：将英文被动式（如"are considered"）转化为中文主动表述（"被视为"）
4. 概念显化：将"zero-shot"译为"零样本条件下"，保留技术含义的同时确保可读性
5. 程度副词处理："tantalizingly close"译为"已接近...的目标"，准确传达原文的期待感
6. 逻辑连接：通过"然而"、"特别是"等连接词清晰呈现研究发现的对比关系
7. 技术表述："conditionally extracting"译为"在...条件下提取"，保持学术准确性
