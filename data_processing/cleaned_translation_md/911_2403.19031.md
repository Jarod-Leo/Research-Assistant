# Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data

链接: http://arxiv.org/abs/2403.19031v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable success in NLP
tasks. However, there is a paucity of studies that attempt to evaluate their
performances on social media-based health-related natural language processing
tasks, which have traditionally been difficult to achieve high scores in. We
benchmarked one supervised classic machine learning model based on Support
Vector Machines (SVMs), three supervised pretrained language models (PLMs)
based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5
and GPT4), across 6 text classification tasks. We developed three approaches
for leveraging LLMs for text classification: employing LLMs as zero-shot
classifiers, us-ing LLMs as annotators to annotate training data for supervised
classifiers, and utilizing LLMs with few-shot examples for augmentation of
manually annotated data. Our comprehensive experiments demonstrate that
employ-ing data augmentation using LLMs (GPT-4) with relatively small
human-annotated data to train lightweight supervised classification models
achieves superior results compared to training with human-annotated data alone.
Supervised learners also outperform GPT-4 and GPT-3.5 in zero-shot settings. By
leveraging this data augmentation strategy, we can harness the power of LLMs to
develop smaller, more effective domain-specific NLP models. LLM-annotated data
without human guidance for training light-weight supervised classification
models is an ineffective strategy. However, LLM, as a zero-shot classifier,
shows promise in excluding false negatives and potentially reducing the human
effort required for data annotation. Future investigations are imperative to
explore optimal training data sizes and the optimal amounts of augmented data.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在自然语言处理任务中展现出卓越成效，但针对社交媒体健康领域文本处理任务（该领域传统上难以获得高准确率）的性能评估研究仍属匮乏。本研究系统评估了六种文本分类模型：基于支持向量机（SVM）的经典监督模型、三种预训练语言模型（RoBERTa、BERTweet和SocBERT），以及两种LLM分类器（GPT-3.5和GPT-4）。我们开发了三种LLM应用方案：零样本分类器、训练数据标注工具，以及结合少量人工标注样本的数据增强方法。实验表明：使用GPT-4进行数据增强，配合少量人工标注数据训练轻量级监督模型，其效果显著优于纯人工标注数据训练。监督学习模型在零样本场景下也优于GPT-4和GPT-3.5。这种数据增强策略能有效利用LLMs构建更精简高效的领域专用模型。研究发现：无人工指导的LLM标注数据训练策略效果欠佳，但作为零样本分类器时，LLM在排除假阴性样本方面表现突出，可降低人工标注需求。未来研究需重点探索最佳训练数据规模与增强数据比例的优化方案。

翻译说明：
1. 专业术语处理：采用"大型语言模型（LLMs）"、"零样本分类器"等学界通用译法
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句结构
3. 被动语态转换："have been difficult"译为主动式"难以获得"
4. 概念显化："lightweight supervised classification models"译为"轻量级监督模型"并保留技术特征
5. 逻辑显化：通过"实验表明"、"研究发现"等过渡词明确研究结论的层次
6. 文化适配："benchmark"译为"系统评估"更符合中文论文表述习惯
7. 术语统一：全篇保持"监督学习/零样本/数据增强"等核心概念译法一致
