# Vision-Language Models for Automated Chest X-ray Interpretation: Leveraging ViT and GPT-2

链接: http://arxiv.org/abs/2501.12356v1

原文摘要:
Radiology plays a pivotal role in modern medicine due to its non-invasive
diagnostic capabilities. However, the manual generation of unstructured medical
reports is time consuming and prone to errors. It creates a significant
bottleneck in clinical workflows. Despite advancements in AI-generated
radiology reports, challenges remain in achieving detailed and accurate report
generation. In this study we have evaluated different combinations of
multimodal models that integrate Computer Vision and Natural Language
Processing to generate comprehensive radiology reports. We employed a
pretrained Vision Transformer (ViT-B16) and a SWIN Transformer as the image
encoders. The BART and GPT-2 models serve as the textual decoders. We used
Chest X-ray images and reports from the IU-Xray dataset to evaluate the
usability of the SWIN Transformer-BART, SWIN Transformer-GPT-2, ViT-B16-BART
and ViT-B16-GPT-2 models for report generation. We aimed at finding the best
combination among the models. The SWIN-BART model performs as the
best-performing model among the four models achieving remarkable results in
almost all the evaluation metrics like ROUGE, BLEU and BERTScore.

中文翻译:
放射学因其无创诊断能力在现代医学中发挥着关键作用。然而，人工生成非结构化的医学报告不仅耗时且容易出错，已成为临床工作流程中的显著瓶颈。尽管人工智能生成放射学报告的技术有所进步，但在实现详尽准确的报告生成方面仍存在挑战。本研究评估了多种结合计算机视觉与自然语言处理的多模态模型组合，以生成全面的放射学报告。我们采用预训练的Vision Transformer（ViT-B16）和SWIN Transformer作为图像编码器，并选用BART与GPT-2模型作为文本解码器。通过使用IU-Xray数据集中的胸部X光图像及对应报告，我们评估了SWIN-BART、SWIN-GPT-2、ViT-BART和ViT-GPT-2四种模型组合的报告生成性能，旨在确定最优模型组合。实验结果表明，SWIN-BART模型在四种组合中表现最优，在ROUGE、BLEU和BERTScore等几乎所有评估指标上均取得了显著成果。

（翻译说明：1. 专业术语如"Vision Transformer"保留英文缩写ViT并标注全称；2. 被动语态转换为中文主动句式；3. 长句拆分符合中文表达习惯；4. 关键指标名称保留英文大写形式；5. "bottleneck"译为"瓶颈"并添加"显著"强化语境；6. 模型组合名称采用中划线连接保持技术文档规范性）
