# Boosting Healthcare LLMs Through Retrieved Context

链接: http://arxiv.org/abs/2409.15127v1

原文摘要:
This study leverages optimized context retrieval to enhance open-source Large
Language Models (LLMs) for cost-effective, high performance healthcare AI. We
demonstrate that this approach achieves state-of-the-art accuracy on medical
question answering at a fraction of the cost of proprietary models,
significantly improving the cost-accuracy Pareto frontier on the MedQA
benchmark. Key contributions include: (1) OpenMedQA, a novel benchmark
revealing a performance gap in open-ended medical QA compared to
multiple-choice formats; (2) a practical, reproducible pipeline for context
retrieval optimization; and (3) open-source resources (Prompt Engine,
CoT/ToT/Thinking databases) to empower healthcare AI development. By advancing
retrieval techniques and QA evaluation, we enable more affordable and reliable
LLM solutions for healthcare.

中文翻译:
本研究通过优化上下文检索技术来增强开源大语言模型（LLMs），旨在实现高性价比的医疗人工智能应用。我们证明该方法在医学问答任务上以远低于商业模型的成本达到最先进准确率，显著改善了MedQA基准测试中成本-准确率的帕累托前沿。主要贡献包括：（1）OpenMedQA新基准测试，揭示了开放式医学问答与多选题形式之间的性能差距；（2）一套可复现的上下文检索优化实践流程；（3）开源资源（提示引擎、思维链/思维树数据库）以赋能医疗AI开发。通过推进检索技术与问答评估体系，我们为医疗领域提供了更经济可靠的LLM解决方案。

（翻译说明：采用学术论文摘要的标准表述方式，对专业术语如"Pareto frontier"保留核心概念并采用中文领域通用译法"帕累托前沿"，"CoT/ToT"等缩写首次出现时补充完整译名。通过拆分英文长句为符合中文表达习惯的短句结构，如将"at a fraction of the cost"转化为"以远低于...的成本"，同时保持"state-of-the-art"等关键表述的准确传达。最后一句采用"推进...提供..."的递进句式，既忠实原意又符合中文科技文本的总结性表述规范。）
