# Relational Database Augmented Large Language Model

链接: http://arxiv.org/abs/2407.15071v1

原文摘要:
Large language models (LLMs) excel in many natural language processing (NLP)
tasks. However, since LLMs can only incorporate new knowledge through training
or supervised fine-tuning processes, they are unsuitable for applications that
demand precise, up-to-date, and private information not available in the
training corpora. This precise, up-to-date, and private information is
typically stored in relational databases. Thus, a promising solution is to
augment LLMs with the inclusion of relational databases as external memory.
This can ensure the timeliness, correctness, and consistency of data, and
assist LLMs in performing complex arithmetic operations beyond their inherent
capabilities. However, bridging the gap between LLMs and relational databases
is challenging. It requires the awareness of databases and data values stored
in databases to select correct databases and issue correct SQL queries.
Besides, it is necessary for the external memory to be independent of the LLM
to meet the needs of real-world applications. We introduce a novel LLM-agnostic
memory architecture comprising a database selection memory, a data value
memory, and relational databases. And we design an elegant pipeline to retrieve
information from it. Besides, we carefully design the prompts to instruct the
LLM to maximize the framework's potential. To evaluate our method, we compose a
new dataset with various types of questions. Experimental results show that our
framework enables LLMs to effectively answer database-related questions, which
is beyond their direct ability.

中文翻译:
以下是您提供的英文论文摘要的中文翻译：

【大语言模型与关系型数据库的协同增强框架】

大语言模型（LLMs）在众多自然语言处理任务中表现卓越，但其知识更新仅能通过训练或有监督微调实现，这导致其难以满足需要精确性、时效性及私有性信息的应用场景——这类信息通常存储于关系型数据库中。为此，我们提出通过将关系型数据库作为外部记忆模块来增强LLMs，既可确保数据的时效性、准确性与一致性，又能辅助模型完成其固有能力之外的复杂算术运算。

然而，实现LLMs与关系型数据库的协同面临双重挑战：一方面需要模型具备数据库感知能力以正确选择目标数据库并生成准确SQL查询，另一方面要求外部记忆模块保持与LLM的独立性以适应实际应用需求。本文创新性地提出了一种与LLM无关的三层记忆架构（包含数据库选择记忆、数据值记忆及关系型数据库），并设计了高效的信息检索流程。通过精心设计的提示模板，我们最大程度释放了该框架的潜力。

为验证方法有效性，我们构建了包含多类型问题的新数据集。实验结果表明，该框架成功突破了LLMs的固有局限，使其能够有效解答依赖数据库信息的复杂问题。
