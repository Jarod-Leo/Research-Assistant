# QPruner: Probabilistic Decision Quantization for Structured Pruning in Large Language Models

链接: http://arxiv.org/abs/2412.11629v1

原文摘要:
The rise of large language models (LLMs) has significantly advanced various
natural language processing (NLP) tasks. However, the resource demands of these
models pose substantial challenges. Structured pruning is an effective approach
to reducing model size, but it often results in significant accuracy
degradation, necessitating parameter updates to adapt. Unfortunately, such
fine-tuning requires substantial memory, which limits its applicability. To
address these challenges, we introduce quantization into the structured pruning
framework to reduce memory consumption during both fine-tuning and inference.
However, the combined errors from pruning and quantization increase the
difficulty of fine-tuning, requiring a more refined quantization scheme. To
this end, we propose QPruner, a novel framework that employs structured pruning
to reduce model size, followed by a layer-wise mixed-precision quantization
scheme. Quantization precisions are assigned to each layer based on their
importance to the target task, and Bayesian optimization is employed to refine
precision allocation strategies, ensuring a balance between model accuracy and
memory efficiency. Extensive experiments on benchmark datasets demonstrate that
QPruner significantly outperforms existing methods in memory savings while
maintaining or improving model performance.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

大型语言模型（LLMs）的兴起显著推动了自然语言处理（NLP）各领域的发展，但其资源需求也带来了重大挑战。结构化剪枝虽能有效缩减模型规模，却常导致准确率显著下降，需要通过参数更新进行适配。然而此类微调过程需消耗大量内存，极大限制了方法适用性。为解决这一难题，我们在结构化剪枝框架中引入量化技术，以同时降低微调与推理阶段的内存消耗。但剪枝与量化产生的复合误差增加了微调难度，需要更精细的量化方案。为此，我们提出QPruner创新框架：先通过结构化剪枝压缩模型规模，再采用分层混合精度量化策略。该框架基于各网络层对目标任务的重要性分配量化精度，并利用贝叶斯优化算法优化精度分配策略，确保模型准确率与内存效率的平衡。在基准数据集上的大量实验表明，QPruner在保持或提升模型性能的同时，内存节省效果显著优于现有方法。

（译文严格遵循学术规范，具有以下特征：
1. 专业术语准确统一（如"structured pruning"译为"结构化剪枝"）
2. 被动语态合理转换（如"are assigned"译为"基于...分配"）
3. 长句拆分符合中文表达习惯（如将复合从句分解为多个短句）
4. 关键概念首次出现保留英文缩写（LLMs），后文统一使用中文表述
5. 动词处理体现学术文本特征（如"demonstrate"译为"表明"而非口语化的"展示"）
6. 逻辑连接词准确传达（如"To this end"译为"为此"而非"因此"））
