# American Sign Language to Text Translation using Transformer and Seq2Seq with LSTM

链接: http://arxiv.org/abs/2409.10874v1

原文摘要:
Sign language translation is one of the important issues in communication
between deaf and hearing people, as it expresses words through hand, body, and
mouth movements. American Sign Language is one of the sign languages used, one
of which is the alphabetic sign. The development of neural machine translation
technology is moving towards sign language translation. Transformer became the
state-of-the-art in natural language processing. This study compares the
Transformer with the Sequence-to-Sequence (Seq2Seq) model in translating sign
language to text. In addition, an experiment was conducted by adding Residual
Long Short-Term Memory (ResidualLSTM) in the Transformer. The addition of
ResidualLSTM to the Transformer reduces the performance of the Transformer
model by 23.37% based on the BLEU Score value. In comparison, the Transformer
itself increases the BLEU Score value by 28.14 compared to the Seq2Seq model.

中文翻译:
手语翻译是聋人与听人交流的重要课题之一，它通过手部动作、身体姿态和唇部运动来表达语义。美国手语作为主流手语体系之一，其字母手语是重要的组成部分。随着神经机器翻译技术的发展，手语翻译领域也迎来了技术革新，其中Transformer模型已成为自然语言处理领域的性能标杆。本研究对比了Transformer与序列到序列（Seq2Seq）模型在手语文本翻译中的表现，并创新性地在Transformer架构中引入残差长短时记忆网络（ResidualLSTM）进行实验。实验结果表明：基于BLEU评分指标，添加ResidualLSTM反而使Transformer模型性能下降23.37%；而原生Transformer模型相较Seq2Seq模型则实现了28.14分的BLEU值提升。

（翻译说明：
1. 专业术语统一处理："ResidualLSTM"保留英文缩写同时补充中文全称，"BLEU Score"采用通用译法
2. 句式重构：将原文三个松散段落整合为符合中文论文摘要的紧凑结构，包含研究背景、方法、结论三要素
3. 逻辑显化：通过"其中"、"而"等连接词明确对比关系，使用"创新性地"突出研究亮点
4. 数据呈现：精确保留百分比和评分值，采用中文数字书写规范
5. 学术风格：使用"迎来技术革新"、"性能标杆"等符合学术文本的表述方式）
