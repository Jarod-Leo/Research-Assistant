# Bridging the Gap: Deciphering Tabular Data Using Large Language Model

链接: http://arxiv.org/abs/2308.11891v1

原文摘要:
In the realm of natural language processing, the understanding of tabular
data has perpetually stood as a focal point of scholarly inquiry. The emergence
of expansive language models, exemplified by the likes of ChatGPT, has ushered
in a wave of endeavors wherein researchers aim to harness these models for
tasks related to table-based question answering. Central to our investigative
pursuits is the elucidation of methodologies that amplify the aptitude of such
large language models in discerning both the structural intricacies and
inherent content of tables, ultimately facilitating their capacity to provide
informed responses to pertinent queries. To this end, we have architected a
distinctive module dedicated to the serialization of tables for seamless
integration with expansive language models. Additionally, we've instituted a
corrective mechanism within the model to rectify potential inaccuracies.
Experimental results indicate that, although our proposed method trails the
SOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about
1.2% in tests on specific datasets. This research marks the first application
of large language models to table-based question answering tasks, enhancing the
model's comprehension of both table structures and content.

中文翻译:
在自然语言处理领域，表格数据的理解始终是学术研究的重点方向。随着以ChatGPT为代表的超大规模语言模型的出现，研究者们掀起了一波利用此类模型进行表格问答任务的研究热潮。本研究的核心在于探索增强大语言模型解析表格结构特征与内在内容的方法，从而提升其回答相关问题的能力。为此，我们设计了一个独特的表格序列化模块以实现与大语言模型的无缝对接，并在模型中内置了错误校正机制。实验结果表明：虽然我们提出的方法在整体指标上较SOTA（当前最优技术）低约11.7%，但在特定数据集测试中反超SOTA约1.2%。本研究首次将大语言模型应用于表格问答任务，显著提升了模型对表格结构与内容的理解能力。


