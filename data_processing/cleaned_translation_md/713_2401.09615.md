# Learning Shortcuts: On the Misleading Promise of NLU in Language Models

链接: http://arxiv.org/abs/2401.09615v1

原文摘要:
The advent of large language models (LLMs) has enabled significant
performance gains in the field of natural language processing. However, recent
studies have found that LLMs often resort to shortcuts when performing tasks,
creating an illusion of enhanced performance while lacking generalizability in
their decision rules. This phenomenon introduces challenges in accurately
assessing natural language understanding in LLMs. Our paper provides a concise
survey of relevant research in this area and puts forth a perspective on the
implications of shortcut learning in the evaluation of language models,
specifically for NLU tasks. This paper urges more research efforts to be put
towards deepening our comprehension of shortcut learning, contributing to the
development of more robust language models, and raising the standards of NLU
evaluation in real-world scenarios.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）的出现为自然语言处理领域带来了显著的性能提升。然而，最新研究发现LLMs在执行任务时往往依赖捷径策略，这种机制虽能营造性能增强的表象，却导致其决策规则缺乏泛化能力。该现象为准确评估LLMs的自然语言理解能力带来了新的挑战。本文系统梳理了该领域的相关研究，并就捷径学习对语言模型评估（特别是自然语言理解任务）的影响提出了新的观点。我们呼吁学界投入更多研究以深化对捷径学习的认知，这既有助于开发更具鲁棒性的语言模型，也能提升现实场景中自然语言理解任务的评估标准。

注：翻译过程中采取了以下专业处理：
1. 术语统一："shortcuts"译为"捷径策略"而非字面直译，符合认知心理学领域术语
2. 句式重构：将英文长句拆解为符合中文表达习惯的短句结构（如第二句处理）
3. 学术规范：使用"泛化能力""鲁棒性"等专业术语保持学术严谨性
4. 逻辑显化：通过"机制""表象"等词准确传达原文的批判性立场
5. 衔接处理：使用"该现象""既...也..."等连接词保持论证连贯性
