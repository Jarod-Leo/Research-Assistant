# Automated Interviewer or Augmented Survey? Collecting Social Data with Large Language Models

链接: http://arxiv.org/abs/2309.10187v1

原文摘要:
Chatbots have shown promise as tools to scale qualitative data collection.
Recent advances in Large Language Models (LLMs) could accelerate this process
by allowing researchers to easily deploy sophisticated interviewing chatbots.
We test this assumption by conducting a large-scale user study (n=399)
evaluating 3 different chatbots, two of which are LLM-based and a baseline
which employs hard-coded questions. We evaluate the results with respect to
participant engagement and experience, established metrics of chatbot quality
grounded in theories of effective communication, and a novel scale evaluating
"richness" or the extent to which responses capture the complexity and
specificity of the social context under study. We find that, while the chatbots
were able to elicit high-quality responses based on established evaluation
metrics, the responses rarely capture participants' specific motives or
personalized examples, and thus perform poorly with respect to richness. We
further find low inter-rater reliability between LLMs and humans in the
assessment of both quality and richness metrics. Our study offers a cautionary
tale for scaling and evaluating qualitative research with LLMs.

中文翻译:
聊天机器人作为扩展定性数据收集的工具已展现出应用潜力。大型语言模型（LLM）的最新进展可能加速这一进程，使研究者能便捷部署复杂的访谈机器人。我们通过一项大规模用户研究（n=399）验证这一假设，评估了三种不同聊天机器人（其中两个基于LLM，另一个采用硬编码问题作为基线）。我们从参与者参与度与体验、基于有效沟通理论建立的聊天机器人质量指标，以及评估"丰富性"（即回答捕捉研究对象社会背景复杂性和具体程度的程度）的新量表三个维度进行分析。研究发现：虽然这些机器人能基于既定评估指标获得高质量回答，但回应很少能体现参与者的具体动机或个性化案例，因此在丰富性维度表现欠佳。我们还发现LLM与人类评估者在质量与丰富性指标评判上存在较低的评价者间信度。本研究为使用LLM扩展和评估定性研究提出了警示性启示。

（翻译说明：1. 专业术语如"qualitative data collection"译为"定性数据收集"符合学术规范 2. 采用"大型语言模型"统一"LLM"的译法 3. "richness"创新译为"丰富性"并通过括号补充解释 4. 长难句拆分处理，如将原文最后复合句分解为两个独立句 5. 保持被动语态与主动语态的合理转换 6. 计量单位"n=399"保留国际通用写法 7. "cautionary tale"译为"警示性启示"准确传达原文隐喻）
