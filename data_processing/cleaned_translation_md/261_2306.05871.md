# Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?

链接: http://arxiv.org/abs/2306.05871v1

原文摘要:
Recent advances in natural language processing (NLP) have led to the
development of large language models (LLMs) such as ChatGPT. This paper
proposes a methodology for developing and evaluating ChatGPT detectors for
French text, with a focus on investigating their robustness on out-of-domain
data and against common attack schemes. The proposed method involves
translating an English dataset into French and training a classifier on the
translated data. Results show that the detectors can effectively detect
ChatGPT-generated text, with a degree of robustness against basic attack
techniques in in-domain settings. However, vulnerabilities are evident in
out-of-domain contexts, highlighting the challenge of detecting adversarial
text. The study emphasizes caution when applying in-domain testing results to a
wider variety of content. We provide our translated datasets and models as
open-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection

中文翻译:
自然语言处理（NLP）领域的最新进展催生了ChatGPT等大语言模型（LLM）的发展。本文提出了一种针对法语文本的ChatGPT检测器开发与评估方法，重点探究其在域外数据及常见攻击方案下的鲁棒性。该方法通过将英文数据集翻译为法语，并基于翻译数据训练分类器实现。实验结果表明，该检测器能有效识别ChatGPT生成文本，在域内场景中对基础攻击技术具有一定鲁棒性。然而在域外语境中暴露出明显脆弱性，这凸显了对抗性文本检测的挑战。研究强调将域内测试结果推广至多样化内容时需保持谨慎。我们已将翻译数据集与模型作为开源资源发布。https://gitlab.inria.fr/wantoun/robust-chatgpt-detection

（翻译说明：采用学术论文摘要的标准表述方式，处理了以下要点：
1. 专业术语统一："large language models"译为"大语言模型"并保留"LLM"缩写
2. 技术概念准确传达："out-of-domain data"译为"域外数据"，"adversarial text"译为"对抗性文本"
3. 句式结构调整：将英文长句拆分为符合中文表达习惯的短句，如将"with a focus on..."处理为独立分句
4. 被动语态转换："are evident"译为"暴露出"增强可读性
5. 保留关键信息：完整呈现开源链接及项目名称
6. 学术风格保持：使用"探究""凸显""需保持谨慎"等符合学术规范的表述）
