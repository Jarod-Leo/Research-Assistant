# Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models

链接: http://arxiv.org/abs/2311.01732v1

原文摘要:
Large Language Models (LLMs) have significantly advanced the field of Natural
Language Processing (NLP), but their lack of interpretability has been a major
concern. Current methods for interpreting LLMs are post hoc, applied after
inference time, and have limitations such as their focus on low-level features
and lack of explainability at higher level text units. In this work, we
introduce proto-lm, a prototypical network-based white-box framework that
allows LLMs to learn immediately interpretable embeddings during the
fine-tuning stage while maintaining competitive performance. Our method's
applicability and interpretability are demonstrated through experiments on a
wide range of NLP tasks, and our results indicate a new possibility of creating
interpretable models without sacrificing performance. This novel approach to
interpretability in LLMs can pave the way for more interpretable models without
the need to sacrifice performance.

中文翻译:
大语言模型（LLMs）显著推动了自然语言处理（NLP）领域的发展，但其缺乏可解释性始终是主要痛点。现有LLM解释方法多为事后分析，在模型推理完成后实施，且存在明显局限：这些方法往往聚焦底层特征，无法对更高层次的文本单元提供有效解释。本研究提出proto-lm——一个基于原型网络的白盒框架，使LLMs在微调阶段即可学习即时可解释的嵌入表示，同时保持竞争优势。通过在多类NLP任务上的实验，我们验证了该方法的适用性与可解释性。实验结果表明，构建不牺牲性能的可解释模型具有新的可能性。这种创新的LLM可解释性研究路径，为开发性能与可解释性兼备的模型开辟了新方向。
