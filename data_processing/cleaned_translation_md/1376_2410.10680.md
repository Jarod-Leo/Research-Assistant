# Evaluating SQL Understanding in Large Language Models

链接: http://arxiv.org/abs/2410.10680v1

原文摘要:
The rise of large language models (LLMs) has significantly impacted various
domains, including natural language processing (NLP) and image generation, by
making complex computational tasks more accessible. While LLMs demonstrate
impressive generative capabilities, there is an ongoing debate about their
level of "understanding," particularly in structured domains like SQL. In this
paper, we evaluate the extent to which LLMs "understand" SQL by testing them on
a series of key SQL tasks. These tasks, such as syntax error detection, missing
token identification, query performance prediction, query equivalence checking,
and query explanation, assess the models' proficiency in recognition, context
awareness, semantics, and coherence, which are essential skills for SQL
understanding. We generate labeled datasets from well-known workloads, and
evaluate the latest LLMs, focusing on how query complexity and syntactic
features influence performance. Our results indicate that while GPT4 excels at
tasks requiring recognition and context, all models struggle with deeper
semantic understanding and coherence, especially in query equivalence and
performance estimation, revealing the limitations of current LLMs in achieving
full SQL comprehension.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）的崛起通过降低复杂计算任务的门槛，显著影响了自然语言处理（NLP）和图像生成等多个领域。尽管LLMs展现出令人印象深刻的生成能力，学界对其"理解"水平的争论持续存在，尤其在SQL这类结构化领域。本文通过一系列关键SQL任务测试，系统评估了LLMs对SQL的"理解"程度。这些任务包括语法错误检测、缺失标记识别、查询性能预测、查询等价性检查和查询解释，分别检验模型在识别能力、上下文感知、语义理解和逻辑连贯性等SQL理解核心维度上的表现。我们从知名工作负载生成标注数据集，重点评估最新LLMs在不同查询复杂度与语法特征下的表现。结果表明：GPT4在需要识别能力和上下文理解的任务中表现优异，但所有模型在深层语义理解和逻辑连贯性（特别是查询等价性判断和性能预估）方面均存在明显不足，这揭示了当前LLMs在实现完整SQL理解方面的局限性。

翻译说明：
1. 专业术语处理：保留"NLP"、"GPT4"等专业缩写，确保学术严谨性
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句（如将定语从句转换为分句）
3. 概念对应："context awareness"译为"上下文感知"，"semantic understanding"译为"语义理解"等
4. 逻辑显化：通过"结果表明"等连接词明确原文隐含的因果关系
5. 术语统一：全篇保持"LLMs"、"SQL"等关键术语译法一致
6. 学术风格：使用"显著影响""系统评估"等符合论文摘要规范的表述
