# A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms

链接: http://arxiv.org/abs/2409.16694v1

原文摘要:
Large language models (LLMs) have achieved remarkable advancements in natural
language processing, showcasing exceptional performance across various tasks.
However, the expensive memory and computational requirements present
significant challenges for their practical deployment. Low-bit quantization has
emerged as a critical approach to mitigate these challenges by reducing the
bit-width of model parameters, activations, and gradients, thus decreasing
memory usage and computational demands. This paper presents a comprehensive
survey of low-bit quantization methods tailored for LLMs, covering the
fundamental principles, system implementations, and algorithmic strategies. An
overview of basic concepts and new data formats specific to low-bit LLMs is
first introduced, followed by a review of frameworks and systems that
facilitate low-bit LLMs across various hardware platforms. Then, we categorize
and analyze techniques and toolkits for efficient low-bit training and
inference of LLMs. Finally, we conclude with a discussion of future trends and
potential advancements of low-bit LLMs. Our systematic overview from basic,
system, and algorithm perspectives can offer valuable insights and guidelines
for future works to enhance the efficiency and applicability of LLMs through
low-bit quantization.

中文翻译:
以下是符合您要求的学术化中文翻译：

大语言模型（LLMs）在自然语言处理领域取得了显著进展，在各种任务中展现出卓越性能。然而，其高昂的内存与计算需求为实际部署带来了重大挑战。低比特量化通过降低模型参数、激活值和梯度的位宽，有效减少内存占用和计算需求，已成为应对这些挑战的关键技术路径。本文系统综述了面向大语言模型的低比特量化方法，涵盖基本原理、系统实现与算法策略三个维度：首先阐述低比特大语言模型的基础概念与新型数据格式；继而梳理支持跨硬件平台部署的低比特框架与系统架构；随后对高效低比特训练与推理的技术工具包进行分类解析；最后探讨该领域的未来发展趋势与潜在突破方向。本研究从基础理论、系统实现和算法创新三个层面构建的系统性综述，可为通过低比特量化提升大语言模型效率与适用性的后续研究提供有价值的参考框架与技术指引。

注：本译文具有以下特点：
1. 专业术语统一（如"low-bit quantization"统一译为"低比特量化"）
2. 长句拆分符合中文表达习惯（如将原文最后长句拆分为两个层次）
3. 学术用语准确（如"systematic overview"译为"系统性综述"）
4. 逻辑连接词处理（如"followed by"转化为中文惯用的"继而"）
5. 被动语态转化（如"are first introduced"译为主动式的"首先阐述"）
