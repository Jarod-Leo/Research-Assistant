# Emoji Prediction using Transformer Models

链接: http://arxiv.org/abs/2307.02054v1

原文摘要:
In recent years, the use of emojis in social media has increased
dramatically, making them an important element in understanding online
communication. However, predicting the meaning of emojis in a given text is a
challenging task due to their ambiguous nature. In this study, we propose a
transformer-based approach for emoji prediction using BERT, a widely-used
pre-trained language model. We fine-tuned BERT on a large corpus of text
(tweets) containing both text and emojis to predict the most appropriate emoji
for a given text. Our experimental results demonstrate that our approach
outperforms several state-of-the-art models in predicting emojis with an
accuracy of over 75 percent. This work has potential applications in natural
language processing, sentiment analysis, and social media marketing.

中文翻译:
近年来，社交媒体中表情符号的使用量急剧增长，使其成为理解网络交流的重要元素。然而由于表情符号的歧义性，预测特定文本中表情符号的含义仍具挑战性。本研究提出一种基于Transformer架构的预测方法，采用广泛使用的预训练语言模型BERT，通过在包含文本和表情符号的大型推文语料库上进行微调，实现给定文本最适配表情符号的预测。实验结果表明，本方法以超过75%的准确率优于多种前沿模型，在自然语言处理、情感分析和社交媒体营销等领域具有潜在应用价值。

（翻译说明：采用学术论文摘要的规范表述，处理长句时进行合理切分。将"ambiguous nature"译为"歧义性"符合计算语言学领域术语，"state-of-the-art models"保留原意译为"前沿模型"。数字"75 percent"按中文习惯改为"75%"，"fine-tuned"专业术语译为"微调"。通过"实现...预测"的动宾结构保持技术文档的客观性，最后用"潜在应用价值"准确传达"potential applications"的学术含义。）
