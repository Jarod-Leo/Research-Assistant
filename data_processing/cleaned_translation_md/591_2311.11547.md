# Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT

链接: http://arxiv.org/abs/2311.11547v1

原文摘要:
Recently, Large Language Models like ChatGPT have demonstrated remarkable
proficiency in various Natural Language Processing tasks. Their application in
Requirements Engineering, especially in requirements classification, has gained
increasing interest. This paper reports an extensive empirical evaluation of
two ChatGPT models, specifically gpt-3.5-turbo, and gpt-4 in both zero-shot and
few-shot settings for requirements classification. The question arises as to
how these models compare to traditional classification methods, specifically
Support Vector Machine and Long Short-Term Memory. Based on five different
datasets, our results show that there is no single best technique for all types
of requirement classes. Interestingly, the few-shot setting has been found to
be beneficial primarily in scenarios where zero-shot results are significantly
low.

中文翻译:
近年来，以ChatGPT为代表的大型语言模型在各类自然语言处理任务中展现出卓越性能。其在需求工程领域（特别是需求分类任务）的应用正引发日益广泛的关注。本文针对gpt-3.5-turbo和gpt-4两种ChatGPT模型，在零样本和小样本场景下的需求分类表现开展了全面实证评估。研究核心在于探究这些模型与传统分类方法（特别是支持向量机和长短期记忆网络）的性能对比。基于五个不同数据集的实验结果表明：对于所有类型的需求类别而言，并不存在一种绝对最优的技术方案。值得注意的是，小样本学习仅在零样本分类效果显著偏低的情况下才展现出明显优势。

（译文说明：
1. 专业术语处理："Requirements Engineering"规范译为"需求工程"，"Support Vector Machine"采用中文领域通用译名"支持向量机"
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"how these models compare to..."转换为探究式表达
3. 逻辑显化：通过"研究核心在于"明确揭示隐含的研究问题
4. 学术风格保持：使用"实证评估""显著偏低"等符合学术论文表达的措辞
5. 文化适配：将被动语态"has been found to be"转换为中文常见的主动表述"展现出"）
