# Making Metadata More FAIR Using Large Language Models

链接: http://arxiv.org/abs/2307.13085v1

原文摘要:
With the global increase in experimental data artifacts, harnessing them in a
unified fashion leads to a major stumbling block - bad metadata. To bridge this
gap, this work presents a Natural Language Processing (NLP) informed
application, called FAIRMetaText, that compares metadata. Specifically,
FAIRMetaText analyzes the natural language descriptions of metadata and
provides a mathematical similarity measure between two terms. This measure can
then be utilized for analyzing varied metadata, by suggesting terms for
compliance or grouping similar terms for identification of replaceable terms.
The efficacy of the algorithm is presented qualitatively and quantitatively on
publicly available research artifacts and demonstrates large gains across
metadata related tasks through an in-depth study of a wide variety of Large
Language Models (LLMs). This software can drastically reduce the human effort
in sifting through various natural language metadata while employing several
experimental datasets on the same topic.

中文翻译:
随着全球实验数据资源的快速增长，如何统一规范化利用这些资源面临着一个主要障碍——元数据质量问题。为消除这一障碍，本研究开发了一款基于自然语言处理（NLP）技术的元数据比对工具FAIRMetaText。该工具通过分析元数据的自然语言描述，为不同术语提供数学化的相似性度量指标。该指标可应用于多元元数据分析场景：既能推荐符合规范的标准术语，也能通过聚类相似术语识别可替换词汇。我们基于公开研究数据资源，采用定性与定量相结合的方法验证算法效能，并通过系统评估多种大语言模型（LLM）在元数据相关任务中的表现，证实其能显著提升处理效率。该软件可大幅降低科研人员在整合同一主题下多组实验数据集时，人工筛选自然语言元数据的工作负担。

（翻译说明：
1. 专业术语处理："artifacts"译为"资源"以符合中文科研语境，"metadata"统一译为"元数据"
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"harnessing them..."处理为因果句式
3. 被动语态转换："the efficacy is presented"转为主动语态"验证算法效能"
4. 概念显化："suggesting terms for compliance"具体化为"推荐符合规范的标准术语"
5. 文化适配："stumbling block"译为"障碍"而非直译"绊脚石"，更符合学术文本风格
6. 逻辑衔接：通过"既能...也能..."的并列结构清晰呈现工具的双重功能）
