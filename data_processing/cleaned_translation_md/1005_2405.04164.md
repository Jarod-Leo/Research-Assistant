# Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation

链接: http://arxiv.org/abs/2405.04164v1

原文摘要:
Automatic Sign Language Translation requires the integration of both computer
vision and natural language processing to effectively bridge the communication
gap between sign and spoken languages. However, the deficiency in large-scale
training data to support sign language translation means we need to leverage
resources from spoken language. We introduce, Sign2GPT, a novel framework for
sign language translation that utilizes large-scale pretrained vision and
language models via lightweight adapters for gloss-free sign language
translation. The lightweight adapters are crucial for sign language
translation, due to the constraints imposed by limited dataset sizes and the
computational requirements when training with long sign videos. We also propose
a novel pretraining strategy that directs our encoder to learn sign
representations from automatically extracted pseudo-glosses without requiring
gloss order information or annotations. We evaluate our approach on two public
benchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T
and CSL-Daily, and improve on state-of-the-art gloss-free translation
performance with a significant margin.

中文翻译:
自动手语翻译需要结合计算机视觉与自然语言处理技术，以有效消除手语与口语之间的沟通障碍。然而，由于缺乏支持手语翻译的大规模训练数据，我们必须充分利用口语资源。本文提出创新框架Sign2GPT，该框架通过轻量级适配器利用大规模预训练的视觉与语言模型，实现无需手语注释词汇（gloss-free）的翻译。鉴于有限数据集规模和长手语视频训练的计算需求，轻量级适配器对手语翻译至关重要。我们还提出一种新颖的预训练策略：通过自动提取的伪注释词汇引导编码器学习手语表征，且无需注释词汇顺序信息或标注。在RWTH-PHOENIX-Weather 2014T和CSL-Daily两个公开手语翻译基准数据集上的实验表明，我们的方法以显著优势刷新了无需注释词汇翻译任务的最高性能。

（翻译说明：采用学术论文摘要的标准表述方式，处理了以下难点：
1. "gloss-free"译为专业术语"无需手语注释词汇"并括号标注英文原词
2. "pseudo-glosses"意译为"伪注释词汇"以保持概念准确性
3. "state-of-the-art"译为"最高性能"符合中文论文习惯
4. 长难句拆分重组，如将"due to..."状语从句转为独立分句
5. 专业术语如"encoder"统一译为"编码器"
6. 保持被动语态与主动语态的合理转换，如"are crucial for"转为"对...至关重要"）
