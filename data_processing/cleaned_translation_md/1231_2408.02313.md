# A Lean Transformer Model for Dynamic Malware Analysis and Detection

链接: http://arxiv.org/abs/2408.02313v1

原文摘要:
Malware is a fast-growing threat to the modern computing world and existing
lines of defense are not efficient enough to address this issue. This is mainly
due to the fact that many prevention solutions rely on signature-based
detection methods that can easily be circumvented by hackers. Therefore, there
is a recurrent need for behavior-based analysis where a suspicious file is ran
in a secured environment and its traces are collected to reports for analysis.
Previous works have shown some success leveraging Neural Networks and API calls
sequences extracted from these execution reports.
  Recently, Large Language Models and Generative AI have demonstrated
impressive capabilities mainly in Natural Language Processing tasks and
promising applications in the cybersecurity field for both attackers and
defenders.
  In this paper, we design an Encoder-Only model, based on the Transformers
architecture, to detect malicious files, digesting their API call sequences
collected by an execution emulation solution. We are also limiting the size of
the model architecture and the number of its parameters since it is often
considered that Large Language Models may be overkill for specific tasks such
as the one we are dealing with hereafter. In addition to achieving decent
detection results, this approach has the advantage of reducing our carbon
footprint by limiting training and inference times and facilitating technical
operations with less hardware requirements.
  We also carry out some analysis of our results and highlight the limits and
possible improvements when using Transformers to analyze malicious files.

中文翻译:
恶意软件对现代计算机世界构成快速增长的威胁，而现有防御体系尚不足以有效应对这一问题。这主要源于许多防护方案依赖基于特征码的检测方法，此类方法极易被黑客规避。因此，业界持续需要基于行为的分析方法——通过在安全环境中运行可疑文件并收集其行为轨迹生成分析报告。已有研究表明，利用神经网络处理从这些执行报告中提取的API调用序列可取得一定成效。

近年来，大语言模型和生成式人工智能展现出卓越能力，不仅在自然语言处理任务中表现突出，更为网络安全攻防双方都带来了创新应用前景。

本文设计了一种基于Transformer架构的纯编码器模型，通过解析执行模拟解决方案收集的API调用序列来检测恶意文件。考虑到大语言模型可能对特定任务（如本文研究场景）存在过度配置问题，我们有意限制了模型架构规模和参数数量。该方案在保持良好检测效果的同时，还具有三重优势：通过缩短训练和推理时间降低碳足迹；减少硬件需求以简化技术操作；提升实际部署可行性。

此外，我们对实验结果进行了多维度分析，并着重探讨了使用Transformer架构分析恶意文件时的局限性及潜在优化方向。
