# PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization

链接: http://arxiv.org/abs/2408.15185v1

原文摘要:
Video Anomaly Detection (VAD) presents a significant challenge in computer
vision, particularly due to the unpredictable and infrequent nature of
anomalous events, coupled with the diverse and dynamic environments in which
they occur. Human-centric VAD, a specialized area within this domain, faces
additional complexities, including variations in human behavior, potential
biases in data, and substantial privacy concerns related to human subjects.
These issues complicate the development of models that are both robust and
generalizable. To address these challenges, recent advancements have focused on
pose-based VAD, which leverages human pose as a high-level feature to mitigate
privacy concerns, reduce appearance biases, and minimize background
interference. In this paper, we introduce SPARTA, a novel transformer-based
architecture designed specifically for human-centric pose-based VAD. SPARTA
introduces an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)
tokenization method that produces an enriched representation of human motion
over time. This approach ensures that the transformer's attention mechanism
captures both spatial and temporal patterns simultaneously, rather than
focusing on only one aspect. The addition of the relative pose further
emphasizes subtle deviations from normal human movements. The architecture's
core, a novel Unified Encoder Twin Decoders (UETD) transformer, significantly
improves the detection of anomalous behaviors in video data. Extensive
evaluations across multiple benchmark datasets demonstrate that SPARTA
consistently outperforms existing methods, establishing a new state-of-the-art
in pose-based VAD.

中文翻译:
视频异常检测（VAD）是计算机视觉领域的一项重大挑战，这主要源于异常事件的不可预测性和罕见性，以及其所处环境的多样性与动态性。以人为中心的VAD作为该领域的细分方向，还面临着更多复杂问题：人类行为的多样性、数据潜在的偏见性，以及涉及人类主体的重大隐私问题。这些因素使得开发兼具鲁棒性和泛化能力的模型变得尤为困难。

为应对这些挑战，近期研究聚焦于基于人体姿态的VAD方法。该方法利用人体姿态作为高层特征，既能缓解隐私问题，又可减少外观偏见和背景干扰。本文提出SPARTA——一种专为以人为中心的姿态VAD设计的创新型Transformer架构。该架构首创时空姿态与相对姿态（ST-PRP）标记化方法，能生成随时间演进的人体运动增强表征。这种设计确保Transformer注意力机制能同步捕捉空间和时间模式，而非仅关注单一维度。相对姿态的引入进一步强化了对正常人体运动细微偏差的识别能力。

该架构的核心是创新的统一编码器-双解码器（UETD）Transformer结构，显著提升了视频数据中异常行为的检测性能。在多个基准数据集上的大量实验表明，SPARTA持续超越现有方法，为基于姿态的VAD确立了新的技术标杆。

（翻译说明：
1. 专业术语处理：VAD保持英文缩写但首次出现标注全称，Transformer/Encoder/Decoder等专业术语保留英文形式
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如将"coupled with..."独立成短句
3. 被动语态转换："are complicated"转为主动式"使得...变得困难"
4. 概念显化："appearance biases"译为"外观偏见"并补充"性"字符合中文名词习惯
5. 技术表述优化："ST-PRP tokenization"译为"标记化方法"而非直译"令牌化"，更符合计算机视觉领域术语
6. 逻辑连接词添加：使用"既能...又可..."等关联词增强技术方案表述的连贯性
7. 学术风格保持：使用"表征""鲁棒性"等学术用语，结尾"技术标杆"替代直译"state-of-the-art"更符合中文论文表述习惯）
