# Benchmark Data Contamination of Large Language Models: A Survey

链接: http://arxiv.org/abs/2406.04244v1

原文摘要:
The rapid development of Large Language Models (LLMs) like GPT-4, Claude-3,
and Gemini has transformed the field of natural language processing. However,
it has also resulted in a significant issue known as Benchmark Data
Contamination (BDC). This occurs when language models inadvertently incorporate
evaluation benchmark information from their training data, leading to
inaccurate or unreliable performance during the evaluation phase of the
process. This paper reviews the complex challenge of BDC in LLM evaluation and
explores alternative assessment methods to mitigate the risks associated with
traditional benchmarks. The paper also examines challenges and future
directions in mitigating BDC risks, highlighting the complexity of the issue
and the need for innovative solutions to ensure the reliability of LLM
evaluation in real-world applications.

中文翻译:
随着GPT-4、Claude-3和Gemini等大语言模型（LLMs）的快速发展，自然语言处理领域发生了革命性变化。然而，这也引发了一个被称为"基准数据污染"（Benchmark Data Contamination, BDC）的重要问题——当语言模型在训练过程中无意吸纳了评估基准信息时，会导致模型在评估阶段表现出不准确或不可靠的性能表现。本文系统梳理了LLM评估中BDC这一复杂挑战，探讨了替代传统基准测试的评估方法以降低相关风险，同时深入分析了缓解BDC风险面临的挑战与未来研究方向，强调该问题的复杂性及开发创新解决方案的必要性，以确保LLM在实际应用中的评估可靠性。  

（译文说明：  
1. 专业术语统一处理："Large Language Models"统一译为"大语言模型"并保留缩写LLMs；"Benchmark Data Contamination"首次出现时保留英文全称及缩写BDC，后文直接使用缩写  
2. 长句拆分重组：将原文复合句按中文表达习惯拆分为多个短句，如将"when引导的状语从句"转换为破折号解释说明结构  
3. 学术用语规范化："mitigate the risks"译为"降低相关风险"而非字面直译"缓解风险"，更符合学术语境  
4. 逻辑显化处理：通过"——"和"强调"等标点与衔接词，使原文隐含的因果关系更清晰  
5. 动态对等原则："inadvertently incorporate"译为"无意吸纳"而非机械对应"不经意合并"，准确传达技术场景含义）
