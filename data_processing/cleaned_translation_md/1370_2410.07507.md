# Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)

链接: http://arxiv.org/abs/2410.07507v1

原文摘要:
Decoding and expressing brain activity in a comprehensible form is a
challenging frontier in AI. This paper presents Thought2Text, which uses
instruction-tuned Large Language Models (LLMs) fine-tuned with EEG data to
achieve this goal. The approach involves three stages: (1) training an EEG
encoder for visual feature extraction, (2) fine-tuning LLMs on image and text
data, enabling multimodal description generation, and (3) further fine-tuning
on EEG embeddings to generate text directly from EEG during inference.
Experiments on a public EEG dataset collected for six subjects with image
stimuli and text captions demonstrate the efficacy of multimodal LLMs
(LLaMA-v3, Mistral-v0.3, Qwen2.5), validated using traditional language
generation evaluation metrics, as well as fluency and adequacy measures. This
approach marks a significant advancement towards portable, low-cost
"thoughts-to-text" technology with potential applications in both neuroscience
and natural language processing.

中文翻译:
以下是根据学术规范优化的中文翻译：

【译文】
将大脑活动解码并转化为可理解的表达形式是人工智能领域的一项前沿挑战。本研究提出Thought2Text系统，通过基于脑电图（EEG）数据微调的指令型大语言模型（LLMs）实现这一目标。该方法包含三个阶段：（1）训练EEG编码器提取视觉特征；（2）在图像-文本数据上微调LLMs以实现多模态描述生成；（3）进一步在EEG嵌入向量上微调，使模型在推理阶段能直接从EEG信号生成文本。在包含六名受试者观看图像刺激并生成文字描述的公开EEG数据集上，实验验证了多模态LLMs（LLaMA-v3、Mistral-v0.3、Qwen2.5）的有效性，评估采用传统语言生成指标及流畅性、适切性度量。该技术标志着向便携式低成本"思维转文本"系统迈出重要一步，在神经科学与自然语言处理领域均具应用潜力。

【翻译要点说明】
1. 专业术语处理：
- "EEG"译为"脑电图"并首次出现标注英文缩写
- "instruction-tuned"译为"指令型"符合NLP领域规范
- "embeddings"译为"嵌入向量"准确表达数学概念

2. 句式重构：
- 将原文三个stage的列举式结构转化为中文惯用的分号连接式
- "Experiments on..."长句拆分为实验设置与结果两个意群

3. 学术表达优化：
- "demonstrate the efficacy"译为"验证...有效性"更符合中文论文表述
- "potential applications"译为"具应用潜力"保持学术严谨性

4. 技术名词统一：
- 模型名称保留英文代号（LLaMA-v3等）
- "multimodal"统一译为"多模态"（术语一致性）

5. 文化适配：
- "portable, low-cost"译为"便携式低成本"符合中文科技产品描述习惯
