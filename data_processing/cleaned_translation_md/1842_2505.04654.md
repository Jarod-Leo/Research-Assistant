# A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient

链接: http://arxiv.org/abs/2505.04654v1

原文摘要:
Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly
evolved in recent years, showcasing remarkable capabilities in natural language
understanding and generation. However, these advancements also raise critical
ethical questions regarding safety, potential misuse, discrimination and
overall societal impact. This article provides a comparative analysis of the
ethical performance of various AI models, including the brand new
DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5
Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp)
and highlights the need for robust human oversight, especially in situations
with high stakes. Furthermore, we present a new metric for calculating harm in
LLMs called Relative Danger Coefficient (RDC).

中文翻译:
近年来，人工智能（AI）与大语言模型（LLM）快速发展，在自然语言理解与生成方面展现出卓越能力。然而这些技术进步也引发了关于安全性、潜在滥用、歧视及整体社会影响等关键伦理问题。本文对多种AI模型的伦理表现展开对比分析，包括全新推出的DeepSeek-V3（含推理模块的R1版与基础版）、多款GPT变体（4o、3.5 Turbo、4 Turbo、o1/o3 mini）以及Gemini系列（1.5 flash、2.0 flash和2.0 flash exp），并强调在高风险场景中加强人工监督的必要性。此外，我们提出了一项名为"相对危险系数"（RDC）的新指标，用于量化大语言模型可能造成的危害程度。

（翻译说明：
1. 专业术语保留英文缩写并首次出现时标注全称，如LLM/RDC
2. 模型版本号采用技术文档常用表述方式，如"Turbo"不直译
3. "high stakes"译为"高风险场景"符合中文技术文本表述习惯
4. 被动语态转换为主动句式（如"we present"译为"我们提出"）
5. 长句拆分重组，如将"including..."长定语单独处理为中文分句
6. 保持学术文本的严谨性，避免口语化表达）
