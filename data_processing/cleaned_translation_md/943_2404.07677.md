# ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs

链接: http://arxiv.org/abs/2404.07677v1

原文摘要:
The integration of Large Language Models (LLMs) and knowledge graphs (KGs)
has achieved remarkable success in various natural language processing tasks.
However, existing methodologies that integrate LLMs and KGs often navigate the
task-solving process solely based on the LLM's analysis of the question,
overlooking the rich cognitive potential inherent in the vast knowledge
encapsulated in KGs. To address this, we introduce Observation-Driven Agent
(ODA), a novel AI agent framework tailored for tasks involving KGs. ODA
incorporates KG reasoning abilities via global observation, which enhances
reasoning capabilities through a cyclical paradigm of observation, action, and
reflection. Confronting the exponential explosion of knowledge during
observation, we innovatively design a recursive observation mechanism.
Subsequently, we integrate the observed knowledge into the action and
reflection modules. Through extensive experiments, ODA demonstrates
state-of-the-art performance on several datasets, notably achieving accuracy
improvements of 12.87% and 8.9%.

中文翻译:
大型语言模型（LLMs）与知识图谱（KGs）的融合在各类自然语言处理任务中取得了显著成功。然而，现有整合方法通常仅基于LLM对问题的分析来引导任务求解过程，忽视了知识图谱中海量知识所蕴含的丰富认知潜能。为此，我们提出观察驱动智能体（ODA）——一种专为知识图谱任务设计的新型AI智能体框架。ODA通过全局观察机制赋予知识图谱推理能力，构建"观察-行动-反思"的循环范式来增强推理性能。针对观察过程中知识指数级爆炸的挑战，我们创新性地设计了递归观察机制，并将观察所得知识动态融入行动与反思模块。大量实验表明，ODA在多个数据集上实现了最先进的性能表现，准确率最高提升达12.87%和8.9%。

（译文特点说明：
1. 专业术语统一处理："Large Language Models"统一译为"大型语言模型"并保留缩写LLMs
2. 被动语态转化：将"are often navigated"等被动结构转为中文主动式表达
3. 长句拆分重组：将原文复合句按中文表达习惯分解为多个短句
4. 概念显化处理："cyclical paradigm"译为"循环范式"而非字面直译
5. 数据呈现优化：百分比数据保留原始精度，采用中文数字表达规范
6. 技术名词一致性：全程保持"知识图谱"、"智能体"等术语统一）
