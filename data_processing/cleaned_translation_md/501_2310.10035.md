# Empirical Study of Zero-Shot NER with ChatGPT

链接: http://arxiv.org/abs/2310.10035v1

原文摘要:
Large language models (LLMs) exhibited powerful capability in various natural
language processing tasks. This work focuses on exploring LLM performance on
zero-shot information extraction, with a focus on the ChatGPT and named entity
recognition (NER) task. Inspired by the remarkable reasoning capability of LLM
on symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods
to NER and propose reasoning strategies tailored for NER. First, we explore a
decomposed question-answering paradigm by breaking down the NER task into
simpler subproblems by labels. Second, we propose syntactic augmentation to
stimulate the model's intermediate thinking in two ways: syntactic prompting,
which encourages the model to analyze the syntactic structure itself, and tool
augmentation, which provides the model with the syntactic information generated
by a parsing tool. Besides, we adapt self-consistency to NER by proposing a
two-stage majority voting strategy, which first votes for the most consistent
mentions, then the most consistent types. The proposed methods achieve
remarkable improvements for zero-shot NER across seven benchmarks, including
Chinese and English datasets, and on both domain-specific and general-domain
scenarios. In addition, we present a comprehensive analysis of the error types
with suggestions for optimization directions. We also verify the effectiveness
of the proposed methods on the few-shot setting and other LLMs.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）在各类自然语言处理任务中展现出强大能力。本研究重点探索LLMs在零样本信息抽取任务中的表现，以ChatGPT和命名实体识别（NER）任务为核心研究对象。受LLMs在符号推理与算术推理方面卓越表现的启发，我们将主流推理方法适配于NER任务，并提出针对性的推理策略：首先，通过按标签分解NER任务为更简单的子问题，探索分步问答范式；其次，提出两种激发模型中间思维的句法增强方法——鼓励模型自主分析句法结构的提示法，以及为模型提供解析工具生成句法信息的工具增强法。此外，我们通过设计两阶段多数投票策略（先投票选择最一致的实体指称，再确定最一致的实体类型）将自洽性方法适配于NER任务。所提方法在涵盖中英文的七个基准测试（包括领域专用和通用领域场景）中显著提升了零样本NER性能。我们还对错误类型进行系统分析并提出优化方向建议，同时验证了该方法在少样本设置及其他LLMs上的有效性。

注：翻译严格遵循以下学术规范：
1. 专业术语统一（如"zero-shot"译为"零样本"）
2. 被动语态转换（英文被动句转为中文主动表述）
3. 长句拆分重组（保持逻辑清晰性）
4. 概念准确传达（如"self-consistency"译为"自洽性"）
5. 保留关键实验细节（如"two-stage majority voting"完整表述）
