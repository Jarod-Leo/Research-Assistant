# From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews

链接: http://arxiv.org/abs/2312.01202v1

原文摘要:
Obtaining stakeholders' diverse experiences and opinions about current policy
in a timely manner is crucial for policymakers to identify strengths and gaps
in resource allocation, thereby supporting effective policy design and
implementation. However, manually coding even moderately sized interview texts
or open-ended survey responses from stakeholders can often be labor-intensive
and time-consuming. This study explores the integration of Large Language
Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of
stakeholder interviews regarding K-12 education policy within one U.S. state.
Employing a mixed-methods approach, human experts developed a codebook and
coding processes as informed by domain knowledge and unsupervised topic
modeling results. They then designed prompts to guide GPT-4 analysis and
iteratively evaluate different prompts' performances. This combined
human-computer method enabled nuanced thematic and sentiment analysis. Results
reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at
specific themes, expanding to broader themes increased congruence to 96.02%,
surpassing traditional Natural Language Processing (NLP) methods by over 25%.
Additionally, GPT-4 is more closely matched to expert sentiment analysis than
lexicon-based methods. Findings from quantitative measures and qualitative
reviews underscore the complementary roles of human domain expertise and
automated analysis as LLMs offer new perspectives and coding consistency. The
human-computer interactive approach enhances efficiency, validity, and
interpretability of educational policy research.

中文翻译:
以下是按照您的要求翻译的中文摘要：

【译文】
及时获取利益相关者对现行政策的多元体验与意见，对于政策制定者识别资源配置的优势与不足至关重要，进而支撑有效的政策设计与实施。然而，即使对中等规模的访谈文本或利益相关者的开放式问卷反馈进行人工编码，也往往需要耗费大量人力与时间。本研究探索将GPT-4等大语言模型（LLMs）与人类专业知识相结合，以增强对美国某州K-12教育政策利益相关者访谈的文本分析。通过混合研究方法，领域专家基于专业知识和无监督主题建模结果开发了编码手册及流程，继而设计提示词引导GPT-4进行分析，并通过迭代评估优化提示词效果。这种人机协同方法实现了精细化的主题分析与情感分析。结果显示：GPT-4在具体主题上的编码与人工编码吻合度达77.89%，扩展至广义主题后吻合度提升至96.02%，较传统自然语言处理方法（NLP）提高超25%；在情感分析方面，GPT-4也比基于词典的方法更贴近专家判断。定量指标与定性评估共同表明：大语言模型能提供新颖视角并保持编码一致性，与人类领域知识形成互补。这种人机交互模式显著提升了教育政策研究的效率、效度与可解释性。

【翻译说明】
1. 专业术语处理：
- "stakeholders"译为"利益相关者"（政策研究领域标准译法）
- "codebook"译为"编码手册"（质性研究术语）
- "unsupervised topic modeling"保留"无监督主题建模"（机器学习专业术语）

2. 长句拆分与重组：
将原文复合句拆分为符合中文表达习惯的短句，如将"Employing a mixed-methods approach..."长句分解为三个逻辑连贯的短句，并添加"通过"等连接词保持连贯性。

3. 被动语态转换：
将英文被动式（如"can often be labor-intensive"）转换为中文主动表述（"往往需要耗费..."）

4. 数据呈现优化：
精确保留百分比数据（77.89%/96.02%），并添加"达""提升至"等动词增强动态感

5. 概念对等处理：
- "nuanced thematic analysis"译为"精细化主题分析"（准确传达"nuanced"的细微分析含义）
- "lexicon-based methods"译为"基于词典的方法"（NLP领域通用译法）

6. 学术风格保持：
使用"效度""可解释性"等社会科学研究术语，符合政策研究论文的学术规范
