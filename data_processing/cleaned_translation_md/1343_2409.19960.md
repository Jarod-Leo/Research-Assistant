# TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning

链接: http://arxiv.org/abs/2409.19960v1

原文摘要:
Zero-shot inference, where pre-trained models perform tasks without specific
training data, is an exciting emergent ability of large models like CLIP.
Although there has been considerable exploration into enhancing zero-shot
abilities in image captioning (IC) for popular datasets such as MSCOCO and
Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,
UCM-Captions, and Sydney-Captions. These datasets require captions to discern
between visually and semantically similar classes, focusing on detailed object
parts and their attributes. To overcome this challenge, we introduce
TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption
with additional object-part details using object detector proposals and Natural
Language Processing techniques. It complements rather than alters the base
caption, allowing seamless integration with other captioning methods and
offering users enhanced flexibility. Our evaluations show that TROPE
consistently boosts performance across all tested zero-shot IC approaches and
achieves state-of-the-art results on fine-grained IC datasets.

中文翻译:
零样本推理（即预训练模型无需特定任务训练数据即可执行任务）是CLIP等大型模型令人振奋的涌现能力。尽管学界已对提升MSCOCO、Flickr8k等流行数据集的图像描述（IC）零样本能力进行了大量探索，但这些方法在CUB、FLO、UCM-Captions和Sydney-Captions等细粒度数据集上表现欠佳。此类数据集要求描述文本能区分视觉和语义相似的类别，重点关注物体局部细节及其属性特征。为应对这一挑战，我们提出无需训练的对象局部增强框架TROPE。该框架通过目标检测提案和自然语言处理技术，在基础描述文本中补充物体局部细节信息。TROPE采用补充而非修改基础描述的方式，既可与其他描述方法无缝集成，又能为用户提供更强的灵活性。实验表明，TROPE在所有测试的零样本IC方法中均能稳定提升性能，并在细粒度IC数据集上取得了最先进的结果。

（翻译说明：
1. 专业术语处理："zero-shot inference"译为"零样本推理"符合计算机视觉领域术语规范，"emergent ability"译为"涌现能力"保留原文学术性
2. 长句拆分：将原文复合长句拆分为符合中文表达习惯的短句，如第二句拆分为两个逻辑递进的短句
3. 被动语态转换："these approaches fall short"译为主动式"这些方法表现欠佳"
4. 概念显化："object detector proposals"译为"目标检测提案"并补充"技术"二字明确技术属性
5. 动态对等："seamless integration"译为"无缝集成"既准确又符合中文技术文档表达
6. 学术风格保持：使用"框架""特征""最先进"等符合学术论文表述的词汇
7. 术语统一性：全篇保持"图像描述（IC）"的缩写标注一致性）
