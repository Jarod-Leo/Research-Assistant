# A Review of Transformer-Based Models for Computer Vision Tasks: Capturing Global Context and Spatial Relationships

链接: http://arxiv.org/abs/2408.15178v1

原文摘要:
Transformer-based models have transformed the landscape of natural language
processing (NLP) and are increasingly applied to computer vision tasks with
remarkable success. These models, renowned for their ability to capture
long-range dependencies and contextual information, offer a promising
alternative to traditional convolutional neural networks (CNNs) in computer
vision. In this review paper, we provide an extensive overview of various
transformer architectures adapted for computer vision tasks. We delve into how
these models capture global context and spatial relationships in images,
empowering them to excel in tasks such as image classification, object
detection, and segmentation. Analyzing the key components, training
methodologies, and performance metrics of transformer-based models, we
highlight their strengths, limitations, and recent advancements. Additionally,
we discuss potential research directions and applications of transformer-based
models in computer vision, offering insights into their implications for future
advancements in the field.

中文翻译:
基于Transformer的模型已经彻底改变了自然语言处理（NLP）的格局，并越来越多地成功应用于计算机视觉任务。这些模型以其捕捉长距离依赖关系和上下文信息的能力而闻名，为计算机视觉领域提供了传统卷积神经网络（CNN）之外极具前景的替代方案。本文综述了适用于计算机视觉任务的各种Transformer架构，深入探讨了这些模型如何捕捉图像中的全局上下文和空间关系，从而在图像分类、目标检测和分割等任务中表现出色。通过分析基于Transformer模型的核心组件、训练方法和性能指标，我们重点阐述了其优势、局限性以及最新进展。此外，我们还探讨了Transformer模型在计算机视觉中的潜在研究方向与应用前景，为未来该领域的发展提供了前瞻性见解。
