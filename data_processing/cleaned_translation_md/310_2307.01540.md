# Learning to Prompt in the Classroom to Understand AI Limits: A pilot study

链接: http://arxiv.org/abs/2307.01540v1

原文摘要:
Artificial intelligence's (AI) progress holds great promise in tackling
pressing societal concerns such as health and climate. Large Language Models
(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural
language processing capabilities of AI systems allowing them to process an
unprecedented amount of unstructured data. However, the ensuing excitement has
led to negative sentiments, even as AI methods demonstrate remarkable
contributions (e.g. in health and genetics). A key factor contributing to this
sentiment is the misleading perception that LLMs can effortlessly provide
solutions across domains, ignoring their limitations such as hallucinations and
reasoning constraints. Acknowledging AI fallibility is crucial to address the
impact of dogmatic overconfidence in possibly erroneous suggestions generated
by LLMs. At the same time, it can reduce fear and other negative attitudes
toward AI. This necessitates comprehensive AI literacy interventions that
educate the public about LLM constraints and effective usage techniques, i.e
prompting strategies. With this aim, a pilot educational intervention was
performed in a high school with 21 students. It involved presenting high-level
concepts about intelligence, AI, and LLMs, followed by practical exercises
involving ChatGPT in creating natural educational conversations and applying
established prompting strategies. Encouraging preliminary results emerged,
including high appreciation of the activity, improved interaction quality with
the LLM, reduced negative AI sentiments, and a better grasp of limitations,
specifically unreliability, limited understanding of commands leading to
unsatisfactory responses, and limited presentation flexibility. Our aim is to
explore AI acceptance factors and refine this approach for more controlled
future studies.

中文翻译:
人工智能（AI）的发展为解决健康与气候等紧迫社会问题带来了巨大希望。以ChatGPT为代表的大语言模型（LLM）及其衍生的聊天机器人显著提升了AI系统的自然语言处理能力，使其能够处理前所未有的非结构化数据。然而随之而来的热潮也引发了负面情绪——尽管AI技术已在健康与遗传学等领域展现出卓越贡献。这种情绪的关键诱因在于人们存在认知误区，误以为LLM能轻松提供跨领域解决方案，却忽视了其存在幻觉与推理局限等缺陷。  

承认AI的可错性至关重要：既能消解人们对LLM可能生成错误建议的盲目自信，又能缓解对AI的恐惧等负面态度。这需要通过系统的AI素养教育向公众普及LLM的局限性及使用技巧（即提示策略）。基于此目标，我们在某高中对21名学生开展了试点教学：先讲解智力、AI与LLM的核心概念，再通过ChatGPT实操训练创建自然教育对话并应用成熟提示策略。初步成果令人鼓舞：活动获得高度评价，学生与LLM的交互质量提升，对AI的负面情绪减少，并更清晰地认识到其局限性——包括回答不可靠、指令理解有限导致反馈不佳，以及呈现方式缺乏灵活性等。本研究旨在探索AI接受度的影响因素，并优化教学方法以供未来开展更严谨的实证研究。  

（翻译说明：  
1. 专业术语处理：LLM保留英文缩写但首次出现时标注全称，ChatGPT等专有名词不译  
2. 长句拆分：将原文复合句按中文表达习惯分解为短句群  
3. 概念显化："hallucinations"译为行业通用术语"幻觉"，"prompting strategies"译为"提示策略"  
4. 逻辑衔接：通过破折号、冒号等标点重构英文的从句关系  
5. 学术风格：保持"实证研究""试点教学"等学术用语，避免口语化表达）
