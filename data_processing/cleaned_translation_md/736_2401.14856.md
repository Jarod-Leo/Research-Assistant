# Memory-Inspired Temporal Prompt Interaction for Text-Image Classification

链接: http://arxiv.org/abs/2401.14856v1

原文摘要:
In recent years, large-scale pre-trained multimodal models (LMM) generally
emerge to integrate the vision and language modalities, achieving considerable
success in various natural language processing and computer vision tasks. The
growing size of LMMs, however, results in a significant computational cost for
fine-tuning these models for downstream tasks. Hence, prompt-based interaction
strategy is studied to align modalities more efficiently. In this contex, we
propose a novel prompt-based multimodal interaction strategy inspired by human
memory strategy, namely Memory-Inspired Temporal Prompt Interaction (MITP). Our
proposed method involves in two stages as in human memory strategy: the
acquiring stage, and the consolidation and activation stage. We utilize
temporal prompts on intermediate layers to imitate the acquiring stage,
leverage similarity-based prompt interaction to imitate memory consolidation,
and employ prompt generation strategy to imitate memory activation. The main
strength of our paper is that we interact the prompt vectors on intermediate
layers to leverage sufficient information exchange between modalities, with
compressed trainable parameters and memory usage. We achieve competitive
results on several datasets with relatively small memory usage and 2.0M of
trainable parameters (about 1% of the pre-trained foundation model).

中文翻译:
近年来，大规模预训练多模态模型（LMM）的兴起有效整合了视觉与语言模态，在各类自然语言处理和计算机视觉任务中取得显著成功。然而随着模型规模不断扩大，针对下游任务进行微调所需的计算成本急剧增加。为此，基于提示词（prompt）的交互策略被提出以实现更高效的模态对齐。本文受人类记忆机制启发，提出一种创新的时序提示词交互策略——记忆启发式时序提示交互（MITP）。该方法模拟人类记忆的两阶段处理过程：在获取阶段，通过在中间层植入时序提示词模拟信息获取；在巩固激活阶段，采用基于相似度的提示词交互实现记忆巩固，并通过提示词生成策略模拟记忆激活。本研究的核心优势在于：通过在中间层进行提示词向量交互，既能实现模态间充分的信息交换，又可大幅压缩可训练参数量和内存占用。实验表明，在仅使用2.0M可训练参数（约为预训练基础模型的1%）和较小内存占用的条件下，该方法在多个数据集上取得了具有竞争力的性能表现。
