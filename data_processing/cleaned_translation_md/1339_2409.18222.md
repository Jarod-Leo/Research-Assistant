# Trustworthy AI: Securing Sensitive Data in Large Language Models

链接: http://arxiv.org/abs/2409.18222v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing
(NLP) by enabling robust text generation and understanding. However, their
deployment in sensitive domains like healthcare, finance, and legal services
raises critical concerns about privacy and data security. This paper proposes a
comprehensive framework for embedding trust mechanisms into LLMs to dynamically
control the disclosure of sensitive information. The framework integrates three
core components: User Trust Profiling, Information Sensitivity Detection, and
Adaptive Output Control. By leveraging techniques such as Role-Based Access
Control (RBAC), Attribute-Based Access Control (ABAC), Named Entity Recognition
(NER), contextual analysis, and privacy-preserving methods like differential
privacy, the system ensures that sensitive information is disclosed
appropriately based on the user's trust level. By focusing on balancing data
utility and privacy, the proposed solution offers a novel approach to securely
deploying LLMs in high-risk environments. Future work will focus on testing
this framework across various domains to evaluate its effectiveness in managing
sensitive data while maintaining system efficiency.

中文翻译:
大型语言模型（LLMs）通过实现强大的文本生成与理解能力，彻底改变了自然语言处理（NLP）领域。然而，当这类模型部署于医疗、金融和法律服务等敏感领域时，隐私与数据安全问题便成为关键挑战。本文提出一个综合性框架，通过嵌入信任机制实现LLMs敏感信息的动态披露控制。该框架整合三大核心组件：用户信任画像、信息敏感度检测和自适应输出控制。通过采用基于角色的访问控制（RBAC）、基于属性的访问控制（ABAC）、命名实体识别（NER）、上下文分析等技术，并结合差分隐私等隐私保护方法，系统能根据用户信任等级恰当地披露敏感信息。该方案聚焦数据效用与隐私保护的平衡，为高风险环境中安全部署LLMs提供了创新思路。未来工作将重点测试该框架在跨领域场景中的表现，以评估其在维护系统效率的同时管理敏感数据的实际效果。

（翻译说明：采用技术文档专业用语风格，保持术语一致性；将英文长句合理切分为符合中文表达习惯的短句；"dynamic control"译为"动态控制"体现技术特性；"trust level"译为"信任等级"符合行业表述；通过"便成为"等连接词增强逻辑衔接；"novel approach"译为"创新思路"既准确又符合中文科技论文表达习惯。）
