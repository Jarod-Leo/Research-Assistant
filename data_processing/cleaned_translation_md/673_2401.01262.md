# Fairness Certification for Natural Language Processing and Large Language Models

链接: http://arxiv.org/abs/2401.01262v1

原文摘要:
Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization.

中文翻译:
自然语言处理（NLP）在我们的日常生活中扮演着重要角色，尤其是随着大语言模型（LLM）的迅猛发展。然而，NLP涉及诸多对公平性要求严苛的应用场景，例如作为招聘领域的专家系统，或教育领域中基于LLM的智能辅导系统。由于NLP建立在人类语言基础之上，潜在的有害偏见可能渗入NLP系统，导致不公正的结果、对少数群体的歧视，甚至引发法律问题。因此，建立针对NLP方法的公平性认证体系至关重要。

本研究采用定性研究方法探索NLP公平性认证路径。具体而言，我们系统梳理了大量算法公平性领域的文献，并与该领域多位专家进行了半结构化访谈。通过系统化分析，我们提出了适用于NLP的六大公平性准则，这些准则可进一步细分为18个子类别。我们的研究为公平性认证的操作化实施和测试流程奠定了基础，既为审计方也为受审机构提供了系统性框架。
