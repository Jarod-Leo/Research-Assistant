# Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey

链接: http://arxiv.org/abs/2403.09606v1

原文摘要:
Causal inference has shown potential in enhancing the predictive accuracy,
fairness, robustness, and explainability of Natural Language Processing (NLP)
models by capturing causal relationships among variables. The emergence of
generative Large Language Models (LLMs) has significantly impacted various NLP
domains, particularly through their advanced reasoning capabilities. This
survey focuses on evaluating and improving LLMs from a causal view in the
following areas: understanding and improving the LLMs' reasoning capacity,
addressing fairness and safety issues in LLMs, complementing LLMs with
explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning
capacities can in turn contribute to the field of causal inference by aiding
causal relationship discovery and causal effect estimations. This review
explores the interplay between causal inference frameworks and LLMs from both
perspectives, emphasizing their collective potential to further the development
of more advanced and equitable artificial intelligence systems.

中文翻译:
因果推断通过捕捉变量间的因果关系，在提升自然语言处理（NLP）模型的预测准确性、公平性、鲁棒性和可解释性方面展现出巨大潜力。随着生成式大语言模型（LLMs）的崛起，其强大的推理能力正深刻影响着NLP的各个领域。本综述从因果视角出发，重点探讨以下方向对LLMs的评估与改进：理解与增强LLMs的推理能力、解决模型公平性与安全问题、为LLMs生成解释补足、以及多模态处理。与此同时，LLMs卓越的推理能力也能反哺因果推断领域，辅助因果关系发现与因果效应估计。本文通过双向视角系统梳理因果推断框架与LLMs的相互作用，强调二者协同推动更先进、更公平人工智能系统发展的集体潜力。

（翻译说明：采用学术文本的简洁句式结构，保留"causal inference/LLMs"等专业术语的规范译法；将长复合句拆分为符合中文表达习惯的短句；"reasoning capacity"译为"推理能力"保持概念一致性；"multimodality"采用领域通用译法"多模态"；通过"反哺""协同"等词汇准确传达双向促进的学术内涵；最后"collective potential"译为"集体潜力"突出合作价值）
