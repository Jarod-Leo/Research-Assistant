# Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey

链接: http://arxiv.org/abs/2504.14891v1

原文摘要:
Recent advancements in Retrieval-Augmented Generation (RAG) have
revolutionized natural language processing by integrating Large Language Models
(LLMs) with external information retrieval, enabling accurate, up-to-date, and
verifiable text generation across diverse applications. However, evaluating RAG
systems presents unique challenges due to their hybrid architecture that
combines retrieval and generation components, as well as their dependence on
dynamic knowledge sources in the LLM era. In response, this paper provides a
comprehensive survey of RAG evaluation methods and frameworks, systematically
reviewing traditional and emerging evaluation approaches, for system
performance, factual accuracy, safety, and computational efficiency in the LLM
era. We also compile and categorize the RAG-specific datasets and evaluation
frameworks, conducting a meta-analysis of evaluation practices in high-impact
RAG research. To the best of our knowledge, this work represents the most
comprehensive survey for RAG evaluation, bridging traditional and LLM-driven
methods, and serves as a critical resource for advancing RAG development.

中文翻译:
近年来，检索增强生成（Retrieval-Augmented Generation, RAG）技术通过将大语言模型（LLMs）与外部信息检索系统相结合，实现了跨领域应用中准确、即时且可验证的文本生成，彻底革新了自然语言处理领域。然而，由于RAG系统融合了检索与生成组件的混合架构，以及其对LLM时代动态知识源的依赖性，其评估工作面临独特挑战。为此，本文对RAG评估方法与框架进行全面综述，系统梳理了传统与新兴评估方法，涵盖LLM时代下系统性能、事实准确性、安全性和计算效率等维度。我们同时汇编并分类了RAG专用数据集与评估框架，对高影响力RAG研究中的评估实践开展元分析。据我们所知，本研究首次构建了贯通传统方法与LLM驱动技术的RAG评估全景图谱，为推进RAG技术发展提供了关键资源。
