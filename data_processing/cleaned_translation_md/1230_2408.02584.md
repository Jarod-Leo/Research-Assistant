# Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization

链接: http://arxiv.org/abs/2408.02584v1

原文摘要:
The ever-increasing volume of digital information necessitates efficient
methods for users to extract key insights from lengthy documents. Aspect-based
summarization offers a targeted approach, generating summaries focused on
specific aspects within a document. Despite advancements in aspect-based
summarization research, there is a continuous quest for improved model
performance. Given that large language models (LLMs) have demonstrated the
potential to revolutionize diverse tasks within natural language processing,
particularly in the problem of summarization, this paper explores the potential
of fine-tuning LLMs for the aspect-based summarization task. We evaluate the
impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,
Gemma and Aya, on a publicly available domain-specific aspect based summary
dataset. We hypothesize that this approach will enable these models to
effectively identify and extract aspect-related information, leading to
superior quality aspect-based summaries compared to the state-of-the-art. We
establish a comprehensive evaluation framework to compare the performance of
fine-tuned LLMs against competing aspect-based summarization methods and
vanilla counterparts of the fine-tuned LLMs. Our work contributes to the field
of aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs
for generating high-quality aspect-based summaries. Furthermore, it opens doors
for further exploration of using LLMs for targeted information extraction tasks
across various NLP domains.

中文翻译:
随着数字信息量的持续激增，用户亟需高效方法从冗长文档中提取关键信息。基于方面的摘要技术提供了一种针对性解决方案，能够生成聚焦文档特定方面的摘要内容。尽管该领域研究已取得进展，但学界仍在不断探索提升模型性能的途径。鉴于大语言模型（LLM）已展现出革新自然语言处理各项任务的潜力（尤其在摘要生成领域），本文探究了微调LLM用于基于方面的摘要任务的可行性。我们在公开的领域专用方面摘要数据集上，系统评估了微调开源基础LLM（包括Llama2、Mistral、Gemma和Aya）的效果。我们假设该方法能使模型有效识别并提取方面相关信息，从而生成质量优于当前最优技术的方面摘要。通过建立综合评估框架，我们将微调后的LLM与现有基于方面的摘要方法及原始LLM进行性能对比。本研究证实了微调LLM在生成高质量方面摘要方面的有效性，为基于方面的摘要研究领域作出贡献，同时为探索LLM在各种NLP领域中执行定向信息抽取任务开辟了新路径。
