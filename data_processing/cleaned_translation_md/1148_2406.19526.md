# TocBERT: Medical Document Structure Extraction Using Bidirectional Transformers

链接: http://arxiv.org/abs/2406.19526v1

原文摘要:
Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.

中文翻译:
文本分割在自然语言处理（NLP）领域具有至关重要的意义。它在信息检索、文档摘要等多个NLP下游任务中发挥着重要作用。本研究提出了一种基于双向Transformer的新型文本分割解决方案TocBERT。该方案通过监督式学习从语义表征中检测标题与子标题，并将该任务构建为命名实体识别（NER）问题。我们在医学文本分割场景中应用了这一方案，通过微调Bio-ClinicalBERT模型对MIMIC-III数据集中的出院小结进行分割。基于250份人工标注的真实病历语料库的评估显示：TocBERT在线性文本分割任务中取得84.6%的F1值，在层级文本分割任务中达到72.8%的F1值。相较于精心设计的基于规则的解决方案，该模型在区分主标题与子标题方面表现尤为突出。
