# Transformers in Reinforcement Learning: A Survey

链接: http://arxiv.org/abs/2307.05979v1

原文摘要:
Transformers have significantly impacted domains like natural language
processing, computer vision, and robotics, where they improve performance
compared to other neural networks. This survey explores how transformers are
used in reinforcement learning (RL), where they are seen as a promising
solution for addressing challenges such as unstable training, credit
assignment, lack of interpretability, and partial observability. We begin by
providing a brief domain overview of RL, followed by a discussion on the
challenges of classical RL algorithms. Next, we delve into the properties of
the transformer and its variants and discuss the characteristics that make them
well-suited to address the challenges inherent in RL. We examine the
application of transformers to various aspects of RL, including representation
learning, transition and reward function modeling, and policy optimization. We
also discuss recent research that aims to enhance the interpretability and
efficiency of transformers in RL, using visualization techniques and efficient
training strategies. Often, the transformer architecture must be tailored to
the specific needs of a given application. We present a broad overview of how
transformers have been adapted for several applications, including robotics,
medicine, language modeling, cloud computing, and combinatorial optimization.
We conclude by discussing the limitations of using transformers in RL and
assess their potential for catalyzing future breakthroughs in this field.

中文翻译:
以下是符合您要求的中文翻译：

Transformer模型已显著影响了自然语言处理、计算机视觉和机器人技术等领域，在这些领域中其性能表现优于其他神经网络。本文综述探讨了Transformer在强化学习（RL）中的应用——它被视为解决训练不稳定、信用分配、可解释性缺失和部分可观测性等挑战的潜在解决方案。我们首先概述强化学习领域，继而讨论传统RL算法面临的挑战；随后深入分析Transformer及其变体的特性，阐释其特别适合应对RL固有挑战的特质；系统考察Transformer在RL各环节的应用，包括表征学习、状态转移与奖励函数建模、策略优化等；同时探讨了通过可视化技术和高效训练策略来增强Transformer可解释性与效率的最新研究。针对不同应用场景的需求，Transformer架构往往需要专门调整，我们全面综述了其在机器人、医疗、语言建模、云计算和组合优化等领域的适配应用。最后，我们讨论了Transformer在RL中的局限性，并评估其推动该领域未来突破的潜力。

（译文严格遵循学术规范，采用专业术语统一原则：如"credit assignment"译为"信用分配"、"partial observability"译为"部分可观测性"等。通过拆分英语长句为中文短句结构（如将定语从句转换为分句），并运用"其"等代词保持指代清晰。被动语态转换为主动表述（如"are seen as"译为"被视为"），同时保留"我们"作为综述主体的学术表达习惯。关键概念首次出现时保留英文缩写"RL"并在括号内标注中文全称，符合中文论文写作惯例。）
