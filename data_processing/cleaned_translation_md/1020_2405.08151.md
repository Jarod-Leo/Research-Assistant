# Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness

链接: http://arxiv.org/abs/2405.08151v1

原文摘要:
Large language models (LLM) have demonstrated remarkable capabilities in
various biomedical natural language processing (NLP) tasks, leveraging the
demonstration within the input context to adapt to new tasks. However, LLM is
sensitive to the selection of demonstrations. To address the hallucination
issue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by
retrieving pertinent information from an established database. Nonetheless,
existing research work lacks rigorous evaluation of the impact of
retrieval-augmented large language models on different biomedical NLP tasks.
This deficiency makes it challenging to ascertain the capabilities of RAL
within the biomedical domain. Moreover, the outputs from RAL are affected by
retrieving the unlabeled, counterfactual, or diverse knowledge that is not well
studied in the biomedical domain. However, such knowledge is common in the real
world. Finally, exploring the self-awareness ability is also crucial for the
RAL system. So, in this paper, we systematically investigate the impact of RALs
on 5 different biomedical tasks (triple extraction, link prediction,
classification, question answering, and natural language inference). We analyze
the performance of RALs in four fundamental abilities, including unlabeled
robustness, counterfactual robustness, diverse robustness, and negative
awareness. To this end, we proposed an evaluation framework to assess the RALs'
performance on different biomedical NLP tasks and establish four different
testbeds based on the aforementioned fundamental abilities. Then, we evaluate 3
representative LLMs with 3 different retrievers on 5 tasks over 9 datasets.

中文翻译:
以下是符合您要求的学术中文翻译：

大型语言模型（LLM）在生物医学自然语言处理（NLP）任务中展现出卓越能力，通过输入上下文中的示例演示来适应新任务。然而，LLM对演示样本的选择具有敏感性。针对LLM固有的幻觉问题，检索增强型语言模型（RAL）通过从既定数据库中检索相关信息提供了解决方案。但现有研究工作缺乏对检索增强型大模型在不同生物医学NLP任务中影响的系统评估，导致难以准确界定RAL在生物医学领域的能力边界。

值得注意的是，RAL的输出会受到以下未充分研究的检索内容影响：未标注知识、反事实知识以及多样性知识——这些在生物医学领域尚未得到充分探索，却在现实世界中普遍存在。此外，探究RAL系统的自我认知能力也至关重要。为此，本文系统研究了RAL在五种生物医学任务（三元组抽取、链接预测、分类、问答和自然语言推理）中的表现，重点分析了四种核心能力：未标注知识鲁棒性、反事实知识鲁棒性、多样性知识鲁棒性以及负样本感知能力。

我们提出了一个评估框架来量化RAL在不同生物医学NLP任务中的表现，并基于上述核心能力构建了四个测试基准。实验部分对3个代表性LLM模型结合3种检索器，在9个数据集的5类任务上进行了全面评估。


