# On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis

链接: http://arxiv.org/abs/2304.03347v1

原文摘要:
The latest large language models (LLMs) such as ChatGPT, exhibit strong
capabilities in automated mental health analysis. However, existing relevant
studies bear several limitations, including inadequate evaluations, lack of
prompting strategies, and ignorance of exploring LLMs for explainability. To
bridge these gaps, we comprehensively evaluate the mental health analysis and
emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore
the effects of different prompting strategies with unsupervised and distantly
supervised emotional information. Based on these prompts, we explore LLMs for
interpretable mental health analysis by instructing them to generate
explanations for each of their decisions. We convey strict human evaluations to
assess the quality of the generated explanations, leading to a novel dataset
with 163 human-assessed explanations. We benchmark existing automatic
evaluation metrics on this dataset to guide future related works. According to
the results, ChatGPT shows strong in-context learning ability but still has a
significant gap with advanced task-specific methods. Careful prompt engineering
with emotional cues and expert-written few-shot examples can also effectively
improve performance on mental health analysis. In addition, ChatGPT generates
explanations that approach human performance, showing its great potential in
explainable mental health analysis.

中文翻译:
最新的大型语言模型（如ChatGPT）在自动化心理健康分析方面展现出强大能力。然而现有相关研究存在若干局限，包括评估不足、缺乏提示策略设计，以及忽视探索模型的可解释性。为弥补这些不足，我们在涵盖5类任务的11个数据集上全面评估了大型语言模型的心理健康分析与情绪推理能力。通过无监督和远程监督的情绪信息，我们系统探索了不同提示策略的影响。基于这些提示策略，我们通过指令要求模型为每个决策生成解释，从而探索可解释的心理健康分析方法。我们实施了严格的人工评估来衡量生成解释的质量，由此构建了一个包含163条人工评注解释的新型数据集，并在此数据集上对现有自动评估指标进行基准测试以指导未来研究。实验结果表明：ChatGPT展现出强大的上下文学习能力，但与先进的任务专用方法仍存在显著差距；结合情绪线索的精细提示工程与专家撰写的少样本示例能有效提升心理健康分析性能；此外，ChatGPT生成的解释接近人类水平，展现出其在可解释心理健康分析领域的巨大潜力。
