# Zero-shot LLM-guided Counterfactual Generation for Text

链接: http://arxiv.org/abs/2405.04793v1

原文摘要:
With the development and proliferation of large, complex, black-box models
for solving many natural language processing (NLP) tasks, there is also an
increasing necessity of methods to stress-test these models and provide some
degree of interpretability or explainability. While counterfactual examples are
useful in this regard, automated generation of counterfactuals is a data and
resource intensive process. such methods depend on models such as pre-trained
language models that are then fine-tuned on auxiliary, often task-specific
datasets, that may be infeasible to build in practice, especially for new tasks
and data domains. Therefore, in this work we explore the possibility of
leveraging large language models (LLMs) for zero-shot counterfactual generation
in order to stress-test NLP models. We propose a structured pipeline to
facilitate this generation, and we hypothesize that the instruction-following
and textual understanding capabilities of recent LLMs can be effectively
leveraged for generating high quality counterfactuals in a zero-shot manner,
without requiring any training or fine-tuning. Through comprehensive
experiments on a variety of propreitary and open-source LLMs, along with
various downstream tasks in NLP, we explore the efficacy of LLMs as zero-shot
counterfactual generators in evaluating and explaining black-box NLP models.

中文翻译:
随着用于解决众多自然语言处理（NLP）任务的大型复杂黑盒模型的发展与普及，对这类模型进行压力测试并提供一定程度的可解释性方法的需求也日益增长。反事实样本虽能有效满足这一需求，但其自动化生成却是数据与资源密集型的过程。现有方法通常依赖于预训练语言模型，并需在辅助性（常为任务特定）数据集上进行微调，而此类数据集在实际中（尤其对于新任务和数据领域）往往难以构建。为此，本研究探索利用大语言模型（LLM）进行零样本反事实生成以压力测试NLP模型的可行性。我们提出结构化生成流程，并假设近期LLM的指令遵循与文本理解能力可被有效用于零样本方式生成高质量反事实样本，且无需任何训练或微调。通过对多种专有及开源LLM的全面实验，结合NLP领域各类下游任务，我们系统探究了LLM作为零样本反事实生成器在评估和解释黑盒NLP模型方面的效能。

（翻译说明：采用学术论文摘要的简洁风格，通过拆分英文长句为中文短句结构；专业术语如"zero-shot"统一译为"零样本"；将被动语态转换为主动表述；"propreitary and open-source"译为"专有及开源"以保持术语准确性；通过"为此""假设""探究"等逻辑连接词保持论证连贯性；最后一句采用"效能"而非"效果"以体现学术严谨性。）
