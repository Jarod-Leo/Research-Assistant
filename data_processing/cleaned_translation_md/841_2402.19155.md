# Beyond Language Models: Byte Models are Digital World Simulators

链接: http://arxiv.org/abs/2402.19155v1

原文摘要:
Traditional deep learning often overlooks bytes, the basic units of the
digital world, where all forms of information and operations are encoded and
manipulated in binary format. Inspired by the success of next token prediction
in natural language processing, we introduce bGPT, a model with next byte
prediction to simulate the digital world. bGPT matches specialized models in
performance across various modalities, including text, audio, and images, and
offers new possibilities for predicting, simulating, and diagnosing algorithm
or hardware behaviour. It has almost flawlessly replicated the process of
converting symbolic music data, achieving a low error rate of 0.0011 bits per
byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates
exceptional capabilities in simulating CPU behaviour, with an accuracy
exceeding 99.99% in executing various operations. Leveraging next byte
prediction, models like bGPT can directly learn from vast binary data,
effectively simulating the intricate patterns of the digital world.

中文翻译:
传统深度学习往往忽视了字节这一数字世界的基本单元——所有形式的信息与操作皆以二进制格式编码与处理。受自然语言处理中"下一词元预测"成功的启发，我们提出了bGPT模型，通过"下一字节预测"来模拟数字世界。bGPT在文本、音频、图像等多种模态任务中表现媲美专用模型，并为预测、模拟和诊断算法或硬件行为开辟了新途径。该模型近乎完美地复现了符号音乐数据的转换过程，在将ABC记谱法转换为MIDI格式时实现了每字节0.0011比特的超低错误率。此外，bGPT在模拟CPU行为方面展现出非凡能力，执行各类操作时的准确率超过99.99%。借助下一字节预测，bGPT类模型能够直接从海量二进制数据中学习，有效模拟数字世界的复杂规律。

（翻译说明：1. 专业术语如"next token prediction"译为行业通用表述"下一词元预测"；2. 技术指标"0.0011 bits per byte"采用中文科技文献惯用单位"每字节0.0011比特"；3. 长句拆分符合中文多用短句的特点，如将原文复合句拆分为三个分句；4. 被动语态转换为主动表述，如"are encoded and manipulated"译为"皆以...编码与处理"；5. 关键概念"digital world"保持"数字世界"统一译法；6. 技术名称"ABC notation"保留专业术语"ABC记谱法"的规范译名）
