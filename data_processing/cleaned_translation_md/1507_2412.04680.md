# Superpixel Tokenization for Vision Transformers: Preserving Semantic Integrity in Visual Tokens

链接: http://arxiv.org/abs/2412.04680v1

原文摘要:
Transformers, a groundbreaking architecture proposed for Natural Language
Processing (NLP), have also achieved remarkable success in Computer Vision. A
cornerstone of their success lies in the attention mechanism, which models
relationships among tokens. While the tokenization process in NLP inherently
ensures that a single token does not contain multiple semantics, the
tokenization of Vision Transformer (ViT) utilizes tokens from uniformly
partitioned square image patches, which may result in an arbitrary mixing of
visual concepts in a token. In this work, we propose to substitute the
grid-based tokenization in ViT with superpixel tokenization, which employs
superpixels to generate a token that encapsulates a sole visual concept.
Unfortunately, the diverse shapes, sizes, and locations of superpixels make
integrating superpixels into ViT tokenization rather challenging. Our
tokenization pipeline, comprised of pre-aggregate extraction and
superpixel-aware aggregation, overcomes the challenges that arise in superpixel
tokenization. Extensive experiments demonstrate that our approach, which
exhibits strong compatibility with existing frameworks, enhances the accuracy
and robustness of ViT on various downstream tasks.

中文翻译:
以下是符合学术规范的译文：

Transformer作为一种突破性的自然语言处理架构，在计算机视觉领域也取得了显著成功。其核心在于注意力机制能够建模语义单元间的关联关系。在自然语言处理中，文本的切分过程天然保证了单个语义单元（token）不会包含多重含义；而视觉Transformer（ViT）采用的均匀划分方形图像块切分方式，可能导致单个语义单元混杂多个视觉概念。本研究提出用超像素切分替代ViT原有的网格切分，通过超像素生成仅包含单一视觉概念的语义单元。然而，超像素在形状、尺寸和空间位置上的高度差异性，为其融入ViT切分机制带来了显著挑战。我们设计的切分流程包含预聚合特征提取和超像素感知聚合两个阶段，有效解决了超像素切分中的技术难题。大量实验表明，该方法与现有框架具有强兼容性，能显著提升ViT在多种下游任务中的准确性与鲁棒性。

注：译文特点说明：
1. 专业术语处理："token"译为"语义单元"并保留英文标注，兼顾专业性与可读性
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句（如第二句）
3. 被动语态转换：将英文被动式转为中文主动式（如"are comprised of"译为"包含"）
4. 概念一致性：保持"superpixel"统一译为"超像素"，"downstream tasks"译为"下游任务"等术语统一
5. 学术风格：使用"显著成功""技术难题""鲁棒性"等符合学术论文表达的词汇
