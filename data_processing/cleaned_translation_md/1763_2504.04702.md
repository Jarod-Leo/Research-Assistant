# Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent

链接: http://arxiv.org/abs/2504.04702v1

原文摘要:
Recent advancements in Transformer-based architectures have led to impressive
breakthroughs in natural language processing tasks, with models such as GPT-4,
Claude, and Gemini demonstrating human-level reasoning abilities. However,
despite their high performance, concerns remain about the inherent limitations
of these models, especially when it comes to learning basic logical functions.
While complexity-theoretic analyses indicate that Transformers can represent
simple logic functions (e.g., $\mathsf{AND}$, $\mathsf{OR}$, and majority
gates) by its nature of belonging to the $\mathsf{TC}^0$ class, these results
assume ideal parameter settings and do not account for the constraints imposed
by gradient descent-based training methods. In this work, we investigate
whether Transformers can truly learn simple majority functions when trained
using gradient-based methods. We focus on a simplified variant of the
Transformer architecture and consider both $n=\mathrm{poly}(d)$ and
$n=\exp(\Omega(d))$ number of training samples, where each sample is a $d$-size
binary string paired with the output of a basic majority function. Our analysis
demonstrates that even after $\mathrm{poly}(d)$ gradient queries, the
generalization error of the Transformer model still remains substantially
large, growing exponentially with $d$. This work highlights fundamental
optimization challenges in training Transformers for the simplest logical
reasoning tasks and provides new insights into their theoretical limitations.

中文翻译:
近年来，基于Transformer架构的模型在自然语言处理任务中取得突破性进展，GPT-4、Claude和Gemini等模型已展现出类人推理能力。然而，尽管这些模型性能卓越，其学习基础逻辑函数的内在局限性仍引发担忧。虽然复杂度理论分析表明Transformer本质上属于$\mathsf{TC}^0$类，能够表示与门（$\mathsf{AND}$）、或门（$\mathsf{OR}$）和多数表决门等基本逻辑函数，但这些结论建立在理想参数设定基础上，未考虑基于梯度下降的训练方法带来的约束。

本研究通过梯度下降方法探究Transformer是否真正能学会简单的多数表决函数。我们采用简化版Transformer架构，分别考察训练样本量$n=\mathrm{poly}(d)$和$n=\exp(\Omega(d))$两种情况，其中每个样本均为$d$维二元字符串及其对应多数表决函数输出。分析表明：即使经过$\mathrm{poly}(d)$次梯度查询，Transformer模型的泛化误差仍保持显著高位，且随$d$呈指数级增长。这项工作揭示了Transformer在最基础逻辑推理任务训练中存在的根本性优化难题，为其理论局限性提供了新的认知视角。


