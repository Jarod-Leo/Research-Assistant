# Exploring Prompting Large Language Models as Explainable Metrics

链接: http://arxiv.org/abs/2311.11552v1

原文摘要:
This paper describes the IUST NLP Lab submission to the Prompting Large
Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023
Workshop on Evaluation & Comparison of NLP Systems. We have proposed a
zero-shot prompt-based strategy for explainable evaluation of the summarization
task using Large Language Models (LLMs). The conducted experiments demonstrate
the promising potential of LLMs as evaluation metrics in Natural Language
Processing (NLP), particularly in the field of summarization. Both few-shot and
zero-shot approaches are employed in these experiments. The performance of our
best provided prompts achieved a Kendall correlation of 0.477 with human
evaluations in the text summarization task on the test data. Code and results
are publicly available on GitHub.

中文翻译:
本文介绍了伊朗科技大学自然语言处理实验室（IUST NLP Lab）为Eval4NLP 2023研讨会"自然语言处理系统评估与比较"中"基于提示的大语言模型可解释性度量"共享任务提交的研究成果。我们提出了一种基于零样本提示策略的方法，利用大语言模型（LLMs）实现文本摘要任务的可解释性评估。实验结果表明，大语言模型在自然语言处理（NLP）领域、特别是文本摘要任务中作为评估指标具有显著潜力。研究采用了少量样本和零样本两种实验方法。在测试数据的文本摘要任务中，我们提供的最佳提示方案与人工评估结果的肯德尔相关系数达到0.477。相关代码与实验结果已在GitHub平台开源。
