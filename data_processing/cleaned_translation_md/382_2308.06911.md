# GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text

链接: http://arxiv.org/abs/2308.06911v1

原文摘要:
Large language models have made significant strides in natural language
processing, enabling innovative applications in molecular science by processing
textual representations of molecules. However, most existing language models
cannot capture the rich information with complex molecular structures or
images. In this paper, we introduce GIT-Mol, a multi-modal large language model
that integrates the Graph, Image, and Text information. To facilitate the
integration of multi-modal molecular data, we propose GIT-Former, a novel
architecture that is capable of aligning all modalities into a unified latent
space. We achieve a 5%-10% accuracy increase in properties prediction and a
20.2% boost in molecule generation validity compared to the baselines. With the
any-to-language molecular translation strategy, our model has the potential to
perform more downstream tasks, such as compound name recognition and chemical
reaction prediction.

中文翻译:
以下是符合要求的学术化中文翻译：

大语言模型在自然语言处理领域取得重大突破，通过处理分子文本表征推动了分子科学领域的创新应用。然而，现有大多数语言模型难以捕捉具有复杂分子结构或图像所蕴含的丰富信息。本文提出GIT-Mol多模态大语言模型，实现图结构、图像与文本信息的有机整合。为促进多模态分子数据融合，我们创新性地设计GIT-Former架构，能够将所有模态对齐到统一潜在空间。相较于基线模型，我们在性质预测任务中实现5%-10%的准确率提升，分子生成有效性提高20.2%。借助"任意模态到语言"的分子翻译策略，本模型具备执行更多下游任务的潜力，包括化合物命名识别与化学反应预测等。

（翻译严格遵循以下原则：
1. 专业术语准确统一："latent space"译为"潜在空间"、"validity"译为"有效性"
2. 被动语态转化："are processed"转为主动式"处理"
3. 长句拆分重组：将原文复合句按中文表达习惯分解为多个短句
4. 学术用语规范："baselines"译为"基线模型"而非"基准线"
5. 概念准确传达："any-to-language"意译为"任意模态到语言"以保持专业性与可读性平衡）
