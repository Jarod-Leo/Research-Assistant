# Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together

链接: http://arxiv.org/abs/2407.10930v1

原文摘要:
Natural Language Processing (NLP) systems are increasingly taking the form of
sophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),
where each module may involve a distinct Language Model (LM) and an associated
prompt template. These compound systems often lack intermediate labels or
gradient flow to optimize each module, making their end-to-end optimization
challenging. Here we seek strategies to optimize both the module-level LM
weights and the associated prompt templates of such systems to maximize a
downstream task metric. We propose for the first time combining the weight and
prompt optimization strategies to optimize a modular LM pipeline by alternating
between the two to get the same LM to teach itself. In experiments with
multi-hop QA, mathematical reasoning, and feature-based classification using
mistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies
optimizing the weights and prompts of a pipeline together outperform directly
optimizing weights alone and prompts alone by up to 60% and 6%, respectively,
on average across LMs and tasks. BetterTogether optimizer is released in DSPy
at http://dspy.ai

中文翻译:
自然语言处理（NLP）系统正日益发展为复杂的模块化流程（例如检索增强生成RAG架构），其中每个模块可能包含独立的大语言模型（LM）及对应的提示模板。这类复合系统通常缺乏中间标签或梯度流来优化各模块，导致端到端优化面临挑战。本文研究如何通过优化模块级LM权重与关联提示模板来最大化下游任务指标，首次提出将权重优化与提示优化策略相结合：通过交替执行两种优化方式，使同一语言模型实现自我教学。在多跳问答、数学推理和基于特征的分类任务实验中（使用mistral-7b、llama-2-7b和llama-3-8b模型），这种协同优化策略（BetterTogether）在权重与提示模板联合优化时，平均表现分别比单独优化权重和单独优化提示模板最高提升60%和6%（跨模型与任务平均值）。BetterTogether优化器已在DSPy开源（http://dspy.ai）。
