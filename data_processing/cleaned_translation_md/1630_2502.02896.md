# A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs

链接: http://arxiv.org/abs/2502.02896v1

原文摘要:
Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

中文翻译:
在评估大语言模型（LLMs）执行事实抽取等任务以支持知识图谱构建时，通常需要基于知识图谱（KG）的基准真值计算准确度指标。这类评估默认所有错误均源于事实性分歧。然而人类话语中普遍存在元语言分歧——参与者对表述事实的语言含义存在分歧，而非事实本身。鉴于LLMs进行自然语言处理与生成的复杂性，我们提出核心问题：LLMs与KGs之间是否也存在元语言分歧？基于对T-REx知识对齐数据集的实验研究，我们假设LLMs与KGs之间确实存在元语言分歧，这一现象可能对知识图谱工程实践具有重要影响。我们提出了一套评估LLMs与KGs间事实性与元语言分歧检测的基准框架，相关概念验证已在Github平台开源。  

（翻译说明：  
1. 专业术语统一处理："metalinguistic disagreement"译为"元语言分歧"保持学术规范性  
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将"Given the complexity..."独立成句  
3. 被动语态转化："are assumed"等被动结构转换为中文主动表达  
4. 概念显化："ground truth benchmark"译为"基准真值"而非字面直译  
5. 逻辑连接显性化：通过破折号、冒号等标点强化论证逻辑链  
6. 技术名词保留：LLMs/KGs等缩写首次出现时保留英文原称+中文全称）
