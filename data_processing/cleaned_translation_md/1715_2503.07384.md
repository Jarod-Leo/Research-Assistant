# Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs

链接: http://arxiv.org/abs/2503.07384v1

原文摘要:
This work adapts and studies the gradient-based Membership Inference Test
(gMINT) to the classification of text based on LLMs. MINT is a general approach
intended to determine if given data was used for training machine learning
models, and this work focuses on its application to the domain of Natural
Language Processing. Using gradient-based analysis, the MINT model identifies
whether particular data samples were included during the language model
training phase, addressing growing concerns about data privacy in machine
learning. The method was evaluated in seven Transformer-based models and six
datasets comprising over 2.5 million sentences, focusing on text classification
tasks. Experimental results demonstrate MINTs robustness, achieving AUC scores
between 85% and 99%, depending on data size and model architecture. These
findings highlight MINTs potential as a scalable and reliable tool for auditing
machine learning models, ensuring transparency, safeguarding sensitive data,
and fostering ethical compliance in the deployment of AI/NLP technologies.

中文翻译:
本研究对基于梯度的成员推断测试（gMINT）进行改进，并将其应用于基于大语言模型（LLMs）的文本分类领域。MINT是一种通用方法，旨在判定特定数据是否被用于机器学习模型训练，本工作重点研究其在自然语言处理领域的应用。通过梯度分析技术，MINT模型能够识别特定数据样本是否参与过语言模型的训练过程，这对解决机器学习中日益增长的数据隐私问题具有重要意义。

该方法在七个基于Transformer架构的模型和六个包含逾250万语句的数据集上进行了评估，主要针对文本分类任务。实验结果表明MINT具有强鲁棒性，根据数据规模和模型架构的不同，其曲线下面积（AUC）得分介于85%至99%之间。这些发现凸显了MINT作为可扩展、可靠模型审计工具的潜力，能够确保人工智能/自然语言处理技术部署过程中的透明度，有效保护敏感数据，并促进伦理合规性。
