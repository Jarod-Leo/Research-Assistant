# Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support

链接: http://arxiv.org/abs/2405.09300v1

原文摘要:
Background: Rapid advancements in natural language processing have led to the
development of large language models with the potential to revolutionize mental
health care. These models have shown promise in assisting clinicians and
providing support to individuals experiencing various psychological challenges.
  Objective: This study aims to compare the performance of two large language
models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,
to assess their potential applicability in mental health care settings.
  Methods: A blind methodology was employed, with a clinical psychologist
evaluating the models' responses without knowledge of their origins. The
prompts encompassed a diverse range of mental health topics, including
depression, anxiety, and trauma, to ensure a comprehensive assessment.
  Results: The results demonstrated a significant difference in performance
between the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out
of 10, while Chat-GPT received an average rating of 6.52. The clinical
psychologist's evaluation suggested that GPT-4 was more effective at generating
clinically relevant and empathetic responses, thereby providing better support
and guidance to potential users.
  Conclusions: This study contributes to the growing body of literature on the
applicability of large language models in mental health care settings. The
findings underscore the importance of continued research and development in the
field to optimize these models for clinical use. Further investigation is
necessary to understand the specific factors underlying the performance
differences between the two models and to explore their generalizability across
various populations and mental health conditions.

中文翻译:
背景：自然语言处理技术的快速发展催生了具有革新心理健康护理潜力的大语言模型。这些模型在辅助临床医师和为面临各类心理挑战的个体提供支持方面展现出应用前景。

目的：本研究旨在比较GPT-4和Chat-GPT两款大语言模型对18项心理提示的应答表现，评估其在心理健康护理场景中的潜在适用性。

方法：采用盲法实验设计，由临床心理学家在不知晓应答来源的情况下对模型回答进行评估。提示内容涵盖抑郁、焦虑、创伤等多样化心理健康主题，以确保全面评估。

结果：两组模型表现存在显著差异（p > 0.05）。GPT-4平均得分8.29分（满分10分），Chat-GPT平均得分6.52分。临床评估表明GPT-4在生成临床相关且富有共情的应答方面更为有效，能为潜在用户提供更优质的支持与指导。

结论：本研究为探讨大语言模型在心理健康护理领域的适用性提供了新的实证依据。研究结果强调需要持续开展该领域的研发工作以优化临床适用性。未来需进一步探究导致模型表现差异的具体因素，并验证其在不同人群及心理健康状况中的普适性。
