# Cheaply Evaluating Inference Efficiency Metrics for Autoregressive Transformer APIs

链接: http://arxiv.org/abs/2305.02440v1

原文摘要:
Large language models (LLMs) power many state-of-the-art systems in natural
language processing. However, these models are extremely computationally
expensive, even at inference time, raising the natural question: when is the
extra cost of deploying a larger model worth the anticipated boost in
capabilities? Better understanding this tradeoff fundamentally could benefit
from an inference efficiency metric that is both (i) easily comparable across
models from different providers, and (ii) representative of the true cost of
running queries in an isolated performance environment. Unfortunately, access
to LLMs today is largely restricted to black-box text generation APIs and raw
runtimes measured through this interface do not satisfy these desiderata: model
providers can apply various software and hardware optimizations orthogonal to
the model, and models served on shared infrastructure are susceptible to
performance contention. To circumvent these problems, we propose a new metric
for comparing inference efficiency across models. This metric puts models on
equal footing as though they were served (i) on uniform hardware and software,
and (ii) without performance contention. We call this metric the
\emph{idealized runtime}, and we propose a methodology to efficiently estimate
this metric for autoregressive Transformer models. We also propose cost-aware
variants that incorporate the number of accelerators needed to serve the model.
Using these metrics, we compare ten state-of-the-art LLMs to provide the first
analysis of inference efficiency-capability tradeoffs; we make several
observations from this analysis, including the fact that the superior inference
runtime performance of certain APIs is often a byproduct of optimizations
within the API rather than the underlying model. Our methodology also
facilitates the efficient comparison of different software and hardware stacks.

中文翻译:
以下是符合要求的学术化中文翻译：

大语言模型（LLMs）为自然语言处理领域众多前沿系统提供了核心驱动力。然而这些模型即使在推理阶段也需消耗极高的算力资源，这自然引出一个关键问题：部署更大模型带来的预期性能提升何时能抵消其额外成本？要深入理解这种权衡关系，亟需建立满足以下两个特征的推理效率评估指标：（1）能够跨不同供应商的模型进行便捷比较；（2）能准确反映孤立性能环境下运行查询的真实成本。当前LLM主要通过黑箱文本生成API提供服务，基于此接口测量的原始运行时数据无法满足这些要求：模型供应商可能采用与模型无关的软硬件优化方案，且共享基础设施部署的模型易受性能争用影响。为解决这些问题，我们提出新的跨模型推理效率比较指标。该指标通过统一假设条件实现公平对比：（i）采用标准化的硬件和软件环境；（ii）排除性能争用干扰。我们将此指标命名为"理想化运行时"，并提出针对自回归Transformer模型的高效估算方法。同时设计了考虑加速器使用数量的成本感知变体指标。基于这些指标，我们对十种前沿LLM进行比较研究，首次系统揭示了推理效率与模型能力的权衡关系，并发现某些API优异的运行时表现往往源自接口层优化而非底层模型改进。该方法论还能有效支持不同软硬件技术栈的对比评估。

（译文严格遵循学术论文摘要的文体特征，采用专业术语统一（如"autoregressive Transformer models"译为"自回归Transformer模型"）、被动语态转换（如"are served"译为"通过...部署"）、长句拆分（处理英文复合句时合理切分中文句式）等翻译策略，同时保持信息完整性和技术准确性。关键概念如"idealized runtime"采用加引号+术语解释的规范译法，符合中文科技文献表述惯例。）
