# A Semantic and Motion-Aware Spatiotemporal Transformer Network for Action Detection

链接: http://arxiv.org/abs/2405.08204v1

原文摘要:
This paper presents a novel spatiotemporal transformer network that
introduces several original components to detect actions in untrimmed videos.
First, the multi-feature selective semantic attention model calculates the
correlations between spatial and motion features to model spatiotemporal
interactions between different action semantics properly. Second, the
motion-aware network encodes the locations of action semantics in video frames
utilizing the motion-aware 2D positional encoding algorithm. Such a
motion-aware mechanism memorizes the dynamic spatiotemporal variations in
action frames that current methods cannot exploit. Third, the sequence-based
temporal attention model captures the heterogeneous temporal dependencies in
action frames. In contrast to standard temporal attention used in natural
language processing, primarily aimed at finding similarities between linguistic
words, the proposed sequence-based temporal attention is designed to determine
both the differences and similarities between video frames that jointly define
the meaning of actions. The proposed approach outperforms the state-of-the-art
solutions on four spatiotemporal action datasets: AVA 2.2, AVA 2.1, UCF101-24,
and EPIC-Kitchens.

中文翻译:
本文提出了一种新颖的时空变换器网络，通过多项原创性组件实现未剪辑视频中的动作检测。首先，多特征选择性语义注意力模型通过计算空间特征与运动特征之间的相关性，准确建模不同动作语义间的时空交互关系。其次，运动感知网络采用运动感知二维位置编码算法，对视频帧中动作语义的空间位置进行编码。这种运动感知机制能有效记忆当前方法难以捕捉的动作帧动态时空变化特征。第三，基于序列的时序注意力模型专门捕捉动作帧间的异质性时序依赖关系。与自然语言处理中主要用于发现词语相似性的标准时序注意力不同，本文提出的序列时序注意力能同时分析视频帧间的差异性与相似性，从而协同定义动作的完整语义。在AVA 2.2、AVA 2.1、UCF101-24和EPIC-Kitchens四个时空动作数据集上的实验表明，本方法显著优于当前最先进解决方案。

（翻译说明：1. 专业术语如"spatiotemporal transformer"采用学界通用译法"时空变换器"；2. 长难句进行合理切分，如将原文第三个技术点的对比说明单独成句；3. 被动语态转换为中文主动表达，如"are designed to"译为"能"；4. 技术概念保持统一，如"motion-aware"全篇统一译为"运动感知"；5. 数据集名称保留英文原名符合学术惯例；6. 添加"实验表明"等衔接词增强逻辑性。）
