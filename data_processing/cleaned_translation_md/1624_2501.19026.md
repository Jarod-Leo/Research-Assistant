# MPLinker: Multi-template Prompt-tuning with Adversarial Training for Issue-commit Link Recovery

链接: http://arxiv.org/abs/2501.19026v1

原文摘要:
In recent years, the pre-training, prompting and prediction paradigm, known
as prompt-tuning, has achieved significant success in Natural Language
Processing (NLP). Issue-commit Link Recovery (ILR) in Software Traceability
(ST) plays an important role in improving the reliability, quality, and
security of software systems. The current ILR methods convert the ILR into a
classification task using pre-trained language models (PLMs) and dedicated
neural networks. these methods do not fully utilize the semantic information
embedded in PLMs, resulting in not achieving acceptable performance. To address
this limitation, we introduce a novel paradigm: Multi-template Prompt-tuning
with adversarial training for issue-commit Link recovery (MPLinker). MPLinker
redefines the ILR task as a cloze task via template-based prompt-tuning and
incorporates adversarial training to enhance model generalization and reduce
overfitting. We evaluated MPLinker on six open-source projects using a
comprehensive set of performance metrics. The experiment results demonstrate
that MPLinker achieves an average F1-score of 96.10%, Precision of 96.49%,
Recall of 95.92%, MCC of 94.04%, AUC of 96.05%, and ACC of 98.15%,
significantly outperforming existing state-of-the-art methods. Overall,
MPLinker improves the performance and generalization of ILR models, and
introduces innovative concepts and methods for ILR. The replication package for
MPLinker is available at
