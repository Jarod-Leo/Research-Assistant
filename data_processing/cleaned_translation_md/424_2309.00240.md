# FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking

链接: http://arxiv.org/abs/2309.00240v1

原文摘要:
Automatic fact-checking plays a crucial role in combating the spread of
misinformation. Large Language Models (LLMs) and Instruction-Following
variants, such as InstructGPT and Alpaca, have shown remarkable performance in
various natural language processing tasks. However, their knowledge may not
always be up-to-date or sufficient, potentially leading to inaccuracies in
fact-checking. To address this limitation, we propose combining the power of
instruction-following language models with external evidence retrieval to
enhance fact-checking performance. Our approach involves leveraging search
engines to retrieve relevant evidence for a given input claim. This external
evidence serves as valuable supplementary information to augment the knowledge
of the pretrained language model. Then, we instruct-tune an open-sourced
language model, called LLaMA, using this evidence, enabling it to predict the
veracity of the input claim more accurately. To evaluate our method, we
conducted experiments on two widely used fact-checking datasets: RAWFC and
LIAR. The results demonstrate that our approach achieves state-of-the-art
performance in fact-checking tasks. By integrating external evidence, we bridge
the gap between the model's knowledge and the most up-to-date and sufficient
context available, leading to improved fact-checking outcomes. Our findings
have implications for combating misinformation and promoting the dissemination
of accurate information on online platforms. Our released materials are
accessible at: https://thcheung.github.io/factllama.

中文翻译:
自动事实核查在遏制虚假信息传播方面发挥着关键作用。大型语言模型（LLMs）及其指令遵循变体（如InstructGPT和Alpaca）已在多种自然语言处理任务中展现出卓越性能。然而，这些模型的知识可能并非始终最新或充分，可能导致事实核查的准确性不足。为突破这一局限，我们提出将指令遵循语言模型与外部证据检索相结合以增强事实核查效能。该方法通过搜索引擎检索与输入主张相关的证据，这些外部证据作为有价值的补充信息来扩展预训练语言模型的知识库。随后，我们使用这些证据对开源语言模型LLaMA进行指令微调，使其能更准确地预测输入主张的真实性。我们在RAWFC和LIAR两个广泛使用的事实核查数据集上进行了实验评估，结果表明该方法达到了当前最优的事实核查性能。通过整合外部证据，我们弥合了模型知识库与最新、最充分可用语境之间的差距，从而提升了事实核查效果。本研究对打击虚假信息、促进网络平台准确信息传播具有重要意义。相关资源已发布于：https://thcheung.github.io/factllama。


