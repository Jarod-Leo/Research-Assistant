# Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?

链接: http://arxiv.org/abs/2402.12025v1

原文摘要:
The field of natural language processing (NLP) has recently witnessed a
transformative shift with the emergence of foundation models, particularly
Large Language Models (LLMs) that have revolutionized text-based NLP. This
paradigm has extended to other modalities, including speech, where researchers
are actively exploring the combination of Speech Foundation Models (SFMs) and
LLMs into single, unified models capable of addressing multimodal tasks. Among
such tasks, this paper focuses on speech-to-text translation (ST). By examining
the published papers on the topic, we propose a unified view of the
architectural solutions and training strategies presented so far, highlighting
similarities and differences among them. Based on this examination, we not only
organize the lessons learned but also show how diverse settings and evaluation
approaches hinder the identification of the best-performing solution for each
architectural building block and training choice. Lastly, we outline
recommendations for future works on the topic aimed at better understanding the
strengths and weaknesses of the SFM+LLM solutions for ST.

中文翻译:
近年来，自然语言处理（NLP）领域因基础模型的出现发生了革命性转变，尤其是彻底改变文本NLP范式的大语言模型（LLMs）。这一范式已扩展至语音等多模态领域，研究者正积极探索将语音基础模型（SFMs）与LLMs融合为统一模型，以处理多模态任务。本文聚焦其中语音到文本翻译（ST）任务，通过系统梳理相关文献，对现有架构方案与训练策略提出统一视角，明晰其异同点。基于此分析，我们不仅整合了现有经验，更揭示出不同实验设置与评估方法如何阻碍对各架构模块及训练方案最优解的判定。最后，本文为该领域未来研究提出建议，以期更深入理解SFM+LLM方案在ST任务中的优势与局限。

（翻译说明：采用学术论文摘要的简洁风格，通过以下处理实现专业性与可读性平衡：
1. 术语统一："foundation models"译为"基础模型"符合国内人工智能领域共识
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句（如第一句拆分为因果逻辑递进）
3. 概念显化："multimodal tasks"译为"多模态任务"后补充"以处理"明确动词关系
4. 被动语态转化："we propose"译为主动式"提出"，符合中文表达习惯
5. 专业表述："architectural building block"译为"架构模块"准确传达技术概念
6. 逻辑连接词使用："基于此分析"、"更揭示出"等短语保持学术文本严谨性）
