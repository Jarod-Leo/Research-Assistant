# Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines

链接: http://arxiv.org/abs/2504.21475v1

原文摘要:
This study addresses the critical gap in Arabic natural language processing
by developing an effective Arabic Reverse Dictionary (RD) system that enables
users to find words based on their descriptions or meanings. We present a novel
transformer-based approach with a semi-encoder neural network architecture
featuring geometrically decreasing layers that achieves state-of-the-art
results for Arabic RD tasks. Our methodology incorporates a comprehensive
dataset construction process and establishes formal quality standards for
Arabic lexicographic definitions. Experiments with various pre-trained models
demonstrate that Arabic-specific models significantly outperform general
multilingual embeddings, with ARBERTv2 achieving the best ranking score
(0.0644). Additionally, we provide a formal abstraction of the reverse
dictionary task that enhances theoretical understanding and develop a modular,
extensible Python library (RDTL) with configurable training pipelines. Our
analysis of dataset quality reveals important insights for improving Arabic
definition construction, leading to eight specific standards for building
high-quality reverse dictionary resources. This work contributes significantly
to Arabic computational linguistics and provides valuable tools for language
learning, academic writing, and professional communication in Arabic.

中文翻译:
本研究针对阿拉伯语自然语言处理领域的关键空白，开发了一套高效的阿拉伯语反向词典系统（RD），使用户能够通过描述或含义来查询目标词汇。我们提出了一种基于Transformer架构的创新方法，采用具有几何递减层的半编码器神经网络结构，在阿拉伯语反向词典任务中取得了最先进的性能。研究过程包含完整的语料库构建流程，并为阿拉伯语词典学定义建立了规范的质量标准。通过多种预训练模型的对比实验，我们发现阿拉伯语专用模型显著优于通用多语言嵌入模型，其中ARBERTv2以0.0644的排序得分表现最佳。

此外，我们提出了反向词典任务的形式化抽象框架以深化理论认知，并开发了具有可配置训练管道的模块化Python工具库（RDTL）。针对数据集质量的分析揭示了改进阿拉伯语定义构建的重要启示，最终提炼出八项构建高质量反向词典资源的具体标准。本研究成果不仅对阿拉伯语计算语言学发展具有重要推动作用，更为阿拉伯语学习、学术写作及专业交流领域提供了有价值的工具。
