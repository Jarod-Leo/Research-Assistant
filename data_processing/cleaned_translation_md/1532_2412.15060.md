# ConfliBERT: A Language Model for Political Conflict

链接: http://arxiv.org/abs/2412.15060v1

原文摘要:
Conflict scholars have used rule-based approaches to extract information
about political violence from news reports and texts. Recent Natural Language
Processing developments move beyond rigid rule-based approaches. We review our
recent ConfliBERT language model (Hu et al. 2022) to process political and
violence related texts. The model can be used to extract actor and action
classifications from texts about political conflict. When fine-tuned, results
show that ConfliBERT has superior performance in accuracy, precision and recall
over other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama
3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also
hundreds of times faster than these more generalist LLMs. These results are
illustrated using texts from the BBC, re3d, and the Global Terrorism Dataset
(GTD).

中文翻译:
冲突研究学者长期采用基于规则的方法从新闻报道和文本中提取政治暴力相关信息。随着自然语言处理技术的发展，学界已突破传统刚性规则的局限。本文评述了我们最新研发的ConfliBERT语言模型（Hu等，2022），该模型专为处理政治与暴力相关文本设计，能够从政治冲突文本中自动识别行为主体和行动类别。实验表明，在特定领域内，经过微调的ConfliBERT在准确率、精确度和召回率等指标上均优于谷歌Gemma 2（90亿参数）、Meta Llama 3.1（70亿参数）和阿里巴巴Qwen 2.5（140亿参数）等通用大语言模型，且处理速度较这些通用模型快数百倍。研究结果通过BBC新闻、re3d数据库及全球恐怖主义数据库（GTD）的文本案例得到了验证。

（翻译说明：
1. 专业术语处理："rule-based approaches"译为"基于规则的方法"，"fine-tuned"译为"微调"，符合机器学习领域术语规范
2. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句，如将"results show..."独立成句
3. 被动语态转换："It is also hundreds..."主动化为"处理速度较这些...快数百倍"
4. 数据呈现：参数规模"9B/7B/14B"统一补充说明为"90亿/70亿/140亿参数"
5. 机构名称保留：Google/Meta/Alibaba等企业名维持英文原名，符合中文科技文献惯例
6. 文献引用格式："(Hu等，2022)"调整为中文文献引用规范）
