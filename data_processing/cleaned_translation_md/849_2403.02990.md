# Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges

链接: http://arxiv.org/abs/2403.02990v1

原文摘要:
In the rapidly evolving field of large language models (LLMs), data
augmentation (DA) has emerged as a pivotal technique for enhancing model
performance by diversifying training examples without the need for additional
data collection. This survey explores the transformative impact of LLMs on DA,
particularly addressing the unique challenges and opportunities they present in
the context of natural language processing (NLP) and beyond. From both data and
learning perspectives, we examine various strategies that utilize LLMs for data
augmentation, including a novel exploration of learning paradigms where
LLM-generated data is used for diverse forms of further training. Additionally,
this paper highlights the primary open challenges faced in this domain, ranging
from controllable data augmentation to multi-modal data augmentation. This
survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve
as a comprehensive guide for researchers and practitioners.

中文翻译:
在大语言模型（LLMs）快速发展的领域中，数据增强（DA）已成为提升模型性能的关键技术——它通过多样化训练样本实现效果优化，且无需额外数据收集。本文系统探讨了LLMs为数据增强带来的变革性影响，特别关注其在自然语言处理（NLP）及其他领域所呈现的独特挑战与机遇。我们从数据和学习的双重视角出发，分析了利用LLMs进行数据增强的多种策略，包括创新性地探索了以LLM生成数据支撑多样化再训练的学习范式。此外，本文重点阐述了该领域面临的核心开放挑战，涵盖可控数据增强到多模态数据增强等关键问题。本综述揭示了LLMs引发的数据增强范式变革，旨在为研究者和实践者提供系统化的指导框架。

（翻译说明：采用学术论文的严谨表述风格，通过以下处理实现专业性与可读性平衡：
1. 术语统一："large language models"严格译为"大语言模型"并标注缩写LLMs
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句，如使用破折号衔接补充说明
3. 概念显化："novel exploration"译为"创新性探索"以突出研究新颖性
4. 逻辑显性化：通过"系统探讨""重点阐述"等动词强化论文的综述属性
5. 动态对等："paradigm shift"译为"范式变革"既保留学术概念又符合中文表达）
