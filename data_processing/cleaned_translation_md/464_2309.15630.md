# NLPBench: Evaluating Large Language Models on Solving NLP Problems

链接: http://arxiv.org/abs/2309.15630v1

原文摘要:
Recent developments in large language models (LLMs) have shown promise in
enhancing the capabilities of natural language processing (NLP). Despite these
successes, there remains a dearth of research dedicated to the NLP
problem-solving abilities of LLMs. To fill the gap in this area, we present a
unique benchmarking dataset, NLPBench, comprising 378 college-level NLP
questions spanning various NLP topics sourced from Yale University's prior
final exams. NLPBench includes questions with context, in which multiple
sub-questions share the same public information, and diverse question types,
including multiple choice, short answer, and math. Our evaluation, centered on
LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting
strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study
reveals that the effectiveness of the advanced prompting strategies can be
inconsistent, occasionally damaging LLM performance, especially in smaller
models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated
specific shortcomings in LLMs' scientific problem-solving skills, with
weaknesses in logical decomposition and reasoning notably affecting results.

中文翻译:
以下是符合要求的学术中文翻译：

大规模语言模型（LLMs）的最新进展显著提升了自然语言处理（NLP）的性能表现。然而当前研究仍缺乏针对LLMs解决NLP问题能力的系统性探索。为此，我们构建了创新性基准数据集NLPBench，该数据集包含378道大学阶段NLP试题，涵盖耶鲁大学历年期末考试中涉及的多领域NLP知识点。NLPBench具有两大特征：1）上下文关联题型——多个子问题共享相同背景信息；2）题型多样性——包括选择题、简答题及数学计算题等。本研究以GPT-3.5/4、PaLM-2和LLAMA-2等主流LLMs为评估对象，结合思维链（CoT）和思维树（ToT）等先进提示策略进行实验。研究发现：1）高级提示策略的效果存在不稳定性，有时反而会损害模型表现，这种现象在LLAMA-2（13b）等较小模型中尤为显著；2）通过人工评估发现LLMs在科学问题解决能力上存在明显缺陷，特别是逻辑分解与推理能力的不足会显著影响最终结果。

（翻译严格遵循以下原则：
1. 专业术语统一处理（如LLMs不译，CoT/ToT保留英文缩写）
2. 长句拆分符合中文表达习惯（如将原文复合句拆分为"具有两大特征"的列举式结构）
3. 被动语态转化（如"our evaluation"译为"本研究"主动句式）
4. 学术用语准确（如"benchmarking dataset"译为"基准数据集"）
5. 逻辑关系显化（如"despite"转化为"然而"转折连词）
6. 数字单位规范处理（如"13b"保留技术参数写法））
