# Towards Equitable AI: Detecting Bias in Using Large Language Models for Marketing

链接: http://arxiv.org/abs/2502.12838v1

原文摘要:
The recent advances in large language models (LLMs) have revolutionized
industries such as finance, marketing, and customer service by enabling
sophisticated natural language processing tasks. However, the broad adoption of
LLMs brings significant challenges, particularly in the form of social biases
that can be embedded within their outputs. Biases related to gender, age, and
other sensitive attributes can lead to unfair treatment, raising ethical
concerns and risking both company reputation and customer trust. This study
examined bias in finance-related marketing slogans generated by LLMs (i.e.,
ChatGPT) by prompting tailored ads targeting five demographic categories:
gender, marital status, age, income level, and education level. A total of
1,700 slogans were generated for 17 unique demographic groups, and key terms
were categorized into four thematic groups: empowerment, financial, benefits
and features, and personalization. Bias was systematically assessed using
relative bias calculations and statistically tested with the Kolmogorov-Smirnov
(KS) test against general slogans generated for any individual. Results
revealed that marketing slogans are not neutral; rather, they emphasize
different themes based on demographic factors. Women, younger individuals,
low-income earners, and those with lower education levels receive more distinct
messaging compared to older, higher-income, and highly educated individuals.
This underscores the need to consider demographic-based biases in AI-generated
marketing strategies and their broader societal implications. The findings of
this study provide a roadmap for developing more equitable AI systems,
highlighting the need for ongoing bias detection and mitigation efforts in
LLMs.

中文翻译:
近期，大型语言模型（LLMs）的技术突破通过实现复杂的自然语言处理任务，彻底改变了金融、营销和客户服务等行业。然而，LLMs的广泛采用也带来了重大挑战，尤其是其输出内容中可能隐含的社会偏见。涉及性别、年龄等敏感属性的偏见会导致不公正待遇，不仅引发伦理争议，更可能损害企业声誉和客户信任。本研究通过让LLMs（即ChatGPT）生成针对五类人口统计特征（性别、婚姻状况、年龄、收入水平和教育水平）的定制广告标语，系统分析了金融类营销口号中的偏见问题。研究共为17个独特人群生成了1,700条标语，并将核心词汇归类为四大主题：赋权导向、金融属性、功能优势和个性化特征。通过相对偏差计算进行系统性评估，并采用Kolmogorov-Smirnov（KS）检验与面向普通个体的通用标语进行统计对比。结果表明，营销标语并非中立存在，而是根据人口统计因素强调不同主题。相较于年长、高收入和高学历群体，女性、年轻人、低收入者和低教育水平者接收到的信息呈现更显著的差异化特征。这凸显了在AI生成的营销策略中考虑人口统计学偏见的必要性及其广泛的社会影响。本研究结果为开发更公平的AI系统提供了路线图，强调了对LLMs进行持续偏见检测与缓解的重要性。  

（翻译说明：  
1. 专业术语处理："relative bias calculations"译为"相对偏差计算"，"Kolmogorov-Smirnov test"保留专业名称并补充中文注释  
2. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句，如将"Biases related to..."长句分解为因果逻辑链  
3. 概念显化："demographic categories"译为"人口统计特征"而非直译"人口类别"，更符合学术语境  
4. 动态对等："roadmap"译为"路线图"而非字面翻译，保留技术文档特征  
5. 文化适配："unfair treatment"译为"不公正待遇"而非"不公平处理"，符合中文社会议题表述习惯）
