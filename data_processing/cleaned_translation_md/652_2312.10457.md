# Semantic-Aware Autoregressive Image Modeling for Visual Representation Learning

链接: http://arxiv.org/abs/2312.10457v1

原文摘要:
The development of autoregressive modeling (AM) in computer vision lags
behind natural language processing (NLP) in self-supervised pre-training. This
is mainly caused by the challenge that images are not sequential signals and
lack a natural order when applying autoregressive modeling. In this study,
inspired by human beings' way of grasping an image, i.e., focusing on the main
object first, we present a semantic-aware autoregressive image modeling
(SemAIM) method to tackle this challenge. The key insight of SemAIM is to
autoregressive model images from the semantic patches to the less semantic
patches. To this end, we first calculate a semantic-aware permutation of
patches according to their feature similarities and then perform the
autoregression procedure based on the permutation. In addition, considering
that the raw pixels of patches are low-level signals and are not ideal
prediction targets for learning high-level semantic representation, we also
explore utilizing the patch features as the prediction targets. Extensive
experiments are conducted on a broad range of downstream tasks, including image
classification, object detection, and instance/semantic segmentation, to
evaluate the performance of SemAIM. The results demonstrate SemAIM achieves
state-of-the-art performance compared with other self-supervised methods.
Specifically, with ViT-B, SemAIM achieves 84.1% top-1 accuracy for fine-tuning
on ImageNet, 51.3% AP and 45.4% AP for object detection and instance
segmentation on COCO, which outperforms the vanilla MAE by 0.5%, 1.0%, and
0.5%, respectively.

中文翻译:
以下是符合您要求的中文翻译：

【译文】
自回归建模（AM）在计算机视觉领域的发展落后于自然语言处理（NLP）中的自监督预训练进展。这主要源于图像并非序列信号，在应用自回归建模时缺乏自然顺序的挑战。本研究受人类观察图像方式（即优先关注主体对象）的启发，提出语义感知的自回归图像建模方法（SemAIM）来解决这一难题。SemAIM的核心思想是依照从高语义区块到低语义区块的顺序进行自回归建模。具体实现中，我们首先根据图像区块的特征相似度计算语义感知的排列顺序，再基于该顺序执行自回归过程。此外，考虑到原始像素属于低级视觉信号，不利于学习高级语义表征，我们还探索将图像区块特征作为预测目标。通过在图像分类、目标检测及实例/语义分割等多样化下游任务上的大量实验表明，SemAIM相较其他自监督方法实现了最先进的性能表现。具体而言，使用ViT-B架构时，SemAIM在ImageNet微调任务中达到84.1%的Top-1准确率，在COCO数据集上获得51.3%的目标检测AP值与45.4%的实例分割AP值，分别比原始MAE方法提升0.5%、1.0%和0.5%。

【翻译要点说明】
1. 专业术语处理：
- "autoregressive modeling"统一译为"自回归建模"
- "self-supervised pre-training"译为"自监督预训练"
- "semantic-aware"统一处理为"语义感知"

2. 长句拆分与语序调整：
- 将原文第一复合长句拆分为两个逻辑清晰的短句，通过"这主要源于"进行衔接
- 方法描述部分采用"核心思想是..."的主动句式，避免被动语态的冗长感

3. 技术概念显化：
- "raw pixels of patches"译为"原始像素"后补充说明"属于低级视觉信号"，增强可读性
- "feature similarities"译为"特征相似度"而非字面直译，符合计算机视觉领域表述习惯

4. 数据呈现优化：
- 性能指标采用中文报告标准格式（如"84.1%的Top-1准确率"）
- 对比数据使用"分别比...提升"的紧凑结构，避免重复表述

5. 学术风格保持：
- 保留"本研究"等学术自称
- 使用"具体而言"等学术过渡语
- 专业缩写（如AP）首次出现时保留英文原词
