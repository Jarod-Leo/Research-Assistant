# AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts

链接: http://arxiv.org/abs/2405.00361v1

原文摘要:
We introduce AdaMoLE, a novel method for fine-tuning large language models
(LLMs) through an Adaptive Mixture of Low-Rank Adaptation (LoRA) Experts.
Moving beyond conventional methods that employ a static top-k strategy for
activating experts, AdaMoLE dynamically adjusts the activation threshold using
a dedicated threshold network, adaptively responding to the varying
complexities of different tasks. By replacing a single LoRA in a layer with
multiple LoRA experts and integrating a gating function with the threshold
mechanism, AdaMoLE effectively selects and activates the most appropriate
experts based on the input context. Our extensive evaluations across a variety
of commonsense reasoning and natural language processing tasks show that
AdaMoLE exceeds baseline performance. This enhancement highlights the
advantages of AdaMoLE's adaptive selection of LoRA experts, improving model
effectiveness without a corresponding increase in the expert count. The
experimental validation not only confirms AdaMoLE as a robust approach for
enhancing LLMs but also suggests valuable directions for future research in
adaptive expert selection mechanisms, potentially broadening the scope for
optimizing model performance across diverse language processing tasks.

中文翻译:
我们提出AdaMoLE（自适应低秩专家混合）这一创新方法，通过自适应混合低秩适配（LoRA）专家来实现大语言模型（LLM）的微调。相较于传统采用静态top-k策略激活专家的方法，AdaMoLE利用专用阈值网络动态调整激活阈值，从而自适应响应不同任务的复杂度变化。该方法通过用多个LoRA专家替代单层中的单一LoRA，并结合门控函数与阈值机制，能基于输入上下文有效选择并激活最合适的专家。我们在常识推理和自然语言处理多任务上的广泛评估表明，AdaMoLE显著超越了基线性能。这种提升凸显了其自适应选择LoRA专家的优势——在不增加专家数量的前提下提高了模型效能。实验验证不仅证实AdaMoLE是增强大语言模型的有效方法，还为自适应专家选择机制的未来研究指明了有价值的方向，有望为多样化语言处理任务的模型性能优化开拓更广阔的空间。
