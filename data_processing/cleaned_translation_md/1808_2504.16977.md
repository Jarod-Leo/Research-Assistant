# Tokenization Matters: Improving Zero-Shot NER for Indic Languages

链接: http://arxiv.org/abs/2504.16977v1

原文摘要:
Tokenization is a critical component of Natural Language Processing (NLP),
especially for low resource languages, where subword segmentation influences
vocabulary structure and downstream task accuracy. Although Byte Pair Encoding
(BPE) is a standard tokenization method in multilingual language models, its
suitability for Named Entity Recognition (NER) in low resource Indic languages
remains underexplored due to its limitations in handling morphological
complexity. In this work, we systematically compare BPE, SentencePiece, and
Character Level tokenization strategies using IndicBERT for NER tasks in low
resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as
extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We
assess both intrinsic linguistic properties tokenization efficiency, out of
vocabulary (OOV) rates, and morphological preservation as well as extrinsic
downstream performance, including fine tuning and zero shot cross lingual
transfer.
  Our experiments show that SentencePiece is a consistently better performing
approach than BPE for NER in low resource Indic Languages, particularly in zero
shot cross lingual settings, as it better preserves entity consistency. While
BPE provides the most compact tokenization form, it is not capable of
generalization because it misclassifies or even fails to recognize entity
labels when tested on unseen languages. In contrast, SentencePiece constitutes
a better linguistic structural preservation model, benefiting extremely low
resource and morphologically rich Indic languages, such as Santali and
Manipuri, for superior entity recognition, as well as high generalization
across scripts, such as Sindhi, written in Arabic. The results point to
SentencePiece as the more effective tokenization strategy for NER within
multilingual and low resource Indic NLP applications.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

分词是自然语言处理（NLP）的关键环节，尤其在低资源语言中，子词切分方式直接影响词汇表结构与下游任务准确率。尽管字节对编码（BPE）是多语言模型的标准化分词方案，但其在处理形态复杂性方面的局限，导致该技术对低资源印度语言命名实体识别（NER）的适用性仍待验证。本研究系统比较了BPE、SentencePiece和字符级分词策略在印度语NER任务中的表现，实验基于IndicBERT模型，涵盖阿萨姆语、孟加拉语、马拉地语、奥里亚语等低资源印度语言，以及桑塔利语、曼尼普尔语、信德语等极低资源语言。我们从内在语言特性（分词效率、未登录词率、形态保留能力）和外在下游表现（微调与零样本跨语言迁移）两个维度进行评估。

实验表明：在低资源印度语言的NER任务中，SentencePiece始终优于BPE方案，尤其在零样本跨语言场景下能更好保持实体一致性。虽然BPE能生成最紧凑的分词形式，但由于其面对未见语言时会出现实体标签误判甚至无法识别的情况，导致泛化能力不足。相比之下，SentencePiece具有更优的语言结构保留能力，不仅能提升桑塔利语、曼尼普尔语等极低资源且形态复杂的印度语言的实体识别效果，还能在阿拉伯文书写的信德语等跨文字场景中展现卓越的泛化性能。研究结果证明，在多语言低资源印度语NLP应用中，SentencePiece是更有效的NER分词策略。


2. 被动语态转换（英文被动式转为中文主动式）
3. 长句拆分重组（如将原文复合从句分解为符合中文表达习惯的短句）
4. 文化适配（"Indic languages"译为"印度语言"而非字面直译）
5. 逻辑连接词显化（增补"相比之下""由于"等衔接词）
6. 计量单位标准化（"OOV rates"译为专业术语"未登录词率"））
