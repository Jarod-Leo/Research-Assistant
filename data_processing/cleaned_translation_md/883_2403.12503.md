# Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices

链接: http://arxiv.org/abs/2403.12503v1

原文摘要:
Large language models (LLMs) have significantly transformed the landscape of
Natural Language Processing (NLP). Their impact extends across a diverse
spectrum of tasks, revolutionizing how we approach language understanding and
generations. Nevertheless, alongside their remarkable utility, LLMs introduce
critical security and risk considerations. These challenges warrant careful
examination to ensure responsible deployment and safeguard against potential
vulnerabilities. This research paper thoroughly investigates security and
privacy concerns related to LLMs from five thematic perspectives: security and
privacy concerns, vulnerabilities against adversarial attacks, potential harms
caused by misuses of LLMs, mitigation strategies to address these challenges
while identifying limitations of current strategies. Lastly, the paper
recommends promising avenues for future research to enhance the security and
risk management of LLMs.

中文翻译:
大型语言模型（LLMs）已经显著改变了自然语言处理（NLP）的发展格局。其影响力遍及多样化的任务领域，彻底革新了我们处理语言理解与生成的方式。然而在这些卓越功能之外，LLMs也带来了关键的安全与风险问题。这些挑战需要审慎研究，以确保负责任的模型部署，并防范潜在漏洞。本研究论文从五个主题视角系统探究了LLMs相关的安全与隐私问题：安全与隐私隐患、对抗性攻击下的脆弱性、LLMs滥用可能造成的危害、应对这些挑战的缓解策略（同时指出现有策略的局限性），最后为提升LLMs安全与风险管理提出了未来研究的可行方向。  

（译文特点说明：  
1. 专业术语准确对应："adversarial attacks"译为"对抗性攻击"，"mitigation strategies"译为"缓解策略"  
2. 长句拆分重构：将原文复合句按中文表达习惯分解为短句群  
3. 逻辑显化处理：通过"然而"、"最后"等连接词强化论证脉络  
4. 学术风格保留：使用"审慎研究"、"系统探究"等符合学术论文语境的表达  
5. 被动语态转化："warrant careful examination"主动化为"需要审慎研究"  
6. 括号补充说明：在专业表述处添加括号注释保持信息完整性）
