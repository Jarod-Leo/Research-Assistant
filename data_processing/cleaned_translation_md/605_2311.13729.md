# Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case

链接: http://arxiv.org/abs/2311.13729v1

原文摘要:
End-to-end relation extraction (E2ERE) is an important and realistic
application of natural language processing (NLP) in biomedicine. In this paper,
we aim to compare three prevailing paradigms for E2ERE using a complex dataset
focused on rare diseases involving discontinuous and nested entities. We use
the RareDis information extraction dataset to evaluate three competing
approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to
sequence models, and generative pre-trained transformer (GPT) models. We use
comparable state-of-the-art models and best practices for each of these
approaches and conduct error analyses to assess their failure modes. Our
findings reveal that pipeline models are still the best, while
sequence-to-sequence models are not far behind; GPT models with eight times as
many parameters are worse than even sequence-to-sequence models and lose to
pipeline models by over 10 F1 points. Partial matches and discontinuous
entities caused many NER errors contributing to lower overall E2E performances.
We also verify these findings on a second E2ERE dataset for chemical-protein
interactions. Although generative LM-based methods are more suitable for
zero-shot settings, when training data is available, our results show that it
is better to work with more conventional models trained and tailored for E2ERE.
More innovative methods are needed to marry the best of the both worlds from
smaller encoder-decoder pipeline models and the larger GPT models to improve
E2ERE. As of now, we see that well designed pipeline models offer substantial
performance gains at a lower cost and carbon footprint for E2ERE. Our
contribution is also the first to conduct E2ERE for the RareDis dataset.

中文翻译:
以下是符合要求的学术中文翻译：

端到端关系抽取（E2ERE）是自然语言处理（NLP）在生物医学领域的重要现实应用。本研究旨在利用包含不连续实体和嵌套实体的复杂罕见病数据集，比较当前主流的三种E2ERE范式。我们采用RareDis信息抽取数据集评估三种竞争性方法：NER→RE流水线模型、联合序列到序列模型以及生成式预训练变换器（GPT）模型。针对每种方法，我们选用可比的最新先进模型与最佳实践方案，并通过错误分析评估其失效模式。研究发现：流水线模型仍保持最优性能，序列到序列模型稍逊但差距不大；参数量达8倍的GPT模型表现甚至不及序列到序列模型，其F1值较流水线模型低10分以上。部分匹配与不连续实体导致的NER错误显著降低了整体端到端性能。我们在化学蛋白质相互作用的第二个E2ERE数据集上验证了这些结论。虽然基于生成式语言模型的方法更适用于零样本场景，但当存在训练数据时，结果表明针对E2ERE专门训练的传统模型更具优势。未来需要创新性方法融合小型编码器-解码器流水线模型与大型GPT模型的优势以提升E2ERE性能。目前研究表明，精心设计的流水线模型能以更低成本与碳排放实现显著性能提升。本研究也是首个在RareDis数据集上开展E2ERE工作的学术贡献。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如"end-to-end relation extraction"译为"端到端关系抽取"）
2. 被动语态转化（"we aim to compare"译为"本研究旨在比较"）
3. 长句拆分重组（将原文复合句分解为符合中文表达习惯的短句）
4. 学术用语规范（"state-of-the-art"译为"最新先进"而非口语化表达）
5. 数据呈现完整（精确保留"10 F1 points"等关键数据）
6. 逻辑关系显化（通过"虽然...但..."等连接词明确原文隐含逻辑））
