# Time Series Language Model for Descriptive Caption Generation

链接: http://arxiv.org/abs/2501.01832v1

原文摘要:
The automatic generation of representative natural language descriptions for
observable patterns in time series data enhances interpretability, simplifies
analysis and increases cross-domain utility of temporal data. While pre-trained
foundation models have made considerable progress in natural language
processing (NLP) and computer vision (CV), their application to time series
analysis has been hindered by data scarcity. Although several large language
model (LLM)-based methods have been proposed for time series forecasting, time
series captioning is under-explored in the context of LLMs. In this paper, we
introduce TSLM, a novel time series language model designed specifically for
time series captioning. TSLM operates as an encoder-decoder model, leveraging
both text prompts and time series data representations to capture subtle
temporal patterns across multiple phases and generate precise textual
descriptions of time series inputs. TSLM addresses the data scarcity problem in
time series captioning by first leveraging an in-context prompting synthetic
data generation, and second denoising the generated data via a novel
cross-modal dense retrieval scoring applied to time series-caption pairs.
Experimental findings on various time series captioning datasets demonstrate
that TSLM outperforms existing state-of-the-art approaches from multiple data
modalities by a significant margin.

中文翻译:
以下是符合您要求的中文翻译：

【学术摘要译文】
为时间序列数据中的可观测模式自动生成具有代表性的自然语言描述，能够增强数据可解释性、简化分析流程并提升时序数据的跨领域应用价值。尽管预训练基础模型在自然语言处理（NLP）和计算机视觉（CV）领域已取得显著进展，但数据稀缺问题一直阻碍着其在时间序列分析中的应用。当前虽已出现若干基于大语言模型（LLM）的时间序列预测方法，但针对LLM环境下的时间序列描述生成研究仍属空白。本文提出TSLM——一种专为时间序列描述任务设计的新型时序语言模型。该模型采用编码器-解码器架构，通过融合文本提示与时间序列数据表征，精准捕捉多阶段下的细微时序模式，并生成对输入序列的精确文本描述。TSLM通过双重机制解决数据稀缺问题：首先采用上下文提示的合成数据生成技术，其次通过我们提出的新型跨模态稠密检索评分方法对生成的时序-描述对进行去噪处理。在多个时间序列描述数据集上的实验表明，TSLM以显著优势超越了来自不同数据模态的现有最先进方法。

【翻译要点说明】
1. 专业术语处理：
- "foundation models"译为"基础模型"（学界通用译法）
- "in-context prompting"译为"上下文提示"（保持技术一致性）
- "cross-modal dense retrieval"译为"跨模态稠密检索"（准确反映算法特性）

2. 长句拆分重构：
将原文复合句分解为符合中文表达习惯的短句，如将"leveraging both text prompts..."部分独立成句并添加"通过"衔接词

3. 被动语态转化：
"has been hindered by"译为主动式"阻碍着"，符合中文表达习惯

4. 概念显化处理：
"under-explored"译为"仍属空白"（强化研究现状的表述力度）
"significant margin"译为"显著优势"（量化比较结果的学术表达）

5. 技术表述准确性：
严格区分"forecasting"（预测）与"captioning"（描述生成）的不同技术内涵

6. 学术风格保持：
使用"本文""所述""显著优势"等规范学术用语，避免口语化表达
