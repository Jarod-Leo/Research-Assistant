# Convolutional Neural Networks and Vision Transformers for Fashion MNIST Classification: A Literature Review

链接: http://arxiv.org/abs/2406.03478v1

原文摘要:
Our review explores the comparative analysis between Convolutional Neural
Networks (CNNs) and Vision Transformers (ViTs) in the domain of image
classification, with a particular focus on clothing classification within the
e-commerce sector. Utilizing the Fashion MNIST dataset, we delve into the
unique attributes of CNNs and ViTs. While CNNs have long been the cornerstone
of image classification, ViTs introduce an innovative self-attention mechanism
enabling nuanced weighting of different input data components. Historically,
transformers have primarily been associated with Natural Language Processing
(NLP) tasks. Through a comprehensive examination of existing literature, our
aim is to unveil the distinctions between ViTs and CNNs in the context of image
classification. Our analysis meticulously scrutinizes state-of-the-art
methodologies employing both architectures, striving to identify the factors
influencing their performance. These factors encompass dataset characteristics,
image dimensions, the number of target classes, hardware infrastructure, and
the specific architectures along with their respective top results. Our key
goal is to determine the most appropriate architecture between ViT and CNN for
classifying images in the Fashion MNIST dataset within the e-commerce industry,
while taking into account specific conditions and needs. We highlight the
importance of combining these two architectures with different forms to enhance
overall performance. By uniting these architectures, we can take advantage of
their unique strengths, which may lead to more precise and reliable models for
e-commerce applications. CNNs are skilled at recognizing local patterns, while
ViTs are effective at grasping overall context, making their combination a
promising strategy for boosting image classification performance.

中文翻译:
本文综述对卷积神经网络（CNN）与视觉变换器（ViT）在图像分类领域的性能进行了对比分析，尤其聚焦电子商务场景下的服装分类任务。基于Fashion MNIST数据集，我们深入探究了两种架构的特性：CNN作为传统图像分类的基石，而ViT则通过创新的自注意力机制实现对输入数据各部分的差异化加权处理——尽管变换器架构最初主要应用于自然语言处理（NLP）领域。通过系统梳理现有文献，我们旨在揭示两种架构在图像分类中的本质差异。

研究采用严谨的分析方法，对采用这两种架构的前沿技术方案进行细致考察，力图识别影响模型性能的关键因素，包括：数据集特性、图像尺寸、目标类别数量、硬件基础设施，以及具体架构设计与其对应最优结果。核心目标在于根据电子商务行业特定需求和条件，确定Fashion MNIST数据集图像分类任务中最适宜的架构选择。我们特别强调将两种架构以不同形式进行融合对提升整体性能的重要意义——通过优势互补（CNN擅长局部特征识别，ViT强调整体上下文理解），这种联合策略有望构建更精准可靠的电商应用模型。
