[
  {
    "arxiv_id": "2301.07057",
    "title": "Transformer Based Implementation for Automatic Book Summarization",
    "url": "http://arxiv.org/abs/2301.07057v1",
    "abstract": "Document Summarization is the procedure of generating a meaningful and\nconcise summary of a given document with the inclusion of relevant and\ntopic-important points. There are two approaches: one is picking up the most\nrelevant statements from the document itself and adding it to the Summary known\nas Extractive and the other is generating sentences for the Summary known as\nAbstractive Summarization. Training a machine learning model to perform tasks\nthat are time-consuming or very difficult for humans to evaluate is a major\nchallenge. Book Abstract generation is one of such complex tasks. Traditional\nmachine learning models are getting modified with pre-trained transformers.\nTransformer based language models trained in a self-supervised fashion are\ngaining a lot of attention; when fine-tuned for Natural Language\nProcessing(NLP) downstream task like text summarization. This work is an\nattempt to use Transformer based techniques for Abstract generation."
  },
  {
    "arxiv_id": "2301.04761",
    "title": "NarrowBERT: Accelerating Masked Language Model Pretraining and Inference",
    "url": "http://arxiv.org/abs/2301.04761v1",
    "abstract": "Large-scale language model pretraining is a very successful form of\nself-supervised learning in natural language processing, but it is increasingly\nexpensive to perform as the models and pretraining corpora have become larger\nover time. We propose NarrowBERT, a modified transformer encoder that increases\nthe throughput for masked language model pretraining by more than $2\\times$.\nNarrowBERT sparsifies the transformer model such that the self-attention\nqueries and feedforward layers only operate on the masked tokens of each\nsentence during pretraining, rather than all of the tokens as with the usual\ntransformer encoder. We also show that NarrowBERT increases the throughput at\ninference time by as much as $3.5\\times$ with minimal (or no) performance\ndegradation on sentence encoding tasks like MNLI. Finally, we examine the\nperformance of NarrowBERT on the IMDB and Amazon reviews classification and\nCoNLL NER tasks and show that it is also comparable to standard BERT\nperformance."
  },
  {
    "arxiv_id": "2301.04013",
    "title": "There is No Big Brother or Small Brother: Knowledge Infusion in Language Models for Link Prediction and Question Answering",
    "url": "http://arxiv.org/abs/2301.04013v1",
    "abstract": "The integration of knowledge graphs with deep learning is thriving in\nimproving the performance of various natural language processing (NLP) tasks.\nIn this paper, we focus on knowledge-infused link prediction and question\nanswering using language models, T5, and BLOOM across three domains: Aviation,\nMovie, and Web. In this context, we infuse knowledge in large and small\nlanguage models and study their performance, and find the performance to be\nsimilar. For the link prediction task on the Aviation Knowledge Graph, we\nobtain a 0.2 hits@1 score using T5-small, T5-base, T5-large, and BLOOM. Using\ntemplate-based scripts, we create a set of 1 million synthetic factoid QA pairs\nin the aviation domain from National Transportation Safety Board (NTSB)\nreports. On our curated QA pairs, the three models of T5 achieve a 0.7 hits@1\nscore. We validate out findings with the paired student t-test and Cohen's\nkappa scores. For link prediction on Aviation Knowledge Graph using T5-small\nand T5-large, we obtain a Cohen's kappa score of 0.76, showing substantial\nagreement between the models. Thus, we infer that small language models perform\nsimilar to large language models with the infusion of knowledge."
  },
  {
    "arxiv_id": "2301.03980",
    "title": "Language Models sounds the Death Knell of Knowledge Graphs",
    "url": "http://arxiv.org/abs/2301.03980v1",
    "abstract": "Healthcare domain generates a lot of unstructured and semi-structured text.\nNatural Language processing (NLP) has been used extensively to process this\ndata. Deep Learning based NLP especially Large Language Models (LLMs) such as\nBERT have found broad acceptance and are used extensively for many\napplications. A Language Model is a probability distribution over a word\nsequence. Self-supervised Learning on a large corpus of data automatically\ngenerates deep learning-based language models. BioBERT and Med-BERT are\nlanguage models pre-trained for the healthcare domain. Healthcare uses typical\nNLP tasks such as question answering, information extraction, named entity\nrecognition, and search to simplify and improve processes. However, to ensure\nrobust application of the results, NLP practitioners need to normalize and\nstandardize them. One of the main ways of achieving normalization and\nstandardization is the use of Knowledge Graphs. A Knowledge Graph captures\nconcepts and their relationships for a specific domain, but their creation is\ntime-consuming and requires manual intervention from domain experts, which can\nprove expensive. SNOMED CT (Systematized Nomenclature of Medicine -- Clinical\nTerms), Unified Medical Language System (UMLS), and Gene Ontology (GO) are\npopular ontologies from the healthcare domain. SNOMED CT and UMLS capture\nconcepts such as disease, symptoms and diagnosis and GO is the world's largest\nsource of information on the functions of genes. Healthcare has been dealing\nwith an explosion in information about different types of drugs, diseases, and\nprocedures. This paper argues that using Knowledge Graphs is not the best\nsolution for solving problems in this domain. We present experiments using LLMs\nfor the healthcare domain to demonstrate that language models provide the same\nfunctionality as knowledge graphs, thereby making knowledge graphs redundant."
  },
  {
    "arxiv_id": "2301.03505",
    "title": "Advances in Medical Image Analysis with Vision Transformers: A Comprehensive Review",
    "url": "http://arxiv.org/abs/2301.03505v2",
    "abstract": "The remarkable performance of the Transformer architecture in natural\nlanguage processing has recently also triggered broad interest in Computer\nVision. Among other merits, Transformers are witnessed as capable of learning\nlong-range dependencies and spatial correlations, which is a clear advantage\nover convolutional neural networks (CNNs), which have been the de facto\nstandard in Computer Vision problems so far. Thus, Transformers have become an\nintegral part of modern medical image analysis. In this review, we provide an\nencyclopedic review of the applications of Transformers in medical imaging.\nSpecifically, we present a systematic and thorough review of relevant recent\nTransformer literature for different medical image analysis tasks, including\nclassification, segmentation, detection, registration, synthesis, and clinical\nreport generation. For each of these applications, we investigate the novelty,\nstrengths and weaknesses of the different proposed strategies and develop\ntaxonomies highlighting key properties and contributions. Further, if\napplicable, we outline current benchmarks on different datasets. Finally, we\nsummarize key challenges and discuss different future research directions. In\naddition, we have provided cited papers with their corresponding\nimplementations in https://github.com/mindflow-institue/Awesome-Transformer."
  },
  {
    "arxiv_id": "2301.01772",
    "title": "Infomaxformer: Maximum Entropy Transformer for Long Time-Series Forecasting Problem",
    "url": "http://arxiv.org/abs/2301.01772v1",
    "abstract": "The Transformer architecture yields state-of-the-art results in many tasks\nsuch as natural language processing (NLP) and computer vision (CV), since the\nability to efficiently capture the precise long-range dependency coupling\nbetween input sequences. With this advanced capability, however, the quadratic\ntime complexity and high memory usage prevents the Transformer from dealing\nwith long time-series forecasting problem (LTFP). To address these\ndifficulties: (i) we revisit the learned attention patterns of the vanilla\nself-attention, redesigned the calculation method of self-attention based the\nMaximum Entropy Principle. (ii) we propose a new method to sparse the\nself-attention, which can prevent the loss of more important self-attention\nscores due to random sampling.(iii) We propose Keys/Values Distilling method\nmotivated that a large amount of feature in the original self-attention map is\nredundant, which can further reduce the time and spatial complexity and make it\npossible to input longer time-series. Finally, we propose a method that\ncombines the encoder-decoder architecture with seasonal-trend decomposition,\ni.e., using the encoder-decoder architecture to capture more specific seasonal\nparts. A large number of experiments on several large-scale datasets show that\nour Infomaxformer is obviously superior to the existing methods. We expect this\nto open up a new solution for Transformer to solve LTFP, and exploring the\nability of the Transformer architecture to capture much longer temporal\ndependencies."
  },
  {
    "arxiv_id": "2301.01172",
    "title": "A Survey On Few-shot Knowledge Graph Completion with Structural and Commonsense Knowledge",
    "url": "http://arxiv.org/abs/2301.01172v1",
    "abstract": "Knowledge graphs (KG) have served as the key component of various natural\nlanguage processing applications. Commonsense knowledge graphs (CKG) are a\nspecial type of KG, where entities and relations are composed of free-form\ntext. However, previous works in KG completion and CKG completion suffer from\nlong-tail relations and newly-added relations which do not have many know\ntriples for training. In light of this, few-shot KG completion (FKGC), which\nrequires the strengths of graph representation learning and few-shot learning,\nhas been proposed to challenge the problem of limited annotated data. In this\npaper, we comprehensively survey previous attempts on such tasks in the form of\na series of methods and applications. Specifically, we first introduce FKGC\nchallenges, commonly used KGs, and CKGs. Then we systematically categorize and\nsummarize existing works in terms of the type of KGs and the methods. Finally,\nwe present applications of FKGC models on prediction tasks in different areas\nand share our thoughts on future research directions of FKGC."
  },
  {
    "arxiv_id": "2301.00303",
    "title": "Rethinking with Retrieval: Faithful Large Language Model Inference",
    "url": "http://arxiv.org/abs/2301.00303v1",
    "abstract": "Despite the success of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, the stored knowledge in these models may\ninevitably be incomplete, out-of-date, or incorrect. This motivates the need to\nutilize external knowledge to assist LLMs. Unfortunately, current methods for\nincorporating external knowledge often require additional training or\nfine-tuning, which can be costly and may not be feasible for LLMs. To address\nthis issue, we propose a novel post-processing approach, rethinking with\nretrieval (RR), which retrieves relevant external knowledge based on the\ndecomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.\nThis lightweight approach does not require additional training or fine-tuning\nand is not limited by the input length of LLMs. We evaluate the effectiveness\nof RR through extensive experiments with GPT-3 on three complex reasoning\ntasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our\nresults show that RR can produce more faithful explanations and improve the\nperformance of LLMs."
  },
  {
    "arxiv_id": "2212.14164",
    "title": "On Transforming Reinforcement Learning by Transformer: The Development Trajectory",
    "url": "http://arxiv.org/abs/2212.14164v1",
    "abstract": "Transformer, originally devised for natural language processing, has also\nattested significant success in computer vision. Thanks to its super expressive\npower, researchers are investigating ways to deploy transformers to\nreinforcement learning (RL) and the transformer-based models have manifested\ntheir potential in representative RL benchmarks. In this paper, we collect and\ndissect recent advances on transforming RL by transformer (transformer-based RL\nor TRL), in order to explore its development trajectory and future trend. We\ngroup existing developments in two categories: architecture enhancement and\ntrajectory optimization, and examine the main applications of TRL in robotic\nmanipulation, text-based games, navigation and autonomous driving. For\narchitecture enhancement, these methods consider how to apply the powerful\ntransformer structure to RL problems under the traditional RL framework, which\nmodel agents and environments much more precisely than deep RL methods, but\nthey are still limited by the inherent defects of traditional RL algorithms,\nsuch as bootstrapping and \"deadly triad\". For trajectory optimization, these\nmethods treat RL problems as sequence modeling and train a joint state-action\nmodel over entire trajectories under the behavior cloning framework, which are\nable to extract policies from static datasets and fully use the long-sequence\nmodeling capability of the transformer. Given these advancements, extensions\nand challenges in TRL are reviewed and proposals about future direction are\ndiscussed. We hope that this survey can provide a detailed introduction to TRL\nand motivate future research in this rapidly developing field."
  },
  {
    "arxiv_id": "2212.13685",
    "title": "Part-guided Relational Transformers for Fine-grained Visual Recognition",
    "url": "http://arxiv.org/abs/2212.13685v1",
    "abstract": "Fine-grained visual recognition is to classify objects with visually similar\nappearances into subcategories, which has made great progress with the\ndevelopment of deep CNNs. However, handling subtle differences between\ndifferent subcategories still remains a challenge. In this paper, we propose to\nsolve this issue in one unified framework from two aspects, i.e., constructing\nfeature-level interrelationships, and capturing part-level discriminative\nfeatures. This framework, namely PArt-guided Relational Transformers (PART), is\nproposed to learn the discriminative part features with an automatic part\ndiscovery module, and to explore the intrinsic correlations with a feature\ntransformation module by adapting the Transformer models from the field of\nnatural language processing. The part discovery module efficiently discovers\nthe discriminative regions which are highly-corresponded to the gradient\ndescent procedure. Then the second feature transformation module builds\ncorrelations within the global embedding and multiple part embedding, enhancing\nspatial interactions among semantic pixels. Moreover, our proposed approach\ndoes not rely on additional part branches in the inference time and reaches\nstate-of-the-art performance on 3 widely-used fine-grained object recognition\nbenchmarks. Experimental results and explainable visualizations demonstrate the\neffectiveness of our proposed approach. The code can be found at\nhttps://github.com/iCVTEAM/PART."
  },
  {
    "arxiv_id": "2212.13428",
    "title": "A Survey on Knowledge-Enhanced Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2212.13428v1",
    "abstract": "Natural Language Processing (NLP) has been revolutionized by the use of\nPre-trained Language Models (PLMs) such as BERT. Despite setting new records in\nnearly every NLP task, PLMs still face a number of challenges including poor\ninterpretability, weak reasoning capability, and the need for a lot of\nexpensive annotated data when applied to downstream tasks. By integrating\nexternal knowledge into PLMs,\n\\textit{\\underline{K}nowledge-\\underline{E}nhanced \\underline{P}re-trained\n\\underline{L}anguage \\underline{M}odels} (KEPLMs) have the potential to\novercome the above-mentioned limitations. In this paper, we examine KEPLMs\nsystematically through a series of studies. Specifically, we outline the common\ntypes and different formats of knowledge to be integrated into KEPLMs, detail\nthe existing methods for building and evaluating KEPLMS, present the\napplications of KEPLMs in downstream tasks, and discuss the future research\ndirections. Researchers will benefit from this survey by gaining a quick and\ncomprehensive overview of the latest developments in this field."
  },
  {
    "arxiv_id": "2212.13408",
    "title": "NEEDED: Introducing Hierarchical Transformer to Eye Diseases Diagnosis",
    "url": "http://arxiv.org/abs/2212.13408v3",
    "abstract": "With the development of natural language processing techniques(NLP),\nautomatic diagnosis of eye diseases using ophthalmology electronic medical\nrecords (OEMR) has become possible. It aims to evaluate the condition of both\neyes of a patient respectively, and we formulate it as a particular multi-label\nclassification task in this paper. Although there are a few related studies in\nother diseases, automatic diagnosis of eye diseases exhibits unique\ncharacteristics. First, descriptions of both eyes are mixed up in OEMR\ndocuments, with both free text and templated asymptomatic descriptions,\nresulting in sparsity and clutter of information. Second, OEMR documents\ncontain multiple parts of descriptions and have long document lengths. Third,\nit is critical to provide explainability to the disease diagnosis model. To\novercome those challenges, we present an effective automatic eye disease\ndiagnosis framework, NEEDED. In this framework, a preprocessing module is\nintegrated to improve the density and quality of information. Then, we design a\nhierarchical transformer structure for learning the contextualized\nrepresentations of each sentence in the OEMR document. For the diagnosis part,\nwe propose an attention-based predictor that enables traceable diagnosis by\nobtaining disease-specific information. Experiments on the real dataset and\ncomparison with several baseline models show the advantage and explainability\nof our framework."
  },
  {
    "arxiv_id": "2212.10898",
    "title": "Training language models for deeper understanding improves brain alignment",
    "url": "http://arxiv.org/abs/2212.10898v1",
    "abstract": "Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling."
  },
  {
    "arxiv_id": "2212.10773",
    "title": "MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning",
    "url": "http://arxiv.org/abs/2212.10773v1",
    "abstract": "Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However, it\nhas yet to be explored for vision and multimodal tasks. In this work, we\nintroduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark\ndataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq\nformat covering 10 broad categories. The tasks are derived from 21 existing\nopen-source datasets and each task is equipped with 5 expert-written\ninstructions. We take OFA as the base pre-trained model for multimodal\ninstruction tuning, and to further improve its zero-shot performance, we\nexplore multiple transfer learning strategies to leverage the large-scale\nNATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot\nperformance on various unseen multimodal tasks and the benefit of transfer\nlearning from a text-only instruction dataset. We also design a new evaluation\nmetric - Sensitivity, to evaluate how sensitive the model is to the variety of\ninstructions. Our results indicate that fine-tuning the model on a diverse set\nof tasks and instructions leads to a reduced sensitivity to variations in\ninstructions for each task."
  },
  {
    "arxiv_id": "2212.10502",
    "title": "A Measure-Theoretic Characterization of Tight Language Models",
    "url": "http://arxiv.org/abs/2212.10502v1",
    "abstract": "Language modeling, a central task in natural language processing, involves\nestimating a probability distribution over strings. In most cases, the\nestimated distribution sums to 1 over all finite strings. However, in some\npathological cases, probability mass can ``leak'' onto the set of infinite\nsequences. In order to characterize the notion of leakage more precisely, this\npaper offers a measure-theoretic treatment of language modeling. We prove that\nmany popular language model families are in fact tight, meaning that they will\nnot leak in this sense. We also generalize characterizations of tightness\nproposed in previous works."
  },
  {
    "arxiv_id": "2212.10450",
    "title": "Is GPT-3 a Good Data Annotator?",
    "url": "http://arxiv.org/abs/2212.10450v1",
    "abstract": "Data annotation is the process of labeling data that could be used to train\nmachine learning models. Having high-quality annotation is crucial, as it\nallows the model to learn the relationship between the input data and the\ndesired output. GPT-3, a large-scale language model developed by OpenAI, has\ndemonstrated impressive zero- and few-shot performance on a wide range of NLP\ntasks. It is therefore natural to wonder whether it can be used to effectively\nannotate data for NLP tasks. In this paper, we evaluate the performance of\nGPT-3 as a data annotator by comparing it with traditional data annotation\nmethods and analyzing its output on a range of tasks. Through this analysis, we\naim to provide insight into the potential of GPT-3 as a general-purpose data\nannotator in NLP."
  },
  {
    "arxiv_id": "2212.10403",
    "title": "Towards Reasoning in Large Language Models: A Survey",
    "url": "http://arxiv.org/abs/2212.10403v1",
    "abstract": "Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work."
  },
  {
    "arxiv_id": "2212.10325",
    "title": "SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers",
    "url": "http://arxiv.org/abs/2212.10325v1",
    "abstract": "Diffusion model, a new generative modelling paradigm, has achieved great\nsuccess in image, audio, and video generation. However, considering the\ndiscrete categorical nature of text, it is not trivial to extend continuous\ndiffusion models to natural language, and text diffusion models are less\nstudied. Sequence-to-sequence text generation is one of the essential natural\nlanguage processing topics. In this work, we apply diffusion models to approach\nsequence-to-sequence text generation, and explore whether the superiority\ngeneration performance of diffusion model can transfer to natural language\ndomain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence\ngeneration. SeqDiffuSeq uses an encoder-decoder Transformers architecture to\nmodel denoising function. In order to improve generation quality, SeqDiffuSeq\ncombines the self-conditioning technique and a newly proposed adaptive noise\nschedule technique. The adaptive noise schedule has the difficulty of denoising\nevenly distributed across time steps, and considers exclusive noise schedules\nfor tokens at different positional order. Experiment results illustrate the\ngood performance on sequence-to-sequence generation in terms of text quality\nand inference time."
  },
  {
    "arxiv_id": "2212.10025",
    "title": "When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods",
    "url": "http://arxiv.org/abs/2212.10025v1",
    "abstract": "With increasing privacy concerns on data, recent studies have made\nsignificant progress using federated learning (FL) on privacy-sensitive natural\nlanguage processing (NLP) tasks. Much literature suggests fully fine-tuning\npre-trained language models (PLMs) in the FL paradigm can mitigate the data\nheterogeneity problem and close the performance gap with centralized training.\nHowever, large PLMs bring the curse of prohibitive communication overhead and\nlocal model adaptation costs for the FL system. To this end, we introduce\nvarious parameter-efficient tuning (PETuning) methods into federated learning.\nSpecifically, we provide a holistic empirical study of representative PLMs\ntuning methods in FL. The experimental results cover the analysis of data\nheterogeneity levels, data scales, and different FL scenarios. Overall\ncommunication overhead can be significantly reduced by locally tuning and\nglobally aggregating lightweight model parameters while maintaining acceptable\nperformance in various FL settings. To facilitate the research of PETuning in\nFL, we also develop a federated tuning framework FedPETuning, which allows\npractitioners to exploit different PETuning methods under the FL training\nparadigm conveniently. The source code is available at\n\\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}."
  },
  {
    "arxiv_id": "2212.09873",
    "title": "A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models",
    "url": "http://arxiv.org/abs/2212.09873v1",
    "abstract": "There is growing interest in incorporating eye-tracking data and other\nimplicit measures of human language processing into natural language processing\n(NLP) pipelines. The data from human language processing contain unique insight\ninto human linguistic understanding that could be exploited by language models.\nHowever, many unanswered questions remain about the nature of this data and how\nit can best be utilized in downstream NLP tasks. In this paper, we present\neyeStyliency, an eye-tracking dataset for human processing of stylistic text\n(e.g., politeness). We develop a variety of methods to derive style saliency\nscores over text using the collected eye dataset. We further investigate how\nthis saliency data compares to both human annotation methods and model-based\ninterpretability metrics. We find that while eye-tracking data is unique, it\nalso intersects with both human annotations and model-based importance scores,\nproviding a possible bridge between human- and machine-based perspectives. We\npropose utilizing this type of data to evaluate the cognitive plausibility of\nmodels that interpret style. Our eye-tracking data and processing code are\npublicly available."
  },
  {
    "arxiv_id": "2301.09112",
    "title": "Differentially Private Natural Language Models: Recent Advances and Future Directions",
    "url": "http://arxiv.org/abs/2301.09112v1",
    "abstract": "Recent developments in deep learning have led to great success in various\nnatural language processing (NLP) tasks. However, these applications may\ninvolve data that contain sensitive information. Therefore, how to achieve good\nperformance while also protecting the privacy of sensitive data is a crucial\nchallenge in NLP. To preserve privacy, Differential Privacy (DP), which can\nprevent reconstruction attacks and protect against potential side knowledge, is\nbecoming a de facto technique for private data analysis. In recent years, NLP\nin DP models (DP-NLP) has been studied from different perspectives, which\ndeserves a comprehensive review. In this paper, we provide the first systematic\nreview of recent advances in DP deep learning models in NLP. In particular, we\nfirst discuss some differences and additional challenges of DP-NLP compared\nwith the standard DP deep learning. Then, we investigate some existing work on\nDP-NLP and present its recent developments from three aspects: gradient\nperturbation based methods, embedding vector perturbation based methods, and\nensemble model based methods. We also discuss some challenges and future\ndirections."
  },
  {
    "arxiv_id": "2301.09003",
    "title": "Blacks is to Anger as Whites is to Joy? Understanding Latent Affective Bias in Large Pre-trained Neural Language Models",
    "url": "http://arxiv.org/abs/2301.09003v1",
    "abstract": "Groundbreaking inventions and highly significant performance improvements in\ndeep learning based Natural Language Processing are witnessed through the\ndevelopment of transformer based large Pre-trained Language Models (PLMs). The\nwide availability of unlabeled data within human generated data deluge along\nwith self-supervised learning strategy helps to accelerate the success of large\nPLMs in language generation, language understanding, etc. But at the same time,\nlatent historical bias/unfairness in human minds towards a particular gender,\nrace, etc., encoded unintentionally/intentionally into the corpora harms and\nquestions the utility and efficacy of large PLMs in many real-world\napplications, particularly for the protected groups. In this paper, we present\nan extensive investigation towards understanding the existence of \"Affective\nBias\" in large PLMs to unveil any biased association of emotions such as anger,\nfear, joy, etc., towards a particular gender, race or religion with respect to\nthe downstream task of textual emotion detection. We conduct our exploration of\naffective bias from the very initial stage of corpus level affective bias\nanalysis by searching for imbalanced distribution of affective words within a\ndomain, in large scale corpora that are used to pre-train and fine-tune PLMs.\nLater, to quantify affective bias in model predictions, we perform an extensive\nset of class-based and intensity-based evaluations using various bias\nevaluation corpora. Our results show the existence of statistically significant\naffective bias in the PLM based emotion detection systems, indicating biased\nassociation of certain emotions towards a particular gender, race, and\nreligion."
  },
  {
    "arxiv_id": "2301.09992",
    "title": "Multitask Instruction-based Prompting for Fallacy Recognition",
    "url": "http://arxiv.org/abs/2301.09992v1",
    "abstract": "Fallacies are used as seemingly valid arguments to support a position and\npersuade the audience about its validity. Recognizing fallacies is an\nintrinsically difficult task both for humans and machines. Moreover, a big\nchallenge for computational models lies in the fact that fallacies are\nformulated differently across the datasets with differences in the input format\n(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,\nsocial media, dialogue, news), as well as types and number of fallacies (from 5\nto 18 types per dataset). To move towards solving the fallacy recognition task,\nwe approach these differences across datasets as multiple tasks and show how\ninstruction-based prompting in a multitask setup based on the T5 model improves\nthe results against approaches built for a specific dataset such as T5, BERT or\nGPT-3. We show the ability of this multitask prompting approach to recognize 28\nunique fallacies across domains and genres and study the effect of model size\nand prompt choice by analyzing the per-class (i.e., fallacy type) results.\nFinally, we analyze the effect of annotation quality on model performance, and\nthe feasibility of complementing this approach with external knowledge."
  },
  {
    "arxiv_id": "2301.09785",
    "title": "Transformer-Patcher: One Mistake worth One Neuron",
    "url": "http://arxiv.org/abs/2301.09785v1",
    "abstract": "Large Transformer-based Pretrained Language Models (PLMs) dominate almost all\nNatural Language Processing (NLP) tasks. Nevertheless, they still make mistakes\nfrom time to time. For a model deployed in an industrial environment, fixing\nthese mistakes quickly and robustly is vital to improve user experiences.\nPrevious works formalize such problems as Model Editing (ME) and mostly focus\non fixing one mistake. However, the one-mistake-fixing scenario is not an\naccurate abstraction of the real-world challenge. In the deployment of AI\nservices, there are ever-emerging mistakes, and the same mistake may recur if\nnot corrected in time. Thus a preferable solution is to rectify the mistakes as\nsoon as they appear nonstop. Therefore, we extend the existing ME into\nSequential Model Editing (SME) to help develop more practical editing methods.\nOur study shows that most current ME methods could yield unsatisfying results\nin this scenario. We then introduce Transformer-Patcher, a novel model editor\nthat can shift the behavior of transformer-based models by simply adding and\ntraining a few neurons in the last Feed-Forward Network layer. Experimental\nresults on both classification and generation tasks show that\nTransformer-Patcher can successively correct up to thousands of errors\n(Reliability) and generalize to their equivalent inputs (Generality) while\nretaining the model's accuracy on irrelevant inputs (Locality). Our method\noutperforms previous fine-tuning and HyperNetwork-based methods and achieves\nstate-of-the-art performance for Sequential Model Editing (SME). The code is\navailable at https://github.com/ZeroYuHuang/Transformer-Patcher."
  },
  {
    "arxiv_id": "2301.09685",
    "title": "Noisy Parallel Data Alignment",
    "url": "http://arxiv.org/abs/2301.09685v1",
    "abstract": "An ongoing challenge in current natural language processing is how its major\nadvancements tend to disproportionately favor resource-rich languages, leaving\na significant number of under-resourced languages behind. Due to the lack of\nresources required to train and evaluate models, most modern language\ntechnologies are either nonexistent or unreliable to process endangered, local,\nand non-standardized languages. Optical character recognition (OCR) is often\nused to convert endangered language documents into machine-readable data.\nHowever, such OCR output is typically noisy, and most word alignment models are\nnot built to work under such noisy conditions. In this work, we study the\nexisting word-level alignment models under noisy settings and aim to make them\nmore robust to noisy data. Our noise simulation and structural biasing method,\ntested on multiple language pairs, manages to reduce the alignment error rate\non a state-of-the-art neural-based alignment model up to 59.6%."
  },
  {
    "arxiv_id": "2301.10412",
    "title": "BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing",
    "url": "http://arxiv.org/abs/2301.10412v1",
    "abstract": "Deep neural networks (DNNs) and natural language processing (NLP) systems\nhave developed rapidly and have been widely used in various real-world fields.\nHowever, they have been shown to be vulnerable to backdoor attacks.\nSpecifically, the adversary injects a backdoor into the model during the\ntraining phase, so that input samples with backdoor triggers are classified as\nthe target class. Some attacks have achieved high attack success rates on the\npre-trained language models (LMs), but there have yet to be effective defense\nmethods. In this work, we propose a defense method based on deep model mutation\ntesting. Our main justification is that backdoor samples are much more robust\nthan clean samples if we impose random mutations on the LMs and that backdoors\nare generalizable. We first confirm the effectiveness of model mutation testing\nin detecting backdoor samples and select the most appropriate mutation\noperators. We then systematically defend against three extensively studied\nbackdoor attack levels (i.e., char-level, word-level, and sentence-level) by\ndetecting backdoor samples. We also make the first attempt to defend against\nthe latest style-level backdoor attacks. We evaluate our approach on three\nbenchmark datasets (i.e., IMDB, Yelp, and AG news) and three style transfer\ndatasets (i.e., SST-2, Hate-speech, and AG news). The extensive experimental\nresults demonstrate that our approach can detect backdoor samples more\nefficiently and accurately than the three state-of-the-art defense approaches."
  },
  {
    "arxiv_id": "2301.10871",
    "title": "Qualitative Analysis of a Graph Transformer Approach to Addressing Hate Speech: Adapting to Dynamically Changing Content",
    "url": "http://arxiv.org/abs/2301.10871v1",
    "abstract": "Our work advances an approach for predicting hate speech in social media,\ndrawing out the critical need to consider the discussions that follow a post to\nsuccessfully detect when hateful discourse may arise. Using graph transformer\nnetworks, coupled with modelling attention and BERT-level natural language\nprocessing, our approach can capture context and anticipate upcoming\nanti-social behaviour. In this paper, we offer a detailed qualitative analysis\nof this solution for hate speech detection in social networks, leading to\ninsights into where the method has the most impressive outcomes in comparison\nwith competitors and identifying scenarios where there are challenges to\nachieving ideal performance. Included is an exploration of the kinds of posts\nthat permeate social media today, including the use of hateful images. This\nsuggests avenues for extending our model to be more comprehensive. A key\ninsight is that the focus on reasoning about the concept of context positions\nus well to be able to support multi-modal analysis of online posts. We conclude\nwith a reflection on how the problem we are addressing relates especially well\nto the theme of dynamic change, a critical concern for all AI solutions for\nsocial impact. We also comment briefly on how mental health well-being can be\nadvanced with our work, through curated content attuned to the extent of hate\nin posts."
  },
  {
    "arxiv_id": "2301.11847",
    "title": "A Comparative Study of Pretrained Language Models for Long Clinical Text",
    "url": "http://arxiv.org/abs/2301.11847v1",
    "abstract": "Objective: Clinical knowledge enriched transformer models (e.g.,\nClinicalBERT) have state-of-the-art results on clinical NLP (natural language\nprocessing) tasks. One of the core limitations of these transformer models is\nthe substantial memory consumption due to their full self-attention mechanism,\nwhich leads to the performance degradation in long clinical texts. To overcome\nthis, we propose to leverage long-sequence transformer models (e.g., Longformer\nand BigBird), which extend the maximum input sequence length from 512 to 4096,\nto enhance the ability to model long-term dependencies in long clinical texts.\n  Materials and Methods: Inspired by the success of long sequence transformer\nmodels and the fact that clinical notes are mostly long, we introduce two\ndomain enriched language models, Clinical-Longformer and Clinical-BigBird,\nwhich are pre-trained on a large-scale clinical corpus. We evaluate both\nlanguage models using 10 baseline tasks including named entity recognition,\nquestion answering, natural language inference, and document classification\ntasks.\n  Results: The results demonstrate that Clinical-Longformer and\nClinical-BigBird consistently and significantly outperform ClinicalBERT and\nother short-sequence transformers in all 10 downstream tasks and achieve new\nstate-of-the-art results.\n  Discussion: Our pre-trained language models provide the bedrock for clinical\nNLP using long texts. We have made our source code available at\nhttps://github.com/luoyuanlab/Clinical-Longformer, and the pre-trained models\navailable for public download at:\nhttps://huggingface.co/yikuan8/Clinical-Longformer.\n  Conclusion: This study demonstrates that clinical knowledge enriched\nlong-sequence transformers are able to learn long-term dependencies in long\nclinical text. Our methods can also inspire the development of other\ndomain-enriched long-sequence transformers."
  },
  {
    "arxiv_id": "2301.11719",
    "title": "Incorporating Knowledge into Document Summarization: an Application of Prefix-Tuning on GPT-2",
    "url": "http://arxiv.org/abs/2301.11719v1",
    "abstract": "Despite the great development of document summarisation techniques nowadays,\nfactual inconsistencies between the generated summaries and the original texts\nstill occur from time to time. This study explores the possibility of adopting\nprompts to incorporate factual knowledge into generated summaries. We\nspecifically study prefix-tuning that uses a set of trainable continuous prefix\nprompts together with discrete natural language prompts to aid summary\ngeneration. Experimental results demonstrate that the trainable prefixes can\nhelp the summarisation model extract information from discrete prompts\nprecisely, thus generating knowledge-preserving summaries that are factually\nconsistent with the discrete prompts. The ROUGE improvements of the generated\nsummaries indicate that explicitly adding factual knowledge into the\nsummarisation process could boost the overall performance, showing great\npotential for applying it to other natural language processing tasks."
  },
  {
    "arxiv_id": "2301.13003",
    "title": "Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation",
    "url": "http://arxiv.org/abs/2301.13003v1",
    "abstract": "Large-scale pre-trained language models (PLMs) have shown great potential in\nnatural language processing tasks. Leveraging the capabilities of PLMs to\nenhance automatic speech recognition (ASR) systems has also emerged as a\npromising research direction. However, previous works may be limited by the\ninflexible structures of PLMs and the insufficient utilization of PLMs. To\nalleviate these problems, we propose the hierarchical knowledge distillation\n(HKD) on the continuous integrate-and-fire (CIF) based ASR models. To transfer\nknowledge from PLMs to the ASR models, HKD employs cross-modal knowledge\ndistillation with contrastive loss at the acoustic level and knowledge\ndistillation with regression loss at the linguistic level. Compared with the\noriginal CIF-based model, our method achieves 15% and 9% relative error rate\nreduction on the AISHELL-1 and LibriSpeech datasets, respectively."
  },
  {
    "arxiv_id": "2301.12867",
    "title": "Exploring AI Ethics of ChatGPT: A Diagnostic Analysis",
    "url": "http://arxiv.org/abs/2301.12867v1",
    "abstract": "Recent breakthroughs in natural language processing (NLP) have permitted the\nsynthesis and comprehension of coherent text in an open-ended way, therefore\ntranslating the theoretical algorithms into practical applications. The large\nlanguage models (LLMs) have significantly impacted businesses such as report\nsummarization software and copywriters. Observations indicate, however, that\nLLMs may exhibit social prejudice and toxicity, posing ethical and societal\ndangers of consequences resulting from irresponsibility. Large-scale benchmarks\nfor accountable LLMs should consequently be developed. Although several\nempirical investigations reveal the existence of a few ethical difficulties in\nadvanced LLMs, there is little systematic examination and user study of the\nrisks and harmful behaviors of current LLM usage. To further educate future\nefforts on constructing ethical LLMs responsibly, we perform a qualitative\nresearch method called ``red teaming'' on OpenAI's ChatGPT\\footnote{In this\npaper, ChatGPT refers to the version released on Dec 15th.} to better\nunderstand the practical features of ethical dangers in recent LLMs. We analyze\nChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2)\n\\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance\nwith our stated viewpoints, we empirically benchmark ChatGPT on multiple sample\ndatasets. We find that a significant number of ethical risks cannot be\naddressed by existing benchmarks, and hence illustrate them via additional case\nstudies. In addition, we examine the implications of our findings on AI ethics\nand harmal behaviors of ChatGPT, as well as future problems and practical\ndesign considerations for responsible LLMs. We believe that our findings may\ngive light on future efforts to determine and mitigate the ethical hazards\nposed by machines in LLM applications."
  },
  {
    "arxiv_id": "2301.12473",
    "title": "Large Language Models for Biomedical Causal Graph Construction",
    "url": "http://arxiv.org/abs/2301.12473v1",
    "abstract": "The automatic construction of knowledge graphs (KGs) is an important research\narea in medicine, with far-reaching applications spanning drug discovery and\nclinical trial design. These applications hinge on the accurate identification\nof interactions among medical and biological entities. In this study, we\npropose an end-to-end machine learning solution based on large language models\n(LLMs) that utilize electronic medical record notes to construct KGs. The\nentities used in the KG construction process are diseases, factors, treatments,\nas well as manifestations that coexist with the patient while experiencing the\ndisease. Given the critical need for high-quality performance in medical\napplications, we embark on a comprehensive assessment of 12 LLMs of various\narchitectures, evaluating their performance and safety attributes. To gauge the\nquantitative efficacy of our approach by assessing both precision and recall,\nwe manually annotate a dataset provided by the Macula and Retina Institute. We\nalso assess the qualitative performance of LLMs, such as the ability to\ngenerate structured outputs or the tendency to hallucinate. The results\nillustrate that in contrast to encoder-only and encoder-decoder, decoder-only\nLLMs require further investigation. Additionally, we provide guided prompt\ndesign to utilize such LLMs. The application of the proposed methodology is\ndemonstrated on age-related macular degeneration."
  },
  {
    "arxiv_id": "2301.12004",
    "title": "Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation",
    "url": "http://arxiv.org/abs/2301.12004v1",
    "abstract": "Language models have steadily increased in size over the past few years. They\nachieve a high level of performance on various natural language processing\n(NLP) tasks such as question answering and summarization. Large language models\n(LLMs) have been used for generation and can now output human-like text. Due to\nthis, there are other downstream tasks in the realm of dialog that can now\nharness the LLMs' language understanding capabilities. Dialog evaluation is one\ntask that this paper will explore. It concentrates on prompting with LLMs:\nBLOOM, OPT, GPT-3, Flan-T5, InstructDial and TNLGv2. The paper shows that the\nchoice of datasets used for training a model contributes to how well it\nperforms on a task as well as on how the prompt should be structured.\nSpecifically, the more diverse and relevant the group of datasets that a model\nis trained on, the better dialog evaluation performs. This paper also\ninvestigates how the number of examples in the prompt and the type of example\nselection used affect the model's performance."
  },
  {
    "arxiv_id": "2301.13720",
    "title": "Zero-shot cross-lingual transfer language selection using linguistic similarity",
    "url": "http://arxiv.org/abs/2301.13720v1",
    "abstract": "We study the selection of transfer languages for different Natural Language\nProcessing tasks, specifically sentiment analysis, named entity recognition and\ndependency parsing. In order to select an optimal transfer language, we propose\nto utilize different linguistic similarity metrics to measure the distance\nbetween languages and make the choice of transfer language based on this\ninformation instead of relying on intuition. We demonstrate that linguistic\nsimilarity correlates with cross-lingual transfer performance for all of the\nproposed tasks. We also show that there is a statistically significant\ndifference in choosing the optimal language as the transfer source instead of\nEnglish. This allows us to select a more suitable transfer language which can\nbe used to better leverage knowledge from high-resource languages in order to\nimprove the performance of language applications lacking data. For the study,\nwe used datasets from eight different languages from three language families."
  },
  {
    "arxiv_id": "2301.13670",
    "title": "What Makes Good Examples for Visual In-Context Learning?",
    "url": "http://arxiv.org/abs/2301.13670v2",
    "abstract": "Large-scale models trained on broad data have recently become the mainstream\narchitecture in computer vision due to their strong generalization performance.\nIn this paper, the main focus is on an emergent ability in large vision models,\nknown as in-context learning, which allows inference on unseen tasks by\nconditioning on in-context examples (a.k.a.~prompt) without updating the model\nparameters. This concept has been well-known in natural language processing but\nhas only been studied very recently for large vision models. We for the first\ntime provide a comprehensive investigation on the impact of in-context examples\nin computer vision, and find that the performance is highly sensitive to the\nchoice of in-context examples. To overcome the problem, we propose a prompt\nretrieval framework to automate the selection of in-context examples.\nSpecifically, we present (1) an unsupervised prompt retrieval method based on\nnearest example search using an off-the-shelf model, and (2) a supervised\nprompt retrieval method, which trains a neural network to choose examples that\ndirectly maximize in-context learning performance. The results demonstrate that\nour methods can bring non-trivial improvements to visual in-context learning in\ncomparison to the commonly-used random selection."
  },
  {
    "arxiv_id": "2302.00456",
    "title": "Feed-Forward Blocks Control Contextualization in Masked Language Models",
    "url": "http://arxiv.org/abs/2302.00456v1",
    "abstract": "Transformers are ubiquitous in wide tasks. Interpreting their internals is a\npivotal goal. Nevertheless, their particular components, feed-forward (FF)\nblocks, have typically been less analyzed despite their substantial parameter\namounts. We analyze the input contextualization effects of FF blocks by\nrendering them in the attention maps as a human-friendly visualization scheme.\nOur experiments with both masked- and causal-language models reveal that FF\nnetworks modify the input contextualization to emphasize specific types of\nlinguistic compositions. In addition, FF and its surrounding components tend to\ncancel out each other's effects, suggesting potential redundancy in the\nprocessing of the Transformer layer."
  },
  {
    "arxiv_id": "2302.00093",
    "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context",
    "url": "http://arxiv.org/abs/2302.00093v1",
    "abstract": "Large language models have achieved impressive performance on various natural\nlanguage processing tasks. However, so far they have been evaluated primarily\non benchmarks where all information in the input context is relevant for\nsolving the task. In this work, we investigate the distractibility of large\nlanguage models, i.e., how the model problem-solving accuracy can be influenced\nby irrelevant context. In particular, we introduce Grade-School Math with\nIrrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant\ninformation in the problem description. We use this benchmark to measure the\ndistractibility of cutting-edge prompting techniques for large language models,\nand find that the model performance is dramatically decreased when irrelevant\ninformation is included. We also identify several approaches for mitigating\nthis deficiency, such as decoding with self-consistency and adding to the\nprompt an instruction that tells the language model to ignore the irrelevant\ninformation."
  },
  {
    "arxiv_id": "2302.00856",
    "title": "idT5: Indonesian Version of Multilingual T5 Transformer",
    "url": "http://arxiv.org/abs/2302.00856v1",
    "abstract": "Indonesian language is spoken by almost 200 million people and is the 10th\nmost spoken language in the world, but it is under-represented in NLP (Natural\nLanguage Processing) research. A sparsity of language resources has hampered\nprevious work on Indonesian. The Transformer is a new architecture rapidly\nbecoming dominant for NLP, surpassing alternatives like convolutional and\nrecurrent neural networks. T5 (Text-to-Text Transfer Transformer) is a\nTransformer model that converts all text-based language problems to\ntext-to-text format for English. The multilingual variant is mT5 (multilingual\nT5) which has shown promising results on many NLP tasks across languages.\nHowever, the size of this multilingual model is a drawback for its application\nin real production applications, which sometimes require only one language. In\nthis study, the mT5 model was adapted for only one language, Indonesian,\nresulting in a pre-trained T5 model that was specific only for Indonesian with\na smaller size. For performance comparison, we fine-tuned this model and the\nmT5 model to the Sentiment Analysis (SA), Question Generation (QG), and\nQuestion Answering (QA) tasks with the exact mechanism and dataset. Fine-tuned\nmodel based on our model achieved 77.18% accuracy on SA, 8% higher than the\nmT5-based model, and obtained nearly the same score as the mT5-based model on\nQG and QA. The results confirm that it is possible to produce a smaller\npre-trained model that maintains comparable yields while reducing the model\nsize by up to 58%. In addition, the resulting model requires less memory, loads\nfaster, and inference times faster."
  },
  {
    "arxiv_id": "2302.01806",
    "title": "Mitigating Data Scarcity for Large Language Models",
    "url": "http://arxiv.org/abs/2302.01806v1",
    "abstract": "In recent years, pretrained neural language models (PNLMs) have taken the\nfield of natural language processing by storm, achieving new benchmarks and\nstate-of-the-art performances. These models often rely heavily on annotated\ndata, which may not always be available. Data scarcity are commonly found in\nspecialized domains, such as medical, or in low-resource languages that are\nunderexplored by AI research. In this dissertation, we focus on mitigating data\nscarcity using data augmentation and neural ensemble learning techniques for\nneural language models. In both research directions, we implement neural\nnetwork algorithms and evaluate their impact on assisting neural language\nmodels in downstream NLP tasks. Specifically, for data augmentation, we explore\ntwo techniques: 1) creating positive training data by moving an answer span\naround its original context and 2) using text simplification techniques to\nintroduce a variety of writing styles to the original training data. Our\nresults indicate that these simple and effective solutions improve the\nperformance of neural language models considerably in low-resource NLP domains\nand tasks. For neural ensemble learning, we use a multilabel neural classifier\nto select the best prediction outcome from a variety of individual pretrained\nneural language models trained for a low-resource medical text simplification\ntask."
  },
  {
    "arxiv_id": "2302.01588",
    "title": "Bioformer: an efficient transformer language model for biomedical text mining",
    "url": "http://arxiv.org/abs/2302.01588v1",
    "abstract": "Pretrained language models such as Bidirectional Encoder Representations from\nTransformers (BERT) have achieved state-of-the-art performance in natural\nlanguage processing (NLP) tasks. Recently, BERT has been adapted to the\nbiomedical domain. Despite the effectiveness, these models have hundreds of\nmillions of parameters and are computationally expensive when applied to\nlarge-scale NLP applications. We hypothesized that the number of parameters of\nthe original BERT can be dramatically reduced with minor impact on performance.\nIn this study, we present Bioformer, a compact BERT model for biomedical text\nmining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)\nwhich reduced the model size by 60% compared to BERTBase. Bioformer uses a\nbiomedical vocabulary and was pre-trained from scratch on PubMed abstracts and\nPubMed Central full-text articles. We thoroughly evaluated the performance of\nBioformer as well as existing biomedical BERT models including BioBERT and\nPubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:\nnamed entity recognition, relation extraction, question answering and document\nclassification. The results show that with 60% fewer parameters, Bioformer16L\nis only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less\naccurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed\nBioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as\nfast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed\nto PubTator Central providing gene annotations over 35 million PubMed abstracts\nand 5 million PubMed Central full-text articles. We make Bioformer publicly\navailable via https://github.com/WGLab/bioformer, including pre-trained models,\ndatasets, and instructions for downstream use."
  },
  {
    "arxiv_id": "2302.01483",
    "title": "SPADE: Self-supervised Pretraining for Acoustic DisEntanglement",
    "url": "http://arxiv.org/abs/2302.01483v1",
    "abstract": "Self-supervised representation learning approaches have grown in popularity\ndue to the ability to train models on large amounts of unlabeled data and have\ndemonstrated success in diverse fields such as natural language processing,\ncomputer vision, and speech. Previous self-supervised work in the speech domain\nhas disentangled multiple attributes of speech such as linguistic content,\nspeaker identity, and rhythm. In this work, we introduce a self-supervised\napproach to disentangle room acoustics from speech and use the acoustic\nrepresentation on the downstream task of device arbitration. Our results\ndemonstrate that our proposed approach significantly improves performance over\na baseline when labeled training data is scarce, indicating that our\npretraining scheme learns to encode room acoustic information while remaining\ninvariant to other attributes of the speech signal."
  },
  {
    "arxiv_id": "2302.01441",
    "title": "Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation",
    "url": "http://arxiv.org/abs/2302.01441v1",
    "abstract": "Improving the emotional awareness of pre-trained language models is an\nemerging important problem for dialogue generation tasks. Although prior\nstudies have introduced methods to improve empathetic dialogue generation, few\nhave discussed how to incorporate commonsense knowledge into pre-trained\nlanguage models for controllable dialogue generation. In this study, we propose\na novel framework that improves empathetic dialogue generation using\npre-trained language models by 1) incorporating commonsense knowledge through\nprompt verbalization, and 2) controlling dialogue generation using a\nstrategy-driven future discriminator. We conducted experiments to reveal that\nboth the incorporation of social commonsense knowledge and enforcement of\ncontrol over generation help to improve generation performance. Finally, we\ndiscuss the implications of our study for future research."
  },
  {
    "arxiv_id": "2302.02108",
    "title": "Knowledge Distillation in Vision Transformers: A Critical Review",
    "url": "http://arxiv.org/abs/2302.02108v1",
    "abstract": "In Natural Language Processing (NLP), Transformers have already\nrevolutionized the field by utilizing an attention-based encoder-decoder model.\nRecently, some pioneering works have employed Transformer-like architectures in\nComputer Vision (CV) and they have reported outstanding performance of these\narchitectures in tasks such as image classification, object detection, and\nsemantic segmentation. Vision Transformers (ViTs) have demonstrated impressive\nperformance improvements over Convolutional Neural Networks (CNNs) due to their\ncompetitive modelling capabilities. However, these architectures demand massive\ncomputational resources which makes these models difficult to be deployed in\nthe resource-constrained applications. Many solutions have been developed to\ncombat this issue, such as compressive transformers and compression functions\nsuch as dilated convolution, min-max pooling, 1D convolution, etc. Model\ncompression has recently attracted considerable research attention as a\npotential remedy. A number of model compression methods have been proposed in\nthe literature such as weight quantization, weight multiplexing, pruning and\nKnowledge Distillation (KD). However, techniques like weight quantization,\npruning and weight multiplexing typically involve complex pipelines for\nperforming the compression. KD has been found to be a simple and much effective\nmodel compression technique that allows a relatively simple model to perform\ntasks almost as accurately as a complex model. This paper discusses various\napproaches based upon KD for effective compression of ViT models. The paper\nelucidates the role played by KD in reducing the computational and memory\nrequirements of these models. The paper also presents the various challenges\nfaced by ViTs that are yet to be resolved."
  },
  {
    "arxiv_id": "2302.03353",
    "title": "What do Language Models know about word senses? Zero-Shot WSD with Language Models and Domain Inventories",
    "url": "http://arxiv.org/abs/2302.03353v1",
    "abstract": "Language Models are the core for almost any Natural Language Processing\nsystem nowadays. One of their particularities is their contextualized\nrepresentations, a game changer feature when a disambiguation between word\nsenses is necessary. In this paper we aim to explore to what extent language\nmodels are capable of discerning among senses at inference time. We performed\nthis analysis by prompting commonly used Languages Models such as BERT or\nRoBERTa to perform the task of Word Sense Disambiguation (WSD). We leverage the\nrelation between word senses and domains, and cast WSD as a textual entailment\nproblem, where the different hypothesis refer to the domains of the word\nsenses. Our results show that this approach is indeed effective, close to\nsupervised systems."
  },
  {
    "arxiv_id": "2302.03241",
    "title": "Continual Learning of Language Models",
    "url": "http://arxiv.org/abs/2302.03241v1",
    "abstract": "Language models (LMs) have been instrumental for the rapid advance of natural\nlanguage processing. This paper studies continual pre-training of LMs, in\nparticular, continual domain-adaptive pre-training (or continual DAP-training).\nExisting research has shown that further pre-training an LM using a domain\ncorpus to adapt the LM to the domain can improve the end-task performance in\nthe domain. This paper proposes a novel method to continually DAP-train an LM\nwith a sequence of unlabeled domain corpora to adapt the LM to these domains to\nimprove their end-task performances. The key novelty of our method is a\nsoft-masking mechanism that directly controls the update to the LM. A novel\nproxy is also proposed to preserve the general knowledge in the original LM.\nAdditionally, it contrasts the representations of the previously learned domain\nknowledge (including the general knowledge in the pre-trained LM) and the\nknowledge from the current full network to achieve knowledge integration. The\nmethod not only overcomes catastrophic forgetting, but also achieves knowledge\ntransfer to improve end-task performances. Empirical evaluation demonstrates\nthe effectiveness of the proposed method."
  },
  {
    "arxiv_id": "2302.03488",
    "title": "APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning",
    "url": "http://arxiv.org/abs/2302.03488v1",
    "abstract": "Practical natural language processing (NLP) tasks are commonly long-tailed\nwith noisy labels. Those problems challenge the generalization and robustness\nof complex models such as Deep Neural Networks (DNNs). Some commonly used\nresampling techniques, such as oversampling or undersampling, could easily lead\nto overfitting. It is growing popular to learn the data weights leveraging a\nsmall amount of metadata. Besides, recent studies have shown the advantages of\nself-supervised pre-training, particularly to the under-represented data. In\nthis work, we propose a general framework to handle the problem of both\nlong-tail and noisy labels. The model is adapted to the domain of problems in a\ncontrastive learning manner. The re-weighting module is a feed-forward network\nthat learns explicit weighting functions and adapts weights according to\nmetadata. The framework further adapts weights of terms in the loss function\nthrough a combination of the polynomial expansion of cross-entropy loss and\nfocal loss. Our extensive experiments show that the proposed framework\nconsistently outperforms baseline methods. Lastly, our sensitive analysis\nemphasizes the capability of the proposed framework to handle the long-tailed\nproblem and mitigate the negative impact of noisy labels."
  },
  {
    "arxiv_id": "2302.04116",
    "title": "Training-free Lexical Backdoor Attacks on Language Models",
    "url": "http://arxiv.org/abs/2302.04116v1",
    "abstract": "Large-scale language models have achieved tremendous success across various\nnatural language processing (NLP) applications. Nevertheless, language models\nare vulnerable to backdoor attacks, which inject stealthy triggers into models\nfor steering them to undesirable behaviors. Most existing backdoor attacks,\nsuch as data poisoning, require further (re)training or fine-tuning language\nmodels to learn the intended backdoor patterns. The additional training process\nhowever diminishes the stealthiness of the attacks, as training a language\nmodel usually requires long optimization time, a massive amount of data, and\nconsiderable modifications to the model parameters. In this work, we propose\nTraining-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free\nbackdoor attack on language models. Our attack is achieved by injecting lexical\ntriggers into the tokenizer of a language model via manipulating its embedding\ndictionary using carefully designed rules. These rules are explainable to human\ndevelopers which inspires attacks from a wider range of hackers. The sparse\nmanipulation of the dictionary also habilitates the stealthiness of our attack.\nWe conduct extensive experiments on three dominant NLP tasks based on nine\nlanguage models to demonstrate the effectiveness and universality of our\nattack. The code of this work is available at\nhttps://github.com/Jinxhy/TFLexAttack."
  },
  {
    "arxiv_id": "2302.04048",
    "title": "Automating Code-Related Tasks Through Transformers: The Impact of Pre-training",
    "url": "http://arxiv.org/abs/2302.04048v1",
    "abstract": "Transformers have gained popularity in the software engineering (SE)\nliterature. These deep learning models are usually pre-trained through a\nself-supervised objective, meant to provide the model with basic knowledge\nabout a language of interest (e.g., Java). A classic pre-training objective is\nthe masked language model (MLM), in which a percentage of tokens from the input\n(e.g., a Java method) is masked, with the model in charge of predicting them.\nOnce pre-trained, the model is then fine-tuned to support the specific\ndownstream task of interest (e.g., code summarization). While there is evidence\nsuggesting the boost in performance provided by pre-training, little is known\nabout the impact of the specific pre-training objective(s) used. Indeed, MLM is\njust one of the possible pre-training objectives and recent work from the\nnatural language processing field suggest that pre-training objectives tailored\nfor the specific downstream task of interest may substantially boost the\nmodel's performance. In this study, we focus on the impact of pre-training\nobjectives on the performance of transformers when automating code-related\ntasks. We start with a systematic literature review aimed at identifying the\npre-training objectives used in SE. Then, we pre-train 32 transformers using\nboth (i) generic pre-training objectives usually adopted in SE; and (ii)\npre-training objectives tailored to specific code-related tasks subject of our\nexperimentation, namely bug-fixing, code summarization, and code completion. We\nalso compare the pre-trained models with non pre-trained ones. Our results show\nthat: (i) pre-training helps in boosting performance only if the amount of\nfine-tuning data available is small; (ii) the MLM objective is usually\nsufficient to maximize the prediction performance of the model, even when\ncomparing it with pre-training objectives specialized for the downstream task\nat hand."
  },
  {
    "arxiv_id": "2302.04045",
    "title": "Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models",
    "url": "http://arxiv.org/abs/2302.04045v1",
    "abstract": "Recent transformer language models achieve outstanding results in many\nnatural language processing (NLP) tasks. However, their enormous size often\nmakes them impractical on memory-constrained devices, requiring practitioners\nto compress them to smaller networks. In this paper, we explore offline\ncompression methods, meaning computationally-cheap approaches that do not\nrequire further fine-tuning of the compressed model. We challenge the classical\nmatrix factorization methods by proposing a novel, better-performing\nautoencoder-based framework. We perform a comprehensive ablation study of our\napproach, examining its different aspects over a diverse set of evaluation\nsettings. Moreover, we show that enabling collaboration between modules across\nlayers by compressing certain modules together positively impacts the final\nmodel performance. Experiments on various NLP tasks demonstrate that our\napproach significantly outperforms commonly used factorization-based offline\ncompression methods."
  },
  {
    "arxiv_id": "2302.03927",
    "title": "On the Applicability of Language Models to Block-Based Programs",
    "url": "http://arxiv.org/abs/2302.03927v1",
    "abstract": "Block-based programming languages like Scratch are increasingly popular for\nprogramming education and end-user programming. Recent program analyses build\non the insight that source code can be modelled using techniques from natural\nlanguage processing. Many of the regularities of source code that support this\napproach are due to the syntactic overhead imposed by textual programming\nlanguages. This syntactic overhead, however, is precisely what block-based\nlanguages remove in order to simplify programming. Consequently, it is unclear\nhow well this modelling approach performs on block-based programming languages.\nIn this paper, we investigate the applicability of language models for the\npopular block-based programming language Scratch. We model Scratch programs\nusing n-gram models, the most essential type of language model, and\ntransformers, a popular deep learning model. Evaluation on the example tasks of\ncode completion and bug finding confirm that blocks inhibit predictability, but\nthe use of language models is nevertheless feasible. Our findings serve as\nfoundation for improving tooling and analyses for block-based languages."
  },
  {
    "arxiv_id": "2302.03735",
    "title": "Pre-train, Prompt and Recommendation: A Comprehensive Survey of Language Modelling Paradigm Adaptations in Recommender Systems",
    "url": "http://arxiv.org/abs/2302.03735v1",
    "abstract": "The emergence of Pre-trained Language Models (PLMs) has achieved tremendous\nsuccess in the field of Natural Language Processing (NLP) by learning universal\nrepresentations on large corpora in a self-supervised manner. The pre-trained\nmodels and the learned representations can be beneficial to a series of\ndownstream NLP tasks. This training paradigm has recently been adapted to the\nrecommendation domain and is considered a promising approach by both academia\nand industry. In this paper, we systematically investigate how to extract and\ntransfer knowledge from pre-trained models learned by different PLM-related\ntraining paradigms to improve recommendation performance from various\nperspectives, such as generality, sparsity, efficiency and effectiveness.\nSpecifically, we propose a comprehensive taxonomy to divide existing PLM-based\nrecommender systems w.r.t. their training strategies and objectives. Then, we\nanalyze and summarize the connection between PLM-based training paradigms and\ndifferent input data types for recommender systems. Finally, we elaborate on\nopen issues and future research directions in this vibrant field."
  },
  {
    "arxiv_id": "2302.04790",
    "title": "Massively Multilingual Language Models for Cross Lingual Fact Extraction from Low Resource Indian Languages",
    "url": "http://arxiv.org/abs/2302.04790v1",
    "abstract": "Massive knowledge graphs like Wikidata attempt to capture world knowledge\nabout multiple entities. Recent approaches concentrate on automatically\nenriching these KGs from text. However a lot of information present in the form\nof natural text in low resource languages is often missed out. Cross Lingual\nInformation Extraction aims at extracting factual information in the form of\nEnglish triples from low resource Indian Language text. Despite its massive\npotential, progress made on this task is lagging when compared to Monolingual\nInformation Extraction. In this paper, we propose the task of Cross Lingual\nFact Extraction(CLFE) from text and devise an end-to-end generative approach\nfor the same which achieves an overall F1 score of 77.46."
  },
  {
    "arxiv_id": "2302.04725",
    "title": "Lightweight Transformers for Clinical Natural Language Processing",
    "url": "http://arxiv.org/abs/2302.04725v1",
    "abstract": "Specialised pre-trained language models are becoming more frequent in NLP\nsince they can potentially outperform models trained on generic texts. BioBERT\nand BioClinicalBERT are two examples of such models that have shown promise in\nmedical NLP tasks. Many of these models are overparametrised and\nresource-intensive, but thanks to techniques like Knowledge Distillation (KD),\nit is possible to create smaller versions that perform almost as well as their\nlarger counterparts. In this work, we specifically focus on development of\ncompact language models for processing clinical texts (i.e. progress notes,\ndischarge summaries etc). We developed a number of efficient lightweight\nclinical transformers using knowledge distillation and continual learning, with\nthe number of parameters ranging from 15 million to 65 million. These models\nperformed comparably to larger models such as BioBERT and ClinicalBioBERT and\nsignificantly outperformed other compact models trained on general or\nbiomedical data. Our extensive evaluation was done across several standard\ndatasets and covered a wide range of clinical text-mining tasks, including\nNatural Language Inference, Relation Extraction, Named Entity Recognition, and\nSequence Classification. To our knowledge, this is the first comprehensive\nstudy specifically focused on creating efficient and compact transformers for\nclinical NLP tasks. The models and code used in this study can be found on our\nHuggingface profile at https://huggingface.co/nlpie and Github page at\nhttps://github.com/nlpie-research/Lightweight-Clinical-Transformers,\nrespectively, promoting reproducibility of our results."
  },
  {
    "arxiv_id": "2302.04443",
    "title": "Enhancing E-Commerce Recommendation using Pre-Trained Language Model and Fine-Tuning",
    "url": "http://arxiv.org/abs/2302.04443v1",
    "abstract": "Pretrained Language Models (PLM) have been greatly successful on a board\nrange of natural language processing (NLP) tasks. However, it has just started\nbeing applied to the domain of recommendation systems. Traditional\nrecommendation algorithms failed to incorporate the rich textual information in\ne-commerce datasets, which hinderss the performance of those models. We present\na thorough investigation on the effect of various strategy of incorporating\nPLMs into traditional recommender algorithms on one of the e-commerce datasets,\nand we compare the results with vanilla recommender baseline models. We show\nthat the application of PLMs and domain specific fine-tuning lead to an\nincrease on the predictive capability of combined models. These results\naccentuate the importance of utilizing textual information in the context of\ne-commerce, and provides insight on how to better apply PLMs alongside\ntraditional recommender system algorithms. The code used in this paper is\navailable on Github: https://github.com/NuofanXu/bert_retail_recommender."
  },
  {
    "arxiv_id": "2302.05128",
    "title": "Translating Natural Language to Planning Goals with Large-Language Models",
    "url": "http://arxiv.org/abs/2302.05128v1",
    "abstract": "Recent large language models (LLMs) have demonstrated remarkable performance\non a variety of natural language processing (NLP) tasks, leading to intense\nexcitement about their applicability across various domains. Unfortunately,\nrecent work has also shown that LLMs are unable to perform accurate reasoning\nnor solve planning problems, which may limit their usefulness for\nrobotics-related tasks. In this work, our central question is whether LLMs are\nable to translate goals specified in natural language to a structured planning\nlanguage. If so, LLM can act as a natural interface between the planner and\nhuman users; the translated goal can be handed to domain-independent AI\nplanners that are very effective at planning. Our empirical results on GPT 3.5\nvariants show that LLMs are much better suited towards translation rather than\nplanning. We find that LLMs are able to leverage commonsense knowledge and\nreasoning to furnish missing details from under-specified goals (as is often\nthe case in natural language). However, our experiments also reveal that LLMs\ncan fail to generate goals in tasks that involve numerical or physical (e.g.,\nspatial) reasoning, and that LLMs are sensitive to the prompts used. As such,\nthese models are promising for translation to structured planning languages,\nbut care should be taken in their use."
  },
  {
    "arxiv_id": "2302.04914",
    "title": "Flexible, Model-Agnostic Method for Materials Data Extraction from Text Using General Purpose Language Models",
    "url": "http://arxiv.org/abs/2302.04914v1",
    "abstract": "Accurate and comprehensive material databases extracted from research papers\nare crucial for materials science and engineering, but their development\nrequires significant human effort. With large language models (LLMs)\ntransforming the way humans interact with text, LLMs provide an opportunity to\nrevolutionize data extraction. In this study, we demonstrate a simple and\nefficient method for extracting materials data from full-text research papers\nleveraging the capabilities of LLMs combined with human supervision. This\napproach is particularly suitable for mid-sized databases and requires minimal\nto no coding or prior knowledge about the extracted property. It offers high\nrecall and nearly perfect precision in the resulting database. The method is\neasily adaptable to new and superior language models, ensuring continued\nutility. We show this by evaluating and comparing its performance on GPT-3 and\nGPT-3.5/4 (which underlie ChatGPT), as well as free alternatives such as BART\nand DeBERTaV3. We provide a detailed analysis of the method's performance in\nextracting sentences containing bulk modulus data, achieving up to 90%\nprecision at 96% recall, depending on the amount of human effort involved. We\nfurther demonstrate the method's broader effectiveness by developing a database\nof critical cooling rates for metallic glasses over twice the size of previous\nhuman curated databases."
  },
  {
    "arxiv_id": "2302.06426",
    "title": "Linguistic ambiguity analysis in ChatGPT",
    "url": "http://arxiv.org/abs/2302.06426v1",
    "abstract": "Linguistic ambiguity is and has always been one of the main challenges in\nNatural Language Processing (NLP) systems. Modern Transformer architectures\nlike BERT, T5 or more recently InstructGPT have achieved some impressive\nimprovements in many NLP fields, but there is still plenty of work to do.\nMotivated by the uproar caused by ChatGPT, in this paper we provide an\nintroduction to linguistic ambiguity, its varieties and their relevance in\nmodern NLP, and perform an extensive empiric analysis. ChatGPT strengths and\nweaknesses are revealed, as well as strategies to get the most of this model."
  },
  {
    "arxiv_id": "2302.06951",
    "title": "Few-shot learning approaches for classifying low resource domain specific software requirements",
    "url": "http://arxiv.org/abs/2302.06951v1",
    "abstract": "With the advent of strong pre-trained natural language processing models like\nBERT, DeBERTa, MiniLM, T5, the data requirement for industries to fine-tune\nthese models to their niche use cases has drastically reduced (typically to a\nfew hundred annotated samples for achieving a reasonable performance). However,\nthe availability of even a few hundred annotated samples may not always be\nguaranteed in low resource domains like automotive, which often limits the\nusage of such deep learning models in an industrial setting. In this paper we\naim to address the challenge of fine-tuning such pre-trained models with only a\nfew annotated samples, also known as Few-shot learning. Our experiments focus\non evaluating the performance of a diverse set of algorithms and methodologies\nto achieve the task of classifying BOSCH automotive domain textual software\nrequirements into 3 categories, while utilizing only 15 annotated samples per\ncategory for fine-tuning. We find that while SciBERT and DeBERTa based models\ntend to be the most accurate at 15 training samples, their performance\nimprovement scales minimally as the number of annotated samples is increased to\n50 in comparison to Siamese and T5 based models."
  },
  {
    "arxiv_id": "2302.06868",
    "title": "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains",
    "url": "http://arxiv.org/abs/2302.06868v1",
    "abstract": "Prompting pre-trained language models leads to promising results across\nnatural language processing tasks but is less effective when applied in\nlow-resource domains, due to the domain gap between the pre-training data and\nthe downstream task. In this work, we bridge this gap with a novel and\nlightweight prompting methodology called SwitchPrompt for the adaptation of\nlanguage models trained on datasets from the general domain to diverse\nlow-resource domains. Using domain-specific keywords with a trainable gated\nprompt, SwitchPrompt offers domain-oriented prompting, that is, effective\nguidance on the target domains for general-domain language models. Our few-shot\nexperiments on three text classification benchmarks demonstrate the efficacy of\nthe general-domain pre-trained language models when used with SwitchPrompt.\nThey often even outperform their domain-specific counterparts trained with\nbaseline state-of-the-art prompting methods by up to 10.7% performance increase\nin accuracy. This result indicates that SwitchPrompt effectively reduces the\nneed for domain-specific language model pre-training."
  },
  {
    "arxiv_id": "2302.06761",
    "title": "Language Model Analysis for Ontology Subsumption Inference",
    "url": "http://arxiv.org/abs/2302.06761v1",
    "abstract": "Investigating whether pre-trained language models (LMs) can function as\nknowledge bases (KBs) has raised wide research interests recently. However,\nexisting works focus on simple, triple-based, relational KBs, but omit more\nsophisticated, logic-based, conceptualised KBs such as OWL ontologies. To\ninvestigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of\ninference-based probing tasks and datasets from ontology subsumption axioms\ninvolving both atomic and complex concepts. We conduct extensive experiments on\nontologies of different domains and scales, and our results demonstrate that\nLMs encode relatively less background knowledge of Subsumption Inference (SI)\nthan traditional Natural Language Inference (NLI) but can improve on SI\nsignificantly when a small number of samples are given. We will open-source our\ncode and datasets."
  },
  {
    "arxiv_id": "2302.07863",
    "title": "Big Little Transformer Decoder",
    "url": "http://arxiv.org/abs/2302.07863v1",
    "abstract": "The recent emergence of Large Language Models based on the Transformer\narchitecture has enabled dramatic advancements in the field of Natural Language\nProcessing. However, these models have long inference latency, which limits\ntheir deployment and makes them prohibitively expensive for various real-time\napplications. The inference latency is further exacerbated by autoregressive\ngenerative tasks, as models need to run iteratively to generate tokens\nsequentially without leveraging token-level parallelization. To address this,\nwe propose Big Little Decoder (BiLD), a framework that can improve inference\nefficiency and latency for a wide range of text generation applications. The\nBiLD framework contains two models with different sizes that collaboratively\ngenerate text. The small model runs autoregressively to generate text with a\nlow inference cost, and the large model is only invoked occasionally to refine\nthe small model's inaccurate predictions in a non-autoregressive manner. To\ncoordinate the small and large models, BiLD introduces two simple yet effective\npolicies: (1) the fallback policy that determines when to hand control over to\nthe large model; and (2) the rollback policy that determines when the large\nmodel needs to correct the small model's inaccurate predictions. To evaluate\nour framework across different tasks and models, we apply BiLD to various text\ngeneration scenarios encompassing machine translation on IWSLT 2017 De-En and\nWMT 2014 De-En, and summarization on XSUM and CNN/DailyMail. On an NVIDIA T4\nGPU, our framework achieves a speedup of up to 2.12x speedup with minimal\ngeneration quality degradation. Furthermore, our framework is fully\nplug-and-play and can be applied without any modifications in the training\nprocess or model architecture. Our code is open-sourced"
  },
  {
    "arxiv_id": "2302.07388",
    "title": "Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models",
    "url": "http://arxiv.org/abs/2302.07388v1",
    "abstract": "Pretrained large language models have become indispensable for solving\nvarious natural language processing (NLP) tasks. However, safely deploying them\nin real world applications is challenging because they generate toxic content.\nTo address this challenge, we propose two novel pretraining data augmentation\nstrategies that significantly reduce model toxicity without compromising its\nutility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data\nto the pretraining samples, and (2) INST: adds instructions to those samples\nindicating their toxicity. Our results indicate that our best performing\nstrategy (INST) substantially reduces the toxicity probability up to 61% while\npreserving the accuracy on five benchmark NLP tasks as well as improving AUC\nscores on four bias detection tasks by 1.3%. We also demonstrate the\ngeneralizability of our techniques by scaling the number of training samples\nand the number of model parameters."
  },
  {
    "arxiv_id": "2302.08374",
    "title": "Efficiency 360: Efficient Vision Transformers",
    "url": "http://arxiv.org/abs/2302.08374v2",
    "abstract": "Transformers are widely used for solving tasks in natural language\nprocessing, computer vision, speech, and music domains. In this paper, we talk\nabout the efficiency of transformers in terms of memory (the number of\nparameters), computation cost (number of floating points operations), and\nperformance of models, including accuracy, the robustness of the model, and\nfair \\& bias-free features. We mainly discuss the vision transformer for the\nimage classification task. Our contribution is to introduce an efficient 360\nframework, which includes various aspects of the vision transformer, to make it\nmore efficient for industrial applications. By considering those applications,\nwe categorize them into multiple dimensions such as privacy, robustness,\ntransparency, fairness, inclusiveness, continual learning, probabilistic\nmodels, approximation, computational complexity, and spectral complexity. We\ncompare various vision transformer models based on their performance, the\nnumber of parameters, and the number of floating point operations (FLOPs) on\nmultiple datasets."
  },
  {
    "arxiv_id": "2302.08102",
    "title": "Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition",
    "url": "http://arxiv.org/abs/2302.08102v1",
    "abstract": "Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID."
  },
  {
    "arxiv_id": "2302.08081",
    "title": "Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization",
    "url": "http://arxiv.org/abs/2302.08081v1",
    "abstract": "Text summarization has been a crucial problem in natural language processing\n(NLP) for several decades. It aims to condense lengthy documents into shorter\nversions while retaining the most critical information. Various methods have\nbeen proposed for text summarization, including extractive and abstractive\nsummarization. The emergence of large language models (LLMs) like GPT3 and\nChatGPT has recently created significant interest in using these models for\ntext summarization tasks. Recent studies \\cite{goyal2022news,\nzhang2023benchmarking} have shown that LLMs-generated news summaries are\nalready on par with humans. However, the performance of LLMs for more practical\napplications like aspect or query-based summaries is underexplored. To fill\nthis gap, we conducted an evaluation of ChatGPT's performance on four widely\nused benchmark datasets, encompassing diverse summaries from Reddit posts, news\narticles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's\nperformance is comparable to traditional fine-tuning methods in terms of Rouge\nscores. Moreover, we highlight some unique differences between\nChatGPT-generated summaries and human references, providing valuable insights\ninto the superpower of ChatGPT for diverse text summarization tasks. Our\nfindings call for new directions in this area, and we plan to conduct further\nresearch to systematically examine the characteristics of ChatGPT-generated\nsummaries through extensive human evaluation."
  },
  {
    "arxiv_id": "2302.08068",
    "title": "LabelPrompt: Effective Prompt-based Learning for Relation Classification",
    "url": "http://arxiv.org/abs/2302.08068v1",
    "abstract": "Recently, prompt-based learning has gained popularity across many natural\nlanguage processing (NLP) tasks by reformulating them into a cloze-style format\nto better align pre-trained language models (PLMs) with downstream tasks.\nHowever, applying this approach to relation classification poses unique\nchallenges. Specifically, associating natural language words that fill the\nmasked token with semantic relation labels (\\textit{e.g.}\n\\textit{``org:founded\\_by}'') is difficult. To address this challenge, this\npaper presents a novel prompt-based learning method, namely LabelPrompt, for\nthe relation classification task. Motivated by the intuition to ``GIVE MODEL\nCHOICES!'', we first define additional tokens to represent relation labels,\nwhich regard these tokens as the verbaliser with semantic initialisation and\nexplicitly construct them with a prompt template method. Then, to mitigate\ninconsistency between predicted relations and given entities, we implement an\nentity-aware module with contrastive learning. Last, we conduct an attention\nquery strategy within the self-attention layer to differentiates prompt tokens\nand sequence tokens. Together, these strategies enhance the adaptability of\nprompt-based learning, especially when only small labelled datasets is\navailable. Comprehensive experiments on benchmark datasets demonstrate the\nsuperiority of our method, particularly in the few-shot scenario."
  },
  {
    "arxiv_id": "2302.08043",
    "title": "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks",
    "url": "http://arxiv.org/abs/2302.08043v1",
    "abstract": "Graphs can model complex relationships between objects, enabling a myriad of\nWeb applications such as online page/article classification and social\nrecommendation. While graph neural networks(GNNs) have emerged as a powerful\ntool for graph representation learning, in an end-to-end supervised setting,\ntheir performance heavily rely on a large amount of task-specific supervision.\nTo reduce labeling requirement, the \"pre-train, fine-tune\" and \"pre-train,\nprompt\" paradigms have become increasingly common. In particular, prompting is\na popular alternative to fine-tuning in natural language processing, which is\ndesigned to narrow the gap between pre-training and downstream objectives in a\ntask-specific manner. However, existing study of prompting on graphs is still\nlimited, lacking a universal treatment to appeal to different downstream tasks.\nIn this paper, we propose GraphPrompt, a novel pre-training and prompting\nframework on graphs. GraphPrompt not only unifies pre-training and downstream\ntasks into a common task template, but also employs a learnable prompt to\nassist a downstream task in locating the most relevant knowledge from the\npre-train model in a task-specific manner. Finally, we conduct extensive\nexperiments on five public datasets to evaluate and analyze GraphPrompt."
  },
  {
    "arxiv_id": "2302.08917",
    "title": "Massively Multilingual Shallow Fusion with Large Language Models",
    "url": "http://arxiv.org/abs/2302.08917v1",
    "abstract": "While large language models (LLM) have made impressive progress in natural\nlanguage processing, it remains unclear how to utilize them in improving\nautomatic speech recognition (ASR). In this work, we propose to train a single\nmultilingual language model (LM) for shallow fusion in multiple languages. We\npush the limits of the multilingual LM to cover up to 84 languages by scaling\nup using a mixture-of-experts LLM, i.e., generalist language model (GLaM). When\nthe number of experts increases, GLaM dynamically selects only two at each\ndecoding step to keep the inference computation roughly constant. We then apply\nGLaM to a multilingual shallow fusion task based on a state-of-the-art\nend-to-end model. Compared to a dense LM of similar computation during\ninference, GLaM reduces the WER of an English long-tail test set by 4.4%\nrelative. In a multilingual shallow fusion task, GLaM improves 41 out of 50\nlanguages with an average relative WER reduction of 3.85%, and a maximum\nreduction of 10%. Compared to the baseline model, GLaM achieves an average WER\nreduction of 5.53% over 43 languages."
  },
  {
    "arxiv_id": "2302.08575",
    "title": "Foundation Models for Natural Language Processing -- Pre-trained Language Models Integrating Media",
    "url": "http://arxiv.org/abs/2302.08575v1",
    "abstract": "This open access book provides a comprehensive overview of the state of the\nart in research and applications of Foundation Models and is intended for\nreaders familiar with basic Natural Language Processing (NLP) concepts. Over\nthe recent years, a revolutionary new paradigm has been developed for training\nmodels for NLP. These models are first pre-trained on large collections of text\ndocuments to acquire general syntactic knowledge and semantic information.\nThen, they are fine-tuned for specific tasks, which they can often solve with\nsuperhuman accuracy. When the models are large enough, they can be instructed\nby prompts to solve new tasks without any fine-tuning. Moreover, they can be\napplied to a wide range of different media and problem domains, ranging from\nimage and video processing to robot control learning. Because they provide a\nblueprint for solving many tasks in artificial intelligence, they have been\ncalled Foundation Models. After a brief introduction to basic NLP models the\nmain pre-trained language models BERT, GPT and sequence-to-sequence transformer\nare described, as well as the concepts of self-attention and context-sensitive\nembedding. Then, different approaches to improving these models are discussed,\nsuch as expanding the pre-training criteria, increasing the length of input\ntexts, or including extra knowledge. An overview of the best-performing models\nfor about twenty application areas is then presented, e.g., question answering,\ntranslation, story generation, dialog systems, generating images from text,\netc. For each application area, the strengths and weaknesses of current models\nare discussed, and an outlook on further developments is given. In addition,\nlinks are provided to freely available program code. A concluding chapter\nsummarizes the economic opportunities, mitigation of risks, and potential\ndevelopments of AI."
  },
  {
    "arxiv_id": "2302.10016",
    "title": "Boosting classification reliability of NLP transformer models in the long run",
    "url": "http://arxiv.org/abs/2302.10016v1",
    "abstract": "Transformer-based machine learning models have become an essential tool for\nmany natural language processing (NLP) tasks since the introduction of the\nmethod. A common objective of these projects is to classify text data.\nClassification models are often extended to a different topic and/or time\nperiod. In these situations, deciding how long a classification is suitable for\nand when it is worth re-training our model is difficult. This paper compares\ndifferent approaches to fine-tune a BERT model for a long-running\nclassification task. We use data from different periods to fine-tune our\noriginal BERT model, and we also measure how a second round of annotation could\nboost the classification quality. Our corpus contains over 8 million comments\non COVID-19 vaccination in Hungary posted between September 2020 and December\n2021. Our results show that the best solution is using all available unlabeled\ncomments to fine-tune a model. It is not advisable to focus only on comments\ncontaining words that our model has not encountered before; a more efficient\nsolution is randomly sample comments from the new period. Fine-tuning does not\nprevent the model from losing performance but merely slows it down. In a\nrapidly changing linguistic environment, it is not possible to maintain model\nperformance without regularly annotating new text."
  },
  {
    "arxiv_id": "2302.09432",
    "title": "BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark",
    "url": "http://arxiv.org/abs/2302.09432v1",
    "abstract": "To advance Chinese financial natural language processing (NLP), we introduce\nBBT-FinT5, a new Chinese financial pre-training language model based on the T5\nmodel. To support this effort, we have built BBT-FinCorpus, a large-scale\nfinancial corpus with approximately 300GB of raw text from four different\nsources. In general domain NLP, comprehensive benchmarks like GLUE and\nSuperGLUE have driven significant advancements in language model pre-training\nby enabling head-to-head comparisons among models. Drawing inspiration from\nthese benchmarks, we propose BBT-CFLEB, a Chinese Financial Language\nunderstanding and generation Evaluation Benchmark, which includes six datasets\ncovering both understanding and generation tasks. Our aim is to facilitate\nresearch in the development of NLP within the Chinese financial domain. Our\nmodel, corpus and benchmark are released at\nhttps://github.com/ssymmetry/BBT-FinCUGE-Applications. Our work belongs to the\nBig Bang Transformer (BBT), a large-scale pre-trained language model project."
  },
  {
    "arxiv_id": "2302.09419",
    "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
    "url": "http://arxiv.org/abs/2302.09419v1",
    "abstract": "Pretrained Foundation Models (PFMs) are regarded as the foundation for\nvarious downstream tasks with different data modalities. A PFM (e.g., BERT,\nChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable\nparameter initialization for a wide range of downstream applications. BERT\nlearns bidirectional encoder representations from Transformers, which are\ntrained on large datasets as contextual language models. Similarly, the\ngenerative pretrained transformer (GPT) method employs Transformers as the\nfeature extractor and is trained using an autoregressive paradigm on large\ndatasets. Recently, ChatGPT shows promising success on large language models,\nwhich applies an autoregressive language model with zero shot or few shot\nprompting. The remarkable achievements of PFM have brought significant\nbreakthroughs to various fields of AI. Numerous studies have proposed different\nmethods, raising the demand for an updated survey. This study provides a\ncomprehensive review of recent research advancements, challenges, and\nopportunities for PFMs in text, image, graph, as well as other data modalities.\nThe review covers the basic components and existing pretraining methods used in\nnatural language processing, computer vision, and graph learning. Additionally,\nit explores advanced PFMs used for different data modalities and unified PFMs\nthat consider data quality and quantity. The review also discusses research\nrelated to the fundamentals of PFMs, such as model efficiency and compression,\nsecurity, and privacy. Finally, the study provides key implications, future\nresearch directions, challenges, and open problems in the field of PFMs.\nOverall, this survey aims to shed light on the research of the PFMs on\nscalability, security, logical reasoning ability, cross-domain learning\nability, and the user-friendly interactive ability for artificial general\nintelligence."
  },
  {
    "arxiv_id": "2302.10724",
    "title": "ChatGPT: Jack of all trades, master of none",
    "url": "http://arxiv.org/abs/2302.10724v1",
    "abstract": "OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and\nrevolutionized the approach in artificial intelligence to human-model\ninteraction. Several publications on ChatGPT evaluation test its effectiveness\non well-known natural language processing (NLP) tasks. However, the existing\nstudies are mostly non-automated and tested on a very limited scale. In this\nwork, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,\nmost of them subjective even to humans, such as sentiment analysis, emotion\nrecognition, offensiveness, and stance detection. In contrast, the other tasks\nrequire more objective reasoning like word sense disambiguation, linguistic\nacceptability, and question answering. We also evaluated GPT-4 model on five\nselected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process\nand analyzed more than 49k responses. Our comparison of its results with\navailable State-of-the-Art (SOTA) solutions showed that the average loss in\nquality of the ChatGPT model was about 25% for zero-shot and few-shot\nevaluation. For GPT-4 model, a loss for semantic tasks is significantly lower\nthan for ChatGPT. We showed that the more difficult the task (lower SOTA\nperformance), the higher the ChatGPT loss. It especially refers to pragmatic\nNLP problems like emotion recognition. We also tested the ability to\npersonalize ChatGPT responses for selected subjective tasks via Random\nContextual Few-Shot Personalization, and we obtained significantly better\nuser-based predictions. Additional qualitative analysis revealed a ChatGPT\nbias, most likely due to the rules imposed on human trainers by OpenAI. Our\nresults provide the basis for a fundamental discussion of whether the high\nquality of recent predictive NLP models can indicate a tool's usefulness to\nsociety and how the learning and validation procedures for such systems should\nbe established."
  },
  {
    "arxiv_id": "2302.11101",
    "title": "Learning from Predictions: Fusing Training and Autoregressive Inference for Long-Term Spatiotemporal Forecasts",
    "url": "http://arxiv.org/abs/2302.11101v1",
    "abstract": "Recurrent Neural Networks (RNNs) have become an integral part of modeling and\nforecasting frameworks in areas like natural language processing and\nhigh-dimensional dynamical systems such as turbulent fluid flows. To improve\nthe accuracy of predictions, RNNs are trained using the Backpropagation Through\nTime (BPTT) method to minimize prediction loss. During testing, RNNs are often\nused in autoregressive scenarios where the output of the network is fed back\ninto the input. However, this can lead to the exposure bias effect, as the\nnetwork was trained to receive ground-truth data instead of its own\npredictions. This mismatch between training and testing is compounded when the\nstate distributions are different, and the train and test losses are measured.\nTo address this, previous studies have proposed solutions for language\nprocessing networks with probabilistic predictions. Building on these advances,\nwe propose the Scheduled Autoregressive BPTT (BPTT-SA) algorithm for predicting\ncomplex systems. Our results show that BPTT-SA effectively reduces iterative\nerror propagation in Convolutional RNNs and Convolutional Autoencoder RNNs, and\ndemonstrate its capabilities in long-term prediction of high-dimensional fluid\nflows."
  },
  {
    "arxiv_id": "2302.11957",
    "title": "Sentence Simplification via Large Language Models",
    "url": "http://arxiv.org/abs/2302.11957v1",
    "abstract": "Sentence Simplification aims to rephrase complex sentences into simpler\nsentences while retaining original meaning. Large Language models (LLMs) have\ndemonstrated the ability to perform a variety of natural language processing\ntasks. However, it is not yet known whether LLMs can be served as a\nhigh-quality sentence simplification system. In this work, we empirically\nanalyze the zero-/few-shot learning ability of LLMs by evaluating them on a\nnumber of benchmark test sets. Experimental results show LLMs outperform\nstate-of-the-art sentence simplification methods, and are judged to be on a par\nwith human annotators."
  },
  {
    "arxiv_id": "2302.11812",
    "title": "Teacher Intervention: Improving Convergence of Quantization Aware Training for Ultra-Low Precision Transformers",
    "url": "http://arxiv.org/abs/2302.11812v1",
    "abstract": "Pre-trained Transformer models such as BERT have shown great success in a\nwide range of applications, but at the cost of substantial increases in model\ncomplexity. Quantization-aware training (QAT) is a promising method to lower\nthe implementation cost and energy consumption. However, aggressive\nquantization below 2-bit causes considerable accuracy degradation due to\nunstable convergence, especially when the downstream dataset is not abundant.\nThis work proposes a proactive knowledge distillation method called Teacher\nIntervention (TI) for fast converging QAT of ultra-low precision pre-trained\nTransformers. TI intervenes layer-wise signal propagation with the intact\nsignal from the teacher to remove the interference of propagated quantization\nerrors, smoothing loss surface of QAT and expediting the convergence.\nFurthermore, we propose a gradual intervention mechanism to stabilize the\nrecovery of subsections of Transformer layers from quantization. The proposed\nschemes enable fast convergence of QAT and improve the model accuracy\nregardless of the diverse characteristics of downstream fine-tuning tasks. We\ndemonstrate that TI consistently achieves superior accuracy with significantly\nlower fine-tuning iterations on well-known Transformers of natural language\nprocessing as well as computer vision compared to the state-of-the-art QAT\nmethods."
  },
  {
    "arxiv_id": "2302.12449",
    "title": "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning",
    "url": "http://arxiv.org/abs/2302.12449v1",
    "abstract": "Recently, much exertion has been paid to design graph self-supervised methods\nto obtain generalized pre-trained models, and adapt pre-trained models onto\ndownstream tasks through fine-tuning. However, there exists an inherent gap\nbetween pretext and downstream graph tasks, which insufficiently exerts the\nability of pre-trained models and even leads to negative transfer. Meanwhile,\nprompt tuning has seen emerging success in natural language processing by\naligning pre-training and fine-tuning with consistent training objectives. In\nthis paper, we identify the challenges for graph prompt tuning: The first is\nthe lack of a strong and universal pre-training task across sundry pre-training\nmethods in graph domain. The second challenge lies in the difficulty of\ndesigning a consistent training objective for both pre-training and downstream\ntasks. To overcome above obstacles, we propose a novel framework named SGL-PT\nwhich follows the learning strategy ``Pre-train, Prompt, and Predict''.\nSpecifically, we raise a strong and universal pre-training task coined as SGL\nthat acquires the complementary merits of generative and contrastive\nself-supervised graph learning. And aiming for graph classification task, we\nunify pre-training and fine-tuning by designing a novel verbalizer-free\nprompting function, which reformulates the downstream task in a similar format\nas pretext task. Empirical results show that our method surpasses other\nbaselines under unsupervised setting, and our prompt tuning method can greatly\nfacilitate models on biological datasets over fine-tuning methods."
  },
  {
    "arxiv_id": "2302.13007",
    "title": "ChatAug: Leveraging ChatGPT for Text Data Augmentation",
    "url": "http://arxiv.org/abs/2302.13007v1",
    "abstract": "Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation to better capture the data invariance and increase the sample\nsize. However, current text data augmentation methods either can't ensure the\ncorrect labeling of the generated data (lacking faithfulness) or can't ensure\nsufficient diversity in the generated data (lacking compactness), or both.\nInspired by the recent success of large language models, especially the\ndevelopment of ChatGPT, which demonstrated improved language comprehension\nabilities, in this work, we propose a text data augmentation approach based on\nChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples\ninto multiple conceptually similar but semantically different samples. The\naugmented samples can then be used in downstream model training. Experiment\nresults on few-shot learning text classification tasks show the superior\nperformance of the proposed AugGPT approach over state-of-the-art text data\naugmentation methods in terms of testing accuracy and distribution of the\naugmented samples."
  },
  {
    "arxiv_id": "2302.13812",
    "title": "Adapting Pre-trained Language Models for Quantum Natural Language Processing",
    "url": "http://arxiv.org/abs/2302.13812v1",
    "abstract": "The emerging classical-quantum transfer learning paradigm has brought a\ndecent performance to quantum computational models in many tasks, such as\ncomputer vision, by enabling a combination of quantum models and classical\npre-trained neural networks. However, using quantum computing with pre-trained\nmodels has yet to be explored in natural language processing (NLP). Due to the\nhigh linearity constraints of the underlying quantum computing infrastructures,\nexisting Quantum NLP models are limited in performance on real tasks. We fill\nthis gap by pre-training a sentence state with complex-valued BERT-like\narchitecture, and adapting it to the classical-quantum transfer learning scheme\nfor sentence classification. On quantum simulation experiments, the pre-trained\nrepresentation can bring 50\\% to 60\\% increases to the capacity of end-to-end\nquantum models."
  },
  {
    "arxiv_id": "2302.14828",
    "title": "Automatic Scoring of Dream Reports' Emotional Content with Large Language Models",
    "url": "http://arxiv.org/abs/2302.14828v1",
    "abstract": "In the field of dream research, the study of dream content typically relies\non the analysis of verbal reports provided by dreamers upon awakening from\ntheir sleep. This task is classically performed through manual scoring provided\nby trained annotators, at a great time expense. While a consistent body of work\nsuggests that natural language processing (NLP) tools can support the automatic\nanalysis of dream reports, proposed methods lacked the ability to reason over a\nreport's full context and required extensive data pre-processing. Furthermore,\nin most cases, these methods were not validated against standard manual scoring\napproaches. In this work, we address these limitations by adopting large\nlanguage models (LLMs) to study and replicate the manual annotation of dream\nreports, using a mixture of off-the-shelf and bespoke approaches, with a focus\non references to reports' emotions. Our results show that the off-the-shelf\nmethod achieves a low performance probably in light of inherent linguistic\ndifferences between reports collected in different (groups of) individuals. On\nthe other hand, the proposed bespoke text classification method achieves a high\nperformance, which is robust against potential biases. Overall, these\nobservations indicate that our approach could find application in the analysis\nof large dream datasets and may favour reproducibility and comparability of\nresults across studies."
  },
  {
    "arxiv_id": "2302.14705",
    "title": "AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference with Transformers",
    "url": "http://arxiv.org/abs/2302.14705v1",
    "abstract": "Self-attention-based transformer models have achieved tremendous success in\nthe domain of natural language processing. Despite their efficacy, accelerating\nthe transformer is challenging due to its quadratic computational complexity\nand large activation sizes. Existing transformer accelerators attempt to prune\nits tokens to reduce memory access, albeit with high compute overheads.\nMoreover, previous works directly operate on large matrices involved in the\nattention operation, which limits hardware utilization. In order to address\nthese challenges, this work proposes a novel dynamic inference scheme,\nDynaTran, which prunes activations at runtime with low overhead, substantially\nreducing the number of ineffectual operations. This improves the throughput of\ntransformer inference. We further propose tiling the matrices in transformer\noperations along with diverse dataflows to improve data reuse, thus enabling\nhigher energy efficiency. To effectively implement these methods, we propose\nAccelTran, a novel accelerator architecture for transformers. Extensive\nexperiments with different models and benchmarks demonstrate that DynaTran\nachieves higher accuracy than the state-of-the-art top-k hardware-aware pruning\nstrategy while attaining up to 1.2$\\times$ higher sparsity. One of our proposed\naccelerators, AccelTran-Edge, achieves 330K$\\times$ higher throughput with\n93K$\\times$ lower energy requirement when compared to a Raspberry Pi device. On\nthe other hand, AccelTran-Server achieves 5.73$\\times$ higher throughput and\n3.69$\\times$ lower energy consumption compared to the state-of-the-art\ntransformer co-processor, Energon. The simulation source code is available at\nhttps://github.com/jha-lab/acceltran."
  },
  {
    "arxiv_id": "2302.14502",
    "title": "A Survey on Long Text Modeling with Transformers",
    "url": "http://arxiv.org/abs/2302.14502v1",
    "abstract": "Modeling long texts has been an essential technique in the field of natural\nlanguage processing (NLP). With the ever-growing number of long documents, it\nis important to develop effective modeling methods that can process and analyze\nsuch texts. However, long texts pose important research challenges for existing\ntext models, with more complex semantics and special characteristics. In this\npaper, we provide an overview of the recent advances on long texts modeling\nbased on Transformer models. Firstly, we introduce the formal definition of\nlong text modeling. Then, as the core content, we discuss how to process long\ninput to satisfy the length limitation and design improved Transformer\narchitectures to effectively extend the maximum context length. Following this,\nwe discuss how to adapt Transformer models to capture the special\ncharacteristics of long texts. Finally, we describe four typical applications\ninvolving long text modeling and conclude this paper with a discussion of\nfuture directions. Our survey intends to provide researchers with a synthesis\nand pointer to related work on long text modeling."
  },
  {
    "arxiv_id": "2303.00733",
    "title": "SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks",
    "url": "http://arxiv.org/abs/2303.00733v1",
    "abstract": "Prompt tuning is a technology that tunes a small set of parameters to steer a\npre-trained language model (LM) to directly generate the output for downstream\ntasks. Recently, prompt tuning has demonstrated its storage and computation\nefficiency in both natural language processing (NLP) and speech processing\nfields. These advantages have also revealed prompt tuning as a candidate\napproach to serving pre-trained LM for multiple tasks in a unified manner. For\nspeech processing, SpeechPrompt shows its high parameter efficiency and\ncompetitive performance on a few speech classification tasks. However, whether\nSpeechPrompt is capable of serving a large number of tasks is unanswered. In\nthis work, we propose SpeechPrompt v2, a prompt tuning framework capable of\nperforming a wide variety of speech classification tasks, covering multiple\nlanguages and prosody-related tasks. The experiment result shows that\nSpeechPrompt v2 achieves performance on par with prior works with less than\n0.15M trainable parameters in a unified framework."
  },
  {
    "arxiv_id": "2303.00293",
    "title": "How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks",
    "url": "http://arxiv.org/abs/2303.00293v1",
    "abstract": "The GPT-3.5 models have demonstrated impressive performance in various\nNatural Language Processing (NLP) tasks, showcasing their strong understanding\nand reasoning capabilities. However, their robustness and abilities to handle\nvarious complexities of the open world have yet to be explored, which is\nespecially crucial in assessing the stability of models and is a key aspect of\ntrustworthy AI. In this study, we perform a comprehensive experimental analysis\nof GPT-3.5, exploring its robustness using 21 datasets (about 116K test\nsamples) with 66 text transformations from TextFlint that cover 9 popular\nNatural Language Understanding (NLU) tasks. Our findings indicate that while\nGPT-3.5 outperforms existing fine-tuned models on some tasks, it still\nencounters significant robustness degradation, such as its average performance\ndropping by up to 35.74\\% and 43.59\\% in natural language inference and\nsentiment analysis tasks, respectively. We also show that GPT-3.5 faces some\nspecific robustness challenges, including robustness instability, prompt\nsensitivity, and number sensitivity. These insights are valuable for\nunderstanding its limitations and guiding future research in addressing these\nchallenges to enhance GPT-3.5's overall performance and generalization\nabilities."
  },
  {
    "arxiv_id": "2303.02444",
    "title": "Calibrating Transformers via Sparse Gaussian Processes",
    "url": "http://arxiv.org/abs/2303.02444v1",
    "abstract": "Transformer models have achieved profound success in prediction tasks in a\nwide range of applications in natural language processing, speech recognition\nand computer vision. Extending Transformer's success to safety-critical domains\nrequires calibrated uncertainty estimation which remains under-explored. To\naddress this, we propose Sparse Gaussian Process attention (SGPA), which\nperforms Bayesian inference directly in the output space of multi-head\nattention blocks (MHAs) in transformer to calibrate its uncertainty. It\nreplaces the scaled dot-product operation with a valid symmetric kernel and\nuses sparse Gaussian processes (SGP) techniques to approximate the posterior\nprocesses of MHA outputs. Empirically, on a suite of prediction tasks on text,\nimages and graphs, SGPA-based Transformers achieve competitive predictive\naccuracy, while noticeably improving both in-distribution calibration and\nout-of-distribution robustness and detection."
  },
  {
    "arxiv_id": "2303.03186",
    "title": "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT",
    "url": "http://arxiv.org/abs/2303.03186v1",
    "abstract": "ChatGPT has shown the potential of emerging general artificial intelligence\ncapabilities, as it has demonstrated competent performance across many natural\nlanguage processing tasks. In this work, we evaluate the capabilities of\nChatGPT to perform text classification on three affective computing problems,\nnamely, big-five personality prediction, sentiment analysis, and suicide\ntendency detection. We utilise three baselines, a robust language model\n(RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and\na simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for\na specific downstream task generally has a superior performance. On the other\nhand, ChatGPT provides decent results, and is relatively comparable to the\nWord2Vec and BoW baselines. ChatGPT further shows robustness against noisy\ndata, where Word2Vec models achieve worse results due to noise. Results\nindicate that ChatGPT is a good generalist model that is capable of achieving\ngood results across various problems without any specialised training, however,\nit is not as good as a specialised model for a downstream task."
  },
  {
    "arxiv_id": "2303.03836",
    "title": "Exploring the Feasibility of ChatGPT for Event Extraction",
    "url": "http://arxiv.org/abs/2303.03836v1",
    "abstract": "Event extraction is a fundamental task in natural language processing that\ninvolves identifying and extracting information about events mentioned in text.\nHowever, it is a challenging task due to the lack of annotated data, which is\nexpensive and time-consuming to obtain. The emergence of large language models\n(LLMs) such as ChatGPT provides an opportunity to solve language tasks with\nsimple prompts without the need for task-specific datasets and fine-tuning.\nWhile ChatGPT has demonstrated impressive results in tasks like machine\ntranslation, text summarization, and question answering, it presents challenges\nwhen used for complex tasks like event extraction. Unlike other tasks, event\nextraction requires the model to be provided with a complex set of instructions\ndefining all event types and their schemas. To explore the feasibility of\nChatGPT for event extraction and the challenges it poses, we conducted a series\nof experiments. Our results show that ChatGPT has, on average, only 51.04% of\nthe performance of a task-specific model such as EEQA in long-tail and complex\nscenarios. Our usability testing experiments indicate that ChatGPT is not\nrobust enough, and continuous refinement of the prompt does not lead to stable\nperformance improvements, which can result in a poor user experience. Besides,\nChatGPT is highly sensitive to different prompt styles."
  },
  {
    "arxiv_id": "2303.05295",
    "title": "Dynamic Stashing Quantization for Efficient Transformer Training",
    "url": "http://arxiv.org/abs/2303.05295v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance on a\nrange of Natural Language Processing (NLP) tasks. Unfortunately, the immense\namount of computations and memory accesses required for LLM training makes them\nprohibitively expensive in terms of hardware cost, and thus challenging to\ndeploy in use cases such as on-device learning. In this paper, motivated by the\nobservation that LLM training is memory-bound, we propose a novel dynamic\nquantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a\nspecial focus on reducing the memory operations, but also enjoys the other\nbenefits of low precision training, such as the reduced arithmetic cost. We\nconduct a thorough study on two translation tasks (trained-from-scratch) and\nthree classification tasks (fine-tuning). DSQ reduces the amount of arithmetic\noperations by $20.95\\times$ and the number of DRAM operations by $2.55\\times$\non IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in\non-device learning."
  },
  {
    "arxiv_id": "2303.05153",
    "title": "Can a Frozen Pretrained Language Model be used for Zero-shot Neural Retrieval on Entity-centric Questions?",
    "url": "http://arxiv.org/abs/2303.05153v1",
    "abstract": "Neural document retrievers, including dense passage retrieval (DPR), have\noutperformed classical lexical-matching retrievers, such as BM25, when\nfine-tuned and tested on specific question-answering datasets. However, it has\nbeen shown that the existing dense retrievers do not generalize well not only\nout of domain but even in domain such as Wikipedia, especially when a named\nentity in a question is a dominant clue for retrieval. In this paper, we\npropose an approach toward in-domain generalization using the embeddings\ngenerated by the frozen language model trained with the entities in the domain.\nBy not fine-tuning, we explore the possibility that the rich knowledge\ncontained in a pretrained language model can be used for retrieval tasks. The\nproposed method outperforms conventional DPRs on entity-centric questions in\nWikipedia domain and achieves almost comparable performance to BM25 and\nstate-of-the-art SPAR model. We also show that the contextualized keys lead to\nstrong improvements compared to BM25 when the entity names consist of common\nwords. Our results demonstrate the feasibility of the zero-shot retrieval\nmethod for entity-centric questions of Wikipedia domain, where DPR has\nstruggled to perform."
  },
  {
    "arxiv_id": "2303.04998",
    "title": "Rethinking Visual Prompt Learning as Masked Visual Token Modeling",
    "url": "http://arxiv.org/abs/2303.04998v1",
    "abstract": "Prompt learning has achieved great success in efficiently exploiting\nlarge-scale pre-trained models in natural language processing (NLP). It\nreformulates the downstream tasks as the generative pre-training ones to\nachieve consistency, thus improving the performance stably. However, when\ntransferring it to the vision area, current visual prompt learning methods are\nalmost designed on discriminative pre-trained models, and there is also a lack\nof careful design to unify the forms of pre-training and downstream tasks. To\nexplore prompt learning on the generative pre-trained visual model, as well as\nkeeping the task consistency, we propose Visual Prompt learning as masked\nvisual Token Modeling (VPTM) to transform the downstream visual classification\ninto the pre-trained masked visual token prediction. In addition, we develop\nthe prototypical verbalizer for mapping the predicted visual token with\nimplicit semantics to explicit downstream labels. To our best knowledge, VPTM\nis the first visual prompt method on the generative pre-trained visual model,\nwhich achieves consistency between pre-training and downstream visual\nclassification by task reformulation. Experiments show that VPTM outperforms\nother visual prompt methods and achieves excellent efficiency. Moreover, the\ntask consistency of VPTM contributes to the robustness against prompt location,\nprompt length and prototype dimension, and could be deployed uniformly."
  },
  {
    "arxiv_id": "2303.05759",
    "title": "An Overview on Language Models: Recent Developments and Outlook",
    "url": "http://arxiv.org/abs/2303.05759v1",
    "abstract": "Language modeling studies the probability distributions over strings of\ntexts. It is one of the most fundamental tasks in natural language processing\n(NLP). It has been widely used in text generation, speech recognition, machine\ntranslation, etc. Conventional language models (CLMs) aim to predict the\nprobability of linguistic sequences in a causal manner, while pre-trained\nlanguage models (PLMs) cover broader concepts and can be used in both causal\nsequential modeling and fine-tuning for downstream applications. PLMs have\ntheir own training paradigms (usually self-supervised) and serve as foundation\nmodels in modern NLP systems. This overview paper provides an introduction to\nboth CLMs and PLMs from five aspects, i.e., linguistic units, architectures,\ntraining methods, evaluation methods, and applications. Furthermore, we discuss\nthe relationship between CLMs and PLMs and shed light on the future directions\nof language modeling in the pre-trained era."
  },
  {
    "arxiv_id": "2303.07226",
    "title": "Scaling Vision-Language Models with Sparse Mixture of Experts",
    "url": "http://arxiv.org/abs/2303.07226v1",
    "abstract": "The field of natural language processing (NLP) has made significant strides\nin recent years, particularly in the development of large-scale vision-language\nmodels (VLMs). These models aim to bridge the gap between text and visual\ninformation, enabling a more comprehensive understanding of multimedia data.\nHowever, as these models become larger and more complex, they also become more\nchallenging to train and deploy. One approach to addressing this challenge is\nthe use of sparsely-gated mixture-of-experts (MoE) techniques, which divide the\nmodel into smaller, specialized sub-models that can jointly solve a task. In\nthis paper, we explore the effectiveness of MoE in scaling vision-language\nmodels, demonstrating its potential to achieve state-of-the-art performance on\na range of benchmarks over dense models of equivalent computational cost. Our\nresearch offers valuable insights into stabilizing the training of MoE models,\nunderstanding the impact of MoE on model interpretability, and balancing the\ntrade-offs between compute performance when scaling VLMs. We hope our work will\ninspire further research into the use of MoE for scaling large-scale\nvision-language models and other multimodal machine learning applications."
  },
  {
    "arxiv_id": "2303.06574",
    "title": "Diffusion Models for Non-autoregressive Text Generation: A Survey",
    "url": "http://arxiv.org/abs/2303.06574v1",
    "abstract": "Non-autoregressive (NAR) text generation has attracted much attention in the\nfield of natural language processing, which greatly reduces the inference\nlatency but has to sacrifice the generation accuracy. Recently, diffusion\nmodels, a class of latent variable generative models, have been introduced into\nNAR text generation, showing an improved text generation quality. In this\nsurvey, we review the recent progress in diffusion models for NAR text\ngeneration. As the background, we first present the general definition of\ndiffusion models and the text diffusion models, and then discuss their merits\nfor NAR generation. As the core content, we further introduce two mainstream\ndiffusion models in existing work of text diffusion, and review the key designs\nof the diffusion process. Moreover, we discuss the utilization of pre-trained\nlanguage models (PLMs) for text diffusion models and introduce optimization\ntechniques for text data. Finally, we discuss several promising directions and\nconclude this paper. Our survey aims to provide researchers with a systematic\nreference of related research on text diffusion models for NAR generation. We\npresent our collection of text diffusion models at\nhttps://github.com/RUCAIBox/Awesome-Text-Diffusion-Models."
  },
  {
    "arxiv_id": "2303.06230",
    "title": "Generating Query Focused Summaries without Fine-tuning the Transformer-based Pre-trained Models",
    "url": "http://arxiv.org/abs/2303.06230v1",
    "abstract": "Fine-tuning the Natural Language Processing (NLP) models for each new data\nset requires higher computational time associated with increased carbon\nfootprint and cost. However, fine-tuning helps the pre-trained models adapt to\nthe latest data sets; what if we avoid the fine-tuning steps and attempt to\ngenerate summaries using just the pre-trained models to reduce computational\ntime and cost. In this paper, we tried to omit the fine-tuning steps and\ninvestigate whether the Marginal Maximum Relevance (MMR)-based approach can\nhelp the pre-trained models to obtain query-focused summaries directly from a\nnew data set that was not used to pre-train the models. First, we used topic\nmodelling on Wikipedia Current Events Portal (WCEP) and Debatepedia datasets to\ngenerate queries for summarization tasks. Then, using MMR, we ranked the\nsentences of the documents according to the queries. Next, we passed the ranked\nsentences to seven transformer-based pre-trained models to perform the\nsummarization tasks. Finally, we used the MMR approach again to select the\nquery relevant sentences from the generated summaries of individual pre-trained\nmodels and constructed the final summary. As indicated by the experimental\nresults, our MMR-based approach successfully ranked and selected the most\nrelevant sentences as summaries and showed better performance than the\nindividual pre-trained models."
  },
  {
    "arxiv_id": "2303.07470",
    "title": "X-Former: In-Memory Acceleration of Transformers",
    "url": "http://arxiv.org/abs/2303.07470v1",
    "abstract": "Transformers have achieved great success in a wide variety of natural\nlanguage processing (NLP) tasks due to the attention mechanism, which assigns\nan importance score for every word relative to other words in a sequence.\nHowever, these models are very large, often reaching hundreds of billions of\nparameters, and therefore require a large number of DRAM accesses. Hence,\ntraditional deep neural network (DNN) accelerators such as GPUs and TPUs face\nlimitations in processing Transformers efficiently. In-memory accelerators\nbased on non-volatile memory promise to be an effective solution to this\nchallenge, since they provide high storage density while performing massively\nparallel matrix vector multiplications within memory arrays. However, attention\nscore computations, which are frequently used in Transformers (unlike CNNs and\nRNNs), require matrix vector multiplications (MVM) where both operands change\ndynamically for each input. As a result, conventional NVM-based accelerators\nincur high write latency and write energy when used for Transformers, and\nfurther suffer from the low endurance of most NVM technologies. To address\nthese challenges, we present X-Former, a hybrid in-memory hardware accelerator\nthat consists of both NVM and CMOS processing elements to execute transformer\nworkloads efficiently. To improve the hardware utilization of X-Former, we also\npropose a sequence blocking dataflow, which overlaps the computations of the\ntwo processing elements and reduces execution time. Across several benchmarks,\nwe show that X-Former achieves upto 85x and 7.5x improvements in latency and\nenergy over a NVIDIA GeForce GTX 1060 GPU and upto 10.7x and 4.6x improvements\nin latency and energy over a state-of-the-art in-memory NVM accelerator."
  },
  {
    "arxiv_id": "2303.07364",
    "title": "Learning the language of QCD jets with transformers",
    "url": "http://arxiv.org/abs/2303.07364v1",
    "abstract": "Transformers have become the primary architecture for natural language\nprocessing. In this study, we explore their use for auto-regressive density\nestimation in high-energy jet physics, which involves working with a\nhigh-dimensional space. We draw an analogy between sentences and words in\nnatural language and jets and their constituents in high-energy physics.\nSpecifically, we investigate density estimation for light QCD jets and\nhadronically decaying boosted top jets. Since transformers allow easy sampling\nfrom learned densities, we exploit their generative capability to assess the\nquality of the density estimate. Our results indicate that the generated data\nsamples closely resemble the original data, as evidenced by the excellent\nagreement of distributions such as particle multiplicity or jet mass.\nFurthermore, the generated samples are difficult to distinguish from the\noriginal data, even by a powerful supervised classifier. Given their\nexceptional data processing capabilities, transformers could potentially be\ntrained directly on the massive LHC data sets to learn the probability\ndensities in high-energy jet physics."
  },
  {
    "arxiv_id": "2303.08262",
    "title": "Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension",
    "url": "http://arxiv.org/abs/2303.08262v1",
    "abstract": "Objective: To develop a natural language processing system that solves both\nclinical concept extraction and relation extraction in a unified prompt-based\nmachine reading comprehension (MRC) architecture with good generalizability for\ncross-institution applications.\n  Methods: We formulate both clinical concept extraction and relation\nextraction using a unified prompt-based MRC architecture and explore\nstate-of-the-art transformer models. We compare our MRC models with existing\ndeep learning models for concept extraction and end-to-end relation extraction\nusing two benchmark datasets developed by the 2018 National NLP Clinical\nChallenges (n2c2) challenge (medications and adverse drug events) and the 2022\nn2c2 challenge (relations of social determinants of health [SDoH]). We also\nevaluate the transfer learning ability of the proposed MRC models in a\ncross-institution setting. We perform error analyses and examine how different\nprompting strategies affect the performance of MRC models.\n  Results and Conclusion: The proposed MRC models achieve state-of-the-art\nperformance for clinical concept and relation extraction on the two benchmark\ndatasets, outperforming previous non-MRC transformer models. GatorTron-MRC\nachieves the best strict and lenient F1-scores for concept extraction,\noutperforming previous deep learning models on the two datasets by 1%~3% and\n0.7%~1.3%, respectively. For end-to-end relation extraction, GatorTron-MRC and\nBERT-MIMIC-MRC achieve the best F1-scores, outperforming previous deep learning\nmodels by 0.9%~2.4% and 10%-11%, respectively. For cross-institution\nevaluation, GatorTron-MRC outperforms traditional GatorTron by 6.4% and 16% for\nthe two datasets, respectively. The proposed method is better at handling\nnested/overlapped concepts, extracting relations, and has good portability for\ncross-institute applications."
  },
  {
    "arxiv_id": "2303.08259",
    "title": "Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures",
    "url": "http://arxiv.org/abs/2303.08259v1",
    "abstract": "Objective: To develop a natural language processing (NLP) system to extract\nmedications and contextual information that help understand drug changes. This\nproject is part of the 2022 n2c2 challenge.\n  Materials and methods: We developed NLP systems for medication mention\nextraction, event classification (indicating medication changes discussed or\nnot), and context classification to classify medication changes context into 5\northogonal dimensions related to drug changes. We explored 6 state-of-the-art\npretrained transformer models for the three subtasks, including GatorTron, a\nlarge language model pretrained using >90 billion words of text (including >80\nbillion words from >290 million clinical notes identified at the University of\nFlorida Health). We evaluated our NLP systems using annotated data and\nevaluation scripts provided by the 2022 n2c2 organizers.\n  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for\nmedication extraction (ranked 3rd), 0.9379 for event classification (ranked\n2nd), and the best micro-average accuracy of 0.9126 for context classification.\nGatorTron outperformed existing transformer models pretrained using smaller\ngeneral English text and clinical text corpora, indicating the advantage of\nlarge language models.\n  Conclusion: This study demonstrated the advantage of using large transformer\nmodels for contextual medication information extraction from clinical\nnarratives."
  },
  {
    "arxiv_id": "2303.09184",
    "title": "Block-wise Bit-Compression of Transformer-based Models",
    "url": "http://arxiv.org/abs/2303.09184v1",
    "abstract": "With the popularity of the recent Transformer-based models represented by\nBERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range\nof natural language processing tasks. However, the massive computations, huge\nmemory footprint, and thus high latency of Transformer-based models is an\ninevitable challenge for the cloud with high real-time requirement. To tackle\nthe issue, we propose BBCT, a method of block-wise bit-compression for\ntransformer without retraining. Our method achieves more fine-grained\ncompression of the whole transformer, including embedding, matrix\nmultiplication, GELU, softmax, layer normalization, and all the intermediate\nresults. As a case, we compress an efficient BERT with the method of BBCT. Our\nbenchmark test results on General Language Understanding Evaluation (GLUE) show\nthat BBCT can achieve less than 1% accuracy drop in most tasks."
  },
  {
    "arxiv_id": "2303.09136",
    "title": "A Short Survey of Viewing Large Language Models in Legal Aspect",
    "url": "http://arxiv.org/abs/2303.09136v1",
    "abstract": "Large language models (LLMs) have transformed many fields, including natural\nlanguage processing, computer vision, and reinforcement learning. These models\nhave also made a significant impact in the field of law, where they are being\nincreasingly utilized to automate various legal tasks, such as legal judgement\nprediction, legal document analysis, and legal document writing. However, the\nintegration of LLMs into the legal field has also raised several legal\nproblems, including privacy concerns, bias, and explainability. In this survey,\nwe explore the integration of LLMs into the field of law. We discuss the\nvarious applications of LLMs in legal tasks, examine the legal challenges that\narise from their use, and explore the data resources that can be used to\nspecialize LLMs in the legal domain. Finally, we discuss several promising\ndirections and conclude this paper. By doing so, we hope to provide an overview\nof the current state of LLMs in law and highlight the potential benefits and\nchallenges of their integration."
  },
  {
    "arxiv_id": "2303.09752",
    "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation",
    "url": "http://arxiv.org/abs/2303.09752v1",
    "abstract": "Many natural language processing tasks benefit from long inputs, but\nprocessing long documents with Transformers is expensive -- not only due to\nquadratic attention complexity but also from applying feedforward and\nprojection layers to every token. However, not all tokens are equally\nimportant, especially for longer documents. We propose CoLT5, a long-input\nTransformer model that builds on this intuition by employing conditional\ncomputation, devoting more resources to important tokens in both feedforward\nand attention layers. We show that CoLT5 achieves stronger performance than\nLongT5 with much faster training and inference, achieving SOTA on the\nlong-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably\nmake use of extremely long inputs, showing strong gains up to 64k input length."
  },
  {
    "arxiv_id": "2303.11146",
    "title": "On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?",
    "url": "http://arxiv.org/abs/2303.11146v1",
    "abstract": "In late 2022, OpenAI released a new version of ChatGPT, a sophisticated\nnatural language processing system capable of holding natural conversations\nwhile preserving and responding to the context of the discussion. ChatGPT has\nexceeded expectations in its abilities, leading to extensive considerations of\nits potential applications and misuse. In this work, we evaluate the influence\nof ChatGPT on university education, with a primary focus on computer\nsecurity-oriented specialization. We gather data regarding the effectiveness\nand usability of this tool for completing exams, programming assignments, and\nterm papers. We evaluate multiple levels of tool misuse, ranging from utilizing\nit as a consultant to simply copying its outputs. While we demonstrate how\neasily ChatGPT can be used to cheat, we also discuss the potentially\nsignificant benefits to the educational system. For instance, it might be used\nas an aid (assistant) to discuss problems encountered while solving an\nassignment or to speed up the learning process. Ultimately, we discuss how\ncomputer science higher education should adapt to tools like ChatGPT."
  },
  {
    "arxiv_id": "2303.10870",
    "title": "Multi-task Transformer with Relation-attention and Type-attention for Named Entity Recognition",
    "url": "http://arxiv.org/abs/2303.10870v1",
    "abstract": "Named entity recognition (NER) is an important research problem in natural\nlanguage processing. There are three types of NER tasks, including flat, nested\nand discontinuous entity recognition. Most previous sequential labeling models\nare task-specific, while recent years have witnessed the rising of generative\nmodels due to the advantage of unifying all NER tasks into the seq2seq model\nframework. Although achieving promising performance, our pilot studies\ndemonstrate that existing generative models are ineffective at detecting entity\nboundaries and estimating entity types. This paper proposes a multi-task\nTransformer, which incorporates an entity boundary detection task into the\nnamed entity recognition task. More concretely, we achieve entity boundary\ndetection by classifying the relations between tokens within the sentence. To\nimprove the accuracy of entity-type mapping during decoding, we adopt an\nexternal knowledge base to calculate the prior entity-type distributions and\nthen incorporate the information into the model via the self and\ncross-attention mechanisms. We perform experiments on an extensive set of NER\nbenchmarks, including two flat, three nested, and three discontinuous NER\ndatasets. Experimental results show that our approach considerably improves the\ngenerative NER model's performance."
  },
  {
    "arxiv_id": "2303.10475",
    "title": "Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning",
    "url": "http://arxiv.org/abs/2303.10475v1",
    "abstract": "Task semantics can be expressed by a set of input-output examples or a piece\nof textual instruction. Conventional machine learning approaches for natural\nlanguage processing (NLP) mainly rely on the availability of large-scale sets\nof task-specific examples. Two issues arise: first, collecting task-specific\nlabeled examples does not apply to scenarios where tasks may be too complicated\nor costly to annotate, or the system is required to handle a new task\nimmediately; second, this is not user-friendly since end-users are probably\nmore willing to provide task description rather than a set of examples before\nusing the system. Therefore, the community is paying increasing interest in a\nnew supervision-seeking paradigm for NLP: learning to follow task instructions,\ni.e., instruction following. Despite its impressive progress, there are some\ncommon issues that the community struggles with. This survey paper tries to\nsummarize and provide insights to the current research on instruction\nfollowing, particularly, by answering the following questions: (i) What is task\ninstruction, and what instruction types exist? (ii) How to model instructions?\n(iii) What are popular instruction following datasets and evaluation metrics?\n(iv) What factors influence and explain the instructions' performance? (v) What\nchallenges remain in instruction following? To our knowledge, this is the first\ncomprehensive survey about instruction following."
  },
  {
    "arxiv_id": "2303.12068",
    "title": "Machine Learning for Brain Disorders: Transformers and Visual Transformers",
    "url": "http://arxiv.org/abs/2303.12068v1",
    "abstract": "Transformers were initially introduced for natural language processing (NLP)\ntasks, but fast they were adopted by most deep learning fields, including\ncomputer vision. They measure the relationships between pairs of input tokens\n(words in the case of text strings, parts of images for visual Transformers),\ntermed attention. The cost is exponential with the number of tokens. For image\nclassification, the most common Transformer Architecture uses only the\nTransformer Encoder in order to transform the various input tokens. However,\nthere are also numerous other applications in which the decoder part of the\ntraditional Transformer Architecture is also used. Here, we first introduce the\nAttention mechanism (Section 1), and then the Basic Transformer Block including\nthe Vision Transformer (Section 2). Next, we discuss some improvements of\nvisual Transformers to account for small datasets or less computation(Section\n3). Finally, we introduce Visual Transformers applied to tasks other than image\nclassification, such as detection, segmentation, generation and training\nwithout labels (Section 4) and other domains, such as video or multimodality\nusing text or audio data (Section 5)."
  },
  {
    "arxiv_id": "2303.11607",
    "title": "Transformers in Speech Processing: A Survey",
    "url": "http://arxiv.org/abs/2303.11607v1",
    "abstract": "The remarkable success of transformers in the field of natural language\nprocessing has sparked the interest of the speech-processing community, leading\nto an exploration of their potential for modeling long-range dependencies\nwithin speech sequences. Recently, transformers have gained prominence across\nvarious speech-related domains, including automatic speech recognition, speech\nsynthesis, speech translation, speech para-linguistics, speech enhancement,\nspoken dialogue systems, and numerous multimodal applications. In this paper,\nwe present a comprehensive survey that aims to bridge research studies from\ndiverse subfields within speech technology. By consolidating findings from\nacross the speech technology landscape, we provide a valuable resource for\nresearchers interested in harnessing the power of transformers to advance the\nfield. We identify the challenges encountered by transformers in speech\nprocessing while also offering insights into potential solutions to address\nthese issues."
  },
  {
    "arxiv_id": "2303.11593",
    "title": "Difficulty in learning chirality for Transformer fed with SMILES",
    "url": "http://arxiv.org/abs/2303.11593v1",
    "abstract": "Recent years have seen rapid development of descriptor generation based on\nrepresentation learning of extremely diverse molecules, especially those that\napply natural language processing (NLP) models to SMILES, a literal\nrepresentation of molecular structure. However, little research has been done\non how these models understand chemical structure. To address this black box,\nwe investigated the relationship between the learning progress of SMILES and\nchemical structure using a representative NLP model, the Transformer. We show\nthat while the Transformer learns partial structures of molecules quickly, it\nrequires extended training to understand overall structures. Consistently, the\naccuracy of molecular property predictions using descriptors generated from\nmodels at different learning steps was similar from the beginning to the end of\ntraining. Furthermore, we found that the Transformer requires particularly long\ntraining to learn chirality and sometimes stagnates with low performance due to\nmisunderstanding of enantiomers. These findings are expected to deepen the\nunderstanding of NLP models in chemistry."
  },
  {
    "arxiv_id": "2303.12914",
    "title": "TRON: Transformer Neural Network Acceleration with Non-Coherent Silicon Photonics",
    "url": "http://arxiv.org/abs/2303.12914v1",
    "abstract": "Transformer neural networks are rapidly being integrated into\nstate-of-the-art solutions for natural language processing (NLP) and computer\nvision. However, the complex structure of these models creates challenges for\naccelerating their execution on conventional electronic platforms. We propose\nthe first silicon photonic hardware neural network accelerator called TRON for\ntransformer-based models such as BERT, and Vision Transformers. Our analysis\ndemonstrates that TRON exhibits at least 14x better throughput and 8x better\nenergy efficiency, in comparison to state-of-the-art transformer accelerators."
  },
  {
    "arxiv_id": "2303.12892",
    "title": "A Small-Scale Switch Transformer and NLP-based Model for Clinical Narratives Classification",
    "url": "http://arxiv.org/abs/2303.12892v1",
    "abstract": "Transformer-based models have shown outstanding results in natural language\nprocessing but face challenges in applications like classifying small-scale\nclinical texts, especially with constrained computational resources. This study\npresents a customized Mixture of Expert (MoE) Transformer models for\nclassifying small-scale French clinical texts at CHU Sainte-Justine Hospital.\nThe MoE-Transformer addresses the dual challenges of effective training with\nlimited data and low-resource computation suitable for in-house hospital use.\nDespite the success of biomedical pre-trained models such as CamemBERT-bio,\nDrBERT, and AliBERT, their high computational demands make them impractical for\nmany clinical settings. Our MoE-Transformer model not only outperforms\nDistillBERT, CamemBERT, FlauBERT, and Transformer models on the same dataset\nbut also achieves impressive results: an accuracy of 87\\%, precision of 87\\%,\nrecall of 85\\%, and F1-score of 86\\%. While the MoE-Transformer does not\nsurpass the performance of biomedical pre-trained BERT models, it can be\ntrained at least 190 times faster, offering a viable alternative for settings\nwith limited data and computational resources. Although the MoE-Transformer\naddresses challenges of generalization gaps and sharp minima, demonstrating\nsome limitations for efficient and accurate clinical text classification, this\nmodel still represents a significant advancement in the field. It is\nparticularly valuable for classifying small French clinical narratives within\nthe privacy and constraints of hospital-based computational resources."
  },
  {
    "arxiv_id": "2303.13988",
    "title": "Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods",
    "url": "http://arxiv.org/abs/2303.13988v1",
    "abstract": "Large language models (LLMs) show increasingly advanced emergent capabilities\nand are being incorporated across various societal domains. Understanding their\nbehavior and reasoning abilities therefore holds significant importance. We\nargue that a fruitful direction for research is engaging LLMs in behavioral\nexperiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and\nsummarize theoretical perspectives, experimental paradigms, and computational\nanalysis techniques that this approach brings to the table. It paves the way\nfor a \"machine psychology\" for generative artificial intelligence (AI) that\ngoes beyond performance benchmarks and focuses instead on computational\ninsights that move us toward a better understanding and discovery of emergent\nabilities and behavioral patterns in LLMs. We review existing work taking this\napproach, synthesize best practices, and highlight promising future directions.\nWe also highlight the important caveats of applying methodologies designed for\nunderstanding humans to machines. We posit that leveraging tools from\nexperimental psychology to study AI will become increasingly valuable as models\nevolve to be more powerful, opaque, multi-modal, and integrated into complex\nreal-world settings."
  },
  {
    "arxiv_id": "2303.13856",
    "title": "Unleasing ChatGPT on the Metaverse: Savior or Destroyer?",
    "url": "http://arxiv.org/abs/2303.13856v1",
    "abstract": "Incorporating artificial intelligence (AI) technology, particularly large\nlanguage models (LLMs), is becoming increasingly vital for developing immersive\nand interactive metaverse experiences. GPT, a representative LLM developed by\nOpenAI, is leading LLM development and gaining attention for its potential in\nbuilding the metaverse. The article delves into the pros and cons of utilizing\nGPT for metaverse-based education, entertainment, personalization, and support.\nDynamic and personalized experiences are possible with this technology, but\nthere are also legitimate privacy, bias, and ethical issues to consider. This\narticle aims to help readers understand the possible influence of GPT,\naccording to its unique technological advantages, on the metaverse and how it\nmay be used to effectively create a more immersive and engaging virtual\nenvironment by evaluating these opportunities and obstacles."
  },
  {
    "arxiv_id": "2303.13679",
    "title": "Primer: Fast Private Transformer Inference on Encrypted Data",
    "url": "http://arxiv.org/abs/2303.13679v1",
    "abstract": "It is increasingly important to enable privacy-preserving inference for cloud\nservices based on Transformers. Post-quantum cryptographic techniques, e.g.,\nfully homomorphic encryption (FHE), and multi-party computation (MPC), are\npopular methods to support private Transformer inference. However, existing\nworks still suffer from prohibitively computational and communicational\noverhead. In this work, we present, Primer, to enable a fast and accurate\nTransformer over encrypted data for natural language processing tasks. In\nparticular, Primer is constructed by a hybrid cryptographic protocol optimized\nfor attention-based Transformer models, as well as techniques including\ncomputation merge and tokens-first ciphertext packing. Comprehensive\nexperiments on encrypted language modeling show that Primer achieves\nstate-of-the-art accuracy and reduces the inference latency by 90.6% ~ 97.5%\nover previous methods."
  },
  {
    "arxiv_id": "2303.13592",
    "title": "Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages",
    "url": "http://arxiv.org/abs/2303.13592v1",
    "abstract": "While code-mixing is a common linguistic practice in many parts of the world,\ncollecting high-quality and low-cost code-mixed data remains a challenge for\nnatural language processing (NLP) research. The recent proliferation of Large\nLanguage Models (LLMs) compels one to ask: how capable are these systems in\ngenerating code-mixed data? In this paper, we explore prompting multilingual\nLLMs in a zero-shot manner to generate code-mixed data for seven languages in\nSouth East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese,\nTamil, and Singlish. We find that publicly available multilingual\ninstruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of\nproducing texts with phrases or clauses from different languages. ChatGPT\nexhibits inconsistent capabilities in generating code-mixed texts, wherein its\nperformance varies depending on the prompt template and language pairing. For\ninstance, ChatGPT generates fluent and natural Singlish texts (an English-based\ncreole spoken in Singapore), but for English-Tamil language pair, the system\nmostly produces grammatically incorrect or semantically meaningless utterances.\nFurthermore, it may erroneously introduce languages not specified in the\nprompt. Based on our investigation, existing multilingual LLMs exhibit a wide\nrange of proficiency in code-mixed data generation for SEA languages. As such,\nwe advise against using LLMs in this context without extensive human checks."
  },
  {
    "arxiv_id": "2303.14956",
    "title": "Unified Text Structuralization with Instruction-tuned Language Models",
    "url": "http://arxiv.org/abs/2303.14956v1",
    "abstract": "Text structuralization is one of the important fields of natural language\nprocessing (NLP) consists of information extraction (IE) and structure\nformalization. However, current studies of text structuralization suffer from a\nshortage of manually annotated high-quality datasets from different domains and\nlanguages, which require specialized professional knowledge. In addition, most\nIE methods are designed for a specific type of structured data, e.g., entities,\nrelations, and events, making them hard to generalize to others. In this work,\nwe propose a simple and efficient approach to instruct large language model\n(LLM) to extract a variety of structures from texts. More concretely, we add a\nprefix and a suffix instruction to indicate the desired IE task and structure\ntype, respectively, before feeding the text into a LLM. Experiments on two LLMs\nshow that this approach can enable language models to perform comparable with\nother state-of-the-art methods on datasets of a variety of languages and\nknowledge, and can generalize to other IE sub-tasks via changing the content of\ninstruction. Another benefit of our approach is that it can help researchers to\nbuild datasets in low-source and domain-specific scenarios, e.g., fields in\nfinance and law, with low cost."
  },
  {
    "arxiv_id": "2303.14342",
    "title": "An Analysis of GPT-3's Performance in Grammatical Error Correction",
    "url": "http://arxiv.org/abs/2303.14342v1",
    "abstract": "GPT-3 and GPT-4 models are powerful, achieving high performance on a variety\nof Natural Language Processing tasks. However, there is a relative lack of\ndetailed published analysis of their performance on the task of grammatical\nerror correction (GEC). To address this, we perform experiments testing the\ncapabilities of a GPT-3.5 model (text-davinci-003) and a GPT-4 model\n(gpt-4-0314) on major GEC benchmarks. We compare the performance of different\nprompts in both zero-shot and few-shot settings, analyzing intriguing or\nproblematic outputs encountered with different prompt formats. We report the\nperformance of our best prompt on the BEA-2019 and JFLEG datasets, finding that\nthe GPT models can perform well in a sentence-level revision setting, with\nGPT-4 achieving a new high score on the JFLEG benchmark. Through human\nevaluation experiments, we compare the GPT models' corrections to source, human\nreference, and baseline GEC system sentences and observe differences in editing\nstrategies and how they are scored by human raters."
  },
  {
    "arxiv_id": "2303.15846",
    "title": "Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes",
    "url": "http://arxiv.org/abs/2303.15846v1",
    "abstract": "We investigate different natural language processing (NLP) approaches based\non contextualised word representations for the problem of early prediction of\nlung cancer using free-text patient medical notes of Dutch primary care\nphysicians. Because lung cancer has a low prevalence in primary care, we also\naddress the problem of classification under highly imbalanced classes.\nSpecifically, we use large Transformer-based pretrained language models (PLMs)\nand investigate: 1) how \\textit{soft prompt-tuning} -- an NLP technique used to\nadapt PLMs using small amounts of training data -- compares to standard model\nfine-tuning; 2) whether simpler static word embedding models (WEMs) can be more\nrobust compared to PLMs in highly imbalanced settings; and 3) how models fare\nwhen trained on notes from a small number of patients. We find that 1)\nsoft-prompt tuning is an efficient alternative to standard model fine-tuning;\n2) PLMs show better discrimination but worse calibration compared to simpler\nstatic word embedding models as the classification problem becomes more\nimbalanced; and 3) results when training models on small number of patients are\nmixed and show no clear differences between PLMs and WEMs. All our code is\navailable open source in\n\\url{https://bitbucket.org/aumc-kik/prompt_tuning_cancer_prediction/}."
  },
  {
    "arxiv_id": "2303.15727",
    "title": "Evaluation of ChatGPT for NLP-based Mental Health Applications",
    "url": "http://arxiv.org/abs/2303.15727v1",
    "abstract": "Large language models (LLM) have been successful in several natural language\nunderstanding tasks and could be relevant for natural language processing\n(NLP)-based mental health application research. In this work, we report the\nperformance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three\ntext-based mental health classification tasks: stress detection (2-class\nclassification), depression detection (2-class classification), and suicidality\ndetection (5-class classification). We obtained annotated social media posts\nfor the three classification tasks from public datasets. Then ChatGPT API\nclassified the social media posts with an input prompt for classification. We\nobtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression\ndetection, and suicidality detection, respectively. A baseline model that\nalways predicted the dominant class resulted in F1 scores of 0.35, 0.60, and\n0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a\npotential use of language models for mental health classification tasks."
  },
  {
    "arxiv_id": "2303.15714",
    "title": "Explicit Planning Helps Language Models in Logical Reasoning",
    "url": "http://arxiv.org/abs/2303.15714v1",
    "abstract": "Language models have been shown to perform remarkably well on a wide range of\nnatural language processing tasks. In this paper, we propose LEAP, a novel\nsystem that uses language models to perform multi-step logical reasoning and\nincorporates explicit planning into the inference procedure. Explicit planning\nenables the system to make more informed reasoning decisions at each step by\nlooking ahead into their future effects. Moreover, we propose a training\nstrategy that safeguards the planning process from being led astray by spurious\nfeatures. Our full system significantly outperforms other competing methods on\nmultiple standard datasets. When using small T5 models as its core selection\nand deduction components, our system performs competitively compared to GPT-3\ndespite having only about 1B parameters (i.e., 175 times smaller than GPT-3).\nWhen using GPT-3.5, it significantly outperforms chain-of-thought prompting on\nthe challenging PrOntoQA dataset. We have conducted extensive empirical studies\nto demonstrate that explicit planning plays a crucial role in the system's\nperformance."
  },
  {
    "arxiv_id": "2303.15619",
    "title": "Typhoon: Towards an Effective Task-Specific Masking Strategy for Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2303.15619v1",
    "abstract": "Through exploiting a high level of parallelism enabled by graphics processing\nunits, transformer architectures have enabled tremendous strides forward in the\nfield of natural language processing. In a traditional masked language model,\nspecial MASK tokens are used to prompt our model to gather contextual\ninformation from surrounding words to restore originally hidden information. In\nthis paper, we explore a task-specific masking framework for pre-trained large\nlanguage models that enables superior performance on particular downstream\ntasks on the datasets in the GLUE benchmark. We develop our own masking\nalgorithm, Typhoon, based on token input gradients, and compare this with other\nstandard baselines. We find that Typhoon offers performance competitive with\nwhole-word masking on the MRPC dataset. Our implementation can be found in a\npublic Github Repository."
  },
  {
    "arxiv_id": "2303.16854",
    "title": "AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators",
    "url": "http://arxiv.org/abs/2303.16854v1",
    "abstract": "Many natural language processing (NLP) tasks rely on labeled data to train\nmachine learning models with high performance. However, data annotation is\ntime-consuming and expensive, especially when the task involves a large amount\nof data or requires specialized domains. Recently, GPT-3.5 series models have\ndemonstrated remarkable few-shot and zero-shot ability across various NLP\ntasks. In this paper, we first claim that large language models (LLMs), such as\nGPT-3.5, can serve as an excellent crowdsourced annotator when provided with\nsufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM,\nan annotation system powered by LLMs, which adopts a two-step approach,\nexplain-then-annotate. Concretely, we first prompt LLMs to provide explanations\nfor why the specific ground truth answer/label was assigned for a given\nexample. Then, we construct the few-shot chain-of-thought prompt with the\nself-generated explanation and employ it to annotate the unlabeled data with\nLLMs. Our experiment results on three tasks, including user input and keyword\nrelevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or\nperforms on par with crowdsourced annotators. Furthermore, we build the first\nconversation-based information retrieval dataset employing AnnoLLM. This\ndataset is designed to facilitate the development of retrieval models capable\nof retrieving pertinent documents for conversational text. Human evaluation has\nvalidated the dataset's high quality."
  },
  {
    "arxiv_id": "2303.16537",
    "title": "LMExplainer: a Knowledge-Enhanced Explainer for Language Models",
    "url": "http://arxiv.org/abs/2303.16537v1",
    "abstract": "Language models (LMs) like GPT-4 are important in AI applications, but their\nopaque decision-making process reduces user trust, especially in\nsafety-critical areas. We introduce LMExplainer, a novel knowledge-grounded\nexplainer that clarifies the reasoning process of LMs through intuitive,\nhuman-understandable explanations. By leveraging a graph attention network\n(GAT) with a large-scale knowledge graph (KG), LMExplainer not only precisely\nnarrows the reasoning space to focus on the most relevant knowledge but also\ngrounds its reasoning in structured, verifiable knowledge to reduce\nhallucinations and enhance interpretability. LMExplainer effectively generates\nhuman-understandable explanations to enhance transparency and streamline the\ndecision-making process. Additionally, by incorporating debugging into the\nexplanation, it offers expertise suggestions that improve LMs from a\ndevelopmental perspective. Thus, LMExplainer stands as an enhancement in making\nLMs more accessible and understandable to users. We evaluate LMExplainer on\nbenchmark datasets such as CommonsenseQA and OpenBookQA, demonstrating that it\noutperforms most existing methods. By comparing the explanations generated by\nLMExplainer with those of other models, we show that our approach offers more\ncomprehensive and clearer explanations of the reasoning process. LMExplainer\nprovides a deeper understanding of the inner workings of LMs, advancing towards\nmore reliable, transparent, and equitable AI."
  },
  {
    "arxiv_id": "2303.17728",
    "title": "Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text",
    "url": "http://arxiv.org/abs/2303.17728v1",
    "abstract": "Detecting protein-protein interactions (PPIs) is crucial for understanding\ngenetic mechanisms, disease pathogenesis, and drug design. However, with the\nfast-paced growth of biomedical literature, there is a growing need for\nautomated and accurate extraction of PPIs to facilitate scientific knowledge\ndiscovery. Pre-trained language models, such as generative pre-trained\ntransformers (GPT) and bidirectional encoder representations from transformers\n(BERT), have shown promising results in natural language processing (NLP)\ntasks. We evaluated the performance of PPI identification of multiple GPT and\nBERT models using three manually curated gold-standard corpora: Learning\nLanguage in Logic (LLL) with 164 PPIs in 77 sentences, Human Protein Reference\nDatabase with 163 PPIs in 145 sentences, and Interaction Extraction Performance\nAssessment with 335 PPIs in 486 sentences. BERT-based models achieved the best\noverall performance, with BioBERT achieving the highest recall (91.95%) and\nF1-score (86.84%) and PubMedBERT achieving the highest precision (85.25%).\nInterestingly, despite not being explicitly trained for biomedical texts, GPT-4\nachieved commendable performance, comparable to the top-performing BERT models.\nIt achieved a precision of 88.37%, a recall of 85.14%, and an F1-score of\n86.49% on the LLL dataset. These results suggest that GPT models can\neffectively detect PPIs from text data, offering promising avenues for\napplication in biomedical literature mining. Further research could explore how\nthese models might be fine-tuned for even more specialized tasks within the\nbiomedical domain."
  },
  {
    "arxiv_id": "2303.17636",
    "title": "Whether and When does Endoscopy Domain Pretraining Make Sense?",
    "url": "http://arxiv.org/abs/2303.17636v1",
    "abstract": "Automated endoscopy video analysis is a challenging task in medical computer\nvision, with the primary objective of assisting surgeons during procedures. The\ndifficulty arises from the complexity of surgical scenes and the lack of a\nsufficient amount of annotated data. In recent years, large-scale pretraining\nhas shown great success in natural language processing and computer vision\ncommunities. These approaches reduce the need for annotated data, which is\nalways a concern in the medical domain. However, most works on endoscopic video\nunderstanding use models pretrained on natural images, creating a domain gap\nbetween pretraining and finetuning. In this work, we investigate the need for\nendoscopy domain-specific pretraining based on downstream objectives. To this\nend, we first collect Endo700k, the largest publicly available corpus of\nendoscopic images, extracted from nine public Minimally Invasive Surgery (MIS)\ndatasets. Endo700k comprises more than 700,000 unannotated raw images. Next, we\nintroduce EndoViT, an endoscopy pretrained Vision Transformer (ViT). Through\nablations, we demonstrate that domain-specific pretraining is particularly\nbeneficial for more complex downstream tasks, such as Action Triplet Detection,\nand less effective and even unnecessary for simpler tasks, such as Surgical\nPhase Recognition. We will release both our code and pretrained models upon\nacceptance to facilitate further research in this direction."
  },
  {
    "arxiv_id": "2304.00869",
    "title": "GreekBART: The First Pretrained Greek Sequence-to-Sequence Model",
    "url": "http://arxiv.org/abs/2304.00869v1",
    "abstract": "The era of transfer learning has revolutionized the fields of Computer Vision\nand Natural Language Processing, bringing powerful pretrained models with\nexceptional performance across a variety of tasks. Specifically, Natural\nLanguage Processing tasks have been dominated by transformer-based language\nmodels. In Natural Language Inference and Natural Language Generation tasks,\nthe BERT model and its variants, as well as the GPT model and its successors,\ndemonstrated exemplary performance. However, the majority of these models are\npretrained and assessed primarily for the English language or on a multilingual\ncorpus. In this paper, we introduce GreekBART, the first Seq2Seq model based on\nBART-base architecture and pretrained on a large-scale Greek corpus. We\nevaluate and compare GreekBART against BART-random, Greek-BERT, and XLM-R on a\nvariety of discriminative tasks. In addition, we examine its performance on two\nNLG tasks from GreekSUM, a newly introduced summarization dataset for the Greek\nlanguage. The model, the code, and the new summarization dataset will be\npublicly available."
  },
  {
    "arxiv_id": "2304.00723",
    "title": "Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study",
    "url": "http://arxiv.org/abs/2304.00723v1",
    "abstract": "Evaluating the quality of generated text is a challenging task in NLP, due to\nthe inherent complexity and diversity of text. Recently, large language models\n(LLMs) have garnered significant attention due to their impressive performance\nin various tasks. Therefore, we present this paper to investigate the\neffectiveness of LLMs, especially ChatGPT, and explore ways to optimize their\nuse in assessing text quality. We compared three kinds of reference-free\nevaluation methods. The experimental results prove that ChatGPT is capable of\nevaluating text quality effectively from various perspectives without reference\nand demonstrates superior performance than most existing automatic metrics. In\nparticular, the Explicit Score, which utilizes ChatGPT to generate a numeric\nscore measuring text quality, is the most effective and reliable method among\nthe three exploited approaches. However, directly comparing the quality of two\ntexts may lead to suboptimal results. We believe this paper will provide\nvaluable insights for evaluating text quality with LLMs and have released the\nused data."
  },
  {
    "arxiv_id": "2304.01964",
    "title": "PromptAid: Prompt Exploration, Perturbation, Testing and Iteration using Visual Analytics for Large Language Models",
    "url": "http://arxiv.org/abs/2304.01964v1",
    "abstract": "Large Language Models (LLMs) have gained widespread popularity due to their\nability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple\nnatural language prompt. Part of the appeal for LLMs is their approachability\nto the general public, including individuals with no prior technical experience\nin NLP techniques. However, natural language prompts can vary significantly in\nterms of their linguistic structure, context, and other semantics. Modifying\none or more of these aspects can result in significant differences in task\nperformance. Non-expert users may find it challenging to identify the changes\nneeded to improve a prompt, especially when they lack domain-specific knowledge\nand lack appropriate feedback. To address this challenge, we present PromptAid,\na visual analytics system designed to interactively create, refine, and test\nprompts through exploration, perturbation, testing, and iteration. PromptAid\nuses multiple, coordinated visualizations which allow users to improve prompts\nby using the three strategies: keyword perturbations, paraphrasing\nperturbations, and obtaining the best set of in-context few-shot examples.\nPromptAid was designed through an iterative prototyping process involving NLP\nexperts and was evaluated through quantitative and qualitative assessments for\nLLMs. Our findings indicate that PromptAid helps users to iterate over prompt\ntemplate alterations with less cognitive overhead, generate diverse prompts\nwith help of recommendations, and analyze the performance of the generated\nprompts while surpassing existing state-of-the-art prompting interfaces in\nperformance."
  },
  {
    "arxiv_id": "2304.01852",
    "title": "Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models",
    "url": "http://arxiv.org/abs/2304.01852v1",
    "abstract": "This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and\nGPT-4) research, state-of-the-art large language models (LLM) from the GPT\nseries, and their prospective applications across diverse domains. Indeed, key\ninnovations such as large-scale pre-training that captures knowledge across the\nentire world wide web, instruction fine-tuning and Reinforcement Learning from\nHuman Feedback (RLHF) have played significant roles in enhancing LLMs'\nadaptability and performance. We performed an in-depth analysis of 194 relevant\npapers on arXiv, encompassing trend analysis, word cloud representation, and\ndistribution analysis across various application domains. The findings reveal a\nsignificant and increasing interest in ChatGPT-related research, predominantly\ncentered on direct natural language processing applications, while also\ndemonstrating considerable potential in areas ranging from education and\nhistory to mathematics, medicine, and physics. This study endeavors to furnish\ninsights into ChatGPT's capabilities, potential implications, ethical concerns,\nand offer direction for future advancements in this field."
  },
  {
    "arxiv_id": "2304.01746",
    "title": "Is ChatGPT a Highly Fluent Grammatical Error Correction System? A Comprehensive Evaluation",
    "url": "http://arxiv.org/abs/2304.01746v1",
    "abstract": "ChatGPT, a large-scale language model based on the advanced GPT-3.5\narchitecture, has shown remarkable potential in various Natural Language\nProcessing (NLP) tasks. However, there is currently a dearth of comprehensive\nstudy exploring its potential in the area of Grammatical Error Correction\n(GEC). To showcase its capabilities in GEC, we design zero-shot\nchain-of-thought (CoT) and few-shot CoT settings using in-context learning for\nChatGPT. Our evaluation involves assessing ChatGPT's performance on five\nofficial test sets in three different languages, along with three\ndocument-level GEC test sets in English. Our experimental results and human\nevaluations demonstrate that ChatGPT has excellent error detection capabilities\nand can freely correct errors to make the corrected sentences very fluent,\npossibly due to its over-correction tendencies and not adhering to the\nprinciple of minimal edits. Additionally, its performance in non-English and\nlow-resource settings highlights its potential in multilingual GEC tasks.\nHowever, further analysis of various types of errors at the document-level has\nshown that ChatGPT cannot effectively correct agreement, coreference, tense\nerrors across sentences, and cross-sentence boundary errors."
  },
  {
    "arxiv_id": "2304.01665",
    "title": "Neural Comprehension: Language Models with Compiled Neural Networks",
    "url": "http://arxiv.org/abs/2304.01665v1",
    "abstract": "Language models' (LMs) proficiency in handling deterministic symbolic\nreasoning and rule-based tasks remains limited due to their dependency implicit\nlearning on textual data. To endow LMs with genuine rule comprehension\nabilities, we propose \"Neural Comprehension\" - a framework that synergistically\nintegrates compiled neural networks (CoNNs) into the standard transformer\narchitecture. CoNNs are neural modules designed to explicitly encode rules\nthrough artificially generated attention weights. By incorporating CoNN\nmodules, the Neural Comprehension framework enables LMs to accurately and\nrobustly execute rule-intensive symbolic tasks. Extensive experiments\ndemonstrate the superiority of our approach over existing techniques in terms\nof length generalization, efficiency, and interpretability for symbolic\noperations. Furthermore, it can be applied to LMs across different model\nscales, outperforming tool-calling methods in arithmetic reasoning tasks while\nmaintaining superior inference efficiency. Our work highlights the potential of\nseamlessly unifying explicit rule learning via CoNNs and implicit pattern\nlearning in LMs, paving the way for true symbolic comprehension capabilities."
  },
  {
    "arxiv_id": "2304.01472",
    "title": "Unsupervised Brain Tumor Segmentation with Image-based Prompts",
    "url": "http://arxiv.org/abs/2304.01472v1",
    "abstract": "Automated brain tumor segmentation based on deep learning (DL) has achieved\npromising performance. However, it generally relies on annotated images for\nmodel training, which is not always feasible in clinical settings. Therefore,\nthe development of unsupervised DL-based brain tumor segmentation approaches\nwithout expert annotations is desired. Motivated by the success of prompt\nlearning (PL) in natural language processing, we propose an approach to\nunsupervised brain tumor segmentation by designing image-based prompts that\nallow indication of brain tumors, and this approach is dubbed as PL-based Brain\nTumor Segmentation (PL-BTS). Specifically, instead of directly training a model\nfor brain tumor segmentation with a large amount of annotated data, we seek to\ntrain a model that can answer the question: is a voxel in the input image\nassociated with tumor-like hyper-/hypo-intensity? Such a model can be trained\nby artificially generating tumor-like hyper-/hypo-intensity on images without\ntumors with hand-crafted designs. Since the hand-crafted designs may be too\nsimplistic to represent all kinds of real tumors, the trained model may overfit\nthe simplistic hand-crafted task rather than actually answer the question of\nabnormality. To address this problem, we propose the use of a validation task,\nwhere we generate a different hand-crafted task to monitor overfitting. In\naddition, we propose PL-BTS+ that further improves PL-BTS by exploiting\nunannotated images with brain tumors. Compared with competing unsupervised\nmethods, the proposed method has achieved marked improvements on both public\nand in-house datasets, and we have also demonstrated its possible extension to\nother brain lesion segmentation tasks."
  },
  {
    "arxiv_id": "2304.02426",
    "title": "ParroT: Translating During Chat Using Large Language Models",
    "url": "http://arxiv.org/abs/2304.02426v2",
    "abstract": "Large language models (LLMs) like ChatGPT have exhibited remarkable abilities\non a wide range of natural language processing~(NLP) tasks, including various\nmachine translation abilities accomplished during chat. However, these models\nare only accessible through restricted APIs, which creates barriers to new\nresearch and advancements in the field. Therefore, we propose ParroT, a\nframework to enhance and regulate the translation abilities during chat based\non open-source LLMs (e.g., LLaMA), human-written translation and feedback data.\nSpecifically, ParroT reformulates translation data into the\ninstruction-following style, and introduces a \"$\\mathbf{Hint}$\" field for\nincorporating extra requirements to regulate the translation process.\nAccordingly, we propose three instruction types for finetuning ParroT models,\nincluding translation instruction, contrastive instruction, and error-guided\ninstruction. Experiments on Flores subsets and WMT22 test sets suggest that\ntranslation instruction improves the translation performance of vanilla LLMs\nsignificantly while error-guided instruction can lead to further improvement,\nwhich demonstrates the importance of learning from low-quality translations\nannotated by humans. We also demonstrate the potential of automatic evaluation\ntools in providing quality information of translations, when constructing\nerror-guided instructions for directions that lack human annotation data.\nPlease refer to our Github project for more implementation details:\nhttps://github.com/wxjiao/ParroT"
  },
  {
    "arxiv_id": "2304.02210",
    "title": "Document-Level Machine Translation with Large Language Models",
    "url": "http://arxiv.org/abs/2304.02210v1",
    "abstract": "Large language models (LLMs) such as ChatGPT can produce coherent, cohesive,\nrelevant, and fluent answers for various natural language processing (NLP)\ntasks. Taking document-level machine translation (MT) as a testbed, this paper\nprovides an in-depth evaluation of LLMs' ability on discourse modeling. The\nstudy focuses on three aspects: 1) Effects of Context-Aware Prompts, where we\ninvestigate the impact of different prompts on document-level translation\nquality and discourse phenomena; 2) Comparison of Translation Models, where we\ncompare the translation performance of ChatGPT with commercial MT systems and\nadvanced document-level MT methods; 3) Analysis of Discourse Modelling\nAbilities, where we further probe discourse knowledge encoded in LLMs and shed\nlight on impacts of training techniques on discourse modeling. By evaluating on\na number of benchmarks, we surprisingly find that LLMs have demonstrated\nsuperior performance and show potential to become a new paradigm for\ndocument-level translation: 1) leveraging their powerful long-text modeling\ncapabilities, GPT-3.5 and GPT-4 outperform commercial MT systems in terms of\nhuman evaluation; 2) GPT-4 demonstrates a stronger ability for probing\nlinguistic knowledge than GPT-3.5. This work highlights the challenges and\nopportunities of LLMs for MT, which we hope can inspire the future design and\nevaluation of LLMs.We release our data and annotations at\nhttps://github.com/longyuewangdcu/Document-MT-LLM."
  },
  {
    "arxiv_id": "2304.02182",
    "title": "Unleashing the Power of ChatGPT for Translation: An Empirical Study",
    "url": "http://arxiv.org/abs/2304.02182v1",
    "abstract": "The recently released ChatGPT has demonstrated surprising abilities in\nnatural language understanding and natural language generation. Machine\ntranslation relies heavily on the abilities of language understanding and\ngeneration. Thus, in this paper, we explore how to assist machine translation\nwith ChatGPT. We adopt several translation prompts on a wide range of\ntranslations. Our experimental results show that ChatGPT with designed\ntranslation prompts can achieve comparable or better performance over\ncommercial translation systems for high-resource language translations. We\nfurther evaluate the translation quality using multiple references, and ChatGPT\nachieves superior performance compared to commercial systems. We also conduct\nexperiments on domain-specific translations, the final results show that\nChatGPT is able to comprehend the provided domain keyword and adjust\naccordingly to output proper translations. At last, we perform few-shot prompts\nthat show consistent improvement across different base prompts. Our work\nprovides empirical evidence that ChatGPT still has great potential in\ntranslations."
  },
  {
    "arxiv_id": "2304.03153",
    "title": "Zero-Shot Next-Item Recommendation using Large Pretrained Language Models",
    "url": "http://arxiv.org/abs/2304.03153v1",
    "abstract": "Large language models (LLMs) have achieved impressive zero-shot performance\nin various natural language processing (NLP) tasks, demonstrating their\ncapabilities for inference without training examples. Despite their success, no\nresearch has yet explored the potential of LLMs to perform next-item\nrecommendations in the zero-shot setting. We have identified two major\nchallenges that must be addressed to enable LLMs to act effectively as\nrecommenders. First, the recommendation space can be extremely large for LLMs,\nand LLMs do not know about the target user's past interacted items and\npreferences. To address this gap, we propose a prompting strategy called\nZero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make\nnext-item recommendations. Specifically, the NIR-based strategy involves using\nan external module to generate candidate items based on user-filtering or\nitem-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3\nto carry subtasks that capture the user's preferences, select representative\npreviously watched movies, and recommend a ranked list of 10 movies. We\nevaluate the proposed approach using GPT-3 on MovieLens 100K dataset and show\nthat it achieves strong zero-shot performance, even outperforming some strong\nsequential recommendation models trained on the entire training dataset. These\npromising results highlight the ample research opportunities to use LLMs as\nrecommenders. The code can be found at\nhttps://github.com/AGI-Edgerunners/LLM-Next-Item-Rec."
  },
  {
    "arxiv_id": "2304.03012",
    "title": "PointCAT: Cross-Attention Transformer for point cloud",
    "url": "http://arxiv.org/abs/2304.03012v1",
    "abstract": "Transformer-based models have significantly advanced natural language\nprocessing and computer vision in recent years. However, due to the irregular\nand disordered structure of point cloud data, transformer-based models for 3D\ndeep learning are still in their infancy compared to other methods. In this\npaper we present Point Cross-Attention Transformer (PointCAT), a novel\nend-to-end network architecture using cross-attentions mechanism for point\ncloud representing. Our approach combines multi-scale features via two seprate\ncross-attention transformer branches. To reduce the computational increase\nbrought by multi-branch structure, we further introduce an efficient model for\nshape classification, which only process single class token of one branch as a\nquery to calculate attention map with the other. Extensive experiments\ndemonstrate that our method outperforms or achieves comparable performance to\nseveral approaches in shape classification, part segmentation and semantic\nsegmentation tasks."
  },
  {
    "arxiv_id": "2304.02868",
    "title": "Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions",
    "url": "http://arxiv.org/abs/2304.02868v1",
    "abstract": "Large language models (LLMs) such as ChatGPT and GPT-4 have recently\ndemonstrated their remarkable abilities of communicating with human users. In\nthis technical report, we take an initiative to investigate their capacities of\nplaying text games, in which a player has to understand the environment and\nrespond to situations by having dialogues with the game world. Our experiments\nshow that ChatGPT performs competitively compared to all the existing systems\nbut still exhibits a low level of intelligence. Precisely, ChatGPT can not\nconstruct the world model by playing the game or even reading the game manual;\nit may fail to leverage the world knowledge that it already has; it cannot\ninfer the goal of each step as the game progresses. Our results open up new\nresearch questions at the intersection of artificial intelligence, machine\nlearning, and natural language processing."
  },
  {
    "arxiv_id": "2304.02796",
    "title": "Opportunities and challenges of ChatGPT for design knowledge management",
    "url": "http://arxiv.org/abs/2304.02796v1",
    "abstract": "Recent advancements in Natural Language Processing have opened up new\npossibilities for the development of large language models like ChatGPT, which\ncan facilitate knowledge management in the design process by providing\ndesigners with access to a vast array of relevant information. However,\nintegrating ChatGPT into the design process also presents new challenges. In\nthis paper, we provide a concise review of the classification and\nrepresentation of design knowledge, and past efforts to support designers in\nacquiring knowledge. We analyze the opportunities and challenges that ChatGPT\npresents for knowledge management in design and propose promising future\nresearch directions. A case study is conducted to validate the advantages and\ndrawbacks of ChatGPT, showing that designers can acquire targeted knowledge\nfrom various domains, but the quality of the acquired knowledge is highly\ndependent on the prompt."
  },
  {
    "arxiv_id": "2304.02768",
    "title": "Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review",
    "url": "http://arxiv.org/abs/2304.02768v1",
    "abstract": "The combined growth of available data and their unstructured nature has\nreceived increased interest in natural language processing (NLP) techniques to\nmake value of these data assets since this format is not suitable for\nstatistical analysis. This work presents a systematic literature review of\nstate-of-the-art advances using transformer-based methods on electronic medical\nrecords (EMRs) in different NLP tasks. To the best of our knowledge, this work\nis unique in providing a comprehensive review of research on transformer-based\nmethods for NLP applied to the EMR field. In the initial query, 99 articles\nwere selected from three public databases and filtered into 65 articles for\ndetailed analysis. The papers were analyzed with respect to the business\nproblem, NLP task, models and techniques, availability of datasets,\nreproducibility of modeling, language, and exchange format. The paper presents\nsome limitations of current research and some recommendations for further\nresearch."
  },
  {
    "arxiv_id": "2304.03347",
    "title": "On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis",
    "url": "http://arxiv.org/abs/2304.03347v1",
    "abstract": "The latest large language models (LLMs) such as ChatGPT, exhibit strong\ncapabilities in automated mental health analysis. However, existing relevant\nstudies bear several limitations, including inadequate evaluations, lack of\nprompting strategies, and ignorance of exploring LLMs for explainability. To\nbridge these gaps, we comprehensively evaluate the mental health analysis and\nemotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore\nthe effects of different prompting strategies with unsupervised and distantly\nsupervised emotional information. Based on these prompts, we explore LLMs for\ninterpretable mental health analysis by instructing them to generate\nexplanations for each of their decisions. We convey strict human evaluations to\nassess the quality of the generated explanations, leading to a novel dataset\nwith 163 human-assessed explanations. We benchmark existing automatic\nevaluation metrics on this dataset to guide future related works. According to\nthe results, ChatGPT shows strong in-context learning ability but still has a\nsignificant gap with advanced task-specific methods. Careful prompt engineering\nwith emotional cues and expert-written few-shot examples can also effectively\nimprove performance on mental health analysis. In addition, ChatGPT generates\nexplanations that approach human performance, showing its great potential in\nexplainable mental health analysis."
  },
  {
    "arxiv_id": "2304.04662",
    "title": "SELFormer: Molecular Representation Learning via SELFIES Language Models",
    "url": "http://arxiv.org/abs/2304.04662v1",
    "abstract": "Automated computational analysis of the vast chemical space is critical for\nnumerous fields of research such as drug discovery and material science.\nRepresentation learning techniques have recently been employed with the primary\nobjective of generating compact and informative numerical expressions of\ncomplex data. One approach to efficiently learn molecular representations is\nprocessing string-based notations of chemicals via natural language processing\n(NLP) algorithms. Majority of the methods proposed so far utilize SMILES\nnotations for this purpose; however, SMILES is associated with numerous\nproblems related to validity and robustness, which may prevent the model from\neffectively uncovering the knowledge hidden in the data. In this study, we\npropose SELFormer, a transformer architecture-based chemical language model\nthat utilizes a 100% valid, compact and expressive notation, SELFIES, as input,\nin order to learn flexible and high-quality molecular representations.\nSELFormer is pre-trained on two million drug-like compounds and fine-tuned for\ndiverse molecular property prediction tasks. Our performance evaluation has\nrevealed that, SELFormer outperforms all competing methods, including graph\nlearning-based approaches and SMILES-based chemical language models, on\npredicting aqueous solubility of molecules and adverse drug reactions. We also\nvisualized molecular representations learned by SELFormer via dimensionality\nreduction, which indicated that even the pre-trained model can discriminate\nmolecules with differing structural properties. We shared SELFormer as a\nprogrammatic tool, together with its datasets and pre-trained models. Overall,\nour research demonstrates the benefit of using the SELFIES notations in the\ncontext of chemical language modeling and opens up new possibilities for the\ndesign and discovery of novel drug candidates with desired features."
  },
  {
    "arxiv_id": "2304.04193",
    "title": "Extractive Summarization via ChatGPT for Faithful Summary Generation",
    "url": "http://arxiv.org/abs/2304.04193v1",
    "abstract": "Extractive summarization is a crucial task in natural language processing\nthat aims to condense long documents into shorter versions by directly\nextracting sentences. The recent introduction of large language models has\nattracted significant interest in the NLP community due to its remarkable\nperformance on a wide range of downstream tasks. This paper first presents a\nthorough evaluation of ChatGPT's performance on extractive summarization and\ncompares it with traditional fine-tuning methods on various benchmark datasets.\nOur experimental analysis reveals that ChatGPT exhibits inferior extractive\nsummarization performance in terms of ROUGE scores compared to existing\nsupervised systems, while achieving higher performance based on LLM-based\nevaluation metrics. In addition, we explore the effectiveness of in-context\nlearning and chain-of-thought reasoning for enhancing its performance.\nFurthermore, we find that applying an extract-then-generate pipeline with\nChatGPT yields significant performance improvements over abstractive baselines\nin terms of summary faithfulness. These observations highlight potential\ndirections for enhancing ChatGPT's capabilities in faithful summarization using\ntwo-stage approaches."
  },
  {
    "arxiv_id": "2304.03879",
    "title": "GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation",
    "url": "http://arxiv.org/abs/2304.03879v1",
    "abstract": "Recent advancements in Natural Language Processing (NLP) have led to the\ndevelopment of NLP-based recommender systems that have shown superior\nperformance. However, current models commonly treat items as mere IDs and adopt\ndiscriminative modeling, resulting in limitations of (1) fully leveraging the\ncontent information of items and the language modeling capabilities of NLP\nmodels; (2) interpreting user interests to improve relevance and diversity; and\n(3) adapting practical circumstances such as growing item inventories. To\naddress these limitations, we present GPT4Rec, a novel and flexible generative\nframework inspired by search engines. It first generates hypothetical \"search\nqueries\" given item titles in a user's history, and then retrieves items for\nrecommendation by searching these queries. The framework overcomes previous\nlimitations by learning both user and item embeddings in the language space. To\nwell-capture user interests with different aspects and granularity for\nimproving relevance and diversity, we propose a multi-query generation\ntechnique with beam search. The generated queries naturally serve as\ninterpretable representations of user interests and can be searched to\nrecommend cold-start items. With GPT-2 language model and BM25 search engine,\nour framework outperforms state-of-the-art methods by $75.7\\%$ and $22.2\\%$ in\nRecall@K on two public datasets. Experiments further revealed that multi-query\ngeneration with beam search improves both the diversity of retrieved items and\nthe coverage of a user's multi-interests. The adaptiveness and interpretability\nof generated queries are discussed with qualitative case studies."
  },
  {
    "arxiv_id": "2304.05335",
    "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models",
    "url": "http://arxiv.org/abs/2304.05335v1",
    "abstract": "Large language models (LLMs) have shown incredible capabilities and\ntranscended the natural language processing (NLP) community, with adoption\nthroughout many services like healthcare, therapy, education, and customer\nservice. Since users include people with critical information needs like\nstudents or patients engaging with chatbots, the safety of these systems is of\nprime importance. Therefore, a clear understanding of the capabilities and\nlimitations of LLMs is necessary. To this end, we systematically evaluate\ntoxicity in over half a million generations of ChatGPT, a popular\ndialogue-based LLM. We find that setting the system parameter of ChatGPT by\nassigning it a persona, say that of the boxer Muhammad Ali, significantly\nincreases the toxicity of generations. Depending on the persona assigned to\nChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect\nstereotypes, harmful dialogue, and hurtful opinions. This may be potentially\ndefamatory to the persona and harmful to an unsuspecting user. Furthermore, we\nfind concerning patterns where specific entities (e.g., certain races) are\ntargeted more than others (3x more) irrespective of the assigned persona, that\nreflect inherent discriminatory biases in the model. We hope that our findings\ninspire the broader AI community to rethink the efficacy of current safety\nguardrails and develop better techniques that lead to robust, safe, and\ntrustworthy AI systems."
  },
  {
    "arxiv_id": "2304.05263",
    "title": "Prompt Learning for News Recommendation",
    "url": "http://arxiv.org/abs/2304.05263v1",
    "abstract": "Some recent \\textit{news recommendation} (NR) methods introduce a Pre-trained\nLanguage Model (PLM) to encode news representation by following the vanilla\npre-train and fine-tune paradigm with carefully-designed\nrecommendation-specific neural networks and objective functions. Due to the\ninconsistent task objective with that of PLM, we argue that their modeling\nparadigm has not well exploited the abundant semantic information and\nlinguistic knowledge embedded in the pre-training process. Recently, the\npre-train, prompt, and predict paradigm, called \\textit{prompt learning}, has\nachieved many successes in natural language processing domain. In this paper,\nwe make the first trial of this new paradigm to develop a \\textit{Prompt\nLearning for News Recommendation} (Prompt4NR) framework, which transforms the\ntask of predicting whether a user would click a candidate news as a cloze-style\nmask-prediction task. Specifically, we design a series of prompt templates,\nincluding discrete, continuous, and hybrid templates, and construct their\ncorresponding answer spaces to examine the proposed Prompt4NR framework.\nFurthermore, we use the prompt ensembling to integrate predictions from\nmultiple prompt templates. Extensive experiments on the MIND dataset validate\nthe effectiveness of our Prompt4NR with a set of new benchmark results."
  },
  {
    "arxiv_id": "2304.05351",
    "title": "The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges",
    "url": "http://arxiv.org/abs/2304.05351v1",
    "abstract": "Recently, large language models (LLMs) like ChatGPT have demonstrated\nremarkable performance across a variety of natural language processing tasks.\nHowever, their effectiveness in the financial domain, specifically in\npredicting stock market movements, remains to be explored. In this paper, we\nconduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal\nstock movement prediction, on three tweets and historical stock price datasets.\nOur findings indicate that ChatGPT is a \"Wall Street Neophyte\" with limited\nsuccess in predicting stock movements, as it underperforms not only\nstate-of-the-art methods but also traditional methods like linear regression\nusing price features. Despite the potential of Chain-of-Thought prompting\nstrategies and the inclusion of tweets, ChatGPT's performance remains subpar.\nFurthermore, we observe limitations in its explainability and stability,\nsuggesting the need for more specialized training or fine-tuning. This research\nprovides insights into ChatGPT's capabilities and serves as a foundation for\nfuture work aimed at improving financial market analysis and prediction by\nleveraging social media sentiment and historical stock data."
  },
  {
    "arxiv_id": "2304.05613",
    "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
    "url": "http://arxiv.org/abs/2304.05613v1",
    "abstract": "Over the last few years, large language models (LLMs) have emerged as the\nmost important breakthroughs in natural language processing (NLP) that\nfundamentally transform research and developments in the field. ChatGPT\nrepresents one of the most exciting LLM systems developed recently to showcase\nimpressive skills for language generation and highly attract public attention.\nAmong various exciting applications discovered for ChatGPT in English, the\nmodel can process and generate texts for multiple languages due to its\nmultilingual training data. Given the broad adoption of ChatGPT for English in\ndifferent problems and areas, a natural question is whether ChatGPT can also be\napplied effectively for other languages or it is necessary to develop more\nlanguage-specific technologies. The answer to this question requires a thorough\nevaluation of ChatGPT over multiple tasks with diverse languages and large\ndatasets (i.e., beyond reported anecdotes), which is still missing or limited\nin current research. Our work aims to fill this gap for the evaluation of\nChatGPT and similar LLMs to provide more comprehensive information for\nmultilingual NLP applications. While this work will be an ongoing effort to\ninclude additional experiments in the future, our current paper evaluates\nChatGPT on 7 different tasks, covering 37 diverse languages with high, medium,\nlow, and extremely low resources. We also focus on the zero-shot learning\nsetting for ChatGPT to improve reproducibility and better simulate the\ninteractions of general users. Compared to the performance of previous models,\nour extensive experimental results demonstrate a worse performance of ChatGPT\nfor different NLP tasks and languages, calling for further research to develop\nbetter models and understanding for multilingual learning."
  },
  {
    "arxiv_id": "2304.05396",
    "title": "SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model",
    "url": "http://arxiv.org/abs/2304.05396v1",
    "abstract": "Foundation models have taken over natural language processing and image\ngeneration domains due to the flexibility of prompting. With the recent\nintroduction of the Segment Anything Model (SAM), this prompt-driven paradigm\nhas entered image segmentation with a hitherto unexplored abundance of\ncapabilities. The purpose of this paper is to conduct an initial evaluation of\nthe out-of-the-box zero-shot capabilities of SAM for medical image\nsegmentation, by evaluating its performance on an abdominal CT organ\nsegmentation task, via point or bounding box based prompting. We show that SAM\ngeneralizes well to CT data, making it a potential catalyst for the advancement\nof semi-automatic segmentation tools for clinicians. We believe that this\nfoundation model, while not reaching state-of-the-art segmentation performance\nin our investigations, can serve as a highly potent starting point for further\nadaptations of such models to the intricacies of the medical domain. Keywords:\nmedical image segmentation, SAM, foundation models, zero-shot learning"
  },
  {
    "arxiv_id": "2304.06306",
    "title": "Efficient Multimodal Fusion via Interactive Prompting",
    "url": "http://arxiv.org/abs/2304.06306v1",
    "abstract": "Large-scale pre-training has brought unimodal fields such as computer vision\nand natural language processing to a new era. Following this trend, the size of\nmulti-modal learning models constantly increases, leading to an urgent need to\nreduce the massive computational cost of finetuning these models for downstream\ntasks. In this paper, we propose an efficient and flexible multimodal fusion\nmethod, namely PMF, tailored for fusing unimodally pre-trained transformers.\nSpecifically, we first present a modular multimodal fusion framework that\nexhibits high flexibility and facilitates mutual interactions among different\nmodalities. In addition, we disentangle vanilla prompts into three types in\norder to learn different optimizing objectives for multimodal learning. It is\nalso worth noting that we propose to add prompt vectors only on the deep layers\nof the unimodal transformers, thus significantly reducing the training memory\nusage. Experiment results show that our proposed method achieves comparable\nperformance to several other multimodal finetuning methods with less than 3%\ntrainable parameters and up to 66% saving of training memory usage."
  },
  {
    "arxiv_id": "2304.07235",
    "title": "Optimal inference of a generalised Potts model by single-layer transformers with factored attention",
    "url": "http://arxiv.org/abs/2304.07235v1",
    "abstract": "Transformers are neural networks that revolutionized natural language\nprocessing and machine learning. They process sequences of inputs, like words,\nusing a mechanism called self-attention, which is trained via masked language\nmodeling (MLM). In MLM, a word is randomly masked in an input sequence, and the\nnetwork is trained to predict the missing word. Despite the practical success\nof transformers, it remains unclear what type of data distribution\nself-attention can learn efficiently. Here, we show analytically that if one\ndecouples the treatment of word positions and embeddings, a single layer of\nself-attention learns the conditionals of a generalized Potts model with\ninteractions between sites and Potts colors. Moreover, we show that training\nthis neural network is exactly equivalent to solving the inverse Potts problem\nby the so-called pseudo-likelihood method, well known in statistical physics.\nUsing this mapping, we compute the generalization error of self-attention in a\nmodel scenario analytically using the replica method."
  },
  {
    "arxiv_id": "2304.07183",
    "title": "Just Tell Me: Prompt Engineering in Business Process Management",
    "url": "http://arxiv.org/abs/2304.07183v1",
    "abstract": "GPT-3 and several other language models (LMs) can effectively address various\nnatural language processing (NLP) tasks, including machine translation and text\nsummarization. Recently, they have also been successfully employed in the\nbusiness process management (BPM) domain, e.g., for predictive process\nmonitoring and process extraction from text. This, however, typically requires\nfine-tuning the employed LM, which, among others, necessitates large amounts of\nsuitable training data. A possible solution to this problem is the use of\nprompt engineering, which leverages pre-trained LMs without fine-tuning them.\nRecognizing this, we argue that prompt engineering can help bring the\ncapabilities of LMs to BPM research. We use this position paper to develop a\nresearch agenda for the use of prompt engineering for BPM research by\nidentifying the associated potentials and challenges."
  },
  {
    "arxiv_id": "2304.06906",
    "title": "Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding",
    "url": "http://arxiv.org/abs/2304.06906v1",
    "abstract": "The use of pretrained backbones with fine-tuning has been successful for 2D\nvision and natural language processing tasks, showing advantages over\ntask-specific networks. In this work, we introduce a pretrained 3D backbone,\ncalled {\\SST}, for 3D indoor scene understanding. We design a 3D Swin\ntransformer as our backbone network, which enables efficient self-attention on\nsparse voxels with linear memory complexity, making the backbone scalable to\nlarge models and datasets. We also introduce a generalized contextual relative\npositional embedding scheme to capture various irregularities of point signals\nfor improved network performance. We pretrained a large {\\SST} model on a\nsynthetic Structured3D dataset, which is an order of magnitude larger than the\nScanNet dataset. Our model pretrained on the synthetic dataset not only\ngeneralizes well to downstream segmentation and detection on real 3D point\ndatasets, but also outperforms state-of-the-art methods on downstream tasks\nwith +2.3 mIoU and +2.2 mIoU on S3DIS Area5 and 6-fold semantic segmentation,\n+1.8 mIoU on ScanNet segmentation (val), +1.9 mAP@0.5 on ScanNet detection, and\n+8.1 mAP@0.5 on S3DIS detection. A series of extensive ablation studies further\nvalidate the scalability, generality, and superior performance enabled by our\napproach. The code and models are available at\nhttps://github.com/microsoft/Swin3D ."
  },
  {
    "arxiv_id": "2304.08453",
    "title": "Improving Autoregressive NLP Tasks via Modular Linearized Attention",
    "url": "http://arxiv.org/abs/2304.08453v1",
    "abstract": "Various natural language processing (NLP) tasks necessitate models that are\nefficient and small based on their ultimate application at the edge or in other\nresource-constrained environments. While prior research has reduced the size of\nthese models, increasing computational efficiency without considerable\nperformance impacts remains difficult, especially for autoregressive tasks.\nThis paper proposes modular linearized attention (MLA), which combines multiple\nefficient attention mechanisms, including cosFormer, to maximize inference\nquality while achieving notable speedups. We validate this approach on several\nautoregressive NLP tasks, including speech-to-text neural machine translation\n(S2T NMT), speech-to-text simultaneous translation (SimulST), and\nautoregressive text-to-spectrogram, noting efficiency gains on TTS and\ncompetitive performance for NMT and SimulST during training and inference."
  },
  {
    "arxiv_id": "2304.08130",
    "title": "A Survey on Few-Shot Class-Incremental Learning",
    "url": "http://arxiv.org/abs/2304.08130v1",
    "abstract": "Large deep learning models are impressive, but they struggle when real-time\ndata is not available. Few-shot class-incremental learning (FSCIL) poses a\nsignificant challenge for deep neural networks to learn new tasks from just a\nfew labeled samples without forgetting the previously learned ones. This setup\neasily leads to catastrophic forgetting and overfitting problems, severely\naffecting model performance. Studying FSCIL helps overcome deep learning model\nlimitations on data volume and acquisition time, while improving practicality\nand adaptability of machine learning models. This paper provides a\ncomprehensive survey on FSCIL. Unlike previous surveys, we aim to synthesize\nfew-shot learning and incremental learning, focusing on introducing FSCIL from\ntwo perspectives, while reviewing over 30 theoretical research studies and more\nthan 20 applied research studies. From the theoretical perspective, we provide\na novel categorization approach that divides the field into five subcategories,\nincluding traditional machine learning methods, meta-learning based methods,\nfeature and feature space-based methods, replay-based methods, and dynamic\nnetwork structure-based methods. We also evaluate the performance of recent\ntheoretical research on benchmark datasets of FSCIL. From the application\nperspective, FSCIL has achieved impressive achievements in various fields of\ncomputer vision such as image classification, object detection, and image\nsegmentation, as well as in natural language processing and graph. We summarize\nthe important applications. Finally, we point out potential future research\ndirections, including applications, problem setups, and theory development.\nOverall, this paper offers a comprehensive analysis of the latest advances in\nFSCIL from a methodological, performance, and application perspective."
  },
  {
    "arxiv_id": "2304.08109",
    "title": "A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model",
    "url": "http://arxiv.org/abs/2304.08109v2",
    "abstract": "Recently, the instruction-tuning of large language models is a crucial area\nof research in the field of natural language processing. Due to resource and\ncost limitations, several researchers have employed parameter-efficient tuning\ntechniques, such as LoRA, for instruction tuning, and have obtained encouraging\nresults In comparison to full-parameter fine-tuning, LoRA-based tuning\ndemonstrates salient benefits in terms of training costs. In this study, we\nundertook experimental comparisons between full-parameter fine-tuning and\nLoRA-based tuning methods, utilizing LLaMA as the base model. The experimental\nresults show that the selection of the foundational model, training dataset\nscale, learnable parameter quantity, and model training cost are all important\nfactors. We hope that the experimental conclusions of this paper can provide\ninspiration for training large language models, especially in the field of\nChinese, and help researchers find a better trade-off strategy between training\ncost and model performance. To facilitate the reproduction of the paper's\nresults, the dataset, model and code will be released."
  },
  {
    "arxiv_id": "2304.07919",
    "title": "Chain of Thought Prompt Tuning in Vision Language Models",
    "url": "http://arxiv.org/abs/2304.07919v1",
    "abstract": "Language-Image Pre-training has demonstrated promising results on zero-shot\nand few-shot downstream tasks by prompting visual models with natural language\nprompts. However, most recent studies only use a single prompt for tuning,\nneglecting the inherent step-to-step cognitive reasoning process that humans\nconduct in complex task settings, for example, when processing images from\nunfamiliar domains. Chain of Thought is a simple and effective approximation to\nhuman reasoning process and has been proven useful for natural language\nprocessing (NLP) tasks. Based on this cognitive intuition, we believe that\nconducting effective reasoning is also an important problem in visual tasks,\nand a chain of thought could be a solution to this problem. In this work, we\npropose a novel chain of thought prompt tuning for vision-language modeling.\nExtensive experiments show that our method not only generalizes better in image\nclassification tasks, has greater transferability beyond a single dataset, and\nhas stronger domain generalization performance, but also performs much better\nin imagetext retrieval and visual question answering, which require more\nreasoning capabilities. We are the first to successfully adapt chain-of-thought\nprompting that combines visual and textual embeddings. We will release our\ncodes"
  },
  {
    "arxiv_id": "2304.07774",
    "title": "Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification",
    "url": "http://arxiv.org/abs/2304.07774v1",
    "abstract": "Text simplification is one of the domains in Natural Language Processing\n(NLP) that offers an opportunity to understand the text in a simplified manner\nfor exploration. However, it is always hard to understand and retrieve\nknowledge from unstructured text, which is usually in the form of compound and\ncomplex sentences. There are state-of-the-art neural network-based methods to\nsimplify the sentences for improved readability while replacing words with\nplain English substitutes and summarising the sentences and paragraphs. In the\nKnowledge Graph (KG) creation process from unstructured text, summarising long\nsentences and substituting words is undesirable since this may lead to\ninformation loss. However, KG creation from text requires the extraction of all\npossible facts (triples) with the same mentions as in the text. In this work,\nwe propose a controlled simplification based on the factual information in a\nsentence, i.e., triple. We present a classical syntactic dependency-based\napproach to split and rephrase a compound and complex sentence into a set of\nsimplified sentences. This simplification process will retain the original\nwording with a simple structure of possible domain facts in each sentence,\ni.e., triples. The paper also introduces an algorithm to identify and measure a\nsentence's syntactic complexity (SC), followed by reduction through a\ncontrolled syntactic simplification process. Last, an experiment for a dataset\nre-annotation is also conducted through GPT3; we aim to publish this refined\ncorpus as a resource. This work is accepted and presented in International\nworkshop on Learning with Knowledge Graphs (IWLKG) at WSDM-2023 Conference. The\ncode and data is available at www.github.com/sallmanm/SynSim."
  },
  {
    "arxiv_id": "2304.09058",
    "title": "Revisiting k-NN for Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2304.09058v1",
    "abstract": "Pre-trained Language Models (PLMs), as parametric-based eager learners, have\nbecome the de-facto choice for current paradigms of Natural Language Processing\n(NLP). In contrast, k-Nearest-Neighbor (kNN) classifiers, as the lazy learning\nparadigm, tend to mitigate over-fitting and isolated noise. In this paper, we\nrevisit kNN classifiers for augmenting the PLMs-based classifiers. From the\nmethodological level, we propose to adopt kNN with textual representations of\nPLMs in two steps: (1) Utilize kNN as prior knowledge to calibrate the training\nprocess. (2) Linearly interpolate the probability distribution predicted by kNN\nwith that of the PLMs' classifier. At the heart of our approach is the\nimplementation of kNN-calibrated training, which treats predicted results as\nindicators for easy versus hard examples during the training process. From the\nperspective of the diversity of application scenarios, we conduct extensive\nexperiments on fine-tuning, prompt-tuning paradigms and zero-shot, few-shot and\nfully-supervised settings, respectively, across eight diverse end-tasks. We\nhope our exploration will encourage the community to revisit the power of\nclassical methods for efficient NLP. Code and datasets are available in\nhttps://github.com/zjunlp/Revisit-KNN."
  },
  {
    "arxiv_id": "2304.08763",
    "title": "A Survey on Biomedical Text Summarization with Pre-trained Language Model",
    "url": "http://arxiv.org/abs/2304.08763v1",
    "abstract": "The exponential growth of biomedical texts such as biomedical literature and\nelectronic health records (EHRs), poses a significant challenge for clinicians\nand researchers to access clinical information efficiently. To tackle this\nchallenge, biomedical text summarization (BTS) has been proposed as a solution\nto support clinical information retrieval and management. BTS aims at\ngenerating concise summaries that distill key information from single or\nmultiple biomedical documents. In recent years, the rapid advancement of\nfundamental natural language processing (NLP) techniques, from pre-trained\nlanguage models (PLMs) to large language models (LLMs), has greatly facilitated\nthe progress of BTS. This growth has led to numerous proposed summarization\nmethods, datasets, and evaluation metrics, raising the need for a comprehensive\nand up-to-date survey for BTS. In this paper, we present a systematic review of\nrecent advancements in BTS, leveraging cutting-edge NLP techniques from PLMs to\nLLMs, to help understand the latest progress, challenges, and future\ndirections. We begin by introducing the foundational concepts of BTS, PLMs and\nLLMs, followed by an in-depth review of available datasets, recent approaches,\nand evaluation metrics in BTS. We finally discuss existing challenges and\npromising future directions in the era of LLMs. To facilitate the research\ncommunity, we line up open resources including available datasets, recent\napproaches, codes, evaluation metrics, and the leaderboard in a public project:\nhttps://github.com/KenZLuo/Biomedical-Text-Summarization-Survey/tree/master. We\nbelieve that this survey will be a useful resource to researchers, allowing\nthem to quickly track recent advancements and provide guidelines for future BTS\nresearch within the research community."
  },
  {
    "arxiv_id": "2304.09854",
    "title": "Transformer-Based Visual Segmentation: A Survey",
    "url": "http://arxiv.org/abs/2304.09854v1",
    "abstract": "Visual segmentation seeks to partition images, video frames, or point clouds\ninto multiple segments or groups. This technique has numerous real-world\napplications, such as autonomous driving, image editing, robot sensing, and\nmedical analysis. Over the past decade, deep learning-based methods have made\nremarkable strides in this area. Recently, transformers, a type of neural\nnetwork based on self-attention originally designed for natural language\nprocessing, have considerably surpassed previous convolutional or recurrent\napproaches in various vision processing tasks. Specifically, vision\ntransformers offer robust, unified, and even simpler solutions for various\nsegmentation tasks. This survey provides a thorough overview of\ntransformer-based visual segmentation, summarizing recent advancements. We\nfirst review the background, encompassing problem definitions, datasets, and\nprior convolutional methods. Next, we summarize a meta-architecture that\nunifies all recent transformer-based approaches. Based on this\nmeta-architecture, we examine various method designs, including modifications\nto the meta-architecture and associated applications. We also present several\nclosely related settings, including 3D point cloud segmentation, foundation\nmodel tuning, domain-aware segmentation, efficient segmentation, and medical\nsegmentation. Additionally, we compile and re-evaluate the reviewed methods on\nseveral well-established datasets. Finally, we identify open challenges in this\nfield and propose directions for future research. The project page can be found\nat https://github.com/lxtGH/Awesome-Segmentation-With-Transformer. We will also\ncontinually monitor developments in this rapidly evolving field."
  },
  {
    "arxiv_id": "2304.09842",
    "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models",
    "url": "http://arxiv.org/abs/2304.09842v1",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in solving\nvarious natural language processing tasks due to emergent reasoning abilities.\nHowever, LLMs have inherent limitations as they are incapable of accessing\nup-to-date information (stored on the Web or in task-specific knowledge bases),\nusing external tools, and performing precise mathematical and logical\nreasoning. In this paper, we present Chameleon, an AI system that mitigates\nthese limitations by augmenting LLMs with plug-and-play modules for\ncompositional reasoning. Chameleon synthesizes programs by composing various\ntools (e.g., LLMs, off-the-shelf vision models, web search engines, Python\nfunctions, and heuristic-based modules) for accomplishing complex reasoning\ntasks. At the heart of Chameleon is an LLM-based planner that assembles a\nsequence of tools to execute to generate the final response. We showcase the\neffectiveness of Chameleon on two multi-modal knowledge-intensive reasoning\ntasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%\noverall accuracy on ScienceQA, improving the best published few-shot result by\n11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,\nlifting the state of the art to 98.78%. Our analysis also shows that the\nGPT-4-powered planner exhibits more consistent and rational tool selection via\ninferring potential constraints from instructions, compared to a\nChatGPT-powered planner. The project is available at\nhttps://chameleon-llm.github.io."
  },
  {
    "arxiv_id": "2304.09513",
    "title": "NetGPT: Generative Pretrained Transformer for Network Traffic",
    "url": "http://arxiv.org/abs/2304.09513v1",
    "abstract": "All data on the Internet are transferred by network traffic, thus accurately\nmodeling network traffic can help improve network services quality and protect\ndata privacy. Pretrained models for network traffic can utilize large-scale raw\ndata to learn the essential characteristics of network traffic, and generate\ndistinguishable results for input traffic without considering specific\ndownstream tasks. Effective pretrained models can significantly optimize the\ntraining efficiency and effectiveness of downstream tasks, such as application\nclassification, attack detection and traffic generation. Despite the great\nsuccess of pretraining in natural language processing, there is no work in the\nnetwork field. Considering the diverse demands and characteristics of network\ntraffic and network tasks, it is non-trivial to build a pretrained model for\nnetwork traffic and we face various challenges, especially the heterogeneous\nheaders and payloads in the multi-pattern network traffic and the different\ndependencies for contexts of diverse downstream network tasks.\n  To tackle these challenges, in this paper, we make the first attempt to\nprovide a generative pretrained model NetGPT for both traffic understanding and\ngeneration tasks. We propose the multi-pattern network traffic modeling to\nconstruct unified text inputs and support both traffic understanding and\ngeneration tasks. We further optimize the adaptation effect of the pretrained\nmodel to diversified tasks by shuffling header fields, segmenting packets in\nflows, and incorporating diverse task labels with prompts. With diverse traffic\ndatasets from encrypted software, DNS, private industrial protocols and\ncryptocurrency mining, expensive experiments demonstrate the effectiveness of\nour NetGPT in a range of traffic understanding and generation tasks on traffic\ndatasets, and outperform state-of-the-art baselines by a wide margin."
  },
  {
    "arxiv_id": "2304.10447",
    "title": "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health",
    "url": "http://arxiv.org/abs/2304.10447v1",
    "abstract": "Pretrained language models have been used in various natural language\nprocessing applications. In the mental health domain, domain-specific language\nmodels are pretrained and released, which facilitates the early detection of\nmental health conditions. Social posts, e.g., on Reddit, are usually long\ndocuments. However, there are no domain-specific pretrained models for\nlong-sequence modeling in the mental health domain. This paper conducts\ndomain-specific continued pretraining to capture the long context for mental\nhealth. Specifically, we train and release MentalXLNet and MentalLongformer\nbased on XLNet and Longformer. We evaluate the mental health classification\nperformance and the long-range ability of these two domain-specific pretrained\nmodels. Our models are released in HuggingFace."
  },
  {
    "arxiv_id": "2304.10294",
    "title": "OptoGPT: A Foundation Model for Inverse Design in Optical Multilayer Thin Film Structures",
    "url": "http://arxiv.org/abs/2304.10294v1",
    "abstract": "Optical multilayer thin film structures have been widely used in numerous\nphotonic applications. However, existing inverse design methods have many\ndrawbacks because they either fail to quickly adapt to different design\ntargets, or are difficult to suit for different types of structures, e.g.,\ndesigning for different materials at each layer. These methods also cannot\naccommodate versatile design situations under different angles and\npolarizations. In addition, how to benefit practical fabrications and\nmanufacturing has not been extensively considered yet. In this work, we\nintroduce OptoGPT (Opto Generative Pretrained Transformer), a decoder-only\ntransformer, to solve all these drawbacks and issues simultaneously."
  },
  {
    "arxiv_id": "2304.10224",
    "title": "Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?",
    "url": "http://arxiv.org/abs/2304.10224v1",
    "abstract": "Point cloud based 3D deep model has wide applications in many applications\nsuch as autonomous driving, house robot, and so on. Inspired by the recent\nprompt learning in natural language processing, this work proposes a novel\nMulti-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud\nclassification. MvNet investigates the possibility of leveraging the\noff-the-shelf 2D pre-trained models to achieve the few-shot classification,\nwhich can alleviate the over-dependence issue of the existing baseline models\ntowards the large-scale annotated 3D point cloud data. Specifically, MvNet\nfirst encodes a 3D point cloud into multi-view image features for a number of\ndifferent views. Then, a novel multi-view prompt fusion module is developed to\neffectively fuse information from different views to bridge the gap between 3D\npoint cloud data and 2D pre-trained models. A set of 2D image prompts can then\nbe derived to better describe the suitable prior knowledge for a large-scale\npre-trained image model for few-shot 3D point cloud classification. Extensive\nexperiments on ModelNet, ScanObjectNN, and ShapeNet datasets demonstrate that\nMvNet achieves new state-of-the-art performance for 3D few-shot point cloud\nimage classification. The source code of this work will be available soon."
  },
  {
    "arxiv_id": "2304.09974",
    "title": "SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery",
    "url": "http://arxiv.org/abs/2304.09974v1",
    "abstract": "Advances in GPT-based large language models (LLMs) are revolutionizing\nnatural language processing, exponentially increasing its use across various\ndomains. Incorporating uni-directional attention, these autoregressive LLMs can\ngenerate long and coherent paragraphs. However, for visual question answering\n(VQA) tasks that require both vision and language processing, models with\nbi-directional attention or models employing fusion techniques are often\nemployed to capture the context of multiple modalities all at once. As GPT does\nnot natively process vision tokens, to exploit the advancements in GPT models\nfor VQA in robotic surgery, we design an end-to-end trainable Language-Vision\nGPT (LV-GPT) model that expands the GPT2 model to include vision input (image).\nThe proposed LV-GPT incorporates a feature extractor (vision tokenizer) and\nvision token embedding (token type and pose). Given the limitations of\nunidirectional attention in GPT models and their ability to generate coherent\nlong paragraphs, we carefully sequence the word tokens before vision tokens,\nmimicking the human thought process of understanding the question to infer an\nanswer from an image. Quantitatively, we prove that the LV-GPT model\noutperforms other state-of-the-art VQA models on two publically available\nsurgical-VQA datasets (based on endoscopic vision challenge robotic scene\nsegmentation 2018 and CholecTriplet2021) and on our newly annotated dataset\n(based on the holistic surgical scene dataset). We further annotate all three\ndatasets to include question-type annotations to allow sub-type analysis.\nFurthermore, we extensively study and present the effects of token sequencing,\ntoken type and pose embedding for vision tokens in the LV-GPT model."
  },
  {
    "arxiv_id": "2304.09948",
    "title": "Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers",
    "url": "http://arxiv.org/abs/2304.09948v1",
    "abstract": "The proliferation of fake reviews of doctors has potentially detrimental\nconsequences for patient well-being and has prompted concern among consumer\nprotection groups and regulatory bodies. Yet despite significant advancements\nin the fields of machine learning and natural language processing, there\nremains limited comprehension of the characteristics differentiating fraudulent\nfrom authentic reviews. This study utilizes a novel pre-labeled dataset of\n38048 physician reviews to establish the effectiveness of large language models\nin classifying reviews. Specifically, we compare the performance of traditional\nML models, such as logistic regression and support vector machines, to\ngenerative pre-trained transformer models. Furthermore, we use GPT4, the newest\nmodel in the GPT family, to uncover the key dimensions along which fake and\ngenuine physician reviews differ. Our findings reveal significantly superior\nperformance of GPT-3 over traditional ML models in this context. Additionally,\nour analysis suggests that GPT3 requires a smaller training sample than\ntraditional models, suggesting its appropriateness for tasks with scarce\ntraining data. Moreover, the superiority of GPT3 performance increases in the\ncold start context i.e., when there are no prior reviews of a doctor. Finally,\nwe employ GPT4 to reveal the crucial dimensions that distinguish fake physician\nreviews. In sharp contrast to previous findings in the literature that were\nobtained using simulated data, our findings from a real-world dataset show that\nfake reviews are generally more clinically detailed, more reserved in\nsentiment, and have better structure and grammar than authentic ones."
  },
  {
    "arxiv_id": "2304.10557",
    "title": "An Introduction to Transformers",
    "url": "http://arxiv.org/abs/2304.10557v1",
    "abstract": "The transformer is a neural network component that can be used to learn\nuseful representations of sequences or sets of data-points. The transformer has\ndriven recent advances in natural language processing, computer vision, and\nspatio-temporal modelling. There are many introductions to transformers, but\nmost do not contain precise mathematical descriptions of the architecture and\nthe intuitions behind the design choices are often also missing. Moreover, as\nresearch takes a winding path, the explanations for the components of the\ntransformer can be idiosyncratic. In this note we aim for a mathematically\nprecise, intuitive, and clean description of the transformer architecture. We\nwill not discuss training as this is rather standard. We assume that the reader\nis familiar with fundamental topics in machine learning including multi-layer\nperceptrons, linear transformations, softmax functions and basic probability."
  },
  {
    "arxiv_id": "2304.10859",
    "title": "Text2Time: Transformer-based Article Time Period Prediction",
    "url": "http://arxiv.org/abs/2304.10859v2",
    "abstract": "The task of predicting the publication period of text documents, such as news\narticles, is an important but less studied problem in the field of natural\nlanguage processing. Predicting the year of a news article can be useful in\nvarious contexts, such as historical research, sentiment analysis, and media\nmonitoring. In this work, we investigate the problem of predicting the\npublication period of a text document, specifically a news article, based on\nits textual content. In order to do so, we created our own extensive labeled\ndataset of over 350,000 news articles published by The New York Times over six\ndecades. In our approach, we use a pretrained BERT model fine-tuned for the\ntask of text classification, specifically for time period prediction.This model\nexceeds our expectations and provides some very impressive results in terms of\naccurately classifying news articles into their respective publication decades.\nThe results beat the performance of the baseline model for this relatively\nunexplored task of time prediction from text."
  },
  {
    "arxiv_id": "2304.13009",
    "title": "The Potential of Visual ChatGPT For Remote Sensing",
    "url": "http://arxiv.org/abs/2304.13009v1",
    "abstract": "Recent advancements in Natural Language Processing (NLP), particularly in\nLarge Language Models (LLMs), associated with deep learning-based computer\nvision techniques, have shown substantial potential for automating a variety of\ntasks. One notable model is Visual ChatGPT, which combines ChatGPT's LLM\ncapabilities with visual computation to enable effective image analysis. The\nmodel's ability to process images based on textual inputs can revolutionize\ndiverse fields. However, its application in the remote sensing domain remains\nunexplored. This is the first paper to examine the potential of Visual ChatGPT,\na cutting-edge LLM founded on the GPT architecture, to tackle the aspects of\nimage processing related to the remote sensing domain. Among its current\ncapabilities, Visual ChatGPT can generate textual descriptions of images,\nperform canny edge and straight line detection, and conduct image segmentation.\nThese offer valuable insights into image content and facilitate the\ninterpretation and extraction of information. By exploring the applicability of\nthese techniques within publicly available datasets of satellite images, we\ndemonstrate the current model's limitations in dealing with remote sensing\nimages, highlighting its challenges and future prospects. Although still in\nearly development, we believe that the combination of LLMs and visual models\nholds a significant potential to transform remote sensing image processing,\ncreating accessible and practical application opportunities in the field."
  },
  {
    "arxiv_id": "2304.12562",
    "title": "A Preliminary Evaluation of ChatGPT in Requirements Information Retrieval",
    "url": "http://arxiv.org/abs/2304.12562v1",
    "abstract": "Recently, various illustrative examples have shown the impressive ability of\ngenerative large language models (LLMs) to perform NLP related tasks. ChatGPT\nundoubtedly is the most representative model. We empirically evaluate ChatGPT's\nperformance on requirements information retrieval (IR) tasks to derive insights\ninto designing or developing more effective requirements retrieval methods or\ntools based on generative LLMs. We design an evaluation framework considering\nfour different combinations of two popular IR tasks and two common artifact\ntypes. Under zero-shot setting, evaluation results reveal ChatGPT's promising\nability to retrieve requirements relevant information (high recall) and limited\nability to retrieve more specific requirements information (low precision). Our\nevaluation of ChatGPT on requirements IR under zero-shot setting provides\npreliminary evidence for designing or developing more effective requirements IR\nmethods or tools based on LLMs."
  },
  {
    "arxiv_id": "2304.13712",
    "title": "Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond",
    "url": "http://arxiv.org/abs/2304.13712v2",
    "abstract": "This paper presents a comprehensive and practical guide for practitioners and\nend-users working with Large Language Models (LLMs) in their downstream natural\nlanguage processing (NLP) tasks. We provide discussions and insights into the\nusage of LLMs from the perspectives of models, data, and downstream tasks.\nFirstly, we offer an introduction and brief summary of current GPT- and\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training\ndata, and test data. Most importantly, we provide a detailed discussion about\nthe use and non-use cases of large language models for various natural language\nprocessing tasks, such as knowledge-intensive tasks, traditional natural\nlanguage understanding tasks, natural language generation tasks, emergent\nabilities, and considerations for specific tasks.We present various use cases\nand non-use cases to illustrate the practical applications and limitations of\nLLMs in real-world scenarios. We also try to understand the importance of data\nand the specific challenges associated with each NLP task. Furthermore, we\nexplore the impact of spurious biases on LLMs and delve into other essential\nconsiderations, such as efficiency, cost, and latency, to ensure a\ncomprehensive understanding of deploying LLMs in practice. This comprehensive\nguide aims to provide researchers and practitioners with valuable insights and\nbest practices for working with LLMs, thereby enabling the successful\nimplementation of these models in a wide range of NLP tasks. A curated list of\npractical guide resources of LLMs, regularly updated, can be found at\n\\url{https://github.com/Mooler0410/LLMsPracticalGuide}."
  },
  {
    "arxiv_id": "2304.13672",
    "title": "FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation",
    "url": "http://arxiv.org/abs/2304.13672v1",
    "abstract": "Medical image segmentation methods normally perform poorly when there is a\ndomain shift between training and testing data. Unsupervised Domain Adaptation\n(UDA) addresses the domain shift problem by training the model using both\nlabeled data from the source domain and unlabeled data from the target domain.\nSource-Free UDA (SFUDA) was recently proposed for UDA without requiring the\nsource data during the adaptation, due to data privacy or data transmission\nissues, which normally adapts the pre-trained deep model in the testing stage.\nHowever, in real clinical scenarios of medical image segmentation, the trained\nmodel is normally frozen in the testing stage. In this paper, we propose\nFourier Visual Prompting (FVP) for SFUDA of medical image segmentation.\nInspired by prompting learning in natural language processing, FVP steers the\nfrozen pre-trained model to perform well in the target domain by adding a\nvisual prompt to the input target data. In FVP, the visual prompt is\nparameterized using only a small amount of low-frequency learnable parameters\nin the input frequency space, and is learned by minimizing the segmentation\nloss between the predicted segmentation of the prompted target image and\nreliable pseudo segmentation label of the target image under the frozen model.\nTo our knowledge, FVP is the first work to apply visual prompts to SFUDA for\nmedical image segmentation. The proposed FVP is validated using three public\ndatasets, and experiments demonstrate that FVP yields better segmentation\nresults, compared with various existing methods."
  },
  {
    "arxiv_id": "2304.13567",
    "title": "Impact of Position Bias on Language Models in Token Classification",
    "url": "http://arxiv.org/abs/2304.13567v1",
    "abstract": "Language Models (LMs) have shown state-of-the-art performance in Natural\nLanguage Processing (NLP) tasks. Downstream tasks such as Named Entity\nRecognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data\nimbalance issues, particularly regarding the ratio of positive to negative\nexamples and class disparities. This paper investigates an often-overlooked\nissue of encoder models, specifically the position bias of positive examples in\ntoken classification tasks. For completeness, we also include decoders in the\nevaluation. We evaluate the impact of position bias using different position\nembedding techniques, focusing on BERT with Absolute Position Embedding (APE),\nRelative Position Embedding (RPE), and Rotary Position Embedding (RoPE).\nTherefore, we conduct an in-depth evaluation of the impact of position bias on\nthe performance of LMs when fine-tuned on token classification benchmarks. Our\nstudy includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD\\_en, and\nTweeBank for POS tagging. We propose an evaluation approach to investigate\nposition bias in transformer models. We show that LMs can suffer from this bias\nwith an average drop ranging from 3\\% to 9\\% in their performance. To mitigate\nthis effect, we propose two methods: Random Position Shifting and Context\nPerturbation, that we apply on batches during the training process. The results\nshow an improvement of $\\approx$ 2\\% in the performance of the model on\nCoNLL03, UD\\_en, and TweeBank."
  },
  {
    "arxiv_id": "2304.14670",
    "title": "Prompt Engineering for Healthcare: Methodologies and Applications",
    "url": "http://arxiv.org/abs/2304.14670v1",
    "abstract": "Prompt engineering is a critical technique in the field of natural language\nprocessing that involves designing and optimizing the prompts used to input\ninformation into models, aiming to enhance their performance on specific tasks.\nWith the recent advancements in large language models, prompt engineering has\nshown significant superiority across various domains and has become\nincreasingly important in the healthcare domain. However, there is a lack of\ncomprehensive reviews specifically focusing on prompt engineering in the\nmedical field. This review will introduce the latest advances in prompt\nengineering in the field of natural language processing for the medical field.\nFirst, we will provide the development of prompt engineering and emphasize its\nsignificant contributions to healthcare natural language processing\napplications such as question-answering systems, text summarization, and\nmachine translation. With the continuous improvement of general large language\nmodels, the importance of prompt engineering in the healthcare domain is\nbecoming increasingly prominent. The aim of this article is to provide useful\nresources and bridges for healthcare natural language processing researchers to\nbetter explore the application of prompt engineering in this field. We hope\nthat this review can provide new ideas and inspire for research and application\nin medical natural language processing."
  },
  {
    "arxiv_id": "2304.14456",
    "title": "Framing the News:From Human Perception to Large Language Model Inferences",
    "url": "http://arxiv.org/abs/2304.14456v1",
    "abstract": "Identifying the frames of news is important to understand the articles'\nvision, intention, message to be conveyed, and which aspects of the news are\nemphasized. Framing is a widely studied concept in journalism, and has emerged\nas a new topic in computing, with the potential to automate processes and\nfacilitate the work of journalism professionals. In this paper, we study this\nissue with articles related to the Covid-19 anti-vaccine movement. First, to\nunderstand the perspectives used to treat this theme, we developed a protocol\nfor human labeling of frames for 1786 headlines of No-Vax movement articles of\nEuropean newspapers from 5 countries. Headlines are key units in the written\npress, and worth of analysis as many people only read headlines (or use them to\nguide their decision for further reading.) Second, considering advances in\nNatural Language Processing (NLP) with large language models, we investigated\ntwo approaches for frame inference of news headlines: first with a GPT-3.5\nfine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work\ncontributes to the study and analysis of the performance that these models have\nto facilitate journalistic tasks like classification of frames, while\nunderstanding whether the models are able to replicate human perception in the\nidentification of these frames."
  },
  {
    "arxiv_id": "2305.00090",
    "title": "NLNDE at SemEval-2023 Task 12: Adaptive Pretraining and Source Language Selection for Low-Resource Multilingual Sentiment Analysis",
    "url": "http://arxiv.org/abs/2305.00090v1",
    "abstract": "This paper describes our system developed for the SemEval-2023 Task 12\n\"Sentiment Analysis for Low-resource African Languages using Twitter Dataset\".\nSentiment analysis is one of the most widely studied applications in natural\nlanguage processing. However, most prior work still focuses on a small number\nof high-resource languages. Building reliable sentiment analysis systems for\nlow-resource languages remains challenging, due to the limited training data in\nthis task. In this work, we propose to leverage language-adaptive and\ntask-adaptive pretraining on African texts and study transfer learning with\nsource language selection on top of an African language-centric pretrained\nlanguage model. Our key findings are: (1) Adapting the pretrained model to the\ntarget language and task using a small yet relevant corpus improves performance\nremarkably by more than 10 F1 score points. (2) Selecting source languages with\npositive transfer gains during training can avoid harmful interference from\ndissimilar languages, leading to better results in multilingual and\ncross-lingual settings. In the shared task, our system wins 8 out of 15 tracks\nand, in particular, performs best in the multilingual evaluation."
  },
  {
    "arxiv_id": "2305.01146",
    "title": "RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models",
    "url": "http://arxiv.org/abs/2305.01146v1",
    "abstract": "We systematically investigate lightweight strategies to adapt large language\nmodels (LLMs) for the task of radiology report summarization (RRS).\nSpecifically, we focus on domain adaptation via pretraining (on natural\nlanguage, biomedical text, or clinical text) and via discrete prompting or\nparameter-efficient fine-tuning. Our results consistently achieve best\nperformance by maximally adapting to the task via pretraining on clinical text\nand fine-tuning on RRS examples. Importantly, this method fine-tunes a mere\n0.32% of parameters throughout the model, in contrast to end-to-end fine-tuning\n(100% of parameters). Additionally, we study the effect of in-context examples\nand out-of-distribution (OOD) training before concluding with a radiologist\nreader study and qualitative analysis. Our findings highlight the importance of\ndomain adaptation in RRS and provide valuable insights toward developing\neffective natural language processing solutions for clinical tasks."
  },
  {
    "arxiv_id": "2305.01028",
    "title": "Company classification using zero-shot learning",
    "url": "http://arxiv.org/abs/2305.01028v1",
    "abstract": "In recent years, natural language processing (NLP) has become increasingly\nimportant in a variety of business applications, including sentiment analysis,\ntext classification, and named entity recognition. In this paper, we propose an\napproach for company classification using NLP and zero-shot learning. Our\nmethod utilizes pre-trained transformer models to extract features from company\ndescriptions, and then applies zero-shot learning to classify companies into\nrelevant categories without the need for specific training data for each\ncategory. We evaluate our approach on a dataset obtained through the Wharton\nResearch Data Services (WRDS), which comprises textual descriptions of publicly\ntraded companies. We demonstrate that the approach can streamline the process\nof company classification, thereby reducing the time and resources required in\ntraditional approaches such as the Global Industry Classification Standard\n(GICS). The results show that this method has potential for automation of\ncompany classification, making it a promising avenue for future research in\nthis area."
  },
  {
    "arxiv_id": "2305.02182",
    "title": "Uncovering ChatGPT's Capabilities in Recommender Systems",
    "url": "http://arxiv.org/abs/2305.02182v1",
    "abstract": "The debut of ChatGPT has recently attracted the attention of the natural\nlanguage processing (NLP) community and beyond. Existing studies have\ndemonstrated that ChatGPT shows significant improvement in a range of\ndownstream NLP tasks, but the capabilities and limitations of ChatGPT in terms\nof recommendations remain unclear. In this study, we aim to conduct an\nempirical analysis of ChatGPT's recommendation ability from an Information\nRetrieval (IR) perspective, including point-wise, pair-wise, and list-wise\nranking. To achieve this goal, we re-formulate the above three recommendation\npolicies into a domain-specific prompt format. Through extensive experiments on\nfour datasets from different domains, we demonstrate that ChatGPT outperforms\nother large language models across all three ranking policies. Based on the\nanalysis of unit cost improvements, we identify that ChatGPT with list-wise\nranking achieves the best trade-off between cost and performance compared to\npoint-wise and pair-wise ranking. Moreover, ChatGPT shows the potential for\nmitigating the cold start problem and explainable recommendation. To facilitate\nfurther explorations in this area, the full code and detailed original results\nare open-sourced at https://github.com/rainym00d/LLM4RS."
  },
  {
    "arxiv_id": "2305.01937",
    "title": "Can Large Language Models Be an Alternative to Human Evaluations?",
    "url": "http://arxiv.org/abs/2305.01937v1",
    "abstract": "Human evaluation is indispensable and inevitable for assessing the quality of\ntexts generated by machine learning models or written by humans. However, human\nevaluation is very difficult to reproduce and its quality is notoriously\nunstable, hindering fair comparisons among different natural language\nprocessing (NLP) models and algorithms. Recently, large language models (LLMs)\nhave demonstrated exceptional performance on unseen tasks when only the task\ninstructions are provided. In this paper, we explore if such an ability of the\nLLMs can be used as an alternative to human evaluation. We present the LLMs\nwith the exact same instructions, samples to be evaluated, and questions used\nto conduct human evaluation, and then ask the LLMs to generate responses to\nthose questions; we dub this LLM evaluation. We use human evaluation and LLM\nevaluation to evaluate the texts in two NLP tasks: open-ended story generation\nand adversarial attacks. We show that the result of LLM evaluation is\nconsistent with the results obtained by expert human evaluation: the texts\nrated higher by human experts are also rated higher by the LLMs. We also find\nthat the results of LLM evaluation are stable over different formatting of the\ntask instructions and the sampling algorithm used to generate the answer. We\nare the first to show the potential of using LLMs to assess the quality of\ntexts and discuss the limitations and ethical considerations of LLM evaluation."
  },
  {
    "arxiv_id": "2305.01711",
    "title": "Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner",
    "url": "http://arxiv.org/abs/2305.01711v1",
    "abstract": "Language models (LMs) trained on vast quantities of unlabelled data have\ngreatly advanced the field of natural language processing (NLP). In this study,\nwe re-visit the widely accepted notion in NLP that continued pre-training LMs\non task-related texts improves the performance of fine-tuning (FT) in\ndownstream tasks. Through experiments on eight single-sentence tasks and eight\nsentence-pair tasks in both semi-supervised and fully-supervised settings, we\nfind that conventional continued pre-training does not consistently provide\nbenefits and can even be detrimental for sentence-pair tasks or when\nprompt-based FT is used. To tackle these issues, we propose Prompt-based\nContinued Pre-training (PCP), which combines the idea of instruction tuning\nwith conventional continued pre-training. Our approach aims to improve the\nperformance of prompt-based FT by presenting both task-related texts and prompt\ntemplates to LMs through unsupervised pre-training objectives before\nfine-tuning for the target task. Our empirical evaluations on 21 benchmarks\ndemonstrate that the PCP consistently improves the performance of\nstate-of-the-art prompt-based FT approaches (up to 20.1% absolute) in both\nsemi-supervised and fully-supervised settings, even with only hundreds of\nunlabelled examples. Additionally, prompt-based FT with the PCP outperforms\nstate-of-the-art semi-supervised approaches with greater simplicity,\neliminating the need for an iterative process and extra data augmentation. Our\nfurther analysis explores the performance lower bound of the PCP and reveals\nthat the advantages of PCP persist across different sizes of models and\ndatasets."
  },
  {
    "arxiv_id": "2305.01666",
    "title": "BrainNPT: Pre-training of Transformer networks for brain network classification",
    "url": "http://arxiv.org/abs/2305.01666v1",
    "abstract": "Deep learning methods have advanced quickly in brain imaging analysis over\nthe past few years, but they are usually restricted by the limited labeled\ndata. Pre-trained model on unlabeled data has presented promising improvement\nin feature learning in many domains, including natural language processing and\ncomputer vision. However, this technique is under-explored in brain network\nanalysis. In this paper, we focused on pre-training methods with Transformer\nnetworks to leverage existing unlabeled data for brain functional network\nclassification. First, we proposed a Transformer-based neural network, named as\nBrainNPT, for brain functional network classification. The proposed method\nleveraged <cls> token as a classification embedding vector for the Transformer\nmodel to effectively capture the representation of brain network. Second, we\nproposed a pre-training framework for BrainNPT model to leverage unlabeled\nbrain network data to learn the structure information of brain networks. The\nresults of classification experiments demonstrated the BrainNPT model without\npre-training achieved the best performance with the state-of-the-art models,\nand the BrainNPT model with pre-training strongly outperformed the\nstate-of-the-art models. The pre-training BrainNPT model improved 8.75% of\naccuracy compared with the model without pre-training. We further compared the\npre-training strategies, analyzed the influence of the parameters of the model,\nand interpreted the trained model."
  },
  {
    "arxiv_id": "2305.02607",
    "title": "DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning",
    "url": "http://arxiv.org/abs/2305.02607v1",
    "abstract": "In recent years, sentiment analysis has gained significant importance in\nnatural language processing. However, most existing models and datasets for\nsentiment analysis are developed for high-resource languages, such as English\nand Chinese, leaving low-resource languages, particularly African languages,\nlargely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this\ngap by evaluating sentiment analysis models on low-resource African languages.\nIn this paper, we present our solution to the shared task, where we employed\ndifferent multilingual XLM-R models with classification head trained on various\ndata, including those retrained in African dialects and fine-tuned on target\nlanguages. Our team achieved the third-best results in Subtask B, Track 16:\nMultilingual, demonstrating the effectiveness of our approach. While our model\nshowed relatively good results on multilingual data, it performed poorly in\nsome languages. Our findings highlight the importance of developing more\ncomprehensive datasets and models for low-resource African languages to advance\nsentiment analysis research. We also provided the solution on the github\nrepository."
  },
  {
    "arxiv_id": "2305.02499",
    "title": "AutoML-GPT: Automatic Machine Learning with GPT",
    "url": "http://arxiv.org/abs/2305.02499v1",
    "abstract": "AI tasks encompass a wide range of domains and fields. While numerous AI\nmodels have been designed for specific tasks and applications, they often\nrequire considerable human efforts in finding the right model architecture,\noptimization algorithm, and hyperparameters. Recent advances in large language\nmodels (LLMs) like ChatGPT show remarkable capabilities in various aspects of\nreasoning, comprehension, and interaction. Consequently, we propose developing\ntask-oriented prompts and automatically utilizing LLMs to automate the training\npipeline. To implement this concept, we present the AutoML-GPT, which employs\nGPT as the bridge to diverse AI models and dynamically trains models with\noptimized hyperparameters. AutoML-GPT dynamically takes user requests from the\nmodel and data cards and composes the corresponding prompt paragraph.\nUltimately, with this prompt paragraph, AutoML-GPT will automatically conduct\nthe experiments from data processing to model architecture, hyperparameter\ntuning, and predicted training log. By leveraging {\\ours}'s robust language\ncapabilities and the available AI models, AutoML-GPT can tackle numerous\nintricate AI tasks across various tasks and datasets. This approach achieves\nremarkable results in computer vision, natural language processing, and other\nchallenging areas. Extensive experiments and ablation studies demonstrate that\nour method can be general, effective, and beneficial for many AI tasks."
  },
  {
    "arxiv_id": "2305.02440",
    "title": "Cheaply Evaluating Inference Efficiency Metrics for Autoregressive Transformer APIs",
    "url": "http://arxiv.org/abs/2305.02440v1",
    "abstract": "Large language models (LLMs) power many state-of-the-art systems in natural\nlanguage processing. However, these models are extremely computationally\nexpensive, even at inference time, raising the natural question: when is the\nextra cost of deploying a larger model worth the anticipated boost in\ncapabilities? Better understanding this tradeoff fundamentally could benefit\nfrom an inference efficiency metric that is both (i) easily comparable across\nmodels from different providers, and (ii) representative of the true cost of\nrunning queries in an isolated performance environment. Unfortunately, access\nto LLMs today is largely restricted to black-box text generation APIs and raw\nruntimes measured through this interface do not satisfy these desiderata: model\nproviders can apply various software and hardware optimizations orthogonal to\nthe model, and models served on shared infrastructure are susceptible to\nperformance contention. To circumvent these problems, we propose a new metric\nfor comparing inference efficiency across models. This metric puts models on\nequal footing as though they were served (i) on uniform hardware and software,\nand (ii) without performance contention. We call this metric the\n\\emph{idealized runtime}, and we propose a methodology to efficiently estimate\nthis metric for autoregressive Transformer models. We also propose cost-aware\nvariants that incorporate the number of accelerators needed to serve the model.\nUsing these metrics, we compare ten state-of-the-art LLMs to provide the first\nanalysis of inference efficiency-capability tradeoffs; we make several\nobservations from this analysis, including the fact that the superior inference\nruntime performance of certain APIs is often a byproduct of optimizations\nwithin the API rather than the underlying model. Our methodology also\nfacilitates the efficient comparison of different software and hardware stacks."
  },
  {
    "arxiv_id": "2305.03453",
    "title": "T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering",
    "url": "http://arxiv.org/abs/2305.03453v1",
    "abstract": "Large Language Models (LLMs) have recently demonstrated exceptional\nperformance in various Natural Language Processing (NLP) tasks. They have also\nshown the ability to perform chain-of-thought (CoT) reasoning to solve complex\nproblems. Recent studies have explored CoT reasoning in complex multimodal\nscenarios, such as the science question answering task, by fine-tuning\nmultimodal models with high-quality human-annotated CoT rationales. However,\ncollecting high-quality COT rationales is usually time-consuming and costly.\nBesides, the annotated rationales are hardly accurate due to the external\nessential information missed. To address these issues, we propose a novel\nmethod termed T-SciQ that aims at teaching science question answering with LLM\nsignals. The T-SciQ approach generates high-quality CoT rationales as teaching\nsignals and is advanced to train much smaller models to perform CoT reasoning\nin complex modalities. Additionally, we introduce a novel data mixing strategy\nto produce more effective teaching data samples for simple and complex science\nquestion answer problems. Extensive experimental results show that our T-SciQ\nmethod achieves a new state-of-the-art performance on the ScienceQA benchmark,\nwith an accuracy of 96.18%. Moreover, our approach outperforms the most\npowerful fine-tuned baseline by 4.5%. The code is publicly available at\nhttps://github.com/T-SciQ/T-SciQ."
  },
  {
    "arxiv_id": "2305.03407",
    "title": "Online Gesture Recognition using Transformer and Natural Language Processing",
    "url": "http://arxiv.org/abs/2305.03407v1",
    "abstract": "The Transformer architecture is shown to provide a powerful machine\ntransduction framework for online handwritten gestures corresponding to glyph\nstrokes of natural language sentences. The attention mechanism is successfully\nused to create latent representations of an end-to-end encoder-decoder model,\nsolving multi-level segmentation while also learning some language features and\nsyntax rules. The additional use of a large decoding space with some learned\nByte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and\nsyntax rules. The encoder stack was directly fed with spatio-temporal data\ntokens potentially forming an infinitely large input vocabulary, an approach\nthat finds applications beyond that of this work. Encoder transfer learning\ncapabilities is also demonstrated on several languages resulting in faster\noptimisation and shared parameters. A new supervised dataset of online\nhandwriting gestures suitable for generic handwriting recognition tasks was\nused to successfully train a small transformer model to an average normalised\nLevenshtein accuracy of 96% on English or German sentences and 94% in French."
  },
  {
    "arxiv_id": "2305.03380",
    "title": "Visualization in the Era of Artificial Intelligence: Experiments for Creating Structural Visualizations by Prompting Large Language Models",
    "url": "http://arxiv.org/abs/2305.03380v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nby generating human-like text and images from textual input. However, their\npotential to generate complex 2D/3D visualizations has been largely unexplored.\nWe report initial experiments showing that LLMs can generate 2D/3D\nvisualizations that may be used for legal visualization. Further research is\nneeded for complex 2D visualizations and 3D scenes. LLMs can become a powerful\ntool for many industries and applications, generating complex visualizations\nwith minimal training."
  },
  {
    "arxiv_id": "2305.03353",
    "title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
    "url": "http://arxiv.org/abs/2305.03353v1",
    "abstract": "Theory of Mind (ToM) is a critical component of intelligence but its\nassessment remains the subject of heated debates. Prior research applied human\nToM assessments to natural language processing models using either\nhuman-created standardized tests or rule-based templates. However, these\nmethods primarily focus on simplistic reasoning and require further validation.\nHere, we leverage dynamic epistemic logic to isolate a particular component of\nToM and to generate controlled problems. We also introduce new verbalization\ntechniques to express these problems in English natural language. Our findings\nindicate that some language model scaling (from 70M to 6B and 350M to 174B)\ndoes not consistently yield results better than random chance. While GPT-4\ndemonstrates superior epistemic reasoning capabilities, there is still room for\nimprovement. Our code and datasets are publicly available\n(https://huggingface.co/datasets/sileod/mindgames ,\nhttps://github.com/sileod/llm-theory-of-mind )"
  },
  {
    "arxiv_id": "2305.04757",
    "title": "Augmented Large Language Models with Parametric Knowledge Guiding",
    "url": "http://arxiv.org/abs/2305.04757v1",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing (NLP) with their impressive language understanding and generation\ncapabilities. However, their performance may be suboptimal for domain-specific\ntasks that require specialized knowledge due to limited exposure to the related\ndata. Additionally, the lack of transparency of most state-of-the-art (SOTA)\nLLMs, which can only be accessed via APIs, impedes further fine-tuning with\ndomain custom data. Moreover, providing private data to the LLMs' owner leads\nto data privacy problems. To address these challenges, we propose the novel\nParametric Knowledge Guiding (PKG) framework, which equips LLMs with a\nknowledge-guiding module to access relevant knowledge without altering the\nLLMs' parameters. Our PKG is based on open-source \"white-box\" language models,\nallowing offline memory of any knowledge that LLMs require. We demonstrate that\nour PKG framework can enhance the performance of \"black-box\" LLMs on a range of\ndomain knowledge-intensive tasks that require factual (+7.9%), tabular\n(+11.9%), medical (+3.0%), and multimodal (+8.1%) knowledge."
  },
  {
    "arxiv_id": "2305.05420",
    "title": "Estimating related words computationally using language model from the Mahabharata -- an Indian epic",
    "url": "http://arxiv.org/abs/2305.05420v1",
    "abstract": "'Mahabharata' is the most popular among many Indian pieces of literature\nreferred to in many domains for completely different purposes. This text itself\nis having various dimension and aspects which is useful for the human being in\ntheir personal life and professional life. This Indian Epic is originally\nwritten in the Sanskrit Language. Now in the era of Natural Language\nProcessing, Artificial Intelligence, Machine Learning, and Human-Computer\ninteraction this text can be processed according to the domain requirement. It\nis interesting to process this text and get useful insights from Mahabharata.\nThe limitation of the humans while analyzing Mahabharata is that they always\nhave a sentiment aspect towards the story narrated by the author. Apart from\nthat, the human cannot memorize statistical or computational details, like\nwhich two words are frequently coming in one sentence? What is the average\nlength of the sentences across the whole literature? Which word is the most\npopular word across the text, what are the lemmas of the words used across the\nsentences? Thus, in this paper, we propose an NLP pipeline to get some\nstatistical and computational insights along with the most relevant word\nsearching method from the largest epic 'Mahabharata'. We stacked the different\ntext-processing approaches to articulate the best results which can be further\nused in the various domain where Mahabharata needs to be referred."
  },
  {
    "arxiv_id": "2305.04989",
    "title": "Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust",
    "url": "http://arxiv.org/abs/2305.04989v1",
    "abstract": "A fundamental question in natural language processing is - what kind of\nlanguage structure and semantics is the language model capturing? Graph formats\nsuch as knowledge graphs are easy to evaluate as they explicitly express\nlanguage semantics and structure. This study evaluates the semantics encoded in\nthe self-attention transformers by leveraging explicit knowledge graph\nstructures. We propose novel metrics to measure the reconstruction error when\nproviding graph path sequences from a knowledge graph and trying to\nreproduce/reconstruct the same from the outputs of the self-attention\ntransformer models. The opacity of language models has an immense bearing on\nsocietal issues of trust and explainable decision outcomes. Our findings\nsuggest that language models are models of stochastic control processes for\nplausible language pattern generation. However, they do not ascribe object and\nconcept-level meaning and semantics to the learned stochastic patterns such as\nthose described in knowledge graphs. Furthermore, to enable robust evaluation\nof concept understanding by language models, we construct and make public an\naugmented language understanding benchmark built on the General Language\nUnderstanding Evaluation (GLUE) benchmark. This has significant\napplication-level user trust implications as stochastic patterns without a\nstrong sense of meaning cannot be trusted in high-stakes applications."
  },
  {
    "arxiv_id": "2305.06140",
    "title": "CrudeBERT: Applying Economic Theory towards fine-tuning Transformer-based Sentiment Analysis Models to the Crude Oil Market",
    "url": "http://arxiv.org/abs/2305.06140v1",
    "abstract": "Predicting market movements based on the sentiment of news media has a long\ntradition in data analysis. With advances in natural language processing,\ntransformer architectures have emerged that enable contextually aware sentiment\nclassification. Nevertheless, current methods built for the general financial\nmarket such as FinBERT cannot distinguish asset-specific value-driving factors.\nThis paper addresses this shortcoming by presenting a method that identifies\nand classifies events that impact supply and demand in the crude oil markets\nwithin a large corpus of relevant news headlines. We then introduce CrudeBERT,\na new sentiment analysis model that draws upon these events to contextualize\nand fine-tune FinBERT, thereby yielding improved sentiment classifications for\nheadlines related to the crude oil futures market. An extensive evaluation\ndemonstrates that CrudeBERT outperforms proprietary and open-source solutions\nin the domain of crude oil."
  },
  {
    "arxiv_id": "2305.06121",
    "title": "Transformer-based model for monocular visual odometry: a video understanding approach",
    "url": "http://arxiv.org/abs/2305.06121v1",
    "abstract": "Estimating the camera's pose given images from a single camera is a\ntraditional task in mobile robots and autonomous vehicles. This problem is\ncalled monocular visual odometry and often relies on geometric approaches that\nrequire considerable engineering effort for a specific scenario. Deep learning\nmethods have been shown to be generalizable after proper training and with a\nlarge amount of available data. Transformer-based architectures have dominated\nthe state-of-the-art in natural language processing and computer vision tasks,\nsuch as image and video understanding. In this work, we deal with the monocular\nvisual odometry as a video understanding task to estimate the 6 degrees of\nfreedom of a camera's pose. We contribute by presenting the TSformer-VO model\nbased on spatio-temporal self-attention mechanisms to extract features from\nclips and estimate the motions in an end-to-end manner. Our approach achieved\ncompetitive state-of-the-art performance compared with geometry-based and deep\nlearning-based methods on the KITTI visual odometry dataset, outperforming the\nDeepVO implementation highly accepted in the visual odometry community. The\ncode is publicly available at https://github.com/aofrancani/TSformer-VO."
  },
  {
    "arxiv_id": "2305.06090",
    "title": "XTab: Cross-table Pretraining for Tabular Transformers",
    "url": "http://arxiv.org/abs/2305.06090v1",
    "abstract": "The success of self-supervised learning in computer vision and natural\nlanguage processing has motivated pretraining methods on tabular data. However,\nmost existing tabular self-supervised learning models fail to leverage\ninformation across multiple data tables and cannot generalize to new tables. In\nthis work, we introduce XTab, a framework for cross-table pretraining of\ntabular transformers on datasets from various domains. We address the challenge\nof inconsistent column types and quantities among tables by utilizing\nindependent featurizers and using federated learning to pretrain the shared\ncomponent. Tested on 84 tabular prediction tasks from the OpenML-AutoML\nBenchmark (AMLB), we show that (1) XTab consistently boosts the\ngeneralizability, learning speed, and performance of multiple tabular\ntransformers, (2) by pretraining FT-Transformer via XTab, we achieve superior\nperformance than other state-of-the-art tabular deep learning models on various\ntasks such as regression, binary, and multiclass classification."
  },
  {
    "arxiv_id": "2305.06530",
    "title": "How Good are Commercial Large Language Models on African Languages?",
    "url": "http://arxiv.org/abs/2305.06530v1",
    "abstract": "Recent advancements in Natural Language Processing (NLP) has led to the\nproliferation of large pretrained language models. These models have been shown\nto yield good performance, using in-context learning, even on unseen tasks and\nlanguages. They have also been exposed as commercial APIs as a form of\nlanguage-model-as-a-service, with great adoption. However, their performance on\nAfrican languages is largely unknown. We present a preliminary analysis of\ncommercial large language models on two tasks (machine translation and text\nclassification) across eight African languages, spanning different language\nfamilies and geographical areas. Our results suggest that commercial language\nmodels produce below-par performance on African languages. We also find that\nthey perform better on text classification than machine translation. In\ngeneral, our findings present a call-to-action to ensure African languages are\nwell represented in commercial large language models, given their growing\npopularity."
  },
  {
    "arxiv_id": "2305.07622",
    "title": "PALR: Personalization Aware LLMs for Recommendation",
    "url": "http://arxiv.org/abs/2305.07622v1",
    "abstract": "Large language models (LLMs) have recently received significant attention for\ntheir exceptional capabilities. Despite extensive efforts in developing\ngeneral-purpose LLMs that can be utilized in various natural language\nprocessing (NLP) tasks, there has been less research exploring their potential\nin recommender systems. In this paper, we propose a novel framework, named\nPALR, which aiming to combine user history behaviors (such as clicks,\npurchases, ratings, etc.) with LLMs to generate user preferred items.\nSpecifically, we first use user/item interactions as guidance for candidate\nretrieval. Then we adopt a LLM-based ranking model to generate recommended\nitems. Unlike existing approaches that typically adopt general-purpose LLMs for\nzero/few-shot recommendation testing or training on small-sized language models\n(with less than 1 billion parameters), which cannot fully elicit LLMs'\nreasoning abilities and leverage rich item side parametric knowledge, we\nfine-tune a 7 billion parameters LLM for the ranking purpose. This model takes\nretrieval candidates in natural language format as input, with instruction\nwhich explicitly asking to select results from input candidates during\ninference. Our experimental results demonstrate that our solution outperforms\nstate-of-the-art models on various sequential recommendation tasks."
  },
  {
    "arxiv_id": "2305.07490",
    "title": "ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4",
    "url": "http://arxiv.org/abs/2305.07490v1",
    "abstract": "The success of large language models (LLMs) has inspired an emerging research\nfield of multimodal learning. However, a grand challenge of exploiting LLMs for\nmultimodal learning is the size of pre-trained LLMs which are always with\nbillions of parameters. To tackle this challenge, models such as MiniGPT-4 and\nLLaVA have been developed to fine-tune the pre-trained models using fewer\nparameters. Despite their promising performance, these models remain limited in\ntheir understanding of artistic imagery. To facilitate better\nartistic-understanding, in this paper, we propose ArtGPT-4, a pioneering large\nvision-language model tailored to address the limitations of existing models in\nartistic comprehension. The key innovation of ArtGPT-4 lies in its craft for\nthe sophisticated challenge of artistic image comprehension, setting it apart\nfrom other models that overlook fine details for broader themes. Specifically,\nit works by integrating some specialized adapter layers into the LLM, enabling\nthe model to more efficiently and effectively parse and interpret complex\nvisual tokens, instead of fine-tuning the whole LLM as in the existing method.\nArtGPT-4 has demonstrated its outstanding performance on the efficiency:\nutilizing a Tesla A100 device, its training can be completed in mere 2 hours\nwith an image-text pair dataset comprising approximately 0.52M entries.\nAdditionally, ArtGPT-4 has also achieved state-of-the-art performance on the\nArtEmis and ArtEmis-v2.0 datasets as well as the benchmarks established in this\nwork, lagging behind professional artists' descriptions by a negligible 0.15\npoints on a 6-point scale. The outstanding performance of ArtGPT-4 shows that\nit can render images with an artistic-understanding and convey the emotions\nthey inspire, mirroring human interpretation. The code and the pre-trained\nmodel are accessible in \\url{https://github.com/DLYuanGod/ArtGPT-4}."
  },
  {
    "arxiv_id": "2305.07239",
    "title": "T-former: An Efficient Transformer for Image Inpainting",
    "url": "http://arxiv.org/abs/2305.07239v1",
    "abstract": "Benefiting from powerful convolutional neural networks (CNNs), learning-based\nimage inpainting methods have made significant breakthroughs over the years.\nHowever, some nature of CNNs (e.g. local prior, spatially shared parameters)\nlimit the performance in the face of broken images with diverse and complex\nforms. Recently, a class of attention-based network architectures, called\ntransformer, has shown significant performance on natural language processing\nfields and high-level vision tasks. Compared with CNNs, attention operators are\nbetter at long-range modeling and have dynamic weights, but their computational\ncomplexity is quadratic in spatial resolution, and thus less suitable for\napplications involving higher resolution images, such as image inpainting. In\nthis paper, we design a novel attention linearly related to the resolution\naccording to Taylor expansion. And based on this attention, a network called\n$T$-former is designed for image inpainting. Experiments on several benchmark\ndatasets demonstrate that our proposed method achieves state-of-the-art\naccuracy while maintaining a relatively low number of parameters and\ncomputational complexity. The code can be found at\n\\href{https://github.com/dengyecode/T-former_image_inpainting}{github.com/dengyecode/T-former\\_image\\_inpainting}"
  },
  {
    "arxiv_id": "2305.08264",
    "title": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling",
    "url": "http://arxiv.org/abs/2305.08264v1",
    "abstract": "We present MatSci-NLP, a natural language benchmark for evaluating the\nperformance of natural language processing (NLP) models on materials science\ntext. We construct the benchmark from publicly available materials science text\ndata to encompass seven different NLP tasks, including conventional NLP tasks\nlike named entity recognition and relation classification, as well as NLP tasks\nspecific to materials science, such as synthesis action retrieval which relates\nto creating synthesis procedures for materials. We study various BERT-based\nmodels pretrained on different scientific text corpora on MatSci-NLP to\nunderstand the impact of pretraining strategies on understanding materials\nscience text. Given the scarcity of high-quality annotated data in the\nmaterials science domain, we perform our fine-tuning experiments with limited\ntraining data to encourage the generalize across MatSci-NLP tasks. Our\nexperiments in this low-resource training setting show that language models\npretrained on scientific text outperform BERT trained on general text. MatBERT,\na model pretrained specifically on materials science journals, generally\nperforms best for most tasks. Moreover, we propose a unified text-to-schema for\nmultitask learning on \\benchmark and compare its performance with traditional\nfine-tuning methods. In our analysis of different training methods, we find\nthat our proposed text-to-schema methods inspired by question-answering\nconsistently outperform single and multitask NLP fine-tuning methods. The code\nand datasets are publicly available at\n\\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}."
  },
  {
    "arxiv_id": "2305.08208",
    "title": "Learning to Generalize for Cross-domain QA",
    "url": "http://arxiv.org/abs/2305.08208v1",
    "abstract": "There have been growing concerns regarding the out-of-domain generalization\nability of natural language processing (NLP) models, particularly in\nquestion-answering (QA) tasks. Current synthesized data augmentation methods\nfor QA are hampered by increased training costs. To address this issue, we\npropose a novel approach that combines prompting methods and linear probing\nthen fine-tuning strategy, which does not entail additional cost. Our method\nhas been theoretically and empirically shown to be effective in enhancing the\ngeneralization ability of both generative and discriminative models. Our\napproach outperforms state-of-the-art baselines, with an average increase in F1\nscore of 4.5%-7.9%. Furthermore, our method can be easily integrated into any\npre-trained models and offers a promising solution to the under-explored\ncross-domain QA task. We release our source code at GitHub*."
  },
  {
    "arxiv_id": "2305.09556",
    "title": "Adapting Sentence Transformers for the Aviation Domain",
    "url": "http://arxiv.org/abs/2305.09556v1",
    "abstract": "Learning effective sentence representations is crucial for many Natural\nLanguage Processing (NLP) tasks, including semantic search, semantic textual\nsimilarity (STS), and clustering. While multiple transformer models have been\ndeveloped for sentence embedding learning, these models may not perform\noptimally when dealing with specialized domains like aviation, which has unique\ncharacteristics such as technical jargon, abbreviations, and unconventional\ngrammar. Furthermore, the absence of labeled datasets makes it difficult to\ntrain models specifically for the aviation domain. To address these challenges,\nwe propose a novel approach for adapting sentence transformers for the aviation\ndomain. Our method is a two-stage process consisting of pre-training followed\nby fine-tuning. During pre-training, we use Transformers and Sequential\nDenoising AutoEncoder (TSDAE) with aviation text data as input to improve the\ninitial model performance. Subsequently, we fine-tune our models using a\nNatural Language Inference (NLI) dataset in the Sentence Bidirectional Encoder\nRepresentations from Transformers (SBERT) architecture to mitigate overfitting\nissues. Experimental results on several downstream tasks show that our adapted\nsentence transformers significantly outperform general-purpose transformers,\ndemonstrating the effectiveness of our approach in capturing the nuances of the\naviation domain. Overall, our work highlights the importance of domain-specific\nadaptation in developing high-quality NLP solutions for specialized industries\nlike aviation."
  },
  {
    "arxiv_id": "2305.09550",
    "title": "Life of PII -- A PII Obfuscation Transformer",
    "url": "http://arxiv.org/abs/2305.09550v1",
    "abstract": "Protecting sensitive information is crucial in today's world of Large\nLanguage Models (LLMs) and data-driven services. One common method used to\npreserve privacy is by using data perturbation techniques to reduce\noverreaching utility of (sensitive) Personal Identifiable Information (PII)\ndata while maintaining its statistical and semantic properties. Data\nperturbation methods often result in significant information loss, making them\nimpractical for use. In this paper, we propose 'Life of PII', a novel\nObfuscation Transformer framework for transforming PII into faux-PII while\npreserving the original information, intent, and context as much as possible.\nOur approach includes an API to interface with the given document, a\nconfiguration-based obfuscator, and a model based on the Transformer\narchitecture, which has shown high context preservation and performance in\nnatural language processing tasks and LLMs.\n  Our Transformer-based approach learns mapping between the original PII and\nits transformed faux-PII representation, which we call \"obfuscated\" data. Our\nexperiments demonstrate that our method, called Life of PII, outperforms\ntraditional data perturbation techniques in terms of both utility preservation\nand privacy protection. We show that our approach can effectively reduce\nutility loss while preserving the original information, offering greater\nflexibility in the trade-off between privacy protection and data utility. Our\nwork provides a solution for protecting PII in various real-world applications."
  },
  {
    "arxiv_id": "2305.10329",
    "title": "G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks",
    "url": "http://arxiv.org/abs/2305.10329v1",
    "abstract": "It has become a popular paradigm to transfer the knowledge of large-scale\npre-trained models to various downstream tasks via fine-tuning the entire model\nparameters. However, with the growth of model scale and the rising number of\ndownstream tasks, this paradigm inevitably meets the challenges in terms of\ncomputation consumption and memory footprint issues. Recently,\nParameter-Efficient Fine-Tuning (PEFT) (e.g., Adapter, LoRA, BitFit) shows a\npromising paradigm to alleviate these concerns by updating only a portion of\nparameters. Despite these PEFTs having demonstrated satisfactory performance in\nnatural language processing, it remains under-explored for the question of\nwhether these techniques could be transferred to graph-based tasks with Graph\nTransformer Networks (GTNs). Therefore, in this paper, we fill this gap by\nproviding extensive benchmarks with traditional PEFTs on a range of graph-based\ndownstream tasks. Our empirical study shows that it is sub-optimal to directly\ntransfer existing PEFTs to graph-based tasks due to the issue of feature\ndistribution shift. To address this issue, we propose a novel structure-aware\nPEFT approach, named G-Adapter, which leverages graph convolution operation to\nintroduce graph structure (e.g., graph adjacent matrix) as an inductive bias to\nguide the updating process. Besides, we propose Bregman proximal point\noptimization to further alleviate feature distribution shift by preventing the\nmodel from aggressive update. Extensive experiments demonstrate that G-Adapter\nobtains the state-of-the-art performance compared to the counterparts on nine\ngraph benchmark datasets based on two pre-trained GTNs, and delivers tremendous\nmemory footprint efficiency compared to the conventional paradigm."
  },
  {
    "arxiv_id": "2305.10036",
    "title": "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark",
    "url": "http://arxiv.org/abs/2305.10036v1",
    "abstract": "Large language models (LLMs) have demonstrated powerful capabilities in both\ntext understanding and generation. Companies have begun to offer Embedding as a\nService (EaaS) based on these LLMs, which can benefit various natural language\nprocessing (NLP) tasks for customers. However, previous studies have shown that\nEaaS is vulnerable to model extraction attacks, which can cause significant\nlosses for the owners of LLMs, as training these models is extremely expensive.\nTo protect the copyright of LLMs for EaaS, we propose an Embedding Watermark\nmethod called EmbMarker that implants backdoors on embeddings. Our method\nselects a group of moderate-frequency words from a general text corpus to form\na trigger set, then selects a target embedding as the watermark, and inserts it\ninto the embeddings of texts containing trigger words as the backdoor. The\nweight of insertion is proportional to the number of trigger words included in\nthe text. This allows the watermark backdoor to be effectively transferred to\nEaaS-stealer's model for copyright verification while minimizing the adverse\nimpact on the original embeddings' utility. Our extensive experiments on\nvarious datasets show that our method can effectively protect the copyright of\nEaaS models without compromising service quality."
  },
  {
    "arxiv_id": "2305.09858",
    "title": "Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs",
    "url": "http://arxiv.org/abs/2305.09858v1",
    "abstract": "Knowledge Graphs (KGs) play a crucial role in enhancing e-commerce system\nperformance by providing structured information about entities and their\nrelationships, such as complementary or substitutable relations between\nproducts or product types, which can be utilized in recommender systems.\nHowever, relation labeling in KGs remains a challenging task due to the dynamic\nnature of e-commerce domains and the associated cost of human labor. Recently,\nbreakthroughs in Large Language Models (LLMs) have shown surprising results in\nnumerous natural language processing tasks. In this paper, we conduct an\nempirical study of LLMs for relation labeling in e-commerce KGs, investigating\ntheir powerful learning capabilities in natural language and effectiveness in\npredicting relations between product types with limited labeled data. We\nevaluate various LLMs, including PaLM and GPT-3.5, on benchmark datasets,\ndemonstrating their ability to achieve competitive performance compared to\nhumans on relation labeling tasks using just 1 to 5 labeled examples per\nrelation. Additionally, we experiment with different prompt engineering\ntechniques to examine their impact on model performance. Our results show that\nLLMs significantly outperform existing KG completion models in relation\nlabeling for e-commerce KGs and exhibit performance strong enough to replace\nhuman labeling."
  },
  {
    "arxiv_id": "2305.11176",
    "title": "Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model",
    "url": "http://arxiv.org/abs/2305.11176v1",
    "abstract": "Foundation models have made significant strides in various applications,\nincluding text-to-image generation, panoptic segmentation, and natural language\nprocessing. This paper presents Instruct2Act, a framework that utilizes Large\nLanguage Models to map multi-modal instructions to sequential actions for\nrobotic manipulation tasks. Specifically, Instruct2Act employs the LLM model to\ngenerate Python programs that constitute a comprehensive perception, planning,\nand action loop for robotic tasks. In the perception section, pre-defined APIs\nare used to access multiple foundation models where the Segment Anything Model\n(SAM) accurately locates candidate objects, and CLIP classifies them. In this\nway, the framework leverages the expertise of foundation models and robotic\nabilities to convert complex high-level instructions into precise policy codes.\nOur approach is adjustable and flexible in accommodating various instruction\nmodalities and input types and catering to specific task demands. We validated\nthe practicality and efficiency of our approach by assessing it on robotic\ntasks in different scenarios within tabletop manipulation domains. Furthermore,\nour zero-shot method outperformed many state-of-the-art learning-based policies\nin several tasks. The code for our proposed approach is available at\nhttps://github.com/OpenGVLab/Instruct2Act, serving as a robust benchmark for\nhigh-level robotic instruction tasks with assorted modality inputs."
  },
  {
    "arxiv_id": "2305.11598",
    "title": "Introspective Tips: Large Language Model for In-Context Decision Making",
    "url": "http://arxiv.org/abs/2305.11598v1",
    "abstract": "The emergence of large language models (LLMs) has substantially influenced\nnatural language processing, demonstrating exceptional results across various\ntasks. In this study, we employ ``Introspective Tips\" to facilitate LLMs in\nself-optimizing their decision-making. By introspectively examining\ntrajectories, LLM refines its policy by generating succinct and valuable tips.\nOur method enhances the agent's performance in both few-shot and zero-shot\nlearning situations by considering three essential scenarios: learning from the\nagent's past experiences, integrating expert demonstrations, and generalizing\nacross diverse games. Importantly, we accomplish these improvements without\nfine-tuning the LLM parameters; rather, we adjust the prompt to generalize\ninsights from the three aforementioned situations. Our framework not only\nsupports but also emphasizes the advantage of employing LLM in in-contxt\ndecision-making. Experiments involving over 100 games in TextWorld illustrate\nthe superior performance of our approach."
  },
  {
    "arxiv_id": "2305.11595",
    "title": "Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate",
    "url": "http://arxiv.org/abs/2305.11595v1",
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in various\napplications, but they still face various inconsistency issues. Existing works\nprimarily focus on the inconsistency issues within a single LLM, while we\ncomplementarily explore the inter-consistency among multiple LLMs for\ncollaboration. To examine whether LLMs can collaborate effectively to achieve a\nconsensus for a shared goal, we focus on commonsense reasoning, and introduce a\nformal debate framework (FORD) to conduct a three-stage debate among LLMs with\nreal-world scenarios alignment: fair debate, mismatched debate, and roundtable\ndebate. Through extensive experiments on various datasets, LLMs can effectively\ncollaborate to reach a consensus despite noticeable inter-inconsistencies, but\nimbalances in their abilities can lead to domination by superior LLMs.\nLeveraging a more advanced LLM like GPT-4 as an authoritative judge can boost\ncollaboration performance. Our work contributes to understanding the\ninter-consistency among LLMs and lays the foundation for developing future\ncollaboration methods. Codes and data are available at\nhttps://github.com/Waste-Wood/FORD"
  },
  {
    "arxiv_id": "2305.11579",
    "title": "Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment",
    "url": "http://arxiv.org/abs/2305.11579v1",
    "abstract": "Recently, speech-text pre-training methods have shown remarkable success in\nmany speech and natural language processing tasks. However, most previous\npre-trained models are usually tailored for one or two specific tasks, but fail\nto conquer a wide range of speech-text tasks. In addition, existing speech-text\npre-training methods fail to explore the contextual information within a\ndialogue to enrich utterance representations. In this paper, we propose\nSpeech-text dialog Pre-training for spoken dialog understanding with ExpliCiT\ncRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog\npre-training model. Concretely, to consider the temporality of speech modality,\nwe design a novel temporal position prediction task to capture the speech-text\nalignment. This pre-training task aims to predict the start and end time of\neach textual word in the corresponding speech waveform. In addition, to learn\nthe characteristics of spoken dialogs, we generalize a response selection task\nfrom textual dialog pre-training to speech-text dialog pre-training scenarios.\nExperimental results on four different downstream speech-text tasks demonstrate\nthe superiority of SPECTRA in learning speech-text alignment and multi-turn\ndialog context."
  },
  {
    "arxiv_id": "2305.11543",
    "title": "Constructing Word-Context-Coupled Space Aligned with Associative Knowledge Relations for Interpretable Language Modeling",
    "url": "http://arxiv.org/abs/2305.11543v1",
    "abstract": "As the foundation of current natural language processing methods, pre-trained\nlanguage model has achieved excellent performance. However, the black-box\nstructure of the deep neural network in pre-trained language models seriously\nlimits the interpretability of the language modeling process. After revisiting\nthe coupled requirement of deep neural representation and semantics logic of\nlanguage modeling, a Word-Context-Coupled Space (W2CSpace) is proposed by\nintroducing the alignment processing between uninterpretable neural\nrepresentation and interpretable statistical logic. Moreover, a clustering\nprocess is also designed to connect the word- and context-level semantics.\nSpecifically, an associative knowledge network (AKN), considered interpretable\nstatistical logic, is introduced in the alignment process for word-level\nsemantics. Furthermore, the context-relative distance is employed as the\nsemantic feature for the downstream classifier, which is greatly different from\nthe current uninterpretable semantic representations of pre-trained models. Our\nexperiments for performance evaluation and interpretable analysis are executed\non several types of datasets, including SIGHAN, Weibo, and ChnSenti. Wherein a\nnovel evaluation strategy for the interpretability of machine learning models\nis first proposed. According to the experimental results, our language model\ncan achieve better performance and highly credible interpretable ability\ncompared to related state-of-the-art methods."
  },
  {
    "arxiv_id": "2305.11408",
    "title": "AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation",
    "url": "http://arxiv.org/abs/2305.11408v1",
    "abstract": "Attention is the core mechanism of today's most used architectures for\nnatural language processing and has been analyzed from many perspectives,\nincluding its effectiveness for machine translation-related tasks. Among these\nstudies, attention resulted to be a useful source of information to get\ninsights about word alignment also when the input text is substituted with\naudio segments, as in the case of the speech translation (ST) task. In this\npaper, we propose AlignAtt, a novel policy for simultaneous ST (SimulST) that\nexploits the attention information to generate source-target alignments that\nguide the model during inference. Through experiments on the 8 language pairs\nof MuST-C v1.0, we show that AlignAtt outperforms previous state-of-the-art\nSimulST policies applied to offline-trained models with gains in terms of BLEU\nof 2 points and latency reductions ranging from 0.5s to 0.8s across the 8\nlanguages."
  },
  {
    "arxiv_id": "2305.13297",
    "title": "Parallel Attention and Feed-Forward Net Design for Pre-training and Inference on Transformers",
    "url": "http://arxiv.org/abs/2305.13297v1",
    "abstract": "This paper investigates the key role of Feed-Forward Networks (FFNs) in\ntransformer models by utilizing the Parallel Attention and Feed-Forward Net\nDesign (PAF) architecture, and comparing it to their Series Attention and\nFeed-Forward Net Design (SAF) counterparts. Central to the effectiveness of PAF\nare two main assumptions regarding the FFN block and the attention block within\na layer: 1) the primary function of the FFN block is to maintain isotropy among\ntoken embeddings and prevent their degeneration, and 2) the residual norm\ncomputed in the attention block is substantially smaller than the input token\nembedding norm. To empirically validate these assumptions, we train PAF\nvariants of two large language models (RoBERTa-large and bert-large-uncased).\nOur results demonstrate that both assumptions hold true in the PAF design. This\nstudy contributes to a deeper understanding of the roles and interactions\nbetween FFNs and self-attention mechanisms in transformer architectures."
  },
  {
    "arxiv_id": "2305.13292",
    "title": "VideoLLM: Modeling Video Sequence with Large Language Models",
    "url": "http://arxiv.org/abs/2305.13292v1",
    "abstract": "With the exponential growth of video data, there is an urgent need for\nautomated technology to analyze and comprehend video content. However, existing\nvideo understanding models are often task-specific and lack a comprehensive\ncapability of handling diverse tasks. The success of large language models\n(LLMs) like GPT has demonstrated their impressive abilities in sequence causal\nreasoning. Building upon this insight, we propose a novel framework called\nVideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs\nfrom natural language processing (NLP) for video sequence understanding.\nVideoLLM incorporates a carefully designed Modality Encoder and Semantic\nTranslator, which convert inputs from various modalities into a unified token\nsequence. This token sequence is then fed into a decoder-only LLM.\nSubsequently, with the aid of a simple task head, our VideoLLM yields an\neffective unified framework for different kinds of video understanding tasks.\nTo evaluate the efficacy of VideoLLM, we conduct extensive experiments using\nmultiple LLMs and fine-tuning methods. We evaluate our VideoLLM on eight tasks\nsourced from four different datasets. The experimental results demonstrate that\nthe understanding and reasoning capabilities of LLMs can be effectively\ntransferred to video understanding tasks. We release the code at\nhttps://github.com/cg1177/VideoLLM."
  },
  {
    "arxiv_id": "2305.13257",
    "title": "Watermarking Text Data on Large Language Models for Dataset Copyright Protection",
    "url": "http://arxiv.org/abs/2305.13257v1",
    "abstract": "Substantial research works have shown that deep models, e.g., pre-trained\nmodels, on the large corpus can learn universal language representations, which\nare beneficial for downstream NLP tasks. However, these powerful models are\nalso vulnerable to various privacy attacks, while much sensitive information\nexists in the training dataset. The attacker can easily steal sensitive\ninformation from public models, e.g., individuals' email addresses and phone\nnumbers. In an attempt to address these issues, particularly the unauthorized\nuse of private data, we introduce a novel watermarking technique via a\nbackdoor-based membership inference approach named TextMarker, which can\nsafeguard diverse forms of private information embedded in the training text\ndata. Specifically, TextMarker only requires data owners to mark a small number\nof samples for data copyright protection under the black-box access assumption\nto the target model. Through extensive evaluation, we demonstrate the\neffectiveness of TextMarker on various real-world datasets, e.g., marking only\n0.1% of the training dataset is practically sufficient for effective membership\ninference with negligible effect on model utility. We also discuss potential\ncountermeasures and show that TextMarker is stealthy enough to bypass them."
  },
  {
    "arxiv_id": "2305.13048",
    "title": "RWKV: Reinventing RNNs for the Transformer Era",
    "url": "http://arxiv.org/abs/2305.13048v1",
    "abstract": "Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of transformers with the efficient inference of RNNs.\n  Our approach leverages a linear attention mechanism and allows us to\nformulate the model as either a Transformer or an RNN, thus parallelizing\ncomputations during training and maintains constant computational and memory\ncomplexity during inference. We scale our models as large as 14 billion\nparameters, by far the largest dense RNN ever trained, and find RWKV performs\non par with similarly sized Transformers, suggesting future work can leverage\nthis architecture to create more efficient models. This work presents a\nsignificant step towards reconciling trade-offs between computational\nefficiency and model performance in sequence processing tasks."
  },
  {
    "arxiv_id": "2305.13002",
    "title": "Rethinking Semi-supervised Learning with Language Models",
    "url": "http://arxiv.org/abs/2305.13002v1",
    "abstract": "Semi-supervised learning (SSL) is a popular setting aiming to effectively\nutilize unlabelled data to improve model performance in downstream natural\nlanguage processing (NLP) tasks. Currently, there are two popular approaches to\nmake use of unlabelled data: Self-training (ST) and Task-adaptive pre-training\n(TAPT). ST uses a teacher model to assign pseudo-labels to the unlabelled data,\nwhile TAPT continues pre-training on the unlabelled data before fine-tuning. To\nthe best of our knowledge, the effectiveness of TAPT in SSL tasks has not been\nsystematically studied, and no previous work has directly compared TAPT and ST\nin terms of their ability to utilize the pool of unlabelled data. In this\npaper, we provide an extensive empirical study comparing five state-of-the-art\nST approaches and TAPT across various NLP tasks and data sizes, including in-\nand out-of-domain settings. Surprisingly, we find that TAPT is a strong and\nmore robust SSL learner, even when using just a few hundred unlabelled samples\nor in the presence of domain shifts, compared to more sophisticated ST\napproaches, and tends to bring greater improvements in SSL than in\nfully-supervised settings. Our further analysis demonstrates the risks of using\nST approaches when the size of labelled or unlabelled data is small or when\ndomain shifts exist. We offer a fresh perspective for future SSL research,\nsuggesting the use of unsupervised pre-training objectives over dependency on\npseudo labels."
  },
  {
    "arxiv_id": "2305.14322",
    "title": "RET-LLM: Towards a General Read-Write Memory for Large Language Models",
    "url": "http://arxiv.org/abs/2305.14322v1",
    "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing (NLP) through their extensive parameters and comprehensive\ndata utilization. However, existing LLMs lack a dedicated memory unit, limiting\ntheir ability to explicitly store and retrieve knowledge for various tasks. In\nthis paper, we propose RET-LLM a novel framework that equips LLMs with a\ngeneral write-read memory unit, allowing them to extract, store, and recall\nknowledge from the text as needed for task performance. Inspired by Davidsonian\nsemantics theory, we extract and save knowledge in the form of triplets. The\nmemory unit is designed to be scalable, aggregatable, updatable, and\ninterpretable. Through qualitative evaluations, we demonstrate the superiority\nof our proposed framework over baseline approaches in question answering tasks.\nMoreover, our framework exhibits robust performance in handling temporal-based\nquestion answering tasks, showcasing its ability to effectively manage\ntime-dependent information."
  },
  {
    "arxiv_id": "2305.13954",
    "title": "Robust Instruction Optimization for Large Language Models with Distribution Shifts",
    "url": "http://arxiv.org/abs/2305.13954v1",
    "abstract": "Large Language Model (LLM) has demonstrated significant ability in various\nNatural Language Processing tasks. However, their effectiveness is highly\ndependent on the phrasing of the task prompt, leading to research on automatic\nprompt optimization using labeled task data. We reveal that these prompt\noptimization techniques are vulnerable to distribution shifts such as\nsubpopulation shifts, which are common for LLMs in real-world scenarios such as\ncustomer reviews analysis. In this light, we propose a new problem of robust\nprompt optimization for LLMs against distribution shifts, which requires the\nprompt optimized over the labeled source group can simultaneously generalize to\nan unlabeled target group. To solve this problem, we propose Generalized Prompt\nOptimization framework, which incorporates the unlabeled data from the target\ngroup into prompt optimization. Extensive experimental results demonstrate the\neffectiveness of the proposed framework with significant performance\nimprovement on the target group and comparable performance on the source group."
  },
  {
    "arxiv_id": "2305.13862",
    "title": "A Trip Towards Fairness: Bias and De-Biasing in Large Language Models",
    "url": "http://arxiv.org/abs/2305.13862v1",
    "abstract": "Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training\nare emerging as the next big revolution in natural language processing and\nunderstanding. These CtB-LLMs are democratizing access to trainable Very\nLarge-Language Models (VLLMs) and, thus, may represent the building blocks of\nmany NLP systems solving downstream tasks. Hence, a little or a large bias in\nCtB-LLMs may cause huge harm. In this paper, we performed a large investigation\nof the bias of three families of CtB-LLMs, and we showed that debiasing\ntechniques are effective and usable. Indeed, according to current tests, the\nLLaMA and the OPT families have an important bias in gender, race, religion,\nand profession. In contrast to the analysis for other LLMs, we discovered that\nbias depends not on the number of parameters but on the perplexity. Finally,\nthe debiasing of OPT using LoRA reduces bias up to 4.12 points in the\nnormalized stereotype score."
  },
  {
    "arxiv_id": "2305.15348",
    "title": "READ: Recurrent Adaptation of Large Transformers",
    "url": "http://arxiv.org/abs/2305.15348v1",
    "abstract": "Fine-tuning large-scale Transformers has led to the explosion of many AI\napplications across Natural Language Processing and Computer Vision tasks.\nHowever, fine-tuning all pre-trained model parameters becomes impractical as\nthe model size and number of tasks increase. Parameter-efficient transfer\nlearning (PETL) methods aim to address these challenges. While effective in\nreducing the number of trainable parameters, PETL methods still require\nsignificant energy and computational resources to fine-tune. In this paper, we\nintroduce \\textbf{RE}current \\textbf{AD}aption (READ) -- a lightweight and\nmemory-efficient fine-tuning method -- to overcome the limitations of the\ncurrent PETL approaches. Specifically, READ inserts a small RNN network\nalongside the backbone model so that the model does not have to back-propagate\nthrough the large backbone network. Through comprehensive empirical evaluation\nof the GLUE benchmark, we demonstrate READ can achieve a $56\\%$ reduction in\nthe training memory consumption and an $84\\%$ reduction in the GPU energy usage\nwhile retraining high model quality compared to full-tuning. Additionally, the\nmodel size of READ does not grow with the backbone model size, making it a\nhighly scalable solution for fine-tuning large Transformers."
  },
  {
    "arxiv_id": "2305.15268",
    "title": "EvEval: A Comprehensive Evaluation of Event Semantics for Large Language Models",
    "url": "http://arxiv.org/abs/2305.15268v1",
    "abstract": "Events serve as fundamental units of occurrence within various contexts. The\nprocessing of event semantics in textual information forms the basis of\nnumerous natural language processing (NLP) applications. Recent studies have\nbegun leveraging large language models (LLMs) to address event semantic\nprocessing. However, the extent that LLMs can effectively tackle these\nchallenges remains uncertain. Furthermore, the lack of a comprehensive\nevaluation framework for event semantic processing poses a significant\nchallenge in evaluating these capabilities. In this paper, we propose an\noverarching framework for event semantic processing, encompassing\nunderstanding, reasoning, and prediction, along with their fine-grained\naspects. To comprehensively evaluate the event semantic processing abilities of\nmodels, we introduce a novel benchmark called EVEVAL. We collect 8 datasets\nthat cover all aspects of event semantic processing. Extensive experiments are\nconducted on EVEVAL, leading to several noteworthy findings based on the\nobtained results."
  },
  {
    "arxiv_id": "2305.15066",
    "title": "GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking",
    "url": "http://arxiv.org/abs/2305.15066v1",
    "abstract": "Large language models~(LLM) like ChatGPT have become indispensable to\nartificial general intelligence~(AGI), demonstrating excellent performance in\nvarious natural language processing tasks. In the real world, graph data is\nubiquitous and an essential part of AGI and prevails in domains like social\nnetwork analysis, bioinformatics and recommender systems. The training corpus\nof large language models often includes some algorithmic components, which\nallows them to achieve certain effects on some graph data-related problems.\nHowever, there is still little research on their performance on a broader range\nof graph-structured data. In this study, we conduct an extensive investigation\nto assess the proficiency of LLMs in comprehending graph data, employing a\ndiverse range of structural and semantic-related tasks. Our analysis\nencompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph\nunderstanding. Through our study, we not only uncover the current limitations\nof language models in comprehending graph structures and performing associated\nreasoning tasks but also emphasize the necessity for further advancements and\nnovel approaches to enhance their graph processing capabilities. Our findings\ncontribute valuable insights towards bridging the gap between language models\nand graph understanding, paving the way for more effective graph mining and\nknowledge extraction."
  },
  {
    "arxiv_id": "2305.15014",
    "title": "Unlocking Temporal Question Answering for Large Language Models Using Code Execution",
    "url": "http://arxiv.org/abs/2305.15014v1",
    "abstract": "The temporal aspect is a significant dimension of our reality. We notice the\nchallenge that large language models (LLMs) face when engaging in temporal\nreasoning. Our preliminary experiments show that methods involving the\ngeneration of intermediate reasoning steps, such as chain-of-thought and\nprogram-aided language models, do not consistently boost the performance of\ncomplex temporal question-answering tasks. This limitation can be attributed to\nthe LLMs' inadequate understanding of temporal information. To address this\nproblem, we propose TempLogic, a novel framework designed specifically for\ntemporal question-answering tasks across three levels of reasoning. TempLogic\nincorporates retrieval-guided context distillation, temporal data extraction,\nand tailor-made logic reasoning. Extensive experiments and analysis demonstrate\nthe effectiveness of our framework in solving intricate time-bound reasoning\ntasks."
  },
  {
    "arxiv_id": "2305.15011",
    "title": "Bactrian-X : A Multilingual Replicable Instruction-Following Model with Low-Rank Adaptation",
    "url": "http://arxiv.org/abs/2305.15011v1",
    "abstract": "Instruction tuning has shown great promise in improving the performance of\nlarge language models. However, research on multilingual instruction tuning has\nbeen limited due to the scarcity of high-quality instruction-response datasets\nacross different languages. To bridge this gap, we present Bactrian-X, a\ncomprehensive multilingual parallel dataset of 3.4 million instruction-response\npairs across 52 languages. Leveraging this dataset, we train a set of adapters\nusing low-rank adaptation (LoRA), which are lightweight components that\nseamlessly integrate with large language models. These adapters have a\nsubstantially lower parameter count than the base model, making them easily\nreplaceable and usable as plug-ins for different languages or language groups.\nExtensive experiments in various multilingual evaluation settings demonstrate\nthat models derived from LoRA-based training over Bactrian-X outperform both\nthe vanilla models and existing instruction-tuned models. The code and models\nare publicly available at https://github.com/mbzuai-nlp/bactrian-x"
  },
  {
    "arxiv_id": "2305.15005",
    "title": "Sentiment Analysis in the Era of Large Language Models: A Reality Check",
    "url": "http://arxiv.org/abs/2305.15005v1",
    "abstract": "Sentiment analysis (SA) has been a long-standing research area in natural\nlanguage processing. It can offer rich insights into human sentiments and\nopinions and has thus seen considerable interest from both academia and\nindustry. With the advent of large language models (LLMs) such as ChatGPT,\nthere is a great potential for their employment on SA problems. However, the\nextent to which existing LLMs can be leveraged for different sentiment analysis\ntasks remains unclear. This paper aims to provide a comprehensive investigation\ninto the capabilities of LLMs in performing various sentiment analysis tasks,\nfrom conventional sentiment classification to aspect-based sentiment analysis\nand multifaceted analysis of subjective texts. We evaluate performance across\n13 tasks on 26 datasets and compare the results against small language models\n(SLMs) trained on domain-specific datasets. Our study reveals that while LLMs\ndemonstrate satisfactory performance in simpler tasks, they lag behind in more\ncomplex tasks requiring deeper understanding or structured sentiment\ninformation. However, LLMs significantly outperform SLMs in few-shot learning\nsettings, suggesting their potential when annotation resources are limited. We\nalso highlight the limitations of current evaluation practices in assessing\nLLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a\nmore comprehensive and realistic evaluation. Data and code during our\ninvestigations are available at\n\\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}."
  },
  {
    "arxiv_id": "2305.14919",
    "title": "Frugal Prompting for Dialog Models",
    "url": "http://arxiv.org/abs/2305.14919v1",
    "abstract": "The use of large language models (LLMs) in natural language processing (NLP)\ntasks is rapidly increasing, leading to changes in how researchers approach\nproblems in the field. To fully utilize these models' abilities, a better\nunderstanding of their behavior for different input protocols is required. With\nLLMs, users can directly interact with the models through a text-based\ninterface to define and solve various tasks. Hence, understanding the\nconversational abilities of these LLMs, which may not have been specifically\ntrained for dialog modeling, is also important. This study examines different\napproaches for building dialog systems using LLMs by considering various\naspects of the prompt. As part of prompt tuning, we experiment with various\nways of providing instructions, exemplars, current query and additional\ncontext. The research also analyzes the representations of dialog history that\nhave the optimal usable-information density. Based on the findings, the paper\nsuggests more compact ways of providing dialog history information while\nensuring good performance and reducing model's inference-API costs. The\nresearch contributes to a better understanding of how LLMs can be effectively\nused for building interactive systems."
  },
  {
    "arxiv_id": "2305.16300",
    "title": "Landmark Attention: Random-Access Infinite Context Length for Transformers",
    "url": "http://arxiv.org/abs/2305.16300v1",
    "abstract": "While Transformers have shown remarkable success in natural language\nprocessing, their attention mechanism's large memory requirements have limited\ntheir ability to handle longer contexts. Prior approaches, such as recurrent\nmemory or retrieval-based augmentation, have either compromised the\nrandom-access flexibility of attention (i.e., the capability to select any\ntoken in the entire context) or relied on separate mechanisms for relevant\ncontext retrieval, which may not be compatible with the model's attention. In\nthis paper, we present a novel approach that allows access to the complete\ncontext while retaining random-access flexibility, closely resembling running\nattention on the entire context. Our method uses a landmark token to represent\neach block of the input and trains the attention to use it for selecting\nrelevant blocks, enabling retrieval of blocks directly through the attention\nmechanism instead of by relying on a separate mechanism. Our approach\nseamlessly integrates with specialized data structures and the system's memory\nhierarchy, enabling processing of arbitrarily long context lengths. We\ndemonstrate that our method can obtain comparable performance with\nTransformer-XL while significantly reducing the number of retrieved tokens in\neach step. Finally, we show that fine-tuning LLaMA 7B with our method\nsuccessfully extends its context length capacity to over 32k tokens, allowing\nfor inference at the context lengths of GPT-4. We release the implementation of\nlandmark attention and the code to reproduce our experiments at\nhttps://github.com/epfml/landmark-attention/."
  },
  {
    "arxiv_id": "2305.16157",
    "title": "Training Data Extraction From Pre-trained Language Models: A Survey",
    "url": "http://arxiv.org/abs/2305.16157v1",
    "abstract": "As the deployment of pre-trained language models (PLMs) expands, pressing\nsecurity concerns have arisen regarding the potential for malicious extraction\nof training data, posing a threat to data privacy. This study is the first to\nprovide a comprehensive survey of training data extraction from PLMs. Our\nreview covers more than 100 key papers in fields such as natural language\nprocessing and security. First, preliminary knowledge is recapped and a\ntaxonomy of various definitions of memorization is presented. The approaches\nfor attack and defense are then systemized. Furthermore, the empirical findings\nof several quantitative studies are highlighted. Finally, future research\ndirections based on this review are suggested."
  },
  {
    "arxiv_id": "2305.17116",
    "title": "Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model",
    "url": "http://arxiv.org/abs/2305.17116v1",
    "abstract": "Large language models (LLMs) have made significant advancements in natural\nlanguage processing (NLP). Broad corpora capture diverse patterns but can\nintroduce irrelevance, while focused corpora enhance reliability by reducing\nmisleading information. Training LLMs on focused corpora poses computational\nchallenges. An alternative approach is to use a retrieval-augmentation (RetA)\nmethod tested in a specific domain.\n  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a\ncustom RetA model were compared using 19 questions on diffuse large B-cell\nlymphoma (DLBCL) disease. Eight independent reviewers assessed responses based\non accuracy, relevance, and readability (rated 1-3).\n  The RetA model performed best in accuracy (12/19 3-point scores, total=47)\nand relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4\nreceived the highest readability scores (17/19, 55), followed by GPT-3 (15/19,\n53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),\nrelevance (32), and readability (38).\n  Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared\nto the RetA model and Prometheus. Hallucinations were mostly associated with\nnon-existent references or fabricated efficacy data.\n  These findings suggest that RetA models, supplemented with domain-specific\ncorpora, may outperform general-purpose LLMs in accuracy and relevance within\nspecific domains. However, this evaluation was limited to specific questions\nand metrics and may not capture challenges in semantic search and other NLP\ntasks. Further research will explore different LLM architectures, RetA\nmethodologies, and evaluation methods to assess strengths and limitations more\ncomprehensively."
  },
  {
    "arxiv_id": "2305.16985",
    "title": "Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation",
    "url": "http://arxiv.org/abs/2305.16985v1",
    "abstract": "In recent years, domains such as natural language processing and image\nrecognition have popularized the paradigm of using large datasets to pretrain\nrepresentations that can be effectively transferred to downstream tasks. In\nthis work we evaluate how such a paradigm should be done in imitation learning,\nwhere both pretraining and finetuning data are trajectories collected by\nexperts interacting with an unknown environment. Namely, we consider a setting\nwhere the pretraining corpus consists of multitask demonstrations and the task\nfor each demonstration is set by an unobserved latent context variable. The\ngoal is to use the pretraining corpus to learn a low dimensional representation\nof the high dimensional (e.g., visual) observation space which can be\ntransferred to a novel context for finetuning on a limited dataset of\ndemonstrations. Among a variety of possible pretraining objectives, we argue\nthat inverse dynamics modeling -- i.e., predicting an action given the\nobservations appearing before and after it in the demonstration -- is\nwell-suited to this setting. We provide empirical evidence of this claim\nthrough evaluations on a variety of simulated visuomotor manipulation problems.\nWhile previous work has attempted various theoretical explanations regarding\nthe benefit of inverse dynamics modeling, we find that these arguments are\ninsufficient to explain the empirical advantages often observed in our\nsettings, and so we derive a novel analysis using a simple but general\nenvironment model."
  },
  {
    "arxiv_id": "2305.16633",
    "title": "Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks",
    "url": "http://arxiv.org/abs/2305.16633v1",
    "abstract": "Recently large language models (LLMs) like ChatGPT have shown impressive\nperformance on many natural language processing tasks with zero-shot. In this\npaper, we investigate the effectiveness of zero-shot LLMs in the financial\ndomain. We compare the performance of ChatGPT along with some open-source\ngenerative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We\naddress three inter-related research questions on data annotation, performance\ngaps, and the feasibility of employing generative models in the finance domain.\nOur findings demonstrate that ChatGPT performs well even without labeled data\nbut fine-tuned models generally outperform it. Our research also highlights how\nannotating with generative models can be time-intensive. Our codebase is\npublicly available on GitHub under CC BY-NC 4.0 license."
  },
  {
    "arxiv_id": "2305.18170",
    "title": "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning",
    "url": "http://arxiv.org/abs/2305.18170v1",
    "abstract": "Chain-of-thought (CoT) prompting with large language models has proven\neffective in numerous natural language processing tasks, but designing prompts\nthat generalize well to diverse problem types can be challenging, especially in\nthe context of math word problem (MWP) solving. Additionally, it is common to\nhave a large amount of training data that have a better diversity coverage but\nCoT annotations are not available, which limits the use of supervised learning\ntechniques. To address these issues, we investigate two approaches to leverage\nthe training data in a few-shot prompting scenario: dynamic program prompting\nand program distillation. Our approach is largely inspired by Gao et al.,\n(2022), where they proposed to replace the CoT with the programs as the\nintermediate reasoning step. Such a prompting strategy allows us to accurately\nverify the answer correctness through program execution in MWP solving. Our\ndynamic program prompting involves annotating the training data by sampling\ncorrect programs from a large language model, while program distillation\ninvolves adapting a smaller model to the program-annotated training data. Our\nexperiments on three standard MWP datasets demonstrate the effectiveness of\nthese approaches, yielding significant improvements over previous baselines for\nprompting and fine-tuning. Our results suggest that leveraging a large amount\nof training data can improve the generalization ability of prompts and boost\nthe performance of fine-tuned small models in MWP solving."
  },
  {
    "arxiv_id": "2305.18156",
    "title": "Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods",
    "url": "http://arxiv.org/abs/2305.18156v1",
    "abstract": "Large-scale pre-trained language models such as GPT-3 have shown remarkable\nperformance across various natural language processing tasks. However, applying\nprompt-based methods with GPT-3 for Grammatical Error Correction (GEC) tasks\nand their controllability remains underexplored. Controllability in GEC is\ncrucial for real-world applications, particularly in educational settings,\nwhere the ability to tailor feedback according to learner levels and specific\nerror types can significantly enhance the learning process. This paper\ninvestigates the performance and controllability of prompt-based methods with\nGPT-3 for GEC tasks using zero-shot and few-shot setting. We explore the impact\nof task instructions and examples on GPT-3's output, focusing on controlling\naspects such as minimal edits, fluency edits, and learner levels. Our findings\ndemonstrate that GPT-3 could effectively perform GEC tasks, outperforming\nexisting supervised and unsupervised approaches. We also showed that GPT-3\ncould achieve controllability when appropriate task instructions and examples\nare given."
  },
  {
    "arxiv_id": "2305.18153",
    "title": "Do Large Language Models Know What They Don't Know?",
    "url": "http://arxiv.org/abs/2305.18153v2",
    "abstract": "Large language models (LLMs) have a wealth of knowledge that allows them to\nexcel in various Natural Language Processing (NLP) tasks. Current research\nfocuses on enhancing their performance within their existing knowledge. Despite\ntheir vast knowledge, LLMs are still limited by the amount of information they\ncan accommodate and comprehend. Therefore, the ability to understand their own\nlimitations on the unknows, referred to as self-knowledge, is of paramount\nimportance. This study aims to evaluate LLMs' self-knowledge by assessing their\nability to identify unanswerable or unknowable questions. We introduce an\nautomated methodology to detect uncertainty in the responses of these models,\nproviding a novel measure of their self-knowledge. We further introduce a\nunique dataset, SelfAware, consisting of unanswerable questions from five\ndiverse categories and their answerable counterparts. Our extensive analysis,\ninvolving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an\nintrinsic capacity for self-knowledge within these models. Moreover, we\ndemonstrate that in-context learning and instruction tuning can further enhance\nthis self-knowledge. Despite this promising insight, our findings also\nhighlight a considerable gap between the capabilities of these models and human\nproficiency in recognizing the limits of their knowledge."
  },
  {
    "arxiv_id": "2305.18125",
    "title": "The Utility of Large Language Models and Generative AI for Education Research",
    "url": "http://arxiv.org/abs/2305.18125v1",
    "abstract": "The use of natural language processing (NLP) techniques in engineering\neducation can provide valuable insights into the underlying processes involved\nin generating text. While accessing these insights can be labor-intensive if\ndone manually, recent advances in NLP and large language models have made it a\nrealistic option for individuals. This study explores and evaluates a\ncombination of clustering, summarization, and prompting techniques to analyze\nover 1,000 student essays in which students discussed their career interests.\nThe specific assignment prompted students to define and explain their career\ngoals as engineers. Using text embedding representations of student responses,\nwe clustered the responses together to identify thematically similar statements\nfrom students. The clustered responses were then summarized to quickly identify\ncareer interest themes. We also used a set of a priori codes about career\nsatisfaction and sectors to demonstrate an alternative approach to using these\ngenerative text models to analyze student writing. The results of this study\ndemonstrate the feasibility and usefulness of NLP techniques in engineering\neducation research. By automating the initial analysis of student essays,\nresearchers and educators can more efficiently and accurately identify key\nthemes and patterns in student writing. The methods presented in this paper\nhave broader applications for engineering education and research purposes\nbeyond analyzing student essays. By explaining these methods to the engineering\neducation community, readers can utilize them in their own contexts."
  },
  {
    "arxiv_id": "2305.17812",
    "title": "Tab-CoT: Zero-shot Tabular Chain of Thought",
    "url": "http://arxiv.org/abs/2305.17812v1",
    "abstract": "The chain-of-though (CoT) prompting methods were successful in various\nnatural language processing (NLP) tasks thanks to their ability to unveil the\nunderlying complex reasoning processes. Such reasoning processes typically\nexhibit implicitly structured steps. Recent efforts also started investigating\nmethods to encourage more explicitly structured reasoning procedures to be\ncaptured. In this work, we propose Tab-CoT, a novel tabular-format CoT\nprompting method, which allows the complex reasoning process to be explicitly\nmodelled in a highly structured manner. Despite its simplicity, we show that\nour approach is capable of performing reasoning across multiple dimensions\n(i.e., both rows and columns). We demonstrate our approach's strong zero-shot\nand few-shot capabilities through extensive experiments on a range of reasoning\ntasks."
  },
  {
    "arxiv_id": "2305.18741",
    "title": "Grokking of Hierarchical Structure in Vanilla Transformers",
    "url": "http://arxiv.org/abs/2305.18741v1",
    "abstract": "For humans, language production and comprehension is sensitive to the\nhierarchical structure of sentences. In natural language processing, past work\nhas questioned how effectively neural sequence models like transformers capture\nthis hierarchical structure when generalizing to structurally novel inputs. We\nshow that transformer language models can learn to generalize hierarchically\nafter training for extremely long periods -- far beyond the point when\nin-domain accuracy has saturated. We call this phenomenon \\emph{structural\ngrokking}. On multiple datasets, structural grokking exhibits inverted U-shaped\nscaling in model depth: intermediate-depth models generalize better than both\nvery deep and very shallow transformers. When analyzing the relationship\nbetween model-internal properties and grokking, we find that optimal depth for\ngrokking can be identified using the tree-structuredness metric of\n\\citet{murty2023projections}. Overall, our work provides strong evidence that,\nwith extended training, vanilla transformers discover and use hierarchical\nstructure."
  },
  {
    "arxiv_id": "2305.18703",
    "title": "Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models",
    "url": "http://arxiv.org/abs/2305.18703v2",
    "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing (NLP), providing a highly useful, task-agnostic foundation\nfor a wide range of applications. However, directly applying LLMs to solve\nsophisticated problems in specific domains meets many hurdles, caused by the\nheterogeneity of domain data, the sophistication of domain knowledge, the\nuniqueness of domain objectives, and the diversity of the constraints (e.g.,\nvarious social norms, cultural conformity, religious beliefs, and ethical\nstandards in the domain applications). Domain specification techniques are key\nto make large language models disruptive in many applications. Specifically, to\nsolve these hurdles, there has been a notable increase in research and\npractices conducted in recent years on the domain specialization of LLMs. This\nemerging field of study, with its substantial potential for impact,\nnecessitates a comprehensive and systematic review to better summarize and\nguide ongoing work in this area. In this article, we present a comprehensive\nsurvey on domain specification techniques for large language models, an\nemerging direction critical for large language model applications. First, we\npropose a systematic taxonomy that categorizes the LLM domain-specialization\ntechniques based on the accessibility to LLMs and summarizes the framework for\nall the subcategories as well as their relations and differences to each other.\nSecond, we present an extensive taxonomy of critical application domains that\ncan benefit dramatically from specialized LLMs, discussing their practical\nsignificance and open challenges. Last, we offer our insights into the current\nresearch status and future trends in this area."
  },
  {
    "arxiv_id": "2305.18699",
    "title": "Approximation and Estimation Ability of Transformers for Sequence-to-Sequence Functions with Infinite Dimensional Input",
    "url": "http://arxiv.org/abs/2305.18699v1",
    "abstract": "Despite the great success of Transformer networks in various applications\nsuch as natural language processing and computer vision, their theoretical\naspects are not well understood. In this paper, we study the approximation and\nestimation ability of Transformers as sequence-to-sequence functions with\ninfinite dimensional inputs. Although inputs and outputs are both infinite\ndimensional, we show that when the target function has anisotropic smoothness,\nTransformers can avoid the curse of dimensionality due to their feature\nextraction ability and parameter sharing property. In addition, we show that\neven if the smoothness changes depending on each input, Transformers can\nestimate the importance of features for each input and extract important\nfeatures dynamically. Then, we proved that Transformers achieve similar\nconvergence rate as in the case of the fixed smoothness. Our theoretical\nresults support the practical success of Transformers for high dimensional\ndata."
  },
  {
    "arxiv_id": "2305.18513",
    "title": "SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics",
    "url": "http://arxiv.org/abs/2305.18513v1",
    "abstract": "Transformer-based models, such as BERT and ViT, have achieved\nstate-of-the-art results across different natural language processing (NLP) and\ncomputer vision (CV) tasks. However, these models are extremely memory\nintensive during their fine-tuning process, making them difficult to deploy on\nGPUs with limited memory resources. To address this issue, we introduce a new\ntool called SlimFit that reduces the memory requirements of these models by\ndynamically analyzing their training dynamics and freezing less-contributory\nlayers during fine-tuning. The layers to freeze are chosen using a runtime\ninter-layer scheduling algorithm. SlimFit adopts quantization and pruning for\nparticular layers to balance the load of dynamic activations and to minimize\nthe memory footprint of static activations, where static activations refer to\nthose that cannot be discarded regardless of freezing. This allows SlimFit to\nfreeze up to 95% of layers and reduce the overall on-device GPU memory usage of\ntransformer-based models such as ViT and BERT by an average of 2.2x, across\ndifferent NLP and CV benchmarks/datasets such as GLUE, SQuAD 2.0, CIFAR-10,\nCIFAR-100 and ImageNet with an average degradation of 0.2% in accuracy. For\nsuch NLP and CV tasks, SlimFit can reduce up to 3.1x the total on-device memory\nusage with an accuracy degradation of only up to 0.4%. As a result, while\nfine-tuning of ViT on ImageNet and BERT on SQuAD 2.0 with a batch size of 128\nrequires 3 and 2 32GB GPUs respectively, SlimFit enables their fine-tuning on a\nsingle 32GB GPU without any significant accuracy degradation."
  },
  {
    "arxiv_id": "2305.19860",
    "title": "A Survey on Large Language Models for Recommendation",
    "url": "http://arxiv.org/abs/2305.19860v2",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools in the field of\nNatural Language Processing (NLP) and have recently gained significant\nattention in the domain of Recommendation Systems (RS). These models, trained\non massive amounts of data using self-supervised learning, have demonstrated\nremarkable success in learning universal representations and have the potential\nto enhance various aspects of recommendation systems by some effective transfer\ntechniques such as fine-tuning and prompt tuning, and so on. The crucial aspect\nof harnessing the power of language models in enhancing recommendation quality\nis the utilization of their high-quality representations of textual features\nand their extensive coverage of external knowledge to establish correlations\nbetween items and users. To provide a comprehensive understanding of the\nexisting LLM-based recommendation systems, this survey presents a taxonomy that\ncategorizes these models into two major paradigms, respectively Discriminative\nLLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation\n(GLLM4Rec), with the latter being systematically sorted out for the first time.\nFurthermore, we systematically review and analyze existing LLM-based\nrecommendation systems within each paradigm, providing insights into their\nmethodologies, techniques, and performance. Additionally, we identify key\nchallenges and several valuable findings to provide researchers and\npractitioners with inspiration. We have also created a GitHub repository to\nindex relevant papers on LLMs for recommendation,\nhttps://github.com/WLiK/LLM4Rec."
  },
  {
    "arxiv_id": "2305.19555",
    "title": "Large Language Models Are Not Abstract Reasoners",
    "url": "http://arxiv.org/abs/2305.19555v1",
    "abstract": "Large Language Models have shown tremendous performance on a large variety of\nnatural language processing tasks, ranging from text comprehension to common\nsense reasoning. However, the mechanisms responsible for this success remain\nopaque, and it is unclear whether LLMs can achieve human-like cognitive\ncapabilities or whether these models are still fundamentally circumscribed.\nAbstract reasoning is a fundamental task for cognition, consisting of finding\nand applying a general pattern from few data. Evaluating deep neural\narchitectures on this task could give insight into their potential limitations\nregarding reasoning and their broad generalisation abilities, yet this is\ncurrently an under-explored area. In this paper, we introduce a new benchmark\nfor evaluating language models beyond memorization on abstract reasoning tasks.\nWe perform extensive evaluations of state-of-the-art LLMs, showing that they\ncurrently achieve very limited performance in contrast with other natural\nlanguage tasks, even when applying techniques that have been shown to improve\nperformance on other NLP tasks. We argue that guiding LLM generation to follow\ncausal paths could help improve the generalisation and reasoning abilities of\nLLMs."
  },
  {
    "arxiv_id": "2306.00618",
    "title": "Effective Structured Prompting by Meta-Learning and Representative Verbalizer",
    "url": "http://arxiv.org/abs/2306.00618v1",
    "abstract": "Prompt tuning for pre-trained masked language models (MLM) has shown\npromising performance in natural language processing tasks with few labeled\nexamples. It tunes a prompt for the downstream task, and a verbalizer is used\nto bridge the predicted token and label prediction. Due to the limited training\ndata, prompt initialization is crucial for prompt tuning. Recently,\nMetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared\ninitialization for all task-specific prompts. However, a single initialization\nis insufficient to obtain good prompts for all tasks and samples when the tasks\nare complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a\nheavy burden on computation and memory as the MLM is usually large. To address\nthese issues, we use a prompt pool to extract more task knowledge and construct\ninstance-dependent prompts via attention. We further propose a novel soft\nverbalizer (RepVerb) which constructs label embedding from feature embeddings\ndirectly. Combining meta-learning the prompt pool and RepVerb, we propose\nMetaPrompter for effective structured prompting. MetaPrompter is\nparameter-efficient as only the pool is required to be tuned. Experimental\nresults demonstrate that MetaPrompter performs better than the recent\nstate-of-the-arts and RepVerb outperforms existing soft verbalizers."
  },
  {
    "arxiv_id": "2306.01499",
    "title": "Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today",
    "url": "http://arxiv.org/abs/2306.01499v1",
    "abstract": "Recent investigations show that large language models (LLMs), specifically\nGPT-4, not only have remarkable capabilities in common Natural Language\nProcessing (NLP) tasks but also exhibit human-level performance on various\nprofessional and academic benchmarks. However, whether GPT-4 can be directly\nused in practical applications and replace traditional artificial intelligence\n(AI) tools in specialized domains requires further experimental validation. In\nthis paper, we explore the potential of LLMs such as GPT-4 to outperform\ntraditional AI tools in dementia diagnosis. Comprehensive comparisons between\nGPT-4 and traditional AI tools are conducted to examine their diagnostic\naccuracy in a clinical setting. Experimental results on two real clinical\ndatasets show that, although LLMs like GPT-4 demonstrate potential for future\nadvancements in dementia diagnosis, they currently do not surpass the\nperformance of traditional AI tools. The interpretability and faithfulness of\nGPT-4 are also evaluated by comparison with real doctors. We discuss the\nlimitations of GPT-4 in its current state and propose future research\ndirections to enhance GPT-4 in dementia diagnosis."
  },
  {
    "arxiv_id": "2306.01312",
    "title": "Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis",
    "url": "http://arxiv.org/abs/2306.01312v1",
    "abstract": "Multimodal Sentiment Analysis (MSA) has been a popular topic in natural\nlanguage processing nowadays, at both sentence and aspect level. However, the\nexisting approaches almost require large-size labeled datasets, which bring\nabout large consumption of time and resources. Therefore, it is practical to\nexplore the method for few-shot sentiment analysis in cross-modalities.\nPrevious works generally execute on textual modality, using the prompt-based\nmethods, mainly two types: hand-crafted prompts and learnable prompts. The\nexisting approach in few-shot multi-modality sentiment analysis task has\nutilized both methods, separately. We further design a hybrid pattern that can\ncombine one or more fixed hand-crafted prompts and learnable prompts and\nutilize the attention mechanisms to optimize the prompt encoder. The\nexperiments on both sentence-level and aspect-level datasets prove that we get\na significant outperformance."
  },
  {
    "arxiv_id": "2306.01249",
    "title": "Transforming ECG Diagnosis:An In-depth Review of Transformer-based DeepLearning Models in Cardiovascular Disease Detection",
    "url": "http://arxiv.org/abs/2306.01249v1",
    "abstract": "The emergence of deep learning has significantly enhanced the analysis of\nelectrocardiograms (ECGs), a non-invasive method that is essential for\nassessing heart health. Despite the complexity of ECG interpretation, advanced\ndeep learning models outperform traditional methods. However, the increasing\ncomplexity of ECG data and the need for real-time and accurate diagnosis\nnecessitate exploring more robust architectures, such as transformers. Here, we\npresent an in-depth review of transformer architectures that are applied to ECG\nclassification. Originally developed for natural language processing, these\nmodels capture complex temporal relationships in ECG signals that other models\nmight overlook. We conducted an extensive search of the latest\ntransformer-based models and summarize them to discuss the advances and\nchallenges in their application and suggest potential future improvements. This\nreview serves as a valuable resource for researchers and practitioners and aims\nto shed light on this innovative application in ECG interpretation."
  },
  {
    "arxiv_id": "2306.01169",
    "title": "Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A Practical Study",
    "url": "http://arxiv.org/abs/2306.01169v1",
    "abstract": "Text summarization is a downstream natural language processing (NLP) task\nthat challenges the understanding and generation capabilities of language\nmodels. Considerable progress has been made in automatically summarizing short\ntexts, such as news articles, often leading to satisfactory results. However,\nsummarizing long documents remains a major challenge. This is due to the\ncomplex contextual information in the text and the lack of open-source\nbenchmarking datasets and evaluation frameworks that can be used to develop and\ntest model performance. In this work, we use ChatGPT, the latest breakthrough\nin the field of large language models (LLMs), together with the extractive\nsummarization model C2F-FAR (Coarse-to-Fine Facet-Aware Ranking) to propose a\nhybrid extraction and summarization pipeline for long documents such as\nbusiness articles and books. We work with the world-renowned company\ngetAbstract AG and leverage their expertise and experience in professional book\nsummarization. A practical study has shown that machine-generated summaries can\nperform at least as well as human-written summaries when evaluated using\ncurrent automated evaluation metrics. However, a closer examination of the\ntexts generated by ChatGPT through human evaluations has shown that there are\nstill critical issues in terms of text coherence, faithfulness, and style.\nOverall, our results show that the use of ChatGPT is a very promising but not\nyet mature approach for summarizing long documents and can at best serve as an\ninspiration for human editors. We anticipate that our work will inform NLP\nresearchers about the extent to which ChatGPT's capabilities for summarizing\nlong documents overlap with practitioners' needs. Further work is needed to\ntest the proposed hybrid summarization pipeline, in particular involving GPT-4,\nand to propose a new evaluation framework tailored to the task of summarizing\nlong documents."
  },
  {
    "arxiv_id": "2306.02776",
    "title": "Cheap-fake Detection with LLM using Prompt Engineering",
    "url": "http://arxiv.org/abs/2306.02776v1",
    "abstract": "The misuse of real photographs with conflicting image captions in news items\nis an example of the out-of-context (OOC) misuse of media. In order to detect\nOOC media, individuals must determine the accuracy of the statement and\nevaluate whether the triplet (~\\textit{i.e.}, the image and two captions)\nrelates to the same event. This paper presents a novel learnable approach for\ndetecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes. The\nproposed method is based on the COSMOS structure, which assesses the coherence\nbetween an image and captions, as well as between two captions. We enhance the\nbaseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a\nfeature extractor. Specifically, we propose an innovative approach to feature\nextraction utilizing prompt engineering to develop a robust and reliable\nfeature extractor with GPT3.5 model. The proposed method captures the\ncorrelation between two captions and effectively integrates this module into\nthe COSMOS baseline model, which allows for a deeper understanding of the\nrelationship between captions. By incorporating this module, we demonstrate the\npotential for significant improvements in cheap-fakes detection performance.\nThe proposed methodology holds promising implications for various applications\nsuch as natural language processing, image captioning, and text-to-image\nsynthesis. Docker for submission is available at\nhttps://hub.docker.com/repository/docker/mulns/ acmmmcheapfakes."
  },
  {
    "arxiv_id": "2306.02428",
    "title": "Taught by the Internet, Exploring Bias in OpenAIs GPT3",
    "url": "http://arxiv.org/abs/2306.02428v1",
    "abstract": "This research delves into the current literature on bias in Natural Language\nProcessing Models and the techniques proposed to mitigate the problem of bias,\nincluding why it is important to tackle bias in the first place. Additionally,\nthese techniques are further analysed in the light of newly developed models\nthat tower in size over past editions. To achieve those aims, the authors of\nthis paper conducted their research on GPT3 by OpenAI, the largest NLP model\navailable to consumers today. With 175 billion parameters in contrast to BERTs\n340 million, GPT3 is the perfect model to test the common pitfalls of NLP\nmodels. Tests were conducted through the development of an Applicant Tracking\nSystem using GPT3. For the sake of feasibility and time constraints, the tests\nprimarily focused on gender bias, rather than all or multiple types of bias.\nFinally, current mitigation techniques are considered and tested to measure\ntheir degree of functionality."
  },
  {
    "arxiv_id": "2306.03799",
    "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models",
    "url": "http://arxiv.org/abs/2306.03799v1",
    "abstract": "Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid mathematical solution for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and effective mathematical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs. Our\ncode is publicly available at\n\\textcolor{blue}{\\url{https://github.com/YouBLEI/Prompt-Space}}"
  },
  {
    "arxiv_id": "2306.03313",
    "title": "A Scalable and Adaptive System to Infer the Industry Sectors of Companies: Prompt + Model Tuning of Generative Language Models",
    "url": "http://arxiv.org/abs/2306.03313v1",
    "abstract": "The Private Equity (PE) firms operate investment funds by acquiring and\nmanaging companies to achieve a high return upon selling. Many PE funds are\nthematic, meaning investment professionals aim to identify trends by covering\nas many industry sectors as possible, and picking promising companies within\nthese sectors. So, inferring sectors for companies is critical to the success\nof thematic PE funds. In this work, we standardize the sector framework and\ndiscuss the typical challenges; we then introduce our sector inference system\naddressing these challenges. Specifically, our system is built on a\nmedium-sized generative language model, finetuned with a prompt + model tuning\nprocedure. The deployed model demonstrates a superior performance than the\ncommon baselines. The system has been serving many PE professionals for over a\nyear, showing great scalability to data volume and adaptability to any change\nin sector framework and/or annotation."
  },
  {
    "arxiv_id": "2306.05323",
    "title": "Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application",
    "url": "http://arxiv.org/abs/2306.05323v1",
    "abstract": "The introduction of computerized medical records in hospitals has reduced\nburdensome activities like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting data from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation by using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Transformers-based model. Moreover, we collected and leveraged three\nexternal independent datasets to implement an effective multicenter model, with\noverall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned\nare: (i) the crucial role of a consistent annotation process and (ii) a\nfine-tuning strategy that combines classical methods with a \"low-resource\"\napproach. This allowed us to establish methodological guidelines that pave the\nway for Natural Language Processing studies in less-resourced languages."
  },
  {
    "arxiv_id": "2306.05276",
    "title": "Extensive Evaluation of Transformer-based Architectures for Adverse Drug Events Extraction",
    "url": "http://arxiv.org/abs/2306.05276v1",
    "abstract": "Adverse Event (ADE) extraction is one of the core tasks in digital\npharmacovigilance, especially when applied to informal texts. This task has\nbeen addressed by the Natural Language Processing community using large\npre-trained language models, such as BERT. Despite the great number of\nTransformer-based architectures used in the literature, it is unclear which of\nthem has better performances and why. Therefore, in this paper we perform an\nextensive evaluation and analysis of 19 Transformer-based models for ADE\nextraction on informal texts. We compare the performance of all the considered\nmodels on two datasets with increasing levels of informality (forums posts and\ntweets). We also combine the purely Transformer-based models with two\ncommonly-used additional processing layers (CRF and LSTM), and analyze their\neffect on the models performance. Furthermore, we use a well-established\nfeature importance technique (SHAP) to correlate the performance of the models\nwith a set of features that describe them: model category (AutoEncoding,\nAutoRegressive, Text-to-Text), pretraining domain, training from scratch, and\nmodel size in number of parameters. At the end of our analyses, we identify a\nlist of take-home messages that can be derived from the experimental data."
  },
  {
    "arxiv_id": "2306.05272",
    "title": "Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models",
    "url": "http://arxiv.org/abs/2306.05272v2",
    "abstract": "The advent of large pre-trained models has brought about a paradigm shift in\nboth visual representation learning and natural language processing. However,\nclustering unlabeled images, as a fundamental and classic machine learning\nproblem, still lacks an effective solution, particularly for large-scale\ndatasets. In this paper, we propose a novel image clustering pipeline that\nleverages the powerful feature representation of large pre-trained models such\nas CLIP and cluster images effectively and efficiently at scale. We first\ndeveloped a novel algorithm to estimate the number of clusters in a given\ndataset. We then show that the pre-trained features are significantly more\nstructured by further optimizing the rate reduction objective. The resulting\nfeatures may significantly improve the clustering accuracy, e.g., from 57\\% to\n66\\% on ImageNet-1k. Furthermore, by leveraging CLIP's multimodality bridge\nbetween image and text, we develop a simple yet effective self-labeling\nalgorithm that produces meaningful captions for the clusters. Through extensive\nexperiments, we show that our pipeline works well on standard datasets such as\nCIFAR-10, CIFAR-100, and ImageNet-1k. It also extends to datasets that are not\ncurated for clustering, such as LAION-Aesthetics and WikiArts. We released the\ncode in https://github.com/LeslieTrue/CPP."
  },
  {
    "arxiv_id": "2306.05179",
    "title": "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models",
    "url": "http://arxiv.org/abs/2306.05179v1",
    "abstract": "Despite the existence of various benchmarks for evaluating natural language\nprocessing models, we argue that human exams are a more suitable means of\nevaluating general intelligence for large language models (LLMs), as they\ninherently demand a much wider range of abilities such as language\nunderstanding, domain knowledge, and problem-solving skills. To this end, we\nintroduce M3Exam, a novel benchmark sourced from real and official human exam\nquestions for evaluating LLMs in a multilingual, multimodal, and multilevel\ncontext. M3Exam exhibits three unique characteristics: (1) multilingualism,\nencompassing questions from multiple countries that require strong multilingual\nproficiency and cultural knowledge; (2) multimodality, accounting for the\nmultimodal nature of many exam questions to test the model's multimodal\nunderstanding capability; and (3) multilevel structure, featuring exams from\nthree critical educational periods to comprehensively assess a model's\nproficiency at different levels. In total, M3Exam contains 12,317 questions in\n9 diverse languages with three educational levels, where about 23\\% of the\nquestions require processing images for successful solving. We assess the\nperformance of top-performing LLMs on M3Exam and find that current models,\nincluding GPT-4, still struggle with multilingual text, particularly in\nlow-resource and non-Latin script languages. Multimodal LLMs also perform\npoorly with complex multimodal questions. We believe that M3Exam can be a\nvaluable resource for comprehensively evaluating LLMs by examining their\nmultilingual and multimodal abilities and tracking their development. Data and\nevaluation code is available at \\url{https://github.com/DAMO-NLP-SG/M3Exam}."
  },
  {
    "arxiv_id": "2306.05064",
    "title": "Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization",
    "url": "http://arxiv.org/abs/2306.05064v1",
    "abstract": "Large language models (LLMs) have achieved great success in general domains\nof natural language processing. In this paper, we bring LLMs to the realm of\ngeoscience with the objective of advancing research and applications in this\nfield. To this end, we present the first-ever LLM in geoscience, K2, alongside\na suite of resources developed to further promote LLM research within\ngeoscience. For instance, we have curated the first geoscience instruction\ntuning dataset, GeoSignal, which aims to align LLM responses to\ngeoscience-related user queries. Additionally, we have established the first\ngeoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience.\nIn this work, we experiment with a complete recipe to adapt a pre-trained\ngeneral-domain LLM to the geoscience domain. Specifically, we further train the\nLLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1\nmillion pieces of geoscience literature, and utilize GeoSignal's supervised\ndata to fine-tune the model. Moreover, we share a protocol that can efficiently\ngather domain-specific data and construct domain-supervised data, even in\nsituations where manpower is scarce. Meanwhile, we equip K2 with the abilities\nof using tools to be a naive geoscience aide. Experiments conducted on the\nGeoBench demonstrate the effectiveness of our approach and datasets on\ngeoscience knowledge understanding and utilization.We open-source all the\ntraining data and K2 model checkpoints at https://github.com/davendw49/k2."
  },
  {
    "arxiv_id": "2306.04926",
    "title": "covLLM: Large Language Models for COVID-19 Biomedical Literature",
    "url": "http://arxiv.org/abs/2306.04926v1",
    "abstract": "The COVID-19 pandemic led to 1.1 million deaths in the United States, despite\nthe explosion of coronavirus research. These new findings are slow to translate\nto clinical interventions, leading to poorer patient outcomes and unnecessary\ndeaths. One reason is that clinicians, overwhelmed by patients, struggle to\nkeep pace with the rate of new coronavirus literature. A potential solution is\ndeveloping a tool for evaluating coronavirus literature using large language\nmodels (LLMs) -- neural networks that are deployed for natural language\nprocessing. LLMs can be used to summarize and extract user-specified\ninformation. The greater availability and advancement of LLMs and pre-processed\ncoronavirus literature databases provide the opportunity to assist clinicians\nin evaluating coronavirus literature through a coronavirus literature specific\nLLM (covLLM), a tool that directly takes an inputted research article and a\nuser query to return an answer. Using the COVID-19 Open Research Dataset\n(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of\nhandwritten prompts and synthetic prompts generated using OpenAI, and (2) real\nabstracts, which contains abstract and title pairs. covLLM was trained with\nLLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca\nand synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real\nabstract datasets. These models were evaluated by two human evaluators and\nChatGPT. Results demonstrate that training covLLM on the synCovid and abstract\npairs datasets performs competitively with ChatGPT and outperforms covLLM\ntrained primarily using the Alpaca dataset."
  },
  {
    "arxiv_id": "2306.04920",
    "title": "Flow-based Network Intrusion Detection Based on BERT Masked Language Model",
    "url": "http://arxiv.org/abs/2306.04920v1",
    "abstract": "A Network Intrusion Detection System (NIDS) is an important tool that\nidentifies potential threats to a network. Recently, different flow-based NIDS\ndesigns utilizing Machine Learning (ML) algorithms have been proposed as\npotential solutions to detect intrusions efficiently. However, conventional\nML-based classifiers have not seen widespread adoption in the real-world due to\ntheir poor domain adaptation capability. In this research, our goal is to\nexplore the possibility of improve the domain adaptation capability of NIDS.\nOur proposal employs Natural Language Processing (NLP) techniques and\nBidirectional Encoder Representations from Transformers (BERT) framework. The\nproposed method achieved positive results when tested on data from different\ndomains."
  },
  {
    "arxiv_id": "2306.06031",
    "title": "FinGPT: Open-Source Financial Large Language Models",
    "url": "http://arxiv.org/abs/2306.06031v1",
    "abstract": "Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}"
  },
  {
    "arxiv_id": "2306.05871",
    "title": "Towards a Robust Detection of Language Model Generated Text: Is ChatGPT that Easy to Detect?",
    "url": "http://arxiv.org/abs/2306.05871v1",
    "abstract": "Recent advances in natural language processing (NLP) have led to the\ndevelopment of large language models (LLMs) such as ChatGPT. This paper\nproposes a methodology for developing and evaluating ChatGPT detectors for\nFrench text, with a focus on investigating their robustness on out-of-domain\ndata and against common attack schemes. The proposed method involves\ntranslating an English dataset into French and training a classifier on the\ntranslated data. Results show that the detectors can effectively detect\nChatGPT-generated text, with a degree of robustness against basic attack\ntechniques in in-domain settings. However, vulnerabilities are evident in\nout-of-domain contexts, highlighting the challenge of detecting adversarial\ntext. The study emphasizes caution when applying in-domain testing results to a\nwider variety of content. We provide our translated datasets and models as\nopen-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection"
  },
  {
    "arxiv_id": "2306.05827",
    "title": "Towards the Exploitation of LLM-based Chatbot for Providing Legal Support to Palestinian Cooperatives",
    "url": "http://arxiv.org/abs/2306.05827v1",
    "abstract": "With the ever-increasing utilization of natural language processing (NLP), we\nstarted to witness over the past few years a significant transformation in our\ninteraction with legal texts. This technology has advanced the analysis and\nenhanced the understanding of complex legal terminology and contexts. The\ndevelopment of recent large language models (LLMs), particularly ChatGPT, has\nalso introduced a revolutionary contribution to the way that legal texts can be\nprocessed and comprehended. In this paper, we present our work on a\ncooperative-legal question-answering LLM-based chatbot, where we developed a\nset of legal questions about Palestinian cooperatives, associated with their\nregulations and compared the auto-generated answers by the chatbot to their\ncorrespondences that are designed by a legal expert. To evaluate the proposed\nchatbot, we have used 50 queries generated by the legal expert and compared the\nanswers produced by the chart to their relevance judgments. Finding\ndemonstrated that an overall accuracy rate of 82% has been achieved when\nanswering the queries, while exhibiting an F1 score equivalent to 79%."
  },
  {
    "arxiv_id": "2306.05817",
    "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
    "url": "http://arxiv.org/abs/2306.05817v1",
    "abstract": "With the rapid development of online services, recommender systems (RS) have\nbecome increasingly indispensable for mitigating information overload. Despite\nremarkable progress, conventional recommendation models (CRM) still have some\nlimitations, e.g., lacking open-world knowledge, and difficulties in\ncomprehending users' underlying preferences and motivations. Meanwhile, large\nlanguage models (LLM) have shown impressive general intelligence and human-like\ncapabilities, which mainly stem from their extensive open-world knowledge,\nreasoning ability, as well as their comprehension of human culture and society.\nConsequently, the emergence of LLM is inspiring the design of recommender\nsystems and pointing out a promising research direction, i.e., whether we can\nincorporate LLM and benefit from their knowledge and capabilities to compensate\nfor the limitations of CRM. In this paper, we conduct a comprehensive survey on\nthis research direction from the perspective of the whole pipeline in\nreal-world recommender systems. Specifically, we summarize existing works from\ntwo orthogonal aspects: where and how to adapt LLM to RS. For the WHERE\nquestion, we discuss the roles that LLM could play in different stages of the\nrecommendation pipeline, i.e., feature engineering, feature encoder,\nscoring/ranking function, user interaction, and pipeline controller. For the\nHOW question, we investigate the training and inference strategies, resulting\nin two fine-grained taxonomy criteria, i.e., whether to tune LLM or not, and\nwhether to involve conventional recommendation models for inference. Then, we\nhighlight key challenges in adapting LLM to RS from three aspects, i.e.,\nefficiency, effectiveness, and ethics. Finally, we summarize the survey and\ndiscuss the future prospects. We actively maintain a GitHub repository for\npapers and other related resources:\nhttps://github.com/CHIANGEL/Awesome-LLM-for-RecSys/."
  },
  {
    "arxiv_id": "2306.05816",
    "title": "Detecting Phishing Sites Using ChatGPT",
    "url": "http://arxiv.org/abs/2306.05816v1",
    "abstract": "The emergence of Large Language Models (LLMs), including ChatGPT, is having a\nsignificant impact on a wide range of fields. While LLMs have been extensively\nresearched for tasks such as code generation and text synthesis, their\napplication in detecting malicious web content, particularly phishing sites,\nhas been largely unexplored. To combat the rising tide of cyber attacks due to\nthe misuse of LLMs, it is important to automate detection by leveraging the\nadvanced capabilities of LLMs.\n  In this paper, we propose a novel system called ChatPhishDetector that\nutilizes LLMs to detect phishing sites. Our system involves leveraging a web\ncrawler to gather information from websites, generating prompts for LLMs based\non the crawled data, and then retrieving the detection results from the\nresponses generated by the LLMs. The system enables us to detect multilingual\nphishing sites with high accuracy by identifying impersonated brands and social\nengineering techniques in the context of the entire website, without the need\nto train machine learning models. To evaluate the performance of our system, we\nconducted experiments on our own dataset and compared it with baseline systems\nand several LLMs. The experimental results using GPT-4V demonstrated\noutstanding performance, with a precision of 98.7% and a recall of 99.6%,\noutperforming the detection results of other LLMs and existing systems. These\nfindings highlight the potential of LLMs for protecting users from online\nfraudulent activities and have important implications for enhancing\ncybersecurity measures."
  },
  {
    "arxiv_id": "2306.06662",
    "title": "EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models",
    "url": "http://arxiv.org/abs/2306.06662v1",
    "abstract": "This paper presents our participation in the FinNLP-2023 shared task on\nmulti-lingual environmental, social, and corporate governance issue\nidentification (ML-ESG). The task's objective is to classify news articles\nbased on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Our\napproach focuses on the English and French subtasks, employing the CerebrasGPT,\nOPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentation\ntechniques. We utilize various encoder models, such as RoBERTa, DeBERTa, and\nFinBERT, subjecting them to knowledge distillation and additional training.\n  Our approach yielded exceptional results, securing the first position in the\nEnglish text subtask with F1-score 0.69 and the second position in the French\ntext subtask with F1-score 0.78. These outcomes underscore the effectiveness of\nour methodology in identifying ESG issues in news articles across different\nlanguages. Our findings contribute to the exploration of ESG topics and\nhighlight the potential of leveraging advanced language models for ESG issue\nidentification."
  },
  {
    "arxiv_id": "2306.06598",
    "title": "RoBERTweet: A BERT Language Model for Romanian Tweets",
    "url": "http://arxiv.org/abs/2306.06598v1",
    "abstract": "Developing natural language processing (NLP) systems for social media\nanalysis remains an important topic in artificial intelligence research. This\narticle introduces RoBERTweet, the first Transformer architecture trained on\nRomanian tweets. Our RoBERTweet comes in two versions, following the base and\nlarge architectures of BERT. The corpus used for pre-training the models\nrepresents a novelty for the Romanian NLP community and consists of all tweets\ncollected from 2008 to 2022. Experiments show that RoBERTweet models outperform\nthe previous general-domain Romanian and multilingual language models on three\nNLP tasks with tweet inputs: emotion detection, sexist language identification,\nand named entity recognition. We make our models and the newly created corpus\nof Romanian tweets freely available."
  },
  {
    "arxiv_id": "2306.06521",
    "title": "Universal Language Modelling agent",
    "url": "http://arxiv.org/abs/2306.06521v1",
    "abstract": "Large Language Models are designed to understand complex Human Language. Yet,\nUnderstanding of animal language has long intrigued researchers striving to\nbridge the communication gap between humans and other species. This research\npaper introduces a novel approach that draws inspiration from the linguistic\nconcepts found in the Quran, a revealed Holy Arabic scripture dating back 1400\nyears. By exploring the linguistic structure of the Quran, specifically the\ncomponents of ism, fil, and harf, we aim to unlock the underlying intentions\nand meanings embedded within animal conversations using audio data. To unravel\nthe intricate complexities of animal language, we employ word embedding\ntechniques to analyze each distinct frequency component. This methodology\nenables the identification of potential correlations and the extraction of\nmeaningful insights from the data. Furthermore, we leverage a bioacoustics\nmodel to generate audio, which serves as a valuable resource for training\nnatural language processing (NLP) techniques. This Paper aims to find the\nintention* behind animal language rather than having each word translation."
  },
  {
    "arxiv_id": "2306.07664",
    "title": "Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis",
    "url": "http://arxiv.org/abs/2306.07664v1",
    "abstract": "In recent years, language models (LMs) have made remarkable progress in\nadvancing the field of natural language processing (NLP). However, the impact\nof data augmentation (DA) techniques on the fine-tuning (FT) performance of\nthese LMs has been a topic of ongoing debate. In this study, we evaluate the\neffectiveness of three different FT methods in conjugation with\nback-translation across an array of 7 diverse NLP tasks, including\nclassification and regression types, covering single-sentence and sentence-pair\ntasks. Contrary to prior assumptions that DA does not contribute to the\nenhancement of LMs' FT performance, our findings reveal that continued\npre-training on augmented data can effectively improve the FT performance of\nthe downstream tasks. In the most favourable case, continued pre-training\nimproves the performance of FT by more than 10% in the few-shot learning\nsetting. Our finding highlights the potential of DA as a powerful tool for\nbolstering LMs' performance."
  },
  {
    "arxiv_id": "2306.07373",
    "title": "EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing",
    "url": "http://arxiv.org/abs/2306.07373v1",
    "abstract": "The utilization of clinical reports for various secondary purposes, including\nhealth research and treatment monitoring, is crucial for enhancing patient\ncare. Natural Language Processing (NLP) tools have emerged as valuable assets\nfor extracting and processing relevant information from these reports. However,\nthe availability of specialized language models for the clinical domain in\nSpanish has been limited.\n  In this paper, we introduce EriBERTa, a bilingual domain-specific language\nmodel pre-trained on extensive medical and clinical corpora. We demonstrate\nthat EriBERTa outperforms previous Spanish language models in the clinical\ndomain, showcasing its superior capabilities in understanding medical texts and\nextracting meaningful information. Moreover, EriBERTa exhibits promising\ntransfer learning abilities, allowing for knowledge transfer from one language\nto another. This aspect is particularly beneficial given the scarcity of\nSpanish clinical data."
  },
  {
    "arxiv_id": "2306.07303",
    "title": "A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks",
    "url": "http://arxiv.org/abs/2306.07303v1",
    "abstract": "Transformer is a deep neural network that employs a self-attention mechanism\nto comprehend the contextual relationships within sequential data. Unlike\nconventional neural networks or updated versions of Recurrent Neural Networks\n(RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in\nhandling long dependencies between input sequence elements and enable parallel\nprocessing. As a result, transformer-based models have attracted substantial\ninterest among researchers in the field of artificial intelligence. This can be\nattributed to their immense potential and remarkable achievements, not only in\nNatural Language Processing (NLP) tasks but also in a wide range of domains,\nincluding computer vision, audio and speech processing, healthcare, and the\nInternet of Things (IoT). Although several survey papers have been published\nhighlighting the transformer's contributions in specific fields, architectural\ndifferences, or performance evaluations, there is still a significant absence\nof a comprehensive survey paper encompassing its major applications across\nvarious domains. Therefore, we undertook the task of filling this gap by\nconducting an extensive survey of proposed transformer models from 2017 to\n2022. Our survey encompasses the identification of the top five application\ndomains for transformer-based models, namely: NLP, Computer Vision,\nMulti-Modality, Audio and Speech Processing, and Signal Processing. We analyze\nthe impact of highly influential transformer-based models in these domains and\nsubsequently classify them based on their respective tasks using a proposed\ntaxonomy. Our aim is to shed light on the existing potential and future\npossibilities of transformers for enthusiastic researchers, thus contributing\nto the broader understanding of this groundbreaking technology."
  },
  {
    "arxiv_id": "2306.09339",
    "title": "From BERT to GPT-3 Codex: Harnessing the Potential of Very Large Language Models for Data Management",
    "url": "http://arxiv.org/abs/2306.09339v1",
    "abstract": "Large language models have recently advanced the state of the art on many\nnatural language processing benchmarks. The newest generation of models can be\napplied to a variety of tasks with little to no specialized training. This\ntechnology creates various opportunities for applications in the context of\ndata management.\n  The tutorial will introduce participants to basic background on language\nmodels, discuss different methods to use language models, and give an overview\nand short demonstration of available libraries and APIs. Models for generating\nnatural language will be considered as well as models, such as GPT-3 Codex,\nwhich complete program code or generate code from natural language\ninstructions. Finally, the tutorial will discuss recent research in the\ndatabase community that exploits language models in the context of traditional\ndatabase systems or proposes novel system architectures that are based on them.\n  The tutorial is targeted at database researchers. No prior background on\nlanguage models is required. The goal of the tutorial is to introduce database\nresearchers to the latest generation of language models, and to their use cases\nin the domain of data management."
  },
  {
    "arxiv_id": "2306.09169",
    "title": "Opportunities for Large Language Models and Discourse in Engineering Design",
    "url": "http://arxiv.org/abs/2306.09169v1",
    "abstract": "In recent years, large language models have achieved breakthroughs on a wide\nrange of benchmarks in natural language processing and continue to increase in\nperformance. Recently, the advances of large language models have raised\ninterest outside the natural language processing community and could have a\nlarge impact on daily life. In this paper, we pose the question: How will large\nlanguage models and other foundation models shape the future product\ndevelopment process? We provide the reader with an overview of the subject by\nsummarizing both recent advances in natural language processing and the use of\ninformation technology in the engineering design process. We argue that\ndiscourse should be regarded as the core of engineering design processes, and\ntherefore should be represented in a digital artifact. On this basis, we\ndescribe how foundation models such as large language models could contribute\nto the design discourse by automating parts thereof that involve creativity and\nreasoning, and were previously reserved for humans. We describe how\nsimulations, experiments, topology optimizations, and other process steps can\nbe integrated into a machine-actionable, discourse-centric design process.\nFinally, we outline the future research that will be necessary for the\nimplementation of the conceptualized framework."
  },
  {
    "arxiv_id": "2306.09049",
    "title": "Mapping Researcher Activity based on Publication Data by means of Transformers",
    "url": "http://arxiv.org/abs/2306.09049v1",
    "abstract": "Modern performance on several natural language processing (NLP) tasks has\nbeen enhanced thanks to the Transformer-based pre-trained language model BERT.\nWe employ this concept to investigate a local publication database. Research\npapers are encoded and clustered to form a landscape view of the scientific\ntopics, in which research is active. Authors working on similar topics can be\nidentified by calculating the similarity between their papers. Based on this,\nwe define a similarity metric between authors. Additionally we introduce the\nconcept of self-similarity to indicate the topical variety of authors."
  },
  {
    "arxiv_id": "2306.08641",
    "title": "Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models",
    "url": "http://arxiv.org/abs/2306.08641v1",
    "abstract": "The AI community has been pursuing algorithms known as artificial general\nintelligence (AGI) that apply to any kind of real-world problem. Recently, chat\nsystems powered by large language models (LLMs) emerge and rapidly become a\npromising direction to achieve AGI in natural language processing (NLP), but\nthe path towards AGI in computer vision (CV) remains unclear. One may owe the\ndilemma to the fact that visual signals are more complex than language signals,\nyet we are interested in finding concrete reasons, as well as absorbing\nexperiences from GPT and LLMs to solve the problem. In this paper, we start\nwith a conceptual definition of AGI and briefly review how NLP solves a wide\nrange of tasks via a chat system. The analysis inspires us that unification is\nthe next important goal of CV. But, despite various efforts in this direction,\nCV is still far from a system like GPT that naturally integrates all tasks. We\npoint out that the essential weakness of CV lies in lacking a paradigm to learn\nfrom environments, yet NLP has accomplished the task in the text world. We then\nimagine a pipeline that puts a CV algorithm (i.e., an agent) in world-scale,\ninteractable environments, pre-trains it to predict future frames with respect\nto its action, and then fine-tunes it with instruction to accomplish various\ntasks. We expect substantial research and engineering efforts to push the idea\nforward and scale it up, for which we share our perspectives on future research\ndirections."
  },
  {
    "arxiv_id": "2306.09992",
    "title": "Rewriting the Script: Adapting Text Instructions for Voice Interaction",
    "url": "http://arxiv.org/abs/2306.09992v1",
    "abstract": "Voice assistants have sharply risen in popularity in recent years, but their\nuse has been limited mostly to simple applications like music, hands-free\nsearch, or control of internet-of-things devices. What would it take for voice\nassistants to guide people through more complex tasks? In our work, we study\nthe limitations of the dominant approach voice assistants take to complex task\nguidance: reading aloud written instructions. Using recipes as an example, we\nobserve twelve participants cook at home with a state-of-the-art voice\nassistant. We learn that the current approach leads to nine challenges,\nincluding obscuring the bigger picture, overwhelming users with too much\ninformation, and failing to communicate affordances. Instructions delivered by\na voice assistant are especially difficult because they cannot be skimmed as\neasily as written instructions. Alexa in particular did not surface crucial\ndetails to the user or answer questions well. We draw on our observations to\npropose eight ways in which voice assistants can ``rewrite the script'' --\nsummarizing, signposting, splitting, elaborating, volunteering, reordering,\nredistributing, and visualizing -- to transform written sources into forms that\nare readily communicated through spoken conversation. We conclude with a vision\nof how modern advancements in natural language processing can be leveraged for\nintelligent agents to guide users effectively through complex tasks."
  },
  {
    "arxiv_id": "2306.09968",
    "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation",
    "url": "http://arxiv.org/abs/2306.09968v1",
    "abstract": "Large language models have exhibited exceptional performance on various\nNatural Language Processing (NLP) tasks, leveraging techniques such as the\npre-training, and instruction fine-tuning. Despite these advances, their\neffectiveness in medical applications is limited, due to challenges such as\nfactual inaccuracies, reasoning abilities, and lack grounding in real-world\nexperience. In this study, we present ClinicalGPT, a language model explicitly\ndesigned and optimized for clinical scenarios. By incorporating extensive and\ndiverse real-world data, such as medical records, domain-specific knowledge,\nand multi-round dialogue consultations in the training process, ClinicalGPT is\nbetter prepared to handle multiple clinical task. Furthermore, we introduce a\ncomprehensive evaluation framework that includes medical knowledge\nquestion-answering, medical exams, patient consultations, and diagnostic\nanalysis of medical records. Our results demonstrate that ClinicalGPT\nsignificantly outperforms other models in these tasks, highlighting the\neffectiveness of our approach in adapting large language models to the critical\ndomain of healthcare."
  },
  {
    "arxiv_id": "2306.09782",
    "title": "Full Parameter Fine-tuning for Large Language Models with Limited Resources",
    "url": "http://arxiv.org/abs/2306.09782v1",
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP) but demand massive GPU resources for training. Lowering the threshold for\nLLMs training would encourage greater participation from researchers,\nbenefiting both academia and society. While existing approaches have focused on\nparameter-efficient fine-tuning, which tunes or adds a small number of\nparameters, few have addressed the challenge of tuning the full parameters of\nLLMs with limited resources. In this work, we propose a new optimizer,\nLOw-Memory Optimization (LOMO), which fuses the gradient computation and the\nparameter update in one step to reduce memory usage. By integrating LOMO with\nexisting memory saving techniques, we reduce memory usage to 10.8% compared to\nthe standard approach (DeepSpeed solution). Consequently, our approach enables\nthe full parameter fine-tuning of a 65B model on a single machine with 8 RTX\n3090, each with 24GB memory.Code and data are available at\nhttps://github.com/OpenLMLab/LOMO."
  },
  {
    "arxiv_id": "2306.11547",
    "title": "Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events",
    "url": "http://arxiv.org/abs/2306.11547v2",
    "abstract": "Generative, pre-trained transformers (GPTs, a.k.a. \"Foundation Models\") have\nreshaped natural language processing (NLP) through their versatility in diverse\ndownstream tasks. However, their potential extends far beyond NLP. This paper\nprovides a software utility to help realize this potential, extending the\napplicability of GPTs to continuous-time sequences of complex events with\ninternal dependencies, such as medical record datasets. Despite their\npotential, the adoption of foundation models in these domains has been hampered\nby the lack of suitable tools for model construction and evaluation. To bridge\nthis gap, we introduce Event Stream GPT (ESGPT), an open-source library\ndesigned to streamline the end-to-end process for building GPTs for\ncontinuous-time event sequences. ESGPT allows users to (1) build flexible,\nfoundation-model scale input datasets by specifying only a minimal\nconfiguration file, (2) leverage a Hugging Face compatible modeling API for\nGPTs over this modality that incorporates intra-event causal dependency\nstructures and autoregressive generation capabilities, and (3) evaluate models\nvia standardized processes that can assess few and even zero-shot performance\nof pre-trained models on user-specified fine-tuning tasks."
  },
  {
    "arxiv_id": "2306.11507",
    "title": "TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models",
    "url": "http://arxiv.org/abs/2306.11507v1",
    "abstract": "Large Language Models (LLMs) such as ChatGPT, have gained significant\nattention due to their impressive natural language processing capabilities. It\nis crucial to prioritize human-centered principles when utilizing these models.\nSafeguarding the ethical and moral compliance of LLMs is of utmost importance.\nHowever, individual ethical issues have not been well studied on the latest\nLLMs. Therefore, this study aims to address these gaps by introducing a new\nbenchmark -- TrustGPT. TrustGPT provides a comprehensive evaluation of LLMs in\nthree crucial areas: toxicity, bias, and value-alignment. Initially, TrustGPT\nexamines toxicity in language models by employing toxic prompt templates\nderived from social norms. It then quantifies the extent of bias in models by\nmeasuring quantifiable toxicity values across different groups. Lastly,\nTrustGPT assesses the value of conversation generation models from both active\nvalue-alignment and passive value-alignment tasks. Through the implementation\nof TrustGPT, this research aims to enhance our understanding of the performance\nof conversation generation models and promote the development of language\nmodels that are more ethical and socially responsible."
  },
  {
    "arxiv_id": "2306.11307",
    "title": "Transforming Graphs for Enhanced Attribute-Based Clustering: An Innovative Graph Transformer Method",
    "url": "http://arxiv.org/abs/2306.11307v1",
    "abstract": "Graph Representation Learning (GRL) is an influential methodology, enabling a\nmore profound understanding of graph-structured data and aiding graph\nclustering, a critical task across various domains. The recent incursion of\nattention mechanisms, originally an artifact of Natural Language Processing\n(NLP), into the realm of graph learning has spearheaded a notable shift in\nresearch trends. Consequently, Graph Attention Networks (GATs) and Graph\nAttention Auto-Encoders have emerged as preferred tools for graph clustering\ntasks. Yet, these methods primarily employ a local attention mechanism, thereby\ncurbing their capacity to apprehend the intricate global dependencies between\nnodes within graphs. Addressing these impediments, this study introduces an\ninnovative method known as the Graph Transformer Auto-Encoder for Graph\nClustering (GTAGC). By melding the Graph Auto-Encoder with the Graph\nTransformer, GTAGC is adept at capturing global dependencies between nodes.\nThis integration amplifies the graph representation and surmounts the\nconstraints posed by the local attention mechanism. The architecture of GTAGC\nencompasses graph embedding, integration of the Graph Transformer within the\nautoencoder structure, and a clustering component. It strategically alternates\nbetween graph embedding and clustering, thereby tailoring the Graph Transformer\nfor clustering tasks, whilst preserving the graph's global structural\ninformation. Through extensive experimentation on diverse benchmark datasets,\nGTAGC has exhibited superior performance against existing state-of-the-art\ngraph clustering methodologies."
  },
  {
    "arxiv_id": "2306.12280",
    "title": "SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence Embeddings",
    "url": "http://arxiv.org/abs/2306.12280v1",
    "abstract": "The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines."
  },
  {
    "arxiv_id": "2306.11892",
    "title": "Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications",
    "url": "http://arxiv.org/abs/2306.11892v1",
    "abstract": "This paper explores new frontiers in agricultural natural language processing\nby investigating the effectiveness of using food-related text corpora for\npretraining transformer-based language models. In particular, we focus on the\ntask of semantic matching, which involves establishing mappings between food\ndescriptions and nutrition data. To accomplish this, we fine-tune a pre-trained\ntransformer-based language model, AgriBERT, on this task, utilizing an external\nsource of knowledge, such as the FoodOn ontology. To advance the field of\nagricultural NLP, we propose two new avenues of exploration: (1) utilizing\nGPT-based models as a baseline and (2) leveraging ChatGPT as an external source\nof knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and\nwe believe it has the potential to improve our model in the task of semantic\nmatching and enhance our model's understanding of food-related concepts and\nrelationships. Additionally, we experiment with other applications, such as\ncuisine prediction based on food ingredients, and expand the scope of our\nresearch to include other NLP tasks beyond semantic matching. Overall, this\npaper provides promising avenues for future research in this field, with\npotential implications for improving the performance of agricultural NLP\napplications."
  },
  {
    "arxiv_id": "2306.12951",
    "title": "Tracking public attitudes toward ChatGPT on Twitter using sentiment analysis and topic modeling",
    "url": "http://arxiv.org/abs/2306.12951v1",
    "abstract": "ChatGPT sets a new record with the fastest-growing user base, as a chatbot\npowered by a large language model (LLM). While it demonstrates state-of-the-art\ncapabilities in a variety of language-generation tasks, it also raises\nwidespread public concerns regarding its societal impact. In this paper, we\ninvestigated public attitudes towards ChatGPT by applying natural language\nprocessing techniques such as sentiment analysis and topic modeling to Twitter\ndata from December 5, 2022 to June 10, 2023. Our sentiment analysis result\nindicates that the overall sentiment was largely neutral to positive, and\nnegative sentiments were decreasing over time. Our topic model reveals that the\nmost popular topics discussed were Education, Bard, Search Engines, OpenAI,\nMarketing, and Cybersecurity, but the ranking varies by month. We also analyzed\nthe occupations of Twitter users and found that those with occupations in arts\nand entertainment tweeted aboutChatGPT most frequently. Additionally, people\ntended to tweet about topics relevant to their occupation. For instance,\nCybersecurity is the most discussed topic among those with occupations related\nto computer and math, and Education is the most discussed topic among those in\nacademic and research. Overall, our exploratory study provides insights into\nthe public perception of ChatGPT, which could be valuable to both the general\npublic and developers of this technology."
  },
  {
    "arxiv_id": "2306.12659",
    "title": "Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models",
    "url": "http://arxiv.org/abs/2306.12659v1",
    "abstract": "Sentiment analysis is a vital tool for uncovering insights from financial\narticles, news, and social media, shaping our understanding of market\nmovements. Despite the impressive capabilities of large language models (LLMs)\nin financial natural language processing (NLP), they still struggle with\naccurately interpreting numerical values and grasping financial context,\nlimiting their effectiveness in predicting financial sentiment. In this paper,\nwe introduce a simple yet effective instruction tuning approach to address\nthese issues. By transforming a small portion of supervised financial sentiment\nanalysis data into instruction data and fine-tuning a general-purpose LLM with\nthis method, we achieve remarkable advancements in financial sentiment\nanalysis. In the experiment, our approach outperforms state-of-the-art\nsupervised sentiment analysis models, as well as widely used LLMs like ChatGPT\nand LLaMAs, particularly in scenarios where numerical understanding and\ncontextual comprehension are vital."
  },
  {
    "arxiv_id": "2306.12656",
    "title": "Identifying and Extracting Rare Disease Phenotypes with Large Language Models",
    "url": "http://arxiv.org/abs/2306.12656v1",
    "abstract": "Rare diseases (RDs) are collectively common and affect 300 million people\nworldwide. Accurate phenotyping is critical for informing diagnosis and\ntreatment, but RD phenotypes are often embedded in unstructured text and\ntime-consuming to extract manually. While natural language processing (NLP)\nmodels can perform named entity recognition (NER) to automate extraction, a\nmajor bottleneck is the development of a large, annotated corpus for model\ntraining. Recently, prompt learning emerged as an NLP paradigm that can lead to\nmore generalizable results without any (zero-shot) or few labeled samples\n(few-shot). Despite growing interest in ChatGPT, a revolutionary large language\nmodel capable of following complex human prompts and generating high-quality\nresponses, none have studied its NER performance for RDs in the zero- and\nfew-shot settings. To this end, we engineered novel prompts aimed at extracting\nRD phenotypes and, to the best of our knowledge, are the first the establish a\nbenchmark for evaluating ChatGPT's performance in these settings. We compared\nits performance to the traditional fine-tuning approach and conducted an\nin-depth error analysis. Overall, fine-tuning BioClinicalBERT resulted in\nhigher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.591 in the\nzero- and few-shot settings, respectively). Despite this, ChatGPT achieved\nsimilar or higher accuracy for certain entities (i.e., rare diseases and signs)\nin the one-shot setting (F1 of 0.776 and 0.725). This suggests that with\nappropriate prompt engineering, ChatGPT has the potential to match or\noutperform fine-tuned language models for certain entity types with just one\nlabeled sample. While the proliferation of large language models may provide\nopportunities for supporting RD diagnosis and treatment, researchers and\nclinicians should critically evaluate model outputs and be well-informed of\ntheir limitations."
  },
  {
    "arxiv_id": "2306.13501",
    "title": "Knowledge-Infused Self Attention Transformers",
    "url": "http://arxiv.org/abs/2306.13501v1",
    "abstract": "Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures."
  },
  {
    "arxiv_id": "2306.13315",
    "title": "Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM",
    "url": "http://arxiv.org/abs/2306.13315v1",
    "abstract": "Text summarization is a fundamental task in natural language processing that\naims to condense large amounts of textual information into concise and coherent\nsummaries. With the exponential growth of content and the need to extract key\ninformation efficiently, text summarization has gained significant attention in\nrecent years. In this study, LSTM and pre-trained T5, Pegasus, BART and\nBART-Large model performances were evaluated on the open source dataset (Xsum,\nCNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared\nresume dataset. This resume dataset consists of many information such as\nlanguage, education, experience, personal information, skills, and this data\nincludes 75 resumes. The primary objective of this research was to classify\nresume text. Various techniques such as LSTM, pre-trained models, and\nfine-tuned models were assessed using a dataset of resumes. The BART-Large\nmodel fine-tuned with the resume dataset gave the best performance."
  },
  {
    "arxiv_id": "2306.13195",
    "title": "Prompt to GPT-3: Step-by-Step Thinking Instructions for Humor Generation",
    "url": "http://arxiv.org/abs/2306.13195v1",
    "abstract": "Artificial intelligence has made significant progress in natural language\nprocessing, with models like GPT-3 demonstrating impressive capabilities.\nHowever, these models still have limitations when it comes to complex tasks\nthat require an understanding of the user, such as mastering human comedy\nwriting strategies. This paper explores humor generation using GPT-3 by\nmodeling human comedy writing theory and leveraging step-by-step thinking\ninstructions. In addition, we explore the role of cognitive distance in\ncreating humor."
  },
  {
    "arxiv_id": "2306.14263",
    "title": "Revolutionizing Cyber Threat Detection with Large Language Models",
    "url": "http://arxiv.org/abs/2306.14263v1",
    "abstract": "The field of Natural Language Processing (NLP) is currently undergoing a\nrevolutionary transformation driven by the power of pre-trained Large Language\nModels (LLMs) based on groundbreaking Transformer architectures. As the\nfrequency and diversity of cybersecurity attacks continue to rise, the\nimportance of incident detection has significantly increased. IoT devices are\nexpanding rapidly, resulting in a growing need for efficient techniques to\nautonomously identify network-based attacks in IoT networks with both high\nprecision and minimal computational requirements. This paper presents\nSecurityBERT, a novel architecture that leverages the Bidirectional Encoder\nRepresentations from Transformers (BERT) model for cyber threat detection in\nIoT networks. During the training of SecurityBERT, we incorporated a novel\nprivacy-preserving encoding technique called Privacy-Preserving Fixed-Length\nEncoding (PPFLE). We effectively represented network traffic data in a\nstructured format by combining PPFLE with the Byte-level Byte-Pair Encoder\n(BBPE) Tokenizer. Our research demonstrates that SecurityBERT outperforms\ntraditional Machine Learning (ML) and Deep Learning (DL) methods, such as\nConvolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), in\ncyber threat detection. Employing the Edge-IIoTset cybersecurity dataset, our\nexperimental analysis shows that SecurityBERT achieved an impressive 98.2%\noverall accuracy in identifying fourteen distinct attack types, surpassing\nprevious records set by hybrid solutions such as GAN-Transformer-based\narchitectures and CNN-LSTM models. With an inference time of less than 0.15\nseconds on an average CPU and a compact model size of just 16.7MB, SecurityBERT\nis ideally suited for real-life traffic analysis and a suitable choice for\ndeployment on resource-constrained IoT devices."
  },
  {
    "arxiv_id": "2306.14096",
    "title": "Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models",
    "url": "http://arxiv.org/abs/2306.14096v1",
    "abstract": "Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. The FinChina SA dataset is\npublicly available at https://github.com/YerayL/FinChina-SA"
  },
  {
    "arxiv_id": "2306.14062",
    "title": "On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions",
    "url": "http://arxiv.org/abs/2306.14062v1",
    "abstract": "The volume, variety, and velocity of change in vulnerabilities and exploits\nhave made incident threat analysis challenging with human expertise and\nexperience along. Tactics, Techniques, and Procedures (TTPs) are to describe\nhow and why attackers exploit vulnerabilities. However, a TTP description\nwritten by one security professional can be interpreted very differently by\nanother, leading to confusion in cybersecurity operations or even business,\npolicy, and legal decisions. Meanwhile, advancements in AI have led to the\nincreasing use of Natural Language Processing (NLP) algorithms to assist the\nvarious tasks in cyber operations. With the rise of Large Language Models\n(LLMs), NLP tasks have significantly improved because of the LLM's semantic\nunderstanding and scalability. This leads us to question how well LLMs can\ninterpret TTPs or general cyberattack descriptions to inform analysts of the\nintended purposes of cyberattacks. We propose to analyze and compare the direct\nuse of LLMs (e.g., GPT-3.5) versus supervised fine-tuning (SFT) of\nsmall-scale-LLMs (e.g., BERT) to study their capabilities in predicting ATT&CK\ntactics. Our results reveal that the small-scale-LLMs with SFT provide a more\nfocused and clearer differentiation between the ATT&CK tactics (if such\ndifferentiation exists). On the other hand, direct use of LLMs offer a broader\ninterpretation of cyberattack techniques. When treating more general cases,\ndespite the power of LLMs, inherent ambiguity exists and limits their\npredictive power. We then summarize the challenges and recommend research\ndirections on LLMs to treat the inherent ambiguity of TTP descriptions used in\nvarious cyber operations."
  },
  {
    "arxiv_id": "2306.13947",
    "title": "Comparison of Pre-trained Language Models for Turkish Address Parsing",
    "url": "http://arxiv.org/abs/2306.13947v1",
    "abstract": "Transformer based pre-trained models such as BERT and its variants, which are\ntrained on large corpora, have demonstrated tremendous success for natural\nlanguage processing (NLP) tasks. Most of academic works are based on the\nEnglish language; however, the number of multilingual and language specific\nstudies increase steadily. Furthermore, several studies claimed that language\nspecific models outperform multilingual models in various tasks. Therefore, the\ncommunity tends to train or fine-tune the models for the language of their case\nstudy, specifically. In this paper, we focus on Turkish maps data and\nthoroughly evaluate both multilingual and Turkish based BERT, DistilBERT,\nELECTRA and RoBERTa. Besides, we also propose a MultiLayer Perceptron (MLP) for\nfine-tuning BERT in addition to the standard approach of one-layer fine-tuning.\nFor the dataset, a mid-sized Address Parsing corpus taken with a relatively\nhigh quality is constructed. Conducted experiments on this dataset indicate\nthat Turkish language specific models with MLP fine-tuning yields slightly\nbetter results when compared to the multilingual fine-tuned models. Moreover,\nvisualization of address tokens' representations further indicates the\neffectiveness of BERT variants for classifying a variety of addresses."
  },
  {
    "arxiv_id": "2306.15609",
    "title": "Exploring Durham University Physics exams with Large Language Models",
    "url": "http://arxiv.org/abs/2306.15609v1",
    "abstract": "The emergence of advanced Natural Language Processing (NLP) models like\nChatGPT has raised concerns among universities regarding AI-driven exam\ncompletion. This paper provides a comprehensive evaluation of the proficiency\nof GPT-4 and GPT-3.5 in answering a set of 42 exam papers derived from 10\ndistinct physics courses, administered at Durham University over the span of\n2018 to 2022, totalling 593 questions and 2504 available marks. These exams,\nspanning both undergraduate and postgraduate levels, include traditional\npre-COVID and adaptive COVID-era formats. Questions from the years 2018-2020\nwere designed for pre-COVID in person adjudicated examinations whereas the\n2021-2022 exams were set for varying COVID-adapted conditions including\nopen-book conditions. To ensure a fair evaluation of AI performances, the exams\ncompleted by AI were assessed by the original exam markers. However, due to\nstaffing constraints, only the aforementioned 593 out of the total 1280\nquestions were marked. GPT-4 and GPT-3.5 scored an average of 49.4\\% and\n38.6\\%, respectively, suggesting only the weaker students would potential\nimprove their marks if using AI. For exams from the pre-COVID era, the average\nscores for GPT-4 and GPT-3.5 were 50.8\\% and 41.6\\%, respectively. However,\npost-COVID, these dropped to 47.5\\% and 33.6\\%. Thus contrary to expectations,\nthe change to less fact-based questions in the COVID era did not significantly\nimpact AI performance for the state-of-the-art models such as GPT-4. These\nfindings suggest that while current AI models struggle with university-level\nPhysics questions, an improving trend is observable. The code used for\nautomated AI completion is made publicly available for further research."
  },
  {
    "arxiv_id": "2306.15498",
    "title": "Using Large Language Models to Provide Explanatory Feedback to Human Tutors",
    "url": "http://arxiv.org/abs/2306.15498v1",
    "abstract": "Research demonstrates learners engaging in the process of producing\nexplanations to support their reasoning, can have a positive impact on\nlearning. However, providing learners real-time explanatory feedback often\npresents challenges related to classification accuracy, particularly in\ndomain-specific environments, containing situationally complex and nuanced\nresponses. We present two approaches for supplying tutors real-time feedback\nwithin an online lesson on how to give students effective praise. This\nwork-in-progress demonstrates considerable accuracy in binary classification\nfor corrective feedback of effective, or effort-based (F1 score = 0.811), and\nineffective, or outcome-based (F1 score = 0.350), praise responses. More\nnotably, we introduce progress towards an enhanced approach of providing\nexplanatory feedback using large language model-facilitated named entity\nrecognition, which can provide tutors feedback, not only while engaging in\nlessons, but can potentially suggest real-time tutor moves. Future work\ninvolves leveraging large language models for data augmentation to improve\naccuracy, while also developing an explanatory feedback interface."
  },
  {
    "arxiv_id": "2306.14979",
    "title": "LM4HPC: Towards Effective Language Model Application in High-Performance Computing",
    "url": "http://arxiv.org/abs/2306.14979v1",
    "abstract": "In recent years, language models (LMs), such as GPT-4, have been widely used\nin multiple domains, including natural language processing, visualization, and\nso on. However, applying them for analyzing and optimizing high-performance\ncomputing (HPC) software is still challenging due to the lack of HPC-specific\nsupport. In this paper, we design the LM4HPC framework to facilitate the\nresearch and development of HPC software analyses and optimizations using LMs.\nTailored for supporting HPC datasets, AI models, and pipelines, our framework\nis built on top of a range of components from different levels of the machine\nlearning software stack, with Hugging Face-compatible APIs. Using three\nrepresentative tasks, we evaluated the prototype of our framework. The results\nshow that LM4HPC can help users quickly evaluate a set of state-of-the-art\nmodels and generate insightful leaderboards."
  },
  {
    "arxiv_id": "2306.16092",
    "title": "ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases",
    "url": "http://arxiv.org/abs/2306.16092v1",
    "abstract": "AI legal assistants based on Large Language Models (LLMs) can provide\naccessible legal consulting services, but the hallucination problem poses\npotential legal risks. This paper presents Chatlaw, an innovative legal\nassistant utilizing a Mixture-of-Experts (MoE) model and a multi-agent system\nto enhance the reliability and accuracy of AI-driven legal services. By\nintegrating knowledge graphs with artificial screening, we construct a\nhigh-quality legal dataset to train the MoE model. This model utilizes\ndifferent experts to address various legal issues, optimizing the accuracy of\nlegal responses. Additionally, Standardized Operating Procedures (SOP), modeled\nafter real law firm workflows, significantly reduce errors and hallucinations\nin legal services. Our MoE model outperforms GPT-4 in the Lawbench and Unified\nQualification Exam for Legal Professionals by 7.73% in accuracy and 11 points,\nrespectively, and also surpasses other models in multiple dimensions during\nreal-case consultations, demonstrating our robust capability for legal\nconsultation."
  },
  {
    "arxiv_id": "2306.15895",
    "title": "Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias",
    "url": "http://arxiv.org/abs/2306.15895v1",
    "abstract": "Large language models (LLMs) have been recently leveraged as training data\ngenerators for various natural language processing (NLP) tasks. While previous\nresearch has explored different approaches to training models using generated\ndata, they generally rely on simple class-conditional prompts, which may limit\nthe diversity of the generated data and inherit systematic biases of LLM. Thus,\nwe investigate training data generation with diversely attributed prompts\n(e.g., specifying attributes like length and style), which have the potential\nto yield diverse and attributed generated data. Our investigation focuses on\ndatasets with high cardinality and diverse domains, wherein we demonstrate that\nattributed prompts outperform simple class-conditional prompts in terms of the\nresulting model's performance. Additionally, we present a comprehensive\nempirical study on data generation encompassing vital aspects like bias,\ndiversity, and efficiency, and highlight three key observations: firstly,\nsynthetic datasets generated by simple prompts exhibit significant biases, such\nas regional bias; secondly, attribute diversity plays a pivotal role in\nenhancing model performance; lastly, attributed prompts achieve the performance\nof simple class-conditional prompts while utilizing only 5\\% of the querying\ncost of ChatGPT associated with the latter. The data and code are available on\n\\url{https://github.com/yueyu1030/AttrPrompt}."
  },
  {
    "arxiv_id": "2306.16793",
    "title": "Benchmarking Large Language Model Capabilities for Conditional Generation",
    "url": "http://arxiv.org/abs/2306.16793v1",
    "abstract": "Pre-trained large language models (PLMs) underlie most new developments in\nnatural language processing. They have shifted the field from\napplication-specific model pipelines to a single model that is adapted to a\nwide range of tasks. Autoregressive PLMs like GPT-3 or PaLM, alongside\ntechniques like few-shot learning, have additionally shifted the output\nmodality to generation instead of classification or regression. Despite their\nubiquitous use, the generation quality of language models is rarely evaluated\nwhen these models are introduced. Additionally, it is unclear how existing\ngeneration tasks--while they can be used to compare systems at a high\nlevel--relate to the real world use cases for which people have been adopting\nthem. In this work, we discuss how to adapt existing application-specific\ngeneration benchmarks to PLMs and provide an in-depth, empirical study of the\nlimitations and capabilities of PLMs in natural language generation tasks along\ndimensions such as scale, architecture, input and output language. Our results\nshow that PLMs differ in their applicability to different data regimes and\ntheir generalization to multiple languages and inform which PLMs to use for a\ngiven generation task setup. We share best practices to be taken into\nconsideration when benchmarking generation capabilities during the development\nof upcoming PLMs."
  },
  {
    "arxiv_id": "2306.16601",
    "title": "An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs",
    "url": "http://arxiv.org/abs/2306.16601v1",
    "abstract": "In recent years, Transformer-based language models have become the standard\napproach for natural language processing tasks. However, stringent throughput\nand latency requirements in industrial applications are limiting their\nadoption. To mitigate the gap, model compression techniques such as structured\npruning are being used to improve inference efficiency. However, most existing\nneural network inference runtimes lack adequate support for structured\nsparsity. In this paper, we propose an efficient sparse deep learning inference\nsoftware stack for Transformer-based language models where the weights are\npruned with constant block size. Our sparse software accelerator leverages\nIntel Deep Learning Boost to maximize the performance of sparse matrix - dense\nmatrix multiplication (commonly abbreviated as SpMM) on CPUs. Our SpMM kernel\noutperforms the existing sparse libraries (oneMKL, TVM, and LIBXSMM) by an\norder of magnitude on a wide range of GEMM shapes under 5 representative\nsparsity ratios (70%, 75%, 80%, 85%, 90%). Moreover, our SpMM kernel shows up\nto 5x speedup over dense GEMM kernel of oneDNN, a well-optimized dense library\nwidely used in industry. We apply our sparse accelerator on widely-used\nTransformer-based language models including Bert-Mini, DistilBERT, Bert-Base,\nand BERT-Large. Our sparse inference software shows up to 1.5x speedup over\nNeural Magic's Deepsparse under same configurations on Xeon on Amazon Web\nServices under proxy production latency constraints. We also compare our\nsolution with two framework-based inference solutions, ONNX Runtime and\nPyTorch, and demonstrate up to 37x speedup over ONNX Runtime and 345x over\nPyTorch on Xeon under the latency constraints. All the source code is publicly\navailable on Github: https://github.com/intel/intel-extension-for-transformers."
  },
  {
    "arxiv_id": "2306.17519",
    "title": "GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models",
    "url": "http://arxiv.org/abs/2306.17519v1",
    "abstract": "Relation extraction (RE) is a crucial task in natural language processing\n(NLP) that aims to identify and classify relationships between entities\nmentioned in text. In the financial domain, relation extraction plays a vital\nrole in extracting valuable information from financial documents, such as news\narticles, earnings reports, and company filings. This paper describes our\nsolution to relation extraction on one such dataset REFinD. The dataset was\nreleased along with shared task as a part of the Fourth Workshop on Knowledge\nDiscovery from Unstructured Data in Financial Services, co-located with SIGIR\n2023. In this paper, we employed OpenAI models under the framework of\nin-context learning (ICL). We utilized two retrieval strategies to find top K\nrelevant in-context learning demonstrations / examples from training data for a\ngiven test example. The first retrieval mechanism, we employed, is a\nlearning-free dense retriever and the other system is a learning-based\nretriever. We were able to achieve 3rd rank overall. Our best F1-score is\n0.718."
  },
  {
    "arxiv_id": "2307.01163",
    "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
    "url": "http://arxiv.org/abs/2307.01163v1",
    "abstract": "Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English."
  },
  {
    "arxiv_id": "2307.01137",
    "title": "Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking",
    "url": "http://arxiv.org/abs/2307.01137v1",
    "abstract": "The biomedical field relies heavily on concept linking in various areas such\nas literature mining, graph alignment, information retrieval,\nquestion-answering, data, and knowledge integration. Although large language\nmodels (LLMs) have made significant strides in many natural language processing\ntasks, their effectiveness in biomedical concept mapping is yet to be fully\nexplored. This research investigates a method that exploits the in-context\nlearning (ICL) capabilities of large models for biomedical concept linking. The\nproposed approach adopts a two-stage retrieve-and-rank framework. Initially,\nbiomedical concepts are embedded using language models, and then embedding\nsimilarity is utilized to retrieve the top candidates. These candidates'\ncontextual information is subsequently incorporated into the prompt and\nprocessed by a large language model to re-rank the concepts. This approach\nachieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%\nin chemical entity normalization, exhibiting a competitive performance relative\nto supervised learning methods. Further, it showed a significant improvement,\nwith an over 20-point absolute increase in F1 score on an oncology matching\ndataset. Extensive qualitative assessments were conducted, and the benefits and\npotential shortcomings of using large language models within the biomedical\ndomain were discussed. were discussed."
  },
  {
    "arxiv_id": "2307.00910",
    "title": "Contextual Prompt Learning for Vision-Language Understanding",
    "url": "http://arxiv.org/abs/2307.00910v1",
    "abstract": "Recent advances in multimodal learning has resulted in powerful\nvision-language models, whose representations are generalizable across a\nvariety of downstream tasks. Recently, their generalization ability has been\nfurther extended by incorporating trainable prompts, borrowed from the natural\nlanguage processing literature. While such prompt learning techniques have\nshown impressive results, we identify that these prompts are trained based on\nglobal image features which limits itself in two aspects: First, by using\nglobal features, these prompts could be focusing less on the discriminative\nforeground image, resulting in poor generalization to various\nout-of-distribution test cases. Second, existing work weights all prompts\nequally whereas intuitively, prompts should be reweighed according to the\nsemantics of the image. We address these as part of our proposed Contextual\nPrompt Learning (CoPL) framework, capable of aligning the prompts to the\nlocalized features of the image. Our key innovations over earlier works include\nusing local image features as part of the prompt learning process, and more\ncrucially, learning to weight these prompts based on local features that are\nappropriate for the task at hand. This gives us dynamic prompts that are both\naligned to local image features as well as aware of local contextual\nrelationships. Our extensive set of experiments on a variety of standard and\nfew-shot datasets show that our method produces substantially improved\nperformance when compared to the current state of the art methods. We also\ndemonstrate both few-shot and out-of-distribution performance to establish the\nutility of learning dynamic prompts that are aligned to local image features."
  },
  {
    "arxiv_id": "2307.00457",
    "title": "Text based Large Language Model for Recommendation",
    "url": "http://arxiv.org/abs/2307.00457v1",
    "abstract": "In recent years, large language models (LLM) have emerged as powerful tools\nfor diverse natural language processing tasks. However, their potential for\nrecommender systems under the generative recommendation paradigm remains\nrelatively unexplored. This paper presents an innovative approach to\nrecommendation systems using large language models (LLMs) based on text data.\nIn this paper, we present a novel LLM for generative recommendation (GenRec)\nthat utilized the expressive power of LLM to directly generate the target item\nto recommend, rather than calculating ranking score for each candidate item one\nby one as in traditional discriminative recommendation. GenRec uses LLM's\nunderstanding ability to interpret context, learn user preferences, and\ngenerate relevant recommendation. Our proposed approach leverages the vast\nknowledge encoded in large language models to accomplish recommendation tasks.\nWe first we formulate specialized prompts to enhance the ability of LLM to\ncomprehend recommendation tasks. Subsequently, we use these prompts to\nfine-tune the LLaMA backbone LLM on a dataset of user-item interactions,\nrepresented by textual data, to capture user preferences and item\ncharacteristics. Our research underscores the potential of LLM-based generative\nrecommendation in revolutionizing the domain of recommendation systems and\noffers a foundational framework for future explorations in this field. We\nconduct extensive experiments on benchmark datasets, and the experiments shows\nthat our GenRec has significant better results on large dataset."
  },
  {
    "arxiv_id": "2307.02301",
    "title": "Sumformer: Universal Approximation for Efficient Transformers",
    "url": "http://arxiv.org/abs/2307.02301v1",
    "abstract": "Natural language processing (NLP) made an impressive jump with the\nintroduction of Transformers. ChatGPT is one of the most famous examples,\nchanging the perception of the possibilities of AI even outside the research\ncommunity. However, besides the impressive performance, the quadratic time and\nspace complexity of Transformers with respect to sequence length pose\nsignificant limitations for handling long sequences. While efficient\nTransformer architectures like Linformer and Performer with linear complexity\nhave emerged as promising solutions, their theoretical understanding remains\nlimited. In this paper, we introduce Sumformer, a novel and simple architecture\ncapable of universally approximating equivariant sequence-to-sequence\nfunctions. We use Sumformer to give the first universal approximation results\nfor Linformer and Performer. Moreover, we derive a new proof for Transformers,\nshowing that just one attention layer is sufficient for universal\napproximation."
  },
  {
    "arxiv_id": "2307.02092",
    "title": "Make A Long Image Short: Adaptive Token Length for Vision Transformers",
    "url": "http://arxiv.org/abs/2307.02092v1",
    "abstract": "The vision transformer is a model that breaks down each image into a sequence\nof tokens with a fixed length and processes them similarly to words in natural\nlanguage processing. Although increasing the number of tokens typically results\nin better performance, it also leads to a considerable increase in\ncomputational cost. Motivated by the saying \"A picture is worth a thousand\nwords,\" we propose an innovative approach to accelerate the ViT model by\nshortening long images. Specifically, we introduce a method for adaptively\nassigning token length for each image at test time to accelerate inference\nspeed. First, we train a Resizable-ViT (ReViT) model capable of processing\ninput with diverse token lengths. Next, we extract token-length labels from\nReViT that indicate the minimum number of tokens required to achieve accurate\npredictions. We then use these labels to train a lightweight Token-Length\nAssigner (TLA) that allocates the optimal token length for each image during\ninference. The TLA enables ReViT to process images with the minimum sufficient\nnumber of tokens, reducing token numbers in the ViT model and improving\ninference speed. Our approach is general and compatible with modern vision\ntransformer architectures, significantly reducing computational costs. We\nverified the effectiveness of our methods on multiple representative ViT models\non image classification and action recognition."
  },
  {
    "arxiv_id": "2307.02054",
    "title": "Emoji Prediction using Transformer Models",
    "url": "http://arxiv.org/abs/2307.02054v1",
    "abstract": "In recent years, the use of emojis in social media has increased\ndramatically, making them an important element in understanding online\ncommunication. However, predicting the meaning of emojis in a given text is a\nchallenging task due to their ambiguous nature. In this study, we propose a\ntransformer-based approach for emoji prediction using BERT, a widely-used\npre-trained language model. We fine-tuned BERT on a large corpus of text\n(tweets) containing both text and emojis to predict the most appropriate emoji\nfor a given text. Our experimental results demonstrate that our approach\noutperforms several state-of-the-art models in predicting emojis with an\naccuracy of over 75 percent. This work has potential applications in natural\nlanguage processing, sentiment analysis, and social media marketing."
  },
  {
    "arxiv_id": "2307.02046",
    "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
    "url": "http://arxiv.org/abs/2307.02046v1",
    "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field."
  },
  {
    "arxiv_id": "2307.01609",
    "title": "A Language Model for Grammatical Error Correction in L2 Russian",
    "url": "http://arxiv.org/abs/2307.01609v1",
    "abstract": "Grammatical error correction is one of the fundamental tasks in Natural\nLanguage Processing. For the Russian language, most of the spellcheckers\navailable correct typos and other simple errors with high accuracy, but often\nfail when faced with non-native (L2) writing, since the latter contains errors\nthat are not typical for native speakers. In this paper, we propose a pipeline\ninvolving a language model intended for correcting errors in L2 Russian\nwriting. The language model proposed is trained on untagged texts of the\nNewspaper subcorpus of the Russian National Corpus, and the quality of the\nmodel is validated against the RULEC-GEC corpus."
  },
  {
    "arxiv_id": "2307.01540",
    "title": "Learning to Prompt in the Classroom to Understand AI Limits: A pilot study",
    "url": "http://arxiv.org/abs/2307.01540v1",
    "abstract": "Artificial intelligence's (AI) progress holds great promise in tackling\npressing societal concerns such as health and climate. Large Language Models\n(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural\nlanguage processing capabilities of AI systems allowing them to process an\nunprecedented amount of unstructured data. However, the ensuing excitement has\nled to negative sentiments, even as AI methods demonstrate remarkable\ncontributions (e.g. in health and genetics). A key factor contributing to this\nsentiment is the misleading perception that LLMs can effortlessly provide\nsolutions across domains, ignoring their limitations such as hallucinations and\nreasoning constraints. Acknowledging AI fallibility is crucial to address the\nimpact of dogmatic overconfidence in possibly erroneous suggestions generated\nby LLMs. At the same time, it can reduce fear and other negative attitudes\ntoward AI. This necessitates comprehensive AI literacy interventions that\neducate the public about LLM constraints and effective usage techniques, i.e\nprompting strategies. With this aim, a pilot educational intervention was\nperformed in a high school with 21 students. It involved presenting high-level\nconcepts about intelligence, AI, and LLMs, followed by practical exercises\ninvolving ChatGPT in creating natural educational conversations and applying\nestablished prompting strategies. Encouraging preliminary results emerged,\nincluding high appreciation of the activity, improved interaction quality with\nthe LLM, reduced negative AI sentiments, and a better grasp of limitations,\nspecifically unreliability, limited understanding of commands leading to\nunsatisfactory responses, and limited presentation flexibility. Our aim is to\nexplore AI acceptance factors and refine this approach for more controlled\nfuture studies."
  },
  {
    "arxiv_id": "2307.01504",
    "title": "All in One: Multi-task Prompting for Graph Neural Networks",
    "url": "http://arxiv.org/abs/2307.01504v1",
    "abstract": "Recently, ''pre-training and fine-tuning'' has been adopted as a standard\nworkflow for many graph tasks since it can take general graph knowledge to\nrelieve the lack of graph annotations from each application. However, graph\ntasks with node level, edge level, and graph level are far diversified, making\nthe pre-training pretext often incompatible with these multiple tasks. This gap\nmay even cause a ''negative transfer'' to the specific application, leading to\npoor results. Inspired by the prompt learning in natural language processing\n(NLP), which has presented significant effectiveness in leveraging prior\nknowledge for various NLP tasks, we study the prompting topic for graphs with\nthe motivation of filling the gap between pre-trained models and various graph\ntasks. In this paper, we propose a novel multi-task prompting method for graph\nmodels. Specifically, we first unify the format of graph prompts and language\nprompts with the prompt token, token structure, and inserting pattern. In this\nway, the prompting idea from NLP can be seamlessly introduced to the graph\narea. Then, to further narrow the gap between various graph tasks and\nstate-of-the-art pre-training strategies, we further study the task space of\nvarious graph applications and reformulate downstream problems to the\ngraph-level task. Afterward, we introduce meta-learning to efficiently learn a\nbetter initialization for the multi-task prompt of graphs so that our prompting\nframework can be more reliable and general for different tasks. We conduct\nextensive experiments, results from which demonstrate the superiority of our\nmethod."
  },
  {
    "arxiv_id": "2307.03162",
    "title": "BrickPal: Augmented Reality-based Assembly Instructions for Brick Models",
    "url": "http://arxiv.org/abs/2307.03162v1",
    "abstract": "The assembly instruction is a mandatory component of Lego-like brick sets.The\nconventional production of assembly instructions requires a considerable amount\nof manual fine-tuning, which is intractable for casual users and customized\nbrick sets.Moreover, the traditional paper-based instructions lack\nexpressiveness and interactivity.To tackle the two problems above, we present\nBrickPal, an augmented reality-based system, which visualizes assembly\ninstructions in an augmented reality head-mounted display. It utilizes Natural\nLanguage Processing (NLP) techniques to generate plausible assembly sequences,\nand provide real-time guidance in the AR headset.Our user study demonstrates\nBrickPal's effectiveness at assisting users in brick assembly compared to\ntraditional assembly methods. Additionally, the NLP algorithm-generated\nassembly sequences achieve the same usability with manually adapted sequences."
  },
  {
    "arxiv_id": "2307.03109",
    "title": "A Survey on Evaluation of Large Language Models",
    "url": "http://arxiv.org/abs/2307.03109v1",
    "abstract": "Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey."
  },
  {
    "arxiv_id": "2307.03493",
    "title": "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers",
    "url": "http://arxiv.org/abs/2307.03493v1",
    "abstract": "Transformer networks have emerged as the state-of-the-art approach for\nnatural language processing tasks and are gaining popularity in other domains\nsuch as computer vision and audio processing. However, the efficient hardware\nacceleration of transformer models poses new challenges due to their high\narithmetic intensities, large memory requirements, and complex dataflow\ndependencies. In this work, we propose ITA, a novel accelerator architecture\nfor transformers and related models that targets efficient inference on\nembedded systems by exploiting 8-bit quantization and an innovative softmax\nimplementation that operates exclusively on integer values. By computing\non-the-fly in streaming mode, our softmax implementation minimizes data\nmovement and energy consumption. ITA achieves competitive energy efficiency\nwith respect to state-of-the-art transformer accelerators with 16.9 TOPS/W,\nwhile outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nm\nfully-depleted silicon-on-insulator technology at 0.8 V."
  },
  {
    "arxiv_id": "2307.03254",
    "title": "Vision Language Transformers: A Survey",
    "url": "http://arxiv.org/abs/2307.03254v1",
    "abstract": "Vision language tasks, such as answering questions about or generating\ncaptions that describe an image, are difficult tasks for computers to perform.\nA relatively recent body of research has adapted the pretrained transformer\narchitecture introduced in \\citet{vaswani2017attention} to vision language\nmodeling. Transformer models have greatly improved performance and versatility\nover previous vision language models. They do so by pretraining models on a\nlarge generic datasets and transferring their learning to new tasks with minor\nchanges in architecture and parameter values. This type of transfer learning\nhas become the standard modeling practice in both natural language processing\nand computer vision. Vision language transformers offer the promise of\nproducing similar advancements in tasks which require both vision and language.\nIn this paper, we provide a broad synthesis of the currently available research\non vision language transformer models and offer some analysis of their\nstrengths, limitations and some open questions that remain."
  },
  {
    "arxiv_id": "2307.04251",
    "title": "ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey",
    "url": "http://arxiv.org/abs/2307.04251v1",
    "abstract": "ChatGPT is a large language model (LLM) created by OpenAI that has been\ncarefully trained on a large amount of data. It has revolutionized the field of\nnatural language processing (NLP) and has pushed the boundaries of LLM\ncapabilities. ChatGPT has played a pivotal role in enabling widespread public\ninteraction with generative artificial intelligence (GAI) on a large scale. It\nhas also sparked research interest in developing similar technologies and\ninvestigating their applications and implications. In this paper, our primary\ngoal is to provide a concise survey on the current lines of research on ChatGPT\nand its evolution. We considered both the glass box and black box views of\nChatGPT, encompassing the components and foundational elements of the\ntechnology, as well as its applications, impacts, and implications. The glass\nbox approach focuses on understanding the inner workings of the technology, and\nthe black box approach embraces it as a complex system, and thus examines its\ninputs, outputs, and effects. This paves the way for a comprehensive\nexploration of the technology and provides a road map for further research and\nexperimentation. We also lay out essential foundational literature on LLMs and\nGAI in general and their connection with ChatGPT. This overview sheds light on\nexisting and missing research lines in the emerging field of LLMs, benefiting\nboth public users and developers. Furthermore, the paper delves into the broad\nspectrum of applications and significant concerns in fields such as education,\nresearch, healthcare, finance, etc."
  },
  {
    "arxiv_id": "2307.04172",
    "title": "Can Generative Large Language Models Perform ASR Error Correction?",
    "url": "http://arxiv.org/abs/2307.04172v1",
    "abstract": "ASR error correction is an interesting option for post processing speech\nrecognition system outputs. These error correction models are usually trained\nin a supervised fashion using the decoding results of a target ASR system. This\napproach can be computationally intensive and the model is tuned to a specific\nASR system. Recently generative large language models (LLMs) have been applied\nto a wide range of natural language processing tasks, as they can operate in a\nzero-shot or few shot fashion. In this paper we investigate using ChatGPT, a\ngenerative LLM, for ASR error correction. Based on the ASR N-best output, we\npropose both unconstrained and constrained, where a member of the N-best list\nis selected, approaches. Additionally, zero and 1-shot settings are evaluated.\nExperiments show that this generative LLM approach can yield performance gains\nfor two different state-of-the-art ASR architectures, transducer and\nattention-encoder-decoder based, and multiple test sets."
  },
  {
    "arxiv_id": "2307.03972",
    "title": "Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task",
    "url": "http://arxiv.org/abs/2307.03972v1",
    "abstract": "Large-scale language models (LLMs) has shown remarkable capability in various\nof Natural Language Processing (NLP) tasks and attracted lots of attention\nrecently. However, some studies indicated that large language models fail to\nachieve promising result beyond the state-of-the-art models in English\ngrammatical error correction (GEC) tasks. In this report, we aim to explore the\nhow large language models perform on Chinese grammatical error correction tasks\nand provide guidance for future work. We conduct experiments with 3 different\nLLMs of different model scale on 4 Chinese GEC dataset. Our experimental\nresults indicate that the performances of LLMs on automatic evaluation metrics\nfalls short of the previous sota models because of the problem of\nover-correction. Furthermore, we also discover notable variations in the\nperformance of LLMs when evaluated on different data distributions. Our\nfindings demonstrates that further investigation is required for the\napplication of LLMs on Chinese GEC task."
  },
  {
    "arxiv_id": "2307.05354",
    "title": "GujiBERT and GujiGPT: Construction of Intelligent Information Processing Foundation Language Models for Ancient Texts",
    "url": "http://arxiv.org/abs/2307.05354v1",
    "abstract": "In the context of the rapid development of large language models, we have\nmeticulously trained and introduced the GujiBERT and GujiGPT language models,\nwhich are foundational models specifically designed for intelligent information\nprocessing of ancient texts. These models have been trained on an extensive\ndataset that encompasses both simplified and traditional Chinese characters,\nallowing them to effectively handle various natural language processing tasks\nrelated to ancient books, including but not limited to automatic sentence\nsegmentation, punctuation, word segmentation, part-of-speech tagging, entity\nrecognition, and automatic translation. Notably, these models have exhibited\nexceptional performance across a range of validation tasks using publicly\navailable datasets. Our research findings highlight the efficacy of employing\nself-supervised methods to further train the models using classical text\ncorpora, thus enhancing their capability to tackle downstream tasks. Moreover,\nit is worth emphasizing that the choice of font, the scale of the corpus, and\nthe initial model selection all exert significant influence over the ultimate\nexperimental outcomes. To cater to the diverse text processing preferences of\nresearchers in digital humanities and linguistics, we have developed three\ndistinct categories comprising a total of nine model variations. We believe\nthat by sharing these foundational language models specialized in the domain of\nancient texts, we can facilitate the intelligent processing and scholarly\nexploration of ancient literary works and, consequently, contribute to the\nglobal dissemination of China's rich and esteemed traditional culture in this\nnew era."
  },
  {
    "arxiv_id": "2307.05979",
    "title": "Transformers in Reinforcement Learning: A Survey",
    "url": "http://arxiv.org/abs/2307.05979v1",
    "abstract": "Transformers have significantly impacted domains like natural language\nprocessing, computer vision, and robotics, where they improve performance\ncompared to other neural networks. This survey explores how transformers are\nused in reinforcement learning (RL), where they are seen as a promising\nsolution for addressing challenges such as unstable training, credit\nassignment, lack of interpretability, and partial observability. We begin by\nproviding a brief domain overview of RL, followed by a discussion on the\nchallenges of classical RL algorithms. Next, we delve into the properties of\nthe transformer and its variants and discuss the characteristics that make them\nwell-suited to address the challenges inherent in RL. We examine the\napplication of transformers to various aspects of RL, including representation\nlearning, transition and reward function modeling, and policy optimization. We\nalso discuss recent research that aims to enhance the interpretability and\nefficiency of transformers in RL, using visualization techniques and efficient\ntraining strategies. Often, the transformer architecture must be tailored to\nthe specific needs of a given application. We present a broad overview of how\ntransformers have been adapted for several applications, including robotics,\nmedicine, language modeling, cloud computing, and combinatorial optimization.\nWe conclude by discussing the limitations of using transformers in RL and\nassess their potential for catalyzing future breakthroughs in this field."
  },
  {
    "arxiv_id": "2307.05722",
    "title": "Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations",
    "url": "http://arxiv.org/abs/2307.05722v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks, demonstrating their exceptional capabilities in various domains.\nHowever, their potential for behavior graph understanding in job\nrecommendations remains largely unexplored. This paper focuses on unveiling the\ncapability of large language models in understanding behavior graphs and\nleveraging this understanding to enhance recommendations in online recruitment,\nincluding the promotion of out-of-distribution (OOD) application. We present a\nnovel framework that harnesses the rich contextual information and semantic\nrepresentations provided by large language models to analyze behavior graphs\nand uncover underlying patterns and relationships. Specifically, we propose a\nmeta-path prompt constructor that leverages LLM recommender to understand\nbehavior graphs for the first time and design a corresponding path augmentation\nmodule to alleviate the prompt bias introduced by path-based sequence input. By\nleveraging this capability, our framework enables personalized and accurate job\nrecommendations for individual users. We evaluate the effectiveness of our\napproach on a comprehensive dataset and demonstrate its ability to improve the\nrelevance and quality of recommended quality. This research not only sheds\nlight on the untapped potential of large language models but also provides\nvaluable insights for developing advanced recommendation systems in the\nrecruitment market. The findings contribute to the growing field of natural\nlanguage processing and offer practical implications for enhancing job search\nexperiences. We release the code at https://github.com/WLiK/GLRec."
  },
  {
    "arxiv_id": "2307.06530",
    "title": "Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study",
    "url": "http://arxiv.org/abs/2307.06530v1",
    "abstract": "This paper explores the integration of Large Language Models (LLMs) into\nAutomatic Speech Recognition (ASR) systems to improve transcription accuracy.\nThe increasing sophistication of LLMs, with their in-context learning\ncapabilities and instruction-following behavior, has drawn significant\nattention in the field of Natural Language Processing (NLP). Our primary focus\nis to investigate the potential of using an LLM's in-context learning\ncapabilities to enhance the performance of ASR systems, which currently face\nchallenges such as ambient noise, speaker accents, and complex linguistic\ncontexts. We designed a study using the Aishell-1 and LibriSpeech datasets,\nwith ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.\nUnfortunately, our initial experiments did not yield promising results,\nindicating the complexity of leveraging LLM's in-context learning for ASR\napplications. Despite further exploration with varied settings and models, the\ncorrected sentences from the LLMs frequently resulted in higher Word Error\nRates (WER), demonstrating the limitations of LLMs in speech applications. This\npaper provides a detailed overview of these experiments, their results, and\nimplications, establishing that using LLMs' in-context learning capabilities to\ncorrect potential errors in speech recognition transcriptions is still a\nchallenging task at the current stage."
  },
  {
    "arxiv_id": "2307.07381",
    "title": "Investigating ChatGPT's Potential to Assist in Requirements Elicitation Processes",
    "url": "http://arxiv.org/abs/2307.07381v1",
    "abstract": "Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE)\nseeks to apply NLP tools, techniques, and resources to the RE process to\nincrease the quality of the requirements. There is little research involving\nthe utilization of Generative AI-based NLP tools and techniques for\nrequirements elicitation. In recent times, Large Language Models (LLM) like\nChatGPT have gained significant recognition due to their notably improved\nperformance in NLP tasks. To explore the potential of ChatGPT to assist in\nrequirements elicitation processes, we formulated six questions to elicit\nrequirements using ChatGPT. Using the same six questions, we conducted\ninterview-based surveys with five RE experts from academia and industry and\ncollected 30 responses containing requirements. The quality of these 36\nresponses (human-formulated + ChatGPT-generated) was evaluated over seven\ndifferent requirements quality attributes by another five RE experts through a\nsecond round of interview-based surveys. In comparing the quality of\nrequirements generated by ChatGPT with those formulated by human experts, we\nfound that ChatGPT-generated requirements are highly Abstract, Atomic,\nConsistent, Correct, and Understandable. Based on these results, we present the\nmost pressing issues related to LLMs and what future research should focus on\nto leverage the emergent behaviour of LLMs more effectively in natural\nlanguage-based RE activities."
  },
  {
    "arxiv_id": "2307.07221",
    "title": "Software Testing with Large Language Model: Survey, Landscape, and Vision",
    "url": "http://arxiv.org/abs/2307.07221v1",
    "abstract": "Pre-trained large language models (LLMs) have recently emerged as a\nbreakthrough technology in natural language processing and artificial\nintelligence, with the ability to handle large-scale datasets and exhibit\nremarkable performance across a wide range of tasks. Meanwhile, software\ntesting is a crucial undertaking that serves as a cornerstone for ensuring the\nquality and reliability of software products. As the scope and complexity of\nsoftware systems continue to grow, the need for more effective software testing\ntechniques becomes increasingly urgent, making it an area ripe for innovative\napproaches such as the use of LLMs. This paper provides a comprehensive review\nof the utilization of LLMs in software testing. It analyzes 102 relevant\nstudies that have used LLMs for software testing, from both the software\ntesting and LLMs perspectives. The paper presents a detailed discussion of the\nsoftware testing tasks for which LLMs are commonly used, among which test case\npreparation and program repair are the most representative. It also analyzes\nthe commonly used LLMs, the types of prompt engineering that are employed, as\nwell as the accompanied techniques with these LLMs. It also summarizes the key\nchallenges and potential opportunities in this direction. This work can serve\nas a roadmap for future research in this area, highlighting potential avenues\nfor exploration, and identifying gaps in our current understanding of the use\nof LLMs in software testing."
  },
  {
    "arxiv_id": "2307.08540",
    "title": "Utilization of Pre-trained Language Model for Adapter-based Knowledge Transfer in Software Engineering",
    "url": "http://arxiv.org/abs/2307.08540v1",
    "abstract": "Software Engineering (SE) Pre-trained Language Models (PLMs), such as\nCodeBERT, are pre-trained on large code corpora, and their learned knowledge\nhas shown success in transferring into downstream tasks (e.g., code clone\ndetection) through the fine-tuning of PLMs. In Natural Language Processing\n(NLP), an alternative in transferring the knowledge of PLMs is explored through\nthe use of adapter, a compact and parameter efficient module that is inserted\ninto a PLM. Although the use of adapters has shown promising results in many\nNLP-based downstream tasks, their application and exploration in SE-based\ndownstream tasks are limited.\n  Here, we study the knowledge transfer using adapters on multiple down-stream\ntasks including cloze test, code clone detection, and code summarization. These\nadapters are trained on code corpora and are inserted into a PLM that is\npre-trained on English corpora or code corpora. We called these PLMs as NL-PLM\nand C-PLM, respectively. We observed an improvement in results using NL-PLM\nover a PLM that does not have adapters, and this suggested that adapters can\ntransfer and utilize useful knowledge from NL-PLM to SE tasks. The results are\nsometimes on par with or exceed the results of C-PLM; while being more\nefficient in terms of the number of parameters and training time.\nInterestingly, adapters inserted into a C-PLM generally yield better results\nthan a traditional fine-tuned C-PLM. Our results open new directions to build\nmore compact models for SE tasks."
  },
  {
    "arxiv_id": "2307.08393",
    "title": "On the application of Large Language Models for language teaching and assessment technology",
    "url": "http://arxiv.org/abs/2307.08393v1",
    "abstract": "The recent release of very large language models such as PaLM and GPT-4 has\nmade an unprecedented impact in the popular media and public consciousness,\ngiving rise to a mixture of excitement and fear as to their capabilities and\npotential uses, and shining a light on natural language processing research\nwhich had not previously received so much attention. The developments offer\ngreat promise for education technology, and in this paper we look specifically\nat the potential for incorporating large language models in AI-driven language\nteaching and assessment systems. We consider several research areas and also\ndiscuss the risks and ethical considerations surrounding generative AI in\neducation technology for language learners. Overall we find that larger\nlanguage models offer improvements over previous models in text generation,\nopening up routes toward content generation which had not previously been\nplausible. For text generation they must be prompted carefully and their\noutputs may need to be reshaped before they are ready for use. For automated\ngrading and grammatical error correction, tasks whose progress is checked on\nwell-known benchmarks, early investigations indicate that large language models\non their own do not improve on state-of-the-art results according to standard\nevaluation metrics. For grading it appears that linguistic features established\nin the literature should still be used for best performance, and for error\ncorrection it may be that the models can offer alternative feedback styles\nwhich are not measured sensitively with existing methods. In all cases, there\nis work to be done to experiment with the inclusion of large language models in\neducation technology for language learners, in order to properly understand and\nreport on their capacities and limitations, and to ensure that foreseeable\nrisks such as misinformation and harmful bias are mitigated."
  },
  {
    "arxiv_id": "2307.08074",
    "title": "Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling",
    "url": "http://arxiv.org/abs/2307.08074v1",
    "abstract": "Modeling discourse -- the linguistic phenomena that go beyond individual\nsentences, is a fundamental yet challenging aspect of natural language\nprocessing (NLP). However, existing evaluation benchmarks primarily focus on\nthe evaluation of inter-sentence properties and overlook critical discourse\nphenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a\nbenchmark that can evaluate intra-sentence discourse properties across a\ndiverse set of NLP tasks, covering understanding, translation, and generation.\nDisco-Bench consists of 9 document-level testsets in the literature domain,\nwhich contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese\nand/or English. For linguistic analysis, we also design a diagnostic test suite\nthat can examine whether the target models learn discourse knowledge. We\ntotally evaluate 20 general-, in-domain and commercial models based on\nTransformer, advanced pretraining architectures and large language models\n(LLMs). Our results show (1) the challenge and necessity of our evaluation\nbenchmark; (2) fine-grained pretraining based on literary document-level\ntraining data consistently improves the modeling of discourse information. We\nwill release the datasets, pretrained models, and leaderboard, which we hope\ncan significantly facilitate research in this field:\nhttps://github.com/longyuewangdcu/Disco-Bench."
  },
  {
    "arxiv_id": "2307.07982",
    "title": "A Survey of Techniques for Optimizing Transformer Inference",
    "url": "http://arxiv.org/abs/2307.07982v1",
    "abstract": "Recent years have seen a phenomenal rise in performance and applications of\ntransformer neural networks. The family of transformer networks, including\nBidirectional Encoder Representations from Transformer (BERT), Generative\nPretrained Transformer (GPT) and Vision Transformer (ViT), have shown their\neffectiveness across Natural Language Processing (NLP) and Computer Vision (CV)\ndomains. Transformer-based networks such as ChatGPT have impacted the lives of\ncommon men. However, the quest for high predictive performance has led to an\nexponential increase in transformers' memory and compute footprint. Researchers\nhave proposed techniques to optimize transformer inference at all levels of\nabstraction. This paper presents a comprehensive survey of techniques for\noptimizing the inference phase of transformer networks. We survey techniques\nsuch as knowledge distillation, pruning, quantization, neural architecture\nsearch and lightweight network design at the algorithmic level. We further\nreview hardware-level optimization techniques and the design of novel hardware\naccelerators for transformers. We summarize the quantitative results on the\nnumber of parameters/FLOPs and accuracy of several models/techniques to\nshowcase the tradeoff exercised by them. We also outline future directions in\nthis rapidly evolving field of research. We believe that this survey will\neducate both novice and seasoned researchers and also spark a plethora of\nresearch efforts in this field."
  },
  {
    "arxiv_id": "2307.07699",
    "title": "Leveraging Large Language Models to Generate Answer Set Programs",
    "url": "http://arxiv.org/abs/2307.07699v1",
    "abstract": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated\nexceptional performance in various natural language processing tasks and have\nshown the ability to solve certain reasoning problems. However, their reasoning\ncapabilities are limited and relatively shallow, despite the application of\nvarious prompting techniques. In contrast, formal logic is adept at handling\ncomplex reasoning, but translating natural language descriptions into formal\nlogic is a challenging task that non-experts struggle with. This paper proposes\na neuro-symbolic method that combines the strengths of large language models\nand answer set programming. Specifically, we employ an LLM to transform natural\nlanguage descriptions of logic puzzles into answer set programs. We carefully\ndesign prompts for an LLM to convert natural language descriptions into answer\nset programs in a step by step manner. Surprisingly, with just a few in-context\nlearning examples, LLMs can generate reasonably complex answer set programs.\nThe majority of errors made are relatively simple and can be easily corrected\nby humans, thus enabling LLMs to effectively assist in the creation of answer\nset programs."
  },
  {
    "arxiv_id": "2307.09249",
    "title": "UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data",
    "url": "http://arxiv.org/abs/2307.09249v1",
    "abstract": "Recent advancements in NLP have witnessed the groundbreaking impact of\npretrained models, yielding impressive outcomes across various tasks. This\nstudy seeks to extend the power of pretraining methodologies to facilitating\nthe prediction over tables in data science, a domain traditionally overlooked,\nyet inherently challenging due to the plethora of table schemas intrinsic to\ndifferent tasks. The primary research questions underpinning this work revolve\naround the establishment of a universal pretraining protocol for tables with\nvaried structures, the generalizability and transferability of learned\nknowledge across tasks, the adaptation to diverse downstream applications, and\nthe incorporation of incremental columns over time. In response to these\nchallenges, we introduce UniTabE, a straightforward yet effective method\ndesigned to process tables in a uniform manner, devoid of constraints imposed\nby specific table structures. UniTabE's core concept relies on representing\neach basic table element with a module, termed TabUnit. This is subsequently\nfollowed by a Transformer encoder to refine the representation. Moreover, our\nmodel is designed to facilitate pretraining and finetuning through the\nutilization of free-form prompts. In order to implement the pretraining phase,\nwe curated an expansive tabular dataset comprising approximately 13B samples,\nmeticulously gathered from the Kaggle platform. This research primarily centers\non classification and regression tasks involving tabular data, and conducts\nrigorous experimental testing and analyses to validate the effectiveness of our\nmethodology. The experimental results demonstrate UniTabE's superior\nperformance against several baselines across massive benchmarks. This,\ntherefore, underscores UniTabE's potential to significantly enhance the\nsemantic representation of tabular data, thereby marking a significant stride\nfor tabular data analysis."
  },
  {
    "arxiv_id": "2307.09162",
    "title": "Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications",
    "url": "http://arxiv.org/abs/2307.09162v1",
    "abstract": "Gender bias in artificial intelligence (AI) and natural language processing\nhas garnered significant attention due to its potential impact on societal\nperceptions and biases. This research paper aims to analyze gender bias in\nLarge Language Models (LLMs) with a focus on multiple comparisons between GPT-2\nand GPT-3.5, some prominent language models, to better understand its\nimplications. Through a comprehensive literature review, the study examines\nexisting research on gender bias in AI language models and identifies gaps in\nthe current knowledge. The methodology involves collecting and preprocessing\ndata from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis\ntechniques to evaluate gender bias in the generated text. The findings shed\nlight on gendered word associations, language usage, and biased narratives\npresent in the outputs of these Large Language Models. The discussion explores\nthe ethical implications of gender bias and its potential consequences on\nsocial perceptions and marginalized communities. Additionally, the paper\npresents strategies for reducing gender bias in LLMs, including algorithmic\napproaches and data augmentation techniques. The research highlights the\nimportance of interdisciplinary collaborations and the role of sociological\nstudies in mitigating gender bias in AI models. By addressing these issues, we\ncan pave the way for more inclusive and unbiased AI systems that have a\npositive impact on society."
  },
  {
    "arxiv_id": "2307.09050",
    "title": "R-Cut: Enhancing Explainability in Vision Transformers with Relationship Weighted Out and Cut",
    "url": "http://arxiv.org/abs/2307.09050v1",
    "abstract": "Transformer-based models have gained popularity in the field of natural\nlanguage processing (NLP) and are extensively utilized in computer vision tasks\nand multi-modal models such as GPT4. This paper presents a novel method to\nenhance the explainability of Transformer-based image classification models.\nOur method aims to improve trust in classification results and empower users to\ngain a deeper understanding of the model for downstream tasks by providing\nvisualizations of class-specific maps. We introduce two modules: the\n``Relationship Weighted Out\" and the ``Cut\" modules. The ``Relationship\nWeighted Out\" module focuses on extracting class-specific information from\nintermediate layers, enabling us to highlight relevant features. Additionally,\nthe ``Cut\" module performs fine-grained feature decomposition, taking into\naccount factors such as position, texture, and color. By integrating these\nmodules, we generate dense class-specific visual explainability maps. We\nvalidate our method with extensive qualitative and quantitative experiments on\nthe ImageNet dataset. Furthermore, we conduct a large number of experiments on\nthe LRN dataset, specifically designed for automatic driving danger alerts, to\nevaluate the explainability of our method in complex backgrounds. The results\ndemonstrate a significant improvement over previous methods. Moreover, we\nconduct ablation experiments to validate the effectiveness of each module.\nThrough these experiments, we are able to confirm the respective contributions\nof each module, thus solidifying the overall effectiveness of our proposed\napproach."
  },
  {
    "arxiv_id": "2307.09007",
    "title": "On the (In)Effectiveness of Large Language Models for Chinese Text Correction",
    "url": "http://arxiv.org/abs/2307.09007v1",
    "abstract": "Recently, the development and progress of Large Language Models (LLMs) have\namazed the entire Artificial Intelligence community. Benefiting from their\nemergent abilities, LLMs have attracted more and more researchers to study\ntheir capabilities and performance on various downstream Natural Language\nProcessing (NLP) tasks. While marveling at LLMs' incredible performance on all\nkinds of tasks, we notice that they also have excellent multilingual processing\ncapabilities, such as Chinese. To explore the Chinese processing ability of\nLLMs, we focus on Chinese Text Correction, a fundamental and challenging\nChinese NLP task. Specifically, we evaluate various representative LLMs on the\nChinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC)\ntasks, which are two main Chinese Text Correction scenarios. Additionally, we\nalso fine-tune LLMs for Chinese Text Correction to better observe the potential\ncapabilities of LLMs. From extensive analyses and comparisons with previous\nstate-of-the-art small models, we empirically find that the LLMs currently have\nboth amazing performance and unsatisfactory behavior for Chinese Text\nCorrection. We believe our findings will promote the landing and application of\nLLMs in the Chinese NLP community."
  },
  {
    "arxiv_id": "2307.08941",
    "title": "NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning",
    "url": "http://arxiv.org/abs/2307.08941v1",
    "abstract": "Fine-tuning a pre-trained language model (PLM) emerges as the predominant\nstrategy in many natural language processing applications. However, this\nprocess is known to be expensive, especially on edge devices with low computing\npower. While general approaches (e.g. quantization and distillation) have been\nwidely studied to reduce the compute/memory of PLM fine-tuning, one-shot\ncompression techniques specifically designed for fine-tuning remain largely\nunexplored. In this paper, we investigate the neural tangent kernel\n(NTK)--which reveals the gradient descent dynamics of neural networks--of the\nmultilayer perceptrons (MLP) modules in a PLM and propose to coin a lightweight\nPLM through NTK-approximating MLP fusion. By incorporating NTK into the\ncompression process, MLP Fusion not only preserves the original model's output\nbut also maintains its training dynamics. To achieve this, we reconsider the\nMLP as a bundle of sub-MLPs and cluster them into a given number of centroids,\nwhich can then be restored as a compressed MLP and surprisingly well\napproximate the NTK of the original PLM. Our approach is applicable to both\nstandard MLP modules and Mixture-of-Experts (MoE) modules in PLMs,\ndemonstrating its scalability and versatility. Additionally, we provide\ntheoretical derivations to demonstrate how the proposed compression preserves\nthe NTK. Extensive experiments of PLM fine-tuning on both natural language\nunderstanding and generation tasks are provided to verify the effectiveness of\nMLP fusion. Our code is available at https://github.com/weitianxin/MLP_Fusion."
  },
  {
    "arxiv_id": "2307.09923",
    "title": "Large Language Models can accomplish Business Process Management Tasks",
    "url": "http://arxiv.org/abs/2307.09923v1",
    "abstract": "Business Process Management (BPM) aims to improve organizational activities\nand their outcomes by managing the underlying processes. To achieve this, it is\noften necessary to consider information from various sources, including\nunstructured textual documents. Therefore, researchers have developed several\nBPM-specific solutions that extract information from textual documents using\nNatural Language Processing techniques. These solutions are specific to their\nrespective tasks and cannot accomplish multiple process-related problems as a\ngeneral-purpose instrument. However, in light of the recent emergence of Large\nLanguage Models (LLMs) with remarkable reasoning capabilities, such a\ngeneral-purpose instrument with multiple applications now appears attainable.\nIn this paper, we illustrate how LLMs can accomplish text-related BPM tasks by\napplying a specific LLM to three exemplary tasks: mining imperative process\nmodels from textual descriptions, mining declarative process models from\ntextual descriptions, and assessing the suitability of process tasks from\ntextual descriptions for robotic process automation. We show that, without\nextensive configuration or prompt engineering, LLMs perform comparably to or\nbetter than existing solutions and discuss implications for future BPM research\nas well as practical usage."
  },
  {
    "arxiv_id": "2307.09909",
    "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
    "url": "http://arxiv.org/abs/2307.09909v1",
    "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets."
  },
  {
    "arxiv_id": "2307.09744",
    "title": "Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction",
    "url": "http://arxiv.org/abs/2307.09744v1",
    "abstract": "The integration of natural language processing (NLP) technologies into\neducational applications has shown promising results, particularly in the\nlanguage learning domain. Recently, many spoken open-domain chatbots have been\nused as speaking partners, helping language learners improve their language\nskills. However, one of the significant challenges is the high word-error-rate\n(WER) when recognizing non-native/non-fluent speech, which interrupts\nconversation flow and leads to disappointment for learners. This paper explores\nthe use of GPT4 for ASR error correction in conversational settings. In\naddition to WER, we propose to use semantic textual similarity (STS) and next\nresponse sensibility (NRS) metrics to evaluate the impact of error correction\nmodels on the quality of the conversation. We find that transcriptions\ncorrected by GPT4 lead to higher conversation quality, despite an increase in\nWER. GPT4 also outperforms standard error correction methods without the need\nfor in-domain training data."
  },
  {
    "arxiv_id": "2307.09723",
    "title": "Improving Domain Generalization for Sound Classification with Sparse Frequency-Regularized Transformer",
    "url": "http://arxiv.org/abs/2307.09723v1",
    "abstract": "Sound classification models' performance suffers from generalizing on\nout-of-distribution (OOD) data. Numerous methods have been proposed to help the\nmodel generalize. However, most either introduce inference overheads or focus\non long-lasting CNN-variants, while Transformers has been proven to outperform\nCNNs on numerous natural language processing and computer vision tasks. We\npropose FRITO, an effective regularization technique on Transformer's\nself-attention, to improve the model's generalization ability by limiting each\nsequence position's attention receptive field along the frequency dimension on\nthe spectrogram. Experiments show that our method helps Transformer models\nachieve SOTA generalization performance on TAU 2020 and Nsynth datasets while\nsaving 20% inference time."
  },
  {
    "arxiv_id": "2307.09532",
    "title": "Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study",
    "url": "http://arxiv.org/abs/2307.09532v1",
    "abstract": "Text classification is an area of research which has been studied over the\nyears in Natural Language Processing (NLP). Adapting NLP to multiple domains\nhas introduced many new challenges for text classification and one of them is\nlong document classification. While state-of-the-art transformer models provide\nexcellent results in text classification, most of them have limitations in the\nmaximum sequence length of the input sequence. The majority of the transformer\nmodels are limited to 512 tokens, and therefore, they struggle with long\ndocument classification problems. In this research, we explore on employing\nModel Fusing for long document classification while comparing the results with\nwell-known BERT and Longformer architectures."
  },
  {
    "arxiv_id": "2307.10778",
    "title": "Extreme Multi-Label Skill Extraction Training using Large Language Models",
    "url": "http://arxiv.org/abs/2307.10778v1",
    "abstract": "Online job ads serve as a valuable source of information for skill\nrequirements, playing a crucial role in labor market analysis and e-recruitment\nprocesses. Since such ads are typically formatted in free text, natural\nlanguage processing (NLP) technologies are required to automatically process\nthem. We specifically focus on the task of detecting skills (mentioned\nliterally, or implicitly described) and linking them to a large skill ontology,\nmaking it a challenging case of extreme multi-label classification (XMLC).\nGiven that there is no sizable labeled (training) dataset are available for\nthis specific XMLC task, we propose techniques to leverage general Large\nLanguage Models (LLMs). We describe a cost-effective approach to generate an\naccurate, fully synthetic labeled dataset for skill extraction, and present a\ncontrastive learning strategy that proves effective in the task. Our results\nacross three skill extraction benchmarks show a consistent increase of between\n15 to 25 percentage points in \\textit{R-Precision@5} compared to previously\npublished results that relied solely on distant supervision through literal\nmatches."
  },
  {
    "arxiv_id": "2307.10558",
    "title": "Instruction-following Evaluation through Verbalizer Manipulation",
    "url": "http://arxiv.org/abs/2307.10558v1",
    "abstract": "While instruction-tuned models have shown remarkable success in various\nnatural language processing tasks, accurately evaluating their ability to\nfollow instructions remains challenging. Existing benchmarks primarily focus on\ncommon instructions that align well with what the model learned during\ntraining. However, proficiency in responding to these instructions does not\nnecessarily imply strong ability in instruction following. In this paper, we\npropose a novel instruction-following evaluation protocol called verbalizer\nmanipulation. It instructs the model to verbalize the task label with words\naligning with model priors to different extents, adopting verbalizers from\nhighly aligned (e.g., outputting ``postive'' for positive sentiment), to\nminimally aligned (e.g., outputting ``negative'' for positive sentiment).\nVerbalizer manipulation can be seamlessly integrated with any classification\nbenchmark to examine the model's reliance on priors and its ability to override\nthem to accurately follow the instructions. We conduct a comprehensive\nevaluation of four major model families across nine datasets, employing twelve\nsets of verbalizers for each of them. We observe that the instruction-following\nabilities of models, across different families and scales, are significantly\ndistinguished by their performance on less natural verbalizers. Even the\nstrongest GPT-4 model struggles to perform better than random guessing on the\nmost challenging verbalizer, emphasizing the need for continued advancements to\nimprove their instruction-following abilities."
  },
  {
    "arxiv_id": "2307.11550",
    "title": "YOLOPose V2: Understanding and Improving Transformer-based 6D Pose Estimation",
    "url": "http://arxiv.org/abs/2307.11550v1",
    "abstract": "6D object pose estimation is a crucial prerequisite for autonomous robot\nmanipulation applications. The state-of-the-art models for pose estimation are\nconvolutional neural network (CNN)-based. Lately, Transformers, an architecture\noriginally proposed for natural language processing, is achieving\nstate-of-the-art results in many computer vision tasks as well. Equipped with\nthe multi-head self-attention mechanism, Transformers enable simple\nsingle-stage end-to-end architectures for learning object detection and 6D\nobject pose estimation jointly. In this work, we propose YOLOPose (short form\nfor You Only Look Once Pose estimation), a Transformer-based multi-object 6D\npose estimation method based on keypoint regression and an improved variant of\nthe YOLOPose model. In contrast to the standard heatmaps for predicting\nkeypoints in an image, we directly regress the keypoints. Additionally, we\nemploy a learnable orientation estimation module to predict the orientation\nfrom the keypoints. Along with a separate translation estimation module, our\nmodel is end-to-end differentiable. Our method is suitable for real-time\napplications and achieves results comparable to state-of-the-art methods. We\nanalyze the role of object queries in our architecture and reveal that the\nobject queries specialize in detecting objects in specific image regions.\nFurthermore, we quantify the accuracy trade-off of using datasets of smaller\nsizes to train our model."
  },
  {
    "arxiv_id": "2307.12980",
    "title": "A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models",
    "url": "http://arxiv.org/abs/2307.12980v1",
    "abstract": "Prompt engineering is a technique that involves augmenting a large\npre-trained model with task-specific hints, known as prompts, to adapt the\nmodel to new tasks. Prompts can be created manually as natural language\ninstructions or generated automatically as either natural language instructions\nor vector representations. Prompt engineering enables the ability to perform\npredictions based solely on prompts without updating model parameters, and the\neasier application of large pre-trained models in real-world tasks. In past\nyears, Prompt engineering has been well-studied in natural language processing.\nRecently, it has also been intensively studied in vision-language modeling.\nHowever, there is currently a lack of a systematic overview of prompt\nengineering on pre-trained vision-language models. This paper aims to provide a\ncomprehensive survey of cutting-edge research in prompt engineering on three\ntypes of vision-language models: multimodal-to-text generation models (e.g.\nFlamingo), image-text matching models (e.g. CLIP), and text-to-image generation\nmodels (e.g. Stable Diffusion). For each type of model, a brief model summary,\nprompting methods, prompting-based applications, and the corresponding\nresponsibility and integrity issues are summarized and discussed. Furthermore,\nthe commonalities and differences between prompting on vision-language models,\nlanguage models, and vision models are also discussed. The challenges, future\ndirections, and research opportunities are summarized to foster future research\non this topic."
  },
  {
    "arxiv_id": "2307.12966",
    "title": "Aligning Large Language Models with Human: A Survey",
    "url": "http://arxiv.org/abs/2307.12966v1",
    "abstract": "Large Language Models (LLMs) trained on extensive textual corpora have\nemerged as leading solutions for a broad array of Natural Language Processing\n(NLP) tasks. Despite their notable performance, these models are prone to\ncertain limitations such as misunderstanding human instructions, generating\npotentially biased content, or factually incorrect (hallucinated) information.\nHence, aligning LLMs with human expectations has become an active area of\ninterest within the research community. This survey presents a comprehensive\noverview of these alignment technologies, including the following aspects. (1)\nData collection: the methods for effectively collecting high-quality\ninstructions for LLM alignment, including the use of NLP benchmarks, human\nannotations, and leveraging strong LLMs. (2) Training methodologies: a detailed\nreview of the prevailing training methods employed for LLM alignment. Our\nexploration encompasses Supervised Fine-tuning, both Online and Offline human\npreference training, along with parameter-efficient training mechanisms. (3)\nModel Evaluation: the methods for evaluating the effectiveness of these\nhuman-aligned LLMs, presenting a multifaceted approach towards their\nassessment. In conclusion, we collate and distill our findings, shedding light\non several promising future research avenues in the field. This survey,\ntherefore, serves as a valuable resource for anyone invested in understanding\nand advancing the alignment of LLMs to better suit human-oriented tasks and\nexpectations. An associated GitHub link collecting the latest papers is\navailable at https://github.com/GaryYufei/AlignLLMHumanSurvey."
  },
  {
    "arxiv_id": "2307.12745",
    "title": "Concept-based explainability for an EEG transformer model",
    "url": "http://arxiv.org/abs/2307.12745v1",
    "abstract": "Deep learning models are complex due to their size, structure, and inherent\nrandomness in training procedures. Additional complexity arises from the\nselection of datasets and inductive biases. Addressing these challenges for\nexplainability, Kim et al. (2018) introduced Concept Activation Vectors (CAVs),\nwhich aim to understand deep models' internal states in terms of human-aligned\nconcepts. These concepts correspond to directions in latent space, identified\nusing linear discriminants. Although this method was first applied to image\nclassification, it was later adapted to other domains, including natural\nlanguage processing. In this work, we attempt to apply the method to\nelectroencephalogram (EEG) data for explainability in Kostas et al.'s BENDR\n(2021), a large-scale transformer model. A crucial part of this endeavor\ninvolves defining the explanatory concepts and selecting relevant datasets to\nground concepts in the latent space. Our focus is on two mechanisms for EEG\nconcept formation: the use of externally labeled EEG datasets, and the\napplication of anatomically defined concepts. The former approach is a\nstraightforward generalization of methods used in image classification, while\nthe latter is novel and specific to EEG. We present evidence that both\napproaches to concept formation yield valuable insights into the\nrepresentations learned by deep EEG models."
  },
  {
    "arxiv_id": "2307.12266",
    "title": "Transformer-based Joint Source Channel Coding for Textual Semantic Communication",
    "url": "http://arxiv.org/abs/2307.12266v1",
    "abstract": "The Space-Air-Ground-Sea integrated network calls for more robust and secure\ntransmission techniques against jamming. In this paper, we propose a textual\nsemantic transmission framework for robust transmission, which utilizes the\nadvanced natural language processing techniques to model and encode sentences.\nSpecifically, the textual sentences are firstly split into tokens using\nwordpiece algorithm, and are embedded to token vectors for semantic extraction\nby Transformer-based encoder. The encoded data are quantized to a fixed length\nbinary sequence for transmission, where binary erasure, symmetric, and deletion\nchannels are considered for transmission. The received binary sequences are\nfurther decoded by the transformer decoders into tokens used for sentence\nreconstruction. Our proposed approach leverages the power of neural networks\nand attention mechanism to provide reliable and efficient communication of\ntextual data in challenging wireless environments, and simulation results on\nsemantic similarity and bilingual evaluation understudy prove the superiority\nof the proposed model in semantic transmission."
  },
  {
    "arxiv_id": "2307.12114",
    "title": "A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks",
    "url": "http://arxiv.org/abs/2307.12114v1",
    "abstract": "We evaluate four state-of-the-art instruction-tuned large language models\n(LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13\nreal-world clinical and biomedical natural language processing (NLP) tasks in\nEnglish, such as named-entity recognition (NER), question-answering (QA),\nrelation extraction (RE), etc. Our overall results demonstrate that the\nevaluated LLMs begin to approach performance of state-of-the-art models in\nzero- and few-shot scenarios for most tasks, and particularly well for the QA\ntask, even though they have never seen examples from these tasks before.\nHowever, we observed that the classification and RE tasks perform below what\ncan be achieved with a specifically trained model for the medical field, such\nas PubMedBERT. Finally, we noted that no LLM outperforms all the others on all\nthe studied tasks, with some models being better suited for certain tasks than\nothers."
  },
  {
    "arxiv_id": "2307.11988",
    "title": "Sparse then Prune: Toward Efficient Vision Transformers",
    "url": "http://arxiv.org/abs/2307.11988v1",
    "abstract": "The Vision Transformer architecture is a deep learning model inspired by the\nsuccess of the Transformer model in Natural Language Processing. However, the\nself-attention mechanism, large number of parameters, and the requirement for a\nsubstantial amount of training data still make Vision Transformers\ncomputationally burdensome. In this research, we investigate the possibility of\napplying Sparse Regularization to Vision Transformers and the impact of\nPruning, either after Sparse Regularization or without it, on the trade-off\nbetween performance and efficiency. To accomplish this, we apply Sparse\nRegularization and Pruning methods to the Vision Transformer architecture for\nimage classification tasks on the CIFAR-10, CIFAR-100, and ImageNet-100\ndatasets. The training process for the Vision Transformer model consists of two\nparts: pre-training and fine-tuning. Pre-training utilizes ImageNet21K data,\nfollowed by fine-tuning for 20 epochs. The results show that when testing with\nCIFAR-100 and ImageNet-100 data, models with Sparse Regularization can increase\naccuracy by 0.12%. Furthermore, applying pruning to models with Sparse\nRegularization yields even better results. Specifically, it increases the\naverage accuracy by 0.568% on CIFAR-10 data, 1.764% on CIFAR-100, and 0.256% on\nImageNet-100 data compared to pruning models without Sparse Regularization.\nCode can be accesed here: https://github.com/yogiprsty/Sparse-ViT"
  },
  {
    "arxiv_id": "2307.13693",
    "title": "Evaluating Large Language Models for Radiology Natural Language Processing",
    "url": "http://arxiv.org/abs/2307.13693v1",
    "abstract": "The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain."
  },
  {
    "arxiv_id": "2307.13221",
    "title": "Multilevel Large Language Models for Everyone",
    "url": "http://arxiv.org/abs/2307.13221v1",
    "abstract": "Large language models have made significant progress in the past few years.\nHowever, they are either generic {\\it or} field specific, splitting the\ncommunity into different groups. In this paper, we unify these large language\nmodels into a larger map, where the generic {\\it and} specific models are\nlinked together and can improve each other, based on the user personal input\nand information from the internet. The idea of linking several large language\nmodels together is inspired by the functionality of human brain. The specific\nregions on the brain cortex are specific for certain low level functionality.\nAnd these regions can jointly work together to achieve more complex high level\nfunctionality. Such behavior on human brain cortex sheds the light to design\nthe multilevel large language models that contain global level, field level and\nuser level models. The user level models run on local machines to achieve\nefficient response and protect the user's privacy. Such multilevel models\nreduce some redundancy and perform better than the single level models. The\nproposed multilevel idea can be applied in various applications, such as\nnatural language processing, computer vision tasks, professional assistant,\nbusiness and healthcare."
  },
  {
    "arxiv_id": "2307.13085",
    "title": "Making Metadata More FAIR Using Large Language Models",
    "url": "http://arxiv.org/abs/2307.13085v1",
    "abstract": "With the global increase in experimental data artifacts, harnessing them in a\nunified fashion leads to a major stumbling block - bad metadata. To bridge this\ngap, this work presents a Natural Language Processing (NLP) informed\napplication, called FAIRMetaText, that compares metadata. Specifically,\nFAIRMetaText analyzes the natural language descriptions of metadata and\nprovides a mathematical similarity measure between two terms. This measure can\nthen be utilized for analyzing varied metadata, by suggesting terms for\ncompliance or grouping similar terms for identification of replaceable terms.\nThe efficacy of the algorithm is presented qualitatively and quantitatively on\npublicly available research artifacts and demonstrates large gains across\nmetadata related tasks through an in-depth study of a wide variety of Large\nLanguage Models (LLMs). This software can drastically reduce the human effort\nin sifting through various natural language metadata while employing several\nexperimental datasets on the same topic."
  },
  {
    "arxiv_id": "2307.14107",
    "title": "Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions",
    "url": "http://arxiv.org/abs/2307.14107v1",
    "abstract": "Chat Generative Pre-trained Transformer (ChatGPT) has gained significant\ninterest and attention since its launch in November 2022. It has shown\nimpressive performance in various domains, including passing exams and creative\nwriting. However, challenges and concerns related to biases and trust persist.\nIn this work, we present a comprehensive review of over 100 Scopus-indexed\npublications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and\nexplore its applications. We critically analyze the existing literature,\nidentifying common approaches employed in the studies. Additionally, we\ninvestigate diverse application areas where ChatGPT has found utility, such as\nhealthcare, marketing and financial services, software engineering, academic\nand scientific writing, research and education, environmental science, and\nnatural language processing. Through examining these applications, we gain\nvaluable insights into the potential of ChatGPT in addressing real-world\nchallenges. We also discuss crucial issues related to ChatGPT, including biases\nand trustworthiness, emphasizing the need for further research and development\nin these areas. Furthermore, we identify potential future directions for\nChatGPT research, proposing solutions to current challenges and speculating on\nexpected advancements. By fully leveraging the capabilities of ChatGPT, we can\nunlock its potential across various domains, leading to advancements in\nconversational AI and transformative impacts in society."
  },
  {
    "arxiv_id": "2307.14666",
    "title": "Improving Natural Language Inference in Arabic using Transformer Models and Linguistically Informed Pre-Training",
    "url": "http://arxiv.org/abs/2307.14666v1",
    "abstract": "This paper addresses the classification of Arabic text data in the field of\nNatural Language Processing (NLP), with a particular focus on Natural Language\nInference (NLI) and Contradiction Detection (CD). Arabic is considered a\nresource-poor language, meaning that there are few data sets available, which\nleads to limited availability of NLP methods. To overcome this limitation, we\ncreate a dedicated data set from publicly available resources. Subsequently,\ntransformer-based machine learning models are being trained and evaluated. We\nfind that a language-specific model (AraBERT) performs competitively with\nstate-of-the-art multilingual approaches, when we apply linguistically informed\npre-training methods such as Named Entity Recognition (NER). To our knowledge,\nthis is the first large-scale evaluation for this task in Arabic, as well as\nthe first application of multi-task pre-training in this context."
  },
  {
    "arxiv_id": "2307.14587",
    "title": "Artificial intelligence-aided protein engineering: from topological data analysis to deep protein language models",
    "url": "http://arxiv.org/abs/2307.14587v1",
    "abstract": "Protein engineering is an emerging field in biotechnology that has the\npotential to revolutionize various areas, such as antibody design, drug\ndiscovery, food security, ecology, and more. However, the mutational space\ninvolved is too vast to be handled through experimental means alone. Leveraging\naccumulative protein databases, machine learning (ML) models, particularly\nthose based on natural language processing (NLP), have considerably expedited\nprotein engineering. Moreover, advances in topological data analysis (TDA) and\nartificial intelligence-based protein structure prediction, such as AlphaFold2,\nhave made more powerful structure-based ML-assisted protein engineering\nstrategies possible. This review aims to offer a comprehensive, systematic, and\nindispensable set of methodological components, including TDA and NLP, for\nprotein engineering and to facilitate their future development."
  },
  {
    "arxiv_id": "2307.15335",
    "title": "BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering",
    "url": "http://arxiv.org/abs/2307.15335v1",
    "abstract": "Visual Question Answering (VQA) is an intricate and demanding task that\nintegrates natural language processing (NLP) and computer vision (CV),\ncapturing the interest of researchers. The English language, renowned for its\nwealth of resources, has witnessed notable advancements in both datasets and\nmodels designed for VQA. However, there is a lack of models that target\nspecific countries such as Vietnam. To address this limitation, we introduce a\ntransformer-based Vietnamese model named BARTPhoBEiT. This model includes\npre-trained Sequence-to-Sequence and bidirectional encoder representation from\nImage Transformers in Vietnamese and evaluates Vietnamese VQA datasets.\nExperimental results demonstrate that our proposed model outperforms the strong\nbaseline and improves the state-of-the-art in six metrics: Accuracy, Precision,\nRecall, F1-score, WUPS 0.0, and WUPS 0.9."
  },
  {
    "arxiv_id": "2307.15311",
    "title": "TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety",
    "url": "http://arxiv.org/abs/2307.15311v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable effectiveness in various\ngeneral-domain natural language processing (NLP) tasks. However, their\nperformance in transportation safety domain tasks has been suboptimal,\nprimarily attributed to the requirement for specialized transportation safety\nexpertise in generating accurate responses [1]. To address this challenge, we\nintroduce TrafficSafetyGPT, a novel LLAMA-based model, which has undergone\nsupervised fine-tuning using TrafficSafety-2K dataset which has human labels\nfrom government produced guiding books and ChatGPT-generated instruction-output\npairs. Our proposed TrafficSafetyGPT model and TrafficSafety-2K train dataset\nare accessible at https://github.com/ozheng1993/TrafficSafetyGPT."
  },
  {
    "arxiv_id": "2307.16648",
    "title": "LLMs4OL: Large Language Models for Ontology Learning",
    "url": "http://arxiv.org/abs/2307.16648v2",
    "abstract": "We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)\nfor Ontology Learning (OL). LLMs have shown significant advancements in natural\nlanguage processing, demonstrating their ability to capture complex language\npatterns in different knowledge domains. Our LLMs4OL paradigm investigates the\nfollowing hypothesis: \\textit{Can LLMs effectively apply their language pattern\ncapturing capability to OL, which involves automatically extracting and\nstructuring knowledge from natural language text?} To test this hypothesis, we\nconduct a comprehensive evaluation using the zero-shot prompting method. We\nevaluate nine different LLM model families for three main OL tasks: term\ntyping, taxonomy discovery, and extraction of non-taxonomic relations.\nAdditionally, the evaluations encompass diverse genres of ontological\nknowledge, including lexicosemantic knowledge in WordNet, geographical\nknowledge in GeoNames, and medical knowledge in UMLS."
  },
  {
    "arxiv_id": "2307.16456",
    "title": "Camoscio: an Italian Instruction-tuned LLaMA",
    "url": "http://arxiv.org/abs/2307.16456v1",
    "abstract": "In recent years Large Language Models (LLMs) have increased the state of the\nart on several natural language processing tasks. However, their accessibility\nis often limited to paid API services, posing challenges for researchers in\nconducting extensive investigations. On the other hand, while some open-source\nmodels have been proposed by the community, they are typically English-centric\nor multilingual without a specific adaptation for the Italian language. In an\neffort to democratize the available and open resources for the Italian\nlanguage, in this paper we introduce Camoscio: a language model specifically\ntuned to follow users' prompts in Italian. Specifically, we finetuned the\nsmallest variant of LLaMA (7b) with LoRA on a corpus of instruction prompts\ntranslated to Italian via ChatGPT. Results indicate that the model's zero-shot\nperformance on various downstream tasks in Italian competes favorably with\nexisting models specifically finetuned for those tasks. All the artifacts\n(code, dataset, model) are released to the community at the following url:\nhttps://github.com/teelinsan/camoscio"
  },
  {
    "arxiv_id": "2307.16372",
    "title": "LP-MusicCaps: LLM-Based Pseudo Music Captioning",
    "url": "http://arxiv.org/abs/2307.16372v1",
    "abstract": "Automatic music captioning, which generates natural language descriptions for\ngiven music tracks, holds significant potential for enhancing the understanding\nand organization of large volumes of musical data. Despite its importance,\nresearchers face challenges due to the costly and time-consuming collection\nprocess of existing music-language datasets, which are limited in size. To\naddress this data scarcity issue, we propose the use of large language models\n(LLMs) to artificially generate the description sentences from large-scale tag\ndatasets. This results in approximately 2.2M captions paired with 0.5M audio\nclips. We term it Large Language Model based Pseudo music caption dataset,\nshortly, LP-MusicCaps. We conduct a systemic evaluation of the large-scale\nmusic captioning dataset with various quantitative evaluation metrics used in\nthe field of natural language processing as well as human evaluation. In\naddition, we trained a transformer-based music captioning model with the\ndataset and evaluated it under zero-shot and transfer-learning settings. The\nresults demonstrate that our proposed approach outperforms the supervised\nbaseline model."
  },
  {
    "arxiv_id": "2308.00255",
    "title": "LGViT: Dynamic Early Exiting for Accelerating Vision Transformer",
    "url": "http://arxiv.org/abs/2308.00255v1",
    "abstract": "Recently, the efficient deployment and acceleration of powerful vision\ntransformers (ViTs) on resource-limited edge devices for providing multimedia\nservices have become attractive tasks. Although early exiting is a feasible\nsolution for accelerating inference, most works focus on convolutional neural\nnetworks (CNNs) and transformer models in natural language processing\n(NLP).Moreover, the direct application of early exiting methods to ViTs may\nresult in substantial performance degradation. To tackle this challenge, we\nsystematically investigate the efficacy of early exiting in ViTs and point out\nthat the insufficient feature representations in shallow internal classifiers\nand the limited ability to capture target semantic information in deep internal\nclassifiers restrict the performance of these methods. We then propose an early\nexiting framework for general ViTs termed LGViT, which incorporates\nheterogeneous exiting heads, namely, local perception head and global\naggregation head, to achieve an efficiency-accuracy trade-off. In particular,\nwe develop a novel two-stage training scheme, including end-to-end training and\nself-distillation with the backbone frozen to generate early exiting ViTs,\nwhich facilitates the fusion of global and local information extracted by the\ntwo types of heads. We conduct extensive experiments using three popular ViT\nbackbones on three vision datasets. Results demonstrate that our LGViT can\nachieve competitive performance with approximately 1.8 $\\times$ speed-up."
  },
  {
    "arxiv_id": "2308.01776",
    "title": "Does Correction Remain An Problem For Large Language Models?",
    "url": "http://arxiv.org/abs/2308.01776v1",
    "abstract": "As large language models, such as GPT, continue to advance the capabilities\nof natural language processing (NLP), the question arises: does the problem of\ncorrection still persist? This paper investigates the role of correction in the\ncontext of large language models by conducting two experiments. The first\nexperiment focuses on correction as a standalone task, employing few-shot\nlearning techniques with GPT-like models for error correction. The second\nexperiment explores the notion of correction as a preparatory task for other\nNLP tasks, examining whether large language models can tolerate and perform\nadequately on texts containing certain levels of noise or errors. By addressing\nthese experiments, we aim to shed light on the significance of correction in\nthe era of large language models and its implications for various NLP\napplications."
  },
  {
    "arxiv_id": "2308.01497",
    "title": "Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors",
    "url": "http://arxiv.org/abs/2308.01497v1",
    "abstract": "Recent advances in the performance of large language models (LLMs) have\nsparked debate over whether, given sufficient training, high-level human\nabilities emerge in such generic forms of artificial intelligence (AI). Despite\nthe exceptional performance of LLMs on a wide range of tasks involving natural\nlanguage processing and reasoning, there has been sharp disagreement as to\nwhether their abilities extend to more creative human abilities. A core example\nis the ability to interpret novel metaphors. Given the enormous and non curated\ntext corpora used to train LLMs, a serious obstacle to designing tests is the\nrequirement of finding novel yet high quality metaphors that are unlikely to\nhave been included in the training data. Here we assessed the ability of GPT4,\na state of the art large language model, to provide natural-language\ninterpretations of novel literary metaphors drawn from Serbian poetry and\ntranslated into English. Despite exhibiting no signs of having been exposed to\nthese metaphors previously, the AI system consistently produced detailed and\nincisive interpretations. Human judges, blind to the fact that an AI model was\ninvolved, rated metaphor interpretations generated by GPT4 as superior to those\nprovided by a group of college students. In interpreting reversed metaphors,\nGPT4, as well as humans, exhibited signs of sensitivity to the Gricean\ncooperative principle. In addition, for several novel English poems GPT4\nproduced interpretations that were rated as excellent or good by a human\nliterary critic. These results indicate that LLMs such as GPT4 have acquired an\nemergent ability to interpret complex metaphors, including those embedded in\nnovel poems."
  },
  {
    "arxiv_id": "2308.03429",
    "title": "RCMHA: Relative Convolutional Multi-Head Attention for Natural Language Modelling",
    "url": "http://arxiv.org/abs/2308.03429v1",
    "abstract": "The Attention module finds common usage in language modeling, presenting\ndistinct challenges within the broader scope of Natural Language Processing.\nMulti-Head Attention (MHA) employs an absolute positional encoding, which\nimposes limitations on token length and entails substantial memory consumption\nduring the processing of embedded inputs. The current remedy proposed by\nresearchers involves the utilization of relative positional encoding, similar\nto the approach adopted in Transformer-XL or Relative Multi-Head Attention\n(RMHA), albeit the employed architecture consumes considerable memory\nresources. To address these challenges, this study endeavors to refine MHA,\nleveraging relative positional encoding in conjunction with the Depth-Wise\nConvolutional Layer architecture, which promises heightened accuracy coupled\nwith minimized memory usage. The proposed RCMHA framework entails the\nmodification of two integral components: firstly, the application of the\nDepth-Wise Convolutional Layer to the input embedding, encompassing Query, Key,\nand Value parameters; secondly, the incorporation of Relative Positional\nEncoding into the attention scoring phase, harmoniously integrated with Scaled\nDot-Product Attention. Empirical experiments underscore the advantages of\nRCMHA, wherein it exhibits superior accuracy, boasting a score of 0.572 in\ncomparison to alternative attention modules such as MHA, Multi-DConv-Head\nAttention (MDHA), and RMHA. Concerning memory utilization, RMHA emerges as the\nmost frugal, demonstrating an average consumption of 2.98 GB, surpassing RMHA\nwhich necessitates 3.5 GB."
  },
  {
    "arxiv_id": "2308.03427",
    "title": "TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents",
    "url": "http://arxiv.org/abs/2308.03427v1",
    "abstract": "With recent advancements in natural language processing, Large Language\nModels (LLMs) have emerged as powerful tools for various real-world\napplications. Despite their prowess, the intrinsic generative abilities of LLMs\nmay prove insufficient for handling complex tasks which necessitate a\ncombination of task planning and the usage of external tools. In this paper, we\nfirst propose a structured framework tailored for LLM-based AI Agents and\ndiscuss the crucial capabilities necessary for tackling intricate problems.\nWithin this framework, we design two distinct types of agents (i.e., one-step\nagent and sequential agent) to execute the inference process. Subsequently, we\ninstantiate the framework using various LLMs and evaluate their Task Planning\nand Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings\nand challenges, our goal is to provide a helpful resource for researchers and\npractitioners to leverage the power of LLMs in their AI applications. Our study\nemphasizes the substantial potential of these models, while also identifying\nareas that need more investigation and improvement."
  },
  {
    "arxiv_id": "2308.03235",
    "title": "Analysis of the Evolution of Advanced Transformer-Based Language Models: Experiments on Opinion Mining",
    "url": "http://arxiv.org/abs/2308.03235v1",
    "abstract": "Opinion mining, also known as sentiment analysis, is a subfield of natural\nlanguage processing (NLP) that focuses on identifying and extracting subjective\ninformation in textual material. This can include determining the overall\nsentiment of a piece of text (e.g., positive or negative), as well as\nidentifying specific emotions or opinions expressed in the text, that involves\nthe use of advanced machine and deep learning techniques. Recently,\ntransformer-based language models make this task of human emotion analysis\nintuitive, thanks to the attention mechanism and parallel computation. These\nadvantages make such models very powerful on linguistic tasks, unlike recurrent\nneural networks that spend a lot of time on sequential processing, making them\nprone to fail when it comes to processing long text. The scope of our paper\naims to study the behaviour of the cutting-edge Transformer-based language\nmodels on opinion mining and provide a high-level comparison between them to\nhighlight their key particularities. Additionally, our comparative study shows\nleads and paves the way for production engineers regarding the approach to\nfocus on and is useful for researchers as it provides guidelines for future\nresearch subjects."
  },
  {
    "arxiv_id": "2308.03212",
    "title": "Average-Hard Attention Transformers are Constant-Depth Uniform Threshold Circuits",
    "url": "http://arxiv.org/abs/2308.03212v1",
    "abstract": "Transformers have emerged as a widely used neural network model for various\nnatural language processing tasks. Previous research explored their\nrelationship with constant-depth threshold circuits, making two assumptions:\naverage-hard attention and logarithmic precision for internal computations\nrelative to input length. Merrill et al. (2022) prove that average-hard\nattention transformers recognize languages that fall within the complexity\nclass TC0, denoting the set of languages that can be recognized by\nconstant-depth polynomial-size threshold circuits. Likewise, Merrill and\nSabharwal (2023) show that log-precision transformers recognize languages\nwithin the class of uniform TC0. This shows that both transformer models can be\nsimulated by constant-depth threshold circuits, with the latter being more\nrobust due to generating a uniform circuit family. Our paper shows that the\nfirst result can be extended to yield uniform circuits as well."
  },
  {
    "arxiv_id": "2308.04109",
    "title": "I-WAS: a Data Augmentation Method with GPT-2 for Simile Detection",
    "url": "http://arxiv.org/abs/2308.04109v1",
    "abstract": "Simile detection is a valuable task for many natural language processing\n(NLP)-based applications, particularly in the field of literature. However,\nexisting research on simile detection often relies on corpora that are limited\nin size and do not adequately represent the full range of simile forms. To\naddress this issue, we propose a simile data augmentation method based on\n\\textbf{W}ord replacement And Sentence completion using the GPT-2 language\nmodel. Our iterative process called I-WAS, is designed to improve the quality\nof the augmented sentences. To better evaluate the performance of our method in\nreal-world applications, we have compiled a corpus containing a more diverse\nset of simile forms for experimentation. Our experimental results demonstrate\nthe effectiveness of our proposed data augmentation method for simile\ndetection."
  },
  {
    "arxiv_id": "2308.03853",
    "title": "Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models",
    "url": "http://arxiv.org/abs/2308.03853v1",
    "abstract": "Both medical care and observational studies in oncology require a thorough\nunderstanding of a patient's disease progression and treatment history, often\nelaborately documented in clinical notes. Despite their vital role, no current\noncology information representation and annotation schema fully encapsulates\nthe diversity of information recorded within these notes. Although large\nlanguage models (LLMs) have recently exhibited impressive performance on\nvarious medical natural language processing tasks, due to the current lack of\ncomprehensively annotated oncology datasets, an extensive evaluation of LLMs in\nextracting and reasoning with the complex rhetoric in oncology notes remains\nunderstudied. We developed a detailed schema for annotating textual oncology\ninformation, encompassing patient characteristics, tumor characteristics,\ntests, treatments, and temporality. Using a corpus of 40 de-identified breast\nand pancreatic cancer progress notes at University of California, San\nFrancisco, we applied this schema to assess the zero-shot abilities of three\nrecent LLMs (GPT-4, GPT-3.5-turbo, and FLAN-UL2) to extract detailed\noncological history from two narrative sections of clinical progress notes. Our\nteam annotated 9028 entities, 9986 modifiers, and 5312 relationships. The GPT-4\nmodel exhibited overall best performance, with an average BLEU score of 0.73,\nan average ROUGE score of 0.72, an exact-match F1-score of 0.51, and an average\naccuracy of 68% on complex tasks (expert manual evaluation on subset). Notably,\nit was proficient in tumor characteristic and medication extraction, and\ndemonstrated superior performance in relational inference like adverse event\ndetection. However, further improvements are needed before using it to reliably\nextract important facts from cancer progress notes needed for clinical\nresearch, complex population management, and documenting quality patient care."
  },
  {
    "arxiv_id": "2308.03825",
    "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",
    "url": "http://arxiv.org/abs/2308.03825v1",
    "abstract": "The misuse of large language models (LLMs) has drawn significant attention\nfrom the general public and LLM vendors. One particular type of adversarial\nprompt, known as jailbreak prompt, has emerged as the main attack vector to\nbypass the safeguards and elicit harmful content from LLMs. In this paper,\nemploying our new framework JailbreakHub, we conduct a comprehensive analysis\nof 1,405 jailbreak prompts spanning from December 2022 to December 2023. We\nidentify 131 jailbreak communities and discover unique characteristics of\njailbreak prompts and their major attack strategies, such as prompt injection\nand privilege escalation. We also observe that jailbreak prompts increasingly\nshift from online Web communities to prompt-aggregation websites and 28 user\naccounts have consistently optimized jailbreak prompts over 100 days. To assess\nthe potential harm caused by jailbreak prompts, we create a question set\ncomprising 107,250 samples across 13 forbidden scenarios. Leveraging this\ndataset, our experiments on six popular LLMs show that their safeguards cannot\nadequately defend jailbreak prompts in all scenarios. Particularly, we identify\nfive highly effective jailbreak prompts that achieve 0.95 attack success rates\non ChatGPT (GPT-3.5) and GPT-4, and the earliest one has persisted online for\nover 240 days. We hope that our study can facilitate the research community and\nLLM vendors in promoting safer and regulated LLMs."
  },
  {
    "arxiv_id": "2308.04898",
    "title": "An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures",
    "url": "http://arxiv.org/abs/2308.04898v1",
    "abstract": "As we increasingly depend on software systems, the consequences of breaches\nin the software supply chain become more severe. High-profile cyber attacks\nlike those on SolarWinds and ShadowHammer have resulted in significant\nfinancial and data losses, underlining the need for stronger cybersecurity. One\nway to prevent future breaches is by studying past failures. However,\ntraditional methods of analyzing these failures require manually reading and\nsummarizing reports about them. Automated support could reduce costs and allow\nanalysis of more failures. Natural Language Processing (NLP) techniques such as\nLarge Language Models (LLMs) could be leveraged to assist the analysis of\nfailures. In this study, we assessed the ability of Large Language Models\n(LLMs) to analyze historical software supply chain breaches. We used LLMs to\nreplicate the manual analysis of 69 software supply chain security failures\nperformed by members of the Cloud Native Computing Foundation (CNCF). We\ndeveloped prompts for LLMs to categorize these by four dimensions: type of\ncompromise, intent, nature, and impact. GPT 3.5s categorizations had an average\naccuracy of 68% and Bard had an accuracy of 58% over these dimensions. We\nreport that LLMs effectively characterize software supply chain failures when\nthe source articles are detailed enough for consensus among manual analysts,\nbut cannot yet replace human analysts. Future work can improve LLM performance\nin this context, and study a broader range of articles and failures."
  },
  {
    "arxiv_id": "2308.04950",
    "title": "Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection",
    "url": "http://arxiv.org/abs/2308.04950v1",
    "abstract": "Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git"
  },
  {
    "arxiv_id": "2308.04838",
    "title": "No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT",
    "url": "http://arxiv.org/abs/2308.04838v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities across\nvarious NLP tasks. Additionally, LLMs are also highly valuable in supporting\nsoftware engineering tasks, particularly in the field of code generation.\nAutomatic code generation is a process of automatically generating source code\nor executable code based on given specifications or requirements, improving\ndeveloper productivity. In this study, we perform a systematic empirical\nassessment to the quality of code generation using ChatGPT. We leverage 728\nalgorithm problems in five languages (i.e., C, C++, Java, Python, and\nJavaScript) and 18 CWEs with 54 code scenarios for the code generation task.\nOur evaluation encompasses a comprehensive analysis of code snippets generated\nby ChatGPT, focusing on three critical aspects: correctness, complexity, and\nsecurity. We also specifically investigate ChatGPT's ability to engage in\nmulti-round fixing process (i.e., ChatGPT's dialog ability) of facilitating\ncode generation. By delving into the generated code and examining the\nexperimental results, this work provides valuable insights into the performance\nof ChatGPT in tackling code generation tasks over the three critical aspects.\nOverall, our findings uncover potential issues and limitations that arise in\nthe ChatGPT-based code generation and lay the groundwork for improving AI and\nLLM-based code generation techniques."
  },
  {
    "arxiv_id": "2308.04739",
    "title": "Optimizing a Transformer-based network for a deep learning seismic processing workflow",
    "url": "http://arxiv.org/abs/2308.04739v1",
    "abstract": "StorSeismic is a recently introduced model based on the Transformer to adapt\nto various seismic processing tasks through its pretraining and fine-tuning\ntraining strategy. In the original implementation, StorSeismic utilized a\nsinusoidal positional encoding and a conventional self-attention mechanism,\nboth borrowed from the natural language processing (NLP) applications. For\nseismic processing they admitted good results, but also hinted to limitations\nin efficiency and expressiveness. We propose modifications to these two key\ncomponents, by utilizing relative positional encoding and low-rank attention\nmatrices as replacements to the vanilla ones. The proposed changes are tested\non processing tasks applied to a realistic Marmousi and offshore field data as\na sequential strategy, starting from denoising, direct arrival removal,\nmultiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$)\nprediction for normal moveout (NMO) correction. We observe faster pretraining\nand competitive results on the fine-tuning tasks and, additionally, fewer\nparameters to train compared to the vanilla model."
  },
  {
    "arxiv_id": "2308.04709",
    "title": "A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology",
    "url": "http://arxiv.org/abs/2308.04709v1",
    "abstract": "In recent years, there have been significant breakthroughs in the field of\nnatural language processing, particularly with the development of large\nlanguage models (LLMs). These LLMs have showcased remarkable capabilities on\nvarious benchmarks. In the healthcare field, the exact role LLMs and other\nfuture AI models will play remains unclear. There is a potential for these\nmodels in the future to be used as part of adaptive physician training, medical\nco-pilot applications, and digital patient interaction scenarios. The ability\nof AI models to participate in medical training and patient care will depend in\npart on their mastery of the knowledge content of specific medical fields. This\nstudy investigated the medical knowledge capability of LLMs, specifically in\nthe context of internal medicine subspecialty multiple-choice test-taking\nability. We compared the performance of several open-source LLMs (Koala 7B,\nFalcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on\nmultiple-choice questions in the field of Nephrology. Nephrology was chosen as\nan example of a particularly conceptually complex subspecialty field within\ninternal medicine. The study was conducted to evaluate the ability of LLM\nmodels to provide correct answers to nephSAP (Nephrology Self-Assessment\nProgram) multiple-choice questions. The overall success of open-sourced LLMs in\nanswering the 858 nephSAP multiple-choice questions correctly was 17.1% -\n25.5%. In contrast, Claude 2 answered 54.4% of the questions correctly, whereas\nGPT-4 achieved a score of 73.3%. We show that current widely used open-sourced\nLLMs do poorly in their ability for zero-shot reasoning when compared to GPT-4\nand Claude 2. The findings of this study potentially have significant\nimplications for the future of subspecialty medical training and patient care."
  },
  {
    "arxiv_id": "2308.05502",
    "title": "Bringing order into the realm of Transformer-based language models for artificial intelligence and law",
    "url": "http://arxiv.org/abs/2308.05502v1",
    "abstract": "Transformer-based language models (TLMs) have widely been recognized to be a\ncutting-edge technology for the successful development of deep-learning-based\nsolutions to problems and applications that require natural language processing\nand understanding. Like for other textual domains, TLMs have indeed pushed the\nstate-of-the-art of AI approaches for many tasks of interest in the legal\ndomain. Despite the first Transformer model being proposed about six years ago,\nthere has been a rapid progress of this technology at an unprecedented rate,\nwhereby BERT and related models represent a major reference, also in the legal\ndomain. This article provides the first systematic overview of TLM-based\nmethods for AI-driven problems and tasks in the legal sphere. A major goal is\nto highlight research advances in this field so as to understand, on the one\nhand, how the Transformers have contributed to the success of AI in supporting\nlegal processes, and on the other hand, what are the current limitations and\nopportunities for further research development."
  },
  {
    "arxiv_id": "2308.05476",
    "title": "Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis",
    "url": "http://arxiv.org/abs/2308.05476v2",
    "abstract": "Deceptive text classification is a critical task in natural language\nprocessing that aims to identify deceptive o fraudulent content. This study\npresents a comparative analysis of machine learning and transformer-based\napproaches for deceptive text classification. We investigate the effectiveness\nof traditional machine learning algorithms and state-of-the-art transformer\nmodels, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive\ntext. A labeled dataset consisting of deceptive and non-deceptive texts is used\nfor training and evaluation purposes. Through extensive experimentation, we\ncompare the performance metrics, including accuracy, precision, recall, and F1\nscore, of the different approaches. The results of this study shed light on the\nstrengths and limitations of machine learning and transformer-based methods for\ndeceptive text classification, enabling researchers and practitioners to make\ninformed decisions when dealing with deceptive content."
  },
  {
    "arxiv_id": "2308.05305",
    "title": "From CNN to Transformer: A Review of Medical Image Segmentation Models",
    "url": "http://arxiv.org/abs/2308.05305v1",
    "abstract": "Medical image segmentation is an important step in medical image analysis,\nespecially as a crucial prerequisite for efficient disease diagnosis and\ntreatment. The use of deep learning for image segmentation has become a\nprevalent trend. The widely adopted approach currently is U-Net and its\nvariants. Additionally, with the remarkable success of pre-trained models in\nnatural language processing tasks, transformer-based models like TransUNet have\nachieved desirable performance on multiple medical image segmentation datasets.\nIn this paper, we conduct a survey of the most representative four medical\nimage segmentation models in recent years. We theoretically analyze the\ncharacteristics of these models and quantitatively evaluate their performance\non two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors).\nFinally, we discuss the main challenges and future trends in medical image\nsegmentation. Our work can assist researchers in the related field to quickly\nestablish medical segmentation models tailored to specific regions."
  },
  {
    "arxiv_id": "2308.06013",
    "title": "Large Language Models for Telecom: Forthcoming Impact on the Industry",
    "url": "http://arxiv.org/abs/2308.06013v1",
    "abstract": "Large Language Models (LLMs), AI-driven models that can achieve\ngeneral-purpose language understanding and generation, have emerged as a\ntransformative force, revolutionizing fields well beyond Natural Language\nProcessing (NLP) and garnering unprecedented attention. As LLM technology\ncontinues to progress, the telecom industry is facing the prospect of its\nimpact on its landscape. To elucidate these implications, we delve into the\ninner workings of LLMs, providing insights into their current capabilities and\nlimitations. We also examine the use cases that can be readily implemented in\nthe telecom industry, streamlining tasks, such as anomalies resolutions and\ntechnical specifications comprehension, which currently hinder operational\nefficiency and demand significant manpower and expertise. Furthermore, we\nuncover essential research directions that deal with the distinctive challenges\nof utilizing the LLMs within the telecom domain. Addressing them represents a\nsignificant stride towards fully harnessing the potential of LLMs and unlocking\ntheir capabilities to the fullest extent within the telecom domain."
  },
  {
    "arxiv_id": "2308.07272",
    "title": "Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Optimization for Few-shot Learning",
    "url": "http://arxiv.org/abs/2308.07272v1",
    "abstract": "Prompt-based pre-trained language models (PLMs) paradigm have succeeded\nsubstantially in few-shot natural language processing (NLP) tasks. However,\nprior discrete prompt optimization methods require expert knowledge to design\nthe base prompt set and identify high-quality prompts, which is costly,\ninefficient, and subjective. Meanwhile, existing continuous prompt optimization\nmethods improve the performance by learning the ideal prompts through the\ngradient information of PLMs, whose high computational cost, and low\nreadability and generalizability are often concerning. To address the research\ngap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt\nOptimization ($DP_2O$) method. We first design a multi-round dialogue alignment\nstrategy for readability prompt set generation based on GPT-4. Furthermore, we\npropose an efficient prompt screening metric to identify high-quality prompts\nwith linear complexity. Finally, we construct a reinforcement learning (RL)\nframework based on policy gradients to match the prompts to inputs optimally.\nBy training a policy network with only 0.67% of the PLM parameter size on the\ntasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)\nmethod by 1.52% in accuracy on average on four open-source datasets. Moreover,\nsubsequent experiments also demonstrate that $DP_2O$ has good universality,\nrobustness, and generalization ability."
  },
  {
    "arxiv_id": "2308.07107",
    "title": "Large Language Models for Information Retrieval: A Survey",
    "url": "http://arxiv.org/abs/2308.07107v2",
    "abstract": "As a primary means of information acquisition, information retrieval (IR)\nsystems, such as search engines, have integrated themselves into our daily\nlives. These systems also serve as components of dialogue, question-answering,\nand recommender systems. The trajectory of IR has evolved dynamically from its\norigins in term-based methods to its integration with advanced neural models.\nWhile the neural models excel at capturing complex contextual signals and\nsemantic nuances, thereby reshaping the IR landscape, they still face\nchallenges such as data scarcity, interpretability, and the generation of\ncontextually plausible yet potentially inaccurate responses. This evolution\nrequires a combination of both traditional methods (such as term-based sparse\nretrieval methods with rapid response) and modern neural architectures (such as\nlanguage models with powerful language understanding capacity). Meanwhile, the\nemergence of large language models (LLMs), typified by ChatGPT and GPT-4, has\nrevolutionized natural language processing due to their remarkable language\nunderstanding, generation, generalization, and reasoning abilities.\nConsequently, recent research has sought to leverage LLMs to improve IR\nsystems. Given the rapid evolution of this research trajectory, it is necessary\nto consolidate existing methodologies and provide nuanced insights through a\ncomprehensive overview. In this survey, we delve into the confluence of LLMs\nand IR systems, including crucial aspects such as query rewriters, retrievers,\nrerankers, and readers. Additionally, we explore promising directions, such as\nsearch agents, within this expanding field."
  },
  {
    "arxiv_id": "2308.06966",
    "title": "EcomGPT: Instruction-tuning Large Language Model with Chain-of-Task Tasks for E-commerce",
    "url": "http://arxiv.org/abs/2308.06966v1",
    "abstract": "Recently, instruction-following Large Language Models (LLMs) , represented by\nChatGPT, have exhibited exceptional performance in general Natural Language\nProcessing (NLP) tasks. However, the unique characteristics of E-commerce data\npose significant challenges to general LLMs. An LLM tailored specifically for\nE-commerce scenarios, possessing robust cross-dataset/task generalization\ncapabilities, is a pressing necessity. To solve this issue, in this work, we\nproposed the first e-commerce instruction dataset EcomInstruct, with a total of\n2.5 million instruction data. EcomInstruct scales up the data size and task\ndiversity by constructing atomic tasks with E-commerce basic data types, such\nas product information, user reviews. Atomic tasks are defined as intermediate\ntasks implicitly involved in solving a final task, which we also call\nChain-of-Task tasks. We developed EcomGPT with different parameter scales by\ntraining the backbone model BLOOMZ with the EcomInstruct. Benefiting from the\nfundamental semantic understanding capabilities acquired from the Chain-of-Task\ntasks, EcomGPT exhibits excellent zero-shot generalization capabilities.\nExtensive experiments and human evaluations demonstrate that EcomGPT\noutperforms ChatGPT in term of cross-dataset/task generalization on E-commerce\ntasks."
  },
  {
    "arxiv_id": "2308.06911",
    "title": "GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text",
    "url": "http://arxiv.org/abs/2308.06911v1",
    "abstract": "Large language models have made significant strides in natural language\nprocessing, enabling innovative applications in molecular science by processing\ntextual representations of molecules. However, most existing language models\ncannot capture the rich information with complex molecular structures or\nimages. In this paper, we introduce GIT-Mol, a multi-modal large language model\nthat integrates the Graph, Image, and Text information. To facilitate the\nintegration of multi-modal molecular data, we propose GIT-Former, a novel\narchitecture that is capable of aligning all modalities into a unified latent\nspace. We achieve a 5%-10% accuracy increase in properties prediction and a\n20.2% boost in molecule generation validity compared to the baselines. With the\nany-to-language molecular translation strategy, our model has the potential to\nperform more downstream tasks, such as compound name recognition and chemical\nreaction prediction."
  },
  {
    "arxiv_id": "2308.06828",
    "title": "An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM",
    "url": "http://arxiv.org/abs/2308.06828v1",
    "abstract": "Natural Language Processing (NLP) has emerged as a crucial technology for\nunderstanding and generating human language, playing an essential role in tasks\nsuch as machine translation, sentiment analysis, and more pertinently, question\nclassification. As a subfield within NLP, question classification focuses on\ndetermining the type of information being sought, a fundamental step for\ndownstream applications like question answering systems. This study presents an\ninnovative ensemble approach for question classification, combining the\nstrengths of Electra, GloVe, and LSTM models. Rigorously tested on the\nwell-regarded TREC dataset, the model demonstrates how the integration of these\ndisparate technologies can lead to superior results. Electra brings in its\ntransformer-based capabilities for complex language understanding, GloVe offers\nglobal vector representations for capturing word-level semantics, and LSTM\ncontributes its sequence learning abilities to model long-term dependencies. By\nfusing these elements strategically, our ensemble model delivers a robust and\nefficient solution for the complex task of question classification. Through\nrigorous comparisons with well-known models like BERT, RoBERTa, and DistilBERT,\nthe ensemble approach verifies its effectiveness by attaining an 80% accuracy\nscore on the test dataset."
  },
  {
    "arxiv_id": "2308.07902",
    "title": "Through the Lens of Core Competency: Survey on Evaluation of Large Language Models",
    "url": "http://arxiv.org/abs/2308.07902v1",
    "abstract": "From pre-trained language model (PLM) to large language model (LLM), the\nfield of natural language processing (NLP) has witnessed steep performance\ngains and wide practical uses. The evaluation of a research field guides its\ndirection of improvement. However, LLMs are extremely hard to thoroughly\nevaluate for two reasons. First of all, traditional NLP tasks become inadequate\ndue to the excellent performance of LLM. Secondly, existing evaluation tasks\nare difficult to keep up with the wide range of applications in real-world\nscenarios. To tackle these problems, existing works proposed various benchmarks\nto better evaluate LLMs. To clarify the numerous evaluation tasks in both\nacademia and industry, we investigate multiple papers concerning LLM\nevaluations. We summarize 4 core competencies of LLM, including reasoning,\nknowledge, reliability, and safety. For every competency, we introduce its\ndefinition, corresponding benchmarks, and metrics. Under this competency\narchitecture, similar tasks are combined to reflect corresponding ability,\nwhile new tasks can also be easily added into the system. Finally, we give our\nsuggestions on the future direction of LLM's evaluation."
  },
  {
    "arxiv_id": "2308.07633",
    "title": "A Survey on Model Compression for Large Language Models",
    "url": "http://arxiv.org/abs/2308.07633v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing\ntasks successfully. Yet, their large size and high computational needs pose\nchallenges for practical use, especially in resource-limited settings. Model\ncompression has emerged as a key research area to address these challenges.\nThis paper presents a survey of model compression techniques for LLMs. We cover\nmethods like quantization, pruning, and knowledge distillation, highlighting\nrecent advancements. We also discuss benchmarking strategies and evaluation\nmetrics crucial for assessing compressed LLMs. This survey offers valuable\ninsights for researchers and practitioners, aiming to enhance efficiency and\nreal-world applicability of LLMs while laying a foundation for future\nadvancements."
  },
  {
    "arxiv_id": "2308.08536",
    "title": "Can Transformers Learn Optimal Filtering for Unknown Systems?",
    "url": "http://arxiv.org/abs/2308.08536v1",
    "abstract": "Transformer models have shown great success in natural language processing;\nhowever, their potential remains mostly unexplored for dynamical systems. In\nthis work, we investigate the optimal output estimation problem using\ntransformers, which generate output predictions using all the past ones.\nParticularly, we train the transformer using various distinct systems and then\nevaluate the performance on unseen systems with unknown dynamics. Empirically,\nthe trained transformer adapts exceedingly well to different unseen systems and\neven matches the optimal performance given by the Kalman filter for linear\nsystems. In more complex settings with non-i.i.d. noise, time-varying dynamics,\nand nonlinear dynamics like a quadrotor system with unknown parameters,\ntransformers also demonstrate promising results. To support our experimental\nfindings, we provide statistical guarantees that quantify the amount of\ntraining data required for the transformer to achieve a desired excess risk.\nFinally, we point out some limitations by identifying two classes of problems\nthat lead to degraded performance, highlighting the need for caution when using\ntransformers for control and estimation."
  },
  {
    "arxiv_id": "2308.08469",
    "title": "LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs",
    "url": "http://arxiv.org/abs/2308.08469v1",
    "abstract": "Multivariate time-series forecasting is vital in various domains, e.g.,\neconomic planning and weather prediction. Deep train-from-scratch models have\nexhibited effective performance yet require large amounts of data, which limits\nreal-world applicability. Recently, researchers have leveraged the\nrepresentation learning transferability of pre-trained Large Language Models\n(LLMs) to handle limited non-linguistic datasets effectively. However,\nincorporating LLMs with time-series data presents challenges of limited\nadaptation due to different compositions between time-series and linguistic\ndata, and the inability to process multi-scale temporal information. To tackle\nthese challenges, we propose LLM4TS, a framework for time-series forecasting\nwith pre-trained LLMs. LLM4TS consists of a two-stage fine-tuning strategy: the\ntime-series alignment stage to align LLMs with the nuances of time-series data,\nand the forecasting fine-tuning stage for downstream time-series forecasting\ntasks. Furthermore, our framework features a novel two-level aggregation method\nthat integrates multi-scale temporal data within pre-trained LLMs, enhancing\ntheir ability to interpret time-specific information. In experiments across 7\ntime-series forecasting datasets, LLM4TS is superior to existing\nstate-of-the-art methods compared with trained-from-scratch models in full-shot\nscenarios, and also achieves the highest rank in few-shot scenarios. In\naddition, evaluations compared with different unsupervised representation\nlearning approaches highlight LLM4TS's effectiveness with representation\nlearning in forecasting tasks. Ablation studies further validate each\ncomponent's contribution to LLM4TS and underscore the essential role of\nutilizing LLM's pre-trained weights for optimal performance. The code is\navailable at https://github.com/blacksnail789521/LLM4TS."
  },
  {
    "arxiv_id": "2308.08234",
    "title": "Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey",
    "url": "http://arxiv.org/abs/2308.08234v1",
    "abstract": "The increasing adoption of natural language processing (NLP) models across\nindustries has led to practitioners' need for machine learning systems to\nhandle these models efficiently, from training to serving them in production.\nHowever, training, deploying, and updating multiple models can be complex,\ncostly, and time-consuming, mainly when using transformer-based pre-trained\nlanguage models. Multi-Task Learning (MTL) has emerged as a promising approach\nto improve efficiency and performance through joint training, rather than\ntraining separate models. Motivated by this, we first provide an overview of\ntransformer-based MTL approaches in NLP. Then, we discuss the challenges and\nopportunities of using MTL approaches throughout typical ML lifecycle phases,\nspecifically focusing on the challenges related to data engineering, model\ndevelopment, deployment, and monitoring phases. This survey focuses on\ntransformer-based MTL architectures and, to the best of our knowledge, is novel\nin that it systematically analyses how transformer-based MTL in NLP fits into\nML lifecycle phases. Furthermore, we motivate research on the connection\nbetween MTL and continual learning (CL), as this area remains unexplored. We\nbelieve it would be practical to have a model that can handle both MTL and CL,\nas this would make it easier to periodically re-train the model, update it due\nto distribution shifts, and add new capabilities to meet real-world\nrequirements."
  },
  {
    "arxiv_id": "2308.09583",
    "title": "WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct",
    "url": "http://arxiv.org/abs/2308.09583v1",
    "abstract": "Large language models (LLMs), such as GPT-4, have shown remarkable\nperformance in natural language processing (NLP) tasks, including challenging\nmathematical reasoning. However, most existing open-source models are only\npre-trained on large-scale internet data and without math-related optimization.\nIn this paper, we present WizardMath, which enhances the mathematical CoT\nreasoning abilities of LLMs without using external python tools, by applying\nour proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method\nto the domain of math. Through extensive experiments on two mathematical\nreasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary\ncapabilities of our model. Remarkably, WizardMath-Mistral 7B surpasses top-tier\nopen-source LLMs by a substantial margin with higher data efficiency.\nFurthermore, WizardMath 70B even outperforms GPT-3.5-Turbo, Claude 2, Gemini\nPro and GPT-4-early-version. Additionally, our preliminary exploration\nhighlights the pivotal role of instruction evolution and process supervision in\nachieving exceptional math performance. For more details refer to\nhttps://github.com/nlpxucan/WizardLM"
  },
  {
    "arxiv_id": "2308.09454",
    "title": "Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model",
    "url": "http://arxiv.org/abs/2308.09454v1",
    "abstract": "Research in natural language processing has demonstrated that the quality of\ngenerations from trained autoregressive language models is significantly\ninfluenced by the used sampling strategy. In this study, we investigate the\nimpact of different sampling techniques on musical qualities such as diversity\nand structure. To accomplish this, we train a high-capacity transformer model\non a vast collection of highly-structured Irish folk melodies and analyze the\nmusical qualities of the samples generated using distribution truncation\nsampling techniques. Specifically, we use nucleus sampling, the recently\nproposed \"typical sampling\", and conventional ancestral sampling. We evaluate\nthe effect of these sampling strategies in two scenarios: optimal circumstances\nwith a well-calibrated model and suboptimal circumstances where we\nsystematically degrade the model's performance. We assess the generated samples\nusing objective and subjective evaluations. We discover that probability\ntruncation techniques may restrict diversity and structural patterns in optimal\ncircumstances, but may also produce more musical samples in suboptimal\ncircumstances."
  },
  {
    "arxiv_id": "2308.09308",
    "title": "Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification",
    "url": "http://arxiv.org/abs/2308.09308v1",
    "abstract": "Retrieval augmentation, which enhances downstream models by a knowledge\nretriever and an external corpus instead of by merely increasing the number of\nmodel parameters, has been successfully applied to many natural language\nprocessing (NLP) tasks such as text classification, question answering and so\non. However, existing methods that separately or asynchronously train the\nretriever and downstream model mainly due to the non-differentiability between\nthe two parts, usually lead to degraded performance compared to end-to-end\njoint training. In this paper, we propose Differentiable Retrieval Augmentation\nvia Generative lANguage modeling(Dragan), to address this problem by a novel\ndifferentiable reformulation. We demonstrate the effectiveness of our proposed\nmethod on a challenging NLP task in e-commerce search, namely query intent\nclassification. Both the experimental results and ablation study show that the\nproposed method significantly and reasonably improves the state-of-the-art\nbaselines on both offline evaluation and online A/B test."
  },
  {
    "arxiv_id": "2308.10482",
    "title": "An Effective Method using Phrase Mechanism in Neural Machine Translation",
    "url": "http://arxiv.org/abs/2308.10482v2",
    "abstract": "Machine Translation is one of the essential tasks in Natural Language\nProcessing (NLP), which has massive applications in real life as well as\ncontributing to other tasks in the NLP research community. Recently,\nTransformer -based methods have attracted numerous researchers in this domain\nand achieved state-of-the-art results in most of the pair languages. In this\npaper, we report an effective method using a phrase mechanism,\nPhraseTransformer, to improve the strong baseline model Transformer in\nconstructing a Neural Machine Translation (NMT) system for parallel corpora\nVietnamese-Chinese. Our experiments on the MT dataset of the VLSP 2022\ncompetition achieved the BLEU score of 35.3 on Vietnamese to Chinese and 33.2\nBLEU scores on Chinese to Vietnamese data. Our code is available at\nhttps://github.com/phuongnm94/PhraseTransformer."
  },
  {
    "arxiv_id": "2308.10410",
    "title": "Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts",
    "url": "http://arxiv.org/abs/2308.10410v1",
    "abstract": "Educational materials such as survey articles in specialized fields like\ncomputer science traditionally require tremendous expert inputs and are\ntherefore expensive to create and update. Recently, Large Language Models\n(LLMs) have achieved significant success across various general tasks. However,\ntheir effectiveness and limitations in the education domain are yet to be fully\nexplored. In this work, we examine the proficiency of LLMs in generating\nsuccinct survey articles specific to the niche field of NLP in computer\nscience, focusing on a curated list of 99 topics. Automated benchmarks reveal\nthat GPT-4 surpasses its predecessors, inluding GPT-3.5, PaLM2, and LLaMa2 by\nmargins ranging from 2% to 20% in comparison to the established ground truth.\nWe compare both human and GPT-based evaluation scores and provide in-depth\nanalysis. While our findings suggest that GPT-created surveys are more\ncontemporary and accessible than human-authored ones, certain limitations were\nobserved. Notably, GPT-4, despite often delivering outstanding content,\noccasionally exhibited lapses like missing details or factual errors. At last,\nwe compared the rating behavior between humans and GPT-4 and found systematic\nbias in using GPT evaluation."
  },
  {
    "arxiv_id": "2308.10261",
    "title": "How Good Are Large Language Models at Out-of-Distribution Detection?",
    "url": "http://arxiv.org/abs/2308.10261v1",
    "abstract": "Out-of-distribution (OOD) detection plays a vital role in enhancing the\nreliability of machine learning (ML) models. The emergence of large language\nmodels (LLMs) has catalyzed a paradigm shift within the ML community,\nshowcasing their exceptional capabilities across diverse natural language\nprocessing tasks. While existing research has probed OOD detection with\nrelative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark\ndifferences in scales, pre-training objectives, and inference paradigms call\ninto question the applicability of these findings to LLMs. This paper embarks\non a pioneering empirical investigation of OOD detection in the domain of LLMs,\nfocusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate\ncommonly-used OOD detectors, scrutinizing their performance in both zero-grad\nand fine-tuning scenarios. Notably, we alter previous discriminative\nin-distribution fine-tuning into generative fine-tuning, aligning the\npre-training objective of LLMs with downstream tasks. Our findings unveil that\na simple cosine distance OOD detector demonstrates superior efficacy,\noutperforming other OOD detectors. We provide an intriguing explanation for\nthis phenomenon by highlighting the isotropic nature of the embedding spaces of\nLLMs, which distinctly contrasts with the anisotropic property observed in\nsmaller BERT family models. The new insight enhances our understanding of how\nLLMs detect OOD data, thereby enhancing their adaptability and reliability in\ndynamic environments. We have released the source code at\n\\url{https://github.com/Awenbocc/LLM-OOD} for other researchers to reproduce\nour results."
  },
  {
    "arxiv_id": "2308.10204",
    "title": "ChatEDA: A Large Language Model Powered Autonomous Agent for EDA",
    "url": "http://arxiv.org/abs/2308.10204v1",
    "abstract": "The integration of a complex set of Electronic Design Automation (EDA) tools\nto enhance interoperability is a critical concern for circuit designers. Recent\nadvancements in large language models (LLMs) have showcased their exceptional\ncapabilities in natural language processing and comprehension, offering a novel\napproach to interfacing with EDA tools. This research paper introduces ChatEDA,\nan autonomous agent for EDA empowered by an LLM, AutoMage, complemented by EDA\ntools serving as executors. ChatEDA streamlines the design flow from the\nRegister-Transfer Level (RTL) to the Graphic Data System Version II (GDSII) by\neffectively managing task decomposition, script generation, and task execution.\nThrough comprehensive experimental evaluations, ChatEDA has demonstrated its\nproficiency in handling diverse requirements, and our fine-tuned AutoMage model\nhas exhibited superior performance compared to GPT-4 and other similar LLMs."
  },
  {
    "arxiv_id": "2308.09975",
    "title": "FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models",
    "url": "http://arxiv.org/abs/2308.09975v1",
    "abstract": "Large language models have demonstrated outstanding performance in various\nnatural language processing tasks, but their security capabilities in the\nfinancial domain have not been explored, and their performance on complex tasks\nlike financial agent remains unknown. This paper presents FinEval, a benchmark\ndesigned to evaluate LLMs' financial domain knowledge and practical abilities.\nThe dataset contains 8,351 questions categorized into four different key areas:\nFinancial Academic Knowledge, Financial Industry Knowledge, Financial Security\nKnowledge, and Financial Agent. Financial Academic Knowledge comprises 4,661\nmultiple-choice questions spanning 34 subjects such as finance and economics.\nFinancial Industry Knowledge contains 1,434 questions covering practical\nscenarios like investment research. Financial Security Knowledge assesses\nmodels through 1,640 questions on topics like application security and\ncryptography. Financial Agent evaluates tool usage and complex reasoning with\n616 questions. FinEval has multiple evaluation settings, including zero-shot,\nfive-shot with chain-of-thought, and assesses model performance using objective\nand subjective criteria. Our results show that Claude 3.5-Sonnet achieves the\nhighest weighted average score of 72.9 across all financial domain categories\nunder zero-shot setting. Our work provides a comprehensive benchmark closely\naligned with Chinese financial domain."
  },
  {
    "arxiv_id": "2308.09884",
    "title": "A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case",
    "url": "http://arxiv.org/abs/2308.09884v1",
    "abstract": "In recent times, Large Language Models (LLMs) have captured a global\nspotlight and revolutionized the field of Natural Language Processing. One of\nthe factors attributed to the effectiveness of LLMs is the model architecture\nused for training, transformers. Transformer models excel at capturing\ncontextual features in sequential data since time series data are sequential,\ntransformer models can be leveraged for more efficient time series data\nprediction. The field of prognostics is vital to system health management and\nproper maintenance planning. A reliable estimation of the remaining useful life\n(RUL) of machines holds the potential for substantial cost savings. This\nincludes avoiding abrupt machine failures, maximizing equipment usage, and\nserving as a decision support system (DSS). This work proposed an\nencoder-transformer architecture-based framework for multivariate time series\nprediction for a prognostics use case. We validated the effectiveness of the\nproposed framework on all four sets of the C-MAPPS benchmark dataset for the\nremaining useful life prediction task. To effectively transfer the knowledge\nand application of transformers from the natural language domain to time\nseries, three model-specific experiments were conducted. Also, to enable the\nmodel awareness of the initial stages of the machine life and its degradation\npath, a novel expanding window method was proposed for the first time in this\nwork, it was compared with the sliding window method, and it led to a large\nimprovement in the performance of the encoder transformer model. Finally, the\nperformance of the proposed encoder-transformer model was evaluated on the test\ndataset and compared with the results from 13 other state-of-the-art (SOTA)\nmodels in the literature and it outperformed them all with an average\nperformance increase of 137.65% over the next best model across all the\ndatasets."
  },
  {
    "arxiv_id": "2308.11295",
    "title": "Uncertainty Estimation of Transformers' Predictions via Topological Analysis of the Attention Matrices",
    "url": "http://arxiv.org/abs/2308.11295v1",
    "abstract": "Transformer-based language models have set new benchmarks across a wide range\nof NLP tasks, yet reliably estimating the uncertainty of their predictions\nremains a significant challenge. Existing uncertainty estimation (UE)\ntechniques often fall short in classification tasks, either offering minimal\nimprovements over basic heuristics or relying on costly ensemble models.\nMoreover, attempts to leverage common embeddings for UE in linear probing\nscenarios have yielded only modest gains, indicating that alternative model\ncomponents should be explored.\n  We tackle these limitations by harnessing the geometry of attention maps\nacross multiple heads and layers to assess model confidence. Our approach\nextracts topological features from attention matrices, providing a\nlow-dimensional, interpretable representation of the model's internal dynamics.\nAdditionally, we introduce topological features to compare attention patterns\nacross heads and layers. Our method significantly outperforms existing UE\ntechniques on benchmarks for acceptability judgments and artificial text\ndetection, offering a more efficient and interpretable solution for uncertainty\nestimation in large-scale language models."
  },
  {
    "arxiv_id": "2308.11131",
    "title": "ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
    "url": "http://arxiv.org/abs/2308.11131v1",
    "abstract": "With large language models (LLMs) achieving remarkable breakthroughs in\nnatural language processing (NLP) domains, LLM-enhanced recommender systems\nhave received much attention and have been actively explored currently. In this\npaper, we focus on adapting and empowering a pure large language model for\nzero-shot and few-shot recommendation tasks. First and foremost, we identify\nand formulate the lifelong sequential behavior incomprehension problem for LLMs\nin recommendation domains, i.e., LLMs fail to extract useful information from a\ntextual context of long user behavior sequence, even if the length of context\nis far from reaching the context limitation of LLMs. To address such an issue\nand improve the recommendation performance of LLMs, we propose a novel\nframework, namely Retrieval-enhanced Large Language models (ReLLa) for\nrecommendation tasks in both zero-shot and few-shot settings. For zero-shot\nrecommendation, we perform semantic user behavior retrieval (SUBR) to improve\nthe data quality of testing samples, which greatly reduces the difficulty for\nLLMs to extract the essential knowledge from user behavior sequences. As for\nfew-shot recommendation, we further design retrieval-enhanced instruction\ntuning (ReiT) by adopting SUBR as a data augmentation technique for training\nsamples. Specifically, we develop a mixed training dataset consisting of both\nthe original data samples and their retrieval-enhanced counterparts. We conduct\nextensive experiments on three real-world public datasets to demonstrate the\nsuperiority of ReLLa compared with existing baseline models, as well as its\ncapability for lifelong sequential behavior comprehension. To be highlighted,\nwith only less than 10% training samples, few-shot ReLLa can outperform\ntraditional CTR models that are trained on the entire training set (e.g.,\nDCNv2, DIN, SIM). The code is available\n\\url{https://github.com/LaVieEnRose365/ReLLa}."
  },
  {
    "arxiv_id": "2308.11042",
    "title": "Unlocking Hardware Security Assurance: The Potential of LLMs",
    "url": "http://arxiv.org/abs/2308.11042v1",
    "abstract": "System-on-Chips (SoCs) form the crux of modern computing systems. SoCs enable\nhigh-level integration through the utilization of multiple Intellectual\nProperty (IP) cores. However, the integration of multiple IP cores also\npresents unique challenges owing to their inherent vulnerabilities, thereby\ncompromising the security of the entire system. Hence, it is imperative to\nperform hardware security validation to address these concerns. The efficiency\nof this validation procedure is contingent on the quality of the SoC security\nproperties provided. However, generating security properties with traditional\napproaches often requires expert intervention and is limited to a few IPs,\nthereby resulting in a time-consuming and non-robust process. To address this\nissue, we, for the first time, propose a novel and automated Natural Language\nProcessing (NLP)-based Security Property Generator (NSPG). Specifically, our\napproach utilizes hardware documentation in order to propose the first hardware\nsecurity-specific language model, HS-BERT, for extracting security properties\ndedicated to hardware design. To evaluate our proposed technique, we trained\nthe HS-BERT model using sentences from RISC-V, OpenRISC, MIPS, OpenSPARC, and\nOpenTitan SoC documentation. When assessedb on five untrained OpenTitan\nhardware IP documents, NSPG was able to extract 326 security properties from\n1723 sentences. This, in turn, aided in identifying eight security bugs in the\nOpenTitan SoC design presented in the hardware hacking competition, Hack@DAC\n2022."
  },
  {
    "arxiv_id": "2308.12272",
    "title": "Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models",
    "url": "http://arxiv.org/abs/2308.12272v1",
    "abstract": "Foundational Language Models (FLMs) have advanced natural language processing\n(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,\nT5) to enable contextualized language representation, classification, and\ngeneration. While developing larger FLMs has been of significant advantage, it\nis also a liability concerning hallucination and predictive uncertainty.\nFundamentally, larger FLMs are built on the same foundations as smaller FLMs\n(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can\nbe realized through an ensemble. In the current research, we perform a reality\ncheck on FLMs and their ensemble on benchmark and real-world datasets. We\nhypothesize that the ensembling of FLMs can influence the individualistic\nattention of FLMs and unravel the strength of coordination and cooperation of\ndifferent FLMs. We utilize BERT and define three other ensemble techniques:\n{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a\nknowledge-guided reinforcement learning approach. We discovered that the\nsuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by\na factor of many times using datasets that show the usefulness of NLP in\nsensitive fields, such as mental health."
  },
  {
    "arxiv_id": "2308.11891",
    "title": "Bridging the Gap: Deciphering Tabular Data Using Large Language Model",
    "url": "http://arxiv.org/abs/2308.11891v1",
    "abstract": "In the realm of natural language processing, the understanding of tabular\ndata has perpetually stood as a focal point of scholarly inquiry. The emergence\nof expansive language models, exemplified by the likes of ChatGPT, has ushered\nin a wave of endeavors wherein researchers aim to harness these models for\ntasks related to table-based question answering. Central to our investigative\npursuits is the elucidation of methodologies that amplify the aptitude of such\nlarge language models in discerning both the structural intricacies and\ninherent content of tables, ultimately facilitating their capacity to provide\ninformed responses to pertinent queries. To this end, we have architected a\ndistinctive module dedicated to the serialization of tables for seamless\nintegration with expansive language models. Additionally, we've instituted a\ncorrective mechanism within the model to rectify potential inaccuracies.\nExperimental results indicate that, although our proposed method trails the\nSOTA by approximately 11.7% in overall metrics, it surpasses the SOTA by about\n1.2% in tests on specific datasets. This research marks the first application\nof large language models to table-based question answering tasks, enhancing the\nmodel's comprehension of both table structures and content."
  },
  {
    "arxiv_id": "2308.11764",
    "title": "Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models",
    "url": "http://arxiv.org/abs/2308.11764v2",
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP). Although convenient for research and practical applications, open-source\nLLMs with fewer parameters often suffer from severe hallucinations compared to\ntheir larger counterparts. This paper focuses on measuring and reducing\nhallucinations in BLOOM 7B, a representative of such weaker open-source LLMs\nthat are publicly available for research and commercial applications. We\nintroduce HaloCheck, a lightweight BlackBox knowledge-free framework designed\nto quantify the severity of hallucinations in LLMs. Additionally, we explore\ntechniques like knowledge injection and teacher-student approaches to alleviate\nhallucinations in low-parameter LLMs. Our experiments effectively demonstrate\nthe reduction of hallucinations in challenging domains for these LLMs."
  },
  {
    "arxiv_id": "2308.13517",
    "title": "ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection",
    "url": "http://arxiv.org/abs/2308.13517v1",
    "abstract": "Open intent detection, a crucial aspect of natural language understanding,\ninvolves the identification of previously unseen intents in user-generated\ntext. Despite the progress made in this field, challenges persist in handling\nnew combinations of language components, which is essential for compositional\ngeneralization. In this paper, we present a case study exploring the use of\nChatGPT as a data augmentation technique to enhance compositional\ngeneralization in open intent detection tasks. We begin by discussing the\nlimitations of existing benchmarks in evaluating this problem, highlighting the\nneed for constructing datasets for addressing compositional generalization in\nopen intent detection tasks. By incorporating synthetic data generated by\nChatGPT into the training process, we demonstrate that our approach can\neffectively improve model performance. Rigorous evaluation of multiple\nbenchmarks reveals that our method outperforms existing techniques and\nsignificantly enhances open intent detection capabilities. Our findings\nunderscore the potential of large language models like ChatGPT for data\naugmentation in natural language understanding tasks."
  },
  {
    "arxiv_id": "2308.13467",
    "title": "Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models",
    "url": "http://arxiv.org/abs/2308.13467v1",
    "abstract": "The Natural Language Processing(NLP) community has been using crowd sourcing\ntechniques to create benchmark datasets such as General Language Understanding\nand Evaluation(GLUE) for training modern Language Models such as BERT. GLUE\ntasks measure the reliability scores using inter annotator metrics i.e. Cohens\nKappa. However, the reliability aspect of LMs has often been overlooked. To\ncounter this problem, we explore a knowledge-guided LM ensembling approach that\nleverages reinforcement learning to integrate knowledge from ConceptNet and\nWikipedia as knowledge graph embeddings. This approach mimics human annotators\nresorting to external knowledge to compensate for information deficits in the\ndatasets. Across nine GLUE datasets, our research shows that ensembling\nstrengthens reliability and accuracy scores, outperforming state of the art."
  },
  {
    "arxiv_id": "2308.13380",
    "title": "In-context learning for model-free system identification",
    "url": "http://arxiv.org/abs/2308.13380v1",
    "abstract": "Is it possible to understand the intricacies of a dynamical system not solely\nfrom its input/output pattern, but also by observing the behavior of other\nsystems within the same class? This central question drives the study presented\nin this paper.\n  In response to this query, we introduce a novel paradigm for system\nidentification, addressing two primary tasks: one-step-ahead prediction and\nmulti-step simulation. Unlike conventional methods, we do not directly estimate\na model for the specific system. Instead, we learn a meta model that represents\na class of dynamical systems. This meta model is trained on a potentially\ninfinite stream of synthetic data, generated by simulators whose settings are\nrandomly extracted from a probability distribution. When provided with a\ncontext from a new system-specifically, an input/output sequence-the meta model\nimplicitly discerns its dynamics, enabling predictions of its behavior.\n  The proposed approach harnesses the power of Transformers, renowned for their\n\\emph{in-context learning} capabilities. For one-step prediction, a GPT-like\ndecoder-only architecture is utilized, whereas the simulation problem employs\nan encoder-decoder structure. Initial experimental results affirmatively answer\nour foundational question, opening doors to fresh research avenues in system\nidentification."
  },
  {
    "arxiv_id": "2308.13315",
    "title": "Construction Grammar and Language Models",
    "url": "http://arxiv.org/abs/2308.13315v1",
    "abstract": "Recent progress in deep learning and natural language processing has given\nrise to powerful models that are primarily trained on a cloze-like task and\nshow some evidence of having access to substantial linguistic information,\nincluding some constructional knowledge. This groundbreaking discovery presents\nan exciting opportunity for a synergistic relationship between computational\nmethods and Construction Grammar research. In this chapter, we explore three\ndistinct approaches to the interplay between computational methods and\nConstruction Grammar: (i) computational methods for text analysis, (ii)\ncomputational Construction Grammar, and (iii) deep learning models, with a\nparticular focus on language models. We touch upon the first two approaches as\na contextual foundation for the use of computational methods before providing\nan accessible, yet comprehensive overview of deep learning models, which also\naddresses reservations construction grammarians may have. Additionally, we\ndelve into experiments that explore the emergence of constructionally relevant\ninformation within these models while also examining the aspects of\nConstruction Grammar that may pose challenges for these models. This chapter\naims to foster collaboration between researchers in the fields of natural\nlanguage processing and Construction Grammar. By doing so, we hope to pave the\nway for new insights and advancements in both these fields."
  },
  {
    "arxiv_id": "2308.13207",
    "title": "LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models",
    "url": "http://arxiv.org/abs/2308.13207v1",
    "abstract": "The advent of Large Language Models (LLM) has revolutionized the field of\nnatural language processing, enabling significant progress in various\napplications. One key area of interest is the construction of Knowledge Bases\n(KB) using these powerful models. Knowledge bases serve as repositories of\nstructured information, facilitating information retrieval and inference tasks.\nOur paper proposes LLM2KB, a system for constructing knowledge bases using\nlarge language models, with a focus on the Llama 2 architecture and the\nWikipedia dataset. We perform parameter efficient instruction tuning for\nLlama-2-13b-chat and StableBeluga-13B by training small injection models that\nhave only 0.05 % of the parameters of the base models using the Low Rank\nAdaptation (LoRA) technique. These injection models have been trained with\nprompts that are engineered to utilize Wikipedia page contexts of subject\nentities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer\nrelevant object entities for a given subject entity and relation. Our best\nperforming model achieved an average F1 score of 0.6185 across 21 relations in\nthe LM-KBC challenge held at the ISWC 2023 conference."
  },
  {
    "arxiv_id": "2308.13191",
    "title": "Chunk, Align, Select: A Simple Long-sequence Processing Method for Transformers",
    "url": "http://arxiv.org/abs/2308.13191v1",
    "abstract": "Although dominant in natural language processing, transformer-based models\nremain challenged by the task of long-sequence processing, because the\ncomputational cost of self-attention operations in transformers swells\nquadratically with the input sequence length. To alleviate the complexity of\nlong-sequence processing, we propose a simple framework to enable the\noffthe-shelf pre-trained transformers to process much longer sequences, while\nthe computation and memory costs remain growing linearly with the input\nsequence lengths. More specifically, our method divides each long-sequence\ninput into a batch of chunks, then aligns the interchunk information during the\nencoding steps, and finally selects the most representative hidden states from\nthe encoder for the decoding process. To extract inter-chunk semantic\ninformation, we align the start and end token embeddings among chunks in each\nencoding transformer block. To learn an effective hidden selection policy, we\ndesign a dual updating scheme inspired by reinforcement learning, which regards\nthe decoders of transformers as environments, and the downstream performance\nmetrics as the rewards to evaluate the hidden selection actions. Our empirical\nresults on real-world long-text summarization and reading comprehension tasks\ndemonstrate effective improvements compared to prior longsequence processing\nbaselines."
  },
  {
    "arxiv_id": "2308.13137",
    "title": "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models",
    "url": "http://arxiv.org/abs/2308.13137v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\ntasks. However, their practical deployment is hindered by their immense memory\nand computation requirements. Although recent post-training quantization (PTQ)\nmethods are effective in reducing memory footprint and improving the\ncomputational efficiency of LLM, they hand-craft quantization parameters,\nleading to low performance, especially in extremely low-bit quantization. To\ntackle this issue, we introduce an Omnidirectionally calibrated Quantization\n(\\textbf{OmniQuant}) technique for LLMs, which achieves good performance in\ndiverse quantization settings while maintaining the computational efficiency of\nPTQ by efficiently optimizing various quantization parameters. OmniQuant\ncomprises two innovative components including Learnable Weight Clipping (LWC)\nand Learnable Equivalent Transformation (LET). LWC modulates the extreme values\nof weights by optimizing the clipping threshold. Meanwhile, LET tackles\nactivation outliers by shifting the challenge of quantization from activations\nto weights. Operating within a differentiable framework using block-wise error\nminimization, OmniQuant can optimize the quantization process efficiently for\nboth weight-only and weight-activation quantization. For instance, the LLaMA-2\nmodel family size 7-70B can be processed with OmniQuant on a single A100-40G\nGPU within 1-16 hours using 128 samples. Extensive experiments validate\nOmniQuant's superior performance across diverse quantization configurations\nsuch as W4A4 (4-bit weight, 4-bit activation), W6A6, W4A16, W3A16, and W2A16.\nAdditionally, OmniQuant demonstrates effectiveness in instruction-tuned models\nand delivers notable improvements in inference speed and memory reduction on\nreal devices. Codes are available at\n\\url{https://github.com/OpenGVLab/OmniQuant}."
  },
  {
    "arxiv_id": "2308.14669",
    "title": "ANER: Arabic and Arabizi Named Entity Recognition using Transformer-Based Approach",
    "url": "http://arxiv.org/abs/2308.14669v1",
    "abstract": "One of the main tasks of Natural Language Processing (NLP), is Named Entity\nRecognition (NER). It is used in many applications and also can be used as an\nintermediate step for other tasks. We present ANER, a web-based named entity\nrecognizer for the Arabic, and Arabizi languages. The model is built upon BERT,\nwhich is a transformer-based encoder. It can recognize 50 different entity\nclasses, covering various fields. We trained our model on the WikiFANE\\_Gold\ndataset which consists of Wikipedia articles. We achieved an F1 score of\n88.7\\%, which beats CAMeL Tools' F1 score of 83\\% on the ANERcorp dataset,\nwhich has only 4 classes. We also got an F1 score of 77.7\\% on the\nNewsFANE\\_Gold dataset which contains out-of-domain data from News articles.\nThe system is deployed on a user-friendly web interface that accepts users'\ninputs in Arabic, or Arabizi. It allows users to explore the entities in the\ntext by highlighting them. It can also direct users to get information about\nentities through Wikipedia directly. We added the ability to do NER using our\nmodel, or CAMeL Tools' model through our website. ANER is publicly accessible\nat \\url{http://www.aner.online}. We also deployed our model on HuggingFace at\nhttps://huggingface.co/boda/ANER, to allow developers to test and use it."
  },
  {
    "arxiv_id": "2308.14363",
    "title": "Rethinking Mobile AI Ecosystem in the LLM Era",
    "url": "http://arxiv.org/abs/2308.14363v1",
    "abstract": "In today's landscape, smartphones have evolved into hubs for hosting a\nmultitude of deep learning models aimed at local execution. A key realization\ndriving this work is the notable fragmentation among these models,\ncharacterized by varied architectures, operators, and implementations. This\nfragmentation imposes a significant burden on the comprehensive optimization of\nhardware, system settings, and algorithms.\n  Buoyed by the recent strides in large foundation models, this work introduces\na pioneering paradigm for mobile AI: a collaborative management approach\nbetween the mobile OS and hardware, overseeing a foundational model capable of\nserving a broad spectrum of mobile AI tasks, if not all. This foundational\nmodel resides within the NPU and remains impervious to app or OS revisions,\nakin to firmware. Concurrently, each app contributes a concise, offline\nfine-tuned \"adapter\" tailored to distinct downstream tasks. From this concept\nemerges a concrete instantiation known as \\sys. It amalgamates a curated\nselection of publicly available Large Language Models (LLMs) and facilitates\ndynamic data flow. This concept's viability is substantiated through the\ncreation of an exhaustive benchmark encompassing 38 mobile AI tasks spanning 50\ndatasets, including domains such as Computer Vision (CV), Natural Language\nProcessing (NLP), audio, sensing, and multimodal inputs. Spanning this\nbenchmark, \\sys unveils its impressive performance. It attains accuracy parity\nin 85\\% of tasks, demonstrates improved scalability in terms of storage and\nmemory, and offers satisfactory inference speed on Commercial Off-The-Shelf\n(COTS) mobile devices fortified with NPU support. This stands in stark contrast\nto task-specific models tailored for individual applications."
  },
  {
    "arxiv_id": "2308.14355",
    "title": "Can Transformer and GNN Help Each Other?",
    "url": "http://arxiv.org/abs/2308.14355v1",
    "abstract": "Graph Neural Networks (GNNs) have emerged as promising solutions for\ncollaborative filtering (CF) through the modeling of user-item interaction\ngraphs. The nucleus of existing GNN-based recommender systems involves\nrecursive message passing along user-item interaction edges to refine encoded\nembeddings. Despite their demonstrated effectiveness, current GNN-based methods\nencounter challenges of limited receptive fields and the presence of noisy\n\"interest-irrelevant\" connections. In contrast, Transformer-based methods excel\nin aggregating information adaptively and globally. Nevertheless, their\napplication to large-scale interaction graphs is hindered by inherent\ncomplexities and challenges in capturing intricate, entangled structural\ninformation. In this paper, we propose TransGNN, a novel model that integrates\nTransformer and GNN layers in an alternating fashion to mutually enhance their\ncapabilities. Specifically, TransGNN leverages Transformer layers to broaden\nthe receptive field and disentangle information aggregation from edges, which\naggregates information from more relevant nodes, thereby enhancing the message\npassing of GNNs. Additionally, to capture graph structure information\neffectively, positional encoding is meticulously designed and integrated into\nGNN layers to encode such structural knowledge into node attributes, thus\nenhancing the Transformer's performance on graphs. Efficiency considerations\nare also alleviated by proposing the sampling of the most relevant nodes for\nthe Transformer, along with two efficient sample update strategies to reduce\ncomplexity. Furthermore, theoretical analysis demonstrates that TransGNN offers\nincreased expressiveness compared to GNNs, with only a marginal increase in\nlinear complexity. Extensive experiments on five public datasets validate the\neffectiveness and efficiency of TransGNN."
  },
  {
    "arxiv_id": "2308.14149",
    "title": "Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models",
    "url": "http://arxiv.org/abs/2308.14149v1",
    "abstract": "Generative pre-trained transformer (GPT) models have revolutionized the field\nof natural language processing (NLP) with remarkable performance in various\ntasks and also extend their power to multimodal domains. Despite their success,\nlarge GPT models like GPT-4 face inherent limitations such as considerable\nsize, high computational requirements, complex deployment processes, and closed\ndevelopment loops. These constraints restrict their widespread adoption and\nraise concerns regarding their responsible development and usage. The need for\nuser-friendly, relatively small, and open-sourced alternative GPT models arises\nfrom the desire to overcome these limitations while retaining high performance.\nIn this survey paper, we provide an examination of alternative open-sourced\nmodels of large GPTs, focusing on user-friendly and relatively small models\nthat facilitate easier deployment and accessibility. Through this extensive\nsurvey, we aim to equip researchers, practitioners, and enthusiasts with a\nthorough understanding of user-friendly and relatively small open-sourced\nmodels of large GPTs, their current state, challenges, and future research\ndirections, inspiring the development of more efficient, accessible, and\nversatile GPT models that cater to the broader scientific community and advance\nthe field of general artificial intelligence. The source contents are\ncontinuously updating in https://github.com/GPT-Alternatives/gpt_alternatives."
  },
  {
    "arxiv_id": "2308.14132",
    "title": "Detecting Language Model Attacks with Perplexity",
    "url": "http://arxiv.org/abs/2308.14132v1",
    "abstract": "A novel hack involving Large Language Models (LLMs) has emerged, exploiting\nadversarial suffixes to deceive models into generating perilous responses. Such\njailbreaks can trick LLMs into providing intricate instructions to a malicious\nuser for creating explosives, orchestrating a bank heist, or facilitating the\ncreation of offensive content. By evaluating the perplexity of queries with\nadversarial suffixes using an open-source LLM (GPT-2), we found that they have\nexceedingly high perplexity values. As we explored a broad range of regular\n(non-adversarial) prompt varieties, we concluded that false positives are a\nsignificant challenge for plain perplexity filtering. A Light-GBM trained on\nperplexity and token length resolved the false positives and correctly detected\nmost adversarial attacks in the test set."
  },
  {
    "arxiv_id": "2308.15118",
    "title": "Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills",
    "url": "http://arxiv.org/abs/2308.15118v1",
    "abstract": "While large language models have made strides in natural language processing,\ntheir proficiency in complex reasoning tasks requiring formal language\ncomprehension, such as chess, remains less investigated. This paper probes the\nperformance of ChatGPT, a sophisticated language model by OpenAI in tackling\nsuch complex reasoning tasks, using chess as a case study. Through robust\nmetrics examining both the legality and quality of moves, we assess ChatGPT's\nunderstanding of the chessboard, adherence to chess rules, and strategic\ndecision-making abilities. Our evaluation identifies limitations within\nChatGPT's attention mechanism that affect its formal language comprehension and\nuncovers the model's underdeveloped self-regulation abilities. Our study also\nreveals ChatGPT's propensity for a coherent strategy in its gameplay and a\nnoticeable uptick in decision-making assertiveness when the model is presented\nwith a greater volume of natural language or possesses a more lucid\nunderstanding of the state of the chessboard. These findings contribute to the\ngrowing exploration of language models' abilities beyond natural language\nprocessing, providing valuable information for future research towards models\ndemonstrating human-like cognitive abilities."
  },
  {
    "arxiv_id": "2308.15010",
    "title": "TransPrompt v2: A Transferable Prompting Framework for Cross-task Text Classification",
    "url": "http://arxiv.org/abs/2308.15010v1",
    "abstract": "Text classification is one of the most imperative tasks in natural language\nprocessing (NLP). Recent advances with pre-trained language models (PLMs) have\nshown remarkable success on this task. However, the satisfying results obtained\nby PLMs heavily depend on the large amounts of task-specific labeled data,\nwhich may not be feasible in many application scenarios due to data access and\nprivacy constraints. The recently-proposed prompt-based fine-tuning paradigm\nimproves the performance of PLMs for few-shot text classification with\ntask-specific templates. Yet, it is unclear how the prompting knowledge can be\ntransferred across tasks, for the purpose of mutual reinforcement. We propose\nTransPrompt v2, a novel transferable prompting framework for few-shot learning\nacross similar or distant text classification tasks. For learning across\nsimilar tasks, we employ a multi-task meta-knowledge acquisition (MMA)\nprocedure to train a meta-learner that captures the cross-task transferable\nknowledge. For learning across distant tasks, we further inject the task type\ndescriptions into the prompt, and capture the intra-type and inter-type prompt\nembeddings among multiple distant tasks. Additionally, two de-biasing\ntechniques are further designed to make the trained meta-learner more\ntask-agnostic and unbiased towards any tasks. After that, the meta-learner can\nbe adapted to each specific task with better parameters initialization.\nExtensive experiments show that TransPrompt v2 outperforms single-task and\ncross-task strong baselines over multiple NLP tasks and datasets. We further\nshow that the meta-learner can effectively improve the performance of PLMs on\npreviously unseen tasks. In addition, TransPrompt v2 also outperforms strong\nfine-tuning baselines when learning with full training sets."
  },
  {
    "arxiv_id": "2308.15996",
    "title": "DTrOCR: Decoder-only Transformer for Optical Character Recognition",
    "url": "http://arxiv.org/abs/2308.15996v1",
    "abstract": "Typical text recognition methods rely on an encoder-decoder structure, in\nwhich the encoder extracts features from an image, and the decoder produces\nrecognized text from these features. In this study, we propose a simpler and\nmore effective method for text recognition, known as the Decoder-only\nTransformer for Optical Character Recognition (DTrOCR). This method uses a\ndecoder-only Transformer to take advantage of a generative language model that\nis pre-trained on a large corpus. We examined whether a generative language\nmodel that has been successful in natural language processing can also be\neffective for text recognition in computer vision. Our experiments demonstrated\nthat DTrOCR outperforms current state-of-the-art methods by a large margin in\nthe recognition of printed, handwritten, and scene text in both English and\nChinese."
  },
  {
    "arxiv_id": "2308.15962",
    "title": "WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model",
    "url": "http://arxiv.org/abs/2308.15962v1",
    "abstract": "Enabling robots to understand language instructions and react accordingly to\nvisual perception has been a long-standing goal in the robotics research\ncommunity. Achieving this goal requires cutting-edge advances in natural\nlanguage processing, computer vision, and robotics engineering. Thus, this\npaper mainly investigates the potential of integrating the most recent Large\nLanguage Models (LLMs) and existing visual grounding and robotic grasping\nsystem to enhance the effectiveness of the human-robot interaction. We\nintroduce the WALL-E (Embodied Robotic WAiter load lifting with Large Language\nmodel) as an example of this integration. The system utilizes the LLM of\nChatGPT to summarize the preference object of the users as a target instruction\nvia the multi-round interactive dialogue. The target instruction is then\nforwarded to a visual grounding system for object pose and size estimation,\nfollowing which the robot grasps the object accordingly. We deploy this\nLLM-empowered system on the physical robot to provide a more user-friendly\ninterface for the instruction-guided grasping task. The further experimental\nresults on various real-world scenarios demonstrated the feasibility and\nefficacy of our proposed framework. See the project website at:\nhttps://star-uu-wang.github.io/WALL-E/"
  },
  {
    "arxiv_id": "2308.15517",
    "title": "Document AI: A Comparative Study of Transformer-Based, Graph-Based Models, and Convolutional Neural Networks For Document Layout Analysis",
    "url": "http://arxiv.org/abs/2308.15517v1",
    "abstract": "Document AI aims to automatically analyze documents by leveraging natural\nlanguage processing and computer vision techniques. One of the major tasks of\nDocument AI is document layout analysis, which structures document pages by\ninterpreting the content and spatial relationships of layout, image, and text.\nThis task can be image-centric, wherein the aim is to identify and label\nvarious regions such as authors and paragraphs, or text-centric, where the\nfocus is on classifying individual words in a document. Although there are\nincreasingly sophisticated methods for improving layout analysis, doubts remain\nabout the extent to which their findings can be generalized to a broader\ncontext. Specifically, prior work developed systems based on very different\narchitectures, such as transformer-based, graph-based, and CNNs. However, no\nwork has mentioned the effectiveness of these models in a comparative analysis.\nMoreover, while language-independent Document AI models capable of knowledge\ntransfer have been developed, it remains to be investigated to what degree they\ncan effectively transfer knowledge. In this study, we aim to fill these gaps by\nconducting a comparative evaluation of state-of-the-art models in document\nlayout analysis and investigating the potential of cross-lingual layout\nanalysis by utilizing machine translation techniques."
  },
  {
    "arxiv_id": "2308.16911",
    "title": "PointLLM: Empowering Large Language Models to Understand Point Clouds",
    "url": "http://arxiv.org/abs/2308.16911v1",
    "abstract": "The unprecedented advancements in Large Language Models (LLMs) have shown a\nprofound impact on natural language processing but are yet to fully embrace the\nrealm of 3D understanding. This paper introduces PointLLM, a preliminary effort\nto fill this gap, enabling LLMs to understand point clouds and offering a new\navenue beyond 2D visual data. PointLLM understands colored object point clouds\nwith human instructions and generates contextually appropriate responses,\nillustrating its grasp of point clouds and common sense. Specifically, it\nleverages a point cloud encoder with a powerful LLM to effectively fuse\ngeometric, appearance, and linguistic information. We collect a novel dataset\ncomprising 660K simple and 70K complex point-text instruction pairs to enable a\ntwo-stage training strategy: aligning latent spaces and subsequently\ninstruction-tuning the unified model. To rigorously evaluate the perceptual and\ngeneralization capabilities of PointLLM, we establish two benchmarks:\nGenerative 3D Object Classification and 3D Object Captioning, assessed through\nthree different methods, including human evaluation, GPT-4/ChatGPT evaluation,\nand traditional metrics. Experimental results reveal PointLLM's superior\nperformance over existing 2D and 3D baselines, with a notable achievement in\nhuman-evaluated object captioning tasks where it surpasses human annotators in\nover 50% of the samples. Codes, datasets, and benchmarks are available at\nhttps://github.com/OpenRobotLab/PointLLM ."
  },
  {
    "arxiv_id": "2308.16688",
    "title": "Using Large Language Models to Automate Category and Trend Analysis of Scientific Articles: An Application in Ophthalmology",
    "url": "http://arxiv.org/abs/2308.16688v1",
    "abstract": "Purpose: In this paper, we present an automated method for article\nclassification, leveraging the power of Large Language Models (LLM). The\nprimary focus is on the field of ophthalmology, but the model is extendable to\nother fields. Methods: We have developed a model based on Natural Language\nProcessing (NLP) techniques, including advanced LLMs, to process and analyze\nthe textual content of scientific papers. Specifically, we have employed\nzero-shot learning (ZSL) LLM models and compared against Bidirectional and\nAuto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder\nRepresentations from Transformers (BERT), and its variant such as distilBERT,\nSciBERT, PubmedBERT, BioBERT. Results: The classification results demonstrate\nthe effectiveness of LLMs in categorizing large number of ophthalmology papers\nwithout human intervention. Results: To evalute the LLMs, we compiled a dataset\n(RenD) of 1000 ocular disease-related articles, which were expertly annotated\nby a panel of six specialists into 15 distinct categories. The model achieved\nmean accuracy of 0.86 and mean F1 of 0.85 based on the RenD dataset.\nConclusion: The proposed framework achieves notable improvements in both\naccuracy and efficiency. Its application in the domain of ophthalmology\nshowcases its potential for knowledge organization and retrieval in other\ndomains too. We performed trend analysis that enables the researchers and\nclinicians to easily categorize and retrieve relevant papers, saving time and\neffort in literature review and information gathering as well as identification\nof emerging scientific trends within different disciplines. Moreover, the\nextendibility of the model to other scientific fields broadens its impact in\nfacilitating research and trend analysis across diverse disciplines."
  },
  {
    "arxiv_id": "2308.16259",
    "title": "Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction",
    "url": "http://arxiv.org/abs/2308.16259v1",
    "abstract": "Recently, the remarkable capabilities of large language models (LLMs) have\nbeen illustrated across a variety of research domains such as natural language\nprocessing, computer vision, and molecular modeling. We extend this paradigm by\nutilizing LLMs for material property prediction by introducing our model\nMaterials Informatics Transformer (MatInFormer). Specifically, we introduce a\nnovel approach that involves learning the grammar of crystallography through\nthe tokenization of pertinent space group information. We further illustrate\nthe adaptability of MatInFormer by incorporating task-specific data pertaining\nto Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover\nthe key features that the model prioritizes during property prediction. The\neffectiveness of our proposed model is empirically validated across 14 distinct\ndatasets, hereby underscoring its potential for high throughput screening\nthrough accurate material property prediction."
  },
  {
    "arxiv_id": "2309.00240",
    "title": "FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking",
    "url": "http://arxiv.org/abs/2309.00240v1",
    "abstract": "Automatic fact-checking plays a crucial role in combating the spread of\nmisinformation. Large Language Models (LLMs) and Instruction-Following\nvariants, such as InstructGPT and Alpaca, have shown remarkable performance in\nvarious natural language processing tasks. However, their knowledge may not\nalways be up-to-date or sufficient, potentially leading to inaccuracies in\nfact-checking. To address this limitation, we propose combining the power of\ninstruction-following language models with external evidence retrieval to\nenhance fact-checking performance. Our approach involves leveraging search\nengines to retrieve relevant evidence for a given input claim. This external\nevidence serves as valuable supplementary information to augment the knowledge\nof the pretrained language model. Then, we instruct-tune an open-sourced\nlanguage model, called LLaMA, using this evidence, enabling it to predict the\nveracity of the input claim more accurately. To evaluate our method, we\nconducted experiments on two widely used fact-checking datasets: RAWFC and\nLIAR. The results demonstrate that our approach achieves state-of-the-art\nperformance in fact-checking tasks. By integrating external evidence, we bridge\nthe gap between the model's knowledge and the most up-to-date and sufficient\ncontext available, leading to improved fact-checking outcomes. Our findings\nhave implications for combating misinformation and promoting the dissemination\nof accurate information on online platforms. Our released materials are\naccessible at: https://thcheung.github.io/factllama."
  },
  {
    "arxiv_id": "2309.02045",
    "title": "Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies",
    "url": "http://arxiv.org/abs/2309.02045v1",
    "abstract": "Large Language Models (LLMs) have made significant strides in both scientific\nresearch and practical applications. Existing studies have demonstrated the\nstate-of-the-art (SOTA) performance of LLMs in various natural language\nprocessing tasks. However, the question of how to further enhance LLMs'\nperformance in specific task using prompting strategies remains a pivotal\nconcern. This paper explores the enhancement of LLMs' performance in sentiment\nanalysis through the application of prompting strategies. We formulate the\nprocess of prompting for sentiment analysis tasks and introduce two novel\nstrategies tailored for sentiment analysis: RolePlaying (RP) prompting and\nChain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT\nprompting strategy which is a combination of RP prompting and CoT prompting. We\nconduct comparative experiments on three distinct domain datasets to evaluate\nthe effectiveness of the proposed sentiment analysis strategies. The results\ndemonstrate that the adoption of the proposed prompting strategies leads to a\nincreasing enhancement in sentiment analysis accuracy. Further, the CoT\nprompting strategy exhibits a notable impact on implicit sentiment analysis,\nwith the RP-CoT prompting strategy delivering the most superior performance\namong all strategies."
  },
  {
    "arxiv_id": "2309.01715",
    "title": "Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction",
    "url": "http://arxiv.org/abs/2309.01715v1",
    "abstract": "Taxonomies represent hierarchical relations between entities, frequently\napplied in various software modeling and natural language processing (NLP)\nactivities. They are typically subject to a set of structural constraints\nrestricting their content. However, manual taxonomy construction can be\ntime-consuming, incomplete, and costly to maintain. Recent studies of large\nlanguage models (LLMs) have demonstrated that appropriate user inputs (called\nprompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks\nwithout explicit (re-)training. However, existing approaches for automated\ntaxonomy construction typically involve fine-tuning a language model by\nadjusting model parameters. In this paper, we present a general framework for\ntaxonomy construction that takes into account structural constraints. We\nsubsequently conduct a systematic comparison between the prompting and\nfine-tuning approaches performed on a hypernym taxonomy and a novel computer\nscience taxonomy dataset. Our result reveals the following: (1) Even without\nexplicit training on the dataset, the prompting approach outperforms\nfine-tuning-based approaches. Moreover, the performance gap between prompting\nand fine-tuning widens when the training dataset is small. However, (2)\ntaxonomies generated by the fine-tuning approach can be easily post-processed\nto satisfy all the constraints, whereas handling violations of the taxonomies\nproduced by the prompting approach can be challenging. These evaluation\nfindings provide guidance on selecting the appropriate method for taxonomy\nconstruction and highlight potential enhancements for both approaches."
  },
  {
    "arxiv_id": "2309.01538",
    "title": "ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning",
    "url": "http://arxiv.org/abs/2309.01538v1",
    "abstract": "Logical rules are essential for uncovering the logical connections between\nrelations, which could improve reasoning performance and provide interpretable\nresults on knowledge graphs (KGs). Although there have been many efforts to\nmine meaningful logical rules over KGs, existing methods suffer from\ncomputationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, the ranked rules can be used to\nconduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,\nw.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method."
  },
  {
    "arxiv_id": "2309.01157",
    "title": "Large Language Models for Generative Recommendation: A Survey and Visionary Discussions",
    "url": "http://arxiv.org/abs/2309.01157v1",
    "abstract": "Large language models (LLM) not only have revolutionized the field of natural\nlanguage processing (NLP) but also have the potential to reshape many other\nfields, e.g., recommender systems (RS). However, most of the related work\ntreats an LLM as a component of the conventional recommendation pipeline (e.g.,\nas a feature extractor), which may not be able to fully leverage the generative\npower of LLM. Instead of separating the recommendation process into multiple\nstages, such as score computation and re-ranking, this process can be\nsimplified to one stage with LLM: directly generating recommendations from the\ncomplete pool of items. This survey reviews the progress, methods, and future\ndirections of LLM-based generative recommendation by examining three questions:\n1) What generative recommendation is, 2) Why RS should advance to generative\nrecommendation, and 3) How to implement LLM-based generative recommendation for\nvarious RS tasks. We hope that this survey can provide the context and guidance\nneeded to explore this interesting and emerging topic."
  },
  {
    "arxiv_id": "2309.02902",
    "title": "ViCGCN: Graph Convolutional Network with Contextualized Language Models for Social Media Mining in Vietnamese",
    "url": "http://arxiv.org/abs/2309.02902v1",
    "abstract": "Social media processing is a fundamental task in natural language processing\nwith numerous applications. As Vietnamese social media and information science\nhave grown rapidly, the necessity of information-based mining on Vietnamese\nsocial media has become crucial. However, state-of-the-art research faces\nseveral significant drawbacks, including imbalanced data and noisy data on\nsocial media platforms. Imbalanced and noisy are two essential issues that need\nto be addressed in Vietnamese social media texts. Graph Convolutional Networks\ncan address the problems of imbalanced and noisy data in text classification on\nsocial media by taking advantage of the graph structure of the data. This study\npresents a novel approach based on contextualized language model (PhoBERT) and\ngraph-based method (Graph Convolutional Networks). In particular, the proposed\napproach, ViCGCN, jointly trained the power of Contextualized embeddings with\nthe ability of Graph Convolutional Networks, GCN, to capture more syntactic and\nsemantic dependencies to address those drawbacks. Extensive experiments on\nvarious Vietnamese benchmark datasets were conducted to verify our approach.\nThe observation shows that applying GCN to BERTology models as the final layer\nsignificantly improves performance. Moreover, the experiments demonstrate that\nViCGCN outperforms 13 powerful baseline models, including BERTology models,\nfusion BERTology and GCN models, other baselines, and SOTA on three benchmark\nsocial media datasets. Our proposed ViCGCN approach demonstrates a significant\nimprovement of up to 6.21%, 4.61%, and 2.63% over the best Contextualized\nLanguage Models, including multilingual and monolingual, on three benchmark\ndatasets, UIT-VSMEC, UIT-ViCTSD, and UIT-VSFC, respectively. Additionally, our\nintegrated model ViCGCN achieves the best performance compared to other\nBERTology integrated with GCN models."
  },
  {
    "arxiv_id": "2309.02884",
    "title": "Aligning Large Language Models for Clinical Tasks",
    "url": "http://arxiv.org/abs/2309.02884v2",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable adaptability,\nshowcasing their capacity to excel in tasks for which they were not explicitly\ntrained. However, despite their impressive natural language processing (NLP)\ncapabilities, effective alignment of LLMs remains a crucial challenge when\ndeploying them for specific clinical applications. The ability to generate\nresponses with factually accurate content and to engage in non-trivial\nreasoning steps are crucial for the LLMs to be eligible for applications in\nclinical medicine. Employing a combination of techniques including\ninstruction-tuning and in-prompt strategies like few-shot and chain-of-thought\nprompting has significantly enhanced the performance of LLMs. Our proposed\nalignment strategy for medical question-answering, known as\n'expand-guess-refine', offers a parameter and data-efficient solution. A\npreliminary analysis of this method demonstrated outstanding performance,\nachieving a score of 70.63% on a subset of questions sourced from the USMLE\ndataset."
  },
  {
    "arxiv_id": "2309.03797",
    "title": "Conformal Autoregressive Generation: Beam Search with Coverage Guarantees",
    "url": "http://arxiv.org/abs/2309.03797v1",
    "abstract": "We introduce two new extensions to the beam search algorithm based on\nconformal predictions (CP) to produce sets of sequences with theoretical\ncoverage guarantees. The first method is very simple and proposes\ndynamically-sized subsets of beam search results but, unlike typical CP\nprocedures, has an upper bound on the achievable guarantee depending on a\npost-hoc calibration measure. Our second algorithm introduces the conformal set\nprediction procedure as part of the decoding process, producing a variable beam\nwidth which adapts to the current uncertainty. While more complex, this\nprocedure can achieve coverage guarantees selected a priori. We provide\nmarginal coverage bounds for each method, and evaluate them empirically on a\nselection of tasks drawing from natural language processing and chemistry."
  },
  {
    "arxiv_id": "2309.03787",
    "title": "USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset",
    "url": "http://arxiv.org/abs/2309.03787v1",
    "abstract": "Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis."
  },
  {
    "arxiv_id": "2309.04354",
    "title": "Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts",
    "url": "http://arxiv.org/abs/2309.04354v1",
    "abstract": "Sparse Mixture-of-Experts models (MoEs) have recently gained popularity due\nto their ability to decouple model size from inference efficiency by only\nactivating a small subset of the model parameters for any given input token. As\nsuch, sparse MoEs have enabled unprecedented scalability, resulting in\ntremendous successes across domains such as natural language processing and\ncomputer vision. In this work, we instead explore the use of sparse MoEs to\nscale-down Vision Transformers (ViTs) to make them more attractive for\nresource-constrained vision applications. To this end, we propose a simplified\nand mobile-friendly MoE design where entire images rather than individual\npatches are routed to the experts. We also propose a stable MoE training\nprocedure that uses super-class information to guide the router. We empirically\nshow that our sparse Mobile Vision MoEs (V-MoEs) can achieve a better trade-off\nbetween performance and efficiency than the corresponding dense ViTs. For\nexample, for the ViT-Tiny model, our Mobile V-MoE outperforms its dense\ncounterpart by 3.39% on ImageNet-1k. For an even smaller ViT variant with only\n54M FLOPs inference cost, our MoE achieves an improvement of 4.66%."
  },
  {
    "arxiv_id": "2309.04292",
    "title": "Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations",
    "url": "http://arxiv.org/abs/2309.04292v1",
    "abstract": "Fuzzy Fingerprints have been successfully used as an interpretable text\nclassification technique, but, like most other techniques, have been largely\nsurpassed in performance by Large Pre-trained Language Models, such as BERT or\nRoBERTa. These models deliver state-of-the-art results in several Natural\nLanguage Processing tasks, namely Emotion Recognition in Conversations (ERC),\nbut suffer from the lack of interpretability and explainability. In this paper,\nwe propose to combine the two approaches to perform ERC, as a means to obtain\nsimpler and more interpretable Large Language Models-based classifiers. We\npropose to feed the utterances and their previous conversational turns to a\npre-trained RoBERTa, obtaining contextual embedding utterance representations,\nthat are then supplied to an adapted Fuzzy Fingerprint classification module.\nWe validate our approach on the widely used DailyDialog ERC benchmark dataset,\nin which we obtain state-of-the-art level results using a much lighter model."
  },
  {
    "arxiv_id": "2309.04255",
    "title": "LLMCad: Fast and Scalable On-device Large Language Model Inference",
    "url": "http://arxiv.org/abs/2309.04255v1",
    "abstract": "Generative tasks, such as text generation and question answering, hold a\ncrucial position in the realm of mobile applications. Due to their sensitivity\nto privacy concerns, there is a growing demand for their execution directly on\nmobile devices. Currently, the execution of these generative tasks heavily\ndepends on Large Language Models (LLMs). Nevertheless, the limited memory\ncapacity of these devices presents a formidable challenge to the scalability of\nsuch models.\n  In our research, we introduce LLMCad, an innovative on-device inference\nengine specifically designed for efficient generative Natural Language\nProcessing (NLP) tasks. The core idea behind LLMCad revolves around model\ncollaboration: a compact LLM, residing in memory, takes charge of generating\nthe most straightforward tokens, while a high-precision LLM steps in to\nvalidate these tokens and rectify any identified errors. LLMCad incorporates\nthree novel techniques: (1) Instead of generating candidate tokens in a\nsequential manner, LLMCad employs the smaller LLM to construct a token tree,\nencompassing a wider range of plausible token pathways. Subsequently, the\nlarger LLM can efficiently validate all of these pathways simultaneously. (2)\nIt employs a self-adjusting fallback strategy, swiftly initiating the\nverification process whenever the smaller LLM generates an erroneous token. (3)\nTo ensure a continuous flow of token generation, LLMCad speculatively generates\ntokens during the verification process by implementing a compute-IO pipeline.\nThrough an extensive series of experiments, LLMCad showcases an impressive\ntoken generation speed, achieving rates up to 9.3x faster than existing\ninference engines."
  },
  {
    "arxiv_id": "2309.04175",
    "title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese",
    "url": "http://arxiv.org/abs/2309.04175v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in diverse\nnatural language processing (NLP) tasks in general domains. However, LLMs\nsometimes generate responses with the hallucination about medical facts due to\nlimited domain knowledge. Such shortcomings pose potential risks in the\nutilization of LLMs within medical contexts. To address this challenge, we\npropose knowledge-tuning, which leverages structured medical knowledge bases\nfor the LLMs to grasp domain knowledge efficiently and facilitate reliable\nresponse generation. We also release cMedKnowQA, a Chinese medical knowledge\nquestion-answering dataset constructed from medical knowledge bases to assess\nthe medical knowledge proficiency of LLMs. Experimental results show that the\nLLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of\naccuracy in response generation compared with vanilla instruction-tuning and\noffer a new reliable way for the domain adaptation of LLMs."
  },
  {
    "arxiv_id": "2309.05501",
    "title": "Black-Box Analysis: GPTs Across Time in Legal Textual Entailment Task",
    "url": "http://arxiv.org/abs/2309.05501v1",
    "abstract": "The evolution of Generative Pre-trained Transformer (GPT) models has led to\nsignificant advancements in various natural language processing applications,\nparticularly in legal textual entailment. We present an analysis of GPT-3.5\n(ChatGPT) and GPT-4 performances on COLIEE Task 4 dataset, a prominent\nbenchmark in this domain. The study encompasses data from Heisei 18 (2006) to\nReiwa 3 (2021), exploring the models' abilities to discern entailment\nrelationships within Japanese statute law across different periods. Our\npreliminary experimental results unveil intriguing insights into the models'\nstrengths and weaknesses in handling legal textual entailment tasks, as well as\nthe patterns observed in model performance. In the context of proprietary\nmodels with undisclosed architectures and weights, black-box analysis becomes\ncrucial for evaluating their capabilities. We discuss the influence of training\ndata distribution and the implications on the models' generalizability. This\nanalysis serves as a foundation for future research, aiming to optimize\nGPT-based models and enable their successful adoption in legal information\nextraction and entailment applications."
  },
  {
    "arxiv_id": "2309.05248",
    "title": "Enhancing Speaker Diarization with Large Language Models: A Contextual Beam Search Approach",
    "url": "http://arxiv.org/abs/2309.05248v1",
    "abstract": "Large language models (LLMs) have shown great promise for capturing\ncontextual information in natural language processing tasks. We propose a novel\napproach to speaker diarization that incorporates the prowess of LLMs to\nexploit contextual cues in human dialogues. Our method builds upon an\nacoustic-based speaker diarization system by adding lexical information from an\nLLM in the inference stage. We model the multi-modal decoding process\nprobabilistically and perform joint acoustic and lexical beam search to\nincorporate cues from both modalities: audio and text. Our experiments\ndemonstrate that infusing lexical knowledge from the LLM into an acoustics-only\ndiarization system improves overall speaker-attributed word error rate\n(SA-WER). The experimental results show that LLMs can provide complementary\ninformation to acoustic models for the speaker diarization task via proposed\nbeam search decoding approach showing up to 39.8% relative delta-SA-WER\nimprovement from the baseline system. Thus, we substantiate that the proposed\ntechnique is able to exploit contextual information that is inaccessible to\nacoustics-only systems which is represented by speaker embeddings. In addition,\nthese findings point to the potential of using LLMs to improve speaker\ndiarization and other speech processing tasks by capturing semantic and\ncontextual cues."
  },
  {
    "arxiv_id": "2309.05173",
    "title": "DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning",
    "url": "http://arxiv.org/abs/2309.05173v1",
    "abstract": "Prompt tuning (PT), where a small amount of trainable soft (continuous)\nprompt vectors is affixed to the input of language models (LM), has shown\npromising results across various tasks and models for parameter-efficient\nfine-tuning (PEFT). PT stands out from other PEFT approaches because it\nmaintains competitive performance with fewer trainable parameters and does not\ndrastically scale up its parameters as the model size expands. However, PT\nintroduces additional soft prompt tokens, leading to longer input sequences,\nwhich significantly impacts training and inference time and memory usage due to\nthe Transformer's quadratic complexity. Particularly concerning for Large\nLanguage Models (LLMs) that face heavy daily querying. To address this issue,\nwe propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt\ninto a shorter soft prompt and a pair of low-rank matrices that are then\noptimised with two different learning rates. This allows DePT to achieve better\nperformance while saving substantial memory and time costs compared to vanilla\nPT and its variants, without changing trainable parameter sizes. Through\nextensive experiments on 23 natural language processing (NLP) and\nvision-language (VL) tasks, we demonstrate that DePT outperforms\nstate-of-the-art PEFT approaches, including the full fine-tuning baseline, in\nsome scenarios. Additionally, we empirically show that DEPT grows more\nefficient as the model size increases. Our further study reveals that DePT\nintegrates seamlessly with parameter-efficient transfer learning in the\nfew-shot learning setting and highlights its adaptability to various model\narchitectures and sizes."
  },
  {
    "arxiv_id": "2309.04842",
    "title": "Leveraging Large Language Models for Exploiting ASR Uncertainty",
    "url": "http://arxiv.org/abs/2309.04842v1",
    "abstract": "While large language models excel in a variety of natural language processing\n(NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they\nmust either rely on off-the-shelf automatic speech recognition (ASR) systems\nfor transcription, or be equipped with an in-built speech modality. This work\nfocuses on the former scenario, where LLM's accuracy on SLU tasks is\nconstrained by the accuracy of a fixed ASR system on the spoken input.\nSpecifically, we tackle speech-intent classification task, where a high\nword-error-rate can limit the LLM's ability to understand the spoken intent.\nInstead of chasing a high accuracy by designing complex or specialized\narchitectures regardless of deployment costs, we seek to answer how far we can\ngo without substantially changing the underlying ASR and LLM, which can\npotentially be shared by multiple unrelated tasks. To this end, we propose\nprompting the LLM with an n-best list of ASR hypotheses instead of only the\nerror-prone 1-best hypothesis. We explore prompt-engineering to explain the\nconcept of n-best lists to the LLM; followed by the finetuning of Low-Rank\nAdapters on the downstream tasks. Our approach using n-best lists proves to be\neffective on a device-directed speech detection task as well as on a keyword\nspotting task, where systems using n-best list prompts outperform those using\n1-best ASR hypothesis; thus paving the way for an efficient method to exploit\nASR uncertainty via LLMs for speech-based applications."
  },
  {
    "arxiv_id": "2309.06706",
    "title": "Simultaneous Machine Translation with Large Language Models",
    "url": "http://arxiv.org/abs/2309.06706v1",
    "abstract": "Real-world simultaneous machine translation (SimulMT) systems face more\nchallenges than just the quality-latency trade-off. They also need to address\nissues related to robustness with noisy input, processing long contexts, and\nflexibility for knowledge injection. These challenges demand models with strong\nlanguage understanding and generation capabilities which may not often equipped\nby dedicated MT models. In this paper, we investigate the possibility of\napplying Large Language Models (LLM) to SimulMT tasks by using existing\nincremental-decoding methods with a newly proposed RALCP algorithm for latency\nreduction. We conducted experiments using the \\texttt{Llama2-7b-chat} model on\nnine different languages from the MUST-C dataset. The results show that LLM\noutperforms dedicated MT models in terms of BLEU and LAAL metrics. Further\nanalysis indicates that LLM has advantages in terms of tuning efficiency and\nrobustness. However, it is important to note that the computational cost of LLM\nremains a significant obstacle to its application in SimulMT.\\footnote{We will\nrelease our code, weights, and data with publication.}"
  },
  {
    "arxiv_id": "2309.06453",
    "title": "Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model",
    "url": "http://arxiv.org/abs/2309.06453v1",
    "abstract": "Sentence Representation Learning (SRL) is a fundamental task in Natural\nLanguage Processing (NLP), with the Contrastive Learning of Sentence Embeddings\n(CSE) being the mainstream technique due to its superior performance. An\nintriguing phenomenon in CSE is the significant performance gap between\nsupervised and unsupervised methods, with their only difference lying in the\ntraining data. Previous works attribute this performance gap to differences in\ntwo representation properties (alignment and uniformity). However, since\nalignment and uniformity only measure the results, they fail to answer \"What\naspects of the training data contribute to the performance gap?\" and \"How can\nthe performance gap be narrowed?\", In this paper, we conduct empirical\nexperiments to answer these \"What\" and \"How\" questions. We first answer the\n\"What\" question by thoroughly comparing the behavior of supervised and\nunsupervised CSE during their respective training processes. From the\ncomparison, we identify the similarity pattern as a key factor to the\nperformance gap, and introduce a metric, called Relative Fitting Difficulty\n(RFD), to measure the complexity of the similarity pattern. Then, based on the\ninsights gained from the \"What\" question, we tackle the \"How\" question by\nincreasing the pattern complexity of the training data. We achieve this by\nleveraging the In-Context Learning (ICL) capability of the Large Language Model\n(LLM) to generate data that simulates complex patterns. By utilizing the\nhierarchical patterns in the LLM-generated data, we effectively narrow the gap\nbetween supervised and unsupervised CSE. We release our codes and appendix at\nhttps://github.com/BDBC-KG-NLP/NGCSE."
  },
  {
    "arxiv_id": "2309.07755",
    "title": "Generative AI Text Classification using Ensemble LLM Approaches",
    "url": "http://arxiv.org/abs/2309.07755v1",
    "abstract": "Large Language Models (LLMs) have shown impressive performance across a\nvariety of Artificial Intelligence (AI) and natural language processing tasks,\nsuch as content creation, report generation, etc. However, unregulated malign\napplication of these models can create undesirable consequences such as\ngeneration of fake news, plagiarism, etc. As a result, accurate detection of\nAI-generated language can be crucial in responsible usage of LLMs. In this\nwork, we explore 1) whether a certain body of text is AI generated or written\nby human, and 2) attribution of a specific language model in generating a body\nof text. Texts in both English and Spanish are considered. The datasets used in\nthis study are provided as part of the Automated Text Identification\n(AuTexTification) shared task. For each of the research objectives stated\nabove, we propose an ensemble neural model that generates probabilities from\ndifferent pre-trained LLMs which are used as features to a Traditional Machine\nLearning (TML) classifier following it. For the first task of distinguishing\nbetween AI and human generated text, our model ranked in fifth and thirteenth\nplace (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish\ntexts, respectively. For the second task on model attribution, our model ranked\nin first place with macro $F1$ scores of 0.625 and 0.653 for English and\nSpanish texts, respectively."
  },
  {
    "arxiv_id": "2309.07462",
    "title": "Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?",
    "url": "http://arxiv.org/abs/2309.07462v1",
    "abstract": "Large Language Models (LLMs) excel in various Natural Language Processing\n(NLP) tasks, yet their evaluation, particularly in languages beyond the top\n$20$, remains inadequate due to existing benchmarks and metrics limitations.\nEmploying LLMs as evaluators to rank or score other models' outputs emerges as\na viable solution, addressing the constraints tied to human annotators and\nestablished benchmarks. In this study, we explore the potential of LLM-based\nevaluators, specifically GPT-4 in enhancing multilingual evaluation by\ncalibrating them against $20$K human judgments across three text-generation\ntasks, five metrics, and eight languages. Our analysis reveals a bias in\nGPT4-based evaluators towards higher scores, underscoring the necessity of\ncalibration with native speaker judgments, especially in low-resource and\nnon-Latin script languages, to ensure accurate evaluation of LLM performance\nacross diverse languages."
  },
  {
    "arxiv_id": "2309.07430",
    "title": "Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts",
    "url": "http://arxiv.org/abs/2309.07430v1",
    "abstract": "Analyzing vast textual data and summarizing key information from electronic\nhealth records imposes a substantial burden on how clinicians allocate their\ntime. Although large language models (LLMs) have shown promise in natural\nlanguage processing (NLP), their effectiveness on a diverse range of clinical\nsummarization tasks remains unproven. In this study, we apply adaptation\nmethods to eight LLMs, spanning four distinct clinical summarization tasks:\nradiology reports, patient questions, progress notes, and doctor-patient\ndialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP\nmetrics reveal trade-offs between models and adaptation methods. A clinical\nreader study with ten physicians evaluates summary completeness, correctness,\nand conciseness; in a majority of cases, summaries from our best adapted LLMs\nare either equivalent (45%) or superior (36%) compared to summaries from\nmedical experts. The ensuing safety analysis highlights challenges faced by\nboth LLMs and medical experts, as we connect errors to potential medical harm\nand categorize types of fabricated information. Our research provides evidence\nof LLMs outperforming medical experts in clinical text summarization across\nmultiple tasks. This suggests that integrating LLMs into clinical workflows\ncould alleviate documentation burden, allowing clinicians to focus more on\npatient care."
  },
  {
    "arxiv_id": "2309.07315",
    "title": "Traveling Words: A Geometric Interpretation of Transformers",
    "url": "http://arxiv.org/abs/2309.07315v1",
    "abstract": "Transformers have significantly advanced the field of natural language\nprocessing, but comprehending their internal mechanisms remains a challenge. In\nthis paper, we introduce a novel geometric perspective that elucidates the\ninner mechanisms of transformer operations. Our primary contribution is\nillustrating how layer normalization confines the latent features to a\nhyper-sphere, subsequently enabling attention to mold the semantic\nrepresentation of words on this surface. This geometric viewpoint seamlessly\nconnects established properties such as iterative refinement and contextual\nembeddings. We validate our insights by probing a pre-trained 124M parameter\nGPT-2 model. Our findings reveal clear query-key attention patterns in early\nlayers and build upon prior observations regarding the subject-specific nature\nof attention heads at deeper layers. Harnessing these geometric insights, we\npresent an intuitive understanding of transformers, depicting them as processes\nthat model the trajectory of word particles along the hyper-sphere."
  },
  {
    "arxiv_id": "2309.08474",
    "title": "VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model",
    "url": "http://arxiv.org/abs/2309.08474v1",
    "abstract": "This paper presents VulnSense framework, a comprehensive approach to\nefficiently detect vulnerabilities in Ethereum smart contracts using a\nmultimodal learning approach on graph-based and natural language processing\n(NLP) models. Our proposed framework combines three types of features from\nsmart contracts comprising source code, opcode sequences, and control flow\ngraph (CFG) extracted from bytecode. We employ Bidirectional Encoder\nRepresentations from Transformers (BERT), Bidirectional Long Short-Term Memory\n(BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these\nfeatures. The final layer of our multimodal approach consists of a fully\nconnected layer used to predict vulnerabilities in Ethereum smart contracts.\nAddressing limitations of existing vulnerability detection methods relying on\nsingle-feature or single-model deep learning techniques, our method surpasses\naccuracy and effectiveness constraints. We assess VulnSense using a collection\nof 1.769 smart contracts derived from the combination of three datasets:\nCurated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with\nvarious unimodal and multimodal learning techniques contributed by GNN, BiLSTM\nand BERT architectures. The experimental outcomes demonstrate the superior\nperformance of our proposed approach, achieving an average accuracy of 77.96\\%\nacross all three categories of vulnerable smart contracts."
  },
  {
    "arxiv_id": "2309.08221",
    "title": "Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study",
    "url": "http://arxiv.org/abs/2309.08221v1",
    "abstract": "Code review is an essential activity for ensuring the quality and\nmaintainability of software projects. However, it is a time-consuming and often\nerror-prone task that can significantly impact the development process.\nRecently, ChatGPT, a cutting-edge language model, has demonstrated impressive\nperformance in various natural language processing tasks, suggesting its\npotential to automate code review processes. However, it is still unclear how\nwell ChatGPT performs in code review tasks. To fill this gap, in this paper, we\nconduct the first empirical study to understand the capabilities of ChatGPT in\ncode review tasks, specifically focusing on automated code refinement based on\ngiven code reviews. To conduct the study, we select the existing benchmark\nCodeReview and construct a new code review dataset with high quality. We use\nCodeReviewer, a state-of-the-art code review tool, as a baseline for comparison\nwith ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code\nrefinement tasks. Specifically, our results show that ChatGPT achieves higher\nEM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art\nmethod achieves only 15.50 and 62.88 on a high-quality code review dataset. We\nfurther identify the root causes for ChatGPT's underperformance and propose\nseveral strategies to mitigate these challenges. Our study provides insights\ninto the potential of ChatGPT in automating the code review process, and\nhighlights the potential research directions."
  },
  {
    "arxiv_id": "2309.08008",
    "title": "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing",
    "url": "http://arxiv.org/abs/2309.08008v1",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in Natural\nLanguage Processing (NLP), especially in domains where labeled data is scarce\nor expensive, such as clinical domain. However, to unlock the clinical\nknowledge hidden in these LLMs, we need to design effective prompts that can\nguide them to perform specific clinical NLP tasks without any task-specific\ntraining data. This is known as in-context learning, which is an art and\nscience that requires understanding the strengths and weaknesses of different\nLLMs and prompt engineering approaches. In this paper, we present a\ncomprehensive and systematic experimental study on prompt engineering for five\nclinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence\nExtraction, Coreference Resolution, Medication Status Extraction, and\nMedication Attribute Extraction. We assessed the prompts proposed in recent\nliterature, including simple prefix, simple cloze, chain of thought, and\nanticipatory prompts, and introduced two new types of prompts, namely heuristic\nprompting and ensemble prompting. We evaluated the performance of these prompts\non three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted\nzero-shot prompting with few-shot prompting, and provide novel insights and\nguidelines for prompt engineering for LLMs in clinical NLP. To the best of our\nknowledge, this is one of the first works on the empirical evaluation of\ndifferent prompt engineering approaches for clinical NLP in this era of\ngenerative AI, and we hope that it will inspire and inform future research in\nthis area."
  },
  {
    "arxiv_id": "2309.09431",
    "title": "FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised Pre-Training",
    "url": "http://arxiv.org/abs/2309.09431v1",
    "abstract": "Hyperspectral images (HSIs) contain rich spectral and spatial information.\nMotivated by the success of transformers in the field of natural language\nprocessing and computer vision where they have shown the ability to learn long\nrange dependencies within input data, recent research has focused on using\ntransformers for HSIs. However, current state-of-the-art hyperspectral\ntransformers only tokenize the input HSI sample along the spectral dimension,\nresulting in the under-utilization of spatial information. Moreover,\ntransformers are known to be data-hungry and their performance relies heavily\non large-scale pretraining, which is challenging due to limited annotated\nhyperspectral data. Therefore, the full potential of HSI transformers has not\nbeen fully realized. To overcome these limitations, we propose a novel\nfactorized spectral-spatial transformer that incorporates factorized\nself-supervised pretraining procedures, leading to significant improvements in\nperformance. The factorization of the inputs allows the spectral and spatial\ntransformers to better capture the interactions within the hyperspectral data\ncubes. Inspired by masked image modeling pretraining, we also devise efficient\nmasking strategies for pretraining each of the spectral and spatial\ntransformers. We conduct experiments on six publicly available datasets for HSI\nclassification task and demonstrate that our model achieves state-of-the-art\nperformance in all the datasets. The code for our model will be made available\nat https://github.com/csiro-robotics/factoformer."
  },
  {
    "arxiv_id": "2309.09400",
    "title": "CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages",
    "url": "http://arxiv.org/abs/2309.09400v1",
    "abstract": "The driving factors behind the development of large language models (LLMs)\nwith impressive learning capabilities are their colossal model sizes and\nextensive training datasets. Along with the progress in natural language\nprocessing, LLMs have been frequently made accessible to the public to foster\ndeeper investigation and applications. However, when it comes to training\ndatasets for these LLMs, especially the recent state-of-the-art models, they\nare often not fully disclosed. Creating training data for high-performing LLMs\ninvolves extensive cleaning and deduplication to ensure the necessary level of\nquality. The lack of transparency for training data has thus hampered research\non attributing and addressing hallucination and bias issues in LLMs, hindering\nreplication efforts and further advancements in the community. These challenges\nbecome even more pronounced in multilingual learning scenarios, where the\navailable multilingual text datasets are often inadequately collected and\ncleaned. Consequently, there is a lack of open-source and readily usable\ndataset to effectively train LLMs in multiple languages. To overcome this\nissue, we present CulturaX, a substantial multilingual dataset with 6.3\ntrillion tokens in 167 languages, tailored for LLM development. Our dataset\nundergoes meticulous cleaning and deduplication through a rigorous pipeline of\nmultiple stages to accomplish the best quality for model training, including\nlanguage identification, URL-based filtering, metric-based cleaning, document\nrefinement, and data deduplication. CulturaX is fully released to the public in\nHuggingFace to facilitate research and advancements in multilingual LLMs:\nhttps://huggingface.co/datasets/uonlp/CulturaX."
  },
  {
    "arxiv_id": "2309.09298",
    "title": "OWL: A Large Language Model for IT Operations",
    "url": "http://arxiv.org/abs/2309.09298v1",
    "abstract": "With the rapid development of IT operations, it has become increasingly\ncrucial to efficiently manage and analyze large volumes of data for practical\napplications. The techniques of Natural Language Processing (NLP) have shown\nremarkable capabilities for various tasks, including named entity recognition,\nmachine translation and dialogue systems. Recently, Large Language Models\n(LLMs) have achieved significant improvements across various NLP downstream\ntasks. However, there is a lack of specialized LLMs for IT operations. In this\npaper, we introduce the OWL, a large language model trained on our collected\nOWL-Instruct dataset with a wide range of IT-related information, where the\nmixture-of-adapter strategy is proposed to improve the parameter-efficient\ntuning across different domains or tasks. Furthermore, we evaluate the\nperformance of our OWL on the OWL-Bench established by us and open IT-related\nbenchmarks. OWL demonstrates superior performance results on IT tasks, which\noutperforms existing models by significant margins. Moreover, we hope that the\nfindings of our work will provide more insights to revolutionize the techniques\nof IT operations with specialized LLMs."
  },
  {
    "arxiv_id": "2309.08989",
    "title": "RMP: A Random Mask Pretrain Framework for Motion Prediction",
    "url": "http://arxiv.org/abs/2309.08989v1",
    "abstract": "As the pretraining technique is growing in popularity, little work has been\ndone on pretrained learning-based motion prediction methods in autonomous\ndriving. In this paper, we propose a framework to formalize the pretraining\ntask for trajectory prediction of traffic participants. Within our framework,\ninspired by the random masked model in natural language processing (NLP) and\ncomputer vision (CV), objects' positions at random timesteps are masked and\nthen filled in by the learned neural network (NN). By changing the mask\nprofile, our framework can easily switch among a range of motion-related tasks.\nWe show that our proposed pretraining framework is able to deal with noisy\ninputs and improves the motion prediction accuracy and miss rate, especially\nfor objects occluded over time by evaluating it on Argoverse and NuScenes\ndatasets."
  },
  {
    "arxiv_id": "2309.08968",
    "title": "Sorted LLaMA: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference Using Sorted Fine-Tuning (SoFT)",
    "url": "http://arxiv.org/abs/2309.08968v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) by excelling at understanding and generating human-like text. However,\ntheir widespread deployment can be prohibitively expensive. SortedNet is a\nrecent training technique for enabling dynamic inference by leveraging the\nmodularity in networks and sorting sub-models based on computation/accuracy in\na nested manner. We extend SortedNet to generative NLP tasks, making large\nlanguage models dynamic without any Pre-Training and by only replacing Standard\nFine-Tuning (SFT) with Sorted Fine-Tuning (SoFT). Our approach boosts model\nefficiency, eliminating the need for multiple models for various scenarios\nduring inference. We show that this approach can unlock the power of\nintermediate layers of transformers in generating the target output. Our\nsub-models remain integral components of the original model, minimizing storage\nrequirements and transition costs between different computational/latency\nbudgets. The efficacy of our proposed method was demonstrated by applying it to\ntune LLaMA 2 13B on the Stanford Alpaca dataset for instruction following and\nTriviaQA for closed-book question answering. Our results show the superior\nperformance of sub-models in comparison to Standard Fine-Tuning and SFT+ICT\n(Early-Exit), all achieved with efficient tuning and without additional memory\nusage during inference."
  },
  {
    "arxiv_id": "2309.10654",
    "title": "CFGPT: Chinese Financial Assistant with Large Language Model",
    "url": "http://arxiv.org/abs/2309.10654v1",
    "abstract": "Large language models (LLMs) have demonstrated great potential in natural\nlanguage processing tasks within the financial domain. In this work, we present\na Chinese Financial Generative Pre-trained Transformer framework, named CFGPT,\nwhich includes a dataset~(CFData) for pre-training and supervised fine-tuning,\na financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment\nframework~(CFAPP) designed to navigate real-world financial applications. The\nCFData comprising both a pre-training dataset and a supervised fine-tuning\ndataset, where the pre-training dataset collates Chinese financial data and\nanalytics, alongside a smaller subset of general-purpose text with 584M\ndocuments and 141B tokens in total, and the supervised fine-tuning dataset is\ntailored for six distinct financial tasks, embodying various facets of\nfinancial analysis and decision-making with 1.5M instruction pairs and 1.5B\ntokens in total. The CFLLM, which is based on InternLM-7B to balance the model\ncapability and size, is trained on CFData in two stage, continued pre-training\nand supervised fine-tuning. The CFAPP is centered on large language models\n(LLMs) and augmented with additional modules to ensure multifaceted\nfunctionality in real-world application. Our codes are released at\nhttps://github.com/TongjiFinLab/CFGPT."
  },
  {
    "arxiv_id": "2309.10272",
    "title": "Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and Hindi",
    "url": "http://arxiv.org/abs/2309.10272v1",
    "abstract": "One of the most popular downstream tasks in the field of Natural Language\nProcessing is text classification. Text classification tasks have become more\ndaunting when the texts are code-mixed. Though they are not exposed to such\ntext during pre-training, different BERT models have demonstrated success in\ntackling Code-Mixed NLP challenges. Again, in order to enhance their\nperformance, Code-Mixed NLP models have depended on combining synthetic data\nwith real-world data. It is crucial to understand how the BERT models'\nperformance is impacted when they are pretrained using corresponding code-mixed\nlanguages. In this paper, we introduce Tri-Distil-BERT, a multilingual model\npre-trained on Bangla, English, and Hindi, and Mixed-Distil-BERT, a model\nfine-tuned on code-mixed data. Both models are evaluated across multiple NLP\ntasks and demonstrate competitive performance against larger models like mBERT\nand XLM-R. Our two-tiered pre-training approach offers efficient alternatives\nfor multilingual and code-mixed language understanding, contributing to\nadvancements in the field."
  },
  {
    "arxiv_id": "2309.10187",
    "title": "Automated Interviewer or Augmented Survey? Collecting Social Data with Large Language Models",
    "url": "http://arxiv.org/abs/2309.10187v1",
    "abstract": "Chatbots have shown promise as tools to scale qualitative data collection.\nRecent advances in Large Language Models (LLMs) could accelerate this process\nby allowing researchers to easily deploy sophisticated interviewing chatbots.\nWe test this assumption by conducting a large-scale user study (n=399)\nevaluating 3 different chatbots, two of which are LLM-based and a baseline\nwhich employs hard-coded questions. We evaluate the results with respect to\nparticipant engagement and experience, established metrics of chatbot quality\ngrounded in theories of effective communication, and a novel scale evaluating\n\"richness\" or the extent to which responses capture the complexity and\nspecificity of the social context under study. We find that, while the chatbots\nwere able to elicit high-quality responses based on established evaluation\nmetrics, the responses rarely capture participants' specific motives or\npersonalized examples, and thus perform poorly with respect to richness. We\nfurther find low inter-rater reliability between LLMs and humans in the\nassessment of both quality and richness metrics. Our study offers a cautionary\ntale for scaling and evaluating qualitative research with LLMs."
  },
  {
    "arxiv_id": "2309.11400",
    "title": "Transformers versus LSTMs for electronic trading",
    "url": "http://arxiv.org/abs/2309.11400v1",
    "abstract": "With the rapid development of artificial intelligence, long short term memory\n(LSTM), one kind of recurrent neural network (RNN), has been widely applied in\ntime series prediction.\n  Like RNN, Transformer is designed to handle the sequential data. As\nTransformer achieved great success in Natural Language Processing (NLP),\nresearchers got interested in Transformer's performance on time series\nprediction, and plenty of Transformer-based solutions on long time series\nforecasting have come out recently. However, when it comes to financial time\nseries prediction, LSTM is still a dominant architecture. Therefore, the\nquestion this study wants to answer is: whether the Transformer-based model can\nbe applied in financial time series prediction and beat LSTM.\n  To answer this question, various LSTM-based and Transformer-based models are\ncompared on multiple financial prediction tasks based on high-frequency limit\norder book data. A new LSTM-based model called DLSTM is built and new\narchitecture for the Transformer-based model is designed to adapt for financial\nprediction. The experiment result reflects that the Transformer-based model\nonly has the limited advantage in absolute price sequence prediction. The\nLSTM-based models show better and more robust performance on difference\nsequence prediction, such as price difference and price movement."
  },
  {
    "arxiv_id": "2309.11042",
    "title": "Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters",
    "url": "http://arxiv.org/abs/2309.11042v1",
    "abstract": "Recently, Large Language Models (LLMs) have achieved amazing zero-shot\nlearning performance over a variety of Natural Language Processing (NLP) tasks,\nespecially for text generative tasks. Yet, the large size of LLMs often leads\nto the high computational cost of model training and online deployment. In our\nwork, we present ALTER, a system that effectively builds the multi-tAsk\nLearners with mixTure-of-task-adaptERs upon small language models (with <1B\nparameters) to address multiple NLP tasks simultaneously, capturing the\ncommonalities and differences between tasks, in order to support\ndomain-specific applications. Specifically, in ALTER, we propose the\nMixture-of-Task-Adapters (MTA) module as an extension to the transformer\narchitecture for the underlying model to capture the intra-task and inter-task\nknowledge. A two-stage training method is further proposed to optimize the\ncollaboration between adapters at a small computational cost. Experimental\nresults over a mixture of NLP tasks show that our proposed MTA architecture and\nthe two-stage training method achieve good performance. Based on ALTER, we have\nalso produced MTA-equipped language models for various domains."
  },
  {
    "arxiv_id": "2309.10952",
    "title": "LMDX: Language Model-based Document Information Extraction and Localization",
    "url": "http://arxiv.org/abs/2309.10952v1",
    "abstract": "Large Language Models (LLM) have revolutionized Natural Language Processing\n(NLP), improving state-of-the-art and exhibiting emergent capabilities across\nvarious tasks. However, their application in extracting information from\nvisually rich documents, which is at the core of many document processing\nworkflows and involving the extraction of key entities from semi-structured\ndocuments, has not yet been successful. The main obstacles to adopting LLMs for\nthis task include the absence of layout encoding within LLMs, which is critical\nfor high quality extraction, and the lack of a grounding mechanism to localize\nthe predicted entities within the document. In this paper, we introduce\nLanguage Model-based Document Information Extraction and Localization (LMDX), a\nmethodology to reframe the document information extraction task for a LLM. LMDX\nenables extraction of singular, repeated, and hierarchical entities, both with\nand without training data, while providing grounding guarantees and localizing\nthe entities within the document. Finally, we apply LMDX to the PaLM 2-S and\nGemini Pro LLMs and evaluate it on VRDU and CORD benchmarks, setting a new\nstate-of-the-art and showing how LMDX enables the creation of high quality,\ndata-efficient parsers."
  },
  {
    "arxiv_id": "2309.12626",
    "title": "Construction contract risk identification based on knowledge-augmented language model",
    "url": "http://arxiv.org/abs/2309.12626v1",
    "abstract": "Contract review is an essential step in construction projects to prevent\npotential losses. However, the current methods for reviewing construction\ncontracts lack effectiveness and reliability, leading to time-consuming and\nerror-prone processes. While large language models (LLMs) have shown promise in\nrevolutionizing natural language processing (NLP) tasks, they struggle with\ndomain-specific knowledge and addressing specialized issues. This paper\npresents a novel approach that leverages LLMs with construction contract\nknowledge to emulate the process of contract review by human experts. Our\ntuning-free approach incorporates construction contract domain knowledge to\nenhance language models for identifying construction contract risks. The use of\na natural language when building the domain knowledge base facilitates\npractical implementation. We evaluated our method on real construction\ncontracts and achieved solid performance. Additionally, we investigated how\nlarge language models employ logical thinking during the task and provide\ninsights and recommendations for future research."
  },
  {
    "arxiv_id": "2309.14488",
    "title": "When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs",
    "url": "http://arxiv.org/abs/2309.14488v1",
    "abstract": "The use of machine learning (ML) models to assess and score textual data has\nbecome increasingly pervasive in an array of contexts including natural\nlanguage processing, information retrieval, search and recommendation, and\ncredibility assessment of online content. A significant disruption at the\nintersection of ML and text are text-generating large-language models such as\ngenerative pre-trained transformers (GPTs). We empirically assess the\ndifferences in how ML-based scoring models trained on human content assess the\nquality of content generated by humans versus GPTs. To do so, we propose an\nanalysis framework that encompasses essay scoring ML-models, human and\nML-generated essays, and a statistical model that parsimoniously considers the\nimpact of type of respondent, prompt genre, and the ML model used for\nassessment model. A rich testbed is utilized that encompasses 18,460\nhuman-generated and GPT-based essays. Results of our benchmark analysis reveal\nthat transformer pretrained language models (PLMs) more accurately score human\nessay quality as compared to CNN/RNN and feature-based ML methods.\nInterestingly, we find that the transformer PLMs tend to score GPT-generated\ntext 10-15\\% higher on average, relative to human-authored documents.\nConversely, traditional deep learning and feature-based ML models score human\ntext considerably higher. Further analysis reveals that although the\ntransformer PLMs are exclusively fine-tuned on human text, they more\nprominently attend to certain tokens appearing only in GPT-generated text,\npossibly due to familiarity/overlap in pre-training. Our framework and results\nhave implications for text classification settings where automated scoring of\ntext is likely to be disrupted by generative AI."
  },
  {
    "arxiv_id": "2309.15714",
    "title": "ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension",
    "url": "http://arxiv.org/abs/2309.15714v1",
    "abstract": "With the recent proliferation of large language models (LLMs), such as\nGenerative Pre-trained Transformers (GPT), there has been a significant shift\nin exploring human and machine comprehension of semantic language meaning. This\nshift calls for interdisciplinary research that bridges cognitive science and\nnatural language processing (NLP). This pilot study aims to provide insights\ninto individuals' neural states during a semantic relation\nreading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and\nelectroencephalographic (EEG) data to study how the brain processes words with\nvarying degrees of relevance to a keyword during reading. We also use a feature\nengineering approach to improve the fixation-related EEG data classification\nwhile participants read words with high versus low relevance to the keyword.\nThe best validation accuracy in this word-level classification is over 60\\%\nacross 12 subjects. Words of high relevance to the inference keyword had\nsignificantly more eye fixations per word: 1.0584 compared to 0.6576 when\nexcluding no-fixation words, and 1.5126 compared to 1.4026 when including them.\nThis study represents the first attempt to classify brain states at a word\nlevel using LLM knowledge. It provides valuable insights into human cognitive\nabilities and the realm of Artificial General Intelligence (AGI), and offers\nguidance for developing potential reading-assisted technologies."
  },
  {
    "arxiv_id": "2309.15630",
    "title": "NLPBench: Evaluating Large Language Models on Solving NLP Problems",
    "url": "http://arxiv.org/abs/2309.15630v1",
    "abstract": "Recent developments in large language models (LLMs) have shown promise in\nenhancing the capabilities of natural language processing (NLP). Despite these\nsuccesses, there remains a dearth of research dedicated to the NLP\nproblem-solving abilities of LLMs. To fill the gap in this area, we present a\nunique benchmarking dataset, NLPBench, comprising 378 college-level NLP\nquestions spanning various NLP topics sourced from Yale University's prior\nfinal exams. NLPBench includes questions with context, in which multiple\nsub-questions share the same public information, and diverse question types,\nincluding multiple choice, short answer, and math. Our evaluation, centered on\nLLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting\nstrategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study\nreveals that the effectiveness of the advanced prompting strategies can be\ninconsistent, occasionally damaging LLM performance, especially in smaller\nmodels like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated\nspecific shortcomings in LLMs' scientific problem-solving skills, with\nweaknesses in logical decomposition and reasoning notably affecting results."
  },
  {
    "arxiv_id": "2309.15487",
    "title": "Tackling VQA with Pretrained Foundation Models without Further Training",
    "url": "http://arxiv.org/abs/2309.15487v1",
    "abstract": "Large language models (LLMs) have achieved state-of-the-art results in many\nnatural language processing tasks. They have also demonstrated ability to adapt\nwell to different tasks through zero-shot or few-shot settings. With the\ncapability of these LLMs, researchers have looked into how to adopt them for\nuse with Visual Question Answering (VQA). Many methods require further training\nto align the image and text embeddings. However, these methods are\ncomputationally expensive and requires large scale image-text dataset for\ntraining. In this paper, we explore a method of combining pretrained LLMs and\nother foundation models without further training to solve the VQA problem. The\ngeneral idea is to use natural language to represent the images such that the\nLLM can understand the images. We explore different decoding strategies for\ngenerating textual representation of the image and evaluate their performance\non the VQAv2 dataset."
  },
  {
    "arxiv_id": "2309.15251",
    "title": "VPA: Fully Test-Time Visual Prompt Adaptation",
    "url": "http://arxiv.org/abs/2309.15251v1",
    "abstract": "Textual prompt tuning has demonstrated significant performance improvements\nin adapting natural language processing models to a variety of downstream tasks\nby treating hand-engineered prompts as trainable parameters. Inspired by the\nsuccess of textual prompting, several studies have investigated the efficacy of\nvisual prompt tuning. In this work, we present Visual Prompt Adaptation (VPA),\nthe first framework that generalizes visual prompting with test-time\nadaptation. VPA introduces a small number of learnable tokens, enabling fully\ntest-time and storage-efficient adaptation without necessitating source-domain\ninformation. We examine our VPA design under diverse adaptation settings,\nencompassing single-image, batched-image, and pseudo-label adaptation. We\nevaluate VPA on multiple tasks, including out-of-distribution (OOD)\ngeneralization, corruption robustness, and domain adaptation. Experimental\nresults reveal that VPA effectively enhances OOD generalization by 3.3% across\nvarious models, surpassing previous test-time approaches. Furthermore, we show\nthat VPA improves corruption robustness by 6.5% compared to strong baselines.\nFinally, we demonstrate that VPA also boosts domain adaptation performance by\nrelatively 5.2%. Our VPA also exhibits marked effectiveness in improving the\nrobustness of zero-shot recognition for vision-language models."
  },
  {
    "arxiv_id": "2309.16459",
    "title": "Augmenting LLMs with Knowledge: A survey on hallucination prevention",
    "url": "http://arxiv.org/abs/2309.16459v1",
    "abstract": "Large pre-trained language models have demonstrated their proficiency in\nstoring factual knowledge within their parameters and achieving remarkable\nresults when fine-tuned for downstream natural language processing tasks.\nNonetheless, their capacity to access and manipulate knowledge with precision\nremains constrained, resulting in performance disparities on\nknowledge-intensive tasks when compared to task-specific architectures.\nAdditionally, the challenges of providing provenance for model decisions and\nmaintaining up-to-date world knowledge persist as open research frontiers. To\naddress these limitations, the integration of pre-trained models with\ndifferentiable access mechanisms to explicit non-parametric memory emerges as a\npromising solution. This survey delves into the realm of language models (LMs)\naugmented with the ability to tap into external knowledge sources, including\nexternal knowledge bases and search engines. While adhering to the standard\nobjective of predicting missing tokens, these augmented LMs leverage diverse,\npossibly non-parametric external modules to augment their contextual processing\ncapabilities, departing from the conventional language modeling paradigm.\nThrough an exploration of current advancements in augmenting large language\nmodels with knowledge, this work concludes that this emerging research\ndirection holds the potential to address prevalent issues in traditional LMs,\nsuch as hallucinations, un-grounded responses, and scalability challenges."
  },
  {
    "arxiv_id": "2309.17447",
    "title": "A Large Language Model Approach to Educational Survey Feedback Analysis",
    "url": "http://arxiv.org/abs/2309.17447v1",
    "abstract": "This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text."
  },
  {
    "arxiv_id": "2309.17122",
    "title": "Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?",
    "url": "http://arxiv.org/abs/2309.17122v1",
    "abstract": "Large Language Models (LLMs) are advancing at a rapid pace, with significant\nimprovements at natural language processing and coding tasks. Yet, their\nability to work with formal languages representing data, specifically within\nthe realm of knowledge graph engineering, remains under-investigated. To\nevaluate the proficiency of various LLMs, we created a set of five tasks that\nprobe their ability to parse, understand, analyze, and create knowledge graphs\nserialized in Turtle syntax. These tasks, each embodying distinct degrees of\ncomplexity and being able to scale with the size of the problem, have been\nintegrated into our automated evaluation system, the LLM-KG-Bench. The\nevaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4,\nClaude 1.3, and Claude 2.0, as well as two freely accessible offline models,\nGPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth\nunderstanding of the strengths and shortcomings of LLMs in relation to their\napplication within RDF knowledge graph engineering workflows utilizing Turtle\nrepresentation. While our findings show that the latest commercial models\noutperform their forerunners in terms of proficiency with the Turtle language,\nthey also reveal an apparent weakness. These models fall short when it comes to\nadhering strictly to the output formatting constraints, a crucial requirement\nin this context."
  },
  {
    "arxiv_id": "2309.17050",
    "title": "Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models",
    "url": "http://arxiv.org/abs/2309.17050v1",
    "abstract": "Many individuals are likely to face a legal dispute at some point in their\nlives, but their lack of understanding of how to navigate these complex issues\noften renders them vulnerable. The advancement of natural language processing\nopens new avenues for bridging this legal literacy gap through the development\nof automated legal aid systems. However, existing legal question answering\n(LQA) approaches often suffer from a narrow scope, being either confined to\nspecific legal domains or limited to brief, uninformative responses. In this\nwork, we propose an end-to-end methodology designed to generate long-form\nanswers to any statutory law questions, utilizing a \"retrieve-then-read\"\npipeline. To support this approach, we introduce and release the Long-form\nLegal Question Answering (LLeQA) dataset, comprising 1,868 expert-annotated\nlegal questions in the French language, complete with detailed answers rooted\nin pertinent legal provisions. Our experimental results demonstrate promising\nperformance on automatic evaluation metrics, but a qualitative analysis\nuncovers areas for refinement. As one of the only comprehensive,\nexpert-annotated long-form LQA dataset, LLeQA has the potential to not only\naccelerate research towards resolving a significant real-world issue, but also\nact as a rigorous benchmark for evaluating NLP models in specialized domains.\nWe publicly release our code, data, and models."
  },
  {
    "arxiv_id": "2309.16777",
    "title": "How many words does ChatGPT know? The answer is ChatWords",
    "url": "http://arxiv.org/abs/2309.16777v1",
    "abstract": "The introduction of ChatGPT has put Artificial Intelligence (AI) Natural\nLanguage Processing (NLP) in the spotlight. ChatGPT adoption has been\nexponential with millions of users experimenting with it in a myriad of tasks\nand application domains with impressive results. However, ChatGPT has\nlimitations and suffers hallucinations, for example producing answers that look\nplausible but they are completely wrong. Evaluating the performance of ChatGPT\nand similar AI tools is a complex issue that is being explored from different\nperspectives. In this work, we contribute to those efforts with ChatWords, an\nautomated test system, to evaluate ChatGPT knowledge of an arbitrary set of\nwords. ChatWords is designed to be extensible, easy to use, and adaptable to\nevaluate also other NLP AI tools. ChatWords is publicly available and its main\ngoal is to facilitate research on the lexical knowledge of AI tools. The\nbenefits of ChatWords are illustrated with two case studies: evaluating the\nknowledge that ChatGPT has of the Spanish lexicon (taken from the official\ndictionary of the \"Real Academia Espa\\~nola\") and of the words that appear in\nthe Quixote, the well-known novel written by Miguel de Cervantes. The results\nshow that ChatGPT is only able to recognize approximately 80% of the words in\nthe dictionary and 90% of the words in the Quixote, in some cases with an\nincorrect meaning. The implications of the lexical knowledge of NLP AI tools\nand potential applications of ChatWords are also discussed providing directions\nfor further work on the study of the lexical knowledge of AI tools."
  },
  {
    "arxiv_id": "2310.02239",
    "title": "MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens",
    "url": "http://arxiv.org/abs/2310.02239v1",
    "abstract": "The effectiveness of Multimodal Large Language Models (MLLMs) demonstrates a\nprofound capability in multimodal understanding. However, the simultaneous\ngeneration of images with coherent texts is still underdeveloped. Addressing\nthis, we introduce a novel interleaved vision-and-language generation method,\ncentered around the concept of ``generative vokens\". These vokens serve as\npivotal elements contributing to coherent image-text outputs. Our method is\nmarked by a unique two-stage training strategy for description-free multimodal\ngeneration, which does not necessitate extensive descriptions of images. We\nintegrate classifier-free guidance to enhance the alignment of generated images\nand texts, ensuring more seamless and contextually relevant multimodal\ninteractions. Our model, MiniGPT-5, exhibits substantial improvement over the\nbaseline models on multimodal generation datasets, including MMDialog and VIST.\nThe human evaluation shows MiniGPT-5 is better than the baseline model on more\nthan 56\\% cases for multimodal generation, highlighting its efficacy across\ndiverse benchmarks."
  },
  {
    "arxiv_id": "2310.02124",
    "title": "Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View",
    "url": "http://arxiv.org/abs/2310.02124v1",
    "abstract": "As Natural Language Processing (NLP) systems are increasingly employed in\nintricate social environments, a pressing query emerges: Can these NLP systems\nmirror human-esque collaborative intelligence, in a multi-agent society\nconsisting of multiple large language models (LLMs)? This paper probes the\ncollaboration mechanisms among contemporary NLP systems by melding practical\nexperiments with theoretical insights. We fabricate four unique `societies'\ncomprised of LLM agents, where each agent is characterized by a specific\n`trait' (easy-going or overconfident) and engages in collaboration with a\ndistinct `thinking pattern' (debate or reflection). Through evaluating these\nmulti-agent societies on three benchmark datasets, we discern that certain\ncollaborative strategies not only outshine previous top-tier approaches, but\nalso optimize efficiency (using fewer API tokens). Moreover, our results\nfurther illustrate that LLM agents manifest human-like social behaviors, such\nas conformity and consensus reaching, mirroring foundational social psychology\ntheories. In conclusion, we integrate insights from social psychology to\ncontextualize the collaboration of LLM agents, inspiring further investigations\ninto the collaboration mechanism for LLMs. We commit to sharing our code and\ndatasets\\footnote{\\url{https://github.com/zjunlp/MachineSoM}.}, hoping to\ncatalyze further research in this promising avenue."
  },
  {
    "arxiv_id": "2310.01728",
    "title": "Time-LLM: Time Series Forecasting by Reprogramming Large Language Models",
    "url": "http://arxiv.org/abs/2310.01728v1",
    "abstract": "Time series forecasting holds significant importance in many real-world\ndynamic systems and has been extensively studied. Unlike natural language\nprocess (NLP) and computer vision (CV), where a single large model can tackle\nmultiple tasks, models for time series forecasting are often specialized,\nnecessitating distinct designs for different tasks and applications. While\npre-trained foundation models have made impressive strides in NLP and CV, their\ndevelopment in time series domains has been constrained by data sparsity.\nRecent studies have revealed that large language models (LLMs) possess robust\npattern recognition and reasoning abilities over complex sequences of tokens.\nHowever, the challenge remains in effectively aligning the modalities of time\nseries data and natural language to leverage these capabilities. In this work,\nwe present Time-LLM, a reprogramming framework to repurpose LLMs for general\ntime series forecasting with the backbone language models kept intact. We begin\nby reprogramming the input time series with text prototypes before feeding it\ninto the frozen LLM to align the two modalities. To augment the LLM's ability\nto reason with time series data, we propose Prompt-as-Prefix (PaP), which\nenriches the input context and directs the transformation of reprogrammed input\npatches. The transformed time series patches from the LLM are finally projected\nto obtain the forecasts. Our comprehensive evaluations demonstrate that\nTime-LLM is a powerful time series learner that outperforms state-of-the-art,\nspecialized forecasting models. Moreover, Time-LLM excels in both few-shot and\nzero-shot learning scenarios."
  },
  {
    "arxiv_id": "2310.01704",
    "title": "Transformers are efficient hierarchical chemical graph learners",
    "url": "http://arxiv.org/abs/2310.01704v1",
    "abstract": "Transformers, adapted from natural language processing, are emerging as a\nleading approach for graph representation learning. Contemporary graph\ntransformers often treat nodes or edges as separate tokens. This approach leads\nto computational challenges for even moderately-sized graphs due to the\nquadratic scaling of self-attention complexity with token count. In this paper,\nwe introduce SubFormer, a graph transformer that operates on subgraphs that\naggregate information by a message-passing mechanism. This approach reduces the\nnumber of tokens and enhances learning long-range interactions. We demonstrate\nSubFormer on benchmarks for predicting molecular properties from chemical\nstructures and show that it is competitive with state-of-the-art graph\ntransformers at a fraction of the computational cost, with training times on\nthe order of minutes on a consumer-grade graphics card. We interpret the\nattention weights in terms of chemical structures. We show that SubFormer\nexhibits limited over-smoothing and avoids over-squashing, which is prevalent\nin traditional graph neural networks."
  },
  {
    "arxiv_id": "2310.01691",
    "title": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models",
    "url": "http://arxiv.org/abs/2310.01691v1",
    "abstract": "Prompt tuning in natural language processing (NLP) has become an increasingly\npopular method for adapting large language models to specific tasks. However,\nthe transferability of these prompts, especially continuous prompts, between\ndifferent models remains a challenge. In this work, we propose a zero-shot\ncontinuous prompt transfer method, where source prompts are encoded into\nrelative space and the corresponding target prompts are searched for\ntransferring to target models. Experimental results confirm the effectiveness\nof our method, showing that 'task semantics' in continuous prompts can be\ngeneralized across various language models. Moreover, we find that combining\n'task semantics' from multiple source models can further enhance the\ngeneralizability of transfer."
  },
  {
    "arxiv_id": "2310.02790",
    "title": "Low Resource Summarization using Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2310.02790v1",
    "abstract": "With the advent of Deep Learning based Artificial Neural Networks models,\nNatural Language Processing (NLP) has witnessed significant improvements in\ntextual data processing in terms of its efficiency and accuracy. However, the\nresearch is mostly restricted to high-resource languages such as English and\nlow-resource languages still suffer from a lack of available resources in terms\nof training datasets as well as models with even baseline evaluation results.\nConsidering the limited availability of resources for low-resource languages,\nwe propose a methodology for adapting self-attentive transformer-based\narchitecture models (mBERT, mT5) for low-resource summarization, supplemented\nby the construction of a new baseline dataset (76.5k article, summary pairs) in\na low-resource language Urdu. Choosing news (a publicly available source) as\nthe application domain has the potential to make the proposed methodology\nuseful for reproducing in other languages with limited resources. Our adapted\nsummarization model \\textit{urT5} with up to 44.78\\% reduction in size as\ncompared to \\textit{mT5} can capture contextual information of low resource\nlanguage effectively with evaluation score (up to 46.35 ROUGE-1, 77 BERTScore)\nat par with state-of-the-art models in high resource language English\n\\textit{(PEGASUS: 47.21, BART: 45.14 on XSUM Dataset)}. The proposed method\nprovided a baseline approach towards extractive as well as abstractive\nsummarization with competitive evaluation results in a limited resource setup."
  },
  {
    "arxiv_id": "2310.03376",
    "title": "Procedural Text Mining with Large Language Models",
    "url": "http://arxiv.org/abs/2310.03376v1",
    "abstract": "Recent advancements in the field of Natural Language Processing, particularly\nthe development of large-scale language models that are pretrained on vast\namounts of knowledge, are creating novel opportunities within the realm of\nKnowledge Engineering. In this paper, we investigate the usage of large\nlanguage models (LLMs) in both zero-shot and in-context learning settings to\ntackle the problem of extracting procedures from unstructured PDF text in an\nincremental question-answering fashion. In particular, we leverage the current\nstate-of-the-art GPT-4 (Generative Pre-trained Transformer 4) model,\naccompanied by two variations of in-context learning that involve an ontology\nwith definitions of procedures and steps and a limited number of samples of\nfew-shot learning. The findings highlight both the promise of this approach and\nthe value of the in-context learning customisations. These modifications have\nthe potential to significantly address the challenge of obtaining sufficient\ntraining data, a hurdle often encountered in deep learning-based Natural\nLanguage Processing techniques for procedure extraction."
  },
  {
    "arxiv_id": "2310.03283",
    "title": "A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores",
    "url": "http://arxiv.org/abs/2310.03283v1",
    "abstract": "Large Language Models (LLMs), such as ChatGPT, have achieved impressive\nmilestones in natural language processing (NLP). Despite their impressive\nperformance, the models are known to pose important risks. As these models are\ndeployed in real-world applications, a systematic understanding of different\nrisks posed by these models on tasks such as natural language inference (NLI),\nis much needed. In this paper, we define and formalize two distinct types of\nrisk: decision risk and composite risk. We also propose a risk-centric\nevaluation framework, and four novel metrics, for assessing LLMs on these risks\nin both in-domain and out-of-domain settings. Finally, we propose a\nrisk-adjusted calibration method called DwD for helping LLMs minimize these\nrisks in an overall NLI architecture. Detailed experiments, using four NLI\nbenchmarks, three baselines and two LLMs, including ChatGPT, show both the\npractical utility of the evaluation framework, and the efficacy of DwD in\nreducing decision and composite risk. For instance, when using DwD, an\nunderlying LLM is able to address an extra 20.1% of low-risk inference tasks\n(but which the LLM erroneously deems high-risk without risk adjustment) and\nskip a further 19.8% of high-risk tasks, which would have been answered\nincorrectly."
  },
  {
    "arxiv_id": "2310.03269",
    "title": "InstructProtein: Aligning Human and Protein Language via Knowledge Instruction",
    "url": "http://arxiv.org/abs/2310.03269v1",
    "abstract": "Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing, but they fall short in comprehending biological sequences\nsuch as proteins. To address this challenge, we propose InstructProtein, an\ninnovative LLM that possesses bidirectional generation capabilities in both\nhuman and protein languages: (i) taking a protein sequence as input to predict\nits textual function description and (ii) using natural language to prompt\nprotein sequence generation. To achieve this, we first pre-train an LLM on both\nprotein and natural language corpora, enabling it to comprehend individual\nlanguages. Then supervised instruction tuning is employed to facilitate the\nalignment of these two distinct languages. Herein, we introduce a knowledge\ngraph-based instruction generation framework to construct a high-quality\ninstruction dataset, addressing annotation imbalance and instruction deficits\nin existing protein-text corpus. In particular, the instructions inherit the\nstructural relations between proteins and function annotations in knowledge\ngraphs, which empowers our model to engage in the causal modeling of protein\nfunctions, akin to the chain-of-thought processes in natural languages.\nExtensive experiments on bidirectional protein-text generation tasks show that\nInstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,\nInstructProtein serves as a pioneering step towards text-based protein function\nprediction and sequence design, effectively bridging the gap between protein\nand human language understanding."
  },
  {
    "arxiv_id": "2310.03150",
    "title": "Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly",
    "url": "http://arxiv.org/abs/2310.03150v1",
    "abstract": "Large Language Models (LLM) and foundation models are popular as they offer\nnew opportunities for individuals and businesses to improve natural language\nprocessing, interact with data, and retrieve information faster. However,\ntraining or fine-tuning LLMs requires a vast amount of data, which can be\nchallenging to access due to legal or technical restrictions and may require\nprivate computing resources. Federated Learning (FL) is a solution designed to\novercome these challenges and expand data access for deep learning\napplications.\n  This paper takes a hardware-centric approach to explore how LLMs can be\nbrought to modern edge computing systems. Our study fine-tunes the FLAN-T5\nmodel family, ranging from 80M to 3B parameters, using FL for a text\nsummarization task. We provide a micro-level hardware benchmark, compare the\nmodel FLOP utilization to a state-of-the-art data center GPU, and study the\nnetwork utilization in realistic conditions. Our contribution is twofold:\nFirst, we evaluate the current capabilities of edge computing systems and their\npotential for LLM FL workloads. Second, by comparing these systems with a\ndata-center GPU, we demonstrate the potential for improvement and the next\nsteps toward achieving greater computational efficiency at the edge."
  },
  {
    "arxiv_id": "2310.04039",
    "title": "Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models",
    "url": "http://arxiv.org/abs/2310.04039v1",
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nimpressive capabilities across a range of natural language processing tasks,\nespecially in reasoning, a cornerstone for achieving Artificial General\nIntelligence (AGI). However, commonly used benchmarks may not fully encapsulate\nthe inferential abilities of these models in real-world scenarios. To address\nthis gap, a new form of Question-Answering (QA) task, termed Reasoning with\nRedundant Information Provided (RRIP), is introduced. The study designed a\nmodified version of the grade school math 8K (GSM-8K) dataset which has several\nvariants focusing on different attributes of redundant information. This\ninvestigation evaluates two popular LLMs, LlaMA2-13B-chat and generative\npre-trained transformer 3.5 (GPT-3.5), contrasting their performance on\ntraditional QA tasks against the RRIP tasks. Findings indicate that while these\nmodels achieved moderate success on standard QA benchmarks, their performance\nnotably declines when assessed on RRIP tasks. The study not only highlights the\nlimitations of current LLMs in handling redundant information but also suggests\nthat future training of these models should focus on incorporating redundant\ninformation into the training data to increase the performance on RRIP tasks."
  },
  {
    "arxiv_id": "2310.03971",
    "title": "Quantized Transformer Language Model Implementations on Edge Devices",
    "url": "http://arxiv.org/abs/2310.03971v1",
    "abstract": "Large-scale transformer-based models like the Bidirectional Encoder\nRepresentations from Transformers (BERT) are widely used for Natural Language\nProcessing (NLP) applications, wherein these models are initially pre-trained\nwith a large corpus with millions of parameters and then fine-tuned for a\ndownstream NLP task. One of the major limitations of these large-scale models\nis that they cannot be deployed on resource-constrained devices due to their\nlarge model size and increased inference latency. In order to overcome these\nlimitations, such large-scale models can be converted to an optimized\nFlatBuffer format, tailored for deployment on resource-constrained edge\ndevices. Herein, we evaluate the performance of such FlatBuffer transformed\nMobileBERT models on three different edge devices, fine-tuned for Reputation\nanalysis of English language tweets in the RepLab 2013 dataset. In addition,\nthis study encompassed an evaluation of the deployed models, wherein their\nlatency, performance, and resource efficiency were meticulously assessed. Our\nexperiment results show that, compared to the original BERT large model, the\nconverted and quantized MobileBERT models have 160$\\times$ smaller footprints\nfor a 4.1% drop in accuracy while analyzing at least one tweet per second on\nedge devices. Furthermore, our study highlights the privacy-preserving aspect\nof TinyML systems as all data is processed locally within a serverless\nenvironment."
  },
  {
    "arxiv_id": "2310.05797",
    "title": "Are Large Language Models Post Hoc Explainers?",
    "url": "http://arxiv.org/abs/2310.05797v2",
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated\nexceptional capabilities in complex tasks like machine translation, commonsense\nreasoning, and language understanding. One of the primary reasons for the\nadaptability of LLMs in such diverse tasks is their in-context learning (ICL)\ncapability, which allows them to perform well on new tasks by simply using a\nfew task samples in the prompt. Despite their effectiveness in enhancing the\nperformance of LLMs on diverse language and tabular tasks, these methods have\nnot been thoroughly explored for their potential to generate post hoc\nexplanations. In this work, we carry out one of the first explorations to\nanalyze the effectiveness of LLMs in explaining other complex predictive models\nusing ICL. To this end, we propose a novel framework, In-Context Explainers,\ncomprising of three novel approaches that exploit the ICL capabilities of LLMs\nto explain the predictions made by other predictive models. We conduct\nextensive analysis with these approaches on real-world tabular and text\ndatasets and demonstrate that LLMs are capable of explaining other predictive\nmodels similar to state-of-the-art post hoc explainers, opening up promising\navenues for future research into LLM-based post hoc explanations of complex\npredictive models."
  },
  {
    "arxiv_id": "2310.05664",
    "title": "ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain",
    "url": "http://arxiv.org/abs/2310.05664v1",
    "abstract": "Transformer design is the de facto standard for natural language processing\ntasks. The success of the transformer design in natural language processing has\nlately piqued the interest of researchers in the domain of computer vision.\nWhen compared to Convolutional Neural Networks (CNNs), Vision Transformers\n(ViTs) are becoming more popular and dominant solutions for many vision\nproblems. Transformer-based models outperform other types of networks, such as\nconvolutional and recurrent neural networks, in a range of visual benchmarks.\nWe evaluate various vision transformer models in this work by dividing them\ninto distinct jobs and examining their benefits and drawbacks. ViTs can\novercome several possible difficulties with convolutional neural networks\n(CNNs). The goal of this survey is to show the first use of ViTs in CV. In the\nfirst phase, we categorize various CV applications where ViTs are appropriate.\nImage classification, object identification, image segmentation, video\ntransformer, image denoising, and NAS are all CV applications. Our next step\nwill be to analyze the state-of-the-art in each area and identify the models\nthat are currently available. In addition, we outline numerous open research\ndifficulties as well as prospective research possibilities."
  },
  {
    "arxiv_id": "2310.05553",
    "title": "Regulation and NLP (RegNLP): Taming Large Language Models",
    "url": "http://arxiv.org/abs/2310.05553v1",
    "abstract": "The scientific innovation in Natural Language Processing (NLP) and more\nbroadly in artificial intelligence (AI) is at its fastest pace to date. As\nlarge language models (LLMs) unleash a new era of automation, important debates\nemerge regarding the benefits and risks of their development, deployment and\nuse. Currently, these debates have been dominated by often polarized narratives\nmainly led by the AI Safety and AI Ethics movements. This polarization, often\namplified by social media, is swaying political agendas on AI regulation and\ngovernance and posing issues of regulatory capture. Capture occurs when the\nregulator advances the interests of the industry it is supposed to regulate, or\nof special interest groups rather than pursuing the general public interest.\nMeanwhile in NLP research, attention has been increasingly paid to the\ndiscussion of regulating risks and harms. This often happens without systematic\nmethodologies or sufficient rooting in the disciplines that inspire an extended\nscope of NLP research, jeopardizing the scientific integrity of these\nendeavors. Regulation studies are a rich source of knowledge on how to\nsystematically deal with risk and uncertainty, as well as with scientific\nevidence, to evaluate and compare regulatory options. This resource has largely\nremained untapped so far. In this paper, we argue how NLP research on these\ntopics can benefit from proximity to regulatory studies and adjacent fields. We\ndo so by discussing basic tenets of regulation, and risk and uncertainty, and\nby highlighting the shortcomings of current NLP discussions dealing with risk\nassessment. Finally, we advocate for the development of a new multidisciplinary\nresearch space on regulation and NLP (RegNLP), focused on connecting scientific\nknowledge to regulatory processes based on systematic methodologies."
  },
  {
    "arxiv_id": "2310.05470",
    "title": "Generative Judge for Evaluating Alignment",
    "url": "http://arxiv.org/abs/2310.05470v1",
    "abstract": "The rapid development of Large Language Models (LLMs) has substantially\nexpanded the range of tasks they can address. In the field of Natural Language\nProcessing (NLP), researchers have shifted their focus from conventional NLP\ntasks (e.g., sequence tagging and parsing) towards tasks that revolve around\naligning with human needs (e.g., brainstorming and email writing). This shift\nin task distribution imposes new requirements on evaluating these aligned\nmodels regarding generality (i.e., assessing performance across diverse\nscenarios), flexibility (i.e., examining under different protocols), and\ninterpretability (i.e., scrutinizing models with explanations). In this paper,\nwe propose a generative judge with 13B parameters, Auto-J, designed to address\nthese challenges. Our model is trained on user queries and LLM-generated\nresponses under massive real-world scenarios and accommodates diverse\nevaluation protocols (e.g., pairwise response comparison and single-response\nevaluation) with well-structured natural language critiques. To demonstrate the\nefficacy of our approach, we construct a new testbed covering 58 different\nscenarios. Experimentally, Auto-J outperforms a series of strong competitors,\nincluding both open-source and closed-source models, by a large margin. We also\nprovide detailed analysis and case studies to further reveal the potential of\nour method and make a variety of resources public at\nhttps://github.com/GAIR-NLP/auto-j."
  },
  {
    "arxiv_id": "2310.05318",
    "title": "Resolving the Imbalance Issue in Hierarchical Disciplinary Topic Inference via LLM-based Data Augmentation",
    "url": "http://arxiv.org/abs/2310.05318v1",
    "abstract": "In addressing the imbalanced issue of data within the realm of Natural\nLanguage Processing, text data augmentation methods have emerged as pivotal\nsolutions. This data imbalance is prevalent in the research proposals submitted\nduring the funding application process. Such imbalances, resulting from the\nvarying popularity of disciplines or the emergence of interdisciplinary\nstudies, significantly impede the precision of downstream topic models that\ndeduce the affiliated disciplines of these proposals. At the data level,\nproposals penned by experts and scientists are inherently complex technological\ntexts, replete with intricate terminologies, which augmenting such specialized\ntext data poses unique challenges. At the system level, this, in turn,\ncompromises the fairness of AI-assisted reviewer assignment systems, which\nraises a spotlight on solving this issue. This study leverages large language\nmodels (Llama V1) as data generators to augment research proposals categorized\nwithin intricate disciplinary hierarchies, aiming to rectify data imbalances\nand enhance the equity of expert assignments. We first sample within the\nhierarchical structure to find the under-represented class. Then we designed a\nprompt for keyword-based research proposal generation. Our experiments attests\nto the efficacy of the generated data, demonstrating that research proposals\nproduced using the prompts can effectively address the aforementioned issues\nand generate high quality scientific text data, thus help the model overcome\nthe imbalanced issue."
  },
  {
    "arxiv_id": "2310.06626",
    "title": "Topic-DPR: Topic-based Prompts for Dense Passage Retrieval",
    "url": "http://arxiv.org/abs/2310.06626v1",
    "abstract": "Prompt-based learning's efficacy across numerous natural language processing\ntasks has led to its integration into dense passage retrieval. Prior research\nhas mainly focused on enhancing the semantic understanding of pre-trained\nlanguage models by optimizing a single vector as a continuous prompt. This\napproach, however, leads to a semantic space collapse; identical semantic\ninformation seeps into all representations, causing their distributions to\nconverge in a restricted region. This hinders differentiation between relevant\nand irrelevant passages during dense retrieval. To tackle this issue, we\npresent Topic-DPR, a dense passage retrieval model that uses topic-based\nprompts. Unlike the single prompt method, multiple topic-based prompts are\nestablished over a probabilistic simplex and optimized simultaneously through\ncontrastive learning. This encourages representations to align with their topic\ndistributions, improving space uniformity. Furthermore, we introduce a novel\npositive and negative sampling strategy, leveraging semi-structured data to\nboost dense retrieval efficiency. Experimental results from two datasets affirm\nthat our method surpasses previous state-of-the-art retrieval techniques."
  },
  {
    "arxiv_id": "2310.06504",
    "title": "Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task",
    "url": "http://arxiv.org/abs/2310.06504v1",
    "abstract": "With the increasing capabilities of large language models (LLMs), these\nhigh-performance models have achieved state-of-the-art results on a wide range\nof natural language processing (NLP) tasks. However, the models' performance on\ncommonly-used benchmark datasets often fails to accurately reflect their\nreliability and robustness when applied to real-world noisy data. To address\nthese challenges, we propose a unified robustness evaluation framework based on\nthe slot-filling task to systematically evaluate the dialogue understanding\ncapability of LLMs in diverse input perturbation scenarios. Specifically, we\nconstruct a input perturbation evaluation dataset, Noise-LLM, which contains\nfive types of single perturbation and four types of mixed perturbation data.\nFurthermore, we utilize a multi-level data augmentation method (character,\nword, and sentence levels) to construct a candidate data pool, and carefully\ndesign two ways of automatic task demonstration construction strategies\n(instance-level and entity-level) with various prompt templates. Our aim is to\nassess how well various robustness methods of LLMs perform in real-world noisy\nscenarios. The experiments have demonstrated that the current open-source LLMs\ngenerally achieve limited perturbation robustness performance. Based on these\nexperimental observations, we make some forward-looking suggestions to fuel the\nresearch in this direction."
  },
  {
    "arxiv_id": "2310.07676",
    "title": "Composite Backdoor Attacks Against Large Language Models",
    "url": "http://arxiv.org/abs/2310.07676v1",
    "abstract": "Large language models (LLMs) have demonstrated superior performance compared\nto previous methods on various tasks, and often serve as the foundation models\nfor many researches and services. However, the untrustworthy third-party LLMs\nmay covertly introduce vulnerabilities for downstream tasks. In this paper, we\nexplore the vulnerability of LLMs through the lens of backdoor attacks.\nDifferent from existing backdoor attacks against LLMs, ours scatters multiple\ntrigger keys in different prompt components. Such a Composite Backdoor Attack\n(CBA) is shown to be stealthier than implanting the same multiple trigger keys\nin only a single component. CBA ensures that the backdoor is activated only\nwhen all trigger keys appear. Our experiments demonstrate that CBA is effective\nin both natural language processing (NLP) and multimodal tasks. For instance,\nwith $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset,\nour attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered\nRate (FTR) below $2.06\\%$ and negligible model accuracy degradation. Our work\nhighlights the necessity of increased security research on the trustworthiness\nof foundation LLMs."
  },
  {
    "arxiv_id": "2310.07629",
    "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",
    "url": "http://arxiv.org/abs/2310.07629v1",
    "abstract": "Human feedback is increasingly used to steer the behaviours of Large Language\nModels (LLMs). However, it is unclear how to collect and incorporate feedback\nin a way that is efficient, effective and unbiased, especially for highly\nsubjective human preferences and values. In this paper, we survey existing\napproaches for learning from human feedback, drawing on 95 papers primarily\nfrom the ACL and arXiv repositories.First, we summarise the past, pre-LLM\ntrends for integrating human feedback into language models. Second, we give an\noverview of present techniques and practices, as well as the motivations for\nusing feedback; conceptual frameworks for defining values and preferences; and\nhow feedback is collected and from whom. Finally, we encourage a better future\nof feedback learning in LLMs by raising five unresolved conceptual and\npractical challenges."
  },
  {
    "arxiv_id": "2310.07282",
    "title": "An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT",
    "url": "http://arxiv.org/abs/2310.07282v2",
    "abstract": "This paper conducts a comprehensive investigation into applying large\nlanguage models, particularly on BioBERT, in healthcare. It begins with\nthoroughly examining previous natural language processing (NLP) approaches in\nhealthcare, shedding light on the limitations and challenges these methods\nface. Following that, this research explores the path that led to the\nincorporation of BioBERT into healthcare applications, highlighting its\nsuitability for addressing the specific requirements of tasks related to\nbiomedical text mining. The analysis outlines a systematic methodology for\nfine-tuning BioBERT to meet the unique needs of the healthcare domain. This\napproach includes various components, including the gathering of data from a\nwide range of healthcare sources, data annotation for tasks like identifying\nmedical entities and categorizing them, and the application of specialized\npreprocessing techniques tailored to handle the complexities found in\nbiomedical texts. Additionally, the paper covers aspects related to model\nevaluation, with a focus on healthcare benchmarks and functions like processing\nof natural language in biomedical, question-answering, clinical document\nclassification, and medical entity recognition. It explores techniques to\nimprove the model's interpretability and validates its performance compared to\nexisting healthcare-focused language models. The paper thoroughly examines\nethical considerations, particularly patient privacy and data security. It\nhighlights the benefits of incorporating BioBERT into healthcare contexts,\nincluding enhanced clinical decision support and more efficient information\nretrieval. Nevertheless, it acknowledges the impediments and complexities of\nthis integration, encompassing concerns regarding data privacy, transparency,\nresource-intensive requirements, and the necessity for model customization to\nalign with diverse healthcare domains."
  },
  {
    "arxiv_id": "2310.08123",
    "title": "Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification",
    "url": "http://arxiv.org/abs/2310.08123v1",
    "abstract": "Authorship verification (AV) is a fundamental task in natural language\nprocessing (NLP) and computational linguistics, with applications in forensic\nanalysis, plagiarism detection, and identification of deceptive content.\nExisting AV techniques, including traditional stylometric and deep learning\napproaches, face limitations in terms of data requirements and lack of\nexplainability. To address these limitations, this paper proposes PromptAV, a\nnovel technique that leverages Large-Language Models (LLMs) for AV by providing\nstep-by-step stylometric explanation prompts. PromptAV outperforms\nstate-of-the-art baselines, operates effectively with limited training data,\nand enhances interpretability through intuitive explanations, showcasing its\npotential as an effective and interpretable solution for the AV task."
  },
  {
    "arxiv_id": "2310.07871",
    "title": "Hierarchical Pretraining on Multimodal Electronic Health Records",
    "url": "http://arxiv.org/abs/2310.07871v1",
    "abstract": "Pretraining has proven to be a powerful technique in natural language\nprocessing (NLP), exhibiting remarkable success in various NLP downstream\ntasks. However, in the medical domain, existing pretrained models on electronic\nhealth records (EHR) fail to capture the hierarchical nature of EHR data,\nlimiting their generalization capability across diverse downstream tasks using\na single pretrained model. To tackle this challenge, this paper introduces a\nnovel, general, and unified pretraining framework called MEDHMP, specifically\ndesigned for hierarchically multimodal EHR data. The effectiveness of the\nproposed MEDHMP is demonstrated through experimental results on eight\ndownstream tasks spanning three levels. Comparisons against eighteen baselines\nfurther highlight the efficacy of our approach."
  },
  {
    "arxiv_id": "2310.07830",
    "title": "Does Synthetic Data Make Large Language Models More Efficient?",
    "url": "http://arxiv.org/abs/2310.07830v1",
    "abstract": "Natural Language Processing (NLP) has undergone transformative changes with\nthe advent of deep learning methodologies. One challenge persistently\nconfronting researchers is the scarcity of high-quality, annotated datasets\nthat drive these models. This paper explores the nuances of synthetic data\ngeneration in NLP, with a focal point on template-based question generation. By\nassessing its advantages, including data augmentation potential and the\nintroduction of structured variety, we juxtapose these benefits against\ninherent limitations, such as the risk of overfitting and the constraints posed\nby pre-defined templates. Drawing from empirical evaluations, we demonstrate\nthe impact of template-based synthetic data on the performance of modern\ntransformer models. We conclude by emphasizing the delicate balance required\nbetween synthetic and real-world data, and the future trajectories of\nintegrating synthetic data in model training pipelines. The findings aim to\nguide NLP practitioners in harnessing synthetic data's potential, ensuring\noptimal model performance in diverse applications."
  },
  {
    "arxiv_id": "2310.10513",
    "title": "Unifying Image Processing as Visual Prompting Question Answering",
    "url": "http://arxiv.org/abs/2310.10513v1",
    "abstract": "Image processing is a fundamental task in computer vision, which aims at\nenhancing image quality and extracting essential features for subsequent vision\napplications. Traditionally, task-specific models are developed for individual\ntasks and designing such models requires distinct expertise. Building upon the\nsuccess of large language models (LLMs) in natural language processing (NLP),\nthere is a similar trend in computer vision, which focuses on developing\nlarge-scale models through pretraining and in-context learning. This paradigm\nshift reduces the reliance on task-specific models, yielding a powerful unified\nmodel to deal with various tasks. However, these advances have predominantly\nconcentrated on high-level vision tasks, with less attention paid to low-level\nvision tasks. To address this issue, we propose a universal model for general\nimage processing that covers image restoration, image enhancement, image\nfeature extraction tasks, etc. Our proposed framework, named PromptGIP, unifies\nthese diverse image processing tasks within a universal framework. Inspired by\nNLP question answering (QA) techniques, we employ a visual prompting question\nanswering paradigm. Specifically, we treat the input-output image pair as a\nstructured question-answer sentence, thereby reprogramming the image processing\ntask as a prompting QA problem. PromptGIP can undertake diverse cross-domain\ntasks using provided visual prompts, eliminating the need for task-specific\nfinetuning. Our methodology offers a universal and adaptive solution to general\nimage processing. While PromptGIP has demonstrated a certain degree of\nout-of-domain task generalization capability, further research is expected to\nfully explore its more powerful emergent generalization."
  },
  {
    "arxiv_id": "2310.10449",
    "title": "Text Summarization Using Large Language Models: A Comparative Study of MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models",
    "url": "http://arxiv.org/abs/2310.10449v1",
    "abstract": "Text summarization is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation.\nLeveraging Large Language Models (LLMs) has shown remarkable promise in\nenhancing summarization techniques. This paper embarks on an exploration of\ntext summarization with a diverse set of LLMs, including MPT-7b-instruct,\nfalcon-7b-instruct, and OpenAI ChatGPT text-davinci-003 models. The experiment\nwas performed with different hyperparameters and evaluated the generated\nsummaries using widely accepted metrics such as the Bilingual Evaluation\nUnderstudy (BLEU) Score, Recall-Oriented Understudy for Gisting Evaluation\n(ROUGE) Score, and Bidirectional Encoder Representations from Transformers\n(BERT) Score. According to the experiment, text-davinci-003 outperformed the\nothers. This investigation involved two distinct datasets: CNN Daily Mail and\nXSum. Its primary objective was to provide a comprehensive understanding of the\nperformance of Large Language Models (LLMs) when applied to different datasets.\nThe assessment of these models' effectiveness contributes valuable insights to\nresearchers and practitioners within the NLP domain. This work serves as a\nresource for those interested in harnessing the potential of LLMs for text\nsummarization and lays the foundation for the development of advanced\nGenerative AI applications aimed at addressing a wide spectrum of business\nchallenges."
  },
  {
    "arxiv_id": "2310.10362",
    "title": "Prompt Tuning for Multi-View Graph Contrastive Learning",
    "url": "http://arxiv.org/abs/2310.10362v1",
    "abstract": "Graphs have become an important modeling tool for web applications, and Graph\nNeural Networks (GNNs) have achieved great success in graph representation\nlearning. However, the performance of traditional GNNs heavily relies on a\nlarge amount of supervision. Recently, ``pre-train, fine-tune'' has become the\nparadigm to address the issues of label dependency and poor generalization.\nHowever, the pre-training strategies vary for graphs with homophily and\nheterophily, and the objectives for various downstream tasks also differ. This\nleads to a gap between pretexts and downstream tasks, resulting in ``negative\ntransfer'' and poor performance. Inspired by prompt learning in Natural\nLanguage Processing (NLP), many studies turn to bridge the gap and fully\nleverage the pre-trained model. However, existing methods for graph prompting\nare tailored to homophily, neglecting inherent heterophily on graphs.\nMeanwhile, most of them rely on the randomly initialized prompts, which\nnegatively impact on the stability. Therefore, we propose Self-Prompt, a\nprompting framework for graphs based on the model and data itself. We first\nintroduce asymmetric graph contrastive learning for pretext to address\nheterophily and align the objectives of pretext and downstream tasks. Then we\nreuse the component from pre-training phase as the self adapter and introduce\nself-prompts based on graph itself for task adaptation. Finally, we conduct\nextensive experiments on 11 benchmark datasets to demonstrate its superiority.\nWe provide our codes at https://github.com/gongchenghua/Self-Pro."
  },
  {
    "arxiv_id": "2310.10076",
    "title": "Verbosity Bias in Preference Labeling by Large Language Models",
    "url": "http://arxiv.org/abs/2310.10076v1",
    "abstract": "In recent years, Large Language Models (LLMs) have witnessed a remarkable\nsurge in prevalence, altering the landscape of natural language processing and\nmachine learning. One key factor in improving the performance of LLMs is\nalignment with humans achieved with Reinforcement Learning from Human Feedback\n(RLHF), as for many LLMs such as GPT-4, Bard, etc. In addition, recent studies\nare investigating the replacement of human feedback with feedback from other\nLLMs named Reinforcement Learning from AI Feedback (RLAIF). We examine the\nbiases that come along with evaluating LLMs with other LLMs and take a closer\nlook into verbosity bias -- a bias where LLMs sometimes prefer more verbose\nanswers even if they have similar qualities. We see that in our problem\nsetting, GPT-4 prefers longer answers more than humans. We also propose a\nmetric to measure this bias."
  },
  {
    "arxiv_id": "2310.10035",
    "title": "Empirical Study of Zero-Shot NER with ChatGPT",
    "url": "http://arxiv.org/abs/2310.10035v1",
    "abstract": "Large language models (LLMs) exhibited powerful capability in various natural\nlanguage processing tasks. This work focuses on exploring LLM performance on\nzero-shot information extraction, with a focus on the ChatGPT and named entity\nrecognition (NER) task. Inspired by the remarkable reasoning capability of LLM\non symbolic and arithmetic reasoning, we adapt the prevalent reasoning methods\nto NER and propose reasoning strategies tailored for NER. First, we explore a\ndecomposed question-answering paradigm by breaking down the NER task into\nsimpler subproblems by labels. Second, we propose syntactic augmentation to\nstimulate the model's intermediate thinking in two ways: syntactic prompting,\nwhich encourages the model to analyze the syntactic structure itself, and tool\naugmentation, which provides the model with the syntactic information generated\nby a parsing tool. Besides, we adapt self-consistency to NER by proposing a\ntwo-stage majority voting strategy, which first votes for the most consistent\nmentions, then the most consistent types. The proposed methods achieve\nremarkable improvements for zero-shot NER across seven benchmarks, including\nChinese and English datasets, and on both domain-specific and general-domain\nscenarios. In addition, we present a comprehensive analysis of the error types\nwith suggestions for optimization directions. We also verify the effectiveness\nof the proposed methods on the few-shot setting and other LLMs."
  },
  {
    "arxiv_id": "2310.11397",
    "title": "Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning",
    "url": "http://arxiv.org/abs/2310.11397v1",
    "abstract": "Large Language Models (LLMs) are powerful tools for natural language\nprocessing, enabling novel applications and user experiences. However, to\nachieve optimal performance, LLMs often require adaptation with private data,\nwhich poses privacy and security challenges. Several techniques have been\nproposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA),\nSoft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative\nprivacy and security properties have not been systematically investigated. In\nthis work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL\nagainst three types of well-established attacks: membership inference, which\nexposes data leakage (privacy); backdoor, which injects malicious behavior\n(security); and model stealing, which can violate intellectual property\n(privacy and security). Our results show that there is no silver bullet for\nprivacy and security in LLM adaptation and each technique has different\nstrengths and weaknesses."
  },
  {
    "arxiv_id": "2310.11374",
    "title": "DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for Emotion Recognition in Conversations",
    "url": "http://arxiv.org/abs/2310.11374v1",
    "abstract": "Large language models (LLMs) and their variants have shown extraordinary\nefficacy across numerous downstream natural language processing (NLP) tasks,\nwhich has presented a new vision for the development of NLP. Despite their\nremarkable performance in natural language generating (NLG), LLMs lack a\ndistinct focus on the emotion understanding domain. As a result, using LLMs for\nemotion recognition may lead to suboptimal and inadequate precision. Another\nlimitation of LLMs is that they are typical trained without leveraging\nmulti-modal information. To overcome these limitations, we propose DialogueLLM,\na context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA\nmodels with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.\nThe visual information is considered as the supplementary knowledge to\nconstruct high-quality instructions. We offer a comprehensive evaluation of our\nproposed model on three benchmarking emotion recognition in conversations (ERC)\ndatasets and compare the results against the SOTA baselines and other SOTA\nLLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB\nA100 GPU in 5 hours, facilitating reproducibility for other researchers."
  },
  {
    "arxiv_id": "2310.11207",
    "title": "Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations",
    "url": "http://arxiv.org/abs/2310.11207v1",
    "abstract": "Large language models (LLMs) such as ChatGPT have demonstrated superior\nperformance on a variety of natural language processing (NLP) tasks including\nsentiment analysis, mathematical reasoning and summarization. Furthermore,\nsince these models are instruction-tuned on human conversations to produce\n\"helpful\" responses, they can and often will produce explanations along with\nthe response, which we call self-explanations. For example, when analyzing the\nsentiment of a movie review, the model may output not only the positivity of\nthe sentiment, but also an explanation (e.g., by listing the sentiment-laden\nwords such as \"fantastic\" and \"memorable\" in the review). How good are these\nautomatically generated self-explanations? In this paper, we investigate this\nquestion on the task of sentiment analysis and for feature attribution\nexplanation, one of the most commonly studied settings in the interpretability\nliterature (for pre-ChatGPT models). Specifically, we study different ways to\nelicit the self-explanations, evaluate their faithfulness on a set of\nevaluation metrics, and compare them to traditional explanation methods such as\nocclusion or LIME saliency maps. Through an extensive set of experiments, we\nfind that ChatGPT's self-explanations perform on par with traditional ones, but\nare quite different from them according to various agreement metrics, meanwhile\nbeing much cheaper to produce (as they are generated along with the\nprediction). In addition, we identified several interesting characteristics of\nthem, which prompt us to rethink many current model interpretability practices\nin the era of ChatGPT(-like) LLMs."
  },
  {
    "arxiv_id": "2310.11166",
    "title": "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing",
    "url": "http://arxiv.org/abs/2310.11166v1",
    "abstract": "English and Chinese, known as resource-rich languages, have witnessed the\nstrong development of transformer-based language models for natural language\nprocessing tasks. Although Vietnam has approximately 100M people speaking\nVietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,\nperformed well on general Vietnamese NLP tasks, including POS tagging and named\nentity recognition. These pre-trained language models are still limited to\nVietnamese social media tasks. In this paper, we present the first monolingual\npre-trained language model for Vietnamese social media texts, ViSoBERT, which\nis pre-trained on a large-scale corpus of high-quality and diverse Vietnamese\nsocial media texts using XLM-R architecture. Moreover, we explored our\npre-trained model on five important natural language downstream tasks on\nVietnamese social media texts: emotion recognition, hate speech detection,\nsentiment analysis, spam reviews detection, and hate speech spans detection.\nOur experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses\nthe previous state-of-the-art models on multiple Vietnamese social media tasks.\nOur ViSoBERT model is available only for research purposes."
  },
  {
    "arxiv_id": "2310.11146",
    "title": "The Quo Vadis of the Relationship between Language and Large Language Models",
    "url": "http://arxiv.org/abs/2310.11146v1",
    "abstract": "In the field of Artificial (General) Intelligence (AI), the several recent\nadvancements in Natural language processing (NLP) activities relying on Large\nLanguage Models (LLMs) have come to encourage the adoption of LLMs as\nscientific models of language. While the terminology employed for the\ncharacterization of LLMs favors their embracing as such, it is not clear that\nthey are in a place to offer insights into the target system they seek to\nrepresent. After identifying the most important theoretical and empirical risks\nbrought about by the adoption of scientific models that lack transparency, we\ndiscuss LLMs relating them to every scientific model's fundamental components:\nthe object, the medium, the meaning and the user. We conclude that, at their\ncurrent stage of development, LLMs hardly offer any explanations for language,\nand then we provide an outlook for more informative future research directions\non this topic."
  },
  {
    "arxiv_id": "2310.11029",
    "title": "Core Building Blocks: Next Gen Geo Spatial GPT Application",
    "url": "http://arxiv.org/abs/2310.11029v1",
    "abstract": "This paper proposes MapGPT which is a novel approach that integrates the\ncapabilities of language models, specifically large language models (LLMs),\nwith spatial data processing techniques. This paper introduces MapGPT, which\naims to bridge the gap between natural language understanding and spatial data\nanalysis by highlighting the relevant core building blocks. By combining the\nstrengths of LLMs and geospatial analysis, MapGPT enables more accurate and\ncontextually aware responses to location-based queries. The proposed\nmethodology highlights building LLMs on spatial and textual data, utilizing\ntokenization and vector representations specific to spatial information. The\npaper also explores the challenges associated with generating spatial vector\nrepresentations. Furthermore, the study discusses the potential of\ncomputational capabilities within MapGPT, allowing users to perform geospatial\ncomputations and obtain visualized outputs. Overall, this research paper\npresents the building blocks and methodology of MapGPT, highlighting its\npotential to enhance spatial data understanding and generation in natural\nlanguage processing applications."
  },
  {
    "arxiv_id": "2310.10930",
    "title": "Enhanced Transformer Architecture for Natural Language Processing",
    "url": "http://arxiv.org/abs/2310.10930v1",
    "abstract": "Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset."
  },
  {
    "arxiv_id": "2310.12069",
    "title": "Transformers for scientific data: a pedagogical review for astronomers",
    "url": "http://arxiv.org/abs/2310.12069v2",
    "abstract": "The deep learning architecture associated with ChatGPT and related generative\nAI products is known as transformers. Initially applied to Natural Language\nProcessing, transformers and the self-attention mechanism they exploit have\ngained widespread interest across the natural sciences. The goal of this\npedagogical and informal review is to introduce transformers to scientists. The\nreview includes the mathematics underlying the attention mechanism, a\ndescription of the original transformer architecture, and a section on\napplications to time series and imaging data in astronomy. We include a\nFrequently Asked Questions section for readers who are curious about generative\nAI or interested in getting started with transformers for their research\nproblem."
  },
  {
    "arxiv_id": "2310.12059",
    "title": "Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education",
    "url": "http://arxiv.org/abs/2310.12059v1",
    "abstract": "In this paper, we evaluate the ability of large language models (LLMs) to\nperform multiple choice symbol binding (MCSB) for multiple choice question\nanswering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus\non Vietnamese, with fewer challenging MCQA datasets than in English. The two\nexisting datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent\nresearch in Vietnamese natural language processing (NLP) has focused on the\nVietnamese National High School Graduation Examination (VNHSGE) from 2019 to\n2023 to evaluate ChatGPT. However, these studies have mainly focused on how\nChatGPT solves the VNHSGE step by step. We aim to create a novel and\nhigh-quality dataset by providing structured guidelines for typing LaTeX\nformulas for mathematics, physics, chemistry, and biology. This dataset can be\nused to evaluate the MCSB ability of LLMs and smaller language models (LMs)\nbecause it is typed in a strict LaTeX style. We focus on predicting the\ncharacter (A, B, C, or D) that is the most likely answer to a question, given\nthe context of the question. Our evaluation of six well-known LLMs, namely\nBLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the\nViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising\nresults on the MCSB ability of LLMs for Vietnamese. The dataset is available\nfor research purposes only."
  },
  {
    "arxiv_id": "2310.11655",
    "title": "Field-testing items using artificial intelligence: Natural language processing with transformers",
    "url": "http://arxiv.org/abs/2310.11655v1",
    "abstract": "Five thousand variations of the RoBERTa model, an artificially intelligent\n\"transformer\" that can understand text language, completed an English literacy\nexam with 29 multiple-choice questions. Data were used to calculate the\npsychometric properties of the items, which showed some degree of agreement to\nthose obtained from human examinee data."
  },
  {
    "arxiv_id": "2310.12746",
    "title": "TabuLa: Harnessing Language Models for Tabular Data Synthesis",
    "url": "http://arxiv.org/abs/2310.12746v1",
    "abstract": "Tabular data synthesis is crucial for addressing privacy and security\nconcerns in industries reliant on tabular data. While recent advancements adopt\nlarge language models (LLMs) for realistic tabular data generation, their long\ntraining times and limited reusability hinder practical applications. In this\npaper, we propose Tabula, a tabular data synthesizer that leverages the\nstructure of LLM. Unlike state-of-the-art (SOTA) LLM-based tabular data\nsynthesizers that rely on pre-trained LLMs, Tabula discards the pre-trained\nweights originally designed for natural language tasks, focusing instead on a\ntailored approach for tabular data. In addition, Tabula introduces a token\nsequence compression strategy that significantly reduces training time while\nmaintaining data quality, alongside a novel token padding method that improves\nsequence alignment across training batches. Experiments on six datasets show\nthat Tabula achieves superior synthetic data utility compared to current SOTA\nmethods. Additionally, the results demonstrate that Tabula model trained on\ntabular datasets serves effectively as a foundational model for synthesizing\nnew tabular datasets. Furthermore, the proposed padding method outperforms the\nconventional left and right padding strategies. Finally, the results highlight\nthat Tabula averagely reduces training time per epoch by 46.2% compared to\nstate-of-the-art LLM approaches while achieving higher data utility. Our code\nis available at https://github.com/zhao-zilong/Tabula"
  },
  {
    "arxiv_id": "2310.12664",
    "title": "Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing",
    "url": "http://arxiv.org/abs/2310.12664v1",
    "abstract": "The emergence of Large Language Models (LLMs), such as ChatGPT, has\nrevolutionized general natural language preprocessing (NLP) tasks. However,\ntheir expertise in the financial domain lacks a comprehensive evaluation. To\nassess the ability of LLMs to solve financial NLP tasks, we present FinLMEval,\na framework for Financial Language Model Evaluation, comprising nine datasets\ndesigned to evaluate the performance of language models. This study compares\nthe performance of encoder-only language models and the decoder-only language\nmodels. Our findings reveal that while some decoder-only LLMs demonstrate\nnotable performance across most financial tasks via zero-shot prompting, they\ngenerally lag behind the fine-tuned expert models, especially when dealing with\nproprietary datasets. We hope this study provides foundation evaluations for\ncontinuing efforts to build more advanced LLMs in the financial domain."
  },
  {
    "arxiv_id": "2310.12477",
    "title": "An Exploration of In-Context Learning for Speech Language Model",
    "url": "http://arxiv.org/abs/2310.12477v1",
    "abstract": "Ever since the development of GPT-3 in the natural language processing (NLP)\nfield, in-context learning (ICL) has played an essential role in utilizing\nlarge language models (LLMs). By presenting the LM utterance-label\ndemonstrations at the input, the LM can accomplish few-shot learning without\nrelying on gradient descent or requiring explicit modification of its\nparameters. This enables the LM to perform various downstream tasks in a\nblack-box manner. Despite the success of ICL in NLP, little work is exploring\nthe possibility of ICL in speech processing. This study is the first work\nexploring ICL for speech classification tasks with textless speech LM. We first\nshow that the current speech LM lacks the ICL capability. We then perform\nwarmup training on the speech LM, equipping the LM with demonstration learning\ncapability. This paper explores and proposes the first speech LM capable of\nperforming unseen classification tasks in an ICL manner."
  },
  {
    "arxiv_id": "2310.12462",
    "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights",
    "url": "http://arxiv.org/abs/2310.12462v1",
    "abstract": "In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data."
  },
  {
    "arxiv_id": "2310.12442",
    "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer",
    "url": "http://arxiv.org/abs/2310.12442v1",
    "abstract": "Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest."
  },
  {
    "arxiv_id": "2310.13332",
    "title": "Democratizing Reasoning Ability: Tailored Learning from Large Language Model",
    "url": "http://arxiv.org/abs/2310.13332v1",
    "abstract": "Large language models (LLMs) exhibit impressive emergent abilities in natural\nlanguage processing, but their democratization is hindered due to huge\ncomputation requirements and closed-source nature. Recent research on advancing\nopen-source smaller LMs by distilling knowledge from black-box LLMs has\nobtained promising results in the instruction-following ability. However, the\nreasoning ability which is more challenging to foster, is relatively rarely\nexplored. In this paper, we propose a tailored learning approach to distill\nsuch reasoning ability to smaller LMs to facilitate the democratization of the\nexclusive reasoning ability. In contrast to merely employing LLM as a data\nannotator, we exploit the potential of LLM as a reasoning teacher by building\nan interactive multi-round learning paradigm. This paradigm enables the student\nto expose its deficiencies to the black-box teacher who then can provide\ncustomized training data in return. Further, to exploit the reasoning potential\nof the smaller LM, we propose self-reflection learning to motivate the student\nto learn from self-made mistakes. The learning from self-reflection and LLM are\nall tailored to the student's learning status, thanks to the seamless\nintegration with the multi-round learning paradigm. Comprehensive experiments\nand analysis on mathematical and commonsense reasoning tasks demonstrate the\neffectiveness of our method. The code will be available at\nhttps://github.com/Raibows/Learn-to-Reason."
  },
  {
    "arxiv_id": "2310.13229",
    "title": "The GitHub Recent Bugs Dataset for Evaluating LLM-based Debugging Applications",
    "url": "http://arxiv.org/abs/2310.13229v1",
    "abstract": "Large Language Models (LLMs) have demonstrated strong natural language\nprocessing and code synthesis capabilities, which has led to their rapid\nadoption in software engineering applications. However, details about LLM\ntraining data are often not made public, which has caused concern as to whether\nexisting bug benchmarks are included. In lieu of the training data for the\npopular GPT models, we examine the training data of the open-source LLM\nStarCoder, and find it likely that data from the widely used Defects4J\nbenchmark was included, raising the possibility of its inclusion in GPT\ntraining data as well. This makes it difficult to tell how well LLM-based\nresults on Defects4J would generalize, as for any results it would be unclear\nwhether a technique's performance is due to LLM generalization or memorization.\nTo remedy this issue and facilitate continued research on LLM-based SE, we\npresent the GitHub Recent Bugs (GHRB) dataset, which includes 76 real-world\nJava bugs that were gathered after the OpenAI data cut-off point."
  },
  {
    "arxiv_id": "2310.15021",
    "title": "Efficient Data Learning for Open Information Extraction with Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2310.15021v1",
    "abstract": "Open Information Extraction (OpenIE) is a fundamental yet challenging task in\nNatural Language Processing, which involves extracting all triples (subject,\npredicate, object) from a given sentence. While labeling-based methods have\ntheir merits, generation-based techniques offer unique advantages, such as the\nability to generate tokens not present in the original sentence. However, these\ngeneration-based methods often require a significant amount of training data to\nlearn the task form of OpenIE and substantial training time to overcome slow\nmodel convergence due to the order penalty. In this paper, we introduce a novel\nframework, OK-IE, that ingeniously transforms the task form of OpenIE into the\npre-training task form of the T5 model, thereby reducing the need for extensive\ntraining data. Furthermore, we introduce an innovative concept of Anchor to\ncontrol the sequence of model outputs, effectively eliminating the impact of\norder penalty on model convergence and significantly reducing training time.\nExperimental results indicate that, compared to previous SOTA methods, OK-IE\nrequires only 1/100 of the training data (900 instances) and 1/120 of the\ntraining time (3 minutes) to achieve comparable results."
  },
  {
    "arxiv_id": "2310.14855",
    "title": "Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing",
    "url": "http://arxiv.org/abs/2310.14855v1",
    "abstract": "Large Language Models (LLM's) have demonstrated considerable success in\nvarious Natural Language Processing tasks, but they have yet to attain\nstate-of-the-art performance in Neural Machine Translation (NMT). Nevertheless,\ntheir significant performance in tasks demanding a broad understanding and\ncontextual processing shows their potential for translation. To exploit these\nabilities, we investigate using LLM's for MT and explore recent\nparameter-efficient fine-tuning techniques. Surprisingly, our initial\nexperiments find that fine-tuning for translation purposes even led to\nperformance degradation. To overcome this, we propose an alternative approach:\nadapting LLM's as Automatic Post-Editors (APE) rather than direct translators.\nBuilding on the LLM's exceptional ability to process and generate lengthy\nsequences, we also propose extending our approach to document-level\ntranslation. We show that leveraging Low-Rank-Adapter fine-tuning for APE can\nyield significant improvements across both sentence and document-level metrics\nwhile generalizing to out-of-domain data. Most notably, we achieve a\nstate-of-the-art accuracy rate of 89\\% on the ContraPro test set, which\nspecifically assesses the model's ability to resolve pronoun ambiguities when\ntranslating from English to German. Lastly, we investigate a practical scenario\ninvolving manual post-editing for document-level translation, where reference\ncontext is made available. Here, we demonstrate that leveraging human\ncorrections can significantly reduce the number of edits required for\nsubsequent translations (Interactive Demo for integrating manual feedback can\nbe found here:\nhttps://huggingface.co/spaces/skoneru/contextual_refinement_ende)."
  },
  {
    "arxiv_id": "2310.14845",
    "title": "ULTRA-DP: Unifying Graph Pre-training with Multi-task Graph Dual Prompt",
    "url": "http://arxiv.org/abs/2310.14845v1",
    "abstract": "Recent research has demonstrated the efficacy of pre-training graph neural\nnetworks (GNNs) to capture the transferable graph semantics and enhance the\nperformance of various downstream tasks. However, the semantic knowledge\nlearned from pretext tasks might be unrelated to the downstream task, leading\nto a semantic gap that limits the application of graph pre-training. To reduce\nthis gap, traditional approaches propose hybrid pre-training to combine various\npretext tasks together in a multi-task learning fashion and learn multi-grained\nknowledge, which, however, cannot distinguish tasks and results in some\ntransferable task-specific knowledge distortion by each other. Moreover, most\nGNNs cannot distinguish nodes located in different parts of the graph, making\nthem fail to learn position-specific knowledge and lead to suboptimal\nperformance. In this work, inspired by the prompt-based tuning in natural\nlanguage processing, we propose a unified framework for graph hybrid\npre-training which injects the task identification and position identification\ninto GNNs through a prompt mechanism, namely multi-task graph dual prompt\n(ULTRA-DP). Based on this framework, we propose a prompt-based transferability\ntest to find the most relevant pretext task in order to reduce the semantic\ngap. To implement the hybrid pre-training tasks, beyond the classical edge\nprediction task (node-node level), we further propose a novel pre-training\nparadigm based on a group of $k$-nearest neighbors (node-group level). The\ncombination of them across different scales is able to comprehensively express\nmore structural semantics and derive richer multi-grained knowledge. Extensive\nexperiments show that our proposed ULTRA-DP can significantly enhance the\nperformance of hybrid pre-training methods and show the generalizability to\nother pre-training tasks and backbone architectures."
  },
  {
    "arxiv_id": "2310.14602",
    "title": "Generative Pre-trained Transformer for Vietnamese Community-based COVID-19 Question Answering",
    "url": "http://arxiv.org/abs/2310.14602v1",
    "abstract": "Recent studies have provided empirical evidence of the wide-ranging potential\nof Generative Pre-trained Transformer (GPT), a pretrained language model, in\nthe field of natural language processing. GPT has been effectively employed as\na decoder within state-of-the-art (SOTA) question answering systems, yielding\nexceptional performance across various tasks. However, the current research\nlandscape concerning GPT's application in Vietnamese remains limited. This\npaper aims to address this gap by presenting an implementation of GPT-2 for\ncommunity-based question answering specifically focused on COVID-19 related\nqueries in Vietnamese. We introduce a novel approach by conducting a\ncomparative analysis of different Transformers vs SOTA models in the\ncommunity-based COVID-19 question answering dataset. The experimental findings\ndemonstrate that the GPT-2 models exhibit highly promising outcomes,\noutperforming other SOTA models as well as previous community-based COVID-19\nquestion answering models developed for Vietnamese."
  },
  {
    "arxiv_id": "2310.14596",
    "title": "Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning",
    "url": "http://arxiv.org/abs/2310.14596v1",
    "abstract": "Fine-grained entity typing (FET) is an essential task in natural language\nprocessing that aims to assign semantic types to entities in text. However, FET\nposes a major challenge known as the noise labeling problem, whereby current\nmethods rely on estimating noise distribution to identify noisy labels but are\nconfused by diverse noise distribution deviation. To address this limitation,\nwe introduce Co-Prediction Prompt Tuning for noise correction in FET, which\nleverages multiple prediction results to identify and correct noisy labels.\nSpecifically, we integrate prediction results to recall labeled labels and\nutilize a differentiated margin to identify inaccurate labels. Moreover, we\ndesign an optimization objective concerning divergent co-predictions during\nfine-tuning, ensuring that the model captures sufficient information and\nmaintains robustness in noise identification. Experimental results on three\nwidely-used FET datasets demonstrate that our noise correction approach\nsignificantly enhances the quality of various types of training samples,\nincluding those annotated using distant supervision, ChatGPT, and\ncrowdsourcing."
  },
  {
    "arxiv_id": "2310.14573",
    "title": "Exploring the Boundaries of GPT-4 in Radiology",
    "url": "http://arxiv.org/abs/2310.14573v1",
    "abstract": "The recent success of general-domain large language models (LLMs) has\nsignificantly changed the natural language processing paradigm towards a\nunified foundation model across domains and applications. In this paper, we\nfocus on assessing the performance of GPT-4, the most capable LLM so far, on\nthe text-based applications for radiology reports, comparing against\nstate-of-the-art (SOTA) radiology-specific models. Exploring various prompting\nstrategies, we evaluated GPT-4 on a diverse range of common radiology tasks and\nwe found GPT-4 either outperforms or is on par with current SOTA radiology\nmodels. With zero-shot prompting, GPT-4 already obtains substantial gains\n($\\approx$ 10% absolute improvement) over radiology models in temporal sentence\nsimilarity classification (accuracy) and natural language inference ($F_1$).\nFor tasks that require learning dataset-specific style or schema (e.g. findings\nsummarisation), GPT-4 improves with example-based prompting and matches\nsupervised SOTA. Our extensive error analysis with a board-certified\nradiologist shows GPT-4 has a sufficient level of radiology knowledge with only\noccasional errors in complex context that require nuanced domain knowledge. For\nfindings summarisation, GPT-4 outputs are found to be overall comparable with\nexisting manually-written impressions."
  },
  {
    "arxiv_id": "2310.16040",
    "title": "Instruct and Extract: Instruction Tuning for On-Demand Information Extraction",
    "url": "http://arxiv.org/abs/2310.16040v1",
    "abstract": "Large language models with instruction-following capabilities open the door\nto a wider group of users. However, when it comes to information extraction - a\nclassic task in natural language processing - most task-specific systems cannot\nalign well with long-tail ad hoc extraction use cases for non-expert users. To\naddress this, we propose a novel paradigm, termed On-Demand Information\nExtraction, to fulfill the personalized demands of real-world users. Our task\naims to follow the instructions to extract the desired content from the\nassociated text and present it in a structured tabular format. The table\nheaders can either be user-specified or inferred contextually by the model. To\nfacilitate research in this emerging area, we present a benchmark named\nInstructIE, inclusive of both automatically generated training data, as well as\nthe human-annotated test set. Building on InstructIE, we further develop an\nOn-Demand Information Extractor, ODIE. Comprehensive evaluations on our\nbenchmark reveal that ODIE substantially outperforms the existing open-source\nmodels of similar size. Our code and dataset are released on\nhttps://github.com/yzjiao/On-Demand-IE."
  },
  {
    "arxiv_id": "2310.15941",
    "title": "This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models",
    "url": "http://arxiv.org/abs/2310.15941v1",
    "abstract": "Although large language models (LLMs) have apparently acquired a certain\nlevel of grammatical knowledge and the ability to make generalizations, they\nfail to interpret negation, a crucial step in Natural Language Processing. We\ntry to clarify the reasons for the sub-optimal performance of LLMs\nunderstanding negation. We introduce a large semi-automatically generated\ndataset of circa 400,000 descriptive sentences about commonsense knowledge that\ncan be true or false in which negation is present in about 2/3 of the corpus in\ndifferent forms. We have used our dataset with the largest available open LLMs\nin a zero-shot approach to grasp their generalization and inference capability\nand we have also fine-tuned some of the models to assess whether the\nunderstanding of negation can be trained. Our findings show that, while LLMs\nare proficient at classifying affirmative sentences, they struggle with\nnegative sentences and lack a deep understanding of negation, often relying on\nsuperficial cues. Although fine-tuning the models on negative sentences\nimproves their performance, the lack of generalization in handling negation is\npersistent, highlighting the ongoing challenges of LLMs regarding negation\nunderstanding and generalization. The dataset and code are publicly available."
  },
  {
    "arxiv_id": "2310.15720",
    "title": "Ensemble of Task-Specific Language Models for Brain Encoding",
    "url": "http://arxiv.org/abs/2310.15720v1",
    "abstract": "Language models have been shown to be rich enough to encode fMRI activations\nof certain Regions of Interest in our Brains. Previous works have explored\ntransfer learning from representations learned for popular natural language\nprocessing tasks for predicting brain responses. In our work, we improve the\nperformance of such encoders by creating an ensemble model out of 10 popular\nLanguage Models (2 syntactic and 8 semantic). We beat the current baselines by\n10% on average across all ROIs through our ensembling methods."
  },
  {
    "arxiv_id": "2310.15638",
    "title": "CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation",
    "url": "http://arxiv.org/abs/2310.15638v1",
    "abstract": "Annotated data plays a critical role in Natural Language Processing (NLP) in\ntraining models and evaluating their performance. Given recent developments in\nLarge Language Models (LLMs), models such as ChatGPT demonstrate zero-shot\ncapability on many text-annotation tasks, comparable with or even exceeding\nhuman annotators. Such LLMs can serve as alternatives for manual annotation,\ndue to lower costs and higher scalability. However, limited work has leveraged\nLLMs as complementary annotators, nor explored how annotation work is best\nallocated among humans and LLMs to achieve both quality and cost objectives. We\npropose CoAnnotating, a novel paradigm for Human-LLM co-annotation of\nunstructured texts at scale. Under this framework, we utilize uncertainty to\nestimate LLMs' annotation capability. Our empirical study shows CoAnnotating to\nbe an effective means to allocate work from results on different datasets, with\nup to 21% performance improvement over random baseline. For code\nimplementation, see https://github.com/SALT-NLP/CoAnnotating."
  },
  {
    "arxiv_id": "2310.15594",
    "title": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression",
    "url": "http://arxiv.org/abs/2310.15594v1",
    "abstract": "Large-scale pre-trained language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, the\nmassive size of these models poses huge challenges for their deployment in\nreal-world applications. While numerous model compression techniques have been\nproposed, most of them are not well-suited for achieving extreme model\ncompression when there is a significant gap in model scale. In this paper, we\nintroduce a novel compression paradigm called Retrieval-based Knowledge\nTransfer (RetriKT), which effectively transfers the knowledge of LLMs to\nextremely small-scale models (e.g., 1%). In particular, our approach extracts\nknowledge from LLMs to construct a knowledge store, from which the small-scale\nmodel can retrieve relevant information and leverage it for effective\ninference. To improve the quality of the model, soft prompt tuning and Proximal\nPolicy Optimization (PPO) reinforcement learning techniques are employed.\nExtensive experiments are conducted on low-resource tasks from SuperGLUE and\nGLUE benchmarks. The results demonstrate that the proposed approach\nsignificantly enhances the performance of small-scale models by leveraging the\nknowledge from LLMs."
  },
  {
    "arxiv_id": "2310.15541",
    "title": "Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary",
    "url": "http://arxiv.org/abs/2310.15541v1",
    "abstract": "The non-humanlike behaviour of contemporary pre-trained language models\n(PLMs) is a leading cause undermining their trustworthiness. A striking\nphenomenon of such faulty behaviours is the generation of inconsistent\npredictions, which produces logically contradictory results, such as generating\ndifferent predictions for texts delivering the same meaning or violating\nlogical properties. Previous studies exploited data augmentation or implemented\nspecialised loss functions to alleviate the issue. However, their usage is\nlimited, because they consume expensive training resources for large-sized PLMs\nand can only handle a certain consistency type. To this end, we propose a\npractical approach that alleviates the inconsistent behaviour issue by\nfundamentally improving PLMs' meaning awareness. Based on the conceptual role\ntheory, our method allows PLMs to capture accurate meaning by learning precise\ninterrelationships between concepts from word-definition pairs in a dictionary.\nNext, we propose an efficient parameter integration technique that updates only\na few additional parameters to combine the learned interrelationship with PLMs'\npre-trained knowledge. Our experimental results reveal that the approach can\nconcurrently improve multiple types of consistency, enables efficient knowledge\nintegration, and easily applies to other languages."
  },
  {
    "arxiv_id": "2310.15326",
    "title": "Specialist or Generalist? Instruction Tuning for Specific NLP Tasks",
    "url": "http://arxiv.org/abs/2310.15326v1",
    "abstract": "The potential of large language models (LLMs) to simultaneously perform a\nwide range of natural language processing (NLP) tasks has been the subject of\nextensive research. Although instruction tuning has proven to be a\ndata-efficient method for transforming LLMs into such generalist models, their\nperformance still lags behind specialist models trained exclusively for\nspecific tasks. In this paper, we investigate whether incorporating\nbroad-coverage generalist instruction tuning can contribute to building a\nspecialist model. We hypothesize that its efficacy depends on task specificity\nand skill requirements. Our experiments assess four target tasks with distinct\ncoverage levels, revealing that integrating generalist instruction tuning\nconsistently enhances model performance when the task coverage is broad. The\neffect is particularly pronounced when the amount of task-specific training\ndata is limited. Further investigation into three target tasks focusing on\ndifferent capabilities demonstrates that generalist instruction tuning improves\nunderstanding and reasoning abilities. However, for tasks requiring factual\nknowledge, generalist data containing hallucinatory information may negatively\naffect the model's performance. Overall, our work provides a systematic guide\nfor developing specialist models with general instruction tuning. Our code and\nother related resources can be found at\nhttps://github.com/DavidFanzz/Generalist_or_Specialist."
  },
  {
    "arxiv_id": "2310.15318",
    "title": "HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks",
    "url": "http://arxiv.org/abs/2310.15318v1",
    "abstract": "Graphs have emerged as a natural choice to represent and analyze the\nintricate patterns and rich information of the Web, enabling applications such\nas online page classification and social recommendation. The prevailing\n\"pre-train, fine-tune\" paradigm has been widely adopted in graph machine\nlearning tasks, particularly in scenarios with limited labeled nodes. However,\nthis approach often exhibits a misalignment between the training objectives of\npretext tasks and those of downstream tasks. This gap can result in the\n\"negative transfer\" problem, wherein the knowledge gained from pre-training\nadversely affects performance in the downstream tasks. The surge in\nprompt-based learning within Natural Language Processing (NLP) suggests the\npotential of adapting a \"pre-train, prompt\" paradigm to graphs as an\nalternative. However, existing graph prompting techniques are tailored to\nhomogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To\nbridge this gap, we propose HetGPT, a general post-training prompting framework\nto improve the predictive performance of pre-trained heterogeneous graph neural\nnetworks (HGNNs). The key is the design of a novel prompting function that\nintegrates a virtual class prompt and a heterogeneous feature prompt, with the\naim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT\nintroduces a multi-view neighborhood aggregation mechanism, capturing the\ncomplex neighborhood structure in heterogeneous graphs. Extensive experiments\non three benchmark datasets demonstrate HetGPT's capability to enhance the\nperformance of state-of-the-art HGNNs on semi-supervised node classification."
  },
  {
    "arxiv_id": "2310.16673",
    "title": "Exploring Large Language Models for Code Explanation",
    "url": "http://arxiv.org/abs/2310.16673v1",
    "abstract": "Automating code documentation through explanatory text can prove highly\nbeneficial in code understanding. Large Language Models (LLMs) have made\nremarkable strides in Natural Language Processing, especially within software\nengineering tasks such as code generation and code summarization. This study\nspecifically delves into the task of generating natural-language summaries for\ncode snippets, using various LLMs. The findings indicate that Code LLMs\noutperform their generic counterparts, and zero-shot methods yield superior\nresults when dealing with datasets with dissimilar distributions between\ntraining and testing sets."
  },
  {
    "arxiv_id": "2310.16517",
    "title": "OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models",
    "url": "http://arxiv.org/abs/2310.16517v1",
    "abstract": "The emergence of large language models (LLMs) has revolutionized natural\nlanguage processing tasks. However, existing instruction-tuning datasets suffer\nfrom occupational bias: the majority of data relates to only a few occupations,\nwhich hampers the instruction-tuned LLMs to generate helpful responses to\nprofessional queries from practitioners in specific fields. To mitigate this\nissue and promote occupation-inclusive LLMs, we create an instruction-tuning\ndataset named \\emph{OccuQuest}, which contains 110,000+ prompt-completion pairs\nand 30,000+ dialogues covering over 1,000 occupations in 26 occupational\ncategories. We systematically request ChatGPT, organizing queries\nhierarchically based on Occupation, Responsibility, Topic, and Question, to\nensure a comprehensive coverage of occupational specialty inquiries. By\ncomparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we\nobserve that OccuQuest exhibits a more balanced distribution across\noccupations. Furthermore, we assemble three test sets for comprehensive\nevaluation, an occu-test set covering 25 occupational categories, an estate set\nfocusing on real estate, and an occu-quora set containing real-world questions\nfrom Quora. We then fine-tune LLaMA on OccuQuest to obtain OccuLLaMA, which\nsignificantly outperforms state-of-the-art LLaMA variants (Vicuna, Tulu, and\nWizardLM) on professional questions in GPT-4 and human evaluations. Notably, on\nthe occu-quora set, OccuLLaMA reaches a high win rate of 86.4\\% against\nWizardLM."
  },
  {
    "arxiv_id": "2310.16484",
    "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training",
    "url": "http://arxiv.org/abs/2310.16484v1",
    "abstract": "Representational spaces learned via language modeling are fundamental to\nNatural Language Processing (NLP), however there has been limited understanding\nregarding how and when during training various types of linguistic information\nemerge and interact. Leveraging a novel information theoretic probing suite,\nwhich enables direct comparisons of not just task performance, but their\nrepresentational subspaces, we analyze nine tasks covering syntax, semantics\nand reasoning, across 2M pre-training steps and five seeds. We identify\ncritical learning phases across tasks and time, during which subspaces emerge,\nshare information, and later disentangle to specialize. Across these phases,\nsyntactic knowledge is acquired rapidly after 0.5% of full training. Continued\nperformance improvements primarily stem from the acquisition of open-domain\nknowledge, while semantics and reasoning tasks benefit from later boosts to\nlong-range contextualization and higher specialization. Measuring cross-task\nsimilarity further reveals that linguistically related tasks share information\nthroughout training, and do so more during the critical phase of learning than\nbefore or after. Our findings have implications for model interpretability,\nmulti-task learning, and learning from limited data."
  },
  {
    "arxiv_id": "2310.17271",
    "title": "Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?",
    "url": "http://arxiv.org/abs/2310.17271v1",
    "abstract": "Understanding how and what pre-trained language models (PLMs) learn about\nlanguage is an open challenge in natural language processing. Previous work has\nfocused on identifying whether they capture semantic and syntactic information,\nand how the data or the pre-training objective affects their performance.\nHowever, to the best of our knowledge, no previous work has specifically\nexamined how information loss in input token characters affects the performance\nof PLMs. In this study, we address this gap by pre-training language models\nusing small subsets of characters from individual tokens. Surprisingly, we find\nthat pre-training even under extreme settings, i.e. using only one character of\neach token, the performance retention in standard NLU benchmarks and probing\ntasks compared to full-token models is high. For instance, a model pre-trained\nonly on single first characters from tokens achieves performance retention of\napproximately $90$\\% and $77$\\% of the full-token model in SuperGLUE and GLUE\ntasks, respectively."
  },
  {
    "arxiv_id": "2310.18018",
    "title": "NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark",
    "url": "http://arxiv.org/abs/2310.18018v1",
    "abstract": "In this position paper, we argue that the classical evaluation on Natural\nLanguage Processing (NLP) tasks using annotated benchmarks is in trouble. The\nworst kind of data contamination happens when a Large Language Model (LLM) is\ntrained on the test split of a benchmark, and then evaluated in the same\nbenchmark. The extent of the problem is unknown, as it is not straightforward\nto measure. Contamination causes an overestimation of the performance of a\ncontaminated model in a target benchmark and associated task with respect to\ntheir non-contaminated counterparts. The consequences can be very harmful, with\nwrong scientific conclusions being published while other correct ones are\ndiscarded. This position paper defines different levels of data contamination\nand argues for a community effort, including the development of automatic and\nsemi-automatic measures to detect when data from a benchmark was exposed to a\nmodel, and suggestions for flagging papers with conclusions that are\ncompromised by data contamination."
  },
  {
    "arxiv_id": "2310.17918",
    "title": "Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method",
    "url": "http://arxiv.org/abs/2310.17918v1",
    "abstract": "Large Language Models (LLMs) have shown great potential in Natural Language\nProcessing (NLP) tasks. However, recent literature reveals that LLMs generate\nnonfactual responses intermittently, which impedes the LLMs' reliability for\nfurther utilization. In this paper, we propose a novel self-detection method to\ndetect which questions that a LLM does not know that are prone to generate\nnonfactual results. Specifically, we first diversify the textual expressions\nfor a given question and collect the corresponding answers. Then we examine the\ndivergencies between the generated answers to identify the questions that the\nmodel may generate falsehoods. All of the above steps can be accomplished by\nprompting the LLMs themselves without referring to any other external\nresources. We conduct comprehensive experiments and demonstrate the\neffectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT,\nand GPT-4."
  },
  {
    "arxiv_id": "2310.19055",
    "title": "A Survey on Recent Named Entity Recognition and Relation Classification Methods with Focus on Few-Shot Learning Approaches",
    "url": "http://arxiv.org/abs/2310.19055v1",
    "abstract": "Named Entity Recognition (NER) and Relation Classification (RC) are important\nsteps in extracting information from unstructured text and formatting it into a\nmachine-readable format. We present a survey of recent deep learning models\nthat address named entity recognition and relation classification, with focus\non few-shot learning performance. Our survey is helpful for researchers in\nknowing the recent techniques in text mining and extracting structured\ninformation from raw text."
  },
  {
    "arxiv_id": "2310.18951",
    "title": "A Multimodal Ecological Civilization Pattern Recommendation Method Based on Large Language Models and Knowledge Graph",
    "url": "http://arxiv.org/abs/2310.18951v1",
    "abstract": "The Ecological Civilization Pattern Recommendation System (ECPRS) aims to\nrecommend suitable ecological civilization patterns for target regions,\npromoting sustainable development and reducing regional disparities. However,\nthe current representative recommendation methods are not suitable for\nrecommending ecological civilization patterns in a geographical context. There\nare two reasons for this. Firstly, regions have spatial heterogeneity, and the\n(ECPRS)needs to consider factors like climate, topography, vegetation, etc., to\nrecommend civilization patterns adapted to specific ecological environments,\nensuring the feasibility and practicality of the recommendations. Secondly, the\nabstract features of the ecological civilization patterns in the real world\nhave not been fully utilized., resulting in poor richness in their embedding\nrepresentations and consequently, lower performance of the recommendation\nsystem. Considering these limitations, we propose the ECPR-MML method.\nInitially, based on the novel method UGPIG, we construct a knowledge graph to\nextract regional representations incorporating spatial heterogeneity features.\nFollowing that, inspired by the significant progress made by Large Language\nModels (LLMs) in the field of Natural Language Processing (NLP), we employ\nLarge LLMs to generate multimodal features for ecological civilization patterns\nin the form of text and images. We extract and integrate these multimodal\nfeatures to obtain semantically rich representations of ecological\ncivilization. Through extensive experiments, we validate the performance of our\nECPR-MML model. Our results show that F1@5 is 2.11% higher compared to\nstate-of-the-art models, 2.02% higher than NGCF, and 1.16% higher than UGPIG.\nFurthermore, multimodal data can indeed enhance recommendation performance.\nHowever, the data generated by LLM is not as effective as real data to a\ncertain extent."
  },
  {
    "arxiv_id": "2310.18633",
    "title": "Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots",
    "url": "http://arxiv.org/abs/2310.18633v1",
    "abstract": "In the field of natural language processing, the prevalent approach involves\nfine-tuning pretrained language models (PLMs) using local samples. Recent\nresearch has exposed the susceptibility of PLMs to backdoor attacks, wherein\nthe adversaries can embed malicious prediction behaviors by manipulating a few\ntraining samples. In this study, our objective is to develop a\nbackdoor-resistant tuning procedure that yields a backdoor-free model, no\nmatter whether the fine-tuning dataset contains poisoned samples. To this end,\nwe propose and integrate a honeypot module into the original PLM, specifically\ndesigned to absorb backdoor information exclusively. Our design is motivated by\nthe observation that lower-layer representations in PLMs carry sufficient\nbackdoor features while carrying minimal information about the original tasks.\nConsequently, we can impose penalties on the information acquired by the\nhoneypot module to inhibit backdoor creation during the fine-tuning process of\nthe stem network. Comprehensive experiments conducted on benchmark datasets\nsubstantiate the effectiveness and robustness of our defensive strategy.\nNotably, these results indicate a substantial reduction in the attack success\nrate ranging from 10\\% to 40\\% when compared to prior state-of-the-art methods."
  },
  {
    "arxiv_id": "2310.20440",
    "title": "The SourceData-NLP dataset: integrating curation into scientific publishing for training large language models",
    "url": "http://arxiv.org/abs/2310.20440v1",
    "abstract": "High throughput extraction and structured labeling of data from academic\narticles is critical to enable downstream machine learning applications and\nsecondary analyses. We have embedded multimodal data curation into the academic\npublishing process to annotate segmented figure panels and captions. Natural\nlanguage processing (NLP) was combined with human-in-the-loop feedback from the\noriginal authors to increase annotation accuracy. Annotation included eight\nclasses of bioentities (small molecules, gene products, subcellular components,\ncell lines, cell types, tissues, organisms, and diseases) plus additional\nclasses delineating the entities' roles in experiment designs and\nmethodologies. The resultant dataset, SourceData-NLP, contains more than\n620,000 annotated biomedical entities, curated from 18,689 figures in 3,223\narticles in molecular and cell biology. We evaluate the utility of the dataset\nto train AI models using named-entity recognition, segmentation of figure\ncaptions into their constituent panels, and a novel context-dependent semantic\ntask assessing whether an entity is a controlled intervention target or a\nmeasurement object. We also illustrate the use of our dataset in performing a\nmulti-modal task for segmenting figures into panel images and their\ncorresponding captions."
  },
  {
    "arxiv_id": "2310.20352",
    "title": "AMERICANO: Argument Generation with Discourse-driven Decomposition and Agent Interaction",
    "url": "http://arxiv.org/abs/2310.20352v1",
    "abstract": "Argument generation is a challenging task in natural language processing,\nwhich requires rigorous reasoning and proper content organization. Inspired by\nrecent chain-of-thought prompting that breaks down a complex task into\nintermediate steps, we propose Americano, a novel framework with agent\ninteraction for argument generation. Our approach decomposes the generation\nprocess into sequential actions grounded on argumentation theory, which first\nexecutes actions sequentially to generate argumentative discourse components,\nand then produces a final argument conditioned on the components. To further\nmimic the human writing process and improve the left-to-right generation\nparadigm of current autoregressive language models, we introduce an argument\nrefinement module which automatically evaluates and refines argument drafts\nbased on feedback received. We evaluate our framework on the task of\ncounterargument generation using a subset of Reddit/CMV dataset. The results\nshow that our method outperforms both end-to-end and chain-of-thought prompting\nmethods and can generate more coherent and persuasive arguments with diverse\nand rich contents."
  },
  {
    "arxiv_id": "2310.20081",
    "title": "Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models",
    "url": "http://arxiv.org/abs/2310.20081v1",
    "abstract": "Personalization, the ability to tailor a system to individual users, is an\nessential factor in user experience with natural language processing (NLP)\nsystems. With the emergence of Large Language Models (LLMs), a key question is\nhow to leverage these models to better personalize user experiences. To\npersonalize a language model's output, a straightforward approach is to\nincorporate past user data into the language model prompt, but this approach\ncan result in lengthy inputs exceeding limitations on input length and\nincurring latency and cost issues. Existing approaches tackle such challenges\nby selectively extracting relevant user data (i.e. selective retrieval) to\nconstruct a prompt for downstream tasks. However, retrieval-based methods are\nlimited by potential information loss, lack of more profound user\nunderstanding, and cold-start challenges. To overcome these limitations, we\npropose a novel summary-augmented approach by extending retrieval-augmented\npersonalization with task-aware user summaries generated by LLMs. The summaries\ncan be generated and stored offline, enabling real-world systems with runtime\nconstraints like voice assistants to leverage the power of LLMs. Experiments\nshow our method with 75% less of retrieved user data is on-par or outperforms\nretrieval augmentation on most tasks in the LaMP personalization benchmark. We\ndemonstrate that offline summarization via LLMs and runtime retrieval enables\nbetter performance for personalization on a range of tasks under practical\nconstraints."
  },
  {
    "arxiv_id": "2310.20077",
    "title": "Partial Tensorized Transformers for Natural Language Processing",
    "url": "http://arxiv.org/abs/2310.20077v1",
    "abstract": "The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition."
  },
  {
    "arxiv_id": "2310.19975",
    "title": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing",
    "url": "http://arxiv.org/abs/2310.19975v1",
    "abstract": "To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications."
  },
  {
    "arxiv_id": "2311.00287",
    "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models",
    "url": "http://arxiv.org/abs/2311.00287v1",
    "abstract": "Clinical natural language processing requires methods that can address\ndomain-specific challenges, such as complex medical terminology and clinical\ncontexts. Recently, large language models (LLMs) have shown promise in this\ndomain. Yet, their direct deployment can lead to privacy issues and are\nconstrained by resources. To address this challenge, we delve into synthetic\nclinical text generation using LLMs for clinical NLP tasks. We propose an\ninnovative, resource-efficient approach, ClinGen, which infuses knowledge into\nthe process. Our model involves clinical knowledge extraction and\ncontext-informed LLM prompting. Both clinical topics and writing styles are\ndrawn from external domain-specific knowledge graphs and LLMs to guide data\ngeneration. Our extensive empirical study across 7 clinical NLP tasks and 16\ndatasets reveals that ClinGen consistently enhances performance across various\ntasks, effectively aligning the distribution of real datasets and significantly\nenriching the diversity of generated training instances. Our code is available\nat \\url{https://github.com/ritaranx/ClinGen}."
  },
  {
    "arxiv_id": "2311.00208",
    "title": "Transformers as Recognizers of Formal Languages: A Survey on Expressivity",
    "url": "http://arxiv.org/abs/2311.00208v1",
    "abstract": "As transformers have gained prominence in natural language processing, some\nresearchers have investigated theoretically what problems they can and cannot\nsolve, by treating problems as formal languages. Exploring such questions can\nhelp clarify the power of transformers relative to other models of computation,\ntheir fundamental capabilities and limits, and the impact of architectural\nchoices. Work in this subarea has made considerable progress in recent years.\nHere, we undertake a comprehensive survey of this work, documenting the diverse\nassumptions that underlie different results and providing a unified framework\nfor harmonizing seemingly contradictory findings."
  },
  {
    "arxiv_id": "2311.01429",
    "title": "Efficient Vision Transformer for Accurate Traffic Sign Detection",
    "url": "http://arxiv.org/abs/2311.01429v1",
    "abstract": "This research paper addresses the challenges associated with traffic sign\ndetection in self-driving vehicles and driver assistance systems. The\ndevelopment of reliable and highly accurate algorithms is crucial for the\nwidespread adoption of traffic sign recognition and detection (TSRD) in diverse\nreal-life scenarios. However, this task is complicated by suboptimal traffic\nimages affected by factors such as camera movement, adverse weather conditions,\nand inadequate lighting. This study specifically focuses on traffic sign\ndetection methods and introduces the application of the Transformer model,\nparticularly the Vision Transformer variants, to tackle this task. The\nTransformer's attention mechanism, originally designed for natural language\nprocessing, offers improved parallel efficiency. Vision Transformers have\ndemonstrated success in various domains, including autonomous driving, object\ndetection, healthcare, and defense-related applications. To enhance the\nefficiency of the Transformer model, the research proposes a novel strategy\nthat integrates a locality inductive bias and a transformer module. This\nincludes the introduction of the Efficient Convolution Block and the Local\nTransformer Block, which effectively capture short-term and long-term\ndependency information, thereby improving both detection speed and accuracy.\nExperimental evaluations demonstrate the significant advancements achieved by\nthis approach, particularly when applied to the GTSDB dataset."
  },
  {
    "arxiv_id": "2311.01108",
    "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance",
    "url": "http://arxiv.org/abs/2311.01108v1",
    "abstract": "Adopting a two-stage paradigm of pretraining followed by fine-tuning,\nPretrained Language Models (PLMs) have achieved substantial advancements in the\nfield of natural language processing. However, in real-world scenarios, data\nlabels are often noisy due to the complex annotation process, making it\nessential to develop strategies for fine-tuning PLMs with such noisy labels. To\nthis end, we introduce an innovative approach for fine-tuning PLMs using noisy\nlabels, which incorporates the guidance of Large Language Models (LLMs) like\nChatGPT. This guidance assists in accurately distinguishing between clean and\nnoisy samples and provides supplementary information beyond the noisy labels,\nthereby boosting the learning process during fine-tuning PLMs. Extensive\nexperiments on synthetic and real-world noisy datasets further demonstrate the\nsuperior advantages of our framework over the state-of-the-art baselines."
  },
  {
    "arxiv_id": "2311.02069",
    "title": "Grounded Intuition of GPT-Vision's Abilities with Scientific Images",
    "url": "http://arxiv.org/abs/2311.02069v1",
    "abstract": "GPT-Vision has impressed us on a range of vision-language tasks, but it comes\nwith the familiar new challenge: we have little idea of its capabilities and\nlimitations. In our study, we formalize a process that many have instinctively\nbeen trying already to develop \"grounded intuition\" of this new model. Inspired\nby the recent movement away from benchmarking in favor of example-driven\nqualitative evaluation, we draw upon grounded theory and thematic analysis in\nsocial science and human-computer interaction to establish a rigorous framework\nfor qualitative evaluation in natural language processing. We use our technique\nto examine alt text generation for scientific figures, finding that GPT-Vision\nis particularly sensitive to prompting, counterfactual text in images, and\nrelative spatial relationships. Our method and analysis aim to help researchers\nramp up their own grounded intuitions of new models while exposing how\nGPT-Vision can be applied to make information more accessible."
  },
  {
    "arxiv_id": "2311.01786",
    "title": "TCM-GPT: Efficient Pre-training of Large Language Models for Domain Adaptation in Traditional Chinese Medicine",
    "url": "http://arxiv.org/abs/2311.01786v1",
    "abstract": "Pre-training and fine-tuning have emerged as a promising paradigm across\nvarious natural language processing (NLP) tasks. The effectiveness of\npretrained large language models (LLM) has witnessed further enhancement,\nholding potential for applications in the field of medicine, particularly in\nthe context of Traditional Chinese Medicine (TCM). However, the application of\nthese general models to specific domains often yields suboptimal results,\nprimarily due to challenges like lack of domain knowledge, unique objectives,\nand computational efficiency. Furthermore, their effectiveness in specialized\ndomains, such as Traditional Chinese Medicine, requires comprehensive\nevaluation. To address the above issues, we propose a novel domain specific\nTCMDA (TCM Domain Adaptation) approach, efficient pre-training with\ndomain-specific corpus. Specifically, we first construct a large TCM-specific\ncorpus, TCM-Corpus-1B, by identifying domain keywords and retreving from\ngeneral corpus. Then, our TCMDA leverages the LoRA which freezes the pretrained\nmodel's weights and uses rank decomposition matrices to efficiently train\nspecific dense layers for pre-training and fine-tuning, efficiently aligning\nthe model with TCM-related tasks, namely TCM-GPT-7B. We further conducted\nextensive experiments on two TCM tasks, including TCM examination and TCM\ndiagnosis. TCM-GPT-7B archived the best performance across both datasets,\noutperforming other models by relative increments of 17% and 12% in accuracy,\nrespectively. To the best of our knowledge, our study represents the pioneering\nvalidation of domain adaptation of a large language model with 7 billion\nparameters in TCM domain. We will release both TCMCorpus-1B and TCM-GPT-7B\nmodel once accepted to facilitate interdisciplinary development in TCM and NLP,\nserving as the foundation for further study."
  },
  {
    "arxiv_id": "2311.01732",
    "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models",
    "url": "http://arxiv.org/abs/2311.01732v1",
    "abstract": "Large Language Models (LLMs) have significantly advanced the field of Natural\nLanguage Processing (NLP), but their lack of interpretability has been a major\nconcern. Current methods for interpreting LLMs are post hoc, applied after\ninference time, and have limitations such as their focus on low-level features\nand lack of explainability at higher level text units. In this work, we\nintroduce proto-lm, a prototypical network-based white-box framework that\nallows LLMs to learn immediately interpretable embeddings during the\nfine-tuning stage while maintaining competitive performance. Our method's\napplicability and interpretability are demonstrated through experiments on a\nwide range of NLP tasks, and our results indicate a new possibility of creating\ninterpretable models without sacrificing performance. This novel approach to\ninterpretability in LLMs can pave the way for more interpretable models without\nthe need to sacrifice performance."
  },
  {
    "arxiv_id": "2311.01544",
    "title": "Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization",
    "url": "http://arxiv.org/abs/2311.01544v1",
    "abstract": "Large Language Models (LLMs) have reshaped natural language processing with\ntheir impressive capabilities. However, their ever-increasing size has raised\nconcerns about their effective deployment and the need for LLM compression.\nThis study introduces the Divergent Token Metrics (DTMs), a novel approach to\nassessing compressed LLMs, addressing the limitations of traditional perplexity\nor accuracy measures that fail to accurately reflect text generation quality.\nDTMs measure token divergences that allow deeper insights into the subtleties\nof model compression, in particular, when evaluating components' impacts\nindividually. Utilizing the First Divergent Token Metric (FDTM) in model\nsparsification reveals that 25% of all attention components can be pruned\nbeyond 90% on the Llama-2 model family, still keeping SOTA performance. For\nquantization, FDTM suggests that more than 80% of parameters can be naively\ntransformed to int8 without special outlier management. These evaluations\nindicate the necessity of choosing appropriate compressions for parameters\nindividually -- and that FDTM can identify those -- while standard metrics\nresult in deteriorated outcomes."
  },
  {
    "arxiv_id": "2311.03058",
    "title": "Zero-shot Bilingual App Reviews Mining with Large Language Models",
    "url": "http://arxiv.org/abs/2311.03058v1",
    "abstract": "App reviews from app stores are crucial for improving software requirements.\nA large number of valuable reviews are continually being posted, describing\nsoftware problems and expected features. Effectively utilizing user reviews\nnecessitates the extraction of relevant information, as well as their\nsubsequent summarization. Due to the substantial volume of user reviews, manual\nanalysis is arduous. Various approaches based on natural language processing\n(NLP) have been proposed for automatic user review mining. However, the\nmajority of them requires a manually crafted dataset to train their models,\nwhich limits their usage in real-world scenarios. In this work, we propose\nMini-BAR, a tool that integrates large language models (LLMs) to perform\nzero-shot mining of user reviews in both English and French. Specifically,\nMini-BAR is designed to (i) classify the user reviews, (ii) cluster similar\nreviews together, (iii) generate an abstractive summary for each cluster and\n(iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we\ncreated a dataset containing 6,000 English and 6,000 French annotated user\nreviews and conducted extensive experiments. Preliminary results demonstrate\nthe effectiveness and efficiency of Mini-BAR in requirement engineering by\nanalyzing bilingual app reviews. (Replication package containing the code,\ndataset, and experiment setups on https://github.com/Jl-wei/mini-bar )"
  },
  {
    "arxiv_id": "2311.04166",
    "title": "Perturbed examples reveal invariances shared by language models",
    "url": "http://arxiv.org/abs/2311.04166v1",
    "abstract": "The rapid growth in natural language processing (NLP) research has led to\nnumerous new models, outpacing our understanding of how they compare to\nestablished ones. One major reason for this difficulty is saturating\nbenchmarks, which may not well reflect differences in model performance in the\nwild. In this work, we introduce a novel framework to compare two NLP models by\nrevealing their shared invariance to interpretable input perturbations\ntargeting a specific linguistic capability. Via experiments on models from the\nsame and different architecture families, this framework offers insights about\nhow changes in models (e.g., distillation, size increase) affect linguistic\ncapabilities. Furthermore, our framework enables evaluation of invariances\nbetween commercial black-box models (e.g., InstructGPT family) and models that\nare better understood (e.g., GPT-2). Across experiments, we observe that large\nlanguage models share many invariances encoded by models of various sizes,\nwhereas the invariances by large models are only shared by other large models.\nPossessing a wide variety of invariances may be key to the recent successes of\nlarge language models, and our framework can shed light on the types of\ninvariances retained or emerging in new models. We make the code publicly\navailable."
  },
  {
    "arxiv_id": "2311.04124",
    "title": "Unveiling Safety Vulnerabilities of Large Language Models",
    "url": "http://arxiv.org/abs/2311.04124v1",
    "abstract": "As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability."
  },
  {
    "arxiv_id": "2311.03812",
    "title": "Conversations in Galician: a Large Language Model for an Underrepresented Language",
    "url": "http://arxiv.org/abs/2311.03812v1",
    "abstract": "The recent proliferation of Large Conversation Language Models has\nhighlighted the economic significance of widespread access to this type of AI\ntechnologies in the current information age. Nevertheless, prevailing models\nhave primarily been trained on corpora consisting of documents written in\npopular languages. The dearth of such cutting-edge tools for low-resource\nlanguages further exacerbates their underrepresentation in the current economic\nlandscape, thereby impacting their native speakers. This paper introduces two\nnovel resources designed to enhance Natural Language Processing (NLP) for the\nGalician language. We present a Galician adaptation of the Alpaca dataset,\ncomprising 52,000 instructions and demonstrations. This dataset proves\ninvaluable for enhancing language models by fine-tuning them to more accurately\nadhere to provided instructions. Additionally, as a demonstration of the\ndataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician,\na language not originally supported by the model, by following the Alpaca\nformat. This work contributes to the research on multilingual models tailored\nfor low-resource settings, a crucial endeavor in ensuring the inclusion of all\nlinguistic communities in the development of Large Language Models. Another\nnoteworthy aspect of this research is the exploration of how knowledge of a\nclosely related language, in this case, Portuguese, can assist in generating\ncoherent text when training resources are scarce. Both the Galician Alpaca\ndataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we\nhave made the source code available to facilitate replication of this\nexperiment and encourage further advancements for underrepresented languages."
  },
  {
    "arxiv_id": "2311.03648",
    "title": "Instruct Me More! Random Prompting for Visual In-Context Learning",
    "url": "http://arxiv.org/abs/2311.03648v1",
    "abstract": "Large-scale models trained on extensive datasets, have emerged as the\npreferred approach due to their high generalizability across various tasks.\nIn-context learning (ICL), a popular strategy in natural language processing,\nuses such models for different tasks by providing instructive prompts but\nwithout updating model parameters. This idea is now being explored in computer\nvision, where an input-output image pair (called an in-context pair) is\nsupplied to the model with a query image as a prompt to exemplify the desired\noutput. The efficacy of visual ICL often depends on the quality of the prompts.\nWe thus introduce a method coined Instruct Me More (InMeMo), which augments\nin-context pairs with a learnable perturbation (prompt), to explore its\npotential. Our experiments on mainstream tasks reveal that InMeMo surpasses the\ncurrent state-of-the-art performance. Specifically, compared to the baseline\nwithout learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for\nforeground segmentation and single object detection tasks, respectively. Our\nfindings suggest that InMeMo offers a versatile and efficient way to enhance\nthe performance of visual ICL with lightweight training. Code is available at\nhttps://github.com/Jackieam/InMeMo."
  },
  {
    "arxiv_id": "2311.04532",
    "title": "Evaluating Diverse Large Language Models for Automatic and General Bug Reproduction",
    "url": "http://arxiv.org/abs/2311.04532v2",
    "abstract": "Bug reproduction is a critical developer activity that is also challenging to\nautomate, as bug reports are often in natural language and thus can be\ndifficult to transform to test cases consistently. As a result, existing\ntechniques mostly focused on crash bugs, which are easier to automatically\ndetect and verify. In this work, we overcome this limitation by using large\nlanguage models (LLMs), which have been demonstrated to be adept at natural\nlanguage processing and code generation. By prompting LLMs to generate\nbug-reproducing tests, and via a post-processing pipeline to automatically\nidentify promising generated tests, our proposed technique LIBRO could\nsuccessfully reproduce about one-third of all bugs in the widely used Defects4J\nbenchmark. Furthermore, our extensive evaluation on 15 LLMs, including 11\nopen-source LLMs, suggests that open-source LLMs also demonstrate substantial\npotential, with the StarCoder LLM achieving 70% of the reproduction performance\nof the closed-source OpenAI LLM code-davinci-002 on the large Defects4J\nbenchmark, and 90% of performance on a held-out bug dataset likely not part of\nany LLM's training data. In addition, our experiments on LLMs of different\nsizes show that bug reproduction using LIBRO improves as LLM size increases,\nproviding information as to which LLMs can be used with the LIBRO pipeline."
  },
  {
    "arxiv_id": "2311.04329",
    "title": "Formal Aspects of Language Modeling",
    "url": "http://arxiv.org/abs/2311.04329v1",
    "abstract": "Large language models have become one of the most commonly deployed NLP\ninventions. In the past half-decade, their integration into core natural\nlanguage processing tools has dramatically increased the performance of such\ntools, and they have entered the public discourse surrounding artificial\nintelligence. Consequently, it is important for both developers and researchers\nalike to understand the mathematical foundations of large language models, as\nwell as how to implement them. These notes are the accompaniment to the\ntheoretical portion of the ETH Z\\\"urich course on large language models,\ncovering what constitutes a language model from a formal, theoretical\nperspective."
  },
  {
    "arxiv_id": "2311.05232",
    "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",
    "url": "http://arxiv.org/abs/2311.05232v1",
    "abstract": "The emergence of large language models (LLMs) has marked a significant\nbreakthrough in natural language processing (NLP), fueling a paradigm shift in\ninformation acquisition. Nevertheless, LLMs are prone to hallucination,\ngenerating plausible yet nonfactual content. This phenomenon raises significant\nconcerns over the reliability of LLMs in real-world information retrieval (IR)\nsystems and has attracted intensive research to detect and mitigate such\nhallucinations. Given the open-ended general-purpose attributes inherent to\nLLMs, LLM hallucinations present distinct challenges that diverge from prior\ntask-specific models. This divergence highlights the urgency for a nuanced\nunderstanding and comprehensive overview of recent advances in LLM\nhallucinations. In this survey, we begin with an innovative taxonomy of\nhallucination in the era of LLM and then delve into the factors contributing to\nhallucinations. Subsequently, we present a thorough overview of hallucination\ndetection methods and benchmarks. Our discussion then transfers to\nrepresentative methodologies for mitigating LLM hallucinations. Additionally,\nwe delve into the current limitations faced by retrieval-augmented LLMs in\ncombating hallucinations, offering insights for developing more robust IR\nsystems. Finally, we highlight the promising research directions on LLM\nhallucinations, including hallucination in large vision-language models and\nunderstanding of knowledge boundaries in LLM hallucinations."
  },
  {
    "arxiv_id": "2311.05161",
    "title": "Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization",
    "url": "http://arxiv.org/abs/2311.05161v1",
    "abstract": "Large Language Models (LLMs) are proficient in natural language processing\ntasks, but their deployment is often restricted by extensive parameter sizes\nand computational demands. This paper focuses on post-training quantization\n(PTQ) in LLMs, specifically 4-bit weight and 8-bit activation (W4A8)\nquantization, to enhance computational efficiency -- a topic less explored\ncompared to weight-only quantization. We present two innovative techniques:\nactivation-quantization-aware scaling (AQAS) and sequence-length-aware\ncalibration (SLAC) to enhance PTQ by considering the combined effects on\nweights and activations and aligning calibration sequence lengths to target\ntasks. Moreover, we introduce dINT, a hybrid data format combining integer and\ndenormal representations, to address the underflow issue in W4A8 quantization,\nwhere small values are rounded to zero. Through rigorous evaluations of LLMs,\nincluding OPT and LLaMA, we demonstrate that our techniques significantly boost\ntask accuracies to levels comparable with full-precision models. By developing\narithmetic units compatible with dINT, we further confirm that our methods\nyield a 2$\\times$ hardware efficiency improvement compared to 8-bit integer MAC\nunit."
  },
  {
    "arxiv_id": "2311.05014",
    "title": "Interpreting Pretrained Language Models via Concept Bottlenecks",
    "url": "http://arxiv.org/abs/2311.05014v1",
    "abstract": "Pretrained language models (PLMs) have made significant strides in various\nnatural language processing tasks. However, the lack of interpretability due to\ntheir ``black-box'' nature poses challenges for responsible implementation.\nAlthough previous studies have attempted to improve interpretability by using,\ne.g., attention weights in self-attention layers, these weights often lack\nclarity, readability, and intuitiveness. In this research, we propose a novel\napproach to interpreting PLMs by employing high-level, meaningful concepts that\nare easily understandable for humans. For example, we learn the concept of\n``Food'' and investigate how it influences the prediction of a model's\nsentiment towards a restaurant review. We introduce C$^3$M, which combines\nhuman-annotated and machine-generated concepts to extract hidden neurons\ndesigned to encapsulate semantically meaningful and task-specific concepts.\nThrough empirical evaluations on real-world datasets, we manifest that our\napproach offers valuable insights to interpret PLM behavior, helps diagnose\nmodel failures, and enhances model robustness amidst noisy concept labels."
  },
  {
    "arxiv_id": "2311.06025",
    "title": "ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences",
    "url": "http://arxiv.org/abs/2311.06025v1",
    "abstract": "Recently, the increasing demand for superior medical services has highlighted\nthe discrepancies in the medical infrastructure. With big data, especially\ntexts, forming the foundation of medical services, there is an exigent need for\neffective natural language processing (NLP) solutions tailored to the\nhealthcare domain. Conventional approaches leveraging pre-trained models\npresent promising results in this domain and current large language models\n(LLMs) offer advanced foundation for medical text processing. However, most\nmedical LLMs are trained only with supervised fine-tuning (SFT), even though it\nefficiently empowers LLMs to understand and respond to medical instructions but\nis ineffective in learning domain knowledge and aligning with human preference.\nIn this work, we propose ChiMed-GPT, a new benchmark LLM designed explicitly\nfor Chinese medical domain, and undergoes a comprehensive training regime with\npre-training, SFT, and RLHF. Evaluations on tasks including information\nextraction, question answering, and dialogue generation demonstrate\nChiMed-GPT's superior performance over general domain LLMs. Furthermore, we\nanalyze possible biases through prompting ChiMed-GPT to perform attitude scales\nregarding discrimination of patients, so as to contribute to further\nresponsible development of LLMs in the medical domain. The code and model are\nreleased at https://github.com/synlp/ChiMed-GPT."
  },
  {
    "arxiv_id": "2311.05884",
    "title": "Hiformer: Heterogeneous Feature Interactions Learning with Transformers for Recommender Systems",
    "url": "http://arxiv.org/abs/2311.05884v1",
    "abstract": "Learning feature interaction is the critical backbone to building recommender\nsystems. In web-scale applications, learning feature interaction is extremely\nchallenging due to the sparse and large input feature space; meanwhile,\nmanually crafting effective feature interactions is infeasible because of the\nexponential solution space. We propose to leverage a Transformer-based\narchitecture with attention layers to automatically capture feature\ninteractions. Transformer architectures have witnessed great success in many\ndomains, such as natural language processing and computer vision. However,\nthere has not been much adoption of Transformer architecture for feature\ninteraction modeling in industry. We aim at closing the gap. We identify two\nkey challenges for applying the vanilla Transformer architecture to web-scale\nrecommender systems: (1) Transformer architecture fails to capture the\nheterogeneous feature interactions in the self-attention layer; (2) The serving\nlatency of Transformer architecture might be too high to be deployed in\nweb-scale recommender systems. We first propose a heterogeneous self-attention\nlayer, which is a simple yet effective modification to the self-attention layer\nin Transformer, to take into account the heterogeneity of feature interactions.\nWe then introduce \\textsc{Hiformer} (\\textbf{H}eterogeneous\n\\textbf{I}nteraction Trans\\textbf{former}) to further improve the model\nexpressiveness. With low-rank approximation and model pruning, \\hiformer enjoys\nfast inference for online deployment. Extensive offline experiment results\ncorroborates the effectiveness and efficiency of the \\textsc{Hiformer} model.\nWe have successfully deployed the \\textsc{Hiformer} model to a real world large\nscale App ranking model at Google Play, with significant improvement in key\nengagement metrics (up to +2.66\\%)."
  },
  {
    "arxiv_id": "2311.05850",
    "title": "Exploring Fine-tuning ChatGPT for News Recommendation",
    "url": "http://arxiv.org/abs/2311.05850v1",
    "abstract": "News recommendation systems (RS) play a pivotal role in the current digital\nage, shaping how individuals access and engage with information. The fusion of\nnatural language processing (NLP) and RS, spurred by the rise of large language\nmodels such as the GPT and T5 series, blurs the boundaries between these\ndomains, making a tendency to treat RS as a language task. ChatGPT, renowned\nfor its user-friendly interface and increasing popularity, has become a\nprominent choice for a wide range of NLP tasks. While previous studies have\nexplored ChatGPT on recommendation tasks, this study breaks new ground by\ninvestigating its fine-tuning capability, particularly within the news domain.\nIn this study, we design two distinct prompts: one designed to treat news RS as\nthe ranking task and another tailored for the rating task. We evaluate\nChatGPT's performance in news recommendation by eliciting direct responses\nthrough the formulation of these two tasks. More importantly, we unravel the\npivotal role of fine-tuning data quality in enhancing ChatGPT's personalized\nrecommendation capabilities, and illustrates its potential in addressing the\nlongstanding challenge of the \"cold item\" problem in RS. Our experiments,\nconducted using the Microsoft News dataset (MIND), reveal significant\nimprovements achieved by ChatGPT after fine-tuning, especially in scenarios\nwhere a user's topic interests remain consistent, treating news RS as a ranking\ntask. This study illuminates the transformative potential of fine-tuning\nChatGPT as a means to advance news RS, offering more effective news consumption\nexperiences."
  },
  {
    "arxiv_id": "2311.05720",
    "title": "Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models",
    "url": "http://arxiv.org/abs/2311.05720v1",
    "abstract": "Deception and persuasion play a critical role in long-horizon dialogues\nbetween multiple parties, especially when the interests, goals, and motivations\nof the participants are not aligned. Such complex tasks pose challenges for\ncurrent Large Language Models (LLM) as deception and persuasion can easily\nmislead them, especially in long-horizon multi-party dialogues. To this end, we\nexplore the game of Avalon: The Resistance, a social deduction game in which\nplayers must determine each other's hidden identities to complete their team's\nobjective. We introduce an online testbed and a dataset containing 20 carefully\ncollected and labeled games among human players that exhibit long-horizon\ndeception in a cooperative-competitive setting. We discuss the capabilities of\nLLMs to utilize deceptive long-horizon conversations between six human players\nto determine each player's goal and motivation. Particularly, we discuss the\nmultimodal integration of the chat between the players and the game's state\nthat grounds the conversation, providing further insights into the true player\nidentities. We find that even current state-of-the-art LLMs do not reach human\nperformance, making our dataset a compelling benchmark to investigate the\ndecision-making and language-processing capabilities of LLMs. Our dataset and\nonline testbed can be found at our project website:\nhttps://sstepput.github.io/Avalon-NLU/"
  },
  {
    "arxiv_id": "2311.07463",
    "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks",
    "url": "http://arxiv.org/abs/2311.07463v1",
    "abstract": "There has been a surge in LLM evaluation research to understand LLM\ncapabilities and limitations. However, much of this research has been confined\nto English, leaving LLM building and evaluation for non-English languages\nrelatively unexplored. Several new LLMs have been introduced recently,\nnecessitating their evaluation on non-English languages. This study aims to\nperform a thorough evaluation of the non-English capabilities of SoTA LLMs\n(GPT-3.5-Turbo, GPT-4, PaLM2, Gemini-Pro, Mistral, Llama2, and Gemma) by\ncomparing them on the same set of multilingual datasets. Our benchmark\ncomprises 22 datasets covering 83 languages, including low-resource African\nlanguages. We also include two multimodal datasets in the benchmark and compare\nthe performance of LLaVA models, GPT-4-Vision and Gemini-Pro-Vision. Our\nexperiments show that larger models such as GPT-4, Gemini-Pro and PaLM2\noutperform smaller models on various tasks, notably on low-resource languages,\nwith GPT-4 outperforming PaLM2 and Gemini-Pro on more datasets. We also perform\na study on data contamination and find that several models are likely to be\ncontaminated with multilingual evaluation benchmarks, necessitating approaches\nto detect and handle contamination while assessing the multilingual performance\nof LLMs."
  },
  {
    "arxiv_id": "2311.07361",
    "title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
    "url": "http://arxiv.org/abs/2311.07361v1",
    "abstract": "In recent years, groundbreaking advancements in natural language processing\nhave culminated in the emergence of powerful large language models (LLMs),\nwhich have showcased remarkable capabilities across a vast array of domains,\nincluding the understanding, generation, and translation of natural language,\nand even tasks that extend beyond language processing. In this report, we delve\ninto the performance of LLMs within the context of scientific discovery,\nfocusing on GPT-4, the state-of-the-art language model. Our investigation spans\na diverse range of scientific areas encompassing drug discovery, biology,\ncomputational chemistry (density functional theory (DFT) and molecular dynamics\n(MD)), materials design, and partial differential equations (PDE). Evaluating\nGPT-4 on scientific tasks is crucial for uncovering its potential across\nvarious research domains, validating its domain-specific expertise,\naccelerating scientific progress, optimizing resource allocation, guiding\nfuture model development, and fostering interdisciplinary research. Our\nexploration methodology primarily consists of expert-driven case assessments,\nwhich offer qualitative insights into the model's comprehension of intricate\nscientific concepts and relationships, and occasionally benchmark testing,\nwhich quantitatively evaluates the model's capacity to solve well-defined\ndomain-specific problems. Our preliminary exploration indicates that GPT-4\nexhibits promising potential for a variety of scientific applications,\ndemonstrating its aptitude for handling complex problem-solving and knowledge\nintegration tasks. Broadly speaking, we evaluate GPT-4's knowledge base,\nscientific understanding, scientific numerical calculation abilities, and\nvarious scientific prediction capabilities."
  },
  {
    "arxiv_id": "2311.06838",
    "title": "GIELLM: Japanese General Information Extraction Large Language Model Utilizing Mutual Reinforcement Effect",
    "url": "http://arxiv.org/abs/2311.06838v1",
    "abstract": "Information Extraction (IE) stands as a cornerstone in natural language\nprocessing, traditionally segmented into distinct sub-tasks. The advent of\nLarge Language Models (LLMs) heralds a paradigm shift, suggesting the\nfeasibility of a singular model addressing multiple IE subtasks. In this vein,\nwe introduce the General Information Extraction Large Language Model (GIELLM),\nwhich integrates text Classification, Sentiment Analysis, Named Entity\nRecognition, Relation Extraction, and Event Extraction using a uniform\ninput-output schema. This innovation marks the first instance of a model\nsimultaneously handling such a diverse array of IE subtasks. Notably, the\nGIELLM leverages the Mutual Reinforcement Effect (MRE), enhancing performance\nin integrated tasks compared to their isolated counterparts. Our experiments\ndemonstrate State-of-the-Art (SOTA) results in five out of six Japanese mixed\ndatasets, significantly surpassing GPT-3.5-Turbo. Further, an independent\nevaluation using the novel Text Classification Relation and Event\nExtraction(TCREE) dataset corroborates the synergistic advantages of MRE in\ntext and word classification. This breakthrough paves the way for most IE\nsubtasks to be subsumed under a singular LLM framework. Specialized fine-tune\ntask-specific models are no longer needed."
  },
  {
    "arxiv_id": "2311.06786",
    "title": "Explainability of Vision Transformers: A Comprehensive Review and New Perspectives",
    "url": "http://arxiv.org/abs/2311.06786v1",
    "abstract": "Transformers have had a significant impact on natural language processing and\nhave recently demonstrated their potential in computer vision. They have shown\npromising results over convolution neural networks in fundamental computer\nvision tasks. However, the scientific community has not fully grasped the inner\nworkings of vision transformers, nor the basis for their decision-making, which\nunderscores the importance of explainability methods. Understanding how these\nmodels arrive at their decisions not only improves their performance but also\nbuilds trust in AI systems. This study explores different explainability\nmethods proposed for visual transformers and presents a taxonomy for organizing\nthem according to their motivations, structures, and application scenarios. In\naddition, it provides a comprehensive review of evaluation criteria that can be\nused for comparing explanation results, as well as explainability tools and\nframeworks. Finally, the paper highlights essential but unexplored aspects that\ncan enhance the explainability of visual transformers, and promising research\ndirections are suggested for future investment."
  },
  {
    "arxiv_id": "2311.06737",
    "title": "Detecting and Correcting Hate Speech in Multimodal Memes with Large Visual Language Model",
    "url": "http://arxiv.org/abs/2311.06737v1",
    "abstract": "Recently, large language models (LLMs) have taken the spotlight in natural\nlanguage processing. Further, integrating LLMs with vision enables the users to\nexplore more emergent abilities in multimodality. Visual language models\n(VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive\nperformance on various visio-linguistic tasks. Consequently, there are enormous\napplications of large models that could be potentially used on social media\nplatforms. Despite that, there is a lack of related work on detecting or\ncorrecting hateful memes with VLMs. In this work, we study the ability of VLMs\non hateful meme detection and hateful meme correction tasks with zero-shot\nprompting. From our empirical experiments, we show the effectiveness of the\npretrained LLaVA model and discuss its strengths and weaknesses in these tasks."
  },
  {
    "arxiv_id": "2311.08152",
    "title": "Towards Reasoning in Large Language Models via Multi-Agent Peer Review Collaboration",
    "url": "http://arxiv.org/abs/2311.08152v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in general\nnatural language processing tasks but often fall short in complex reasoning\ntasks. Recent studies have explored human-like problem-solving strategies, such\nas self-correct, to push further the boundary of single-model reasoning\nability. In this work, we let a single model \"step outside the box\" by engaging\nmultiple models to correct each other. We introduce a multi-agent collaboration\nstrategy that emulates the academic peer review process. Each agent\nindependently constructs its own solution, provides reviews on the solutions of\nothers, and assigns confidence levels to its reviews. Upon receiving peer\nreviews, agents revise their initial solutions. Extensive experiments on three\ndifferent types of reasoning tasks show that our collaboration approach\ndelivers superior accuracy across all ten datasets compared to existing\nmethods. Further study underscores the effectiveness of integrating confidence\nin reviews, demonstrates the superiority of feedback exchange over mere\nsolution sharing, and highlights the role of capability and diversity in\nfostering successful collaboration."
  },
  {
    "arxiv_id": "2311.07978",
    "title": "How good are Large Language Models on African Languages?",
    "url": "http://arxiv.org/abs/2311.07978v1",
    "abstract": "Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/"
  },
  {
    "arxiv_id": "2311.09214",
    "title": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models",
    "url": "http://arxiv.org/abs/2311.09214v1",
    "abstract": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage processing. However, the massive scale and computational demands of\nthese models present formidable challenges when considering their practical\ndeployment in resource-constrained environments. While techniques such as\nchain-of-thought (CoT) distillation have displayed promise in distilling LLMs\ninto small language models (SLMs), there is a risk that distilled SLMs may\nstill inherit flawed reasoning and hallucinations from LLMs. To address these\nissues, we propose a twofold methodology: First, we introduce a novel method\nfor distilling the self-evaluation capability from LLMs into SLMs, aiming to\nmitigate the adverse effects of flawed reasoning and hallucinations inherited\nfrom LLMs. Second, we advocate for distilling more comprehensive thinking by\nincorporating multiple distinct CoTs and self-evaluation outputs, to ensure a\nmore thorough and robust knowledge transfer into SLMs. Experiments on three NLP\nbenchmarks demonstrate that our method significantly improves the performance\nof distilled SLMs, offering a new perspective for developing more effective and\nefficient SLMs in resource-constrained environments."
  },
  {
    "arxiv_id": "2311.09022",
    "title": "Exploring the Potential of Large Language Models in Computational Argumentation",
    "url": "http://arxiv.org/abs/2311.09022v1",
    "abstract": "Computational argumentation has become an essential tool in various domains,\nincluding law, public policy, and artificial intelligence. It is an emerging\nresearch field in natural language processing that attracts increasing\nattention. Research on computational argumentation mainly involves two types of\ntasks: argument mining and argument generation. As large language models (LLMs)\nhave demonstrated impressive capabilities in understanding context and\ngenerating natural language, it is worthwhile to evaluate the performance of\nLLMs on diverse computational argumentation tasks. This work aims to embark on\nan assessment of LLMs, such as ChatGPT, Flan models, and LLaMA2 models, in both\nzero-shot and few-shot settings. We organize existing tasks into six main\ncategories and standardize the format of fourteen openly available datasets. In\naddition, we present a new benchmark dataset on counter speech generation that\naims to holistically evaluate the end-to-end performance of LLMs on argument\nmining and argument generation. Extensive experiments show that LLMs exhibit\ncommendable performance across most of the datasets, demonstrating their\ncapabilities in the field of argumentation. Our analysis offers valuable\nsuggestions for evaluating computational argumentation and its integration with\nLLMs in future research endeavors."
  },
  {
    "arxiv_id": "2311.08890",
    "title": "Large Language Models are legal but they are not: Making the case for a powerful LegalLLM",
    "url": "http://arxiv.org/abs/2311.08890v1",
    "abstract": "Realizing the recent advances in Natural Language Processing (NLP) to the\nlegal sector poses challenging problems such as extremely long sequence\nlengths, specialized vocabulary that is usually only understood by legal\nprofessionals, and high amounts of data imbalance. The recent surge of Large\nLanguage Models (LLMs) has begun to provide new opportunities to apply NLP in\nthe legal domain due to their ability to handle lengthy, complex sequences.\nMoreover, the emergence of domain-specific LLMs has displayed extremely\npromising results on various tasks. In this study, we aim to quantify how\ngeneral LLMs perform in comparison to legal-domain models (be it an LLM or\notherwise). Specifically, we compare the zero-shot performance of three\ngeneral-purpose LLMs (ChatGPT-20b, LLaMA-2-70b, and Falcon-180b) on the LEDGAR\nsubset of the LexGLUE benchmark for contract provision classification. Although\nthe LLMs were not explicitly trained on legal data, we observe that they are\nstill able to classify the theme correctly in most cases. However, we find that\ntheir mic-F1/mac-F1 performance is up to 19.2/26.8\\% lesser than smaller models\nfine-tuned on the legal domain, thus underscoring the need for more powerful\nlegal-domain LLMs."
  },
  {
    "arxiv_id": "2311.08562",
    "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration",
    "url": "http://arxiv.org/abs/2311.08562v2",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing, demonstrating exceptional reasoning, tool usage, and memory\ncapabilities. As their applications expand into multi-agent environments, there\narises a need for a comprehensive evaluation framework that captures LLMs'\nreasoning, planning, collaboration, and other social abilities. This work\nintroduces a novel competition-based benchmark framework specifically designed\nto assess LLMs within multi-agent settings, providing quantitative metrics to\nevaluate their judgment, reasoning, deception, self-awareness, cooperation,\ncoordination, and rationality. We utilize two social deduction games alongside\nthree game-theory scenarios to create diverse environments. Our frame is\nfortified with the probabilistic graphic modeling (PGM) method, enhancing the\nLLMs' capabilities in navigating complex social and cognitive dimensions. We\nevaluate seven LLMs, quantitatively highlighting a significant capability gap\nof over threefold between the strongest, GPT o1, and the weakest, Llama-2-70B.\nIt also confirms that our PGM enhancement boosts the abilities of all selected\nmodels by an average of 37%. Our data and code can be found here\nhttps://github.com/cathyxl/MAgIC."
  },
  {
    "arxiv_id": "2311.08526",
    "title": "GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer",
    "url": "http://arxiv.org/abs/2311.08526v1",
    "abstract": "Named Entity Recognition (NER) is essential in various Natural Language\nProcessing (NLP) applications. Traditional NER models are effective but limited\nto a set of predefined entity types. In contrast, Large Language Models (LLMs)\ncan extract arbitrary entities through natural language instructions, offering\ngreater flexibility. However, their size and cost, particularly for those\naccessed via APIs like ChatGPT, make them impractical in resource-limited\nscenarios. In this paper, we introduce a compact NER model trained to identify\nany type of entity. Leveraging a bidirectional transformer encoder, our model,\nGLiNER, facilitates parallel entity extraction, an advantage over the slow\nsequential token generation of LLMs. Through comprehensive testing, GLiNER\ndemonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs\nin zero-shot evaluations on various NER benchmarks."
  },
  {
    "arxiv_id": "2311.08481",
    "title": "Functionality learning through specification instructions",
    "url": "http://arxiv.org/abs/2311.08481v1",
    "abstract": "Test suites assess natural language processing models' performance on\nspecific functionalities: cases of interest involving model robustness,\nfairness, or particular linguistic capabilities. This paper introduces\nspecification instructions: text descriptions specifying fine-grained\ntask-specific behaviors. For each functionality in a suite, we generate an\ninstruction that describes it. We combine the specification instructions to\ncreate specification-augmented prompts, which we feed to language models\npre-trained on natural instruction data.\n  We conduct experiments to measure how optimizing for some functionalities may\nnegatively impact functionalities that are not covered by the specification\nset. Our analyses across four tasks and models of diverse sizes and families\nshow that smaller models struggle to follow specification instructions.\nHowever, larger models (>~3B params.) can benefit from specifications and --\nsurprisingly -- even generalize certain desirable behaviors across\nfunctionalities."
  },
  {
    "arxiv_id": "2311.09976",
    "title": "Revolutionizing Customer Interactions: Insights and Challenges in Deploying ChatGPT and Generative Chatbots for FAQs",
    "url": "http://arxiv.org/abs/2311.09976v1",
    "abstract": "In the rapidly evolving domain of artificial intelligence, chatbots have\nemerged as a potent tool for various applications ranging from e-commerce to\nhealthcare. This research delves into the intricacies of chatbot technology,\nfrom its foundational concepts to advanced generative models like ChatGPT. We\npresent a comprehensive taxonomy of existing chatbot approaches, distinguishing\nbetween rule-based, retrieval-based, generative, and hybrid models. A specific\nemphasis is placed on ChatGPT, elucidating its merits for frequently asked\nquestions (FAQs)-based chatbots, coupled with an exploration of associated\nNatural Language Processing (NLP) techniques such as named entity recognition,\nintent classification, and sentiment analysis. The paper further delves into\nthe customization and fine-tuning of ChatGPT, its integration with knowledge\nbases, and the consequent challenges and ethical considerations that arise.\nThrough real-world applications in domains such as online shopping, healthcare,\nand education, we underscore the transformative potential of chatbots. However,\nwe also spotlight open challenges and suggest future research directions,\nemphasizing the need for optimizing conversational flow, advancing dialogue\nmechanics, improving domain adaptability, and enhancing ethical considerations.\nThe research culminates in a call for further exploration in ensuring\ntransparent, ethical, and user-centric chatbot systems."
  },
  {
    "arxiv_id": "2311.09758",
    "title": "OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking",
    "url": "http://arxiv.org/abs/2311.09758v1",
    "abstract": "Large language models (LLMs) have revolutionized the landscape of Natural\nLanguage Processing systems, but are computationally expensive. To reduce the\ncost without sacrificing performance, previous studies have explored various\napproaches to harness the potential of Small Language Models (SLMs) as\ncost-effective alternatives to their larger counterparts. Driven by findings\nthat SLMs and LLMs exhibit complementary strengths in a structured knowledge\nextraction task, this work presents a novel SLM/LLM routing framework designed\nto improve computational efficiency and enhance task performance. First,\nexemplar pools are created to represent the types of contexts where each LM\nprovides a more reliable answer, leveraging a sentence embedding fine-tuned so\nthat context similarity is close to dialogue state similarity. Then, during\ninference, the k-nearest exemplars to the testing instance are retrieved, and\nthe instance is routed according to majority vote. In dialogue state tracking\ntasks, the proposed routing framework enhances performance substantially\ncompared to relying solely on LLMs, while reducing the computational costs by\nover 50%."
  },
  {
    "arxiv_id": "2311.09358",
    "title": "Empirical evaluation of Uncertainty Quantification in Retrieval-Augmented Language Models for Science",
    "url": "http://arxiv.org/abs/2311.09358v1",
    "abstract": "Large language models (LLMs) have shown remarkable achievements in natural\nlanguage processing tasks, producing high-quality outputs. However, LLMs still\nexhibit limitations, including the generation of factually incorrect\ninformation. In safety-critical applications, it is important to assess the\nconfidence of LLM-generated content to make informed decisions. Retrieval\nAugmented Language Models (RALMs) is relatively a new area of research in NLP.\nRALMs offer potential benefits for scientific NLP tasks, as retrieved\ndocuments, can serve as evidence to support model-generated content. This\ninclusion of evidence enhances trustworthiness, as users can verify and explore\nthe retrieved documents to validate model outputs. Quantifying uncertainty in\nRALM generations further improves trustworthiness, with retrieved text and\nconfidence scores contributing to a comprehensive and reliable model for\nscientific applications. However, there is limited to no research on UQ for\nRALMs, particularly in scientific contexts. This study aims to address this gap\nby conducting a comprehensive evaluation of UQ in RALMs, focusing on scientific\ntasks. This research investigates how uncertainty scores vary when scientific\nknowledge is incorporated as pretraining and retrieval data and explores the\nrelationship between uncertainty scores and the accuracy of model-generated\noutputs. We observe that an existing RALM finetuned with scientific knowledge\nas the retrieval data tends to be more confident in generating predictions\ncompared to the model pretrained only with scientific knowledge. We also found\nthat RALMs are overconfident in their predictions, making inaccurate\npredictions more confidently than accurate ones. Scientific knowledge provided\neither as pretraining or retrieval corpus does not help alleviate this issue.\nWe released our code, data and dashboards at https://github.com/pnnl/EXPERT2."
  },
  {
    "arxiv_id": "2311.10436",
    "title": "Sinhala-English Word Embedding Alignment: Introducing Datasets and Benchmark for a Low Resource Language",
    "url": "http://arxiv.org/abs/2311.10436v1",
    "abstract": "Since their inception, embeddings have become a primary ingredient in many\nflavours of Natural Language Processing (NLP) tasks supplanting earlier types\nof representation. Even though multilingual embeddings have been used for the\nincreasing number of multilingual tasks, due to the scarcity of parallel\ntraining data, low-resource languages such as Sinhala, tend to focus more on\nmonolingual embeddings. Then when it comes to the aforementioned multi-lingual\ntasks, it is challenging to utilize these monolingual embeddings given that\neven if the embedding spaces have a similar geometric arrangement due to an\nidentical training process, the embeddings of the languages considered are not\naligned. This is solved by the embedding alignment task. Even in this,\nhigh-resource language pairs are in the limelight while low-resource languages\nsuch as Sinhala which is in dire need of help seem to have fallen by the\nwayside. In this paper, we try to align Sinhala and English word embedding\nspaces based on available alignment techniques and introduce a benchmark for\nSinhala language embedding alignment. In addition to that, to facilitate the\nsupervised alignment, as an intermediate task, we also introduce\nSinhala-English alignment datasets. These datasets serve as our anchor datasets\nfor supervised word embedding alignment. Even though we do not obtain results\ncomparable to the high-resource languages such as French, German, or Chinese,\nwe believe our work lays the groundwork for more specialized alignment between\nEnglish and Sinhala embeddings."
  },
  {
    "arxiv_id": "2311.10431",
    "title": "Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human Narrative Processing",
    "url": "http://arxiv.org/abs/2311.10431v1",
    "abstract": "Understanding how humans process natural language has long been a vital\nresearch direction. The field of natural language processing (NLP) has recently\nexperienced a surge in the development of powerful language models. These\nmodels have proven to be invaluable tools for studying another complex system\nknown to process human language: the brain. Previous studies have demonstrated\nthat the features of language models can be mapped to fMRI brain activity. This\nraises the question: is there a commonality between information processing in\nlanguage models and the human brain? To estimate information flow patterns in a\nlanguage model, we examined the causal relationships between different layers.\nDrawing inspiration from the workspace framework for consciousness, we\nhypothesized that features integrating more information would more accurately\npredict higher hierarchical brain activity. To validate this hypothesis, we\nclassified language model features into two categories based on causal network\nmeasures: 'low in-degree' and 'high in-degree'. We subsequently compared the\nbrain prediction accuracy maps for these two groups. Our results reveal that\nthe difference in prediction accuracy follows a hierarchical pattern,\nconsistent with the cortical hierarchy map revealed by activity time constants.\nThis finding suggests a parallel between how language models and the human\nbrain process linguistic information."
  },
  {
    "arxiv_id": "2311.11861",
    "title": "Generating Valid and Natural Adversarial Examples with Large Language Models",
    "url": "http://arxiv.org/abs/2311.11861v1",
    "abstract": "Deep learning-based natural language processing (NLP) models, particularly\npre-trained language models (PLMs), have been revealed to be vulnerable to\nadversarial attacks. However, the adversarial examples generated by many\nmainstream word-level adversarial attack models are neither valid nor natural,\nleading to the loss of semantic maintenance, grammaticality, and human\nimperceptibility. Based on the exceptional capacity of language understanding\nand generation of large language models (LLMs), we propose LLM-Attack, which\naims at generating both valid and natural adversarial examples with LLMs. The\nmethod consists of two stages: word importance ranking (which searches for the\nmost vulnerable words) and word synonym replacement (which substitutes them\nwith their synonyms obtained from LLMs). Experimental results on the Movie\nReview (MR), IMDB, and Yelp Review Polarity datasets against the baseline\nadversarial attack models illustrate the effectiveness of LLM-Attack, and it\noutperforms the baselines in human and GPT-4 evaluation by a significant\nmargin. The model can generate adversarial examples that are typically valid\nand natural, with the preservation of semantic meaning, grammaticality, and\nhuman imperceptibility."
  },
  {
    "arxiv_id": "2311.11652",
    "title": "Web News Timeline Generation with Extended Task Prompting",
    "url": "http://arxiv.org/abs/2311.11652v1",
    "abstract": "The creation of news timeline is essential for a comprehensive and contextual\nunderstanding of events as they unfold over time. This approach aids in\ndiscerning patterns and trends that might be obscured when news is viewed in\nisolation. By organizing news in a chronological sequence, it becomes easier to\ntrack the development of stories, understand the interrelation of events, and\ngrasp the broader implications of news items. This is particularly helpful in\nsectors like finance and insurance, where timely understanding of the event\ndevelopment-ranging from extreme weather to political upheavals and health\ncrises-is indispensable for effective risk management. While traditional\nnatural language processing (NLP) techniques have had some success, they often\nfail to capture the news with nuanced relevance that are readily apparent to\ndomain experts, hindering broader industry integration. The advance of Large\nLanguage Models (LLMs) offers a renewed opportunity to tackle this challenge.\nHowever, direct prompting LLMs for this task is often ineffective. Our study\ninvestigates the application of an extended task prompting technique to assess\npast news relevance. We demonstrate that enhancing conventional prompts with\nadditional tasks boosts their effectiveness on various news dataset, rendering\nnews timeline generation practical for professional use. This work has been\ndeployed as a publicly accessible browser extension which is adopted within our\nnetwork."
  },
  {
    "arxiv_id": "2311.11608",
    "title": "Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks",
    "url": "http://arxiv.org/abs/2311.11608v1",
    "abstract": "Objective: Most existing fine-tuned biomedical large language models (LLMs)\nfocus on enhancing performance in monolingual biomedical question answering and\nconversation tasks. To investigate the effectiveness of the fine-tuned LLMs on\ndiverse biomedical NLP tasks in different languages, We present Taiyi, a\nbilingual fine-tuned LLM for diverse biomedical tasks. Materials and Methods:\nWe first curated a comprehensive collection of 140 existing biomedical text\nmining datasets (102 English and 38 Chinese datasets) across over 10 task\ntypes. Subsequently, a two-stage strategy is proposed for supervised\nfine-tuning to optimize the model performance across varied tasks. Results:\nExperimental results on 13 test sets covering named entity recognition,\nrelation extraction, text classification, question answering tasks demonstrate\nthat Taiyi achieves superior performance compared to general LLMs. The case\nstudy involving additional biomedical NLP tasks further shows Taiyi's\nconsiderable potential for bilingual biomedical multi-tasking. Conclusion:\nLeveraging rich high-quality biomedical corpora and developing effective\nfine-tuning strategies can significantly improve the performance of LLMs within\nthe biomedical domain. Taiyi shows the bilingual multi-tasking capability\nthrough supervised fine-tuning. However, those tasks such as information\nextraction that are not generation tasks in nature remain challenging for\nLLM-based generative approaches, and they still underperform the conventional\ndiscriminative approaches of smaller language models."
  },
  {
    "arxiv_id": "2311.11552",
    "title": "Exploring Prompting Large Language Models as Explainable Metrics",
    "url": "http://arxiv.org/abs/2311.11552v1",
    "abstract": "This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub."
  },
  {
    "arxiv_id": "2311.11547",
    "title": "Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT",
    "url": "http://arxiv.org/abs/2311.11547v1",
    "abstract": "Recently, Large Language Models like ChatGPT have demonstrated remarkable\nproficiency in various Natural Language Processing tasks. Their application in\nRequirements Engineering, especially in requirements classification, has gained\nincreasing interest. This paper reports an extensive empirical evaluation of\ntwo ChatGPT models, specifically gpt-3.5-turbo, and gpt-4 in both zero-shot and\nfew-shot settings for requirements classification. The question arises as to\nhow these models compare to traditional classification methods, specifically\nSupport Vector Machine and Long Short-Term Memory. Based on five different\ndatasets, our results show that there is no single best technique for all types\nof requirement classes. Interestingly, the few-shot setting has been found to\nbe beneficial primarily in scenarios where zero-shot results are significantly\nlow."
  },
  {
    "arxiv_id": "2311.12448",
    "title": "Extracting Definienda in Mathematical Scholarly Articles with Transformers",
    "url": "http://arxiv.org/abs/2311.12448v1",
    "abstract": "We consider automatically identifying the defined term within a mathematical\ndefinition from the text of an academic article. Inspired by the development of\ntransformer-based natural language processing applications, we pose the problem\nas (a) a token-level classification task using fine-tuned pre-trained\ntransformers; and (b) a question-answering task using a generalist large\nlanguage model (GPT). We also propose a rule-based approach to build a labeled\ndataset from the LATEX source of papers. Experimental results show that it is\npossible to reach high levels of precision and recall using either recent (and\nexpensive) GPT 4 or simpler pre-trained models fine-tuned on our task."
  },
  {
    "arxiv_id": "2311.12338",
    "title": "A Survey on Large Language Models for Personalized and Explainable Recommendations",
    "url": "http://arxiv.org/abs/2311.12338v1",
    "abstract": "In recent years, Recommender Systems(RS) have witnessed a transformative\nshift with the advent of Large Language Models(LLMs) in the field of Natural\nLanguage Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from\nMeta, have demonstrated unprecedented capabilities in understanding and\ngenerating human-like text. This has led to a paradigm shift in the realm of\npersonalized and explainable recommendations, as LLMs offer a versatile toolset\nfor processing vast amounts of textual data to enhance user experiences. To\nprovide a comprehensive understanding of the existing LLM-based recommendation\nsystems, this survey aims to analyze how RS can benefit from LLM-based\nmethodologies. Furthermore, we describe major challenges in Personalized\nExplanation Generating(PEG) tasks, which are cold-start problems, unfairness\nand bias problems in RS."
  },
  {
    "arxiv_id": "2311.12315",
    "title": "AcademicGPT: Empowering Academic Research",
    "url": "http://arxiv.org/abs/2311.12315v1",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Yet, many of these advanced\nLLMs are tailored for broad, general-purpose applications. In this technical\nreport, we introduce AcademicGPT, designed specifically to empower academic\nresearch. AcademicGPT is a continual training model derived from LLaMA2-70B.\nOur training corpus mainly consists of academic papers, thesis, content from\nsome academic domain, high-quality Chinese data and others. While it may not be\nextensive in data scale, AcademicGPT marks our initial venture into a\ndomain-specific GPT tailored for research area. We evaluate AcademicGPT on\nseveral established public benchmarks such as MMLU and CEval, as well as on\nsome specialized academic benchmarks like PubMedQA, SCIEval, and our\nnewly-created ComputerScienceQA, to demonstrate its ability from general\nknowledge ability, to Chinese ability, and to academic ability. Building upon\nAcademicGPT's foundation model, we also developed several applications catered\nto the academic area, including General Academic Question Answering,\nAI-assisted Paper Reading, Paper Review, and AI-assisted Title and Abstract\nGeneration."
  },
  {
    "arxiv_id": "2311.12289",
    "title": "ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for Interdisciplinary Science",
    "url": "http://arxiv.org/abs/2311.12289v1",
    "abstract": "Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy."
  },
  {
    "arxiv_id": "2311.12257",
    "title": "Equipping Pretrained Unconditional Music Transformers with Instrument and Genre Controls",
    "url": "http://arxiv.org/abs/2311.12257v1",
    "abstract": "The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality."
  },
  {
    "arxiv_id": "2311.13381",
    "title": "Confidant: Customizing Transformer-based LLMs via Collaborative Edge Training",
    "url": "http://arxiv.org/abs/2311.13381v1",
    "abstract": "Transformer-based large language models (LLMs) have demonstrated impressive\ncapabilities in a variety of natural language processing (NLP) tasks.\nNonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge\ndevices with limited computing, memory, and energy budgets. In this paper, we\npropose Confidant, a multi-backend collaborative training framework for\ncustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.\nConfidant partitions an LLM into several sub-models so that each fits into a\nmobile device's memory. A pipeline parallel training mechanism is further\ndeveloped to ensure fast and efficient distributed training. In addition, we\npropose a novel backend scheduler to allocate different attention heads to\nheterogeneous compute hardware, including mobile CPU and GPUs, to maximize the\ncompute resource utilization on each edge device. Our preliminary experimental\nresults show that Confidant achieves at most 45.3% memory reduction and 8.03x\ninference speedup in practical settings."
  },
  {
    "arxiv_id": "2311.12893",
    "title": "A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs",
    "url": "http://arxiv.org/abs/2311.12893v1",
    "abstract": "For intelligent quadcopter UAVs, a robust and reliable autonomous planning\nsystem is crucial. Most current trajectory planning methods for UAVs are\nsuitable for static environments but struggle to handle dynamic obstacles,\nwhich can pose challenges and even dangers to flight. To address this issue,\nthis paper proposes a vision-based planning system that combines tracking and\ntrajectory prediction of dynamic obstacles to achieve efficient and reliable\nautonomous flight. We use a lightweight object detection algorithm to identify\ndynamic obstacles and then use Kalman Filtering to track and estimate their\nmotion states. During the planning phase, we not only consider static obstacles\nbut also account for the potential movements of dynamic obstacles. For\ntrajectory generation, we use a B-spline-based trajectory search algorithm,\nwhich is further optimized with various constraints to enhance safety and\nalignment with the UAV's motion characteristics. We conduct experiments in both\nsimulation and real-world environments, and the results indicate that our\napproach can successfully detect and avoid obstacles in dynamic environments in\nreal-time, offering greater reliability compared to existing approaches.\nFurthermore, with the advancements in Natural Language Processing (NLP)\ntechnology demonstrating exceptional zero-shot generalization capabilities,\nmore user-friendly human-machine interactions have become feasible, and this\nstudy also explores the integration of autonomous planning systems with Large\nLanguage Models (LLMs)."
  },
  {
    "arxiv_id": "2311.14583",
    "title": "GPT Struct Me: Probing GPT Models on Narrative Entity Extraction",
    "url": "http://arxiv.org/abs/2311.14583v1",
    "abstract": "The importance of systems that can extract structured information from\ntextual data becomes increasingly pronounced given the ever-increasing volume\nof text produced on a daily basis. Having a system that can effectively extract\nsuch information in an interoperable manner would be an asset for several\ndomains, be it finance, health, or legal. Recent developments in natural\nlanguage processing led to the production of powerful language models that can,\nto some degree, mimic human intelligence. Such effectiveness raises a pertinent\nquestion: Can these models be leveraged for the extraction of structured\ninformation? In this work, we address this question by evaluating the\ncapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,\ncommonly known as ChatGPT -- in the extraction of narrative entities, namely\nevents, participants, and temporal expressions. This study is conducted on the\nText2Story Lusa dataset, a collection of 119 Portuguese news articles whose\nannotation framework includes a set of entity structures along with several\ntags and attribute values. We first select the best prompt template through an\nablation study over prompt components that provide varying degrees of\ninformation on a subset of documents of the dataset. Subsequently, we use the\nbest templates to evaluate the effectiveness of the models on the remaining\ndocuments. The results obtained indicate that GPT models are competitive with\nout-of-the-box baseline systems, presenting an all-in-one alternative for\npractitioners with limited resources. By studying the strengths and limitations\nof these models in the context of information extraction, we offer insights\nthat can guide future improvements and avenues to explore in this field."
  },
  {
    "arxiv_id": "2311.14539",
    "title": "CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue Generation",
    "url": "http://arxiv.org/abs/2311.14539v1",
    "abstract": "Medical dialogue generation relies on natural language generation techniques\nto enable online medical consultations. Recently, the widespread adoption of\nlarge-scale models in the field of natural language processing has facilitated\nrapid advancements in this technology. Existing medical dialogue models are\nmostly based on BERT and pre-trained on English corpora, but there is a lack of\nhigh-performing models on the task of Chinese medical dialogue generation. To\nsolve the above problem, this paper proposes CMed-GPT, which is the GPT\npre-training language model based on Chinese medical domain text. The model is\navailable in two versions, namely, base and large, with corresponding\nperplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and\nentity embeddings into the dialogue text in a uniform manner to meet the\nrequirements of downstream dialogue generation tasks. By applying both\nfine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.\nThis study not only confirms the exceptional performance of the CMed-GPT model\nin generating Chinese biomedical text but also highlights the advantages of\np-tuning over traditional fine-tuning with prefix prompts. Furthermore, we\nvalidate the significance of incorporating external information in medical\ndialogue generation, which enhances the quality of dialogue generation."
  },
  {
    "arxiv_id": "2311.14419",
    "title": "Narratives from GPT-derived Networks of News, and a link to Financial Markets Dislocations",
    "url": "http://arxiv.org/abs/2311.14419v1",
    "abstract": "Starting from a corpus of economic articles from The Wall Street Journal, we\npresent a novel systematic way to analyse news content that evolves over time.\nWe leverage on state-of-the-art natural language processing techniques (i.e.\nGPT3.5) to extract the most important entities of each article available, and\naggregate co-occurrence of entities in a related graph at the weekly level.\nNetwork analysis techniques and fuzzy community detection are tested on the\nproposed set of graphs, and a framework is introduced that allows systematic\nbut interpretable detection of topics and narratives. In parallel, we propose\nto consider the sentiment around main entities of an article as a more accurate\nproxy for the overall sentiment of such piece of text, and describe a\ncase-study to motivate this choice. Finally, we design features that\ncharacterise the type and structure of news within each week, and map them to\nmoments of financial markets dislocations. The latter are identified as dates\nwith unusually high volatility across asset classes, and we find quantitative\nevidence that they relate to instances of high entropy in the high-dimensional\nspace of interconnected news. This result further motivates the pursued efforts\nto provide a novel framework for the systematic analysis of narratives within\nnews."
  },
  {
    "arxiv_id": "2311.14407",
    "title": "LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo Molecular Design",
    "url": "http://arxiv.org/abs/2311.14407v1",
    "abstract": "Generative models have demonstrated substantial promise in Natural Language\nProcessing (NLP) and have found application in designing molecules, as seen in\nGeneral Pretrained Transformer (GPT) models. In our efforts to develop such a\ntool for exploring the organic chemical space in search of potentially\nelectro-active compounds, we present \"LLamol\", a single novel generative\ntransformer model based on the LLama 2 architecture, which was trained on a 13M\nsuperset of organic compounds drawn from diverse public sources. To allow for a\nmaximum flexibility in usage and robustness in view of potentially incomplete\ndata, we introduce \"Stochastic Context Learning\" as a new training procedure.\nWe demonstrate that the resulting model adeptly handles single- and\nmulti-conditional organic molecule generation with up to four conditions, yet\nmore are possible. The model generates valid molecular structures in SMILES\nnotation while flexibly incorporating three numerical and/or one token sequence\ninto the generative process, just as requested. The generated compounds are\nvery satisfactory in all scenarios tested. In detail, we showcase the model's\ncapability to utilize token sequences for conditioning, either individually or\nin combination with numerical properties, making LLamol a potent tool for de\nnovo molecule design, easily expandable with new properties."
  },
  {
    "arxiv_id": "2311.14324",
    "title": "Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs",
    "url": "http://arxiv.org/abs/2311.14324v1",
    "abstract": "The latest advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing (NLP). Inspired by the success of LLMs\nin NLP tasks, some recent work has begun investigating the potential of\napplying LLMs in graph learning tasks. However, most of the existing work\nfocuses on utilizing LLMs as powerful node feature augmenters, leaving\nemploying LLMs to enhance graph topological structures an understudied problem.\nIn this work, we explore how to leverage the information retrieval and text\ngeneration capabilities of LLMs to refine/enhance the topological structure of\ntext-attributed graphs (TAGs) under the node classification setting. First, we\npropose using LLMs to help remove unreliable edges and add reliable ones in the\nTAG. Specifically, we first let the LLM output the semantic similarity between\nnode attributes through delicate prompt designs, and then perform edge deletion\nand edge addition based on the similarity. Second, we propose using\npseudo-labels generated by the LLM to improve graph topology, that is, we\nintroduce the pseudo-label propagation as a regularization to guide the graph\nneural network (GNN) in learning proper edge weights. Finally, we incorporate\nthe two aforementioned LLM-based methods for graph topological refinement into\nthe process of GNN training, and perform extensive experiments on four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nLLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain\non public benchmarks)."
  },
  {
    "arxiv_id": "2311.14061",
    "title": "Towards Explainable Strategy Templates using NLP Transformers",
    "url": "http://arxiv.org/abs/2311.14061v1",
    "abstract": "This paper bridges the gap between mathematical heuristic strategies learned\nfrom Deep Reinforcement Learning (DRL) in automated agent negotiation, and\ncomprehensible, natural language explanations. Our aim is to make these\nstrategies more accessible to non-experts. By leveraging traditional Natural\nLanguage Processing (NLP) techniques and Large Language Models (LLMs) equipped\nwith Transformers, we outline how parts of DRL strategies composed of parts\nwithin strategy templates can be transformed into user-friendly, human-like\nEnglish narratives. To achieve this, we present a top-level algorithm that\ninvolves parsing mathematical expressions of strategy templates, semantically\ninterpreting variables and structures, generating rule-based primary\nexplanations, and utilizing a Generative Pre-trained Transformer (GPT) model to\nrefine and contextualize these explanations. Subsequent customization for\nvaried audiences and meticulous validation processes in an example illustrate\nthe applicability and potential of this approach."
  },
  {
    "arxiv_id": "2311.13729",
    "title": "Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case",
    "url": "http://arxiv.org/abs/2311.13729v1",
    "abstract": "End-to-end relation extraction (E2ERE) is an important and realistic\napplication of natural language processing (NLP) in biomedicine. In this paper,\nwe aim to compare three prevailing paradigms for E2ERE using a complex dataset\nfocused on rare diseases involving discontinuous and nested entities. We use\nthe RareDis information extraction dataset to evaluate three competing\napproaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to\nsequence models, and generative pre-trained transformer (GPT) models. We use\ncomparable state-of-the-art models and best practices for each of these\napproaches and conduct error analyses to assess their failure modes. Our\nfindings reveal that pipeline models are still the best, while\nsequence-to-sequence models are not far behind; GPT models with eight times as\nmany parameters are worse than even sequence-to-sequence models and lose to\npipeline models by over 10 F1 points. Partial matches and discontinuous\nentities caused many NER errors contributing to lower overall E2E performances.\nWe also verify these findings on a second E2ERE dataset for chemical-protein\ninteractions. Although generative LM-based methods are more suitable for\nzero-shot settings, when training data is available, our results show that it\nis better to work with more conventional models trained and tailored for E2ERE.\nMore innovative methods are needed to marry the best of the both worlds from\nsmaller encoder-decoder pipeline models and the larger GPT models to improve\nE2ERE. As of now, we see that well designed pipeline models offer substantial\nperformance gains at a lower cost and carbon footprint for E2ERE. Our\ncontribution is also the first to conduct E2ERE for the RareDis dataset."
  },
  {
    "arxiv_id": "2311.15766",
    "title": "Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges",
    "url": "http://arxiv.org/abs/2311.15766v1",
    "abstract": "In recent years, large language models (LLMs) have spurred a new research\nparadigm in natural language processing. Despite their excellent capability in\nknowledge-based question answering and reasoning, their potential to retain\nfaulty or even harmful knowledge poses risks of malicious application. The\nchallenge of mitigating this issue and transforming these models into purer\nassistants is crucial for their widespread applicability. Unfortunately,\nRetraining LLMs repeatedly to eliminate undesirable knowledge is impractical\ndue to their immense parameters. Knowledge unlearning, derived from analogous\nstudies on machine unlearning, presents a promising avenue to address this\nconcern and is notably advantageous in the context of LLMs. It allows for the\nremoval of harmful knowledge in an efficient manner, without affecting\nunrelated knowledge in the model. To this end, we provide a survey of knowledge\nunlearning in the era of LLMs. Firstly, we formally define the knowledge\nunlearning problem and distinguish it from related works. Subsequently, we\ncategorize existing knowledge unlearning methods into three classes: those\nbased on parameter optimization, parameter merging, and in-context learning,\nand introduce details of these unlearning methods. We further present\nevaluation datasets used in existing methods, and finally conclude this survey\nby presenting the ongoing challenges and future directions."
  },
  {
    "arxiv_id": "2311.15698",
    "title": "Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced Chat Corpus Generation and Evaluation",
    "url": "http://arxiv.org/abs/2311.15698v1",
    "abstract": "This study introduces a novel approach for generating high-quality,\nlanguage-specific chat corpora using a self-chat mechanism. We combine a\ngenerator LLM for creating new samples and an embedder LLM to ensure diversity.\nA new Masked Language Modelling (MLM) model-based quality assessment metric is\nproposed for evaluating and filtering the corpora. Utilizing the llama2-70b as\nthe generator and a multilingual sentence transformer as embedder, we generate\nan Italian chat corpus and refine the Fauno corpus, which is based on\ntranslated English ChatGPT self-chat data. The refinement uses structural\nassertions and Natural Language Processing techniques. Both corpora undergo a\ncomprehensive quality evaluation using the proposed MLM model-based quality\nmetric. The Italian LLM fine-tuned with these corpora demonstrates\nsignificantly enhanced language comprehension and question-answering skills.\nThe resultant model, cerbero-7b, establishes a new state-of-the-art for Italian\nLLMs. This approach marks a substantial advancement in the development of\nlanguage-specific LLMs, with a special emphasis on augmenting corpora for\nunderrepresented languages like Italian."
  },
  {
    "arxiv_id": "2311.15649",
    "title": "RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks",
    "url": "http://arxiv.org/abs/2311.15649v1",
    "abstract": "Robotic agents must master common sense and long-term sequential decisions to\nsolve daily tasks through natural language instruction. The developments in\nLarge Language Models (LLMs) in natural language processing have inspired\nefforts to use LLMs in complex robot planning. Despite LLMs' great\ngeneralization and comprehension of instruction tasks, LLMs-generated task\nplans sometimes lack feasibility and correctness. To address the problem, we\npropose a RoboGPT agent\\footnote{our code and dataset will be released soon}\nfor making embodied long-term decisions for daily tasks, with two modules: 1)\nLLMs-based planning with re-plan to break the task into multiple sub-goals; 2)\nRoboSkill individually designed for sub-goals to learn better navigation and\nmanipulation skills. The LLMs-based planning is enhanced with a new robotic\ndataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily\ninstruction tasks is gathered for fine-tuning the Llama model and obtaining\nRoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily\ninstruction tasks. Additionally, a low-computational Re-Plan module is designed\nto allow plans to flexibly adapt to the environment, thereby addressing the\nnomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA\nmethods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA\nLLM-based planners like ChatGPT in task-planning rationality for hundreds of\nunseen daily tasks, and even other domain tasks, while keeping the large\nmodel's original broad application and generality."
  },
  {
    "arxiv_id": "2311.16720",
    "title": "RankingGPT: Empowering Large Language Models in Text Ranking with Progressive Enhancement",
    "url": "http://arxiv.org/abs/2311.16720v1",
    "abstract": "Text ranking is a critical task in information retrieval. Recent advances in\npre-trained language models (PLMs), especially large language models (LLMs),\npresent new opportunities for applying them to text ranking. While supervised\nfine-tuning (SFT) with ranking data has been widely explored to better align\nPLMs with text ranking goals, previous studies have focused primarily on\nencoder-only and encoder-decoder PLMs. Research on leveraging decoder-only LLMs\nfor text ranking remains scarce. An exception to this is RankLLaMA, which uses\ndirect SFT to explore LLaMA's potential for text ranking. In this work, we\npropose a two-stage progressive paradigm to better adapt LLMs to text ranking.\nFirst, we conduct continual pre-training (CPT) of LLMs on a large\nweakly-supervised corpus. Second, we perform SFT, and propose an improved\noptimization strategy building upon RankLLaMA. Our experimental results on\nmultiple benchmarks show that our approach outperforms previous methods in both\nin-domain and out-domain scenarios."
  },
  {
    "arxiv_id": "2311.16673",
    "title": "Large Language Models Meet Computer Vision: A Brief Survey",
    "url": "http://arxiv.org/abs/2311.16673v1",
    "abstract": "Recently, the intersection of Large Language Models (LLMs) and Computer\nVision (CV) has emerged as a pivotal area of research, driving significant\nadvancements in the field of Artificial Intelligence (AI). As transformers have\nbecome the backbone of many state-of-the-art models in both Natural Language\nProcessing (NLP) and CV, understanding their evolution and potential\nenhancements is crucial. This survey paper delves into the latest progressions\nin the domain of transformers and their subsequent successors, emphasizing\ntheir potential to revolutionize Vision Transformers (ViTs) and LLMs. This\nsurvey also presents a comparative analysis, juxtaposing the performance\nmetrics of several leading paid and open-source LLMs, shedding light on their\nstrengths and areas of improvement as well as a literature review on how LLMs\nare being used to tackle vision related tasks. Furthermore, the survey presents\na comprehensive collection of datasets employed to train LLMs, offering\ninsights into the diverse data available to achieve high performance in various\npre-training and downstream tasks of LLMs. The survey is concluded by\nhighlighting open directions in the field, suggesting potential venues for\nfuture research and development. This survey aims to underscores the profound\nintersection of LLMs on CV, leading to a new era of integrated and advanced AI\nmodels."
  },
  {
    "arxiv_id": "2311.16534",
    "title": "Graph Prompt Learning: A Comprehensive Survey and Beyond",
    "url": "http://arxiv.org/abs/2311.16534v1",
    "abstract": "Artificial General Intelligence (AGI) has revolutionized numerous fields, yet\nits integration with graph data, a cornerstone in our interconnected world,\nremains nascent. This paper presents a pioneering survey on the emerging domain\nof graph prompts in AGI, addressing key challenges and opportunities in\nharnessing graph data for AGI applications. Despite substantial advancements in\nAGI across natural language processing and computer vision, the application to\ngraph data is relatively underexplored. This survey critically evaluates the\ncurrent landscape of AGI in handling graph data, highlighting the distinct\nchallenges in cross-modality, cross-domain, and cross-task applications\nspecific to graphs. Our work is the first to propose a unified framework for\nunderstanding graph prompt learning, offering clarity on prompt tokens, token\nstructures, and insertion patterns in the graph domain. We delve into the\nintrinsic properties of graph prompts, exploring their flexibility,\nexpressiveness, and interplay with existing graph models. A comprehensive\ntaxonomy categorizes over 100 works in this field, aligning them with\npre-training tasks across node-level, edge-level, and graph-level objectives.\nAdditionally, we present, ProG, a Python library, and an accompanying website,\nto support and advance research in graph prompting. The survey culminates in a\ndiscussion of current challenges and future directions, offering a roadmap for\nresearch in graph prompting within AGI. Through this comprehensive analysis, we\naim to catalyze further exploration and practical applications of AGI in graph\ndata, underlining its potential to reshape AGI fields and beyond. ProG and the\nwebsite can be accessed by\n\\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and\n\\url{https://github.com/sheldonresearch/ProG}, respectively."
  },
  {
    "arxiv_id": "2311.17686",
    "title": "AviationGPT: A Large Language Model for the Aviation Domain",
    "url": "http://arxiv.org/abs/2311.17686v1",
    "abstract": "The advent of ChatGPT and GPT-4 has captivated the world with large language\nmodels (LLMs), demonstrating exceptional performance in question-answering,\nsummarization, and content generation. The aviation industry is characterized\nby an abundance of complex, unstructured text data, replete with technical\njargon and specialized terminology. Moreover, labeled data for model building\nare scarce in this domain, resulting in low usage of aviation text data. The\nemergence of LLMs presents an opportunity to transform this situation, but\nthere is a lack of LLMs specifically designed for the aviation domain. To\naddress this gap, we propose AviationGPT, which is built on open-source LLaMA-2\nand Mistral architectures and continuously trained on a wealth of carefully\ncurated aviation datasets. Experimental results reveal that AviationGPT offers\nusers multiple advantages, including the versatility to tackle diverse natural\nlanguage processing (NLP) problems (e.g., question-answering, summarization,\ndocument writing, information extraction, report querying, data cleaning, and\ninteractive data exploration). It also provides accurate and contextually\nrelevant responses within the aviation domain and significantly improves\nperformance (e.g., over a 40% performance gain in tested cases). With\nAviationGPT, the aviation industry is better equipped to address more complex\nresearch problems and enhance the efficiency and safety of National Airspace\nSystem (NAS) operations."
  },
  {
    "arxiv_id": "2311.17633",
    "title": "Introduction to Transformers: an NLP Perspective",
    "url": "http://arxiv.org/abs/2311.17633v1",
    "abstract": "Transformers have dominated empirical machine learning models of natural\nlanguage processing. In this paper, we introduce basic concepts of Transformers\nand present key techniques that form the recent advances of these models. This\nincludes a description of the standard Transformer architecture, a series of\nmodel refinements, and common applications. Given that Transformers and related\ndeep learning techniques might be evolving in ways we have never seen, we\ncannot dive into all the model details or cover all the technical areas.\nInstead, we focus on just those concepts that are helpful for gaining a good\nunderstanding of Transformers and their variants. We also summarize the key\nideas that impact this field, thereby yielding some insights into the strengths\nand limitations of these models."
  },
  {
    "arxiv_id": "2311.17400",
    "title": "Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention",
    "url": "http://arxiv.org/abs/2311.17400v1",
    "abstract": "Transformer-based models, such as BERT and GPT, have been widely adopted in\nnatural language processing (NLP) due to their exceptional performance.\nHowever, recent studies show their vulnerability to textual adversarial attacks\nwhere the model's output can be misled by intentionally manipulating the text\ninputs. Despite various methods that have been proposed to enhance the model's\nrobustness and mitigate this vulnerability, many require heavy consumption\nresources (e.g., adversarial training) or only provide limited protection\n(e.g., defensive dropout). In this paper, we propose a novel method called\ndynamic attention, tailored for the transformer architecture, to enhance the\ninherent robustness of the model itself against various adversarial attacks.\nOur method requires no downstream task knowledge and does not incur additional\ncosts. The proposed dynamic attention consists of two modules: (I) attention\nrectification, which masks or weakens the attention value of the chosen tokens,\nand (ii) dynamic modeling, which dynamically builds the set of candidate\ntokens. Extensive experiments demonstrate that dynamic attention significantly\nmitigates the impact of adversarial attacks, improving up to 33\\% better\nperformance than previous methods against widely-used adversarial attacks. The\nmodel-level design of dynamic attention enables it to be easily combined with\nother defense methods (e.g., adversarial training) to further enhance the\nmodel's robustness. Furthermore, we demonstrate that dynamic attention\npreserves the state-of-the-art robustness space of the original model compared\nto other dynamic modeling methods."
  },
  {
    "arxiv_id": "2311.17355",
    "title": "Are Large Language Models Good Fact Checkers: A Preliminary Study",
    "url": "http://arxiv.org/abs/2311.17355v1",
    "abstract": "Recently, Large Language Models (LLMs) have drawn significant attention due\nto their outstanding reasoning capabilities and extensive knowledge repository,\npositioning them as superior in handling various natural language processing\ntasks compared to other language models. In this paper, we present a\npreliminary investigation into the potential of LLMs in fact-checking. This\nstudy aims to comprehensively evaluate various LLMs in tackling specific\nfact-checking subtasks, systematically evaluating their capabilities, and\nconducting a comparative analysis of their performance against pre-trained and\nstate-of-the-art low-parameter models. Experiments demonstrate that LLMs\nachieve competitive performance compared to other small models in most\nscenarios. However, they encounter challenges in effectively handling Chinese\nfact verification and the entirety of the fact-checking pipeline due to\nlanguage inconsistencies and hallucinations. These findings underscore the need\nfor further exploration and research to enhance the proficiency of LLMs as\nreliable fact-checkers, unveiling the potential capability of LLMs and the\npossible challenges in fact-checking tasks."
  },
  {
    "arxiv_id": "2311.17295",
    "title": "Elo Uncovered: Robustness and Best Practices in Language Model Evaluation",
    "url": "http://arxiv.org/abs/2311.17295v1",
    "abstract": "In Natural Language Processing (NLP), the Elo rating system, originally\ndesigned for ranking players in dynamic games such as chess, is increasingly\nbeing used to evaluate Large Language Models (LLMs) through \"A vs B\" paired\ncomparisons. However, while popular, the system's suitability for assessing\nentities with constant skill levels, such as LLMs, remains relatively\nunexplored. We study two fundamental axioms that evaluation methods should\nadhere to: reliability and transitivity. We conduct extensive evaluation of Elo\nbehaviour, illustrating that individual Elo computations exhibit volatility and\ndelving into the impact of varying the Elo rating system's hyperparameters. We\nshow that these axioms are not always satisfied raising questions about the\nreliability of current comparative evaluations of LLMs. If the current use of\nElo scores is intended to substitute the costly head-to-head comparison of\nLLMs, it is crucial to ensure the ranking is as robust as possible. Guided by\nthe axioms, our findings offer concrete guidelines for enhancing the\nreliability of LLM evaluation methods, suggesting a need for reassessment of\nexisting comparative approaches."
  },
  {
    "arxiv_id": "2311.18702",
    "title": "CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable Evaluation of Large Language Model Generation",
    "url": "http://arxiv.org/abs/2311.18702v1",
    "abstract": "Since the natural language processing (NLP) community started to make large\nlanguage models (LLMs) act as a critic to evaluate the quality of generated\ntexts, most of the existing works train a critique generation model on the\nevaluation data labeled by GPT-4's direct prompting. We observe that these\nmodels lack the ability to generate informative critiques in both pointwise\ngrading and pairwise comparison especially without references. As a result,\ntheir generated critiques cannot provide fine-grained distinguishability on\ngenerated texts, causing unsatisfactory evaluation performance. In this paper,\nwe propose a simple yet effective method called Eval-Instruct, which can first\nacquire pointwise grading critiques with pseudo references and then revise\nthese critiques via multi-path prompting to obtain informative evaluation data\nin different tasks and settings, including pointwise grading and pairwise\ncomparison with / without references. After fine-tuning on these data, the\nresulting model CritiqueLLM is empirically shown to outperform ChatGPT and all\nthe open-source baselines and even achieve comparable evaluation performance to\nGPT-4 in system-level correlations of pointwise grading. We also demonstrate\nthat our generated critiques can act as scalable feedback to further improve\nthe generation quality of strong LLMs like ChatGPT."
  },
  {
    "arxiv_id": "2311.18215",
    "title": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models",
    "url": "http://arxiv.org/abs/2311.18215v1",
    "abstract": "Caution: this paper may include material that could be offensive or\ndistressing.\n  The advent of Large Language Models (LLMs) necessitates the development of\ntraining approaches that mitigate the generation of unethical language and\naptly manage toxic user queries. Given the challenges related to human labor\nand the scarcity of data, we present KoTox, comprising 39K unethical\ninstruction-output pairs. This collection of automatically generated toxic\ninstructions refines the training of LLMs and establishes a foundational\nframework for improving LLMs' ethical awareness and response to various toxic\ninputs, promoting more secure and responsible interactions in Natural Language\nProcessing (NLP) applications."
  },
  {
    "arxiv_id": "2312.00751",
    "title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals",
    "url": "http://arxiv.org/abs/2312.00751v1",
    "abstract": "Transformers have achieved remarkable success in a wide range of natural\nlanguage processing and computer vision applications. However, the\nrepresentation capacity of a deep transformer model is degraded due to the\nover-smoothing issue in which the token representations become identical when\nthe model's depth grows. In this work, we show that self-attention layers in\ntransformers minimize a functional which promotes smoothness, thereby causing\ntoken uniformity. We then propose a novel regularizer that penalizes the norm\nof the difference between the smooth output tokens from self-attention and the\ninput tokens to preserve the fidelity of the tokens. Minimizing the resulting\nregularized energy functional, we derive the Neural Transformer with a\nRegularized Nonlocal Functional (NeuTRENO), a novel class of transformer models\nthat can mitigate the over-smoothing issue. We empirically demonstrate the\nadvantages of NeuTRENO over the baseline transformers and state-of-the-art\nmethods in reducing the over-smoothing of token representations on various\npractical tasks, including object classification, image segmentation, and\nlanguage modeling."
  },
  {
    "arxiv_id": "2312.00662",
    "title": "Nonparametric Variational Regularisation of Pretrained Transformers",
    "url": "http://arxiv.org/abs/2312.00662v1",
    "abstract": "The current paradigm of large-scale pre-training and fine-tuning Transformer\nlarge language models has lead to significant improvements across the board in\nnatural language processing. However, such large models are susceptible to\noverfitting to their training data, and as a result the models perform poorly\nwhen the domain changes. Also, due to the model's scale, the cost of\nfine-tuning the model to the new domain is large. Nonparametric Variational\nInformation Bottleneck (NVIB) has been proposed as a regulariser for training\ncross-attention in Transformers, potentially addressing the overfitting\nproblem. We extend the NVIB framework to replace all types of attention\nfunctions in Transformers, and show that existing pretrained Transformers can\nbe reinterpreted as Nonparametric Variational (NV) models using a proposed\nidentity initialisation. We then show that changing the initialisation\nintroduces a novel, information-theoretic post-training regularisation in the\nattention mechanism, which improves out-of-domain generalisation without any\ntraining. This success supports the hypothesis that pretrained Transformers are\nimplicitly NV Bayesian models."
  },
  {
    "arxiv_id": "2312.00407",
    "title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way",
    "url": "http://arxiv.org/abs/2312.00407v1",
    "abstract": "Large language models (LLMs) are increasingly pivotal in a wide range of\nnatural language processing tasks. Access to pre-trained models, courtesy of\nthe open-source community, has made it possible to adapt these models to\nspecific applications for enhanced performance. However, the substantial\nresources required for training these models necessitate efficient solutions.\nThis paper introduces CoLLiE, an efficient library that facilitates\ncollaborative training of large language models using 3D parallelism,\nparameter-efficient fine-tuning (PEFT) methods, and optimizers such as Lion,\nAdan, Sophia, LOMO and AdaLomo. With its modular design and comprehensive\nfunctionality, CoLLiE offers a balanced blend of efficiency, ease of use, and\ncustomization. CoLLiE has proven superior training efficiency in comparison\nwith prevalent solutions in pre-training and fine-tuning scenarios.\nFurthermore, we provide an empirical evaluation of the correlation between\nmodel size and GPU memory consumption under different optimization methods, as\nwell as an analysis of the throughput. Lastly, we carry out a comprehensive\ncomparison of various optimizers and PEFT methods within the instruction-tuning\ncontext. CoLLiE is available at https://github.com/OpenLMLab/collie."
  },
  {
    "arxiv_id": "2312.02125",
    "title": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and Advanced Decoding Techniques",
    "url": "http://arxiv.org/abs/2312.02125v1",
    "abstract": "Recent advances in language models (LMs), have demonstrated significant\nefficacy in tasks related to the arts and humanities. While LMs have exhibited\nexceptional performance across a wide range of natural language processing\ntasks, there are notable challenges associated with their utilization on small\ndatasets and their ability to replicate more creative human capacities. In this\nstudy, we aim to address these challenges by training a Persian classical\npoetry generation model using a transformer architecture on a specialized\ndataset with no pretraining. Additionally, we propose a novel decoding method\nto enhance coherence and meaningfulness in the generated poetry, effectively\nmanaging the tradeoff between diversity and quality. Furthermore, the results\nof our training approach and the proposed decoding method are evaluated through\ncomprehensive set of automatic and human evaluations and showed its superior\ncapability to generate coherent and meaningful poetry in compare to other\ndecoding methods and an existing Persian large language model (LLM)."
  },
  {
    "arxiv_id": "2312.01701",
    "title": "Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites",
    "url": "http://arxiv.org/abs/2312.01701v1",
    "abstract": "Large language models (LLMs) have shown remarkable performance in natural\nlanguage processing (NLP) tasks. To comprehend and execute diverse human\ninstructions over image data, instruction-tuned large vision-language models\n(LVLMs) have been introduced. However, LVLMs may suffer from different types of\nobject hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained\nobject hallucinations only (i.e., generated objects non-existent in the input\nimage). The fine-grained object attributes and behaviors non-existent in the\nimage may still be generated but not measured by the current evaluation\nmethods. In this paper, we thus focus on reducing fine-grained hallucinations\nof LVLMs. We propose \\textit{ReCaption}, a framework that consists of two\ncomponents: rewriting captions using ChatGPT and fine-tuning the\ninstruction-tuned LVLMs on the rewritten captions. We also propose a\nfine-grained probing-based evaluation method named \\textit{Fine-Grained Object\nHallucination Evaluation} (\\textit{FGHE}). Our experiment results demonstrate\nthat ReCaption effectively reduces fine-grained object hallucination for\ndifferent LVLM options and improves their text generation quality. The code can\nbe found at https://github.com/Anonymousanoy/FOHE."
  },
  {
    "arxiv_id": "2312.01314",
    "title": "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian",
    "url": "http://arxiv.org/abs/2312.01314v1",
    "abstract": "Norwegian, spoken by only 5 million population, is under-representative\nwithin the most impressive breakthroughs in NLP tasks. To the best of our\nknowledge, there has not yet been a comprehensive evaluation of the existing\nlanguage models (LMs) on Norwegian generation tasks during the article writing\nprocess. To fill this gap, we 1) compiled the existing Norwegian dataset and\npre-trained 4 Norwegian Open Language Models varied from parameter scales and\narchitectures, collectively called NorGLM; 2) introduced a comprehensive\nbenchmark, NLEBench, for evaluating natural language generation capabilities in\nNorwegian, encompassing translation and human annotation. Based on the\ninvestigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5\nhas limited capability in understanding the Norwegian context; 2) the increase\nin model parameter scales demonstrates limited impact on the performance of\ndownstream tasks when the pre-training dataset is constrained in size; 3)\nsmaller models also demonstrate the reasoning capability through\nChain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be\nused to verify the generalizability of LLMs on natural language understanding\nand, meanwhile, test the interconnectedness of these NLP tasks. We share our\nresources and code for reproducibility under a CC BY-NC 4.0 license."
  },
  {
    "arxiv_id": "2312.01202",
    "title": "From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews",
    "url": "http://arxiv.org/abs/2312.01202v1",
    "abstract": "Obtaining stakeholders' diverse experiences and opinions about current policy\nin a timely manner is crucial for policymakers to identify strengths and gaps\nin resource allocation, thereby supporting effective policy design and\nimplementation. However, manually coding even moderately sized interview texts\nor open-ended survey responses from stakeholders can often be labor-intensive\nand time-consuming. This study explores the integration of Large Language\nModels (LLMs)--like GPT-4--with human expertise to enhance text analysis of\nstakeholder interviews regarding K-12 education policy within one U.S. state.\nEmploying a mixed-methods approach, human experts developed a codebook and\ncoding processes as informed by domain knowledge and unsupervised topic\nmodeling results. They then designed prompts to guide GPT-4 analysis and\niteratively evaluate different prompts' performances. This combined\nhuman-computer method enabled nuanced thematic and sentiment analysis. Results\nreveal that while GPT-4 thematic coding aligned with human coding by 77.89% at\nspecific themes, expanding to broader themes increased congruence to 96.02%,\nsurpassing traditional Natural Language Processing (NLP) methods by over 25%.\nAdditionally, GPT-4 is more closely matched to expert sentiment analysis than\nlexicon-based methods. Findings from quantitative measures and qualitative\nreviews underscore the complementary roles of human domain expertise and\nautomated analysis as LLMs offer new perspectives and coding consistency. The\nhuman-computer interactive approach enhances efficiency, validity, and\ninterpretability of educational policy research."
  },
  {
    "arxiv_id": "2312.02783",
    "title": "Large Language Models on Graphs: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2312.02783v1",
    "abstract": "Large language models (LLMs), such as GPT4 and LLaMA, are creating\nsignificant advancements in natural language processing, due to their strong\ntext encoding/decoding ability and newly found emergent capability (e.g.,\nreasoning). While LLMs are mainly designed to process pure texts, there are\nmany real-world scenarios where text data is associated with rich structure\ninformation in the form of graphs (e.g., academic networks, and e-commerce\nnetworks) or scenarios where graph data is paired with rich textual information\n(e.g., molecules with descriptions). Besides, although LLMs have shown their\npure text-based reasoning ability, it is underexplored whether such ability can\nbe generalized to graphs (i.e., graph-based reasoning). In this paper, we\nprovide a systematic review of scenarios and techniques related to large\nlanguage models on graphs. We first summarize potential scenarios of adopting\nLLMs on graphs into three categories, namely pure graphs, text-attributed\ngraphs, and text-paired graphs. We then discuss detailed techniques for\nutilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM\nas Aligner, and compare the advantages and disadvantages of different schools\nof models. Furthermore, we discuss the real-world applications of such methods\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future research directions in this fast-growing field. The\nrelated source can be found at\nhttps://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs."
  },
  {
    "arxiv_id": "2312.02578",
    "title": "Empathy and Distress Detection using Ensembles of Transformer Models",
    "url": "http://arxiv.org/abs/2312.02578v1",
    "abstract": "This paper presents our approach for the WASSA 2023 Empathy, Emotion and\nPersonality Shared Task. Empathy and distress are human feelings that are\nimplicitly expressed in natural discourses. Empathy and distress detection are\ncrucial challenges in Natural Language Processing that can aid our\nunderstanding of conversations. The provided dataset consists of several\nlong-text examples in the English language, with each example associated with a\nnumeric score for empathy and distress. We experiment with several BERT-based\nmodels as a part of our approach. We also try various ensemble methods. Our\nfinal submission has a Pearson's r score of 0.346, placing us third in the\nempathy and distress detection subtask."
  },
  {
    "arxiv_id": "2312.02337",
    "title": "Measuring Distributional Shifts in Text: The Advantage of Language Model-Based Embeddings",
    "url": "http://arxiv.org/abs/2312.02337v1",
    "abstract": "An essential part of monitoring machine learning models in production is\nmeasuring input and output data drift. In this paper, we present a system for\nmeasuring distributional shifts in natural language data and highlight and\ninvestigate the potential advantage of using large language models (LLMs) for\nthis problem. Recent advancements in LLMs and their successful adoption in\ndifferent domains indicate their effectiveness in capturing semantic\nrelationships for solving various natural language processing problems. The\npower of LLMs comes largely from the encodings (embeddings) generated in the\nhidden layers of the corresponding neural network. First we propose a\nclustering-based algorithm for measuring distributional shifts in text data by\nexploiting such embeddings. Then we study the effectiveness of our approach\nwhen applied to text embeddings generated by both LLMs and classical embedding\nalgorithms. Our experiments show that general-purpose LLM-based embeddings\nprovide a high sensitivity to data drift compared to other embedding methods.\nWe propose drift sensitivity as an important evaluation metric to consider when\ncomparing language models. Finally, we present insights and lessons learned\nfrom deploying our framework as part of the Fiddler ML Monitoring platform over\na period of 18 months."
  },
  {
    "arxiv_id": "2312.02331",
    "title": "Revisiting Topic-Guided Language Models",
    "url": "http://arxiv.org/abs/2312.02331v1",
    "abstract": "A recent line of work in natural language processing has aimed to combine\nlanguage models and topic models. These topic-guided language models augment\nneural language models with topic models, unsupervised learning methods that\ncan discover document-level patterns of word use. This paper compares the\neffectiveness of these methods in a standardized setting. We study four\ntopic-guided language models and two baselines, evaluating the held-out\npredictive performance of each model on four corpora. Surprisingly, we find\nthat none of these methods outperform a standard LSTM language model baseline,\nand most fail to learn good topics. Further, we train a probe of the neural\nlanguage model that shows that the baseline's hidden states already encode\ntopic information. We make public all code used for this study."
  },
  {
    "arxiv_id": "2312.02296",
    "title": "LLMs Accelerate Annotation for Medical Information Extraction",
    "url": "http://arxiv.org/abs/2312.02296v1",
    "abstract": "The unstructured nature of clinical notes within electronic health records\noften conceals vital patient-related information, making it challenging to\naccess or interpret. To uncover this hidden information, specialized Natural\nLanguage Processing (NLP) models are required. However, training these models\nnecessitates large amounts of labeled data, a process that is both\ntime-consuming and costly when relying solely on human experts for annotation.\nIn this paper, we propose an approach that combines Large Language Models\n(LLMs) with human expertise to create an efficient method for generating ground\ntruth labels for medical text annotation. By utilizing LLMs in conjunction with\nhuman annotators, we significantly reduce the human annotation burden, enabling\nthe rapid creation of labeled datasets. We rigorously evaluate our method on a\nmedical information extraction task, demonstrating that our approach not only\nsubstantially cuts down on human intervention but also maintains high accuracy.\nThe results highlight the potential of using LLMs to improve the utilization of\nunstructured clinical data, allowing for the swift deployment of tailored NLP\nsolutions in healthcare."
  },
  {
    "arxiv_id": "2312.03694",
    "title": "Parameter-Efficient Transfer Learning of Audio Spectrogram Transformers",
    "url": "http://arxiv.org/abs/2312.03694v2",
    "abstract": "Parameter-efficient transfer learning (PETL) methods have emerged as a solid\nalternative to the standard full fine-tuning approach. They only train a few\nextra parameters for each downstream task, without sacrificing performance and\ndispensing with the issue of storing a copy of the pre-trained model for each\ntask. For audio classification tasks, the Audio Spectrogram Transformer (AST)\nmodel shows impressive results. However, surprisingly, how to efficiently adapt\nit to several downstream tasks has not been tackled before. In this paper, we\nbridge this gap and present a detailed investigation of common PETL methods for\nthe adaptation of the AST model to audio/speech tasks. Furthermore, we propose\na new adapter design that exploits the convolution module of the Conformer\nmodel, leading to superior performance over the standard PETL approaches and\nsurpassing or achieving performance parity with full fine-tuning by updating\nonly 0.29% of the parameters. Finally, we provide ablation studies revealing\nthat our proposed adapter: 1) proves to be effective in few-shot efficient\ntransfer learning, 2) attains optimal results regardless of the amount of the\nallocated parameters, and 3) can be applied to other pre-trained models."
  },
  {
    "arxiv_id": "2312.03042",
    "title": "Inherent limitations of LLMs regarding spatial information",
    "url": "http://arxiv.org/abs/2312.03042v1",
    "abstract": "Despite the significant advancements in natural language processing\ncapabilities demonstrated by large language models such as ChatGPT, their\nproficiency in comprehending and processing spatial information, especially\nwithin the domains of 2D and 3D route planning, remains notably underdeveloped.\nThis paper investigates the inherent limitations of ChatGPT and similar models\nin spatial reasoning and navigation-related tasks, an area critical for\napplications ranging from autonomous vehicle guidance to assistive technologies\nfor the visually impaired. In this paper, we introduce a novel evaluation\nframework complemented by a baseline dataset, meticulously crafted for this\nstudy. This dataset is structured around three key tasks: plotting spatial\npoints, planning routes in two-dimensional (2D) spaces, and devising pathways\nin three-dimensional (3D) environments. We specifically developed this dataset\nto assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals\nkey insights into the model's capabilities and limitations in spatial\nunderstanding."
  },
  {
    "arxiv_id": "2312.04463",
    "title": "Leveraging Transformer-based Language Models to Automate Requirements Satisfaction Assessment",
    "url": "http://arxiv.org/abs/2312.04463v1",
    "abstract": "Requirements Satisfaction Assessment (RSA) evaluates whether the set of\ndesign elements linked to a single requirement provide sufficient coverage of\nthat requirement -- typically meaning that all concepts in the requirement are\naddressed by at least one of the design elements. RSA is an important software\nengineering activity for systems with any form of hierarchical decomposition --\nespecially safety or mission critical ones. In previous studies, researchers\nused basic Information Retrieval (IR) models to decompose requirements and\ndesign elements into chunks, and then evaluated the extent to which chunks of\ndesign elements covered all chunks in the requirement. However, results had low\naccuracy because many critical concepts that extend across the entirety of the\nsentence were not well represented when the sentence was parsed into\nindependent chunks. In this paper we leverage recent advances in natural\nlanguage processing to deliver significantly more accurate results. We propose\ntwo major architectures: Satisfaction BERT (Sat-BERT), and Dual-Satisfaction\nBERT (DSat-BERT), along with their multitask learning variants to improve\nsatisfaction assessments. We perform RSA on five different datasets and compare\nresults from our variants against the chunk-based legacy approach. All\nBERT-based models significantly outperformed the legacy baseline, and Sat-BERT\ndelivered the best results returning an average improvement of 124.75% in Mean\nAverage Precision."
  },
  {
    "arxiv_id": "2312.04350",
    "title": "CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models",
    "url": "http://arxiv.org/abs/2312.04350v1",
    "abstract": "The ability to perform causal reasoning is widely considered a core feature\nof intelligence. In this work, we investigate whether large language models\n(LLMs) can coherently reason about causality. Much of the existing work in\nnatural language processing (NLP) focuses on evaluating commonsense causal\nreasoning in LLMs, thus failing to assess whether a model can perform causal\ninference in accordance with a set of well-defined formal rules. To address\nthis, we propose a new NLP task, causal inference in natural language, inspired\nby the \"causal inference engine\" postulated by Judea Pearl et al. We compose a\nlarge dataset, CLadder, with 10K samples: based on a collection of causal\ngraphs and queries (associational, interventional, and counterfactual), we\nobtain symbolic questions and ground-truth answers, through an oracle causal\ninference engine. These are then translated into natural language. We evaluate\nmultiple LLMs on our dataset, and we introduce and evaluate a bespoke\nchain-of-thought prompting strategy, CausalCoT. We show that our task is highly\nchallenging for LLMs, and we conduct an in-depth analysis to gain deeper\ninsights into the causal reasoning abilities of LLMs. Our data is open-sourced\nat https://huggingface.co/datasets/causalNLP/cladder, and our code can be found\nat https://github.com/causalNLP/cladder."
  },
  {
    "arxiv_id": "2312.04234",
    "title": "Graph Convolutions Enrich the Self-Attention in Transformers!",
    "url": "http://arxiv.org/abs/2312.04234v1",
    "abstract": "Transformers, renowned for their self-attention mechanism, have achieved\nstate-of-the-art performance across various tasks in natural language\nprocessing, computer vision, time-series modeling, etc. However, one of the\nchallenges with deep Transformer models is the oversmoothing problem, where\nrepresentations across layers converge to indistinguishable values, leading to\nsignificant performance degradation. We interpret the original self-attention\nas a simple graph filter and redesign it from a graph signal processing (GSP)\nperspective. We propose a graph-filter-based self-attention (GFSA) to learn a\ngeneral yet effective one, whose complexity, however, is slightly larger than\nthat of the original self-attention mechanism. We demonstrate that GFSA\nimproves the performance of Transformers in various fields, including computer\nvision, natural language processing, graph-level tasks, speech recognition, and\ncode classification."
  },
  {
    "arxiv_id": "2312.04193",
    "title": "Language Model Knowledge Distillation for Efficient Question Answering in Spanish",
    "url": "http://arxiv.org/abs/2312.04193v1",
    "abstract": "Recent advances in the development of pre-trained Spanish language models has\nled to significant progress in many Natural Language Processing (NLP) tasks,\nsuch as question answering. However, the lack of efficient models imposes a\nbarrier for the adoption of such models in resource-constrained environments.\nTherefore, smaller distilled models for the Spanish language could be proven to\nbe highly scalable and facilitate their further adoption on a variety of tasks\nand scenarios. In this work, we take one step in this direction by developing\nSpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient\nquestion answering in Spanish. To achieve this, we employ knowledge\ndistillation from a large model onto a lighter model that allows for a wider\nimplementation, even in areas with limited computational resources, whilst\nattaining negligible performance sacrifice. Our experiments show that the dense\ndistilled model can still preserve the performance of its larger counterpart,\nwhile significantly increasing inference speedup. This work serves as a\nstarting point for further research and investigation of model compression\nefforts for Spanish language models across various NLP tasks."
  },
  {
    "arxiv_id": "2312.05047",
    "title": "Converting Epics/Stories into Pseudocode using Transformers",
    "url": "http://arxiv.org/abs/2312.05047v1",
    "abstract": "The conversion of user epics or stories into their appropriate representation\nin pseudocode or code is a time-consuming task, which can take up a large\nportion of the time in an industrial project. With this research paper, we aim\nto present a methodology to generate pseudocode from a given agile user story\nof small functionalities so as to reduce the overall time spent on the\nindustrial project. Pseudocode is a programming language agnostic\nrepresentation of the steps involved in a computer program, which can be easily\nconverted into any programming language. Leveraging the potential of Natural\nLanguage Processing, we want to simplify the development process in\norganizations that use the Agile Model of Software Development. We present a\nmethodology to convert a problem described in the English language into\npseudocode. This methodology divides the Text to Pseudocode conversion task\ninto two stages or subtasks, each of which is treated like an individual\nmachine translation task. Stage 1 is Text to Code Conversion and Stage 2 is\nCode to Pseudocode Conversion. We find that the CodeT5 model gives the best\nresults in terms of BLEU score when trained separately on the two subtasks\nmentioned above. BLEU score is a metric that is used to measure the similarity\nbetween a machine-translated text and a set of reference translations."
  },
  {
    "arxiv_id": "2312.04906",
    "title": "Ophtha-LLaMA2: A Large Language Model for Ophthalmology",
    "url": "http://arxiv.org/abs/2312.04906v1",
    "abstract": "In recent years, pre-trained large language models (LLMs) have achieved\ntremendous success in the field of Natural Language Processing (NLP). Prior\nstudies have primarily focused on general and generic domains, with relatively\nless research on specialized LLMs in the medical field. The specialization and\nhigh accuracy requirements for diagnosis in the medical field, as well as the\nchallenges in collecting large-scale data, have constrained the application and\ndevelopment of LLMs in medical scenarios. In the field of ophthalmology,\nclinical diagnosis mainly relies on doctors' interpretation of reports and\nmaking diagnostic decisions. In order to take advantage of LLMs to provide\ndecision support for doctors, we collected three modalities of ophthalmic\nreport data and fine-tuned the LLaMA2 model, successfully constructing an LLM\ntermed the \"Ophtha-LLaMA2\" specifically tailored for ophthalmic disease\ndiagnosis. Inference test results show that even with a smaller fine-tuning\ndataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis\ncompared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits\nsatisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a\nvaluable tool for ophthalmologists to provide improved diagnostic support for\npatients. This research provides a useful reference for the application of LLMs\nin the field of ophthalmology, while showcasing the immense potential and\nprospects in this domain."
  },
  {
    "arxiv_id": "2312.04775",
    "title": "How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey",
    "url": "http://arxiv.org/abs/2312.04775v1",
    "abstract": "Transferability estimation has been attached to great attention in the\ncomputer vision fields. Researchers try to estimate with low computational cost\nthe performance of a model when transferred from a source task to a given\ntarget task. Considering the effectiveness of such estimations, the communities\nof natural language processing also began to study similar problems for the\nselection of pre-trained language models. However, there is a lack of a\ncomprehensive comparison between these estimation methods yet. Also, the\ndifferences between vision and language scenarios make it doubtful whether\nprevious conclusions can be established across fields. In this paper, we first\nconduct a thorough survey of existing transferability estimation methods being\nable to find the most suitable model, then we conduct a detailed empirical\nstudy for the surveyed methods based on the GLUE benchmark. From qualitative\nand quantitative analyses, we demonstrate the strengths and weaknesses of\nexisting methods and show that H-Score generally performs well with\nsuperiorities in effectiveness and efficiency. We also outline the difficulties\nof consideration of training details, applicability to text generation, and\nconsistency to certain metrics which shed light on future directions."
  },
  {
    "arxiv_id": "2312.04691",
    "title": "Simul-LLM: A Framework for Exploring High-Quality Simultaneous Translation with Large Language Models",
    "url": "http://arxiv.org/abs/2312.04691v1",
    "abstract": "Large language models (LLMs) with billions of parameters and pretrained on\nmassive amounts of data are now capable of near or better than state-of-the-art\nperformance in a variety of downstream natural language processing tasks.\nNeural machine translation (NMT) is one such task that LLMs have been applied\nto with great success. However, little research has focused on applying LLMs to\nthe more difficult subset of NMT called simultaneous translation (SimulMT),\nwhere translation begins before the entire source context is available to the\nmodel. In this paper, we address key challenges facing LLMs fine-tuned for\nSimulMT, validate classical SimulMT concepts and practices in the context of\nLLMs, explore adapting LLMs that are fine-tuned for NMT to the task of SimulMT,\nand introduce Simul-LLM, the first open-source fine-tuning and evaluation\npipeline development framework for LLMs focused on SimulMT."
  },
  {
    "arxiv_id": "2312.06099",
    "title": "Generative Large Language Models Are All-purpose Text Analytics Engines: Text-to-text Learning Is All Your Need",
    "url": "http://arxiv.org/abs/2312.06099v1",
    "abstract": "Objective To solve major clinical natural language processing (NLP) tasks\nusing a unified text-to-text learning architecture based on a generative large\nlanguage model (LLM) via prompt tuning. Methods We formulated 7 key clinical\nNLP tasks as text-to-text learning and solved them using one unified generative\nclinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with\nup to 20 billion parameters. We adopted soft prompts (i.e., trainable vectors)\nwith frozen LLM, where the LLM parameters were not updated (i.e., frozen) and\nonly the vectors of soft prompts were updated, known as prompt tuning. We added\nadditional soft prompts as a prefix to the input layer, which were optimized\nduring the prompt tuning. We evaluated the proposed method using 7 clinical NLP\ntasks and compared them with previous task-specific solutions based on\nTransformer models. Results and Conclusion The proposed approach achieved\nstate-of-the-art performance for 5 out of 7 major clinical NLP tasks using one\nunified generative LLM. Our approach outperformed previous task-specific\ntransformer models by ~3% for concept extraction and 7% for relation extraction\napplied to social determinants of health, 3.4% for clinical concept\nnormalization, 3.4~10% for clinical abbreviation disambiguation, and 5.5~9% for\nnatural language inference. Our approach also outperformed a previously\ndeveloped prompt-based machine reading comprehension (MRC) model,\nGatorTron-MRC, for clinical concept and relation extraction. The proposed\napproach can deliver the ``one model for all`` promise from training to\ndeployment using a unified generative LLM."
  },
  {
    "arxiv_id": "2312.06002",
    "title": "Large Language Models on Lexical Semantic Change Detection: An Evaluation",
    "url": "http://arxiv.org/abs/2312.06002v1",
    "abstract": "Lexical Semantic Change Detection stands out as one of the few areas where\nLarge Language Models (LLMs) have not been extensively involved. Traditional\nmethods like PPMI, and SGNS remain prevalent in research, alongside newer\nBERT-based approaches. Despite the comprehensive coverage of various natural\nlanguage processing domains by LLMs, there is a notable scarcity of literature\nconcerning their application in this specific realm. In this work, we seek to\nbridge this gap by introducing LLMs into the domain of Lexical Semantic Change\nDetection. Our work presents novel prompting solutions and a comprehensive\nevaluation that spans all three generations of language models, contributing to\nthe exploration of LLMs in this research area."
  },
  {
    "arxiv_id": "2312.05725",
    "title": "FP8-BERT: Post-Training Quantization for Transformer",
    "url": "http://arxiv.org/abs/2312.05725v1",
    "abstract": "Transformer-based models, such as BERT, have been widely applied in a wide\nrange of natural language processing tasks. However, one inevitable side effect\nis that they require massive memory storage and inference cost when deployed in\nproduction. Quantization is one of the popularized ways to alleviate the cost.\nHowever, the previous 8-bit quantization strategy based on INT8 data format\neither suffers from the degradation of accuracy in a Post-Training Quantization\n(PTQ) fashion or requires an expensive Quantization-Aware Training (QAT)\nprocess. Recently, a new numeric format FP8 (i.e. floating-point of 8-bits) has\nbeen proposed and supported in commercial AI computing platforms such as H100.\nIn this paper, we empirically validate the effectiveness of FP8 as a way to do\nPost-Training Quantization without significant loss of accuracy, with a simple\ncalibration and format conversion process. We adopt the FP8 standard proposed\nby NVIDIA Corp. (2022) in our extensive experiments of BERT variants on GLUE\nand SQuAD v1.1 datasets, and show that PTQ with FP8 can significantly improve\nthe accuracy upon that with INT8, to the extent of the full-precision model."
  },
  {
    "arxiv_id": "2312.08212",
    "title": "LAMM: Label Alignment for Multi-Modal Prompt Learning",
    "url": "http://arxiv.org/abs/2312.08212v1",
    "abstract": "With the success of pre-trained visual-language (VL) models such as CLIP in\nvisual representation tasks, transferring pre-trained models to downstream\ntasks has become a crucial paradigm. Recently, the prompt tuning paradigm,\nwhich draws inspiration from natural language processing (NLP), has made\nsignificant progress in VL field. However, preceding methods mainly focus on\nconstructing prompt templates for text and visual inputs, neglecting the gap in\nclass label representations between the VL models and downstream tasks. To\naddress this challenge, we introduce an innovative label alignment method named\n\\textbf{LAMM}, which can dynamically adjust the category embeddings of\ndownstream datasets through end-to-end training. Moreover, to achieve a more\nappropriate label distribution, we propose a hierarchical loss, encompassing\nthe alignment of the parameter space, feature space, and logits space. We\nconduct experiments on 11 downstream vision datasets and demonstrate that our\nmethod significantly improves the performance of existing multi-modal prompt\nlearning models in few-shot scenarios, exhibiting an average accuracy\nimprovement of 2.31(\\%) compared to the state-of-the-art methods on 16 shots.\nMoreover, our methodology exhibits the preeminence in continual learning\ncompared to other prompt tuning methods. Importantly, our method is synergistic\nwith existing prompt tuning methods and can boost the performance on top of\nthem. Our code and dataset will be publicly available at\nhttps://github.com/gaojingsheng/LAMM."
  },
  {
    "arxiv_id": "2312.07887",
    "title": "Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2312.07887v1",
    "abstract": "Incremental Learning (IL) has been a long-standing problem in both vision and\nNatural Language Processing (NLP) communities. In recent years, as Pre-trained\nLanguage Models (PLMs) have achieved remarkable progress in various NLP\ndownstream tasks, utilizing PLMs as backbones has become a common practice in\nrecent research of IL in NLP. Most assume that catastrophic forgetting is the\nbiggest obstacle to achieving superior IL performance and propose various\ntechniques to overcome this issue. However, we find that this assumption is\nproblematic. Specifically, we revisit more than 20 methods on four\nclassification tasks (Text Classification, Intent Classification, Relation\nExtraction, and Named Entity Recognition) under the two most popular IL\nsettings (Class-Incremental and Task-Incremental) and reveal that most of them\nseverely underestimate the inherent anti-forgetting ability of PLMs. Based on\nthe observation, we propose a frustratingly easy method called SEQ* for IL with\nPLMs. The results show that SEQ* has competitive or superior performance\ncompared to state-of-the-art (SOTA) IL methods and requires considerably less\ntrainable parameters and training time. These findings urge us to revisit the\nIL with PLMs and encourage future studies to have a fundamental understanding\nof the catastrophic forgetting in PLMs. The data, code and scripts are publicly\navailable at\nhttps://github.com/zzz47zzz/codebase-for-incremental-learning-with-llm."
  },
  {
    "arxiv_id": "2312.08725",
    "title": "A Comparative Analysis of Fine-Tuned LLMs and Few-Shot Learning of LLMs for Financial Sentiment Analysis",
    "url": "http://arxiv.org/abs/2312.08725v1",
    "abstract": "Financial sentiment analysis plays a crucial role in uncovering latent\npatterns and detecting emerging trends, enabling individuals to make\nwell-informed decisions that may yield substantial advantages within the\nconstantly changing realm of finance. Recently, Large Language Models (LLMs)\nhave demonstrated their effectiveness in diverse domains, showcasing remarkable\ncapabilities even in zero-shot and few-shot in-context learning for various\nNatural Language Processing (NLP) tasks. Nevertheless, their potential and\napplicability in the context of financial sentiment analysis have not been\nthoroughly explored yet. To bridge this gap, we employ two approaches:\nin-context learning (with a focus on gpt-3.5-turbo model) and fine-tuning LLMs\non a finance-domain dataset. Given the computational costs associated with\nfine-tuning LLMs with large parameter sizes, our focus lies on smaller LLMs,\nspanning from 250M to 3B parameters for fine-tuning. We then compare the\nperformances with state-of-the-art results to evaluate their effectiveness in\nthe finance-domain. Our results demonstrate that fine-tuned smaller LLMs can\nachieve comparable performance to state-of-the-art fine-tuned LLMs, even with\nmodels having fewer parameters and a smaller training dataset. Additionally,\nthe zero-shot and one-shot performance of LLMs produces comparable results with\nfine-tuned smaller LLMs and state-of-the-art outcomes. Furthermore, our\nanalysis demonstrates that there is no observed enhancement in performance for\nfinance-domain sentiment analysis when the number of shots for in-context\nlearning is increased."
  },
  {
    "arxiv_id": "2312.08629",
    "title": "ChatSOS: LLM-based knowledge Q&A system for safety engineering",
    "url": "http://arxiv.org/abs/2312.08629v1",
    "abstract": "Recent advancements in large language models (LLMs) have notably propelled\nnatural language processing (NLP) capabilities, demonstrating significant\npotential in safety engineering applications. Despite these advancements, LLMs\nface constraints in processing specialized tasks, attributed to factors such as\ncorpus size, input processing limitations, and privacy concerns. Obtaining\nuseful information from reliable sources in a limited time is crucial for LLM.\nAddressing this, our study introduces an LLM-based Q&A system for safety\nengineering, enhancing the comprehension and response accuracy of the model. We\nemployed prompt engineering to incorporate external knowledge databases, thus\nenriching the LLM with up-to-date and reliable information. The system analyzes\nhistorical incident reports through statistical methods, utilizes vector\nembedding to construct a vector database, and offers an efficient\nsimilarity-based search functionality. Our findings indicate that the\nintegration of external knowledge significantly augments the capabilities of\nLLM for in-depth problem analysis and autonomous task assignment. It\neffectively summarizes accident reports and provides pertinent recommendations.\nThis integration approach not only expands LLM applications in safety\nengineering but also sets a precedent for future developments towards\nautomation and intelligent systems."
  },
  {
    "arxiv_id": "2312.10007",
    "title": "Faithful Persona-based Conversational Dataset Generation with Large Language Models",
    "url": "http://arxiv.org/abs/2312.10007v1",
    "abstract": "High-quality conversational datasets are essential for developing AI models\nthat can communicate with users. One way to foster deeper interactions between\na chatbot and its user is through personas, aspects of the user's character\nthat provide insights into their personality, motivations, and behaviors.\nTraining Natural Language Processing (NLP) models on a diverse and\ncomprehensive persona-based dataset can lead to conversational models that\ncreate a deeper connection with the user, and maintain their engagement. In\nthis paper, we leverage the power of Large Language Models (LLMs) to create a\nlarge, high-quality conversational dataset from a seed dataset. We propose a\nGenerator-Critic architecture framework to expand the initial dataset, while\nimproving the quality of its conversations. The Generator is an LLM prompted to\noutput conversations. The Critic consists of a mixture of expert LLMs that\ncontrol the quality of the generated conversations. These experts select the\nbest generated conversations, which we then use to improve the Generator. We\nrelease Synthetic-Persona-Chat, consisting of 20k conversations seeded from\nPersona-Chat. We evaluate the quality of Synthetic-Persona-Chat and our\ngeneration framework on different dimensions through extensive experiments, and\nobserve that the losing rate of Synthetic-Persona-Chat against Persona-Chat\nduring Turing test decreases from 17.2% to 8.8% over three iterations."
  },
  {
    "arxiv_id": "2312.10770",
    "title": "Identification of Knowledge Neurons in Protein Language Models",
    "url": "http://arxiv.org/abs/2312.10770v1",
    "abstract": "Neural language models have become powerful tools for learning complex\nrepresentations of entities in natural language processing tasks. However,\ntheir interpretability remains a significant challenge, particularly in domains\nlike computational biology where trust in model predictions is crucial. In this\nwork, we aim to enhance the interpretability of protein language models,\nspecifically the state-of-the-art ESM model, by identifying and characterizing\nknowledge neurons - components that express understanding of key information.\nAfter fine-tuning the ESM model for the task of enzyme sequence classification,\nwe compare two knowledge neuron selection methods that preserve a subset of\nneurons from the original model. The two methods, activation-based and\nintegrated gradient-based selection, consistently outperform a random baseline.\nIn particular, these methods show that there is a high density of knowledge\nneurons in the key vector prediction networks of self-attention modules. Given\nthat key vectors specialize in understanding different features of input\nsequences, these knowledge neurons could capture knowledge of different enzyme\nsequence motifs. In the future, the types of knowledge captured by each neuron\ncould be characterized."
  },
  {
    "arxiv_id": "2312.10702",
    "title": "Can persistent homology whiten Transformer-based black-box models? A case study on BERT compression",
    "url": "http://arxiv.org/abs/2312.10702v1",
    "abstract": "Large Language Models (LLMs) like BERT have gained significant prominence due\nto their remarkable performance in various natural language processing tasks.\nHowever, they come with substantial computational and memory costs.\nAdditionally, they are essentially black-box models, challenging to explain and\ninterpret. In this article, we propose Optimus BERT Compression and\nExplainability (OBCE), a methodology to bring explainability to BERT models\nusing persistent homology, aiming to measure the importance of each neuron by\nstudying the topological characteristics of their outputs. As a result, we can\ncompress BERT significantly by reducing the number of parameters (58.47% of the\noriginal parameters for BERT Base, 52.3% for BERT Large). We evaluated our\nmethodology on the standard GLUE Benchmark, comparing the results with\nstate-of-the-art techniques and achieving outstanding results. Consequently,\nour methodology can \"whiten\" BERT models by providing explainability to its\nneurons and reducing the model's size, making it more suitable for deployment\non resource-constrained devices."
  },
  {
    "arxiv_id": "2312.10700",
    "title": "Cross-Domain Robustness of Transformer-based Keyphrase Generation",
    "url": "http://arxiv.org/abs/2312.10700v1",
    "abstract": "Modern models for text generation show state-of-the-art results in many\nnatural language processing tasks. In this work, we explore the effectiveness\nof abstractive text summarization models for keyphrase selection. A list of\nkeyphrases is an important element of a text in databases and repositories of\nelectronic documents. In our experiments, abstractive text summarization models\nfine-tuned for keyphrase generation show quite high results for a target text\ncorpus. However, in most cases, the zero-shot performance on other corpora and\ndomains is significantly lower. We investigate cross-domain limitations of\nabstractive text summarization models for keyphrase generation. We present an\nevaluation of the fine-tuned BART models for the keyphrase selection task\nacross six benchmark corpora for keyphrase extraction including scientific\ntexts from two domains and news texts. We explore the role of transfer learning\nbetween different domains to improve the BART model performance on small text\ncorpora. Our experiments show that preliminary fine-tuning on out-of-domain\ncorpora can be effective under conditions of a limited number of samples."
  },
  {
    "arxiv_id": "2312.10457",
    "title": "Semantic-Aware Autoregressive Image Modeling for Visual Representation Learning",
    "url": "http://arxiv.org/abs/2312.10457v1",
    "abstract": "The development of autoregressive modeling (AM) in computer vision lags\nbehind natural language processing (NLP) in self-supervised pre-training. This\nis mainly caused by the challenge that images are not sequential signals and\nlack a natural order when applying autoregressive modeling. In this study,\ninspired by human beings' way of grasping an image, i.e., focusing on the main\nobject first, we present a semantic-aware autoregressive image modeling\n(SemAIM) method to tackle this challenge. The key insight of SemAIM is to\nautoregressive model images from the semantic patches to the less semantic\npatches. To this end, we first calculate a semantic-aware permutation of\npatches according to their feature similarities and then perform the\nautoregression procedure based on the permutation. In addition, considering\nthat the raw pixels of patches are low-level signals and are not ideal\nprediction targets for learning high-level semantic representation, we also\nexplore utilizing the patch features as the prediction targets. Extensive\nexperiments are conducted on a broad range of downstream tasks, including image\nclassification, object detection, and instance/semantic segmentation, to\nevaluate the performance of SemAIM. The results demonstrate SemAIM achieves\nstate-of-the-art performance compared with other self-supervised methods.\nSpecifically, with ViT-B, SemAIM achieves 84.1% top-1 accuracy for fine-tuning\non ImageNet, 51.3% AP and 45.4% AP for object detection and instance\nsegmentation on COCO, which outperforms the vanilla MAE by 0.5%, 1.0%, and\n0.5%, respectively."
  },
  {
    "arxiv_id": "2312.12148",
    "title": "Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment",
    "url": "http://arxiv.org/abs/2312.12148v1",
    "abstract": "With the continuous growth in the number of parameters of transformer-based\npretrained language models (PLMs), particularly the emergence of large language\nmodels (LLMs) with billions of parameters, many natural language processing\n(NLP) tasks have demonstrated remarkable success. However, the enormous size\nand computational demands of these models pose significant challenges for\nadapting them to specific downstream tasks, especially in environments with\nlimited computational resources. Parameter Efficient Fine-Tuning (PEFT) offers\nan effective solution by reducing the number of fine-tuning parameters and\nmemory usage while achieving comparable performance to full fine-tuning. The\ndemands for fine-tuning PLMs, especially LLMs, have led to a surge in the\ndevelopment of PEFT methods, as depicted in Fig. 1. In this paper, we present a\ncomprehensive and systematic review of PEFT methods for PLMs. We summarize\nthese PEFT methods, discuss their applications, and outline future directions.\nFurthermore, we conduct experiments using several representative PEFT methods\nto better understand their effectiveness in parameter efficiency and memory\nefficiency. By offering insights into the latest advancements and practical\napplications, this survey serves as an invaluable resource for researchers and\npractitioners seeking to navigate the challenges and opportunities presented by\nPEFT in the context of PLMs."
  },
  {
    "arxiv_id": "2312.11750",
    "title": "A Heterogeneous Chiplet Architecture for Accelerating End-to-End Transformer Models",
    "url": "http://arxiv.org/abs/2312.11750v1",
    "abstract": "Transformers have revolutionized deep learning and generative modeling,\nenabling advancements in natural language processing tasks. However, the size\nof transformer models is increasing continuously, driven by enhanced\ncapabilities across various deep learning tasks. This trend of ever-increasing\nmodel size has given rise to new challenges in terms of memory and compute\nrequirements. Conventional computing platforms, including GPUs, suffer from\nsuboptimal performance due to the memory demands imposed by models with\nmillions/billions of parameters. The emerging chiplet-based platforms provide a\nnew avenue for compute- and data-intensive machine learning (ML) applications\nenabled by a Network-on-Interposer (NoI). However, designing suitable hardware\naccelerators for executing Transformer inference workloads is challenging due\nto a wide variety of complex computing kernels in the Transformer architecture.\nIn this paper, we leverage chiplet-based heterogeneous integration (HI) to\ndesign a high-performance and energy-efficient multi-chiplet platform to\naccelerate transformer workloads. We demonstrate that the proposed NoI\narchitecture caters to the data access patterns inherent in a transformer\nmodel. The optimized placement of the chiplets and the associated NoI links and\nrouters enable superior performance compared to the state-of-the-art hardware\naccelerators. The proposed NoI-based architecture demonstrates scalability\nacross varying transformer models and improves latency and energy efficiency by\nup to 11.8x and 2.36x, respectively when compared with the existing\nstate-of-the-art architecture HAIMA."
  },
  {
    "arxiv_id": "2312.11166",
    "title": "Structure-Preserving Transformers for Learning Parametrized Hamiltonian Systems",
    "url": "http://arxiv.org/abs/2312.11166v1",
    "abstract": "Two of the many trends in neural network research of the past few years have\nbeen (i) the learning of dynamical systems, especially with recurrent neural\nnetworks such as long short-term memory networks (LSTMs) and (ii) the\nintroduction of transformer neural networks for natural language processing\n(NLP) tasks.\n  While some work has been performed on the intersection of these two trends,\nthose efforts were largely limited to using the vanilla transformer directly\nwithout adjusting its architecture for the setting of a physical system.\n  In this work we develop a transformer-inspired neural network and use it to\nlearn a dynamical system. We (for the first time) change the activation\nfunction of the attention layer to imbue the transformer with\nstructure-preserving properties to improve long-term stability. This is shown\nto be of great advantage when applying the neural network to learning the\ntrajectory of a rigid body."
  },
  {
    "arxiv_id": "2312.12598",
    "title": "A Case Study on Test Case Construction with Large Language Models: Unveiling Practical Insights and Challenges",
    "url": "http://arxiv.org/abs/2312.12598v2",
    "abstract": "This paper presents a detailed case study examining the application of Large\nLanguage Models (LLMs) in the construction of test cases within the context of\nsoftware engineering. LLMs, characterized by their advanced natural language\nprocessing capabilities, are increasingly garnering attention as tools to\nautomate and enhance various aspects of the software development life cycle.\nLeveraging a case study methodology, we systematically explore the integration\nof LLMs in the test case construction process, aiming to shed light on their\npractical efficacy, challenges encountered, and implications for software\nquality assurance. The study encompasses the selection of a representative\nsoftware application, the formulation of test case construction methodologies\nemploying LLMs, and the subsequent evaluation of outcomes. Through a blend of\nqualitative and quantitative analyses, this study assesses the impact of LLMs\non test case comprehensiveness, accuracy, and efficiency. Additionally, delves\ninto challenges such as model interpretability and adaptation to diverse\nsoftware contexts. The findings from this case study contributes with nuanced\ninsights into the practical utility of LLMs in the domain of test case\nconstruction, elucidating their potential benefits and limitations. By\naddressing real-world scenarios and complexities, this research aims to inform\nsoftware practitioners and researchers alike about the tangible implications of\nincorporating LLMs into the software testing landscape, fostering a more\ncomprehensive understanding of their role in optimizing the software\ndevelopment process."
  },
  {
    "arxiv_id": "2312.13881",
    "title": "Diversifying Knowledge Enhancement of Biomedical Language Models using Adapter Modules and Knowledge Graphs",
    "url": "http://arxiv.org/abs/2312.13881v1",
    "abstract": "Recent advances in natural language processing (NLP) owe their success to\npre-training language models on large amounts of unstructured data. Still,\nthere is an increasing effort to combine the unstructured nature of LMs with\nstructured knowledge and reasoning. Particularly in the rapidly evolving field\nof biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as\npromising tools to bridge the gap between large language models and\ndomain-specific knowledge, considering the available biomedical knowledge\ngraphs (KGs) curated by experts over the decades. In this paper, we develop an\napproach that uses lightweight adapter modules to inject structured biomedical\nknowledge into pre-trained language models (PLMs). We use two large KGs, the\nbiomedical knowledge system UMLS and the novel biochemical ontology OntoChem,\nwith two prominent biomedical PLMs, PubMedBERT and BioLinkBERT. The approach\nincludes partitioning knowledge graphs into smaller subgraphs, fine-tuning\nadapter modules for each subgraph, and combining the knowledge in a fusion\nlayer. We test the performance on three downstream tasks: document\nclassification,question answering, and natural language inference. We show that\nour methodology leads to performance improvements in several instances while\nkeeping requirements in computing power low. Finally, we provide a detailed\ninterpretation of the results and report valuable insights for future work."
  },
  {
    "arxiv_id": "2312.13557",
    "title": "Empowering Few-Shot Recommender Systems with Large Language Models -- Enhanced Representations",
    "url": "http://arxiv.org/abs/2312.13557v1",
    "abstract": "Recommender systems utilizing explicit feedback have witnessed significant\nadvancements and widespread applications over the past years. However,\ngenerating recommendations in few-shot scenarios remains a persistent\nchallenge. Recently, large language models (LLMs) have emerged as a promising\nsolution for addressing natural language processing (NLP) tasks, thereby\noffering novel insights into tackling the few-shot scenarios encountered by\nexplicit feedback-based recommender systems. To bridge recommender systems and\nLLMs, we devise a prompting template that generates user and item\nrepresentations based on explicit feedback. Subsequently, we integrate these\nLLM-processed representations into various recommendation models to evaluate\ntheir significance across diverse recommendation tasks. Our ablation\nexperiments and case study analysis collectively demonstrate the effectiveness\nof LLMs in processing explicit feedback, highlighting that LLMs equipped with\ngenerative and logical reasoning capabilities can effectively serve as a\ncomponent of recommender systems to enhance their performance in few-shot\nscenarios. Furthermore, the broad adaptability of LLMs augments the\ngeneralization potential of recommender models, despite certain inherent\nconstraints. We anticipate that our study can inspire researchers to delve\ndeeper into the multifaceted dimensions of LLMs's involvement in recommender\nsystems and contribute to the advancement of the explicit feedback-based\nrecommender systems field."
  },
  {
    "arxiv_id": "2312.14862",
    "title": "YAYI 2: Multilingual Open-Source Large Language Models",
    "url": "http://arxiv.org/abs/2312.14862v1",
    "abstract": "As the latest advancements in natural language processing, large language\nmodels (LLMs) have achieved human-level language understanding and generation\nabilities in many real-world tasks, and even have been regarded as a potential\npath to the artificial general intelligence. To better facilitate research on\nLLMs, many open-source LLMs, such as Llama 2 and Falcon, have recently been\nproposed and gained comparable performances to proprietary models. However,\nthese models are primarily designed for English scenarios and exhibit poor\nperformances in Chinese contexts. In this technical report, we propose YAYI 2,\nincluding both base and chat models, with 30 billion parameters. YAYI 2 is\npre-trained from scratch on a multilingual corpus which contains 2.65 trillion\ntokens filtered by our pre-training data processing pipeline. The base model is\naligned with human values through supervised fine-tuning with millions of\ninstructions and reinforcement learning from human feedback. Extensive\nexperiments on multiple benchmarks, such as MMLU and CMMLU, consistently\ndemonstrate that the proposed YAYI 2 outperforms other similar sized\nopen-source models."
  },
  {
    "arxiv_id": "2312.14769",
    "title": "Large Language Model (LLM) Bias Index -- LLMBI",
    "url": "http://arxiv.org/abs/2312.14769v1",
    "abstract": "The Large Language Model Bias Index (LLMBI) is a pioneering approach designed\nto quantify and address biases inherent in large language models (LLMs), such\nas GPT-4. We recognise the increasing prevalence and impact of LLMs across\ndiverse sectors. This research introduces a novel metric, LLMBI, to\nsystematically measure and mitigate biases potentially skewing model responses.\nWe formulated LLMBI using a composite scoring system incorporating multiple\ndimensions of bias, including but not limited to age, gender, and racial\nbiases. To operationalise this metric, we engaged in a multi-step process\ninvolving collecting and annotating LLM responses, applying sophisticated\nNatural Language Processing (NLP) techniques for bias detection, and computing\nthe LLMBI score through a specially crafted mathematical formula. The formula\nintegrates weighted averages of various bias dimensions, a penalty for dataset\ndiversity deficiencies, and a correction for sentiment biases. Our empirical\nanalysis, conducted using responses from OpenAI's API, employs advanced\nsentiment analysis as a representative method for bias detection. The research\nreveals LLMs, whilst demonstrating impressive capabilities in text generation,\nexhibit varying degrees of bias across different dimensions. LLMBI provides a\nquantifiable measure to compare biases across models and over time, offering a\nvital tool for systems engineers, researchers and regulators in enhancing the\nfairness and reliability of LLMs. It highlights the potential of LLMs in\nmimicking unbiased human-like responses. Additionally, it underscores the\nnecessity of continuously monitoring and recalibrating such models to align\nwith evolving societal norms and ethical standards."
  },
  {
    "arxiv_id": "2312.14670",
    "title": "Zero-shot Causal Graph Extrapolation from Text via LLMs",
    "url": "http://arxiv.org/abs/2312.14670v1",
    "abstract": "We evaluate the ability of large language models (LLMs) to infer causal\nrelations from natural language. Compared to traditional natural language\nprocessing and deep learning techniques, LLMs show competitive performance in a\nbenchmark of pairwise relations without needing (explicit) training samples.\nThis motivates us to extend our approach to extrapolating causal graphs through\niterated pairwise queries. We perform a preliminary analysis on a benchmark of\nbiomedical abstracts with ground-truth causal graphs validated by experts. The\nresults are promising and support the adoption of LLMs for such a crucial step\nin causal inference, especially in medical domains, where the amount of\nscientific text to analyse might be huge, and the causal statements are often\nimplicit."
  },
  {
    "arxiv_id": "2312.16168",
    "title": "Social-Transmotion: Promptable Human Trajectory Prediction",
    "url": "http://arxiv.org/abs/2312.16168v1",
    "abstract": "Accurate human trajectory prediction is crucial for applications such as\nautonomous vehicles, robotics, and surveillance systems. Yet, existing models\noften fail to fully leverage the non-verbal social cues human subconsciously\ncommunicate when navigating the space. To address this, we introduce\nSocial-Transmotion, a generic Transformer-based model that exploits diverse and\nnumerous visual cues to predict human behavior. We translate the idea of a\nprompt from Natural Language Processing (NLP) to the task of human trajectory\nprediction, where a prompt can be a sequence of x-y coordinates on the ground,\nbounding boxes in the image plane, or body pose keypoints in either 2D or 3D.\nThis, in turn, augments trajectory data, leading to enhanced human trajectory\nprediction. Using masking technique, our model exhibits flexibility and\nadaptability by capturing spatiotemporal interactions between agents based on\nthe available visual cues. We delve into the merits of using 2D versus 3D\nposes, and a limited set of poses. Additionally, we investigate the spatial and\ntemporal attention map to identify which keypoints and time-steps in the\nsequence are vital for optimizing human trajectory prediction. Our approach is\nvalidated on multiple datasets, including JTA, JRDB, Pedestrians and Cyclists\nin Road Traffic, and ETH-UCY. The code is publicly available:\nhttps://github.com/vita-epfl/social-transmotion."
  },
  {
    "arxiv_id": "2312.15883",
    "title": "Think and Retrieval: A Hypothesis Knowledge Graph Enhanced Medical Large Language Models",
    "url": "http://arxiv.org/abs/2312.15883v1",
    "abstract": "In this paper, we investigate the retrieval-augmented generation (RAG) based\non Knowledge Graphs (KGs) to improve the accuracy and reliability of Large\nLanguage Models (LLMs). Recent approaches suffer from insufficient and\nrepetitive knowledge retrieval, tedious and time-consuming query parsing, and\nmonotonous knowledge utilization. To this end, we develop a Hypothesis\nKnowledge Graph Enhanced (HyKGE) framework, which leverages LLMs' powerful\nreasoning capacity to compensate for the incompleteness of user queries,\noptimizes the interaction process with LLMs, and provides diverse retrieved\nknowledge. Specifically, HyKGE explores the zero-shot capability and the rich\nknowledge of LLMs with Hypothesis Outputs to extend feasible exploration\ndirections in the KGs, as well as the carefully curated prompt to enhance the\ndensity and efficiency of LLMs' responses. Furthermore, we introduce the HO\nFragment Granularity-aware Rerank Module to filter out noise while ensuring the\nbalance between diversity and relevance in retrieved knowledge. Experiments on\ntwo Chinese medical multiple-choice question datasets and one Chinese\nopen-domain medical Q&A dataset with two LLM turbos demonstrate the superiority\nof HyKGE in terms of accuracy and explainability."
  },
  {
    "arxiv_id": "2312.15872",
    "title": "Heterogeneous Encoders Scaling In The Transformer For Neural Machine Translation",
    "url": "http://arxiv.org/abs/2312.15872v1",
    "abstract": "Although the Transformer is currently the best-performing architecture in the\nhomogeneous configuration (self-attention only) in Neural Machine Translation,\nmany State-of-the-Art models in Natural Language Processing are made of a\ncombination of different Deep Learning approaches. However, these models often\nfocus on combining a couple of techniques only and it is unclear why some\nmethods are chosen over others. In this work, we investigate the effectiveness\nof integrating an increasing number of heterogeneous methods. Based on a simple\ncombination strategy and performance-driven synergy criteria, we designed the\nMulti-Encoder Transformer, which consists of up to five diverse encoders.\nResults showcased that our approach can improve the quality of the translation\nacross a variety of languages and dataset sizes and it is particularly\neffective in low-resource languages where we observed a maximum increase of\n7.16 BLEU compared to the single-encoder model."
  },
  {
    "arxiv_id": "2312.15867",
    "title": "Punctuation Matters! Stealthy Backdoor Attack for Language Models",
    "url": "http://arxiv.org/abs/2312.15867v1",
    "abstract": "Recent studies have pointed out that natural language processing (NLP) models\nare vulnerable to backdoor attacks. A backdoored model produces normal outputs\non the clean samples while performing improperly on the texts with triggers\nthat the adversary injects. However, previous studies on textual backdoor\nattack pay little attention to stealthiness. Moreover, some attack methods even\ncause grammatical issues or change the semantic meaning of the original texts.\nTherefore, they can easily be detected by humans or defense systems. In this\npaper, we propose a novel stealthy backdoor attack method against textual\nmodels, which is called \\textbf{PuncAttack}. It leverages combinations of\npunctuation marks as the trigger and chooses proper locations strategically to\nreplace them. Through extensive experiments, we demonstrate that the proposed\nmethod can effectively compromise multiple models in various tasks. Meanwhile,\nwe conduct automatic evaluation and human inspection, which indicate the\nproposed method possesses good performance of stealthiness without bringing\ngrammatical issues and altering the meaning of sentences."
  },
  {
    "arxiv_id": "2312.15851",
    "title": "Hypergraph Enhanced Knowledge Tree Prompt Learning for Next-Basket Recommendation",
    "url": "http://arxiv.org/abs/2312.15851v1",
    "abstract": "Next-basket recommendation (NBR) aims to infer the items in the next basket\ngiven the corresponding basket sequence. Existing NBR methods are mainly based\non either message passing in a plain graph or transition modelling in a basket\nsequence. However, these methods only consider point-to-point binary item\nrelations while item dependencies in real world scenarios are often in higher\norder. Additionally, the importance of the same item to different users varies\ndue to variation of user preferences, and the relations between items usually\ninvolve various aspects. As pretrained language models (PLMs) excel in multiple\ntasks in natural language processing (NLP) and computer vision (CV), many\nresearchers have made great efforts in utilizing PLMs to boost recommendation.\nHowever, existing PLM-based recommendation methods degrade when encountering\nOut-Of-Vocabulary (OOV) items. OOV items are those whose IDs are out of PLM's\nvocabulary and thus unintelligible to PLM. To settle the above challenges, we\npropose a novel method HEKP4NBR, which transforms the knowledge graph (KG) into\nprompts, namely Knowledge Tree Prompt (KTP), to help PLM encode the OOV item\nIDs in the user's basket sequence. A hypergraph convolutional module is\ndesigned to build a hypergraph based on item similarities measured by an MoE\nmodel from multiple aspects and then employ convolution on the hypergraph to\nmodel correlations among multiple items. Extensive experiments are conducted on\nHEKP4NBR on two datasets based on real company data and validate its\neffectiveness against multiple state-of-the-art methods."
  },
  {
    "arxiv_id": "2312.15746",
    "title": "Large Language Models are Not Stable Recommender Systems",
    "url": "http://arxiv.org/abs/2312.15746v1",
    "abstract": "With the significant successes of large language models (LLMs) in many\nnatural language processing tasks, there is growing interest among researchers\nin exploring LLMs for novel recommender systems. However, we have observed that\ndirectly using LLMs as a recommender system is usually unstable due to its\ninherent position bias. To this end, we introduce exploratory research and find\nconsistent patterns of positional bias in LLMs that influence the performance\nof recommendation across a range of scenarios. Then, we propose a Bayesian\nprobabilistic framework, STELLA (Stable LLM for Recommendation), which involves\na two-stage pipeline. During the first probing stage, we identify patterns in a\ntransition matrix using a probing detection dataset. And in the second\nrecommendation stage, a Bayesian strategy is employed to adjust the biased\noutput of LLMs with an entropy indicator. Therefore, our framework can\ncapitalize on existing pattern information to calibrate instability of LLMs,\nand enhance recommendation performance. Finally, extensive experiments clearly\nvalidate the effectiveness of our framework."
  },
  {
    "arxiv_id": "2312.15713",
    "title": "PersianLLaMA: Towards Building First Persian Large Language Model",
    "url": "http://arxiv.org/abs/2312.15713v1",
    "abstract": "Despite the widespread use of the Persian language by millions globally,\nlimited efforts have been made in natural language processing for this\nlanguage. The use of large language models as effective tools in various\nnatural language processing tasks typically requires extensive textual data and\nrobust hardware resources. Consequently, the scarcity of Persian textual data\nand the unavailability of powerful hardware resources have hindered the\ndevelopment of large language models for Persian. This paper introduces the\nfirst large Persian language model, named PersianLLaMA, trained on a collection\nof Persian texts and datasets. This foundational model comes in two versions,\nwith 7 and 13 billion parameters, trained on formal and colloquial Persian\ntexts using two different approaches. PersianLLaMA has been evaluated for\nnatural language generation tasks based on the latest evaluation methods,\nnamely using larger language models, and for natural language understanding\ntasks based on automated machine metrics. The results indicate that\nPersianLLaMA significantly outperforms its competitors in both understanding\nand generating Persian text. PersianLLaMA marks an important step in the\ndevelopment of Persian natural language processing and can be a valuable\nresource for the Persian-speaking community. This large language model can be\nused for various natural language processing tasks, especially text generation\nlike chatbots, question-answering, machine translation, and text summarization"
  },
  {
    "arxiv_id": "2312.17044",
    "title": "Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding",
    "url": "http://arxiv.org/abs/2312.17044v2",
    "abstract": "Built upon the Transformer, large language models (LLMs) have captured\nworldwide attention due to their remarkable abilities. Nevertheless, all\nTransformer-based models including LLMs suffer from a preset length limit and\ncan hardly generalize from short training sequences to longer inference ones,\nnamely, they cannot perform length extrapolation to handle long sequences,\nwhich severely hinders their application in scenarios demanding long input\nsequences such as legal or scientific documents. Thus, numerous methods have\nemerged to enhance the length extrapolation of Transformers. Despite the great\nresearch efforts, a systematic survey is still lacking. To fill this gap, we\ndelve into these advances in a unified notation from the perspective of\npositional encoding (PE), as it has been considered the primary factor on\nlength extrapolation. Specifically, we begin with extrapolatable PEs that have\ndominated this research field. Then, we dive into extrapolation methods based\non them, covering position interpolation and randomized position methods.\nFinally, several challenges and future directions in this area are highlighted.\nThrough this survey, we aim to enable the reader to gain a deep understanding\nof existing methods and provide stimuli for future research."
  },
  {
    "arxiv_id": "2312.16975",
    "title": "Few-shot learning for automated content analysis: Efficient coding of arguments and claims in the debate on arms deliveries to Ukraine",
    "url": "http://arxiv.org/abs/2312.16975v1",
    "abstract": "Pre-trained language models (PLM) based on transformer neural networks\ndeveloped in the field of natural language processing (NLP) offer great\nopportunities to improve automatic content analysis in communication science,\nespecially for the coding of complex semantic categories in large datasets via\nsupervised machine learning. However, three characteristics so far impeded the\nwidespread adoption of the methods in the applying disciplines: the dominance\nof English language models in NLP research, the necessary computing resources,\nand the effort required to produce training data to fine-tune PLMs. In this\nstudy, we address these challenges by using a multilingual transformer model in\ncombination with the adapter extension to transformers, and few-shot learning\nmethods. We test our approach on a realistic use case from communication\nscience to automatically detect claims and arguments together with their stance\nin the German news debate on arms deliveries to Ukraine. In three experiments,\nwe evaluate (1) data preprocessing strategies and model variants for this task,\n(2) the performance of different few-shot learning methods, and (3) how well\nthe best setup performs on varying training set sizes in terms of validity,\nreliability, replicability and reproducibility of the results. We find that our\nproposed combination of transformer adapters with pattern exploiting training\nprovides a parameter-efficient and easily shareable alternative to fully\nfine-tuning PLMs. It performs on par in terms of validity, while overall,\nprovides better properties for application in communication studies. The\nresults also show that pre-fine-tuning for a task on a near-domain dataset\nleads to substantial improvement, in particular in the few-shot setting.\nFurther, the results indicate that it is useful to bias the dataset away from\nthe viewpoints of specific prominent individuals."
  },
  {
    "arxiv_id": "2312.17522",
    "title": "Overview of the PromptCBLUE Shared Task in CHIP2023",
    "url": "http://arxiv.org/abs/2312.17522v1",
    "abstract": "This paper presents an overview of the PromptCBLUE shared task\n(http://cips-chip.org.cn/2023/eval1) held in the CHIP-2023 Conference. This\nshared task reformualtes the CBLUE benchmark, and provide a good testbed for\nChinese open-domain or medical-domain large language models (LLMs) in general\nmedical natural language processing. Two different tracks are held: (a) prompt\ntuning track, investigating the multitask prompt tuning of LLMs, (b) probing\nthe in-context learning capabilities of open-sourced LLMs. Many teams from both\nthe industry and academia participated in the shared tasks, and the top teams\nachieved amazing test results. This paper describes the tasks, the datasets,\nevaluation metrics, and the top systems for both tasks. Finally, the paper\nsummarizes the techniques and results of the evaluation of the various\napproaches explored by the participating teams."
  },
  {
    "arxiv_id": "2401.01312",
    "title": "LLM Harmony: Multi-Agent Communication for Problem Solving",
    "url": "http://arxiv.org/abs/2401.01312v1",
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\nbut exhibit limitations, particularly in autonomously addressing novel\nchallenges such as reasoning and problem-solving. Traditional techniques like\nchain-of-thought prompting necessitate explicit human guidance. This paper\nintroduces a novel multi-agent communication framework, inspired by the CAMEL\nmodel, to enhance LLMs' autonomous problem-solving capabilities. The framework\nemploys multiple LLM agents, each with a distinct persona, engaged in\nrole-playing communication, offering a nuanced and adaptable approach to\ndiverse problem scenarios. Extensive experimentation demonstrates the\nframework's superior performance and adaptability, providing valuable insights\ninto the collaborative potential of multiple agents in overcoming the\nlimitations of individual models."
  },
  {
    "arxiv_id": "2401.01262",
    "title": "Fairness Certification for Natural Language Processing and Large Language Models",
    "url": "http://arxiv.org/abs/2401.01262v1",
    "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization."
  },
  {
    "arxiv_id": "2401.00689",
    "title": "Large language model for Bible sentiment analysis: Sermon on the Mount",
    "url": "http://arxiv.org/abs/2401.00689v1",
    "abstract": "The revolution of natural language processing via large language models has\nmotivated its use in multidisciplinary areas that include social sciences and\nhumanities and more specifically, comparative religion. Sentiment analysis\nprovides a mechanism to study the emotions expressed in text. Recently,\nsentiment analysis has been used to study and compare translations of the\nBhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we\nuse sentiment analysis for studying selected chapters of the Bible. These\nchapters are known as the Sermon on the Mount. We utilize a pre-trained\nlanguage model for sentiment analysis by reviewing five translations of the\nSermon on the Mount, which include the King James version, the New\nInternational Version, the New Revised Standard Version, the Lamsa Version, and\nthe Basic English Version. We provide a chapter-by-chapter and verse-by-verse\ncomparison using sentiment and semantic analysis and review the major\nsentiments expressed. Our results highlight the varying sentiments across the\nchapters and verses. We found that the vocabulary of the respective\ntranslations is significantly different. We detected different levels of\nhumour, optimism, and empathy in the respective chapters that were used by\nJesus to deliver his message."
  },
  {
    "arxiv_id": "2401.00642",
    "title": "Predicting Anti-microbial Resistance using Large Language Models",
    "url": "http://arxiv.org/abs/2401.00642v1",
    "abstract": "During times of increasing antibiotic resistance and the spread of infectious\ndiseases like COVID-19, it is important to classify genes related to antibiotic\nresistance. As natural language processing has advanced with transformer-based\nlanguage models, many language models that learn characteristics of nucleotide\nsequences have also emerged. These models show good performance in classifying\nvarious features of nucleotide sequences. When classifying nucleotide\nsequences, not only the sequence itself, but also various background knowledge\nis utilized. In this study, we use not only a nucleotide sequence-based\nlanguage model but also a text language model based on PubMed articles to\nreflect more biological background knowledge in the model. We propose a method\nto fine-tune the nucleotide sequence language model and the text language model\nbased on various databases of antibiotic resistance genes. We also propose an\nLLM-based augmentation technique to supplement the data and an ensemble method\nto effectively combine the two models. We also propose a benchmark for\nevaluating the model. Our method achieved better performance than the\nnucleotide sequence language model in the drug resistance class prediction."
  },
  {
    "arxiv_id": "2401.00579",
    "title": "Exploring the Effectiveness of Instruction Tuning in Biomedical Language Processing",
    "url": "http://arxiv.org/abs/2401.00579v1",
    "abstract": "Large Language Models (LLMs), particularly those similar to ChatGPT, have\nsignificantly influenced the field of Natural Language Processing (NLP). While\nthese models excel in general language tasks, their performance in\ndomain-specific downstream tasks such as biomedical and clinical Named Entity\nRecognition (NER), Relation Extraction (RE), and Medical Natural Language\nInference (NLI) is still evolving. In this context, our study investigates the\npotential of instruction tuning for biomedical language processing, applying\nthis technique to two general LLMs of substantial scale. We present a\ncomprehensive, instruction-based model trained on a dataset that consists of\napproximately $200,000$ instruction-focused samples. This dataset represents a\ncarefully curated compilation of existing data, meticulously adapted and\nreformatted to align with the specific requirements of our instruction-based\ntasks. This initiative represents an important step in utilising such models to\nachieve results on par with specialised encoder-only models like BioBERT and\nBioClinicalBERT for various classical biomedical NLP tasks. Our work includes\nan analysis of the dataset's composition and its impact on model performance,\nproviding insights into the intricacies of instruction tuning. By sharing our\ncodes, models, and the distinctively assembled instruction-based dataset, we\nseek to encourage ongoing research and development in this area."
  },
  {
    "arxiv_id": "2401.01830",
    "title": "Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling",
    "url": "http://arxiv.org/abs/2401.01830v1",
    "abstract": "Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets."
  },
  {
    "arxiv_id": "2401.01692",
    "title": "Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches",
    "url": "http://arxiv.org/abs/2401.01692v1",
    "abstract": "Effective collaboration requires groups to strategically regulate themselves\nto overcome challenges. Research has shown that groups may fail to regulate due\nto differences in members' perceptions of challenges which may benefit from\nexternal support. In this study, we investigated the potential of leveraging\nthree distinct natural language processing models: an expert knowledge\nrule-based model, a supervised machine learning (ML) model and a Large Language\nmodel (LLM), in challenge detection and challenge dimension identification\n(cognitive, metacognitive, emotional and technical/other challenges) from\nstudent discourse, was investigated. The results show that the supervised ML\nand the LLM approaches performed considerably well in both tasks, in contrast\nto the rule-based approach, whose efficacy heavily relies on the engineered\nfeatures by experts. The paper provides an extensive discussion of the three\napproaches' performance for automated detection and support of students'\nchallenge moments in collaborative learning activities. It argues that,\nalthough LLMs provide many advantages, they are unlikely to be the panacea to\nissues of the detection and feedback provision of socially shared regulation of\nlearning due to their lack of reliability, as well as issues of validity\nevaluation, privacy and confabulation. We conclude the paper with a discussion\non additional considerations, including model transparency to explore feasible\nand meaningful analytical feedback for students and educators using LLMs."
  },
  {
    "arxiv_id": "2401.01641",
    "title": "Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences",
    "url": "http://arxiv.org/abs/2401.01641v2",
    "abstract": "Machine learning models underpin many modern financial systems for use cases\nsuch as fraud detection and churn prediction. Most are based on supervised\nlearning with hand-engineered features, which relies heavily on the\navailability of labelled data. Large self-supervised generative models have\nshown tremendous success in natural language processing and computer vision,\nyet so far they haven't been adapted to multivariate time series of financial\ntransactions. In this paper, we present a generative pretraining method that\ncan be used to obtain contextualised embeddings of financial transactions.\nBenchmarks on public datasets demonstrate that it outperforms state-of-the-art\nself-supervised methods on a range of downstream tasks. We additionally perform\nlarge-scale pretraining of an embedding model using a corpus of data from 180\nissuing banks containing 5.1 billion transactions and apply it to the card\nfraud detection problem on hold-out datasets. The embedding model significantly\nimproves value detection rate at high precision thresholds and transfers well\nto out-of-domain distributions."
  },
  {
    "arxiv_id": "2401.01577",
    "title": "Test-Time Personalization with Meta Prompt for Gaze Estimation",
    "url": "http://arxiv.org/abs/2401.01577v1",
    "abstract": "Despite the recent remarkable achievement in gaze estimation, efficient and\naccurate personalization of gaze estimation without labels is a practical\nproblem but rarely touched on in the literature. To achieve efficient\npersonalization, we take inspiration from the recent advances in Natural\nLanguage Processing (NLP) by updating a negligible number of parameters,\n\"prompts\", at the test time. Specifically, the prompt is additionally attached\nwithout perturbing original network and can contain less than 1% of a\nResNet-18's parameters. Our experiments show high efficiency of the prompt\ntuning approach. The proposed one can be 10 times faster in terms of adaptation\nspeed than the methods compared. However, it is non-trivial to update the\nprompt for personalized gaze estimation without labels. At the test time, it is\nessential to ensure that the minimizing of particular unsupervised loss leads\nto the goals of minimizing gaze estimation error. To address this difficulty,\nwe propose to meta-learn the prompt to ensure that its updates align with the\ngoal. Our experiments show that the meta-learned prompt can be effectively\nadapted even with a simple symmetry loss. In addition, we experiment on four\ncross-dataset validations to show the remarkable advantages of the proposed\nmethod. Code is available at https://github.com/hmarkamcan/TPGaze."
  },
  {
    "arxiv_id": "2401.02909",
    "title": "Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task",
    "url": "http://arxiv.org/abs/2401.02909v1",
    "abstract": "Large Language Models (LLMs) are increasingly bringing advances to Natural\nLanguage Processing. However, low-resource languages, those lacking extensive\nprominence in datasets for various NLP tasks, or where existing datasets are\nnot as substantial, such as Portuguese, already obtain several benefits from\nLLMs, but not to the same extent. LLMs trained on multilingual datasets\nnormally struggle to respond to prompts in Portuguese satisfactorily,\npresenting, for example, code switching in their responses. This work proposes\na fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in two\nversions: 7B and 13B. We evaluate the performance of this model in\nclassification tasks using the zero-shot approach with in-context learning, and\ncompare it with other LLMs. Our main contribution is to bring an LLM with\nsatisfactory results in the Portuguese language, as well as to provide a model\nthat is free for research or commercial purposes."
  },
  {
    "arxiv_id": "2401.02731",
    "title": "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks",
    "url": "http://arxiv.org/abs/2401.02731v1",
    "abstract": "Large language models (LLMs) have demonstrated considerable proficiency in\ngeneral natural language processing (NLP) tasks. Instruction tuning, a\nsuccessful paradigm, enhances the ability of LLMs to follow natural language\ninstructions and exhibit robust generalization across general tasks. However,\nthese models often encounter performance limitations across multiple tasks due\nto constrained model capacity. Expanding this capacity during the instruction\ntuning phase poses significant challenges. To address this issue, we introduce\nparameter-efficient sparsity crafting (PESC), which crafts dense models into\nsparse models using the mixture-of-experts (MoE) architecture. PESC integrates\nadapters into the MoE layers of sparse models, differentiating experts without\naltering the individual weights within these layers. This method significantly\nreduces computational costs and GPU memory requirements, facilitating model\ncapacity expansion through a minimal parameter increase when guaranteeing the\nquality of approximation in function space compared to original sparse\nupcycling. Our empirical evaluation demonstrates the effectiveness of the PESC\nmethod. Using PESC during instruction tuning, our best sparse model outperforms\nother sparse and dense models and exhibits superior general capabilities\ncompared to GPT-3.5. Our code is available at\nhttps://github.com/wuhy68/Parameter-Efficient-MoE."
  },
  {
    "arxiv_id": "2401.04051",
    "title": "Empirical Analysis of Efficient Fine-Tuning Methods for Large Pre-Trained Language Models",
    "url": "http://arxiv.org/abs/2401.04051v1",
    "abstract": "Fine-tuning large pre-trained language models for downstream tasks remains a\ncritical challenge in natural language processing. This paper presents an\nempirical analysis comparing two efficient fine-tuning methods - BitFit and\nadapter modules - to standard full model fine-tuning. Experiments conducted on\nGLUE benchmark datasets (MRPC, COLA, STS-B) reveal several key insights. The\nBitFit approach, which trains only bias terms and task heads, matches full\nfine-tuning performance across varying amounts of training data and time\nconstraints. It demonstrates remarkable stability even with only 30\\% of data,\noutperforming full fine-tuning at intermediate data levels. Adapter modules\nexhibit high variability, with inconsistent gains over default models. The\nfindings indicate BitFit offers an attractive balance between performance and\nparameter efficiency. Our work provides valuable perspectives on model tuning,\nemphasizing robustness and highlighting BitFit as a promising alternative for\nresource-constrained or streaming task settings. The analysis offers actionable\nguidelines for efficient adaptation of large pre-trained models, while\nillustrating open challenges in stabilizing techniques like adapter modules."
  },
  {
    "arxiv_id": "2401.04025",
    "title": "IDoFew: Intermediate Training Using Dual-Clustering in Language Models for Few Labels Text Classification",
    "url": "http://arxiv.org/abs/2401.04025v1",
    "abstract": "Language models such as Bidirectional Encoder Representations from\nTransformers (BERT) have been very effective in various Natural Language\nProcessing (NLP) and text mining tasks including text classification. However,\nsome tasks still pose challenges for these models, including text\nclassification with limited labels. This can result in a cold-start problem.\nAlthough some approaches have attempted to address this problem through\nsingle-stage clustering as an intermediate training step coupled with a\npre-trained language model, which generates pseudo-labels to improve\nclassification, these methods are often error-prone due to the limitations of\nthe clustering algorithms. To overcome this, we have developed a novel\ntwo-stage intermediate clustering with subsequent fine-tuning that models the\npseudo-labels reliably, resulting in reduced prediction errors. The key novelty\nin our model, IDoFew, is that the two-stage clustering coupled with two\ndifferent clustering algorithms helps exploit the advantages of the\ncomplementary algorithms that reduce the errors in generating reliable\npseudo-labels for fine-tuning. Our approach has shown significant improvements\ncompared to strong comparative models."
  },
  {
    "arxiv_id": "2401.03851",
    "title": "Aligned with LLM: a new multi-modal training paradigm for encoding fMRI activity in visual cortex",
    "url": "http://arxiv.org/abs/2401.03851v1",
    "abstract": "Recently, there has been a surge in the popularity of pre trained large\nlanguage models (LLMs) (such as GPT-4), sweeping across the entire Natural\nLanguage Processing (NLP) and Computer Vision (CV) communities. These LLMs have\ndemonstrated advanced multi-modal understanding capabilities and showcased\nstrong performance across various benchmarks. The LLM has started to embody\ntraits of artificial general intelligence, which holds vital guidance for\nenhancing brain-like characteristics within visual encoding models. Hence, This\npaper proposes a new multi-modal training paradigm, aligning with LLM, for\nencoding fMRI activity in visual cortex. Based on this paradigm, we trained an\nencoding model in fMRI data named the LLM-Visual Encoding Model (LLM-VEM).\nSpecifically, we utilize LLM (miniGPT4) to generate descriptive text for all\nstimulus images, forming a high-quality textual description set. Moreover, we\nuse the pre-trained text encoder (CLIP) to process these detailed descriptions,\nobtaining the text embedding features. Next, we use the contrast loss function\nto minimize the distance between the image embedding features and the text\nembedding features to complete the alignment operation of the stimulus image\nand text information. With the assistance of the pre-trained LLM, this\nalignment process facilitates better learning of the visual encoding model,\nresulting in higher precision. The final experimental results indicate that our\ntraining paradigm has significantly aided in enhancing the performance of the\nvisual encoding model."
  },
  {
    "arxiv_id": "2401.03797",
    "title": "Anatomy of Neural Language Models",
    "url": "http://arxiv.org/abs/2401.03797v1",
    "abstract": "The fields of generative AI and transfer learning have experienced remarkable\nadvancements in recent years especially in the domain of Natural Language\nProcessing (NLP). Transformers have been at the heart of these advancements\nwhere the cutting-edge transformer-based Language Models (LMs) have led to new\nstate-of-the-art results in a wide spectrum of applications. While the number\nof research works involving neural LMs is exponentially increasing, their vast\nmajority are high-level and far from self-contained. Consequently, a deep\nunderstanding of the literature in this area is a tough task especially in the\nabsence of a unified mathematical framework explaining the main types of neural\nLMs. We address the aforementioned problem in this tutorial where the objective\nis to explain neural LMs in a detailed, simplified and unambiguous mathematical\nframework accompanied by clear graphical illustrations. Concrete examples on\nwidely used models like BERT and GPT2 are explored. Finally, since transformers\npretrained on language-modeling-like tasks have been widely adopted in computer\nvision and time series applications, we briefly explore some examples of such\nsolutions in order to enable readers to understand how transformers work in the\naforementioned domains and compare this use with the original one in NLP."
  },
  {
    "arxiv_id": "2401.03428",
    "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
    "url": "http://arxiv.org/abs/2401.03428v1",
    "abstract": "Intelligent agents stand out as a potential path toward artificial general\nintelligence (AGI). Thus, researchers have dedicated significant effort to\ndiverse implementations for them. Benefiting from recent progress in large\nlanguage models (LLMs), LLM-based agents that use universal natural language as\nan interface exhibit robust generalization capabilities across various\napplications -- from serving as autonomous general-purpose task assistants to\napplications in coding, social, and economic domains, LLM-based agents offer\nextensive exploration opportunities. This paper surveys current research to\nprovide an in-depth overview of LLM-based intelligent agents within\nsingle-agent and multi-agent systems. It covers their definitions, research\nframeworks, and foundational components such as their composition, cognitive\nand planning methods, tool utilization, and responses to environmental\nfeedback. We also delve into the mechanisms of deploying LLM-based agents in\nmulti-agent systems, including multi-role collaboration, message passing, and\nstrategies to alleviate communication issues between agents. The discussions\nalso shed light on popular datasets and application scenarios. We conclude by\nenvisioning prospects for LLM-based agents, considering the evolving landscape\nof AI and natural language processing."
  },
  {
    "arxiv_id": "2401.04507",
    "title": "TechGPT-2.0: A large language model project to solve the task of knowledge graph construction",
    "url": "http://arxiv.org/abs/2401.04507v1",
    "abstract": "Large language models have exhibited robust performance across diverse\nnatural language processing tasks. This report introduces TechGPT-2.0, a\nproject designed to enhance the capabilities of large language models\nspecifically in knowledge graph construction tasks, including named entity\nrecognition (NER) and relationship triple extraction (RTE) tasks in NLP\napplications. Additionally, it serves as a LLM accessible for research within\nthe Chinese open-source model community. We offer two 7B large language model\nweights and a QLoRA weight specialized for processing lengthy texts.Notably,\nTechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all\nfunctionalities from TechGPT-1.0, it exhibits robust text processing\ncapabilities, particularly in the domains of medicine and law. Furthermore, we\nintroduce new capabilities to the model, enabling it to process texts in\nvarious domains such as geographical areas, transportation, organizations,\nliterary works, biology, natural sciences, astronomical objects, and\narchitecture. These enhancements also fortified the model's adeptness in\nhandling hallucinations, unanswerable queries, and lengthy texts. This report\nprovides a comprehensive and detailed introduction to the full fine-tuning\nprocess on Huawei's Ascend servers, encompassing experiences in Ascend server\ndebugging, instruction fine-tuning data processing, and model training. Our\ncode is available at https://github.com/neukg/TechGPT-2.0"
  },
  {
    "arxiv_id": "2401.04319",
    "title": "Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs",
    "url": "http://arxiv.org/abs/2401.04319v1",
    "abstract": "In this paper, we explore a new way for user targeting, where non-expert\nmarketers could select their target users solely given demands in natural\nlanguage form. The key to this issue is how to transform natural languages into\npractical structured logical languages, i.e., the structured understanding of\nmarketer demands. In practical scenarios, the demands of non-expert marketers\nare often abstract and diverse. Considering the impressive natural language\nprocessing ability of large language models (LLMs), we try to leverage LLMs to\nsolve this issue. To stimulate the LLMs' reasoning ability, the\nchain-of-thought (CoT) prompting method is widely used, but existing methods\nstill have some limitations in our scenario: (1) Previous methods either use\nsimple \"Let's think step by step\" spells or provide fixed examples in\ndemonstrations without considering compatibility between prompts and concrete\nquestions, making LLMs ineffective when the marketers' demands are abstract and\ndiverse. (2) Previous methods are often implemented in closed-source models or\nexcessively large models, which is not suitable in industrial practical\nscenarios. Based on these, we propose ARALLM (i.e., Analogical Reasoning\nAugmented Large Language Models) consisting of two modules: Analogical\nReasoning based Prompting and Reasoning-Augmented Multi-Task Model\nDistillation. Part of our data and code can be found at\nhttps://github.com/alipay/Analogic-Reasoning-Augmented-Large-Language-Model."
  },
  {
    "arxiv_id": "2401.04155",
    "title": "Large language models in bioinformatics: applications and perspectives",
    "url": "http://arxiv.org/abs/2401.04155v1",
    "abstract": "Large language models (LLMs) are a class of artificial intelligence models\nbased on deep learning, which have great performance in various tasks,\nespecially in natural language processing (NLP). Large language models\ntypically consist of artificial neural networks with numerous parameters,\ntrained on large amounts of unlabeled input using self-supervised or\nsemi-supervised learning. However, their potential for solving bioinformatics\nproblems may even exceed their proficiency in modeling human language. In this\nreview, we will provide a comprehensive overview of the essential components of\nlarge language models (LLMs) in bioinformatics, spanning genomics,\ntranscriptomics, proteomics, drug discovery, and single-cell analysis. Key\naspects covered include tokenization methods for diverse data types, the\narchitecture of transformer models, the core attention mechanism, and the\npre-training processes underlying these models. Additionally, we will introduce\ncurrently available foundation models and highlight their downstream\napplications across various bioinformatics domains. Finally, drawing from our\nexperience, we will offer practical guidance for both LLM users and developers,\nemphasizing strategies to optimize their use and foster further innovation in\nthe field."
  },
  {
    "arxiv_id": "2401.05060",
    "title": "MuTox: Universal MUltilingual Audio-based TOXicity Dataset and Zero-shot Detector",
    "url": "http://arxiv.org/abs/2401.05060v1",
    "abstract": "Research in toxicity detection in natural language processing for the speech\nmodality (audio-based) is quite limited, particularly for languages other than\nEnglish. To address these limitations and lay the groundwork for truly\nmultilingual audio-based toxicity detection, we introduce MuTox, the first\nhighly multilingual audio-based dataset with toxicity labels. The dataset\ncomprises 20,000 audio utterances for English and Spanish, and 4,000 for the\nother 19 languages. To demonstrate the quality of this dataset, we trained the\nMuTox audio-based toxicity classifier, which enables zero-shot toxicity\ndetection across a wide range of languages. This classifier outperforms\nexisting text-based trainable classifiers by more than 1% AUC, while expanding\nthe language coverage more than tenfold. When compared to a wordlist-based\nclassifier that covers a similar number of languages, MuTox improves precision\nand recall by approximately 2.5 times. This significant improvement underscores\nthe potential of MuTox in advancing the field of audio-based toxicity\ndetection."
  },
  {
    "arxiv_id": "2401.04821",
    "title": "MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer",
    "url": "http://arxiv.org/abs/2401.04821v1",
    "abstract": "Transformer-based pre-trained language models (PLMs) have achieved remarkable\nperformance in various natural language processing (NLP) tasks. However,\npre-training such models can take considerable resources that are almost only\navailable to high-resource languages. On the contrary, static word embeddings\nare easier to train in terms of computing resources and the amount of data\nrequired. In this paper, we introduce MoSECroT Model Stitching with Static Word\nEmbeddings for Crosslingual Zero-shot Transfer), a novel and challenging task\nthat is especially relevant to low-resource languages for which static word\nembeddings are available. To tackle the task, we present the first framework\nthat leverages relative representations to construct a common space for the\nembeddings of a source language PLM and the static word embeddings of a target\nlanguage. In this way, we can train the PLM on source-language training data\nand perform zero-shot transfer to the target language by simply swapping the\nembedding layer. However, through extensive experiments on two classification\ndatasets, we show that although our proposed framework is competitive with weak\nbaselines when addressing MoSECroT, it fails to achieve competitive results\ncompared with some strong baselines. In this paper, we attempt to explain this\nnegative result and provide several thoughts on possible improvement."
  },
  {
    "arxiv_id": "2401.05914",
    "title": "How Teachers Can Use Large Language Models and Bloom's Taxonomy to Create Educational Quizzes",
    "url": "http://arxiv.org/abs/2401.05914v1",
    "abstract": "Question generation (QG) is a natural language processing task with an\nabundance of potential benefits and use cases in the educational domain. In\norder for this potential to be realized, QG systems must be designed and\nvalidated with pedagogical needs in mind. However, little research has assessed\nor designed QG approaches with the input from real teachers or students. This\npaper applies a large language model-based QG approach where questions are\ngenerated with learning goals derived from Bloom's taxonomy. The automatically\ngenerated questions are used in multiple experiments designed to assess how\nteachers use them in practice. The results demonstrate that teachers prefer to\nwrite quizzes with automatically generated questions, and that such quizzes\nhave no loss in quality compared to handwritten versions. Further, several\nmetrics indicate that automatically generated questions can even improve the\nquality of the quizzes created, showing the promise for large scale use of QG\nin the classroom setting."
  },
  {
    "arxiv_id": "2401.05778",
    "title": "Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems",
    "url": "http://arxiv.org/abs/2401.05778v1",
    "abstract": "Large language models (LLMs) have strong capabilities in solving diverse\nnatural language processing tasks. However, the safety and security issues of\nLLM systems have become the major obstacle to their widespread application.\nMany studies have extensively investigated risks in LLM systems and developed\nthe corresponding mitigation strategies. Leading-edge enterprises such as\nOpenAI, Google, Meta, and Anthropic have also made lots of efforts on\nresponsible LLMs. Therefore, there is a growing need to organize the existing\nstudies and establish comprehensive taxonomies for the community. In this\npaper, we delve into four essential modules of an LLM system, including an\ninput module for receiving prompts, a language model trained on extensive\ncorpora, a toolchain module for development and deployment, and an output\nmodule for exporting LLM-generated content. Based on this, we propose a\ncomprehensive taxonomy, which systematically analyzes potential risks\nassociated with each module of an LLM system and discusses the corresponding\nmitigation strategies. Furthermore, we review prevalent benchmarks, aiming to\nfacilitate the risk assessment of LLM systems. We hope that this paper can help\nLLM participants embrace a systematic perspective to build their responsible\nLLM systems."
  },
  {
    "arxiv_id": "2401.05669",
    "title": "ConcEPT: Concept-Enhanced Pre-Training for Language Models",
    "url": "http://arxiv.org/abs/2401.05669v1",
    "abstract": "Pre-trained language models (PLMs) have been prevailing in state-of-the-art\nmethods for natural language processing, and knowledge-enhanced PLMs are\nfurther proposed to promote model performance in knowledge-intensive tasks.\nHowever, conceptual knowledge, one essential kind of knowledge for human\ncognition, still remains understudied in this line of research. This limits\nPLMs' performance in scenarios requiring human-like cognition, such as\nunderstanding long-tail entities with concepts. In this paper, we propose\nConcEPT, which stands for Concept-Enhanced Pre-Training for language models, to\ninfuse conceptual knowledge into PLMs. ConcEPT exploits external taxonomies\nwith entity concept prediction, a novel pre-training objective to predict the\nconcepts of entities mentioned in the pre-training contexts. Unlike previous\nconcept-enhanced methods, ConcEPT can be readily adapted to various downstream\napplications without entity linking or concept mapping. Results of extensive\nexperiments show the effectiveness of ConcEPT in four tasks such as entity\ntyping, which validates that our model gains improved conceptual knowledge with\nconcept-enhanced pre-training."
  },
  {
    "arxiv_id": "2401.05561",
    "title": "TrustLLM: Trustworthiness in Large Language Models",
    "url": "http://arxiv.org/abs/2401.05561v1",
    "abstract": "Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness."
  },
  {
    "arxiv_id": "2401.05476",
    "title": "CADgpt: Harnessing Natural Language Processing for 3D Modelling to Enhance Computer-Aided Design Workflows",
    "url": "http://arxiv.org/abs/2401.05476v1",
    "abstract": "This paper introduces CADgpt, an innovative plugin integrating Natural\nLanguage Processing (NLP) with Rhino3D for enhancing 3D modelling in\ncomputer-aided design (CAD) environments. Leveraging OpenAI's GPT-4, CADgpt\nsimplifies the CAD interface, enabling users, particularly beginners, to\nperform complex 3D modelling tasks through intuitive natural language commands.\nThis approach significantly reduces the learning curve associated with\ntraditional CAD software, fostering a more inclusive and engaging educational\nenvironment. The paper discusses CADgpt's technical architecture, including its\nintegration within Rhino3D and the adaptation of GPT-4 capabilities for CAD\ntasks. It presents case studies demonstrating CADgpt's efficacy in various\ndesign scenarios, highlighting its potential to democratise design education by\nmaking sophisticated design tools accessible to a broader range of students.\nThe discussion further explores CADgpt's implications for pedagogy and\ncurriculum development, emphasising its role in enhancing creative exploration\nand conceptual thinking in design education.\n  Keywords: Natural Language Processing, Computer-Aided Design, 3D Modelling,\nDesign Automation, Design Education, Architectural Education"
  },
  {
    "arxiv_id": "2401.06532",
    "title": "INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning",
    "url": "http://arxiv.org/abs/2401.06532v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nvarious natural language processing tasks. Despite this, their application to\ninformation retrieval (IR) tasks is still challenging due to the infrequent\noccurrence of many IR-specific concepts in natural language. While prompt-based\nmethods can provide task descriptions to LLMs, they often fall short in\nfacilitating a comprehensive understanding and execution of IR tasks, thereby\nlimiting LLMs' applicability. To address this gap, in this work, we explore the\npotential of instruction tuning to enhance LLMs' proficiency in IR tasks. We\nintroduce a novel instruction tuning dataset, INTERS, encompassing 20 tasks\nacross three fundamental IR categories: query understanding, document\nunderstanding, and query-document relationship understanding. The data are\nderived from 43 distinct datasets with manually written templates. Our\nempirical results reveal that INTERS significantly boosts the performance of\nvarious publicly available LLMs, such as LLaMA, Mistral, and Phi, in IR tasks.\nFurthermore, we conduct extensive experiments to analyze the effects of\ninstruction design, template diversity, few-shot demonstrations, and the volume\nof instructions on performance. We make our dataset and the fine-tuned models\npublicly accessible at https://github.com/DaoD/INTERS."
  },
  {
    "arxiv_id": "2401.06468",
    "title": "Adapting Large Language Models for Document-Level Machine Translation",
    "url": "http://arxiv.org/abs/2401.06468v1",
    "abstract": "Large language models (LLMs) have significantly advanced various natural\nlanguage processing (NLP) tasks. Recent research indicates that\nmoderately-sized LLMs often outperform larger ones after task-specific\nfine-tuning. This study focuses on adapting LLMs for document-level machine\ntranslation (DocMT) for specific language pairs. We first investigate the\nimpact of prompt strategies on translation performance and then conduct\nextensive experiments using two fine-tuning methods, three LLM backbones, and\n18 translation tasks across nine language pairs. Our results show that\nspecialized models can sometimes surpass GPT-4 in translation performance but\nstill face issues like off-target translation due to error propagation in\ndecoding. We provide an in-depth analysis of these LLMs tailored for DocMT,\nexamining translation errors, discourse phenomena, strategies for training and\ninference, the data efficiency of parallel documents, recent test set\nevaluations, and zero-shot crosslingual transfer. Our findings highlight the\nstrengths and limitations of LLM-based DocMT models and provide a foundation\nfor future research."
  },
  {
    "arxiv_id": "2401.06311",
    "title": "MuGI: Enhancing Information Retrieval through Multi-Text Generation Intergration with Large Language Models",
    "url": "http://arxiv.org/abs/2401.06311v1",
    "abstract": "Large Language Models (LLMs) are foundational in language technologies,\nparticularly in information retrieval (IR). Previous studies have utilized LLMs\nfor query expansion, achieving notable improvements in IR. In this paper, we\nthoroughly explore the best practice of leveraging LLMs for query expansion. To\nthis end, we introduce a training-free, straightforward yet effective framework\ncalled Multi-Text Generation Integration (\\textsc{MuGI}). It leverages LLMs to\ngenerate multiple pseudo-references, integrating them with queries to enhance\nboth sparse and dense retrievers. Our empirical findings reveal that: (1)\nIncreasing the number of samples from LLMs benefits IR systems; (2) A balance\nbetween the query and pseudo-documents, and an effective integration strategy,\nis critical for high performance; (3) Contextual information from LLMs is\nessential, even boost a 23M model to outperform a 7B baseline model; (4) Pseudo\nrelevance feedback can further calibrate queries for improved performance; and\n(5) Query expansion is widely applicable and versatile, consistently enhancing\nmodels ranging from 23M to 7B parameters. Our code and all generated references\nare made available at \\url{https://github.com/lezhang7/Retrieval_MuGI}"
  },
  {
    "arxiv_id": "2401.08315",
    "title": "Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening",
    "url": "http://arxiv.org/abs/2401.08315v1",
    "abstract": "The automation of resume screening is a crucial aspect of the recruitment\nprocess in organizations. Automated resume screening systems often encompass a\nrange of natural language processing (NLP) tasks. This paper introduces a novel\nLarge Language Models (LLMs) based agent framework for resume screening, aimed\nat enhancing efficiency and time management in recruitment processes. Our\nframework is distinct in its ability to efficiently summarize and grade each\nresume from a large dataset. Moreover, it utilizes LLM agents for\ndecision-making. To evaluate our framework, we constructed a dataset from\nactual resumes and simulated a resume screening process. Subsequently, the\noutcomes of the simulation experiment were compared and subjected to detailed\nanalysis. The results demonstrate that our automated resume screening framework\nis 11 times faster than traditional manual methods. Furthermore, by fine-tuning\nthe LLMs, we observed a significant improvement in the F1 score, reaching\n87.73\\%, during the resume sentence classification phase. In the resume\nsummarization and grading phase, our fine-tuned model surpassed the baseline\nperformance of the GPT-3.5 model. Analysis of the decision-making efficacy of\nthe LLM agents in the final offer stage further underscores the potential of\nLLM agents in transforming resume screening processes."
  },
  {
    "arxiv_id": "2401.07872",
    "title": "The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey",
    "url": "http://arxiv.org/abs/2401.07872v1",
    "abstract": "The advent of Large Language Models (LLMs) represents a notable breakthrough\nin Natural Language Processing (NLP), contributing to substantial progress in\nboth text comprehension and generation. However, amidst these advancements, it\nis noteworthy that LLMs often face a limitation in terms of context length\nextrapolation. Understanding and extending the context length for LLMs is\ncrucial in enhancing their performance across various NLP applications. In this\nsurvey paper, we delve into the multifaceted aspects of exploring why it is\nessential, and the potential transformations that superior techniques could\nbring to NLP applications. We study the inherent challenges associated with\nextending context length and present an organized overview of the existing\nstrategies employed by researchers. Additionally, we discuss the intricacies of\nevaluating context extension techniques and highlight the open challenges that\nresearchers face in this domain. Furthermore, we explore whether there is a\nconsensus within the research community regarding evaluation standards and\nidentify areas where further agreement is needed. This comprehensive survey\naims to serve as a valuable resource for researchers, guiding them through the\nnuances of context length extension techniques and fostering discussions on\nfuture advancements in this evolving field."
  },
  {
    "arxiv_id": "2401.07760",
    "title": "On the importance of Data Scale in Pretraining Arabic Language Models",
    "url": "http://arxiv.org/abs/2401.07760v1",
    "abstract": "Pretraining monolingual language models have been proven to be vital for\nperformance in Arabic Natural Language Processing (NLP) tasks. In this paper,\nwe conduct a comprehensive study on the role of data in Arabic Pretrained\nLanguage Models (PLMs). More precisely, we reassess the performance of a suite\nof state-of-the-art Arabic PLMs by retraining them on massive-scale,\nhigh-quality Arabic corpora. We have significantly improved the performance of\nthe leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on\nthe ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in\ntheir respective model categories. In addition, our analysis strongly suggests\nthat pretraining data by far is the primary contributor to performance,\nsurpassing other factors. Our models and source code are publicly available at\nhttps://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch."
  },
  {
    "arxiv_id": "2401.07510",
    "title": "Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering",
    "url": "http://arxiv.org/abs/2401.07510v1",
    "abstract": "ChatGPT explores a strategic blueprint of question answering (QA) in\ndelivering medical diagnosis, treatment recommendations, and other healthcare\nsupport. This is achieved through the increasing incorporation of medical\ndomain data via natural language processing (NLP) and multimodal paradigms. By\ntransitioning the distribution of text, images, videos, and other modalities\nfrom the general domain to the medical domain, these techniques have expedited\nthe progress of medical domain question answering (MDQA). They bridge the gap\nbetween human natural language and sophisticated medical domain knowledge or\nexpert manual annotations, handling large-scale, diverse, unbalanced, or even\nunlabeled data analysis scenarios in medical contexts. Central to our focus is\nthe utilizing of language models and multimodal paradigms for medical question\nanswering, aiming to guide the research community in selecting appropriate\nmechanisms for their specific medical research requirements. Specialized tasks\nsuch as unimodal-related question answering, reading comprehension, reasoning,\ndiagnosis, relation extraction, probability modeling, and others, as well as\nmultimodal-related tasks like vision question answering, image caption,\ncross-modal retrieval, report summarization, and generation, are discussed in\ndetail. Each section delves into the intricate specifics of the respective\nmethod under consideration. This paper highlights the structures and\nadvancements of medical domain explorations against general domain methods,\nemphasizing their applications across different tasks and datasets. It also\noutlines current challenges and opportunities for future medical domain\nresearch, paving the way for continued innovation and application in this\nrapidly evolving field."
  },
  {
    "arxiv_id": "2401.07414",
    "title": "Leveraging the power of transformers for guilt detection in text",
    "url": "http://arxiv.org/abs/2401.07414v1",
    "abstract": "In recent years, language models and deep learning techniques have\nrevolutionized natural language processing tasks, including emotion detection.\nHowever, the specific emotion of guilt has received limited attention in this\nfield. In this research, we explore the applicability of three\ntransformer-based language models for detecting guilt in text and compare their\nperformance for general emotion detection and guilt detection. Our proposed\nmodel outformed BERT and RoBERTa models by two and one points respectively.\nAdditionally, we analyze the challenges in developing accurate guilt-detection\nmodels and evaluate our model's effectiveness in detecting related emotions\nlike \"shame\" through qualitative analysis of results."
  },
  {
    "arxiv_id": "2401.09232",
    "title": "Dynamic Relation Transformer for Contextual Text Block Detection",
    "url": "http://arxiv.org/abs/2401.09232v1",
    "abstract": "Contextual Text Block Detection (CTBD) is the task of identifying coherent\ntext blocks within the complexity of natural scenes. Previous methodologies\nhave treated CTBD as either a visual relation extraction challenge within\ncomputer vision or as a sequence modeling problem from the perspective of\nnatural language processing. We introduce a new framework that frames CTBD as a\ngraph generation problem. This methodology consists of two essential\nprocedures: identifying individual text units as graph nodes and discerning the\nsequential reading order relationships among these units as graph edges.\nLeveraging the cutting-edge capabilities of DQ-DETR for node detection, our\nframework innovates further by integrating a novel mechanism, a Dynamic\nRelation Transformer (DRFormer), dedicated to edge generation. DRFormer\nincorporates a dual interactive transformer decoder that deftly manages a\ndynamic graph structure refinement process. Through this iterative process, the\nmodel systematically enhances the graph's fidelity, ultimately resulting in\nimproved precision in detecting contextual text blocks. Comprehensive\nexperimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Context\ndatasets substantiate that our method achieves state-of-the-art results,\nunderscoring the effectiveness and potential of our graph generation framework\nin advancing the field of CTBD."
  },
  {
    "arxiv_id": "2401.09042",
    "title": "LLMs for Relational Reasoning: How Far are We?",
    "url": "http://arxiv.org/abs/2401.09042v1",
    "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural\nlanguage processing, software engineering, etc.) by achieving state-of-the-art\nperformance on extensive downstream tasks. Aiming to achieve robust and general\nartificial intelligence, there has been a surge of interest in investigating\nthe reasoning ability of the LLMs. Whereas the textual and numerical reasoning\nbenchmarks adopted by previous works are rather shallow and simple, it is hard\nto conclude that the LLMs possess strong reasoning ability by merely achieving\npositive results on these benchmarks. Recent efforts have demonstrated that the\nLLMs are poor at solving sequential decision-making problems that require\ncommon-sense planning by evaluating their performance on the reinforcement\nlearning benchmarks. In this work, we conduct an in-depth assessment of several\nstate-of-the-art LLMs' reasoning ability based on the inductive logic\nprogramming (ILP) benchmark, which is broadly recognized as a representative\nand challenging measurement for evaluating logic program induction/synthesis\nsystems as it requires inducing strict cause-effect logic to achieve robust\ndeduction on independent and identically distributed (IID) and\nout-of-distribution (OOD) test samples. Our evaluations illustrate that\ncompared with the neural program induction systems which are much smaller in\nmodel size, the state-of-the-art LLMs are much poorer in terms of reasoning\nability by achieving much lower performance and generalization using either\nnatural language prompting or truth-value matrix prompting."
  },
  {
    "arxiv_id": "2401.08508",
    "title": "EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis",
    "url": "http://arxiv.org/abs/2401.08508v1",
    "abstract": "Sentiment analysis and emotion detection are important research topics in\nnatural language processing (NLP) and benefit many downstream tasks. With the\nwidespread application of LLMs, researchers have started exploring the\napplication of LLMs based on instruction-tuning in the field of sentiment\nanalysis. However, these models only focus on single aspects of affective\nclassification tasks (e.g. sentimental polarity or categorical emotions), and\noverlook the regression tasks (e.g. sentiment strength or emotion intensity),\nwhich leads to poor performance in downstream tasks. The main reason is the\nlack of comprehensive affective instruction tuning datasets and evaluation\nbenchmarks, which cover various affective classification and regression tasks.\nMoreover, although emotional information is useful for downstream tasks,\nexisting downstream datasets lack high-quality and comprehensive affective\nannotations. In this paper, we propose EmoLLMs, the first series of\nopen-sourced instruction-following LLMs for comprehensive affective analysis\nbased on fine-tuning various LLMs with instruction data, the first multi-task\naffective analysis instruction dataset (AAID) with 234K data samples based on\nvarious classification and regression tasks to support LLM instruction tuning,\nand a comprehensive affective evaluation benchmark (AEB) with 14 tasks from\nvarious sources and domains to test the generalization ability of LLMs. We\npropose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various\naffective instruction tasks. We compare our model with a variety of LLMs on\nAEB, where our models outperform all other open-sourced LLMs, and surpass\nChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve\nthe ChatGPT-level and GPT-4-level generalization capabilities on affective\nanalysis tasks, and demonstrates our models can be used as affective annotation\ntools."
  },
  {
    "arxiv_id": "2401.08429",
    "title": "Machine Translation with Large Language Models: Prompt Engineering for Persian, English, and Russian Directions",
    "url": "http://arxiv.org/abs/2401.08429v1",
    "abstract": "Generative large language models (LLMs) have demonstrated exceptional\nproficiency in various natural language processing (NLP) tasks, including\nmachine translation, question answering, text summarization, and natural\nlanguage understanding.\n  To further enhance the performance of LLMs in machine translation, we\nconducted an investigation into two popular prompting methods and their\ncombination, focusing on cross-language combinations of Persian, English, and\nRussian. We employed n-shot feeding and tailored prompting frameworks. Our\nfindings indicate that multilingual LLMs like PaLM exhibit human-like machine\ntranslation outputs, enabling superior fine-tuning of desired translation\nnuances in accordance with style guidelines and linguistic considerations.\nThese models also excel in processing and applying prompts. However, the choice\nof language model, machine translation task, and the specific source and target\nlanguages necessitate certain considerations when adopting prompting frameworks\nand utilizing n-shot in-context learning.\n  Furthermore, we identified errors and limitations inherent in popular LLMs as\nmachine translation tools and categorized them based on various linguistic\nmetrics. This typology of errors provides valuable insights for utilizing LLMs\neffectively and offers methods for designing prompts for in-context learning.\nOur report aims to contribute to the advancement of machine translation with\nLLMs by improving both the accuracy and reliability of evaluation metrics."
  },
  {
    "arxiv_id": "2401.10034",
    "title": "Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap",
    "url": "http://arxiv.org/abs/2401.10034v1",
    "abstract": "Large language models (LLMs) have not only revolutionized natural language\nprocessing but also extended their prowess to various domains, marking a\nsignificant stride towards artificial general intelligence. The interplay\nbetween LLMs and evolutionary algorithms (EAs), despite differing in objectives\nand methodologies, share a common pursuit of applicability in complex problems.\nMeanwhile, EA can provide an optimization framework for LLM's further\nenhancement under black-box settings, empowering LLM with flexible global\nsearch capacities. On the other hand, the abundant domain knowledge inherent in\nLLMs could enable EA to conduct more intelligent searches. Furthermore, the\ntext processing and generative capabilities of LLMs would aid in deploying EAs\nacross a wide range of tasks. Based on these complementary advantages, this\npaper provides a thorough review and a forward-looking roadmap, categorizing\nthe reciprocal inspiration into two main avenues: LLM-enhanced EA and\nEA-enhanced LLM. Some integrated synergy methods are further introduced to\nexemplify the complementarity between LLMs and EAs in diverse scenarios,\nincluding code generation, software engineering, neural architecture search,\nand various generation tasks. As the first comprehensive review focused on the\nEA research in the era of LLMs, this paper provides a foundational stepping\nstone for understanding the collaborative potential of LLMs and EAs. The\nidentified challenges and future directions offer guidance for researchers and\npractitioners to unlock the full potential of this innovative collaboration in\npropelling advancements in optimization and artificial intelligence. We have\ncreated a GitHub repository to index the relevant papers:\nhttps://github.com/wuxingyu-ai/LLM4EC."
  },
  {
    "arxiv_id": "2401.09972",
    "title": "Better Explain Transformers by Illuminating Important Information",
    "url": "http://arxiv.org/abs/2401.09972v2",
    "abstract": "Transformer-based models excel in various natural language processing (NLP)\ntasks, attracting countless efforts to explain their inner workings. Prior\nmethods explain Transformers by focusing on the raw gradient and attention as\ntoken attribution scores, where non-relevant information is often considered\nduring explanation computation, resulting in confusing results. In this work,\nwe propose highlighting the important information and eliminating irrelevant\ninformation by a refined information flow on top of the layer-wise relevance\npropagation (LRP) method. Specifically, we consider identifying syntactic and\npositional heads as important attention heads and focus on the relevance\nobtained from these important heads. Experimental results demonstrate that\nirrelevant information does distort output attribution scores and then should\nbe masked during explanation computation. Compared to eight baselines on both\nclassification and question-answering datasets, our method consistently\noutperforms with over 3\\% to 33\\% improvement on explanation metrics, providing\nsuperior explanation performance. Our anonymous code repository is available\nat: https://github.com/LinxinS97/Mask-LRP"
  },
  {
    "arxiv_id": "2401.09890",
    "title": "A Survey on Hardware Accelerators for Large Language Models",
    "url": "http://arxiv.org/abs/2401.09890v1",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. As the demand for more sophisticated\nLLMs continues to grow, there is a pressing need to address the computational\nchallenges associated with their scale and complexity. This paper presents a\ncomprehensive survey on hardware accelerators designed to enhance the\nperformance and energy efficiency of Large Language Models. By examining a\ndiverse range of accelerators, including GPUs, FPGAs, and custom-designed\narchitectures, we explore the landscape of hardware solutions tailored to meet\nthe unique computational demands of LLMs. The survey encompasses an in-depth\nanalysis of architecture, performance metrics, and energy efficiency\nconsiderations, providing valuable insights for researchers, engineers, and\ndecision-makers aiming to optimize the deployment of LLMs in real-world\napplications."
  },
  {
    "arxiv_id": "2401.09615",
    "title": "Learning Shortcuts: On the Misleading Promise of NLU in Language Models",
    "url": "http://arxiv.org/abs/2401.09615v1",
    "abstract": "The advent of large language models (LLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found that LLMs often resort to shortcuts when performing tasks,\ncreating an illusion of enhanced performance while lacking generalizability in\ntheir decision rules. This phenomenon introduces challenges in accurately\nassessing natural language understanding in LLMs. Our paper provides a concise\nsurvey of relevant research in this area and puts forth a perspective on the\nimplications of shortcut learning in the evaluation of language models,\nspecifically for NLU tasks. This paper urges more research efforts to be put\ntowards deepening our comprehension of shortcut learning, contributing to the\ndevelopment of more robust language models, and raising the standards of NLU\nevaluation in real-world scenarios."
  },
  {
    "arxiv_id": "2401.10716",
    "title": "Structured Code Representations Enable Data-Efficient Adaptation of Code Language Models",
    "url": "http://arxiv.org/abs/2401.10716v1",
    "abstract": "Current language models tailored for code tasks often adopt the\npre-training-then-fine-tuning paradigm from natural language processing,\nmodeling source code as plain text. This approach, however, overlooks the\nunambiguous structures inherent in programming languages. In this work, we\nexplore data-efficient adaptation of pre-trained code models by further\npre-training and fine-tuning them with program structures. Specifically, we\nrepresent programs as parse trees -- also known as concrete syntax trees (CSTs)\n-- and adapt pre-trained models on serialized CSTs. Although the models that we\nadapt have been pre-trained only on the surface form of programs, we find that\na small amount of continual pre-training and fine-tuning on CSTs without\nchanging the model architecture yields improvements over the baseline approach\nacross various code tasks. The improvements are found to be particularly\nsignificant when there are limited training examples, demonstrating the\neffectiveness of integrating program structures with plain-text representation\neven when working with backbone models that have not been pre-trained with\nstructures."
  },
  {
    "arxiv_id": "2401.10653",
    "title": "Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech Detection",
    "url": "http://arxiv.org/abs/2401.10653v1",
    "abstract": "With the recent surge and exponential growth of social media usage,\nscrutinizing social media content for the presence of any hateful content is of\nutmost importance. Researchers have been diligently working since the past\ndecade on distinguishing between content that promotes hatred and content that\ndoes not. Traditionally, the main focus has been on analyzing textual content.\nHowever, recent research attempts have also commenced into the identification\nof audio-based content. Nevertheless, studies have shown that relying solely on\naudio or text-based content may be ineffective, as recent upsurge indicates\nthat individuals often employ sarcasm in their speech and writing. To overcome\nthese challenges, we present an approach to identify whether a speech promotes\nhate or not utilizing both audio and textual representations. Our methodology\nis based on the Transformer framework that incorporates both audio and text\nsampling, accompanied by our very own layer called \"Attentive Fusion\". The\nresults of our study surpassed previous state-of-the-art techniques, achieving\nan impressive macro F1 score of 0.927 on the Test Set."
  },
  {
    "arxiv_id": "2401.12078",
    "title": "Temporal Blind Spots in Large Language Models",
    "url": "http://arxiv.org/abs/2401.12078v1",
    "abstract": "Large language models (LLMs) have recently gained significant attention due\nto their unparalleled ability to perform various natural language processing\ntasks. These models, benefiting from their advanced natural language\nunderstanding capabilities, have demonstrated impressive zero-shot performance.\nHowever, the pre-training data utilized in LLMs is often confined to a specific\ncorpus, resulting in inherent freshness and temporal scope limitations.\nConsequently, this raises concerns regarding the effectiveness of LLMs for\ntasks involving temporal intents. In this study, we aim to investigate the\nunderlying limitations of general-purpose LLMs when deployed for tasks that\nrequire a temporal understanding. We pay particular attention to handling\nfactual temporal knowledge through three popular temporal QA datasets.\nSpecifically, we observe low performance on detailed questions about the past\nand, surprisingly, for rather new information. In manual and automatic testing,\nwe find multiple temporal errors and characterize the conditions under which QA\nperformance deteriorates. Our analysis contributes to understanding LLM\nlimitations and offers valuable insights into developing future models that can\nbetter cater to the demands of temporally-oriented tasks. The code is\navailable\\footnote{https://github.com/jwallat/temporalblindspots}."
  },
  {
    "arxiv_id": "2401.11641",
    "title": "Revolutionizing Finance with LLMs: An Overview of Applications and Insights",
    "url": "http://arxiv.org/abs/2401.11641v1",
    "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seen\nconsiderable advancements and have been applied in diverse fields. Built on the\nTransformer architecture, these models are trained on extensive datasets,\nenabling them to understand and generate human language effectively. In the\nfinancial domain, the deployment of LLMs is gaining momentum. These models are\nbeing utilized for automating financial report generation, forecasting market\ntrends, analyzing investor sentiment, and offering personalized financial\nadvice. Leveraging their natural language processing capabilities, LLMs can\ndistill key insights from vast financial data, aiding institutions in making\ninformed investment choices and enhancing both operational efficiency and\ncustomer satisfaction. In this study, we provide a comprehensive overview of\nthe emerging integration of LLMs into various financial tasks. Additionally, we\nconducted holistic tests on multiple financial tasks through the combination of\nnatural language instructions. Our findings show that GPT-4 effectively follow\nprompt instructions across various financial tasks. This survey and evaluation\nof LLMs in the financial domain aim to deepen the understanding of LLMs'\ncurrent role in finance for both financial practitioners and LLM researchers,\nidentify new research and application prospects, and highlight how these\ntechnologies can be leveraged to solve practical challenges in the finance\nindustry."
  },
  {
    "arxiv_id": "2401.11500",
    "title": "Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis",
    "url": "http://arxiv.org/abs/2401.11500v1",
    "abstract": "This paper presents an innovative approach to integrating Large Language\nModels (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for\nprecise color synthesis in automation systems. We propose a novel framework\nthat employs fine-tuned LLMs to interpret natural language commands and convert\nthem into specific operational instructions for EHD pump control. This approach\naims to enhance user interaction with complex hardware systems, making it more\nintuitive and efficient. The methodology involves four key steps: fine-tuning\nthe language model with a dataset of color specifications and corresponding\nArduino code, developing a natural language processing interface, translating\nuser inputs into executable Arduino code, and controlling EHD pumps for\naccurate color mixing. Conceptual experiment results, based on theoretical\nassumptions, indicate a high potential for accurate color synthesis, efficient\nlanguage model interpretation, and reliable EHD pump operation. This research\nextends the application of LLMs beyond text-based tasks, demonstrating their\npotential in industrial automation and control systems. While highlighting the\nlimitations and the need for real-world testing, this study opens new avenues\nfor AI applications in physical system control and sets a foundation for future\nadvancements in AI-driven automation technologies."
  },
  {
    "arxiv_id": "2401.11459",
    "title": "AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology",
    "url": "http://arxiv.org/abs/2401.11459v1",
    "abstract": "Large language models (LLMs) with Transformer architectures have become\nphenomenal in natural language processing, multimodal generative artificial\nintelligence, and agent-oriented artificial intelligence. The self-attention\nmodule is the most dominating sub-structure inside Transformer-based LLMs.\nComputation using general-purpose graphics processing units (GPUs) inflicts\nreckless demand for I/O bandwidth for transferring intermediate calculation\nresults between memories and processing units. To tackle this challenge, this\nwork develops a fully customized vanilla self-attention accelerator,\nAttentionLego, as the basic building block for constructing spatially\nexpandable LLM processors. AttentionLego provides basic implementation with\nfully-customized digital logic incorporating Processing-In-Memory (PIM)\ntechnology. It is based on PIM-based matrix-vector multiplication and look-up\ntable-based Softmax design. The open-source code is available online:\nhttps://bonany.cc/attentionleg."
  },
  {
    "arxiv_id": "2401.12874",
    "title": "From Understanding to Utilization: A Survey on Explainability for Large Language Models",
    "url": "http://arxiv.org/abs/2401.12874v1",
    "abstract": "Explainability for Large Language Models (LLMs) is a critical yet challenging\naspect of natural language processing. As LLMs are increasingly integral to\ndiverse applications, their \"black-box\" nature sparks significant concerns\nregarding transparency and ethical use. This survey underscores the imperative\nfor increased explainability in LLMs, delving into both the research on\nexplainability and the various methodologies and tasks that utilize an\nunderstanding of these models. Our focus is primarily on pre-trained\nTransformer-based LLMs, such as LLaMA family, which pose distinctive\ninterpretability challenges due to their scale and complexity. In terms of\nexisting methods, we classify them into local and global analyses, based on\ntheir explanatory objectives. When considering the utilization of\nexplainability, we explore several compelling methods that concentrate on model\nediting, control generation, and model enhancement. Additionally, we examine\nrepresentative evaluation metrics and datasets, elucidating their advantages\nand limitations. Our goal is to reconcile theoretical and empirical\nunderstanding with practical implementation, proposing exciting avenues for\nexplanatory techniques and their applications in the LLMs era."
  },
  {
    "arxiv_id": "2401.12794",
    "title": "Benchmarking LLMs via Uncertainty Quantification",
    "url": "http://arxiv.org/abs/2401.12794v1",
    "abstract": "The proliferation of open-source Large Language Models (LLMs) from various\ninstitutions has highlighted the urgent need for comprehensive evaluation\nmethods. However, current evaluation platforms, such as the widely recognized\nHuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,\nwhich is vital for thoroughly assessing LLMs. To bridge this gap, we introduce\na new benchmarking approach for LLMs that integrates uncertainty\nquantification. Our examination involves nine LLMs (LLM series) spanning five\nrepresentative natural language processing tasks. Our findings reveal that: I)\nLLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs\nmay display greater uncertainty compared to their smaller counterparts; and\nIII) Instruction-finetuning tends to increase the uncertainty of LLMs. These\nresults underscore the significance of incorporating uncertainty in the\nevaluation of LLMs."
  },
  {
    "arxiv_id": "2401.12492",
    "title": "Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?",
    "url": "http://arxiv.org/abs/2401.12492v1",
    "abstract": "Pre-trained language models consider the context of neighboring words and\ndocuments but lack any author context of the human generating the text.\nHowever, language depends on the author's states, traits, social, situational,\nand environmental attributes, collectively referred to as human context (Soni\net al., 2024). Human-centered natural language processing requires\nincorporating human context into language models. Currently, two methods exist:\npre-training with 1) group-wise attributes (e.g., over-45-year-olds) or 2)\nindividual traits. Group attributes are simple but coarse -- not all\n45-year-olds write the same way -- while individual traits allow for more\npersonalized representations, but require more complex modeling and data. It is\nunclear which approach benefits what tasks. We compare pre-training models with\nhuman context via 1) group attributes, 2) individual users, and 3) a combined\napproach on five user- and document-level tasks. Our results show that there is\nno best approach, but that human-centered language modeling holds avenues for\ndifferent methods."
  },
  {
    "arxiv_id": "2401.12491",
    "title": "Assessing and Understanding Creativity in Large Language Models",
    "url": "http://arxiv.org/abs/2401.12491v1",
    "abstract": "In the field of natural language processing, the rapid development of large\nlanguage model (LLM) has attracted more and more attention. LLMs have shown a\nhigh level of creativity in various tasks, but the methods for assessing such\ncreativity are inadequate. The assessment of LLM creativity needs to consider\ndifferences from humans, requiring multi-dimensional measurement while\nbalancing accuracy and efficiency. This paper aims to establish an efficient\nframework for assessing the level of creativity in LLMs. By adapting the\nmodified Torrance Tests of Creative Thinking, the research evaluates the\ncreative performance of various LLMs across 7 tasks, emphasizing 4 criteria\nincluding Fluency, Flexibility, Originality, and Elaboration. In this context,\nwe develop a comprehensive dataset of 700 questions for testing and an\nLLM-based evaluation method. In addition, this study presents a novel analysis\nof LLMs' responses to diverse prompts and role-play situations. We found that\nthe creativity of LLMs primarily falls short in originality, while excelling in\nelaboration. Besides, the use of prompts and the role-play settings of the\nmodel significantly influence creativity. Additionally, the experimental\nresults also indicate that collaboration among multiple LLMs can enhance\noriginality. Notably, our findings reveal a consensus between human evaluations\nand LLMs regarding the personality traits that influence creativity. The\nfindings underscore the significant impact of LLM design on creativity and\nbridges artificial intelligence and human creativity, offering insights into\nLLMs' creativity and potential applications."
  },
  {
    "arxiv_id": "2401.13504",
    "title": "Research about the Ability of LLM in the Tamper-Detection Area",
    "url": "http://arxiv.org/abs/2401.13504v1",
    "abstract": "In recent years, particularly since the early 2020s, Large Language Models\n(LLMs) have emerged as the most powerful AI tools in addressing a diverse range\nof challenges, from natural language processing to complex problem-solving in\nvarious domains. In the field of tamper detection, LLMs are capable of\nidentifying basic tampering activities.To assess the capabilities of LLMs in\nmore specialized domains, we have collected five different LLMs developed by\nvarious companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. This\ndiverse range of models allows for a comprehensive evaluation of their\nperformance in detecting sophisticated tampering instances.We devised two\ndomains of detection: AI-Generated Content (AIGC) detection and manipulation\ndetection. AIGC detection aims to test the ability to distinguish whether an\nimage is real or AI-generated. Manipulation detection, on the other hand,\nfocuses on identifying tampered images. According to our experiments, most LLMs\ncan identify composite pictures that are inconsistent with logic, and only more\npowerful LLMs can distinguish logical, but visible signs of tampering to the\nhuman eye. All of the LLMs can't identify carefully forged images and very\nrealistic images generated by AI. In the area of tamper detection, LLMs still\nhave a long way to go, particularly in reliably identifying highly\nsophisticated forgeries and AI-generated images that closely mimic reality."
  },
  {
    "arxiv_id": "2401.13303",
    "title": "MaLA-500: Massive Language Adaptation of Large Language Models",
    "url": "http://arxiv.org/abs/2401.13303v1",
    "abstract": "Large language models (LLMs) have advanced the state of the art in natural\nlanguage processing. However, their predominant design for English or a limited\nset of languages creates a substantial gap in their effectiveness for\nlow-resource languages. To bridge this gap, we introduce MaLA-500, a novel\nlarge language model designed to cover an extensive range of 534 languages. To\ntrain MaLA-500, we employ vocabulary extension and continued pretraining on\nLLaMA 2 with Glot500-c. Our intrinsic evaluation demonstrates that MaLA-500 is\nbetter at predicting the given texts of low-resource languages than existing\nmultilingual LLMs. Moreover, the extrinsic evaluation of in-context learning\nshows that MaLA-500 outperforms previous LLMs on SIB200 and Taxi1500 by a\nsignificant margin, i.e., 11.68% and 4.82% marco-average accuracy across\nlanguages. We release MaLA-500 at https://huggingface.co/MaLA-LM"
  },
  {
    "arxiv_id": "2401.13266",
    "title": "SpecLLM: Exploring Generation and Review of VLSI Design Specification with Large Language Model",
    "url": "http://arxiv.org/abs/2401.13266v1",
    "abstract": "The development of architecture specifications is an initial and fundamental\nstage of the integrated circuit (IC) design process. Traditionally,\narchitecture specifications are crafted by experienced chip architects, a\nprocess that is not only time-consuming but also error-prone. Mistakes in these\nspecifications may significantly affect subsequent stages of chip design.\nDespite the presence of advanced electronic design automation (EDA) tools,\neffective solutions to these specification-related challenges remain scarce.\nSince writing architecture specifications is naturally a natural language\nprocessing (NLP) task, this paper pioneers the automation of architecture\nspecification development with the advanced capabilities of large language\nmodels (LLMs). Leveraging our definition and dataset, we explore the\napplication of LLMs in two key aspects of architecture specification\ndevelopment: (1) Generating architecture specifications, which includes both\nwriting specifications from scratch and converting RTL code into detailed\nspecifications. (2) Reviewing existing architecture specifications. We got\npromising results indicating that LLMs may revolutionize how these critical\nspecification documents are developed in IC design nowadays. By reducing the\neffort required, LLMs open up new possibilities for efficiency and accuracy in\nthis crucial aspect of chip design."
  },
  {
    "arxiv_id": "2401.13229",
    "title": "From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning",
    "url": "http://arxiv.org/abs/2401.13229v1",
    "abstract": "A major challenge in Natural Language Processing is obtaining annotated data\nfor supervised learning. An option is the use of crowdsourcing platforms for\ndata annotation. However, crowdsourcing introduces issues related to the\nannotator's experience, consistency, and biases. An alternative is to use\nzero-shot methods, which in turn have limitations compared to their few-shot or\nfully supervised counterparts. Recent advancements driven by large language\nmodels show potential, but struggle to adapt to specialized domains with\nseverely limited data. The most common approaches therefore involve the human\nitself randomly annotating a set of datapoints to build initial datasets. But\nrandomly sampling data to be annotated is often inefficient as it ignores the\ncharacteristics of the data and the specific needs of the model. The situation\nworsens when working with imbalanced datasets, as random sampling tends to\nheavily bias towards the majority classes, leading to excessive annotated data.\nTo address these issues, this paper contributes an automatic and informed data\nselection architecture to build a small dataset for few-shot learning. Our\nproposal minimizes the quantity and maximizes diversity of data selected for\nhuman annotation, while improving model performance."
  },
  {
    "arxiv_id": "2401.14373",
    "title": "TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation",
    "url": "http://arxiv.org/abs/2401.14373v1",
    "abstract": "The recent advances in natural language processing have predominantly favored\nwell-resourced English-centric models, resulting in a significant gap with\nlow-resource languages. In this work, we introduce the language model TURNA,\nwhich is developed for the low-resource language Turkish and is capable of both\nnatural language understanding and generation tasks. TURNA is pretrained with\nan encoder-decoder architecture based on the unified framework UL2 with a\ndiverse corpus that we specifically curated for this purpose. We evaluated\nTURNA with three generation tasks and five understanding tasks for Turkish. The\nresults show that TURNA outperforms several multilingual models in both\nunderstanding and generation tasks, and competes with monolingual Turkish\nmodels in understanding tasks. TURNA is made available at\nhttps://huggingface.co/boun-tabi-LMG/TURNA ."
  },
  {
    "arxiv_id": "2401.14242",
    "title": "Improving Natural Language Capability of Code Large Language Model",
    "url": "http://arxiv.org/abs/2401.14242v1",
    "abstract": "Code large language models (Code LLMs) have demonstrated remarkable\nperformance in code generation. Nonetheless, most existing works focus on\nboosting code LLMs from the perspective of programming capabilities, while\ntheir natural language capabilities receive less attention. To fill this gap,\nwe thus propose a novel framework, comprising two modules: AttentionExtractor,\nwhich is responsible for extracting key phrases from the user's natural\nlanguage requirements, and AttentionCoder, which leverages these extracted\nphrases to generate target code to solve the requirement. This framework\npioneers an innovative idea by seamlessly integrating code LLMs with\ntraditional natural language processing tools. To validate the effectiveness of\nthe framework, we craft a new code generation benchmark, called MultiNL-H,\ncovering five natural languages. Extensive experimental results demonstrate the\neffectiveness of our proposed framework."
  },
  {
    "arxiv_id": "2401.14192",
    "title": "How Can Large Language Models Understand Spatial-Temporal Data?",
    "url": "http://arxiv.org/abs/2401.14192v1",
    "abstract": "While Large Language Models (LLMs) dominate tasks like natural language\nprocessing and computer vision, harnessing their power for spatial-temporal\nforecasting remains challenging. The disparity between sequential text and\ncomplex spatial-temporal data hinders this application. To address this issue,\nthis paper introduces STG-LLM, an innovative approach empowering LLMs for\nspatial-temporal forecasting. We tackle the data mismatch by proposing: 1)\nSTG-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph\ndata into concise tokens capturing both spatial and temporal relationships; 2)\nSTG-Adapter: This minimalistic adapter, consisting of linear encoding and\ndecoding layers, bridges the gap between tokenized data and LLM comprehension.\nBy fine-tuning only a small set of parameters, it can effectively grasp the\nsemantics of tokens generated by STG-Tokenizer, while preserving the original\nnatural language understanding capabilities of LLMs. Extensive experiments on\ndiverse spatial-temporal benchmark datasets show that STG-LLM successfully\nunlocks LLM potential for spatial-temporal forecasting. Remarkably, our\napproach achieves competitive performance on par with dedicated SOTA methods."
  },
  {
    "arxiv_id": "2401.14040",
    "title": "(Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection",
    "url": "http://arxiv.org/abs/2401.14040v1",
    "abstract": "In the universe of Natural Language Processing, Transformer-based language\nmodels like BERT and (Chat)GPT have emerged as lexical superheroes with great\npower to solve open research problems. In this paper, we specifically focus on\nthe temporal problem of semantic change, and evaluate their ability to solve\ntwo diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and\nHistoWiC. In particular, we investigate the potential of a novel, off-the-shelf\ntechnology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a\nfamily of models that currently stand as the state-of-the-art for modeling\nsemantic change. Our experiments represent the first attempt to assess the use\nof (Chat)GPT for studying semantic change. Our results indicate that ChatGPT\nperforms significantly worse than the foundational GPT version. Furthermore,\nour results demonstrate that (Chat)GPT achieves slightly lower performance than\nBERT in detecting long-term changes but performs significantly worse in\ndetecting short-term changes."
  },
  {
    "arxiv_id": "2401.14021",
    "title": "Accelerating Retrieval-Augmented Language Model Serving with Speculation",
    "url": "http://arxiv.org/abs/2401.14021v1",
    "abstract": "Retrieval-augmented language models (RaLM) have demonstrated the potential to\nsolve knowledge-intensive natural language processing (NLP) tasks by combining\na non-parametric knowledge base with a parametric language model. Instead of\nfine-tuning a fully parametric model, RaLM excels at its low-cost adaptation to\nthe latest data and better source attribution mechanisms. Among various RaLM\napproaches, iterative RaLM delivers a better generation quality due to a more\nfrequent interaction between the retriever and the language model. Despite the\nbenefits, iterative RaLM usually encounters high overheads due to the frequent\nretrieval step. To this end, we propose RaLMSpec, a speculation-inspired\nframework that provides generic speed-up over iterative RaLM while preserving\nthe same model outputs through speculative retrieval and batched verification.\nBy further incorporating prefetching, optimal speculation stride scheduler, and\nasynchronous verification, RaLMSpec can automatically exploit the acceleration\npotential to the fullest. For naive iterative RaLM serving, extensive\nevaluations over three language models on four downstream QA datasets\ndemonstrate that RaLMSpec can achieve a speed-up ratio of 1.75-2.39x,\n1.04-1.39x, and 1.31-1.77x when the retriever is an exact dense retriever,\napproximate dense retriever, and sparse retriever respectively compared with\nthe baseline. For KNN-LM serving, RaLMSpec can achieve a speed-up ratio up to\n7.59x and 2.45x when the retriever is an exact dense retriever and approximate\ndense retriever, respectively, compared with the baseline."
  },
  {
    "arxiv_id": "2401.13924",
    "title": "ChatGPT and Human Synergy in Black-Box Testing: A Comparative Analysis",
    "url": "http://arxiv.org/abs/2401.13924v1",
    "abstract": "In recent years, large language models (LLMs), such as ChatGPT, have been\npivotal in advancing various artificial intelligence applications, including\nnatural language processing and software engineering. A promising yet\nunderexplored area is utilizing LLMs in software testing, particularly in\nblack-box testing. This paper explores the test cases devised by ChatGPT in\ncomparison to those created by human participants. In this study, ChatGPT\n(GPT-4) and four participants each created black-box test cases for three\napplications based on specifications written by the authors. The goal was to\nevaluate the real-world applicability of the proposed test cases, identify\npotential shortcomings, and comprehend how ChatGPT could enhance human testing\nstrategies. ChatGPT can generate test cases that generally match or slightly\nsurpass those created by human participants in terms of test viewpoint\ncoverage. Additionally, our experiments demonstrated that when ChatGPT\ncooperates with humans, it can cover considerably more test viewpoints than\neach can achieve alone, suggesting that collaboration between humans and\nChatGPT may be more effective than human pairs working together. Nevertheless,\nwe noticed that the test cases generated by ChatGPT have certain issues that\nrequire addressing before use."
  },
  {
    "arxiv_id": "2401.13802",
    "title": "Investigating the Efficacy of Large Language Models for Code Clone Detection",
    "url": "http://arxiv.org/abs/2401.13802v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in various\nnatural language processing and software engineering tasks, such as code\ngeneration. The LLMs are mainly utilized in the prompt-based zero/few-shot\nparadigm to guide the model in accomplishing the task. GPT-based models are one\nof the popular ones studied for tasks such as code comment generation or test\ngeneration. These tasks are `generative' tasks. However, there is limited\nresearch on the usage of LLMs for `non-generative' tasks such as classification\nusing the prompt-based paradigm. In this preliminary exploratory study, we\ninvestigated the applicability of LLMs for Code Clone Detection (CCD), a\nnon-generative task. By building a mono-lingual and cross-lingual CCD dataset\nderived from CodeNet, we first investigated two different prompts using ChatGPT\nto detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot\nsetting. We then conducted an analysis to understand the strengths and\nweaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language\nCCD attaining an F1-score of 0.877 and achieves comparable performance to fully\nfine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the\nprompt and the difficulty level of the problems has an impact on the\nperformance of ChatGPT. Finally we provide insights and future directions based\non our initial analysis"
  },
  {
    "arxiv_id": "2401.15024",
    "title": "SliceGPT: Compress Large Language Models by Deleting Rows and Columns",
    "url": "http://arxiv.org/abs/2401.15024v1",
    "abstract": "Large language models have become the cornerstone of natural language\nprocessing, but their use comes with substantial costs in terms of compute and\nmemory resources. Sparsification provides a solution to alleviate these\nresource constraints, and recent works have shown that trained models can be\nsparsified post-hoc. Existing sparsification techniques face challenges as they\nneed additional data structures and offer constrained speedup with current\nhardware. In this paper we present SliceGPT, a new post-training sparsification\nscheme which replaces each weight matrix with a smaller (dense) matrix,\nreducing the embedding dimension of the network. Through extensive\nexperimentation, we show that SliceGPT can remove up to 25% of the model\nparameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 models\nwhile maintaining 99%, 99% and 90% zero-shot task performance of the dense\nmodel respectively. Our sliced models run on fewer GPUs and run faster without\nany additional code optimization: on 24GB consumer GPUs we reduce the total\ncompute for inference on LLAMA2-70B to 64% of that of the dense model; on 40GB\nA100 GPUs we reduce it to 66%. We offer a new insight, computational invariance\nin transformer networks, which enables SliceGPT and we hope it will inspire and\nenable future avenues to reduce memory and computation demands for pre-trained\nmodels. Code is available at:\nhttps://github.com/microsoft/TransformerCompression"
  },
  {
    "arxiv_id": "2401.14856",
    "title": "Memory-Inspired Temporal Prompt Interaction for Text-Image Classification",
    "url": "http://arxiv.org/abs/2401.14856v1",
    "abstract": "In recent years, large-scale pre-trained multimodal models (LMM) generally\nemerge to integrate the vision and language modalities, achieving considerable\nsuccess in various natural language processing and computer vision tasks. The\ngrowing size of LMMs, however, results in a significant computational cost for\nfine-tuning these models for downstream tasks. Hence, prompt-based interaction\nstrategy is studied to align modalities more efficiently. In this contex, we\npropose a novel prompt-based multimodal interaction strategy inspired by human\nmemory strategy, namely Memory-Inspired Temporal Prompt Interaction (MITP). Our\nproposed method involves in two stages as in human memory strategy: the\nacquiring stage, and the consolidation and activation stage. We utilize\ntemporal prompts on intermediate layers to imitate the acquiring stage,\nleverage similarity-based prompt interaction to imitate memory consolidation,\nand employ prompt generation strategy to imitate memory activation. The main\nstrength of our paper is that we interact the prompt vectors on intermediate\nlayers to leverage sufficient information exchange between modalities, with\ncompressed trainable parameters and memory usage. We achieve competitive\nresults on several datasets with relatively small memory usage and 2.0M of\ntrainable parameters (about 1% of the pre-trained foundation model)."
  },
  {
    "arxiv_id": "2401.14845",
    "title": "Adaptive Point Transformer",
    "url": "http://arxiv.org/abs/2401.14845v1",
    "abstract": "The recent surge in 3D data acquisition has spurred the development of\ngeometric deep learning models for point cloud processing, boosted by the\nremarkable success of transformers in natural language processing. While point\ncloud transformers (PTs) have achieved impressive results recently, their\nquadratic scaling with respect to the point cloud size poses a significant\nscalability challenge for real-world applications. To address this issue, we\npropose the Adaptive Point Cloud Transformer (AdaPT), a standard PT model\naugmented by an adaptive token selection mechanism. AdaPT dynamically reduces\nthe number of tokens during inference, enabling efficient processing of large\npoint clouds. Furthermore, we introduce a budget mechanism to flexibly adjust\nthe computational cost of the model at inference time without the need for\nretraining or fine-tuning separate models. Our extensive experimental\nevaluation on point cloud classification tasks demonstrates that AdaPT\nsignificantly reduces computational complexity while maintaining competitive\naccuracy compared to standard PTs. The code for AdaPT is made publicly\navailable."
  },
  {
    "arxiv_id": "2401.14777",
    "title": "Large Language Model Adaptation for Financial Sentiment Analysis",
    "url": "http://arxiv.org/abs/2401.14777v1",
    "abstract": "Natural language processing (NLP) has recently gained relevance within\nfinancial institutions by providing highly valuable insights into companies and\nmarkets' financial documents. However, the landscape of the financial domain\npresents extra challenges for NLP, due to the complexity of the texts and the\nuse of specific terminology. Generalist language models tend to fall short in\ntasks specifically tailored for finance, even when using large language models\n(LLMs) with great natural language understanding and generative capabilities.\nThis paper presents a study on LLM adaptation methods targeted at the financial\ndomain and with high emphasis on financial sentiment analysis. To this purpose,\ntwo foundation models with less than 1.5B parameters have been adapted using a\nwide range of strategies. We show that through careful fine-tuning on both\nfinancial documents and instructions, these foundation models can be adapted to\nthe target domain. Moreover, we observe that small LLMs have comparable\nperformance to larger scale models, while being more efficient in terms of\nparameters and data. In addition to the models, we show how to generate\nartificial instructions through LLMs to augment the number of samples of the\ninstruction dataset."
  },
  {
    "arxiv_id": "2401.16176",
    "title": "A Survey on Structure-Preserving Graph Transformers",
    "url": "http://arxiv.org/abs/2401.16176v1",
    "abstract": "The transformer architecture has shown remarkable success in various domains,\nsuch as natural language processing and computer vision. When it comes to graph\nlearning, transformers are required not only to capture the interactions\nbetween pairs of nodes but also to preserve graph structures connoting the\nunderlying relations and proximity between them, showing the expressive power\nto capture different graph structures. Accordingly, various\nstructure-preserving graph transformers have been proposed and widely used for\nvarious tasks, such as graph-level tasks in bioinformatics and\nchemoinformatics. However, strategies related to graph structure preservation\nhave not been well organized and systematized in the literature. In this paper,\nwe provide a comprehensive overview of structure-preserving graph transformers\nand generalize these methods from the perspective of their design objective.\nFirst, we divide strategies into four main groups: node feature modulation,\ncontext node sampling, graph rewriting, and transformer architecture\nimprovements. We then further divide the strategies according to the coverage\nand goals of graph structure preservation. Furthermore, we also discuss\nchallenges and future directions for graph transformer models to preserve the\ngraph structure and understand the nature of graphs."
  },
  {
    "arxiv_id": "2401.15927",
    "title": "E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models",
    "url": "http://arxiv.org/abs/2401.15927v1",
    "abstract": "With the accelerating development of Large Language Models (LLMs), many LLMs\nare beginning to be used in the Chinese K-12 education domain. The integration\nof LLMs and education is getting closer and closer, however, there is currently\nno benchmark for evaluating LLMs that focuses on the Chinese K-12 education\ndomain. Therefore, there is an urgent need for a comprehensive natural language\nprocessing benchmark to accurately assess the capabilities of various LLMs in\nthe Chinese K-12 education domain. To address this, we introduce the E-EVAL,\nthe first comprehensive evaluation benchmark specifically designed for the\nChinese K-12 education field. The E-EVAL consists of 4,351 multiple-choice\nquestions at the primary, middle, and high school levels across a wide range of\nsubjects, including Chinese, English, Politics, History, Ethics, Physics,\nChemistry, Mathematics, and Geography. We conducted a comprehensive evaluation\nof E-EVAL on advanced LLMs, including both English-dominant and\nChinese-dominant models. Findings show that Chinese-dominant models perform\nwell compared to English-dominant models, with many scoring even above the GPT\n4.0. However, almost all models perform poorly in complex subjects such as\nmathematics. We also found that most Chinese-dominant LLMs did not achieve\nhigher scores at the primary school level compared to the middle school level.\nWe observe that the mastery of higher-order knowledge by the model does not\nnecessarily imply the mastery of lower-order knowledge as well. Additionally,\nthe experimental results indicate that the Chain of Thought (CoT) technique is\neffective only for the challenging science subjects, while Few-shot prompting\nis more beneficial for liberal arts subjects. With E-EVAL, we aim to analyze\nthe strengths and limitations of LLMs in educational applications, and to\ncontribute to the progress and development of Chinese K-12 education and LLMs."
  },
  {
    "arxiv_id": "2401.15861",
    "title": "DrBERT: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining",
    "url": "http://arxiv.org/abs/2401.15861v1",
    "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has\nrevolutionized the field of natural language processing through its exceptional\nperformance on numerous tasks. Yet, the majority of researchers have mainly\nconcentrated on enhancements related to the model structure, such as relative\nposition embedding and more efficient attention mechanisms. Others have delved\ninto pretraining tricks associated with Masked Language Modeling, including\nwhole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's\nencoder model for pretraining, proving to be highly effective. We argue that\nthe design and research around enhanced masked language modeling decoders have\nbeen underappreciated. In this paper, we propose several designs of enhanced\ndecoders and introduce BPDec (BERT Pretraining Decoder), a novel method for\nmodeling training. Typically, a pretrained BERT model is fine-tuned for\nspecific Natural Language Understanding (NLU) tasks. In our approach, we\nutilize the original BERT model as the encoder, making only changes to the\ndecoder without altering the encoder. This approach does not necessitate\nextensive modifications to the encoder architecture and can be seamlessly\nintegrated into existing fine-tuning pipelines and services, offering an\nefficient and effective enhancement strategy. Compared to other methods, while\nwe also incur a moderate training cost for the decoder during the pretraining\nprocess, our approach does not introduce additional training costs during the\nfine-tuning phase. We test multiple enhanced decoder structures after\npretraining and evaluate their performance on the GLUE tasks and SQuAD tasks.\nOur results demonstrate that BPDec, having only undergone subtle refinements to\nthe model structure during pretraining, significantly enhances model\nperformance without escalating the finetuning cost, inference time and serving\nbudget."
  },
  {
    "arxiv_id": "2401.15780",
    "title": "Fine-Tuned Large Language Models for Symptom Recognition from Spanish Clinical Text",
    "url": "http://arxiv.org/abs/2401.15780v1",
    "abstract": "The accurate recognition of symptoms in clinical reports is significantly\nimportant in the fields of healthcare and biomedical natural language\nprocessing. These entities serve as essential building blocks for clinical\ninformation extraction, enabling retrieval of critical medical insights from\nvast amounts of textual data. Furthermore, the ability to identify and\ncategorize these entities is fundamental for developing advanced clinical\ndecision support systems, aiding healthcare professionals in diagnosis and\ntreatment planning. In this study, we participated in SympTEMIST, a shared task\non the detection of symptoms, signs and findings in Spanish medical documents.\nWe combine a set of large language models fine-tuned with the data released by\nthe organizers."
  },
  {
    "arxiv_id": "2401.15501",
    "title": "FloodLense: A Framework for ChatGPT-based Real-time Flood Detection",
    "url": "http://arxiv.org/abs/2401.15501v1",
    "abstract": "This study addresses the vital issue of real-time flood detection and\nmanagement. It innovatively combines advanced deep learning models with Large\nlanguage models (LLM), enhancing flood monitoring and response capabilities.\nThis approach addresses the limitations of current methods by offering a more\naccurate, versatile, user-friendly and accessible solution. The integration of\nUNet, RDN, and ViT models with natural language processing significantly\nimproves flood area detection in diverse environments, including using aerial\nand satellite imagery. The experimental evaluation demonstrates the models'\nefficacy in accurately identifying and mapping flood zones, showcasing the\nproject's potential in transforming environmental monitoring and disaster\nmanagement fields."
  },
  {
    "arxiv_id": "2401.15422",
    "title": "A Survey on Data Augmentation in Large Model Era",
    "url": "http://arxiv.org/abs/2401.15422v1",
    "abstract": "Large models, encompassing large language and diffusion models, have shown\nexceptional promise in approximating human-level intelligence, garnering\nsignificant interest from both academic and industrial spheres. However, the\ntraining of these large models necessitates vast quantities of high-quality\ndata, and with continuous updates to these models, the existing reservoir of\nhigh-quality data may soon be depleted. This challenge has catalyzed a surge in\nresearch focused on data augmentation methods. Leveraging large models, these\ndata augmentation techniques have outperformed traditional approaches. This\npaper offers an exhaustive review of large model-driven data augmentation\nmethods, adopting a comprehensive perspective. We begin by establishing a\nclassification of relevant studies into three main categories: image\naugmentation, text augmentation, and paired data augmentation. Following this,\nwe delve into various data post-processing techniques pertinent to large\nmodel-based data augmentation. Our discussion then expands to encompass the\narray of applications for these data augmentation methods within natural\nlanguage processing, computer vision, and audio signal processing. We proceed\nto evaluate the successes and limitations of large model-based data\naugmentation across different scenarios. Concluding our review, we highlight\nprospective challenges and avenues for future exploration in the field of data\naugmentation. Our objective is to furnish researchers with critical insights,\nultimately contributing to the advancement of more sophisticated large models.\nWe consistently maintain the related open-source materials at:\nhttps://github.com/MLGroup-JLU/LLM-data-aug-survey."
  },
  {
    "arxiv_id": "2401.17139",
    "title": "Large Language Model Evaluation via Matrix Entropy",
    "url": "http://arxiv.org/abs/2401.17139v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing and\nextended their powerful capabilities to multi-modal domains. As LLMs continue\nto advance, it is crucial to develop diverse and appropriate metrics for their\nevaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank,\ngrounded in information theory and geometry principles. Diff-eRank assesses\nLLMs by analyzing their hidden representations, providing a quantitative\nmeasure of how efficiently they eliminate redundant information during\ntraining. We demonstrate the applicability of Diff-eRank in both single-modal\n(e.g., language) and multi-modal settings. For language models, our results\nshow that Diff-eRank increases with model size and correlates well with\nconventional metrics such as loss and accuracy. In the multi-modal context, we\npropose an alignment evaluation method based on the eRank, and verify that\ncontemporary multi-modal LLMs exhibit strong alignment performance based on our\nmethod. Our code is publicly available at\nhttps://github.com/waltonfuture/Diff-eRank."
  },
  {
    "arxiv_id": "2401.17005",
    "title": "SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation",
    "url": "http://arxiv.org/abs/2401.17005v1",
    "abstract": "Text generation is a compelling sub-field of natural language processing,\naiming to generate human-readable text from input words. In particular, the\ndecoder-only generative models, such as generative pre-trained transformer\n(GPT), are widely used for text generation, with two major computational\nstages: summarization and generation. Unlike the summarization stage, which can\nprocess the input tokens in parallel, the generation stage is difficult to\naccelerate due to its sequential generation of output tokens through iteration.\nMoreover, each iteration requires reading a whole model with little data reuse\nopportunity. Therefore, the workload of transformer-based text generation is\nseverely memory-bound, making the external memory bandwidth system bottleneck.\nIn this paper, we proposed a subarray-level processing-in-memory architecture\nnamed SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration of\ntransformer-based text generation. The SAL-PIM architecture includes three\narchitectural features. First, the SAL-PIM architecture utilizes higher\ninternal bandwidth by integrating multiple subarray-level arithmetic logic\nunits with optimized data mapping schemes. Second, the SAL-PIM architecture\nadopts LUT-based linear interpolation to perform complex non-linear functions\nin PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIM\nin text generation. Furthermore, to validate the SAL-PIM architecture, we built\ncycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nm\nCMOS technology. As a result, when the input size is from 32 to 128 and the\noutput size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedup\nand an average of 1.83 times speedup for the text generation based on the GPT-2\nmedium model compared to the server-level GPU."
  },
  {
    "arxiv_id": "2401.16736",
    "title": "Engineering A Large Language Model From Scratch",
    "url": "http://arxiv.org/abs/2401.16736v1",
    "abstract": "The proliferation of deep learning in natural language processing (NLP) has\nled to the development and release of innovative technologies capable of\nunderstanding and generating human language with remarkable proficiency.\nAtinuke, a Transformer-based neural network, optimises performance across\nvarious language tasks by utilising a unique configuration. The architecture\ninterweaves layers for processing sequential data with attention mechanisms to\ndraw meaningful affinities between inputs and outputs. Due to the configuration\nof its topology and hyperparameter tuning, it can emulate human-like language\nby extracting features and learning complex mappings. Atinuke is modular,\nextensible, and integrates seamlessly with existing machine learning pipelines.\nAdvanced matrix operations like softmax, embeddings, and multi-head attention\nenable nuanced handling of textual, acoustic, and visual signals. By unifying\nmodern deep learning techniques with software design principles and\nmathematical theory, the system achieves state-of-the-art results on natural\nlanguage tasks whilst remaining interpretable and robust."
  },
  {
    "arxiv_id": "2401.16640",
    "title": "TeenyTinyLlama: open-source tiny language models trained in Brazilian Portuguese",
    "url": "http://arxiv.org/abs/2401.16640v1",
    "abstract": "Large language models (LLMs) have significantly advanced natural language\nprocessing, but their progress has yet to be equal across languages. While most\nLLMs are trained in high-resource languages like English, multilingual models\ngenerally underperform monolingual ones. Additionally, aspects of their\nmultilingual foundation sometimes restrict the byproducts they produce, like\ncomputational demands and licensing regimes. In this study, we document the\ndevelopment of open-foundation models tailored for use in low-resource\nsettings, their limitations, and their benefits. This is the TeenyTinyLlama\npair: two compact models for Brazilian Portuguese text generation. We release\nthem under the permissive Apache 2.0 license on GitHub and Hugging Face for\ncommunity use and further development. See\nhttps://github.com/Nkluge-correa/TeenyTinyLlama"
  },
  {
    "arxiv_id": "2401.16638",
    "title": "Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs",
    "url": "http://arxiv.org/abs/2401.16638v1",
    "abstract": "Fine-tuning large pre-trained language models (LLMs) on particular datasets\nis a commonly employed strategy in Natural Language Processing (NLP)\nclassification tasks. However, this approach usually results in a loss of\nmodels generalizability. In this paper, we present a framework that allows for\nmaintaining generalizability, and enhances the performance on the downstream\ntask by utilizing task-specific context attribution. We show that a linear\ntransformation of the text representation from any transformer model using the\ntask-specific concept operator results in a projection onto the latent concept\nspace, referred to as context attribution in this paper. The specific concept\noperator is optimized during the supervised learning stage via novel loss\nfunctions. The proposed framework demonstrates that context attribution of the\ntext representation for each task objective can improve the capacity of the\ndiscriminator function and thus achieve better performance for the\nclassification task. Experimental results on three datasets, namely HateXplain,\nIMDB reviews, and Social Media Attributions, illustrate that the proposed model\nattains superior accuracy and generalizability. Specifically, for the\nnon-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement in\naccuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,\nfine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy and\nF1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERT\nfine-tuned on the IMDB dataset in conjunction with the proposed model improves\nthe F1-score on the HateXplain dataset by 7%. For the Social Media Attributions\ndataset of YouTube comments, we observe 5.2% increase in F1-metric. The\nproposed framework is implemented with PyTorch and provided open-source on\nGitHub."
  },
  {
    "arxiv_id": "2401.17897",
    "title": "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance",
    "url": "http://arxiv.org/abs/2401.17897v1",
    "abstract": "The objective of legal text entailment is to ascertain whether the assertions\nin a legal query logically follow from the information provided in one or\nmultiple legal articles. ChatGPT, a large language model, is robust in many\nnatural language processing tasks, including legal text entailment: when we set\nthe temperature = 0 (the ChatGPT answers are deterministic) and prompt the\nmodel, it achieves 70.64% accuracy on COLIEE 2022 dataset, which outperforms\nthe previous SOTA of 67.89%. On the other hand, if the temperature is larger\nthan zero, ChatGPT answers are not deterministic, leading to inconsistent\nanswers and fluctuating results. We propose to leverage label models (a\nfundamental component of weak supervision techniques) to integrate the\nprovisional answers by ChatGPT into consolidated labels. By that way, we treat\nChatGPT provisional answers as noisy predictions which can be consolidated by\nlabel models. The experimental results demonstrate that this approach can\nattain an accuracy of 76.15%, marking a significant improvement of 8.26% over\nthe prior state-of-the-art benchmark. Additionally, we perform an analysis of\nthe instances where ChatGPT produces incorrect answers, then we classify the\nerrors, offering insights that could guide potential enhancements for future\nresearch endeavors."
  },
  {
    "arxiv_id": "2401.17658",
    "title": "Document Structure in Long Document Transformers",
    "url": "http://arxiv.org/abs/2401.17658v1",
    "abstract": "Long documents often exhibit structure with hierarchically organized elements\nof different functions, such as section headers and paragraphs. Despite the\nomnipresence of document structure, its role in natural language processing\n(NLP) remains opaque. Do long-document Transformer models acquire an internal\nrepresentation of document structure during pre-training? How can structural\ninformation be communicated to a model after pre-training, and how does it\ninfluence downstream performance? To answer these questions, we develop a novel\nsuite of probing tasks to assess structure-awareness of long-document\nTransformers, propose general-purpose structure infusion methods, and evaluate\nthe effects of structure infusion on QASPER and Evidence Inference, two\nchallenging long-document NLP tasks. Results on LED and LongT5 suggest that\nthey acquire implicit understanding of document structure during pre-training,\nwhich can be further enhanced by structure infusion, leading to improved\nend-task performance. To foster research on the role of document structure in\nNLP modeling, we make our data and code publicly available."
  },
  {
    "arxiv_id": "2401.17602",
    "title": "Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning",
    "url": "http://arxiv.org/abs/2401.17602v1",
    "abstract": "In this study, we aim to address the task of assertion detection when\nextracting medical concepts from clinical notes, a key process in clinical\nnatural language processing (NLP). Assertion detection in clinical NLP usually\ninvolves identifying assertion types for medical concepts in the clinical text,\nnamely certainty (whether the medical concept is positive, negated, possible,\nor hypothetical), temporality (whether the medical concept is for present or\nthe past history), and experiencer (whether the medical concept is described\nfor the patient or a family member). These assertion types are essential for\nhealthcare professionals to quickly and clearly understand the context of\nmedical conditions from unstructured clinical texts, directly influencing the\nquality and outcomes of patient care. Although widely used, traditional\nmethods, particularly rule-based NLP systems and machine learning or deep\nlearning models, demand intensive manual efforts to create patterns and tend to\noverlook less common assertion types, leading to an incomplete understanding of\nthe context. To address this challenge, our research introduces a novel\nmethodology that utilizes Large Language Models (LLMs) pre-trained on a vast\narray of medical data for assertion detection. We enhanced the current method\nwith advanced reasoning techniques, including Tree of Thought (ToT), Chain of\nThought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank\nAdaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010\nassertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11\nimprovements over the previous works. To further assess the generalizability of\nour approach, we extended our evaluation to a local dataset that focused on\nsleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31\nhigher than the previous method."
  },
  {
    "arxiv_id": "2401.17574",
    "title": "Scavenging Hyena: Distilling Transformers into Long Convolution Models",
    "url": "http://arxiv.org/abs/2401.17574v1",
    "abstract": "The rapid evolution of Large Language Models (LLMs), epitomized by\narchitectures like GPT-4, has reshaped the landscape of natural language\nprocessing. This paper introduces a pioneering approach to address the\nefficiency concerns associated with LLM pre-training, proposing the use of\nknowledge distillation for cross-architecture transfer. Leveraging insights\nfrom the efficient Hyena mechanism, our method replaces attention heads in\ntransformer models by Hyena, offering a cost-effective alternative to\ntraditional pre-training while confronting the challenge of processing long\ncontextual information, inherent in quadratic attention mechanisms. Unlike\nconventional compression-focused methods, our technique not only enhances\ninference speed but also surpasses pre-training in terms of both accuracy and\nefficiency. In the era of evolving LLMs, our work contributes to the pursuit of\nsustainable AI solutions, striking a balance between computational power and\nenvironmental impact."
  },
  {
    "arxiv_id": "2401.17396",
    "title": "Fine-tuning Transformer-based Encoder for Turkish Language Understanding Tasks",
    "url": "http://arxiv.org/abs/2401.17396v1",
    "abstract": "Deep learning-based and lately Transformer-based language models have been\ndominating the studies of natural language processing in the last years. Thanks\nto their accurate and fast fine-tuning characteristics, they have outperformed\ntraditional machine learning-based approaches and achieved state-of-the-art\nresults for many challenging natural language understanding (NLU) problems.\nRecent studies showed that the Transformer-based models such as BERT, which is\nBidirectional Encoder Representations from Transformers, have reached\nimpressive achievements on many tasks. Moreover, thanks to their transfer\nlearning capacity, these architectures allow us to transfer pre-built models\nand fine-tune them to specific NLU tasks such as question answering. In this\nstudy, we provide a Transformer-based model and a baseline benchmark for the\nTurkish Language. We successfully fine-tuned a Turkish BERT model, namely\nBERTurk that is trained with base settings, to many downstream tasks and\nevaluated with a the Turkish Benchmark dataset. We showed that our studies\nsignificantly outperformed other existing baseline approaches for Named-Entity\nRecognition, Sentiment Analysis, Question Answering and Text Classification in\nTurkish Language. We publicly released these four fine-tuned models and\nresources in reproducibility and with the view of supporting other Turkish\nresearchers and applications."
  },
  {
    "arxiv_id": "2402.00858",
    "title": "Can Large Language Models Understand Context?",
    "url": "http://arxiv.org/abs/2402.00858v1",
    "abstract": "Understanding context is key to understanding human language, an ability\nwhich Large Language Models (LLMs) have been increasingly seen to demonstrate\nto an impressive extent. However, though the evaluation of LLMs encompasses\nvarious domains within the realm of Natural Language Processing, limited\nattention has been paid to probing their linguistic capability of understanding\ncontextual features. This paper introduces a context understanding benchmark by\nadapting existing datasets to suit the evaluation of generative models. This\nbenchmark comprises of four distinct tasks and nine datasets, all featuring\nprompts designed to assess the models' ability to understand context. First, we\nevaluate the performance of LLMs under the in-context learning pretraining\nscenario. Experimental results indicate that pre-trained dense models struggle\nwith understanding more nuanced contextual features when compared to\nstate-of-the-art fine-tuned models. Second, as LLM compression holds growing\nsignificance in both research and real-world applications, we assess the\ncontext understanding of quantized models under in-context-learning settings.\nWe find that 3-bit post-training quantization leads to varying degrees of\nperformance reduction on our benchmark. We conduct an extensive analysis of\nthese scenarios to substantiate our experimental results."
  },
  {
    "arxiv_id": "2402.00794",
    "title": "ReAGent: Towards A Model-agnostic Feature Attribution Method for Generative Language Models",
    "url": "http://arxiv.org/abs/2402.00794v1",
    "abstract": "Feature attribution methods (FAs), such as gradients and attention, are\nwidely employed approaches to derive the importance of all input features to\nthe model predictions. Existing work in natural language processing has mostly\nfocused on developing and testing FAs for encoder-only language models (LMs) in\nclassification tasks. However, it is unknown if it is faithful to use these FAs\nfor decoder-only models on text generation, due to the inherent differences\nbetween model architectures and task settings respectively. Moreover, previous\nwork has demonstrated that there is no `one-wins-all' FA across models and\ntasks. This makes the selection of a FA computationally expensive for large LMs\nsince input importance derivation often requires multiple forward and backward\npasses including gradient computations that might be prohibitive even with\naccess to large compute. To address these issues, we present a model-agnostic\nFA for generative LMs called Recursive Attribution Generator (ReAGent). Our\nmethod updates the token importance distribution in a recursive manner. For\neach update, we compute the difference in the probability distribution over the\nvocabulary for predicting the next token between using the original input and\nusing a modified version where a part of the input is replaced with RoBERTa\npredictions. Our intuition is that replacing an important token in the context\nshould have resulted in a larger change in the model's confidence in predicting\nthe token than replacing an unimportant token. Our method can be universally\napplied to any generative LM without accessing internal model weights or\nadditional training and fine-tuning, as most other FAs require. We extensively\ncompare the faithfulness of ReAGent with seven popular FAs across six\ndecoder-only LMs of various sizes. The results show that our method\nconsistently provides more faithful token importance distributions."
  },
  {
    "arxiv_id": "2402.00474",
    "title": "SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection Framework for Large Language Models",
    "url": "http://arxiv.org/abs/2402.00474v1",
    "abstract": "Recent advances in large language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, their\neffective application in the medical domain is hampered by a lack of medical\ndomain knowledge. In this study, we present SA-MDKIF, a scalable and adaptable\nframework that aims to inject medical knowledge into general-purpose LLMs\nthrough instruction tuning, thereby enabling adaptability for various\ndownstream tasks. SA-MDKIF consists of two stages: skill training and skill\nadaptation. In the first stage, we define 12 basic medical skills and use\nAdaLoRA to train these skills based on uniformly formatted instructional\ndatasets that we have constructed. In the next stage, we train the skill router\nusing task-specific downstream data and use this router to integrate the\nacquired skills with LLMs during inference. Experimental results on 9 different\nmedical tasks show that SA-MDKIF improves performance by 10-20% compared to the\noriginal LLMs. Notably, this improvement is particularly pronounced for unseen\nmedical tasks, showing an improvement of up to 30%."
  },
  {
    "arxiv_id": "2402.00159",
    "title": "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research",
    "url": "http://arxiv.org/abs/2402.00159v1",
    "abstract": "Information about pretraining corpora used to train the current\nbest-performing language models is seldom discussed: commercial models rarely\ndetail their data, and even open models are often released without accompanying\ntraining data or recipes to reproduce them. As a result, it is challenging to\nconduct and advance scientific research on language modeling, such as\nunderstanding how training data impacts model capabilities and limitations. To\nfacilitate scientific research on language model pretraining, we curate and\nrelease Dolma, a three-trillion-token English corpus, built from a diverse\nmixture of web content, scientific papers, code, public-domain books, social\nmedia, and encyclopedic materials. We extensively document Dolma, including its\ndesign principles, details about its construction, and a summary of its\ncontents. We present analyses and experimental results on intermediate states\nof Dolma to share what we have learned about important data curation practices.\nFinally, we open-source our data curation toolkit to enable reproduction of our\nwork as well as support further research in large-scale data curation."
  },
  {
    "arxiv_id": "2402.01439",
    "title": "From Words to Molecules: A Survey of Large Language Models in Chemistry",
    "url": "http://arxiv.org/abs/2402.01439v1",
    "abstract": "In recent years, Large Language Models (LLMs) have achieved significant\nsuccess in natural language processing (NLP) and various interdisciplinary\nareas. However, applying LLMs to chemistry is a complex task that requires\nspecialized domain knowledge. This paper provides a thorough exploration of the\nnuanced methodologies employed in integrating LLMs into the field of chemistry,\ndelving into the complexities and innovations at this interdisciplinary\njuncture. Specifically, our analysis begins with examining how molecular\ninformation is fed into LLMs through various representation and tokenization\nmethods. We then categorize chemical LLMs into three distinct groups based on\nthe domain and modality of their input data, and discuss approaches for\nintegrating these inputs for LLMs. Furthermore, this paper delves into the\npretraining objectives with adaptations to chemical LLMs. After that, we\nexplore the diverse applications of LLMs in chemistry, including novel\nparadigms for their application in chemistry tasks. Finally, we identify\npromising research directions, including further integration with chemical\nknowledge, advancements in continual learning, and improvements in model\ninterpretability, paving the way for groundbreaking developments in the field."
  },
  {
    "arxiv_id": "2402.01349",
    "title": "Beyond the Answers: Reviewing the Rationality of Multiple Choice Question Answering for the Evaluation of Large Language Models",
    "url": "http://arxiv.org/abs/2402.01349v1",
    "abstract": "In the field of NLP, Large Language Models (LLMs) have markedly enhanced\nperformance across a variety of tasks. However, the comprehensive evaluation of\nLLMs remains an inevitable challenge for the community. Recently, the adoption\nof Multiple Choice Question Answering (MCQA) as a benchmark for assessing LLMs\nhas gained considerable traction. However, concerns regarding the robustness of\nthis evaluative method persist. Building upon previous discussions on the issue\nof \\textit{variability}, we reveal an additional dimension of concern: LLMs may\nperform MCQA by selecting the least incorrect option rather than distinctly\ncorrect. This observation suggests that LLMs might regard multiple options as\ncorrect, which could undermine the reliability of MCQA as a metric for\nevaluating LLMs. To address this challenge, we introduce an enhanced dataset\naugmentation method for MCQA, termed MCQA+, to provide a more accurate\nreflection of the model performance, thereby highlighting the necessity for\nmore sophisticated evaluation mechanisms in the assessment of LLM capabilities."
  },
  {
    "arxiv_id": "2402.01173",
    "title": "Efficient Prompt Caching via Embedding Similarity",
    "url": "http://arxiv.org/abs/2402.01173v1",
    "abstract": "Large language models (LLMs) have achieved huge success in numerous natural\nlanguage process (NLP) tasks. However, it faces the challenge of significant\nresource consumption during inference. In this paper, we aim to improve the\ninference efficiency of LLMs by prompt caching, i.e., if the current prompt can\nbe answered by the same response of a previous prompt, one can directly utilize\nthat previous response without calling the LLM. Specifically, we focus on the\nprediction accuracy of prompt caching for single-round question-answering tasks\nvia embedding similarity. The existing embeddings of prompts mostly focus on\nwhether two prompts are semantically similar, which is not necessarily\nequivalent to whether the same response can answer them. Therefore, we propose\na distillation-based method to fine-tune the existing embeddings for better\ncaching prediction. Theoretically, we provide finite-sample guarantees for the\nconvergence of our method under different types of loss functions. Empirically,\nwe carefully construct a hard dataset based on Kwiatkowski et al. (2019) where\nthe existing embedding model (Wang et al., 2022) only achieves an AUC of 0.51.\nWe then fine-tune the above embedding model, which significantly improves the\nAUC of caching prediction from 0.51 to 0.81. We also conduct simulations\ndemonstrating that our trained models achieve better caching efficiency than\nthe previous embedding model."
  },
  {
    "arxiv_id": "2402.01018",
    "title": "HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent",
    "url": "http://arxiv.org/abs/2402.01018v1",
    "abstract": "Recent advancements in Large Language Models (LLMs) have been reshaping\nNatural Language Processing (NLP) task in several domains. Their use in the\nfield of Human Resources (HR) has still room for expansions and could be\nbeneficial for several time consuming tasks. Examples such as time-off\nsubmissions, medical claims filing, and access requests are noteworthy, but\nthey are by no means the sole instances. However, the aforementioned\ndevelopments must grapple with the pivotal challenge of constructing a\nhigh-quality training dataset. On one hand, most conversation datasets are\nsolving problems for customers not employees. On the other hand, gathering\nconversations with HR could raise privacy concerns. To solve it, we introduce\nHR-Multiwoz, a fully-labeled dataset of 550 conversations spanning 10 HR\ndomains to evaluate LLM Agent. Our work has the following contributions: (1) It\nis the first labeled open-sourced conversation dataset in the HR domain for NLP\nresearch. (2) It provides a detailed recipe for the data generation procedure\nalong with data analysis and human evaluations. The data generation pipeline is\ntransferable and can be easily adapted for labeled conversation data generation\nin other domains. (3) The proposed data-collection pipeline is mostly based on\nLLMs with minimal human involvement for annotation, which is time and\ncost-efficient."
  },
  {
    "arxiv_id": "2402.00969",
    "title": "SPARQL Generation with Entity Pre-trained GPT for KG Question Answering",
    "url": "http://arxiv.org/abs/2402.00969v1",
    "abstract": "Knowledge Graphs popularity has been rapidly growing in last years. All that\nknowledge is available for people to query it through the many online databases\non the internet. Though, it would be a great achievement if non-programmer\nusers could access whatever information they want to know. There has been a lot\nof effort oriented to solve this task using natural language processing tools\nand creativity encouragement by way of many challenges. Our approach focuses on\nassuming a correct entity linking on the natural language questions and\ntraining a GPT model to create SPARQL queries from them. We managed to isolate\nwhich property of the task can be the most difficult to solve at few or\nzero-shot and we proposed pre-training on all entities (under CWA) to improve\nthe performance. We obtained a 62.703% accuracy of exact SPARQL matches on\ntesting at 3-shots, a F1 of 0.809 on the entity linking challenge and a F1 of\n0.009 on the question answering challenge."
  },
  {
    "arxiv_id": "2402.02622",
    "title": "DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging",
    "url": "http://arxiv.org/abs/2402.02622v1",
    "abstract": "The transformer architecture by Vaswani et al. (2017) is now ubiquitous\nacross application domains, from natural language processing to speech\nprocessing and image understanding. We propose DenseFormer, a simple\nmodification to the standard architecture that improves the perplexity of the\nmodel without increasing its size -- adding a few thousand parameters for\nlarge-scale models in the 100B parameters range. Our approach relies on an\nadditional averaging step after each transformer block, which computes a\nweighted average of current and past representations -- we refer to this\noperation as Depth-Weighted-Average (DWA). The learned DWA weights exhibit\ncoherent patterns of information flow, revealing the strong and structured\nreuse of activations from distant layers. Experiments demonstrate that\nDenseFormer is more data efficient, reaching the same perplexity of much deeper\ntransformer models, and that for the same perplexity, these new models\noutperform transformer baselines in terms of memory efficiency and inference\ntime."
  },
  {
    "arxiv_id": "2402.02586",
    "title": "ClipFormer: Key-Value Clipping of Transformers on Memristive Crossbars for Write Noise Mitigation",
    "url": "http://arxiv.org/abs/2402.02586v1",
    "abstract": "Transformers have revolutionized various real-world applications from natural\nlanguage processing to computer vision. However, traditional von-Neumann\ncomputing paradigm faces memory and bandwidth limitations in accelerating\ntransformers owing to their massive model sizes. To this end, In-memory\nComputing (IMC) crossbars based on Non-volatile Memories (NVMs), due to their\nability to perform highly parallelized Matrix-Vector-Multiplications (MVMs)\nwith high energy-efficiencies, have emerged as a promising solution for\naccelerating transformers. However, analog MVM operations in crossbars\nintroduce non-idealities, such as stochastic read & write noise, which affect\nthe inference accuracy of the deployed transformers. Specifically, we find\npre-trained Vision Transformers (ViTs) to be vulnerable on crossbars due to the\nimpact of write noise on the dynamically-generated Key (K) and Value (V)\nmatrices in the attention layers, an effect not accounted for in prior studies.\nWe, thus, propose ClipFormer, a transformation on the K and V matrices during\ninference, to boost the non-ideal accuracies of pre-trained ViT models.\nClipFormer requires no additional hardware and training overhead and is\namenable to transformers deployed on any memristive crossbar platform. Our\nexperiments on Imagenet-1k dataset using pre-trained DeiT-S transformers,\nsubjected to standard training and variation-aware-training, show >10-40%\nhigher non-ideal accuracies at the high write noise regime by applying\nClipFormer."
  },
  {
    "arxiv_id": "2402.04206",
    "title": "Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models",
    "url": "http://arxiv.org/abs/2402.04206v1",
    "abstract": "This paper introduces a system designed to generate explanations for the\nactions performed by an autonomous robot in Human-Robot Interaction (HRI).\nExplainability in robotics, encapsulated within the concept of an eXplainable\nAutonomous Robot (XAR), is a growing research area. The work described in this\npaper aims to take advantage of the capabilities of Large Language Models\n(LLMs) in performing natural language processing tasks. This study focuses on\nthe possibility of generating explanations using such models in combination\nwith a Retrieval Augmented Generation (RAG) method to interpret data gathered\nfrom the logs of autonomous systems. In addition, this work also presents a\nformalization of the proposed explanation system. It has been evaluated through\na navigation test from the European Robotics League (ERL), a Europe-wide social\nrobotics competition. Regarding the obtained results, a validation\nquestionnaire has been conducted to measure the quality of the explanations\nfrom the perspective of technical users. The results obtained during the\nexperiment highlight the potential utility of LLMs in achieving explanatory\ncapabilities in robots."
  },
  {
    "arxiv_id": "2402.04119",
    "title": "Scientific Language Modeling: A Quantitative Review of Large Language Models in Molecular Science",
    "url": "http://arxiv.org/abs/2402.04119v1",
    "abstract": "Deep learning has significantly advanced molecular modeling and design,\nenabling efficient understanding and discovery of novel molecules. In\nparticular, large language models (LLMs) introduce a fresh research paradigm to\ntackle scientific problems from a natural language processing (NLP)\nperspective. LLMs significantly enhance our understanding and generation of\nmolecules, often surpassing existing methods with their capabilities to decode\nand synthesize complex molecular patterns. However, two key issues remain: how\nto quantify the match between model and data modalities and how to identify the\nknowledge-learning preferences of models. To address these challenges, we\npropose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263\nexperiments to assess the model's compatibility with data modalities and\nknowledge acquisition. Through the modal transition probability matrix, we\nprovide insights into the most suitable modalities for tasks. Furthermore, we\nintroduce a statistically interpretable approach to discover context-specific\nknowledge mapping by localized feature filtering. Our analysis offers an\nexploration of the learning mechanism and paves the way for advancing LLMs in\nmolecular science."
  },
  {
    "arxiv_id": "2402.04088",
    "title": "The Use of a Large Language Model for Cyberbullying Detection",
    "url": "http://arxiv.org/abs/2402.04088v1",
    "abstract": "The dominance of social media has added to the channels of bullying for\nperpetrators. Unfortunately, cyberbullying (CB) is the most prevalent\nphenomenon in todays cyber world, and is a severe threat to the mental and\nphysical health of citizens. This opens the need to develop a robust system to\nprevent bullying content from online forums, blogs, and social media platforms\nto manage the impact in our society. Several machine learning (ML) algorithms\nhave been proposed for this purpose. However, their performances are not\nconsistent due to high class imbalance and generalisation issues. In recent\nyears, large language models (LLMs) like BERT and RoBERTa have achieved\nstate-of-the-art (SOTA) results in several natural language processing (NLP)\ntasks. Unfortunately, the LLMs have not been applied extensively for CB\ndetection. In our paper, we explored the use of these models for cyberbullying\n(CB) detection. We have prepared a new dataset (D2) from existing studies\n(Formspring and Twitter). Our experimental results for dataset D1 and D2 showed\nthat RoBERTa outperformed other models."
  },
  {
    "arxiv_id": "2402.04049",
    "title": "Systematic Biases in LLM Simulations of Debates",
    "url": "http://arxiv.org/abs/2402.04049v1",
    "abstract": "The emergence of Large Language Models (LLMs), has opened exciting\npossibilities for constructing computational simulations designed to replicate\nhuman behavior accurately. Current research suggests that LLM-based agents\nbecome increasingly human-like in their performance, sparking interest in using\nthese AI agents as substitutes for human participants in behavioral studies.\nHowever, LLMs are complex statistical learners without straightforward\ndeductive rules, making them prone to unexpected behaviors. Hence, it is\ncrucial to study and pinpoint the key behavioral distinctions between humans\nand LLM-based agents. In this study, we highlight the limitations of LLMs in\nsimulating human interactions, particularly focusing on LLMs' ability to\nsimulate political debates on topics that are important aspects of people's\nday-to-day lives and decision-making processes. Our findings indicate a\ntendency for LLM agents to conform to the model's inherent social biases\ndespite being directed to debate from certain political perspectives. This\ntendency results in behavioral patterns that seem to deviate from\nwell-established social dynamics among humans. We reinforce these observations\nusing an automatic self-fine-tuning method, which enables us to manipulate the\nbiases within the LLM and demonstrate that agents subsequently align with the\naltered biases. These results underscore the need for further research to\ndevelop methods that help agents overcome these biases, a critical step toward\ncreating more realistic simulations."
  },
  {
    "arxiv_id": "2402.03927",
    "title": "Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs",
    "url": "http://arxiv.org/abs/2402.03927v1",
    "abstract": "Natural Language Processing (NLP) research is increasingly focusing on the\nuse of Large Language Models (LLMs), with some of the most popular ones being\neither fully or partially closed-source. The lack of access to model details,\nespecially regarding training data, has repeatedly raised concerns about data\ncontamination among researchers. Several attempts have been made to address\nthis issue, but they are limited to anecdotal evidence and trial and error.\nAdditionally, they overlook the problem of \\emph{indirect} data leaking, where\nmodels are iteratively improved by using data coming from users. In this work,\nwe conduct the first systematic analysis of work using OpenAI's GPT-3.5 and\nGPT-4, the most prominently used LLMs today, in the context of data\ncontamination. By analysing 255 papers and considering OpenAI's data usage\npolicy, we extensively document the amount of data leaked to these models\nduring the first year after the model's release. We report that these models\nhave been globally exposed to $\\sim$4.7M samples from 263 benchmarks. At the\nsame time, we document a number of evaluation malpractices emerging in the\nreviewed papers, such as unfair or missing baseline comparisons and\nreproducibility issues. We release our results as a collaborative project on\nhttps://leak-llm.github.io/, where other researchers can contribute to our\nefforts."
  },
  {
    "arxiv_id": "2402.03628",
    "title": "Professional Agents -- Evolving Large Language Models into Autonomous Experts with Human-Level Competencies",
    "url": "http://arxiv.org/abs/2402.03628v1",
    "abstract": "The advent of large language models (LLMs) such as ChatGPT, PaLM, and GPT-4\nhas catalyzed remarkable advances in natural language processing, demonstrating\nhuman-like language fluency and reasoning capacities. This position paper\nintroduces the concept of Professional Agents (PAgents), an application\nframework harnessing LLM capabilities to create autonomous agents with\ncontrollable, specialized, interactive, and professional-level competencies. We\nposit that PAgents can reshape professional services through continuously\ndeveloped expertise. Our proposed PAgents framework entails a tri-layered\narchitecture for genesis, evolution, and synergy: a base tool layer, a middle\nagent layer, and a top synergy layer. This paper aims to spur discourse on\npromising real-world applications of LLMs. We argue the increasing\nsophistication and integration of PAgents could lead to AI systems exhibiting\nprofessional mastery over complex domains, serving critical needs, and\npotentially achieving artificial general intelligence."
  },
  {
    "arxiv_id": "2402.03627",
    "title": "Partially Recentralization Softmax Loss for Vision-Language Models Robustness",
    "url": "http://arxiv.org/abs/2402.03627v1",
    "abstract": "As Large Language Models make a breakthrough in natural language processing\ntasks (NLP), multimodal technique becomes extremely popular. However, it has\nbeen shown that multimodal NLP are vulnerable to adversarial attacks, where the\noutputs of a model can be dramatically changed by a perturbation to the input.\nWhile several defense techniques have been proposed both in computer vision and\nNLP models, the multimodal robustness of models have not been fully explored.\nIn this paper, we study the adversarial robustness provided by modifying loss\nfunction of pre-trained multimodal models, by restricting top K softmax\noutputs. Based on the evaluation and scoring, our experiments show that after a\nfine-tuning, adversarial robustness of pre-trained models can be significantly\nimproved, against popular attacks. Further research should be studying, such as\noutput diversity, generalization and the robustness-performance trade-off of\nthis kind of loss functions. Our code will be available after this paper is\naccepted"
  },
  {
    "arxiv_id": "2402.04978",
    "title": "An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration",
    "url": "http://arxiv.org/abs/2402.04978v1",
    "abstract": "While Large Language Models (LLMs) demonstrate exceptional performance in a\nmultitude of Natural Language Processing (NLP) tasks, they encounter challenges\nin practical applications, including issues with hallucinations, inadequate\nknowledge updating, and limited transparency in the reasoning process. To\novercome these limitations, this study innovatively proposes a collaborative\ntraining-free reasoning scheme involving tight cooperation between Knowledge\nGraph (KG) and LLMs. This scheme first involves using LLMs to iteratively\nexplore KG, selectively retrieving a task-relevant knowledge subgraph to\nsupport reasoning. The LLMs are then guided to further combine inherent\nimplicit knowledge to reason on the subgraph while explicitly elucidating the\nreasoning process. Through such a cooperative approach, our scheme achieves\nmore reliable knowledge-based reasoning and facilitates the tracing of the\nreasoning results. Experimental results show that our scheme significantly\nprogressed across multiple datasets, notably achieving over a 10% improvement\non the QALD10 dataset compared to the best baseline and the fine-tuned\nstate-of-the-art (SOTA) work. Building on this success, this study hopes to\noffer a valuable reference for future research in the fusion of KG and LLMs,\nthereby enhancing LLMs' proficiency in solving complex issues."
  },
  {
    "arxiv_id": "2402.04955",
    "title": "Chatbots in Knowledge-Intensive Contexts: Comparing Intent and LLM-Based Systems",
    "url": "http://arxiv.org/abs/2402.04955v1",
    "abstract": "Conversational Assistants (CA) are increasingly supporting human workers in\nknowledge management. Traditionally, CAs respond in specific ways to predefined\nuser intents and conversation patterns. However, this rigidness does not handle\nthe diversity of natural language well. Recent advances in natural language\nprocessing, namely Large Language Models (LLMs), enable CAs to converse in a\nmore flexible, human-like manner, extracting relevant information from texts\nand capturing information from expert humans but introducing new challenges\nsuch as ``hallucinations''. To assess the potential of using LLMs for knowledge\nmanagement tasks, we conducted a user study comparing an LLM-based CA to an\nintent-based system regarding interaction efficiency, user experience,\nworkload, and usability. This revealed that LLM-based CAs exhibited better user\nexperience, task completion rate, usability, and perceived performance than\nintent-based systems, suggesting that switching NLP techniques can be\nbeneficial in the context of knowledge management."
  },
  {
    "arxiv_id": "2402.04614",
    "title": "Faithfulness vs. Plausibility: On the (Un)Reliability of Explanations from Large Language Models",
    "url": "http://arxiv.org/abs/2402.04614v1",
    "abstract": "Large Language Models (LLMs) are deployed as powerful tools for several\nnatural language processing (NLP) applications. Recent works show that modern\nLLMs can generate self-explanations (SEs), which elicit their intermediate\nreasoning steps for explaining their behavior. Self-explanations have seen\nwidespread adoption owing to their conversational and plausible nature.\nHowever, there is little to no understanding of their faithfulness. In this\nwork, we discuss the dichotomy between faithfulness and plausibility in SEs\ngenerated by LLMs. We argue that while LLMs are adept at generating plausible\nexplanations -- seemingly logical and coherent to human users -- these\nexplanations do not necessarily align with the reasoning processes of the LLMs,\nraising concerns about their faithfulness. We highlight that the current trend\ntowards increasing the plausibility of explanations, primarily driven by the\ndemand for user-friendly interfaces, may come at the cost of diminishing their\nfaithfulness. We assert that the faithfulness of explanations is critical in\nLLMs employed for high-stakes decision-making. Moreover, we emphasize the need\nfor a systematic characterization of faithfulness-plausibility requirements of\ndifferent real-world applications and ensure explanations meet those needs.\nWhile there are several approaches to improving plausibility, improving\nfaithfulness is an open challenge. We call upon the community to develop novel\nmethods to enhance the faithfulness of self explanations thereby enabling\ntransparent deployment of LLMs in diverse high-stakes settings."
  },
  {
    "arxiv_id": "2402.04527",
    "title": "RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation",
    "url": "http://arxiv.org/abs/2402.04527v1",
    "abstract": "Large language models (LLM) have recently emerged as a powerful tool for a\nvariety of natural language processing tasks, bringing a new surge of combining\nLLM with recommendation systems, termed as LLM-based RS. Current approaches\ngenerally fall into two main paradigms, the ID direct usage paradigm and the ID\ntranslation paradigm, noting their core weakness stems from lacking\nrecommendation knowledge and uniqueness. To address this limitation, we propose\na new paradigm, ID representation, which incorporates pre-trained ID embeddings\ninto LLMs in a complementary manner. In this work, we present RA-Rec, an\nefficient ID representation alignment framework for LLM-based recommendation,\nwhich is compatible with multiple ID-based methods and LLM architectures.\nSpecifically, we treat ID embeddings as soft prompts and design an innovative\nalignment module and an efficient tuning method with tailored data construction\nfor alignment. Extensive experiments demonstrate RA-Rec substantially\noutperforms current state-of-the-art methods, achieving up to 3.0% absolute\nHitRate@100 improvements while utilizing less than 10x training data."
  },
  {
    "arxiv_id": "2402.04335",
    "title": "LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text",
    "url": "http://arxiv.org/abs/2402.04335v1",
    "abstract": "In this study, we focus on two main tasks, the first for detecting legal\nviolations within unstructured textual data, and the second for associating\nthese violations with potentially affected individuals. We constructed two\ndatasets using Large Language Models (LLMs) which were subsequently validated\nby domain expert annotators. Both tasks were designed specifically for the\ncontext of class-action cases. The experimental design incorporated fine-tuning\nmodels from the BERT family and open-source LLMs, and conducting few-shot\nexperiments using closed-source LLMs. Our results, with an F1-score of 62.69\\%\n(violation identification) and 81.02\\% (associating victims), show that our\ndatasets and setups can be used for both tasks. Finally, we publicly release\nthe datasets and the code used for the experiments in order to advance further\nresearch in the area of legal natural language processing (NLP)."
  },
  {
    "arxiv_id": "2402.05926",
    "title": "On the Convergence of Zeroth-Order Federated Tuning in Large Language Models",
    "url": "http://arxiv.org/abs/2402.05926v1",
    "abstract": "The confluence of Federated Learning (FL) and Large Language Models (LLMs) is\nushering in a new era in privacy-preserving natural language processing.\nHowever, the intensive memory requirements for fine-tuning LLMs pose\nsignificant challenges, especially when deploying on clients with limited\ncomputational resources. To circumvent this, we explore the novel integration\nof Memory-efficient Zeroth-Order Optimization within a federated setting, a\nsynergy we term as FedMeZO. Our study is the first to examine the theoretical\nunderpinnings of FedMeZO in the context of LLMs, tackling key questions\nregarding the influence of large parameter spaces on optimization behavior, the\nestablishment of convergence properties, and the identification of critical\nparameters for convergence to inform personalized federated strategies. Our\nextensive empirical evidence supports the theory, showing that FedMeZO not only\nconverges faster than traditional first-order methods such as FedAvg but also\nsignificantly reduces GPU memory usage during training to levels comparable to\nthose during inference. Moreover, the proposed personalized FL strategy that is\nbuilt upon the theoretical insights to customize the client-wise learning rate\ncan effectively accelerate loss reduction. We hope our work can help to bridge\ntheoretical and practical aspects of federated fine-tuning for LLMs, thereby\nstimulating further advancements and research in this area."
  },
  {
    "arxiv_id": "2402.05624",
    "title": "Efficient Models for the Detection of Hate, Abuse and Profanity",
    "url": "http://arxiv.org/abs/2402.05624v1",
    "abstract": "Large Language Models (LLMs) are the cornerstone for many Natural Language\nProcessing (NLP) tasks like sentiment analysis, document classification, named\nentity recognition, question answering, summarization, etc. LLMs are often\ntrained on data which originates from the web. This data is prone to having\ncontent with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP,\nplease refer to the Appendix. Due to the LLMs being exposed to HAP content\nduring training, the models learn it and may then generate hateful or profane\ncontent. For example, when the open-source RoBERTa model (specifically, the\nRoBERTA base model) from the HuggingFace (HF) Transformers library is prompted\nto replace the mask token in `I do not know that Persian people are that MASK`\nit returns the word `stupid` with the highest score. This is unacceptable in\ncivil discourse.The detection of Hate, Abuse and Profanity in text is a vital\ncomponent of creating civil and unbiased LLMs, which is needed not only for\nEnglish, but for all languages. In this article, we briefly describe the\ncreation of HAP detectors and various ways of using them to make models civil\nand acceptable in the output they generate."
  },
  {
    "arxiv_id": "2402.05547",
    "title": "Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset",
    "url": "http://arxiv.org/abs/2402.05547v1",
    "abstract": "Traditional applications of natural language processing (NLP) in healthcare\nhave predominantly focused on patient-centered services, enhancing patient\ninteractions and care delivery, such as through medical dialogue systems.\nHowever, the potential of NLP to benefit inexperienced doctors, particularly in\nareas such as communicative medical coaching, remains largely unexplored. We\nintroduce \"ChatCoach\", a human-AI cooperative framework designed to assist\nmedical learners in practicing their communication skills during patient\nconsultations. ChatCoach (Our data and code are available online:\nhttps://github.com/zerowst/Chatcoach)differentiates itself from conventional\ndialogue systems by offering a simulated environment where medical learners can\npractice dialogues with a patient agent, while a coach agent provides\nimmediate, structured feedback. This is facilitated by our proposed Generalized\nChain-of-Thought (GCoT) approach, which fosters the generation of structured\nfeedback and enhances the utilization of external knowledge sources.\nAdditionally, we have developed a dataset specifically for evaluating Large\nLanguage Models (LLMs) within the ChatCoach framework on communicative medical\ncoaching tasks. Our empirical results validate the effectiveness of ChatCoach."
  },
  {
    "arxiv_id": "2402.05435",
    "title": "GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study",
    "url": "http://arxiv.org/abs/2402.05435v1",
    "abstract": "Large Language Models (LLMs) play a pivotal role in generating vast arrays of\nnarratives, facilitating a systematic exploration of their effectiveness for\ncommunicating life events in narrative form. In this study, we employ a\nzero-shot structured narrative prompt to generate 24,000 narratives using\nOpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and\nevaluate their validity in conveying birth, death, hiring, and firing events.\nRemarkably, 87.43% of the narratives sufficiently convey the intention of the\nstructured prompt. To automate the identification of valid and invalid\nnarratives, we train and validate nine Machine Learning models on the\nclassified datasets. Leveraging these models, we extend our analysis to predict\nthe classifications of the remaining 21,120 narratives. All the ML models\nexcelled at classifying valid narratives as valid, but experienced challenges\nat simultaneously classifying invalid narratives as invalid. Our findings not\nonly advance the study of LLM capabilities, limitations, and validity but also\noffer practical insights for narrative generation and natural language\nprocessing applications."
  },
  {
    "arxiv_id": "2402.06619",
    "title": "Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning",
    "url": "http://arxiv.org/abs/2402.06619v1",
    "abstract": "Datasets are foundational to many breakthroughs in modern artificial\nintelligence. Many recent achievements in the space of natural language\nprocessing (NLP) can be attributed to the finetuning of pre-trained models on a\ndiverse set of tasks that enables a large language model (LLM) to respond to\ninstructions. Instruction fine-tuning (IFT) requires specifically constructed\nand annotated datasets. However, existing datasets are almost all in the\nEnglish language. In this work, our primary goal is to bridge the language gap\nby building a human-curated instruction-following dataset spanning 65\nlanguages. We worked with fluent speakers of languages from around the world to\ncollect natural instances of instructions and completions. Furthermore, we\ncreate the most extensive multilingual collection to date, comprising 513\nmillion instances through templating and translating existing datasets across\n114 languages. In total, we contribute four key resources: we develop and\nopen-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,\nand the Aya Evaluation Suite. The Aya initiative also serves as a valuable case\nstudy in participatory research, involving collaborators from 119 countries. We\nsee this as a valuable framework for future research collaborations that aim to\nbridge gaps in resources."
  },
  {
    "arxiv_id": "2402.06608",
    "title": "TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations",
    "url": "http://arxiv.org/abs/2402.06608v1",
    "abstract": "We study the problem of generating plans for given natural language planning\ntask requests. On one hand, LLMs excel at natural language processing but do\nnot perform well on planning. On the other hand, classical planning tools excel\nat planning tasks but require input in a structured language such as the\nPlanning Domain Definition Language (PDDL). We leverage the strengths of both\nthe techniques by using an LLM for generating the PDDL representation (task\nPDDL) of planning task requests followed by using a classical planner for\ncomputing a plan. Unlike previous approaches that use LLMs for generating task\nPDDLs directly, our approach comprises of (a) translate: using an LLM only for\ngenerating a logically interpretable intermediate representation of natural\nlanguage task description, (b) infer: deriving additional logically dependent\ninformation from the intermediate representation using a logic reasoner\n(currently, Answer Set Programming solver), and (c) compile: generating the\ntarget task PDDL from the base and inferred information. We observe that using\nan LLM to only output the intermediate representation significantly reduces LLM\nerrors. Consequently, TIC approach achieves, for at least one LLM, high\naccuracy on task PDDL generation for all seven domains of our evaluation\ndataset."
  },
  {
    "arxiv_id": "2402.06584",
    "title": "G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German",
    "url": "http://arxiv.org/abs/2402.06584v1",
    "abstract": "The advancement of natural language processing has paved the way for\nautomated scoring systems in various languages, such as German (e.g., German\nBERT [G-BERT]). Automatically scoring written responses to science questions in\nGerman is a complex task and challenging for standard G-BERT as they lack\ncontextual knowledge in the science domain and may be unaligned with student\nwriting styles. This paper presents a contextualized German Science Education\nBERT (G-SciEdBERT), an innovative large language model tailored for scoring\nGerman-written responses to science tasks and beyond. Using G-BERT, we\npre-trained G-SciEdBERT on a corpus of 30K German written science responses\nwith 3M tokens on the Programme for International Student Assessment (PISA)\n2018. We fine-tuned G-SciEdBERT on an additional 20K student-written responses\nwith 2M tokens and examined the scoring accuracy. We then compared its scoring\nperformance with G-BERT. Our findings revealed a substantial improvement in\nscoring accuracy with G-SciEdBERT, demonstrating a 10.2% increase of quadratic\nweighted Kappa compared to G-BERT (mean difference = 0.1026, SD = 0.069). These\ninsights underline the significance of specialized language models like\nG-SciEdBERT, which is trained to enhance the accuracy of contextualized\nautomated scoring, offering a substantial contribution to the field of AI in\neducation."
  },
  {
    "arxiv_id": "2402.06220",
    "title": "A Unified Causal View of Instruction Tuning",
    "url": "http://arxiv.org/abs/2402.06220v1",
    "abstract": "Instruction tuning on a mixture of tasks has improved zero-shot capabilities\nin natural language processing (NLP). Nevertheless, existing methods often\nlearn features that exhibit correlations between instruction-formatted samples\nand target labels, rather than causal relationships. Termed as ``spurious\ncorrelation'' in statistics, such a correlation may change drastically in a new\ntask, making the effect from the learned features to be misleading. To this\nend, we develop a meta Structural Causal Model (meta-SCM) to integrate\ndifferent NLP tasks under a single causal structure of the data. Specifically,\nthe meta-SCM introduces multiple latent factors that represent properties of\nsource context, only some of which causally influence the target labels for a\nspecific task. The key idea is to learn task-required causal factors and only\nuse those to make predictions for a given task. Theoretically, we prove the\ncausal factor can be identified without mixing information from others. Guided\nby the identifiability, we propose a Structural Instruction Tuning (SIT) method\nto learn the task-required causal representations that can mimic the causal\nfactors for each task. The utility of our approach is verified by improvements\nof zero-shot ability on a range of unseen datasets and tasks."
  },
  {
    "arxiv_id": "2402.07405",
    "title": "Dólares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs Between Spanish and English",
    "url": "http://arxiv.org/abs/2402.07405v1",
    "abstract": "Despite Spanish's pivotal role in the global finance industry, a pronounced\ngap exists in Spanish financial natural language processing (NLP) and\napplication studies compared to English, especially in the era of large\nlanguage models (LLMs). To bridge this gap, we unveil Tois\\'on de Oro, the\nfirst bilingual framework that establishes instruction datasets, finetuned\nLLMs, and evaluation benchmark for financial LLMs in Spanish joint with\nEnglish. We construct a rigorously curated bilingual instruction dataset\nincluding over 144K Spanish and English samples from 15 datasets covering 7\ntasks. Harnessing this, we introduce FinMA-ES, an LLM designed for bilingual\nfinancial applications. We evaluate our model and existing LLMs using FLARE-ES,\nthe first comprehensive bilingual evaluation benchmark with 21 datasets\ncovering 9 tasks. The FLARE-ES benchmark results reveal a significant\nmultilingual performance gap and bias in existing LLMs. FinMA-ES models surpass\nSOTA LLMs such as GPT-4 in Spanish financial tasks, due to strategic\ninstruction tuning and leveraging data from diverse linguistic resources,\nhighlighting the positive impact of cross-linguistic transfer. All our\ndatasets, models, and benchmarks have been released."
  },
  {
    "arxiv_id": "2402.07304",
    "title": "Insights into Natural Language Database Query Errors: From Attention Misalignment to User Handling Strategies",
    "url": "http://arxiv.org/abs/2402.07304v1",
    "abstract": "Querying structured databases with natural language (NL2SQL) has remained a\ndifficult problem for years. Recently, the advancement of machine learning\n(ML), natural language processing (NLP), and large language models (LLM) have\nled to significant improvements in performance, with the best model achieving\n~85% percent accuracy on the benchmark Spider dataset. However, there is a lack\nof a systematic understanding of the types, causes, and effectiveness of\nerror-handling mechanisms of errors for erroneous queries nowadays. To bridge\nthe gap, a taxonomy of errors made by four representative NL2SQL models was\nbuilt in this work, along with an in-depth analysis of the errors. Second, the\ncauses of model errors were explored by analyzing the model-human attention\nalignment to the natural language query. Last, a within-subjects user study\nwith 26 participants was conducted to investigate the effectiveness of three\ninteractive error-handling mechanisms in NL2SQL. Findings from this paper shed\nlight on the design of model structure and error discovery and repair\nstrategies for natural language data query interfaces in the future."
  },
  {
    "arxiv_id": "2402.07233",
    "title": "TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation",
    "url": "http://arxiv.org/abs/2402.07233v1",
    "abstract": "Natural language processing (NLP) is a key component of intelligent\ntransportation systems (ITS), but it faces many challenges in the\ntransportation domain, such as domain-specific knowledge and data, and\nmulti-modal inputs and outputs. This paper presents TransGPT, a novel\n(multi-modal) large language model for the transportation domain, which\nconsists of two independent variants: TransGPT-SM for single-modal data and\nTransGPT-MM for multi-modal data. TransGPT-SM is finetuned on a single-modal\nTransportation dataset (STD) that contains textual data from various sources in\nthe transportation domain. TransGPT-MM is finetuned on a multi-modal\nTransportation dataset (MTD) that we manually collected from three areas of the\ntransportation domain: driving tests, traffic signs, and landmarks. We evaluate\nTransGPT on several benchmark datasets for different tasks in the\ntransportation domain, and show that it outperforms baseline models on most\ntasks. We also showcase the potential applications of TransGPT for traffic\nanalysis and modeling, such as generating synthetic traffic scenarios,\nexplaining traffic phenomena, answering traffic-related questions, providing\ntraffic recommendations, and generating traffic reports. This work advances the\nstate-of-the-art of NLP in the transportation domain and provides a useful tool\nfor ITS researchers and practitioners."
  },
  {
    "arxiv_id": "2402.08679",
    "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability",
    "url": "http://arxiv.org/abs/2402.08679v1",
    "abstract": "Jailbreaks on large language models (LLMs) have recently received increasing\nattention. For a comprehensive assessment of LLM safety, it is essential to\nconsider jailbreaks with diverse attributes, such as contextual coherence and\nsentiment/stylistic variations, and hence it is beneficial to study\ncontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In this\npaper, we formally formulate the controllable attack generation problem, and\nbuild a novel connection between this problem and controllable text generation,\na well-explored topic of natural language processing. Based on this connection,\nwe adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a\nstate-of-the-art, highly efficient algorithm in controllable text generation,\nand introduce the COLD-Attack framework which unifies and automates the search\nof adversarial LLM attacks under a variety of control requirements such as\nfluency, stealthiness, sentiment, and left-right-coherence. The controllability\nenabled by COLD-Attack leads to diverse new jailbreak scenarios which not only\ncover the standard setting of generating fluent (suffix) attack with\ncontinuation constraint, but also allow us to address new controllable attack\nsettings such as revising a user query adversarially with paraphrasing\nconstraint, and inserting stealthy attacks in context with position constraint.\nOur extensive experiments on various LLMs (Llama-2, Mistral, Vicuna, Guanaco,\nGPT-3.5, and GPT-4) show COLD-Attack's broad applicability, strong\ncontrollability, high success rate, and attack transferability. Our code is\navailable at https://github.com/Yu-Fangxu/COLD-Attack."
  },
  {
    "arxiv_id": "2402.08473",
    "title": "Intriguing Differences Between Zero-Shot and Systematic Evaluations of Vision-Language Transformer Models",
    "url": "http://arxiv.org/abs/2402.08473v1",
    "abstract": "Transformer-based models have dominated natural language processing and other\nareas in the last few years due to their superior (zero-shot) performance on\nbenchmark datasets. However, these models are poorly understood due to their\ncomplexity and size. While probing-based methods are widely used to understand\nspecific properties, the structures of the representation space are not\nsystematically characterized; consequently, it is unclear how such models\ngeneralize and overgeneralize to new inputs beyond datasets. In this paper,\nbased on a new gradient descent optimization method, we are able to explore the\nembedding space of a commonly used vision-language model. Using the Imagenette\ndataset, we show that while the model achieves over 99\\% zero-shot\nclassification performance, it fails systematic evaluations completely. Using a\nlinear approximation, we provide a framework to explain the striking\ndifferences. We have also obtained similar results using a different model to\nsupport that our results are applicable to other transformer models with\ncontinuous inputs. We also propose a robust way to detect the modified images."
  },
  {
    "arxiv_id": "2402.08360",
    "title": "Visual Question Answering Instruction: Unlocking Multimodal Large Language Model To Domain-Specific Visual Multitasks",
    "url": "http://arxiv.org/abs/2402.08360v1",
    "abstract": "Having revolutionized natural language processing (NLP) applications, large\nlanguage models (LLMs) are expanding into the realm of multimodal inputs. Owing\nto their ability to interpret images, multimodal LLMs (MLLMs) have been\nprimarily used for vision-language tasks. Currently, MLLMs have not yet been\nextended for domain-specific visual tasks, which require a more explicit\nunderstanding of visual information. We developed a method to transform\ndomain-specific visual and vision-language datasets into a unified question\nanswering format called Visual Question Answering Instruction (VQA-IN), thereby\nextending MLLM to domain-specific tasks. The VQA-IN was applied to train\nmultiple MLLM architectures using smaller versions of LLMs (sLLMs). The\nexperimental results indicated that the proposed method achieved a high score\nmetric on domainspecific visual tasks while also maintaining its performance on\nvision-language tasks in a multitask manner."
  },
  {
    "arxiv_id": "2402.09391",
    "title": "LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset",
    "url": "http://arxiv.org/abs/2402.09391v1",
    "abstract": "Chemistry plays a crucial role in many domains, such as drug discovery and\nmaterial science. While large language models (LLMs) such as GPT-4 exhibit\nremarkable capabilities on natural language processing tasks, existing research\nindicates that their performance on chemistry tasks is discouragingly low. In\nthis paper, however, we demonstrate that our developed LLMs can achieve very\nstrong results on a comprehensive set of chemistry tasks, outperforming the\nmost advanced GPT-4 and Claude 3 Opus by a substantial margin. To accomplish\nthis, we propose SMolInstruct, a large-scale, comprehensive, and high-quality\ndataset for instruction tuning. It contains 14 selected chemistry tasks and\nover three million samples, laying a solid foundation for training and\nevaluating LLMs for chemistry. Using SMolInstruct, we fine-tune a set of\nopen-source LLMs, among which, we find that Mistral serves as the best base\nmodel for chemistry tasks. Our analysis further demonstrates the critical role\nof the proposed dataset in driving the performance improvements."
  },
  {
    "arxiv_id": "2402.09282",
    "title": "Leveraging Large Language Models for Enhanced NLP Task Performance through Knowledge Distillation and Optimized Training Strategies",
    "url": "http://arxiv.org/abs/2402.09282v1",
    "abstract": "Emerging Large Language Models (LLMs) like GPT-4 have revolutionized Natural\nLanguage Processing (NLP), showing potential in traditional tasks such as Named\nEntity Recognition (NER). Our study explores a three-phase training strategy\nthat harnesses GPT-4's capabilities to enhance the BERT model's performance on\nNER. Initially, GPT-4 annotates a subset of the CONLL2003 and additional BBC\ndataset without fine-tuning. We then train BERT using a mix of original and\nLLM-annotated data, analyzing the efficacy of LLM annotations against\ntraditional methods. The second phase involves comparative experiments with\ndifferent training regimens, assessing the synergy between distilled and\noriginal data. We observe that sequential strategies, particularly a simple mix\nof training first with distilled data followed by original data, significantly\nboost performance. In the third phase, we investigate various data blending\ntechniques, including sigmoid and power decay functions, to optimize the\ntraining process further. Our results indicate that a strategic mix of\ndistilled and original data markedly elevates the NER capabilities of BERT. Our\napproach presents a scalable methodology that reduces manual annotation costs\nand increases efficiency, making it especially pertinent in resource-limited\nand closed-network environments. The study concludes that while the 'Simple\nMix' strategy yields the best results, understanding its underlying mechanisms\nrequires further research. Future work will also focus on refining prompt\ndesigns and enhancing annotation selection processes, aiming to extend our\nmethodology to diverse NLP tasks."
  },
  {
    "arxiv_id": "2402.09269",
    "title": "Personalized Large Language Models",
    "url": "http://arxiv.org/abs/2402.09269v1",
    "abstract": "Large language models (LLMs) have significantly advanced Natural Language\nProcessing (NLP) tasks in recent years. However, their universal nature poses\nlimitations in scenarios requiring personalized responses, such as\nrecommendation systems and chatbots. This paper investigates methods to\npersonalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on\nsubjective tasks. Results demonstrate that personalized fine-tuning improves\nmodel reasoning compared to non-personalized models. Experiments on datasets\nfor emotion recognition and hate speech detection show consistent performance\ngains with personalized methods across different LLM architectures. These\nfindings underscore the importance of personalization for enhancing LLM\ncapabilities in subjective text perception tasks."
  },
  {
    "arxiv_id": "2402.09025",
    "title": "SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks",
    "url": "http://arxiv.org/abs/2402.09025v1",
    "abstract": "Large language models (LLMs) have proven to be highly effective across\nvarious natural language processing tasks. However, their large number of\nparameters poses significant challenges for practical deployment. Pruning, a\ntechnique aimed at reducing the size and complexity of LLMs, offers a potential\nsolution by removing redundant components from the network. Despite the promise\nof pruning, existing methods often struggle to achieve substantial end-to-end\nLLM inference speedup. In this paper, we introduce SLEB, a novel approach\ndesigned to streamline LLMs by eliminating redundant transformer blocks. We\nchoose the transformer block as the fundamental unit for pruning, because LLMs\nexhibit block-level redundancy with high similarity between the outputs of\nneighboring blocks. This choice allows us to effectively enhance the processing\nspeed of LLMs. Our experimental results demonstrate that SLEB outperforms\nprevious LLM pruning methods in accelerating LLM inference while also\nmaintaining superior perplexity and accuracy, making SLEB as a promising\ntechnique for enhancing the efficiency of LLMs. The code is available at:\nhttps://github.com/jiwonsong-dev/SLEB."
  },
  {
    "arxiv_id": "2402.08975",
    "title": "Research and application of Transformer based anomaly detection model: A literature review",
    "url": "http://arxiv.org/abs/2402.08975v1",
    "abstract": "Transformer, as one of the most advanced neural network models in Natural\nLanguage Processing (NLP), exhibits diverse applications in the field of\nanomaly detection. To inspire research on Transformer-based anomaly detection,\nthis review offers a fresh perspective on the concept of anomaly detection. We\nexplore the current challenges of anomaly detection and provide detailed\ninsights into the operating principles of Transformer and its variants in\nanomaly detection tasks. Additionally, we delineate various application\nscenarios for Transformer-based anomaly detection models and discuss the\ndatasets and evaluation metrics employed. Furthermore, this review highlights\nthe key challenges in Transformer-based anomaly detection research and conducts\na comprehensive analysis of future research trends in this domain. The review\nincludes an extensive compilation of over 100 core references related to\nTransformer-based anomaly detection. To the best of our knowledge, this is the\nfirst comprehensive review that focuses on the research related to Transformer\nin the context of anomaly detection. We hope that this paper can provide\ndetailed technical information to researchers interested in Transformer-based\nanomaly detection tasks."
  },
  {
    "arxiv_id": "2402.08793",
    "title": "BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation",
    "url": "http://arxiv.org/abs/2402.08793v1",
    "abstract": "The accurate segmentation of medical images is critical for various\nhealthcare applications. Convolutional neural networks (CNNs), especially Fully\nConvolutional Networks (FCNs) like U-Net, have shown remarkable success in\nmedical image segmentation tasks. However, they have limitations in capturing\nglobal context and long-range relations, especially for objects with\nsignificant variations in shape, scale, and texture. While transformers have\nachieved state-of-the-art results in natural language processing and image\nrecognition, they face challenges in medical image segmentation due to image\nlocality and translational invariance issues. To address these challenges, this\npaper proposes an innovative U-shaped network called BEFUnet, which enhances\nthe fusion of body and edge information for precise medical image segmentation.\nThe BEFUnet comprises three main modules, including a novel Local\nCross-Attention Feature (LCAF) fusion module, a novel Double-Level Fusion (DLF)\nmodule, and dual-branch encoder. The dual-branch encoder consists of an edge\nencoder and a body encoder. The edge encoder employs PDC blocks for effective\nedge information extraction, while the body encoder uses the Swin Transformer\nto capture semantic information with global attention. The LCAF module\nefficiently fuses edge and body features by selectively performing local\ncross-attention on features that are spatially close between the two\nmodalities. This local approach significantly reduces computational complexity\ncompared to global cross-attention while ensuring accurate feature matching.\nBEFUnet demonstrates superior performance over existing methods across various\nevaluation metrics on medical image segmentation datasets."
  },
  {
    "arxiv_id": "2402.10198",
    "title": "Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention",
    "url": "http://arxiv.org/abs/2402.10198v1",
    "abstract": "Transformer-based architectures achieved breakthrough performance in natural\nlanguage processing and computer vision, yet they remain inferior to simpler\nlinear baselines in multivariate long-term forecasting. To better understand\nthis phenomenon, we start by studying a toy linear forecasting problem for\nwhich we show that transformers are incapable of converging to their true\nsolution despite their high expressive power. We further identify the attention\nof transformers as being responsible for this low generalization capacity.\nBuilding upon this insight, we propose a shallow lightweight transformer model\nthat successfully escapes bad local minima when optimized with sharpness-aware\noptimization. We empirically demonstrate that this result extends to all\ncommonly used real-world multivariate time series datasets. In particular,\nSAMformer surpasses current state-of-the-art methods and is on par with the\nbiggest foundation model MOIRAI while having significantly fewer parameters.\nThe code is available at https://github.com/romilbert/samformer."
  },
  {
    "arxiv_id": "2402.10118",
    "title": "Reusing Softmax Hardware Unit for GELU Computation in Transformers",
    "url": "http://arxiv.org/abs/2402.10118v1",
    "abstract": "Transformers have improved drastically the performance of natural language\nprocessing (NLP) and computer vision applications. The computation of\ntransformers involves matrix multiplications and non-linear activation\nfunctions such as softmax and GELU (Gaussion Error Linear Unit) that are\naccelerated directly in hardware. Currently, function evaluation is done\nseparately for each function and rarely allows for hardware reuse. To mitigate\nthis problem, in this work, we map the computation of GELU to a softmax\noperator. In this way, the efficient hardware units designed already for\nsoftmax can be reused for computing GELU as well. Computation of GELU can enjoy\nthe inherent vectorized nature of softmax and produce in parallel multiple GELU\noutcomes. Experimental results show that computing GELU via a pre-existing and\nincrementally modified softmax hardware unit (a) does not reduce the accuracy\nof representative NLP applications and (b) allows the reduction of the overall\nhardware area and power by 6.1% and 11.9%, respectively, on average."
  },
  {
    "arxiv_id": "2402.09977",
    "title": "Fast Vocabulary Transfer for Language Model Compression",
    "url": "http://arxiv.org/abs/2402.09977v1",
    "abstract": "Real-world business applications require a trade-off between language model\nperformance and size. We propose a new method for model compression that relies\non vocabulary transfer. We evaluate the method on various vertical domains and\ndownstream tasks. Our results indicate that vocabulary transfer can be\neffectively used in combination with other compression techniques, yielding a\nsignificant reduction in model size and inference time while marginally\ncompromising on performance."
  },
  {
    "arxiv_id": "2402.09874",
    "title": "Camouflage is all you need: Evaluating and Enhancing Language Model Robustness Against Camouflage Adversarial Attacks",
    "url": "http://arxiv.org/abs/2402.09874v1",
    "abstract": "Adversarial attacks represent a substantial challenge in Natural Language\nProcessing (NLP). This study undertakes a systematic exploration of this\nchallenge in two distinct phases: vulnerability evaluation and resilience\nenhancement of Transformer-based models under adversarial attacks.\n  In the evaluation phase, we assess the susceptibility of three Transformer\nconfigurations, encoder-decoder, encoder-only, and decoder-only setups, to\nadversarial attacks of escalating complexity across datasets containing\noffensive language and misinformation. Encoder-only models manifest a 14% and\n21% performance drop in offensive language detection and misinformation\ndetection tasks, respectively. Decoder-only models register a 16% decrease in\nboth tasks, while encoder-decoder models exhibit a maximum performance drop of\n14% and 26% in the respective tasks.\n  The resilience-enhancement phase employs adversarial training, integrating\npre-camouflaged and dynamically altered data. This approach effectively reduces\nthe performance drop in encoder-only models to an average of 5% in offensive\nlanguage detection and 2% in misinformation detection tasks. Decoder-only\nmodels, occasionally exceeding original performance, limit the performance drop\nto 7% and 2% in the respective tasks. Although not surpassing the original\nperformance, Encoder-decoder models can reduce the drop to an average of 6% and\n2% respectively.\n  Results suggest a trade-off between performance and robustness, with some\nmodels maintaining similar performance while gaining robustness. Our study and\nadversarial training techniques have been incorporated into an open-source tool\nfor generating camouflaged datasets. However, methodology effectiveness depends\non the specific camouflage technique and data encountered, emphasizing the need\nfor continued exploration."
  },
  {
    "arxiv_id": "2402.09844",
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "url": "http://arxiv.org/abs/2402.09844v1",
    "abstract": "The search for a general model that can operate seamlessly across multiple\ndomains remains a key goal in machine learning research. The prevailing\nmethodology in Reinforcement Learning (RL) typically limits models to a single\ntask within a unimodal framework, a limitation that contrasts with the broader\nvision of a versatile, multi-domain model. In this paper, we present Jack of\nAll Trades (JAT), a transformer-based model with a unique design optimized for\nhandling sequential decision-making tasks and multi-modal data types. The JAT\nmodel demonstrates its robust capabilities and versatility by achieving strong\nperformance on very different RL benchmarks, along with promising results on\nComputer Vision (CV) and Natural Language Processing (NLP) tasks, all using a\nsingle set of weights. The JAT model marks a significant step towards more\ngeneral, cross-domain AI model design, and notably, it is the first model of\nits kind to be fully open-sourced at https://huggingface.co/jat-project/jat,\nincluding a pioneering general-purpose dataset."
  },
  {
    "arxiv_id": "2402.09834",
    "title": "All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining",
    "url": "http://arxiv.org/abs/2402.09834v1",
    "abstract": "Large Language Models (LLMs) have revolutionized the fields of computer\nvision (CV) and natural language processing (NLP). One of the most notable\nadvancements of LLMs is that a single model is trained on vast and diverse\ndatasets spanning multiple domains -- a paradigm we term `All in One'. This\nmethodology empowers LLMs with super generalization capabilities, facilitating\nan encompassing comprehension of varied data distributions. Leveraging these\ncapabilities, a single LLM demonstrates remarkable versatility across a variety\nof domains -- a paradigm we term `One for All'. However, applying this idea to\nthe graph field remains a formidable challenge, with cross-domain pretraining\noften resulting in negative transfer. This issue is particularly important in\nfew-shot learning scenarios, where the paucity of training data necessitates\nthe incorporation of external knowledge sources. In response to this challenge,\nwe propose a novel approach called Graph COordinators for PrEtraining (GCOPE),\nthat harnesses the underlying commonalities across diverse graph datasets to\nenhance few-shot learning. Our novel methodology involves a unification\nframework that amalgamates disparate graph datasets during the pretraining\nphase to distill and transfer meaningful knowledge to target tasks. Extensive\nexperiments across multiple graph datasets demonstrate the superior efficacy of\nour approach. By successfully leveraging the synergistic potential of multiple\ngraph datasets for pretraining, our work stands as a pioneering contribution to\nthe realm of graph foundational model."
  },
  {
    "arxiv_id": "2402.10671",
    "title": "Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm",
    "url": "http://arxiv.org/abs/2402.10671v1",
    "abstract": "In-context learning of large-language models (LLMs) has achieved remarkable\nsuccess in the field of natural language processing, while extensive case\nstudies reveal that the single-step chain-of-thought prompting approach faces\nchallenges such as attention diffusion and inadequate performance in complex\ntasks like text-to-SQL. To improve the contextual learning capabilities of LLMs\nin text-to-SQL, a workflow paradigm method is proposed, aiming to enhance the\nattention and problem-solving scope of LLMs through decomposition.\nSpecifically, the information determination module for eliminating redundant\ninformation and the brand-new prompt structure based on problem classification\ngreatly enhance the model's attention. Additionally, the inclusion of\nself-correction and active learning modules greatly expands the problem-solving\nscope of LLMs, hence improving the upper limit of LLM-based approaches.\nExtensive experiments conducted on three datasets demonstrate that our approach\noutperforms other methods by a significant margin. About 2-3 percentage point\nimprovements compared to the existing baseline on the Spider Dev,\nSpider-Realistic, and Bird Dev datasets and new SOTA results on the Spider Test\ndataset are achieved. Our code is available on GitHub:\n\\url{https://github.com/FlyingFeather/DEA-SQL}."
  },
  {
    "arxiv_id": "2402.10644",
    "title": "Linear Transformers with Learnable Kernel Functions are Better In-Context Models",
    "url": "http://arxiv.org/abs/2402.10644v1",
    "abstract": "Advancing the frontier of subquadratic architectures for Language Models\n(LMs) is crucial in the rapidly evolving field of natural language processing.\nCurrent innovations, including State Space Models, were initially celebrated\nfor surpassing Transformer performance on language modeling tasks. However,\nthese models have revealed deficiencies in essential In-Context Learning\ncapabilities - a domain where the Transformer traditionally shines. The Based\nmodel emerged as a hybrid solution, blending a Linear Transformer with a kernel\ninspired by the Taylor expansion of exponential functions, augmented by\nconvolutional networks. Mirroring the Transformer's in-context adeptness, it\nbecame a strong contender in the field. In our work, we present a singular,\nelegant alteration to the Based kernel that amplifies its In-Context Learning\nabilities evaluated with the Multi-Query Associative Recall task and overall\nlanguage modeling process, as demonstrated on the Pile dataset."
  },
  {
    "arxiv_id": "2402.10631",
    "title": "BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation",
    "url": "http://arxiv.org/abs/2402.10631v1",
    "abstract": "The upscaling of Large Language Models (LLMs) has yielded impressive advances\nin natural language processing, yet it also poses significant deployment\nchallenges. Weight quantization has emerged as a widely embraced solution to\nreduce memory and computational demands. This paper introduces BitDistiller, a\nframework that synergizes Quantization-Aware Training (QAT) with Knowledge\nDistillation (KD) to boost the performance of LLMs at ultra-low precisions\n(sub-4-bit). Specifically, BitDistiller first incorporates a tailored\nasymmetric quantization and clipping technique to maximally preserve the\nfidelity of quantized weights, and then proposes a novel Confidence-Aware\nKullback-Leibler Divergence (CAKLD) objective, which is employed in a\nself-distillation manner to enable faster convergence and superior model\nperformance. Empirical evaluations demonstrate that BitDistiller significantly\nsurpasses existing methods in both 3-bit and 2-bit configurations on general\nlanguage understanding and complex reasoning benchmarks. Notably, BitDistiller\nis shown to be more cost-effective, demanding fewer data and training\nresources. The code is available at https://github.com/DD-DuDa/BitDistiller."
  },
  {
    "arxiv_id": "2402.10527",
    "title": "Zero-shot sampling of adversarial entities in biomedical question answering",
    "url": "http://arxiv.org/abs/2402.10527v1",
    "abstract": "The increasing depth of parametric domain knowledge in large language models\n(LLMs) is fueling their rapid deployment in real-world applications.\nUnderstanding model vulnerabilities in high-stakes and knowledge-intensive\ntasks is essential for quantifying the trustworthiness of model predictions and\nregulating their use. The recent discovery of named entities as adversarial\nexamples (i.e. adversarial entities) in natural language processing tasks\nraises questions about their potential impact on the knowledge robustness of\npre-trained and finetuned LLMs in high-stakes and specialized domains. We\nexamined the use of type-consistent entity substitution as a template for\ncollecting adversarial entities for billion-parameter LLMs with biomedical\nknowledge. To this end, we developed an embedding-space attack based on\npowerscaled distance-weighted sampling to assess the robustness of their\nbiomedical knowledge with a low query budget and controllable coverage. Our\nmethod has favorable query efficiency and scaling over alternative approaches\nbased on random sampling and blackbox gradient-guided search, which we\ndemonstrated for adversarial distractor generation in biomedical question\nanswering. Subsequent failure mode analysis uncovered two regimes of\nadversarial entities on the attack surface with distinct characteristics and we\nshowed that entity substitution attacks can manipulate token-wise Shapley value\nexplanations, which become deceptive in this setting. Our approach complements\nstandard evaluations for high-capacity models and the results highlight the\nbrittleness of domain knowledge in LLMs."
  },
  {
    "arxiv_id": "2402.12036",
    "title": "Language Model Adaptation to Specialized Domains through Selective Masking based on Genre and Topical Characteristics",
    "url": "http://arxiv.org/abs/2402.12036v1",
    "abstract": "Recent advances in pre-trained language modeling have facilitated significant\nprogress across various natural language processing (NLP) tasks. Word masking\nduring model training constitutes a pivotal component of language modeling in\narchitectures like BERT. However, the prevalent method of word masking relies\non random selection, potentially disregarding domain-specific linguistic\nattributes. In this article, we introduce an innovative masking approach\nleveraging genre and topicality information to tailor language models to\nspecialized domains. Our method incorporates a ranking process that prioritizes\nwords based on their significance, subsequently guiding the masking procedure.\nExperiments conducted using continual pre-training within the legal domain have\nunderscored the efficacy of our approach on the LegalGLUE benchmark in the\nEnglish language. Pre-trained language models and code are freely available for\nuse."
  },
  {
    "arxiv_id": "2402.12026",
    "title": "Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space",
    "url": "http://arxiv.org/abs/2402.12026v1",
    "abstract": "Despite the notable success of language models (LMs) in various natural\nlanguage processing (NLP) tasks, the reliability of LMs is susceptible to\nbackdoor attacks. Prior research attempts to mitigate backdoor learning while\ntraining the LMs on the poisoned dataset, yet struggles against complex\nbackdoor attacks in real-world scenarios. In this paper, we investigate the\nlearning mechanisms of backdoor LMs in the frequency space by Fourier analysis.\nOur findings indicate that the backdoor mapping presented on the poisoned\ndatasets exhibits a more discernible inclination towards lower frequency\ncompared to clean mapping, resulting in the faster convergence of backdoor\nmapping. To alleviate this dilemma, we propose Multi-Scale Low-Rank Adaptation\n(MuScleLoRA), which deploys multiple radial scalings in the frequency space\nwith low-rank adaptation to the target model and further aligns the gradients\nwhen updating parameters. Through downscaling in the frequency space,\nMuScleLoRA encourages the model to prioritize the learning of relatively\nhigh-frequency clean mapping, consequently mitigating backdoor learning.\nExperimental results demonstrate that MuScleLoRA outperforms baselines\nsignificantly. Notably, MuScleLoRA reduces the average success rate of diverse\nbackdoor attacks to below 15\\% across multiple datasets and generalizes to\nvarious backbone LMs, including BERT, RoBERTa, GPT2-XL, and Llama2. The codes\nare publicly available at https://github.com/ZrW00/MuScleLoRA."
  },
  {
    "arxiv_id": "2402.12025",
    "title": "Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?",
    "url": "http://arxiv.org/abs/2402.12025v1",
    "abstract": "The field of natural language processing (NLP) has recently witnessed a\ntransformative shift with the emergence of foundation models, particularly\nLarge Language Models (LLMs) that have revolutionized text-based NLP. This\nparadigm has extended to other modalities, including speech, where researchers\nare actively exploring the combination of Speech Foundation Models (SFMs) and\nLLMs into single, unified models capable of addressing multimodal tasks. Among\nsuch tasks, this paper focuses on speech-to-text translation (ST). By examining\nthe published papers on the topic, we propose a unified view of the\narchitectural solutions and training strategies presented so far, highlighting\nsimilarities and differences among them. Based on this examination, we not only\norganize the lessons learned but also show how diverse settings and evaluation\napproaches hinder the identification of the best-performing solution for each\narchitectural building block and training choice. Lastly, we outline\nrecommendations for future works on the topic aimed at better understanding the\nstrengths and weaknesses of the SFM+LLM solutions for ST."
  },
  {
    "arxiv_id": "2402.11960",
    "title": "DB-LLM: Accurate Dual-Binarization for Efficient LLMs",
    "url": "http://arxiv.org/abs/2402.11960v1",
    "abstract": "Large language models (LLMs) have significantly advanced the field of natural\nlanguage processing, while the expensive memory and computation consumption\nimpede their practical deployment. Quantization emerges as one of the most\neffective methods for improving the computational efficiency of LLMs. However,\nexisting ultra-low-bit quantization always causes severe accuracy drops. In\nthis paper, we empirically relieve the micro and macro characteristics of\nultra-low bit quantization and present a novel Dual-Binarization method for\nLLMs, namely DB-LLM. For the micro-level, we take both the accuracy advantage\nof 2-bit-width and the efficiency advantage of binarization into account,\nintroducing Flexible Dual Binarization (FDB). By splitting 2-bit quantized\nweights into two independent sets of binaries, FDB ensures the accuracy of\nrepresentations and introduces flexibility, utilizing the efficient bitwise\noperations of binarization while retaining the inherent high sparsity of\nultra-low bit quantization. For the macro-level, we find the distortion that\nexists in the prediction of LLM after quantization, which is specified as the\ndeviations related to the ambiguity of samples. We propose the Deviation-Aware\nDistillation (DAD) method, enabling the model to focus differently on various\nsamples. Comprehensive experiments show that our DB-LLM not only significantly\nsurpasses the current State-of-The-Art (SoTA) in ultra-low bit quantization\n(eg, perplexity decreased from 9.64 to 7.23), but also achieves an additional\n20\\% reduction in computational consumption compared to the SOTA method under\nthe same bit-width. Our code will be released soon."
  },
  {
    "arxiv_id": "2402.11883",
    "title": "InMD-X: Large Language Models for Internal Medicine Doctors",
    "url": "http://arxiv.org/abs/2402.11883v1",
    "abstract": "In this paper, we introduce InMD-X, a collection of multiple large language\nmodels specifically designed to cater to the unique characteristics and demands\nof Internal Medicine Doctors (IMD). InMD-X represents a groundbreaking\ndevelopment in natural language processing, offering a suite of language models\nfine-tuned for various aspects of the internal medicine field. These models\nencompass a wide range of medical sub-specialties, enabling IMDs to perform\nmore efficient and accurate research, diagnosis, and documentation. InMD-X's\nversatility and adaptability make it a valuable tool for improving the\nhealthcare industry, enhancing communication between healthcare professionals,\nand advancing medical research. Each model within InMD-X is meticulously\ntailored to address specific challenges faced by IMDs, ensuring the highest\nlevel of precision and comprehensiveness in clinical text analysis and decision\nsupport. This paper provides an overview of the design, development, and\nevaluation of InMD-X, showcasing its potential to revolutionize the way\ninternal medicine practitioners interact with medical data and information. We\npresent results from extensive testing, demonstrating the effectiveness and\npractical utility of InMD-X in real-world medical scenarios."
  },
  {
    "arxiv_id": "2402.13109",
    "title": "CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models",
    "url": "http://arxiv.org/abs/2402.13109v1",
    "abstract": "The advancement of large language models (LLMs) has enhanced the ability to\ngeneralize across a wide range of unseen natural language processing (NLP)\ntasks through instruction-following. Yet, their effectiveness often diminishes\nin low-resource languages like Chinese, exacerbated by biased evaluations from\ndata leakage, casting doubt on their true generalizability to new linguistic\nterritories. In response, we introduce the Chinese Instruction-Following\nBenchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of\nLLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000\ninput-output pairs, developed by native speakers to test complex reasoning and\nChinese cultural nuances across 20 categories. To mitigate data contamination,\nwe release only half of the dataset publicly, with the remainder kept private,\nand introduce diversified instructions to minimize score variance, totaling\n45,000 data instances. Our evaluation of 28 selected LLMs reveals a noticeable\nperformance gap, with the best model scoring only 52.9%, highlighting the\nlimitations of LLMs in less familiar language and task contexts. This work not\nonly uncovers the current limitations of LLMs in handling Chinese language\ntasks but also sets a new standard for future LLM generalizability research,\npushing towards the development of more adaptable, culturally informed, and\nlinguistically diverse models."
  },
  {
    "arxiv_id": "2402.12801",
    "title": "Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting",
    "url": "http://arxiv.org/abs/2402.12801v1",
    "abstract": "Large language models (LLMs) have become the preferred solution for many\nnatural language processing tasks. In low-resource environments such as\nspecialized domains, their few-shot capabilities are expected to deliver high\nperformance. Named Entity Recognition (NER) is a critical task in information\nextraction that is not covered in recent LLM benchmarks. There is a need for\nbetter understanding the performance of LLMs for NER in a variety of settings\nincluding languages other than English. This study aims to evaluate generative\nLLMs, employed through prompt engineering, for few-shot clinical NER. %from the\nperspective of F1 performance and environmental impact. We compare 13\nauto-regressive models using prompting and 16 masked models using fine-tuning\non 14 NER datasets covering English, French and Spanish. While prompt-based\nauto-regressive models achieve competitive F1 for general NER, they are\noutperformed within the clinical domain by lighter biLSTM-CRF taggers based on\nmasked models. Additionally, masked models exhibit lower environmental impact\ncompared to auto-regressive models. Findings are consistent across the three\nlanguages studied, which suggests that LLM prompting is not yet suited for NER\nproduction in the clinical domain."
  },
  {
    "arxiv_id": "2402.13887",
    "title": "Beyond Probabilities: Unveiling the Misalignment in Evaluating Large Language Models",
    "url": "http://arxiv.org/abs/2402.13887v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious applications, fundamentally reshaping the landscape of natural language\nprocessing (NLP) research. However, recent evaluation frameworks often rely on\nthe output probabilities of LLMs for predictions, primarily due to\ncomputational constraints, diverging from real-world LLM usage scenarios. While\nwidely employed, the efficacy of these probability-based evaluation strategies\nremains an open research question. This study aims to scrutinize the validity\nof such probability-based evaluation methods within the context of using LLMs\nfor Multiple Choice Questions (MCQs), highlighting their inherent limitations.\nOur empirical investigation reveals that the prevalent probability-based\nevaluation method inadequately aligns with generation-based prediction.\nFurthermore, current evaluation frameworks typically assess LLMs through\npredictive tasks based on output probabilities rather than directly generating\nresponses, owing to computational limitations. We illustrate that these\nprobability-based approaches do not effectively correspond with generative\npredictions. The outcomes of our study can enhance the understanding of LLM\nevaluation methodologies and provide insights for future research in this\ndomain."
  },
  {
    "arxiv_id": "2402.13823",
    "title": "Using Large Language Models for Natural Language Processing Tasks in Requirements Engineering: A Systematic Guideline",
    "url": "http://arxiv.org/abs/2402.13823v1",
    "abstract": "Large Language Models (LLMs) are the cornerstone in automating Requirements\nEngineering (RE) tasks, underpinning recent advancements in the field. Their\npre-trained comprehension of natural language is pivotal for effectively\ntailoring them to specific RE tasks. However, selecting an appropriate LLM from\na myriad of existing architectures and fine-tuning it to address the\nintricacies of a given task poses a significant challenge for researchers and\npractitioners in the RE domain. Utilizing LLMs effectively for NLP problems in\nRE necessitates a dual understanding: firstly, of the inner workings of LLMs,\nand secondly, of a systematic approach to selecting and adapting LLMs for\nNLP4RE tasks. This chapter aims to furnish readers with essential knowledge\nabout LLMs in its initial segment. Subsequently, it provides a comprehensive\nguideline tailored for students, researchers, and practitioners on harnessing\nLLMs to address their specific objectives. By offering insights into the\nworkings of LLMs and furnishing a practical guide, this chapter contributes\ntowards improving future research and applications leveraging LLMs for solving\nRE challenges."
  },
  {
    "arxiv_id": "2402.13669",
    "title": "Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning",
    "url": "http://arxiv.org/abs/2402.13669v1",
    "abstract": "The surge in Large Language Models (LLMs) has revolutionized natural language\nprocessing, but fine-tuning them for specific tasks often encounters challenges\nin balancing performance and preserving general instruction-following\nabilities. In this paper, we posit that the distribution gap between task\ndatasets and the LLMs serves as the primary underlying cause. To address the\nproblem, we introduce Self-Distillation Fine-Tuning (SDFT), a novel approach\nthat bridges the distribution gap by guiding fine-tuning with a distilled\ndataset generated by the model itself to match its original distribution.\nExperimental results on the Llama-2-chat model across various benchmarks\ndemonstrate that SDFT effectively mitigates catastrophic forgetting while\nachieving comparable or superior performance on downstream tasks compared to\nthe vanilla fine-tuning. Moreover, SDFT demonstrates the potential to maintain\nthe helpfulness and safety alignment of LLMs. Our code is available at\nhttps://github.com/sail-sg/sdft."
  },
  {
    "arxiv_id": "2402.13647",
    "title": "Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions",
    "url": "http://arxiv.org/abs/2402.13647v1",
    "abstract": "Unsupervised Text Style Transfer (UTST) has emerged as a critical task within\nthe domain of Natural Language Processing (NLP), aiming to transfer one\nstylistic aspect of a sentence into another style without changing its\nsemantics, syntax, or other attributes. This task is especially challenging\ngiven the intrinsic lack of parallel text pairings. Among existing methods for\nUTST tasks, attention masking approach and Large Language Models (LLMs) are\ndeemed as two pioneering methods. However, they have shortcomings in generating\nunsmooth sentences and changing the original contents, respectively. In this\npaper, we investigate if we can combine these two methods effectively. We\npropose four ways of interactions, that are pipeline framework with tuned\norders; knowledge distillation from LLMs to attention masking model; in-context\nlearning with constructed parallel examples. We empirically show these\nmulti-way interactions can improve the baselines in certain perspective of\nstyle strength, content preservation and text fluency. Experiments also\ndemonstrate that simply conducting prompting followed by attention\nmasking-based revision can consistently surpass the other systems, including\nsupervised text style transfer systems. On Yelp-clean and Amazon-clean\ndatasets, it improves the previously best mean metric by 0.5 and 3.0 absolute\npercentages respectively, and achieves new SOTA results."
  },
  {
    "arxiv_id": "2402.14558",
    "title": "LLMs with Industrial Lens: Deciphering the Challenges and Prospects -- A Survey",
    "url": "http://arxiv.org/abs/2402.14558v1",
    "abstract": "Large language models (LLMs) have become the secret ingredient driving\nnumerous industrial applications, showcasing their remarkable versatility\nacross a diverse spectrum of tasks. From natural language processing and\nsentiment analysis to content generation and personalized recommendations,\ntheir unparalleled adaptability has facilitated widespread adoption across\nindustries. This transformative shift driven by LLMs underscores the need to\nexplore the underlying associated challenges and avenues for enhancement in\ntheir utilization. In this paper, our objective is to unravel and evaluate the\nobstacles and opportunities inherent in leveraging LLMs within an industrial\ncontext. To this end, we conduct a survey involving a group of industry\npractitioners, develop four research questions derived from the insights\ngathered, and examine 68 industry papers to address these questions and derive\nmeaningful conclusions."
  },
  {
    "arxiv_id": "2402.14531",
    "title": "Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance",
    "url": "http://arxiv.org/abs/2402.14531v1",
    "abstract": "We investigate the impact of politeness levels in prompts on the performance\nof large language models (LLMs). Polite language in human communications often\ngarners more compliance and effectiveness, while rudeness can cause aversion,\nimpacting response quality. We consider that LLMs mirror human communication\ntraits, suggesting they align with human cultural norms. We assess the impact\nof politeness in prompts on LLMs across English, Chinese, and Japanese tasks.\nWe observed that impolite prompts often result in poor performance, but overly\npolite language does not guarantee better outcomes. The best politeness level\nis different according to the language. This phenomenon suggests that LLMs not\nonly reflect human behavior but are also influenced by language, particularly\nin different cultural contexts. Our findings highlight the need to factor in\npoliteness for cross-cultural natural language processing and LLM usage."
  },
  {
    "arxiv_id": "2402.14296",
    "title": "Mitigating Biases of Large Language Models in Stance Detection with Calibration",
    "url": "http://arxiv.org/abs/2402.14296v1",
    "abstract": "Stance detection is critical for understanding the underlying position or\nattitude expressed toward a topic. Large language models (LLMs) have\ndemonstrated significant advancements across various natural language\nprocessing tasks including stance detection, however, their performance in\nstance detection is limited by biases and spurious correlations inherent due to\ntheir data-driven nature. Our statistical experiment reveals that LLMs are\nprone to generate biased stances due to sentiment-stance spurious correlations\nand preference towards certain individuals and topics. Furthermore, the results\ndemonstrate a strong negative correlation between stance bias and stance\ndetection performance, underscoring the importance of mitigating bias to\nenhance the utility of LLMs in stance detection. Therefore, in this paper, we\npropose a Counterfactual Augmented Calibration Network (FACTUAL), which a novel\ncalibration network is devised to calibrate potential bias in the stance\nprediction of LLMs. Further, to address the challenge of effectively learning\nbias representations and the difficulty in the generalizability of debiasing,\nwe construct counterfactual augmented data. This approach enhances the\ncalibration network, facilitating the debiasing and out-of-domain\ngeneralization. Experimental results on in-target and zero-shot stance\ndetection tasks show that the proposed FACTUAL can effectively mitigate biases\nof LLMs, achieving state-of-the-art results."
  },
  {
    "arxiv_id": "2402.14293",
    "title": "Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education",
    "url": "http://arxiv.org/abs/2402.14293v1",
    "abstract": "In the domain of Natural Language Processing (NLP), Large Language Models\n(LLMs) have demonstrated promise in text-generation tasks. However, their\neducational applications, particularly for domain-specific queries, remain\nunderexplored. This study investigates LLMs' capabilities in educational\nscenarios, focusing on concept graph recovery and question-answering (QA). We\nassess LLMs' zero-shot performance in creating domain-specific concept graphs\nand introduce TutorQA, a new expert-verified NLP-focused benchmark for\nscientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA\npairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating\nconcept graphs with LLMs for answering diverse questions. Our results indicate\nthat LLMs' zero-shot concept graph recovery is competitive with supervised\nmethods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs\nachieve up to 26% F1 score enhancement. Moreover, human evaluation and analysis\nshow that CGLLM generates answers with more fine-grained concepts."
  },
  {
    "arxiv_id": "2402.14215",
    "title": "Swin3D++: Effective Multi-Source Pretraining for 3D Indoor Scene Understanding",
    "url": "http://arxiv.org/abs/2402.14215v1",
    "abstract": "Data diversity and abundance are essential for improving the performance and\ngeneralization of models in natural language processing and 2D vision. However,\n3D vision domain suffers from the lack of 3D data, and simply combining\nmultiple 3D datasets for pretraining a 3D backbone does not yield significant\nimprovement, due to the domain discrepancies among different 3D datasets that\nimpede effective feature learning. In this work, we identify the main sources\nof the domain discrepancies between 3D indoor scene datasets, and propose\nSwin3D++, an enhanced architecture based on Swin3D for efficient pretraining on\nmulti-source 3D point clouds. Swin3D++ introduces domain-specific mechanisms to\nSwin3D's modules to address domain discrepancies and enhance the network\ncapability on multi-source pretraining. Moreover, we devise a simple\nsource-augmentation strategy to increase the pretraining data scale and\nfacilitate supervised pretraining. We validate the effectiveness of our design,\nand demonstrate that Swin3D++ surpasses the state-of-the-art 3D pretraining\nmethods on typical indoor scene understanding tasks. Our code and models will\nbe released at https://github.com/microsoft/Swin3D"
  },
  {
    "arxiv_id": "2402.15478",
    "title": "Transformers are Expressive, But Are They Expressive Enough for Regression?",
    "url": "http://arxiv.org/abs/2402.15478v1",
    "abstract": "Transformers have become pivotal in Natural Language Processing,\ndemonstrating remarkable success in applications like Machine Translation and\nSummarization. Given their widespread adoption, several works have attempted to\nanalyze the expressivity of Transformers. Expressivity of a neural network is\nthe class of functions it can approximate. A neural network is fully expressive\nif it can act as a universal function approximator. We attempt to analyze the\nsame for Transformers. Contrary to existing claims, our findings reveal that\nTransformers struggle to reliably approximate smooth functions, relying on\npiecewise constant approximations with sizable intervals. The central question\nemerges as: ''Are Transformers truly Universal Function Approximators?'' To\naddress this, we conduct a thorough investigation, providing theoretical\ninsights and supporting evidence through experiments. Theoretically, we prove\nthat Transformer Encoders cannot approximate smooth functions. Experimentally,\nwe complement our theory and show that the full Transformer architecture cannot\napproximate smooth functions. By shedding light on these challenges, we\nadvocate a refined understanding of Transformers' capabilities. Code Link:\nhttps://github.com/swaroop-nath/transformer-expressivity."
  },
  {
    "arxiv_id": "2402.15404",
    "title": "United We Pretrain, Divided We Fail! Representation Learning for Time Series by Pretraining on 75 Datasets at Once",
    "url": "http://arxiv.org/abs/2402.15404v1",
    "abstract": "In natural language processing and vision, pretraining is utilized to learn\neffective representations. Unfortunately, the success of pretraining does not\neasily carry over to time series due to potential mismatch between sources and\ntarget. Actually, common belief is that multi-dataset pretraining does not work\nfor time series! Au contraire, we introduce a new self-supervised contrastive\npretraining approach to learn one encoding from many unlabeled and diverse time\nseries datasets, so that the single learned representation can then be reused\nin several target domains for, say, classification. Specifically, we propose\nthe XD-MixUp interpolation method and the Soft Interpolation Contextual\nContrasting (SICC) loss. Empirically, this outperforms both supervised training\nand other self-supervised pretraining methods when finetuning on low-data\nregimes. This disproves the common belief: We can actually learn from multiple\ntime series datasets, even from 75 at once."
  },
  {
    "arxiv_id": "2402.15202",
    "title": "Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models",
    "url": "http://arxiv.org/abs/2402.15202v1",
    "abstract": "Impressive results have been achieved in natural language processing (NLP)\ntasks through the training of large language models (LLMs). However, these\nmodels occasionally produce toxic content such as insults, threats, and\nprofanity in response to certain prompts, thereby constraining their practical\nutility. To tackle this issue, various finetuning-based and decoding-based\napproaches have been utilized to mitigate toxicity. However, these methods\ntypically necessitate additional costs such as high-quality training data or\nauxiliary models. In this paper, we propose fine-grained detoxification via\ninstance-level prefixes (FGDILP) to mitigate toxic text without additional\ncost. Specifically, FGDILP contrasts the contextualized representation in\nattention space using a positive prefix-prepended prompt against multiple\nnegative prefix-prepended prompts at the instance level. This allows for\nconstructing fine-grained subtoxicity vectors, which enables collaborative\ndetoxification by fusing them to correct the normal generation process when\nprovided with a raw prompt. We validate that FGDILP enables controlled text\ngeneration with regard to toxicity at both the utterance and context levels.\nOur method surpasses prompt-based baselines in detoxification, although at a\nslight cost to generation fluency and diversity."
  },
  {
    "arxiv_id": "2402.15010",
    "title": "How Important Is Tokenization in French Medical Masked Language Models?",
    "url": "http://arxiv.org/abs/2402.15010v1",
    "abstract": "Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods."
  },
  {
    "arxiv_id": "2402.16445",
    "title": "ProLLaMA: A Protein Large Language Model for Multi-Task Protein Language Processing",
    "url": "http://arxiv.org/abs/2402.16445v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable performance in multiple\nNatural Language Processing (NLP) tasks. Under the premise that protein\nsequences constitute the protein language, Protein Language Models(PLMs) have\nadvanced the field of protein engineering. However, as of now, unlike LLMs in\nNLP, PLMs cannot handle the protein understanding task and the protein\ngeneration task simultaneously in the Protein Language Processing (PLP) field.\nThis prompts us to delineate the inherent limitations in current PLMs: (i) the\nlack of natural language capabilities, (ii) insufficient instruction\nunderstanding, and (iii) high training resource demands. To address these\nchallenges, we introduce a training framework to transform any general LLM into\na PLM capable of handling multiple PLP tasks. To improve training efficiency,\nwe propose Protein Vocabulary Pruning (PVP) for general LLMs. We construct a\nmulti-task instruction dataset containing 13 million samples with superfamily\ninformation, facilitating better modeling of protein sequence-function\nlandscapes. Through these methods, we develop the ProLLaMA model, the first\nknown PLM to handle multiple PLP tasks simultaneously. Experiments show that\nProLLaMA achieves state-of-the-art results in the unconditional protein\nsequence generation task. In the controllable protein sequence generation task,\nProLLaMA can design novel proteins with desired functionalities. As for the\nprotein understanding task, ProLLaMA achieves a 62\\% exact match rate in\nsuperfamily prediction. Codes, model weights, and datasets are available at\n\\url{https://github.com/PKU-YuanGroup/ProLLaMA} and\n\\url{https://huggingface.co/GreatCaptainNemo}."
  },
  {
    "arxiv_id": "2402.16389",
    "title": "MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property",
    "url": "http://arxiv.org/abs/2402.16389v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nvarious natural language processing (NLP) tasks. However, there is limited\nunderstanding of how well LLMs perform in specific domains (e.g, the\nintellectual property (IP) domain). In this paper, we contribute a new\nbenchmark, the first Multilingual-oriented quiZ on Intellectual Property\n(MoZIP), for the evaluation of LLMs in the IP domain. The MoZIP benchmark\nincludes three challenging tasks: IP multiple-choice quiz (IPQuiz), IP question\nanswering (IPQA), and patent matching (PatentMatch). In addition, we also\ndevelop a new IP-oriented multilingual large language model (called MoZi),\nwhich is a BLOOMZ-based model that has been supervised fine-tuned with\nmultilingual IP-related text data. We evaluate our proposed MoZi model and four\nwell-known LLMs (i.e., BLOOMZ, BELLE, ChatGLM and ChatGPT) on the MoZIP\nbenchmark. Experimental results demonstrate that MoZi outperforms BLOOMZ, BELLE\nand ChatGLM by a noticeable margin, while it had lower scores compared with\nChatGPT. Notably, the performance of current LLMs on the MoZIP benchmark has\nmuch room for improvement, and even the most powerful ChatGPT does not reach\nthe passing level. Our source code, data, and models are available at\n\\url{https://github.com/AI-for-Science/MoZi}."
  },
  {
    "arxiv_id": "2402.16142",
    "title": "From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility",
    "url": "http://arxiv.org/abs/2402.16142v1",
    "abstract": "This groundbreaking study explores the expanse of Large Language Models\n(LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional\nEncoder Representations from Transformers (BERT) across varied domains ranging\nfrom technology, finance, healthcare to education. Despite their established\nprowess in Natural Language Processing (NLP), these LLMs have not been\nsystematically examined for their impact on domains such as fitness, and\nholistic well-being, urban planning, climate modelling as well as disaster\nmanagement. This review paper, in addition to furnishing a comprehensive\nanalysis of the vast expanse and extent of LLMs' utility in diverse domains,\nrecognizes the research gaps and realms where the potential of LLMs is yet to\nbe harnessed. This study uncovers innovative ways in which LLMs can leave a\nmark in the fields like fitness and wellbeing, urban planning, climate\nmodelling and disaster response which could inspire future researches and\napplications in the said avenues."
  },
  {
    "arxiv_id": "2402.15862",
    "title": "SportQA: A Benchmark for Sports Understanding in Large Language Models",
    "url": "http://arxiv.org/abs/2402.15862v1",
    "abstract": "A deep understanding of sports, a field rich in strategic and dynamic\ncontent, is crucial for advancing Natural Language Processing (NLP). This holds\nparticular significance in the context of evaluating and advancing Large\nLanguage Models (LLMs), given the existing gap in specialized benchmarks. To\nbridge this gap, we introduce SportQA, a novel benchmark specifically designed\nfor evaluating LLMs in the context of sports understanding. SportQA encompasses\nover 70,000 multiple-choice questions across three distinct difficulty levels,\neach targeting different aspects of sports knowledge from basic historical\nfacts to intricate, scenario-based reasoning tasks. We conducted a thorough\nevaluation of prevalent LLMs, mainly utilizing few-shot learning paradigms\nsupplemented by chain-of-thought (CoT) prompting. Our results reveal that while\nLLMs exhibit competent performance in basic sports knowledge, they struggle\nwith more complex, scenario-based sports reasoning, lagging behind human\nexpertise. The introduction of SportQA marks a significant step forward in NLP,\noffering a tool for assessing and enhancing sports understanding in LLMs."
  },
  {
    "arxiv_id": "2402.15833",
    "title": "Prompt Perturbation Consistency Learning for Robust Language Models",
    "url": "http://arxiv.org/abs/2402.15833v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on a\nnumber of natural language processing tasks, such as question answering and\ntext summarization. However, their performance on sequence labeling tasks such\nas intent classification and slot filling (IC-SF), which is a central component\nin personal assistant systems, lags significantly behind discriminative models.\nFurthermore, there is a lack of substantive research on the robustness of LLMs\nto various perturbations in the input prompts. The contributions of this paper\nare three-fold. First, we show that fine-tuning sufficiently large LLMs can\nproduce IC-SF performance comparable to discriminative models. Next, we\nsystematically analyze the performance deterioration of those fine-tuned models\ndue to three distinct yet relevant types of input perturbations - oronyms,\nsynonyms, and paraphrasing. Finally, we propose an efficient mitigation\napproach, Prompt Perturbation Consistency Learning (PPCL), which works by\nregularizing the divergence between losses from clean and perturbed samples.\nOur experiments demonstrate that PPCL can recover on average 59% and 69% of the\nperformance drop for IC and SF tasks, respectively. Furthermore, PPCL beats the\ndata augmentation approach while using ten times fewer augmented data samples."
  },
  {
    "arxiv_id": "2402.15818",
    "title": "Linguistic Intelligence in Large Language Models for Telecommunications",
    "url": "http://arxiv.org/abs/2402.15818v1",
    "abstract": "Large Language Models (LLMs) have emerged as a significant advancement in the\nfield of Natural Language Processing (NLP), demonstrating remarkable\ncapabilities in language generation and other language-centric tasks. Despite\ntheir evaluation across a multitude of analytical and reasoning tasks in\nvarious scientific domains, a comprehensive exploration of their knowledge and\nunderstanding within the realm of natural language tasks in the\ntelecommunications domain is still needed. This study, therefore, seeks to\nevaluate the knowledge and understanding capabilities of LLMs within this\ndomain. To achieve this, we conduct an exhaustive zero-shot evaluation of four\nprominent LLMs-Llama-2, Falcon, Mistral, and Zephyr. These models require fewer\nresources than ChatGPT, making them suitable for resource-constrained\nenvironments. Their performance is compared with state-of-the-art, fine-tuned\nmodels. To the best of our knowledge, this is the first work to extensively\nevaluate and compare the understanding of LLMs across multiple language-centric\ntasks in this domain. Our evaluation reveals that zero-shot LLMs can achieve\nperformance levels comparable to the current state-of-the-art fine-tuned\nmodels. This indicates that pretraining on extensive text corpora equips LLMs\nwith a degree of specialization, even within the telecommunications domain. We\nalso observe that no single LLM consistently outperforms others, and the\nperformance of different LLMs can fluctuate. Although their performance lags\nbehind fine-tuned models, our findings underscore the potential of LLMs as a\nvaluable resource for understanding various aspects of this field that lack\nlarge annotated data."
  },
  {
    "arxiv_id": "2402.15637",
    "title": "Addressing Order Sensitivity of In-Context Demonstration Examples in Causal Language Models",
    "url": "http://arxiv.org/abs/2402.15637v1",
    "abstract": "In-context learning has become a popular paradigm in natural language\nprocessing. However, its performance can be significantly influenced by the\norder of in-context demonstration examples. In this paper, we found that causal\nlanguage models (CausalLMs) are more sensitive to this order compared to prefix\nlanguage models (PrefixLMs). We attribute this phenomenon to the\nauto-regressive attention masks within CausalLMs, which restrict each token\nfrom accessing information from subsequent tokens. This results in different\nreceptive fields for samples at different positions, thereby leading to\nrepresentation disparities across positions. To tackle this challenge, we\nintroduce an unsupervised fine-tuning method, termed the Information-Augmented\nand Consistency-Enhanced approach. This approach utilizes contrastive learning\nto align representations of in-context examples across different positions and\nintroduces a consistency loss to ensure similar representations for inputs with\ndifferent permutations. This enhances the model's predictive consistency across\npermutations. Experimental results on five benchmarks suggest that our proposed\nmethod can reduce the sensitivity of CausalLMs to the order of in-context\nexamples and exhibit robust generalizability, particularly when demonstrations\nare sourced from a candidate pool different from that used in the training\nphase, or when the number of in-context examples differs from what is used\nduring training."
  },
  {
    "arxiv_id": "2402.17396",
    "title": "Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies",
    "url": "http://arxiv.org/abs/2402.17396v1",
    "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing thanks to their ability to reuse knowledge acquired on\nmassive text corpora on a wide variety of downstream tasks, with minimal (if\nany) tuning steps. At the same time, it has been repeatedly shown that LLMs\nlack systematic generalization, which allows to extrapolate the learned\nstatistical regularities outside the training distribution. In this work, we\noffer a systematic benchmarking of GPT-4, one of the most advanced LLMs\navailable, on three algorithmic tasks characterized by the possibility to\ncontrol the problem difficulty with two parameters. We compare the performance\nof GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the\nTransformer-Encoder architecture recently introduced to solve similar tasks,\nthe Neural Data Router. We find that the deployment of advanced prompting\ntechniques allows GPT-4 to reach superior accuracy on all tasks, demonstrating\nthat state-of-the-art LLMs constitute a very strong baseline also in\nchallenging tasks that require systematic generalization."
  },
  {
    "arxiv_id": "2402.17389",
    "title": "FairBelief - Assessing Harmful Beliefs in Language Models",
    "url": "http://arxiv.org/abs/2402.17389v1",
    "abstract": "Language Models (LMs) have been shown to inherit undesired biases that might\nhurt minorities and underrepresented groups if such systems were integrated\ninto real-world applications without careful fairness auditing. This paper\nproposes FairBelief, an analytical approach to capture and assess beliefs,\ni.e., propositions that an LM may embed with different degrees of confidence\nand that covertly influence its predictions. With FairBelief, we leverage\nprompting to study the behavior of several state-of-the-art LMs across\ndifferent previously neglected axes, such as model scale and likelihood,\nassessing predictions on a fairness dataset specifically designed to quantify\nLMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative\nassessment of the beliefs emitted by the models. We apply FairBelief to English\nLMs, revealing that, although these architectures enable high performances on\ndiverse natural language processing tasks, they show hurtful beliefs about\nspecific genders. Interestingly, training procedure and dataset, model scale,\nand architecture induce beliefs of different degrees of hurtfulness."
  },
  {
    "arxiv_id": "2402.18179",
    "title": "Challenges in Pre-Training Graph Neural Networks for Context-Based Fake News Detection: An Evaluation of Current Strategies and Resource Limitations",
    "url": "http://arxiv.org/abs/2402.18179v1",
    "abstract": "Pre-training of neural networks has recently revolutionized the field of\nNatural Language Processing (NLP) and has before demonstrated its effectiveness\nin computer vision. At the same time, advances around the detection of fake\nnews were mainly driven by the context-based paradigm, where different types of\nsignals (e.g. from social media) form graph-like structures that hold\ncontextual information apart from the news article to classify. We propose to\nmerge these two developments by applying pre-training of Graph Neural Networks\n(GNNs) in the domain of context-based fake news detection. Our experiments\nprovide an evaluation of different pre-training strategies for graph-based\nmisinformation detection and demonstrate that transfer learning does currently\nnot lead to significant improvements over training a model from scratch in the\ndomain. We argue that a major current issue is the lack of suitable large-scale\nresources that can be used for pre-training."
  },
  {
    "arxiv_id": "2402.18121",
    "title": "Saving the legacy of Hero Ibash: Evaluating Four Language Models for Aminoacian",
    "url": "http://arxiv.org/abs/2402.18121v1",
    "abstract": "This study assesses four cutting-edge language models in the underexplored\nAminoacian language. Through evaluation, it scrutinizes their adaptability,\neffectiveness, and limitations in text generation, semantic coherence, and\ncontextual understanding. Uncovering insights into these models' performance in\na low-resourced language, this research pioneers pathways to bridge linguistic\ngaps. By offering benchmarks and understanding challenges, it lays groundwork\nfor future advancements in natural language processing, aiming to elevate the\napplicability of language models in similar linguistic landscapes, marking a\nsignificant step toward inclusivity and progress in language technology."
  },
  {
    "arxiv_id": "2402.18041",
    "title": "Datasets for Large Language Models: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2402.18041v1",
    "abstract": "This paper embarks on an exploration into the Large Language Model (LLM)\ndatasets, which play a crucial role in the remarkable advancements of LLMs. The\ndatasets serve as the foundational infrastructure analogous to a root system\nthat sustains and nurtures the development of LLMs. Consequently, examination\nof these datasets emerges as a critical topic in research. In order to address\nthe current lack of a comprehensive overview and thorough analysis of LLM\ndatasets, and to gain insights into their current status and future trends,\nthis survey consolidates and categorizes the fundamental aspects of LLM\ndatasets from five perspectives: (1) Pre-training Corpora; (2) Instruction\nFine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5)\nTraditional Natural Language Processing (NLP) Datasets. The survey sheds light\non the prevailing challenges and points out potential avenues for future\ninvestigation. Additionally, a comprehensive review of the existing available\ndataset resources is also provided, including statistics from 444 datasets,\ncovering 8 language categories and spanning 32 domains. Information from 20\ndimensions is incorporated into the dataset statistics. The total data size\nsurveyed surpasses 774.5 TB for pre-training corpora and 700M instances for\nother datasets. We aim to present the entire landscape of LLM text datasets,\nserving as a comprehensive reference for researchers in this field and\ncontributing to future studies. Related resources are available at:\nhttps://github.com/lmmlzn/Awesome-LLMs-Datasets."
  },
  {
    "arxiv_id": "2402.17946",
    "title": "Gradient-Free Adaptive Global Pruning for Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2402.17946v1",
    "abstract": "The transformative impact of large language models (LLMs) like LLaMA and GPT\non natural language processing is countered by their prohibitive computational\ndemands. Pruning has emerged as a pivotal compression strategy, introducing\nsparsity to enhance both memory and computational efficiency. Yet, traditional\nglobal pruning is impractical for LLMs due to scalability issues, while local\npruning, despite its efficiency, leads to suboptimal solutions. Addressing\nthese challenges, we propose SparseLLM, a novel framework that redefines the\nglobal pruning process into manageable, coordinated subproblems, allowing for\nresource-efficient optimization with global optimality. SparseLLM's approach,\nwhich conceptualizes LLMs as a chain of modular functions and leverages\nauxiliary variables for problem decomposition, not only facilitates a pragmatic\napplication on LLMs but also demonstrates significant performance improvements,\nparticularly in high-sparsity regimes where it surpasses current\nstate-of-the-art methods."
  },
  {
    "arxiv_id": "2402.19155",
    "title": "Beyond Language Models: Byte Models are Digital World Simulators",
    "url": "http://arxiv.org/abs/2402.19155v1",
    "abstract": "Traditional deep learning often overlooks bytes, the basic units of the\ndigital world, where all forms of information and operations are encoded and\nmanipulated in binary format. Inspired by the success of next token prediction\nin natural language processing, we introduce bGPT, a model with next byte\nprediction to simulate the digital world. bGPT matches specialized models in\nperformance across various modalities, including text, audio, and images, and\noffers new possibilities for predicting, simulating, and diagnosing algorithm\nor hardware behaviour. It has almost flawlessly replicated the process of\nconverting symbolic music data, achieving a low error rate of 0.0011 bits per\nbyte in converting ABC notation to MIDI format. In addition, bGPT demonstrates\nexceptional capabilities in simulating CPU behaviour, with an accuracy\nexceeding 99.99% in executing various operations. Leveraging next byte\nprediction, models like bGPT can directly learn from vast binary data,\neffectively simulating the intricate patterns of the digital world."
  },
  {
    "arxiv_id": "2402.18700",
    "title": "Learning to Compress Prompt in Natural Language Formats",
    "url": "http://arxiv.org/abs/2402.18700v1",
    "abstract": "Large language models (LLMs) are great at processing multiple natural\nlanguage processing tasks, but their abilities are constrained by inferior\nperformance with long context, slow inference speed, and the high cost of\ncomputing the results. Deploying LLMs with precise and informative context\nhelps users process large-scale datasets more effectively and cost-efficiently.\nExisting works rely on compressing long prompt contexts into soft prompts.\nHowever, soft prompt compression encounters limitations in transferability\nacross different LLMs, especially API-based LLMs. To this end, this work aims\nto compress lengthy prompts in the form of natural language with LLM\ntransferability. This poses two challenges: (i) Natural Language (NL) prompts\nare incompatible with back-propagation, and (ii) NL prompts lack flexibility in\nimposing length constraints. In this work, we propose a Natural Language Prompt\nEncapsulation (Nano-Capsulator) framework compressing original prompts into NL\nformatted Capsule Prompt while maintaining the prompt utility and\ntransferability. Specifically, to tackle the first challenge, the\nNano-Capsulator is optimized by a reward function that interacts with the\nproposed semantics preserving loss. To address the second question, the\nNano-Capsulator is optimized by a reward function featuring length constraints.\nExperimental results demonstrate that the Capsule Prompt can reduce 81.4% of\nthe original length, decrease inference latency up to 4.5x, and save 80.1% of\nbudget overheads while providing transferability across diverse LLMs and\ndifferent datasets."
  },
  {
    "arxiv_id": "2402.18659",
    "title": "Large Language Models and Games: A Survey and Roadmap",
    "url": "http://arxiv.org/abs/2402.18659v1",
    "abstract": "Recent years have seen an explosive increase in research on large language\nmodels (LLMs), and accompanying public engagement on the topic. While starting\nas a niche area within natural language processing, LLMs have shown remarkable\npotential across a broad range of applications and domains, including games.\nThis paper surveys the current state of the art across the various applications\nof LLMs in and for games, and identifies the different roles LLMs can take\nwithin a game. Importantly, we discuss underexplored areas and promising\ndirections for future uses of LLMs in games and we reconcile the potential and\nlimitations of LLMs within the games domain. As the first comprehensive survey\nand roadmap at the intersection of LLMs and games, we are hopeful that this\npaper will serve as the basis for groundbreaking research and innovation in\nthis exciting new field."
  },
  {
    "arxiv_id": "2403.01342",
    "title": "LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems",
    "url": "http://arxiv.org/abs/2403.01342v1",
    "abstract": "In the rapidly evolving field of natural language processing, the translation\nof linguistic descriptions into mathematical formulation of optimization\nproblems presents a formidable challenge, demanding intricate understanding and\nprocessing capabilities from Large Language Models (LLMs). This study compares\nprominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and\none-shot settings for this task. Our findings show GPT-4's superior\nperformance, particularly in the one-shot scenario. A central part of this\nresearch is the introduction of `LM4OPT,' a progressive fine-tuning framework\nfor Llama-2-7b that utilizes noisy embeddings and specialized datasets.\nHowever, this research highlights a notable gap in the contextual understanding\ncapabilities of smaller models such as Llama-2-7b compared to larger\ncounterparts, especially in processing lengthy and complex input contexts. Our\nempirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4\nsurpasses the baseline performance established by previous research, achieving\nan F1-score of 0.63, solely based on the problem description in natural\nlanguage, and without relying on any additional named entity information.\nGPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These\nfindings not only benchmark the current capabilities of LLMs in a novel\napplication area but also lay the groundwork for future improvements in\nmathematical formulation of optimization problems from natural language input."
  },
  {
    "arxiv_id": "2403.01308",
    "title": "VBART: The Turkish LLM",
    "url": "http://arxiv.org/abs/2403.01308v1",
    "abstract": "We present VBART, the first Turkish sequence-to-sequence Large Language\nModels (LLMs) pre-trained on a large corpus from scratch. VBART are compact\nLLMs based on good ideas leveraged from BART and mBART models and come in two\nsizes, Large and XLarge. Fine-tuned VBART models surpass the prior\nstate-of-the-art results in abstractive text summarization, title generation,\ntext paraphrasing, question answering and question generation tasks. They allow\nfine-tuning for future text generation tasks and datasets, carving a new path\nfor Turkish Natural Language Processing (NLP) research. Our work shows that\nhaving a pre-trained LLM for Turkish outperforms up to 3x multilingual models,\nimproving existing results and providing efficient models for training and\ninference. Moreover, we show that our monolingual tokenizer is up to 11x more\nefficient than multilingual tokenizers. Last but not least, we introduce a\nmethod to enlarge an existing pre-trained LLM and question the relevancy of\nChinchilla Scaling Law to sequence-to-sequence masked language models. Our\nfine-tuned models, tokenizer and cleaned vngrs-web-corpus of 135 GB are\npublicly available at huggingface.co/vngrs-ai."
  },
  {
    "arxiv_id": "2403.01241",
    "title": "IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact",
    "url": "http://arxiv.org/abs/2403.01241v1",
    "abstract": "Large language models (LLMs) excel in natural language processing but demand\nintensive computation. To mitigate this, various quantization methods have been\nexplored, yet they compromise LLM performance. This paper unveils a previously\noverlooked type of outliers in LLMs. Such outliers are found to allocate most\nof the attention scores on initial tokens of input, termed as pivot tokens,\nwhich are crucial to the performance of quantized LLMs. Given that, we propose\nIntactKV to generate the KV cache of pivot tokens losslessly from the\nfull-precision model. The approach is simple and easy to combine with existing\nquantization solutions with no extra inference overhead. Besides, IntactKV can\nbe calibrated as additional LLM parameters to boost the quantized LLMs further\nwith minimal training costs. Mathematical analysis also proves that IntactKV\neffectively reduces the upper bound of quantization error. Empirical results\nshow that IntactKV brings consistent improvement over various quantization\nmethods across different LLMs and downstream tasks, leading to the new\nstate-of-the-art for LLM quantization. The codes are available at\nhttps://github.com/ruikangliu/IntactKV."
  },
  {
    "arxiv_id": "2403.01133",
    "title": "Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data",
    "url": "http://arxiv.org/abs/2403.01133v1",
    "abstract": "Traditional human-in-the-loop-based annotation for time-series data like\ninertial data often requires access to alternate modalities like video or audio\nfrom the environment. These alternate sources provide the necessary information\nto the human annotator, as the raw numeric data is often too obfuscated even\nfor an expert. However, this traditional approach has many concerns surrounding\noverall cost, efficiency, storage of additional modalities, time, scalability,\nand privacy. Interestingly, recent large language models (LLMs) are also\ntrained with vast amounts of publicly available alphanumeric data, which allows\nthem to comprehend and perform well on tasks beyond natural language\nprocessing. Naturally, this opens up a potential avenue to explore LLMs as\nvirtual annotators where the LLMs will be directly provided the raw sensor data\nfor annotation instead of relying on any alternate modality. Naturally, this\ncould mitigate the problems of the traditional human-in-the-loop approach.\nMotivated by this observation, we perform a detailed study in this paper to\nassess whether the state-of-the-art (SOTA) LLMs can be used as virtual\nannotators for labeling time-series physical sensing data. To perform this in a\nprincipled manner, we segregate the study into two major phases. In the first\nphase, we investigate the challenges an LLM like GPT-4 faces in comprehending\nraw sensor data. Considering the observations from phase 1, in the next phase,\nwe investigate the possibility of encoding the raw sensor data using SOTA SSL\napproaches and utilizing the projected time-series data to get annotations from\nthe LLM. Detailed evaluation with four benchmark HAR datasets shows that\nSSL-based encoding and metric-based guidance allow the LLM to make more\nreasonable decisions and provide accurate annotations without requiring\ncomputationally expensive fine-tuning or sophisticated prompt engineering."
  },
  {
    "arxiv_id": "2403.00277",
    "title": "Gender Bias in Large Language Models across Multiple Languages",
    "url": "http://arxiv.org/abs/2403.00277v1",
    "abstract": "With the growing deployment of large language models (LLMs) across various\napplications, assessing the influence of gender biases embedded in LLMs becomes\ncrucial. The topic of gender bias within the realm of natural language\nprocessing (NLP) has gained considerable focus, particularly in the context of\nEnglish. Nonetheless, the investigation of gender bias in languages other than\nEnglish is still relatively under-explored and insufficiently analyzed. In this\nwork, We examine gender bias in LLMs-generated outputs for different languages.\nWe use three measurements: 1) gender bias in selecting descriptive words given\nthe gender-related context. 2) gender bias in selecting gender-related pronouns\n(she/he) given the descriptive words. 3) gender bias in the topics of\nLLM-generated dialogues. We investigate the outputs of the GPT series of LLMs\nin various languages using our three measurement methods. Our findings revealed\nsignificant gender biases across all the languages we examined."
  },
  {
    "arxiv_id": "2403.02990",
    "title": "Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges",
    "url": "http://arxiv.org/abs/2403.02990v1",
    "abstract": "In the rapidly evolving field of large language models (LLMs), data\naugmentation (DA) has emerged as a pivotal technique for enhancing model\nperformance by diversifying training examples without the need for additional\ndata collection. This survey explores the transformative impact of LLMs on DA,\nparticularly addressing the unique challenges and opportunities they present in\nthe context of natural language processing (NLP) and beyond. From both data and\nlearning perspectives, we examine various strategies that utilize LLMs for data\naugmentation, including a novel exploration of learning paradigms where\nLLM-generated data is used for diverse forms of further training. Additionally,\nthis paper highlights the primary open challenges faced in this domain, ranging\nfrom controllable data augmentation to multi-modal data augmentation. This\nsurvey highlights a paradigm shift introduced by LLMs in DA, and aims to serve\nas a comprehensive guide for researchers and practitioners."
  },
  {
    "arxiv_id": "2403.02901",
    "title": "A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods",
    "url": "http://arxiv.org/abs/2403.02901v1",
    "abstract": "Automatic Text Summarization (ATS), utilizing Natural Language Processing\n(NLP) algorithms, aims to create concise and accurate summaries, thereby\nsignificantly reducing the human effort required in processing large volumes of\ntext. ATS has drawn considerable interest in both academic and industrial\ncircles. Many studies have been conducted in the past to survey ATS methods;\nhowever, they generally lack practicality for real-world implementations, as\nthey often categorize previous methods from a theoretical standpoint. Moreover,\nthe advent of Large Language Models (LLMs) has altered conventional ATS\nmethods. In this survey, we aim to 1) provide a comprehensive overview of ATS\nfrom a ``Process-Oriented Schema'' perspective, which is best aligned with\nreal-world implementations; 2) comprehensively review the latest LLM-based ATS\nworks; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in\nthe literature. To the best of our knowledge, this is the first survey to\nspecifically investigate LLM-based ATS methods."
  },
  {
    "arxiv_id": "2403.02760",
    "title": "Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations",
    "url": "http://arxiv.org/abs/2403.02760v1",
    "abstract": "With the boom of e-commerce and web applications, recommender systems have\nbecome an important part of our daily lives, providing personalized\nrecommendations based on the user's preferences. Although deep neural networks\n(DNNs) have made significant progress in improving recommendation systems by\nsimulating the interaction between users and items and incorporating their\ntextual information, these DNN-based approaches still have some limitations,\nsuch as the difficulty of effectively understanding users' interests and\ncapturing textual information. It is not possible to generalize to different\nseen/unseen recommendation scenarios and reason about their predictions. At the\nsame time, the emergence of large language models (LLMs), represented by\nChatGPT and GPT-4, has revolutionized the fields of natural language processing\n(NLP) and artificial intelligence (AI) due to their superior capabilities in\nthe basic tasks of language understanding and generation, and their impressive\ngeneralization and reasoning capabilities. As a result, recent research has\nsought to harness the power of LLM to improve recommendation systems. Given the\nrapid development of this research direction in the field of recommendation\nsystems, there is an urgent need for a systematic review of existing LLM-driven\nrecommendation systems for researchers and practitioners in related fields to\ngain insight into. More specifically, we first introduced a representative\napproach to learning user and item representations using LLM as a feature\nencoder. We then reviewed the latest advances in LLMs techniques for\ncollaborative filtering enhanced recommendation systems from the three\nparadigms of pre-training, fine-tuning, and prompting. Finally, we had a\ncomprehensive discussion on the future direction of this emerging field."
  },
  {
    "arxiv_id": "2403.02738",
    "title": "Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment",
    "url": "http://arxiv.org/abs/2403.02738v1",
    "abstract": "Despite the notable advancements of existing prompting methods, such as\nIn-Context Learning and Chain-of-Thought for Large Language Models (LLMs), they\nstill face challenges related to various biases. Traditional debiasing methods\nprimarily focus on the model training stage, including approaches based on data\naugmentation and reweighting, yet they struggle with the complex biases\ninherent in LLMs. To address such limitations, the causal relationship behind\nthe prompting methods is uncovered using a structural causal model, and a novel\ncausal prompting method based on front-door adjustment is proposed to\neffectively mitigate LLMs biases. In specific, causal intervention is achieved\nby designing the prompts without accessing the parameters and logits of LLMs.\nThe chain-of-thought generated by LLM is employed as the mediator variable and\nthe causal effect between input prompts and output answers is calculated\nthrough front-door adjustment to mitigate model biases. Moreover, to accurately\nrepresent the chain-of-thoughts and estimate the causal effects, contrastive\nlearning is used to fine-tune the encoder of chain-of-thought by aligning its\nspace with that of the LLM. Experimental results show that the proposed causal\nprompting approach achieves excellent performance across seven natural language\nprocessing datasets on both open-source and closed-source LLMs."
  },
  {
    "arxiv_id": "2403.02694",
    "title": "Privacy-Aware Semantic Cache for Large Language Models",
    "url": "http://arxiv.org/abs/2403.02694v1",
    "abstract": "Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%."
  },
  {
    "arxiv_id": "2403.02504",
    "title": "A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing",
    "url": "http://arxiv.org/abs/2403.02504v1",
    "abstract": "Given that natural language serves as the primary conduit for expressing\nthoughts and emotions, text analysis has become a key technique in\npsychological research. It enables the extraction of valuable insights from\nnatural language, facilitating endeavors like personality traits assessment,\nmental health monitoring, and sentiment analysis in interpersonal\ncommunications. In text analysis, existing studies often resort to either human\ncoding, which is time-consuming, using pre-built dictionaries, which often\nfails to cover all possible scenarios, or training models from scratch, which\nrequires large amounts of labeled data. In this tutorial, we introduce the\npretrain-finetune paradigm. The pretrain-finetune paradigm represents a\ntransformative approach in text analysis and natural language processing. This\nparadigm distinguishes itself through the use of large pretrained language\nmodels, demonstrating remarkable efficiency in finetuning tasks, even with\nlimited training data. This efficiency is especially beneficial for research in\nsocial sciences, where the number of annotated samples is often quite limited.\nOur tutorial offers a comprehensive introduction to the pretrain-finetune\nparadigm. We first delve into the fundamental concepts of pretraining and\nfinetuning, followed by practical exercises using real-world applications. We\ndemonstrate the application of the paradigm across various tasks, including\nmulti-class classification and regression. Emphasizing its efficacy and\nuser-friendliness, the tutorial aims to encourage broader adoption of this\nparadigm. To this end, we have provided open access to all our code and\ndatasets. The tutorial is highly beneficial across various psychology\ndisciplines, providing a comprehensive guide to employing text analysis in\ndiverse research settings."
  },
  {
    "arxiv_id": "2403.03920",
    "title": "Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts",
    "url": "http://arxiv.org/abs/2403.03920v1",
    "abstract": "This paper explores the transformative potential of computer-assisted textual\nanalysis in enhancing instructional quality through in-depth insights from\neducational artifacts. We integrate Richard Elmore's Instructional Core\nFramework to examine how artificial intelligence (AI) and machine learning (ML)\nmethods, particularly natural language processing (NLP), can analyze\neducational content, teacher discourse, and student responses to foster\ninstructional improvement. Through a comprehensive review and case studies\nwithin the Instructional Core Framework, we identify key areas where AI/ML\nintegration offers significant advantages, including teacher coaching, student\nsupport, and content development. We unveil patterns that indicate AI/ML not\nonly streamlines administrative tasks but also introduces novel pathways for\npersonalized learning, providing actionable feedback for educators and\ncontributing to a richer understanding of instructional dynamics. This paper\nemphasizes the importance of aligning AI/ML technologies with pedagogical goals\nto realize their full potential in educational settings, advocating for a\nbalanced approach that considers ethical considerations, data quality, and the\nintegration of human expertise."
  },
  {
    "arxiv_id": "2403.03737",
    "title": "Probabilistic Topic Modelling with Transformer Representations",
    "url": "http://arxiv.org/abs/2403.03737v1",
    "abstract": "Topic modelling was mostly dominated by Bayesian graphical models during the\nlast decade. With the rise of transformers in Natural Language Processing,\nhowever, several successful models that rely on straightforward clustering\napproaches in transformer-based embedding spaces have emerged and consolidated\nthe notion of topics as clusters of embedding vectors. We propose the\nTransformer-Representation Neural Topic Model (TNTM), which combines the\nbenefits of topic representations in transformer-based embedding spaces and\nprobabilistic modelling. Therefore, this approach unifies the powerful and\nversatile notion of topics based on transformer embeddings with fully\nprobabilistic modelling, as in models such as Latent Dirichlet Allocation\n(LDA). We utilize the variational autoencoder (VAE) framework for improved\ninference speed and modelling flexibility. Experimental results show that our\nproposed model achieves results on par with various state-of-the-art approaches\nin terms of embedding coherence while maintaining almost perfect topic\ndiversity. The corresponding source code is available at\nhttps://github.com/ArikReuter/TNTM."
  },
  {
    "arxiv_id": "2403.03558",
    "title": "Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem",
    "url": "http://arxiv.org/abs/2403.03558v1",
    "abstract": "Large language models (LLMs) are highly effective in various natural language\nprocessing (NLP) tasks. However, they are susceptible to producing unreliable\nconjectures in ambiguous contexts called hallucination. This paper presents a\nnew method for evaluating LLM hallucination in Question Answering (QA) based on\nthe unanswerable math word problem (MWP). To support this approach, we\ninnovatively develop a dataset called Unanswerable Math Word Problem (UMWP)\nwhich comprises 5200 questions across five categories. We developed an\nevaluation methodology combining text similarity and mathematical expression\ndetection to determine whether LLM considers the question unanswerable. The\nresults of extensive experiments conducted on 31 LLMs, including GPT-3,\nInstructGPT, LLaMA, and Claude, demonstrate that in-context learning and\nreinforcement learning with human feedback (RLHF) training significantly\nenhance the model's ability to avoid hallucination. We show that utilizing MWP\nis a reliable and effective approach to assess hallucination. Our code and data\nare available at https://github.com/Yuki-Asuuna/UMWP."
  },
  {
    "arxiv_id": "2403.05262",
    "title": "Debiasing Large Visual Language Models",
    "url": "http://arxiv.org/abs/2403.05262v1",
    "abstract": "In the realms of computer vision and natural language processing, Large\nVision-Language Models (LVLMs) have become indispensable tools, proficient in\ngenerating textual descriptions based on visual inputs. Despite their\nadvancements, our investigation reveals a noteworthy bias in the generated\ncontent, where the output is primarily influenced by the underlying Large\nLanguage Models (LLMs) prior rather than the input image. Our empirical\nexperiments underscore the persistence of this bias, as LVLMs often provide\nconfident answers even in the absence of relevant images or given incongruent\nvisual input. To rectify these biases and redirect the model's focus toward\nvision information, we introduce two simple, training-free strategies. Firstly,\nfor tasks such as classification or multi-choice question-answering (QA), we\npropose a ``calibration'' step through affine transformation to adjust the\noutput distribution. This ``Post-Hoc debias'' approach ensures uniform scores\nfor each answer when the image is absent, serving as an effective\nregularization technique to alleviate the influence of LLM priors. For more\nintricate open-ended generation tasks, we extend this method to ``Debias\nsampling'', drawing inspirations from contrastive decoding methods.\nFurthermore, our investigation sheds light on the instability of LVLMs across\nvarious decoding configurations. Through systematic exploration of different\nsettings, we significantly enhance performance, surpassing reported results and\nraising concerns about the fairness of existing evaluations. Comprehensive\nexperiments substantiate the effectiveness of our proposed strategies in\nmitigating biases. These strategies not only prove beneficial in minimizing\nhallucinations but also contribute to the generation of more helpful and\nprecise illustrations."
  },
  {
    "arxiv_id": "2403.05075",
    "title": "Benchmarking Large Language Models for Molecule Prediction Tasks",
    "url": "http://arxiv.org/abs/2403.05075v1",
    "abstract": "Large Language Models (LLMs) stand at the forefront of a number of Natural\nLanguage Processing (NLP) tasks. Despite the widespread adoption of LLMs in\nNLP, much of their potential in broader fields remains largely unexplored, and\nsignificant limitations persist in their design and implementation. Notably,\nLLMs struggle with structured data, such as graphs, and often falter when\ntasked with answering domain-specific questions requiring deep expertise, such\nas those in biology and chemistry. In this paper, we explore a fundamental\nquestion: Can LLMs effectively handle molecule prediction tasks? Rather than\npursuing top-tier performance, our goal is to assess how LLMs can contribute to\ndiverse molecule tasks. We identify several classification and regression\nprediction tasks across six standard molecule datasets. Subsequently, we\ncarefully design a set of prompts to query LLMs on these tasks and compare\ntheir performance with existing Machine Learning (ML) models, which include\ntext-based models and those specifically designed for analysing the geometric\nstructure of molecules. Our investigation reveals several key insights:\nFirstly, LLMs generally lag behind ML models in achieving competitive\nperformance on molecule tasks, particularly when compared to models adept at\ncapturing the geometric structure of molecules, highlighting the constrained\nability of LLMs to comprehend graph data. Secondly, LLMs show promise in\nenhancing the performance of ML models when used collaboratively. Lastly, we\nengage in a discourse regarding the challenges and promising avenues to harness\nLLMs for molecule prediction tasks. The code and models are available at\nhttps://github.com/zhiqiangzhongddu/LLMaMol."
  },
  {
    "arxiv_id": "2403.05065",
    "title": "Can we obtain significant success in RST discourse parsing by using Large Language Models?",
    "url": "http://arxiv.org/abs/2403.05065v1",
    "abstract": "Recently, decoder-only pre-trained large language models (LLMs), with several\ntens of billion parameters, have significantly impacted a wide range of natural\nlanguage processing (NLP) tasks. While encoder-only or encoder-decoder\npre-trained language models have already proved to be effective in discourse\nparsing, the extent to which LLMs can perform this task remains an open\nresearch question. Therefore, this paper explores how beneficial such LLMs are\nfor Rhetorical Structure Theory (RST) discourse parsing. Here, the parsing\nprocess for both fundamental top-down and bottom-up strategies is converted\ninto prompts, which LLMs can work with. We employ Llama 2 and fine-tune it with\nQLoRA, which has fewer parameters that can be tuned. Experimental results on\nthree benchmark datasets, RST-DT, Instr-DT, and the GUM corpus, demonstrate\nthat Llama 2 with 70 billion parameters in the bottom-up strategy obtained\nstate-of-the-art (SOTA) results with significant differences. Furthermore, our\nparsers demonstrated generalizability when evaluated on RST-DT, showing that,\nin spite of being trained with the GUM corpus, it obtained similar performances\nto those of existing parsers trained with RST-DT."
  },
  {
    "arxiv_id": "2403.06835",
    "title": "Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting",
    "url": "http://arxiv.org/abs/2403.06835v1",
    "abstract": "Data scarcity and privacy concerns limit the availability of high-quality\nmedical images for public use, which can be mitigated through medical image\nsynthesis. However, current medical image synthesis methods often struggle to\naccurately capture the complexity of detailed anatomical structures and\npathological conditions. To address these challenges, we propose a novel\nmedical image synthesis model that leverages fine-grained image-text alignment\nand anatomy-pathology prompts to generate highly detailed and accurate\nsynthetic medical images. Our method integrates advanced natural language\nprocessing techniques with image generative modeling, enabling precise\nalignment between descriptive text prompts and the synthesized images'\nanatomical and pathological details. The proposed approach consists of two key\ncomponents: an anatomy-pathology prompting module and a fine-grained\nalignment-based synthesis module. The anatomy-pathology prompting module\nautomatically generates descriptive prompts for high-quality medical images. To\nfurther synthesize high-quality medical images from the generated prompts, the\nfine-grained alignment-based synthesis module pre-defines a visual codebook for\nthe radiology dataset and performs fine-grained alignment between the codebook\nand generated prompts to obtain key patches as visual clues, facilitating\naccurate image synthesis. We validate the superiority of our method through\nexperiments on public chest X-ray datasets and demonstrate that our synthetic\nimages preserve accurate semantic information, making them valuable for various\nmedical applications."
  },
  {
    "arxiv_id": "2403.06765",
    "title": "ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model",
    "url": "http://arxiv.org/abs/2403.06765v1",
    "abstract": "The internet has brought both benefits and harms to society. A prime example\nof the latter is misinformation, including conspiracy theories, which flood the\nweb. Recent advances in natural language processing, particularly the emergence\nof large language models (LLMs), have improved the prospects of accurate\nmisinformation detection. However, most LLM-based approaches to conspiracy\ntheory detection focus only on binary classification and fail to account for\nthe important relationship between misinformation and affective features (i.e.,\nsentiment and emotions). Driven by a comprehensive analysis of conspiracy text\nthat reveals its distinctive affective features, we propose ConspEmoLLM, the\nfirst open-source LLM that integrates affective information and is able to\nperform diverse tasks relating to conspiracy theories. These tasks include not\nonly conspiracy theory detection, but also classification of theory type and\ndetection of related discussion (e.g., opinions towards theories). ConspEmoLLM\nis fine-tuned based on an emotion-oriented LLM using our novel ConDID dataset,\nwhich includes five tasks to support LLM instruction tuning and evaluation. We\ndemonstrate that when applied to these tasks, ConspEmoLLM largely outperforms\nseveral open-source general domain LLMs and ChatGPT, as well as an LLM that has\nbeen fine-tuned using ConDID, but which does not use affective features. This\nproject will be released on https://github.com/lzw108/ConspEmoLLM/."
  },
  {
    "arxiv_id": "2403.06354",
    "title": "Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages",
    "url": "http://arxiv.org/abs/2403.06354v1",
    "abstract": "Large Language Models (LLMs) like GPT-4 and LLaMA have shown incredible\nproficiency at natural language processing tasks and have even begun to excel\nat tasks across other modalities such as vision and audio. Despite their\nsuccess, LLMs often struggle to perform well on low-resource languages because\nthere is so little training data available. This shortcoming is especially\nprevalent with open source models. In this work, we explore training LLaMA-2 to\nspeak Amharic, a language which is spoken by over 50 million people world wide,\nbut has orders of magnitude less data available than languages like English. We\nemploy methods previously used for training LLMs on other languages with data\nscarcity, and use open source translation models to perform data augmentation\nand grow our dataset from millions of tokens to billions. We further enhance\nthe capabilities of our model by connecting an image encoder and training on a\ntranslated visual instruction tuning dataset in the same manner as LLaVA,\nresulting in a multimodal Amharic LLM that can understand images along with\ntext. We introduce an Amharic version of a popular benchmarking dataset to\nevaluate our work. Our models and dataset are open sourced and available on\nGitHub."
  },
  {
    "arxiv_id": "2403.06294",
    "title": "ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes",
    "url": "http://arxiv.org/abs/2403.06294v1",
    "abstract": "There are two main barriers to using large language models (LLMs) in clinical\nreasoning. Firstly, while LLMs exhibit significant promise in Natural Language\nProcessing (NLP) tasks, their performance in complex reasoning and planning\nfalls short of expectations. Secondly, LLMs use uninterpretable methods to make\nclinical decisions that are fundamentally different from the clinician's\ncognitive processes. This leads to user distrust. In this paper, we present a\nmulti-agent framework called ArgMed-Agents, which aims to enable LLM-based\nagents to make explainable clinical decision reasoning through interaction.\nArgMed-Agents performs self-argumentation iterations via Argumentation Scheme\nfor Clinical Discussion (a reasoning mechanism for modeling cognitive processes\nin clinical reasoning), and then constructs the argumentation process as a\ndirected graph representing conflicting relationships. Ultimately, use symbolic\nsolver to identify a series of rational and coherent arguments to support\ndecision. We construct a formal model of ArgMed-Agents and present conjectures\nfor theoretical guarantees. ArgMed-Agents enables LLMs to mimic the process of\nclinical argumentative reasoning by generating explanations of reasoning in a\nself-directed manner. The setup experiments show that ArgMed-Agents not only\nimproves accuracy in complex clinical decision reasoning problems compared to\nother prompt methods, but more importantly, it provides users with decision\nexplanations that increase their confidence."
  },
  {
    "arxiv_id": "2403.06126",
    "title": "In-context Prompt Learning for Test-time Vision Recognition with Frozen Vision-language Model",
    "url": "http://arxiv.org/abs/2403.06126v1",
    "abstract": "Current pre-trained vision-language models, such as CLIP, have demonstrated\nremarkable zero-shot generalization capabilities across various downstream\ntasks. However, their performance significantly degrades when test inputs\nexhibit different distributions. In this paper, we explore the concept of\ntest-time prompt tuning (TTPT), which facilitates the adaptation of the CLIP\nmodel to novel downstream tasks through a one-step unsupervised optimization\nthat involves only test samples. Inspired by in-context learning in natural\nlanguage processing (NLP), we propose In-Context Prompt Learning (InCPL) for\ntest-time visual recognition tasks, which empowers a pre-trained\nvision-language model with labeled examples as context information on\ndownstream task. Specifically, InCPL associates a new test sample with very few\nlabeled examples (sometimes just one) as context information, enabling reliable\nlabel estimation for the test sample and facilitating model adaptation. To\nachieve this, InCPL employs an efficient language-to-vision translator to\nexplore the textual prior information for visual prompt learning. Further, we\nintroduce a context-aware unsupervised loss to optimize visual prompts tailored\nto test samples. Finally, we design a cyclic learning strategy for visual and\ntextual prompts to ensure mutual synergy across different modalities. This\nenables a pre-trained, frozen CLIP model to adapt to any task using its learned\nadaptive prompt. Our method demonstrates superior performance and achieves\nstate-of-the-art results across various downstream datasets."
  },
  {
    "arxiv_id": "2403.07865",
    "title": "Exploring Safety Generalization Challenges of Large Language Models via Code",
    "url": "http://arxiv.org/abs/2403.07865v1",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has brought about\nremarkable generative capabilities but also raised concerns about their\npotential misuse. While strategies like supervised fine-tuning and\nreinforcement learning from human feedback have enhanced their safety, these\nmethods primarily focus on natural languages, which may not generalize to other\ndomains. This paper introduces CodeAttack, a framework that transforms natural\nlanguage inputs into code inputs, presenting a novel environment for testing\nthe safety generalization of LLMs. Our comprehensive studies on\nstate-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a\nnew and universal safety vulnerability of these models against code input:\nCodeAttack bypasses the safety guardrails of all models more than 80\\% of the\ntime. We find that a larger distribution gap between CodeAttack and natural\nlanguage leads to weaker safety generalization, such as encoding natural\nlanguage input with data structures. Furthermore, we give our hypotheses about\nthe success of CodeAttack: the misaligned bias acquired by LLMs during code\ntraining, prioritizing code completion over avoiding the potential safety risk.\nFinally, we analyze potential mitigation measures. These findings highlight new\nsafety risks in the code domain and the need for more robust safety alignment\nalgorithms to match the code capabilities of LLMs."
  },
  {
    "arxiv_id": "2403.07542",
    "title": "A Survey of Vision Transformers in Autonomous Driving: Current Trends and Future Directions",
    "url": "http://arxiv.org/abs/2403.07542v1",
    "abstract": "This survey explores the adaptation of visual transformer models in\nAutonomous Driving, a transition inspired by their success in Natural Language\nProcessing. Surpassing traditional Recurrent Neural Networks in tasks like\nsequential image processing and outperforming Convolutional Neural Networks in\nglobal context capture, as evidenced in complex scene recognition, Transformers\nare gaining traction in computer vision. These capabilities are crucial in\nAutonomous Driving for real-time, dynamic visual scene processing. Our survey\nprovides a comprehensive overview of Vision Transformer applications in\nAutonomous Driving, focusing on foundational concepts such as self-attention,\nmulti-head attention, and encoder-decoder architecture. We cover applications\nin object detection, segmentation, pedestrian detection, lane detection, and\nmore, comparing their architectural merits and limitations. The survey\nconcludes with future research directions, highlighting the growing role of\nVision Transformers in Autonomous Driving."
  },
  {
    "arxiv_id": "2403.07311",
    "title": "Knowledge Graph Large Language Model (KG-LLM) for Link Prediction",
    "url": "http://arxiv.org/abs/2403.07311v1",
    "abstract": "The task of multi-hop link prediction within knowledge graphs (KGs) stands as\na challenge in the field of knowledge graph analysis, as it requires the model\nto reason through and understand all intermediate connections before making a\nprediction. In this paper, we introduce the Knowledge Graph Large Language\nModel (KG-LLM), a novel framework that leverages large language models (LLMs)\nfor knowledge graph tasks. We first convert structured knowledge graph data\ninto natural language and then use these natural language prompts to fine-tune\nLLMs to enhance multi-hop link prediction in KGs. By converting the KG to\nnatural language prompts, our framework is designed to learn the latent\nrepresentations of entities and their interrelations. To show the efficacy of\nthe KG-LLM Framework, we fine-tune three leading LLMs within this framework,\nincluding Flan-T5, LLaMa2 and Gemma. Further, we explore the framework's\npotential to provide LLMs with zero-shot capabilities for handling previously\nunseen prompts. Experimental results show that KG-LLM significantly improves\nthe models' generalization capabilities, leading to more accurate predictions\nin unfamiliar scenarios."
  },
  {
    "arxiv_id": "2403.08481",
    "title": "SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks",
    "url": "http://arxiv.org/abs/2403.08481v1",
    "abstract": "Natural language processing models have experienced a significant upsurge in\nrecent years, with numerous applications being built upon them. Many of these\napplications require fine-tuning generic base models on customized, proprietary\ndatasets. This fine-tuning data is especially likely to contain personal or\nsensitive information about individuals, resulting in increased privacy risk.\nMembership inference attacks are the most commonly employed attack to assess\nthe privacy leakage of a machine learning model. However, limited research is\navailable on the factors that affect the vulnerability of language models to\nthis kind of attack, or on the applicability of different defense strategies in\nthe language domain. We provide the first systematic review of the\nvulnerability of fine-tuned large language models to membership inference\nattacks, the various factors that come into play, and the effectiveness of\ndifferent defense strategies. We find that some training methods provide\nsignificantly reduced privacy risk, with the combination of differential\nprivacy and low-rank adaptors achieving the best privacy protection against\nthese attacks."
  },
  {
    "arxiv_id": "2403.09606",
    "title": "Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2403.09606v1",
    "abstract": "Causal inference has shown potential in enhancing the predictive accuracy,\nfairness, robustness, and explainability of Natural Language Processing (NLP)\nmodels by capturing causal relationships among variables. The emergence of\ngenerative Large Language Models (LLMs) has significantly impacted various NLP\ndomains, particularly through their advanced reasoning capabilities. This\nsurvey focuses on evaluating and improving LLMs from a causal view in the\nfollowing areas: understanding and improving the LLMs' reasoning capacity,\naddressing fairness and safety issues in LLMs, complementing LLMs with\nexplanations, and handling multimodality. Meanwhile, LLMs' strong reasoning\ncapacities can in turn contribute to the field of causal inference by aiding\ncausal relationship discovery and causal effect estimations. This review\nexplores the interplay between causal inference frameworks and LLMs from both\nperspectives, emphasizing their collective potential to further the development\nof more advanced and equitable artificial intelligence systems."
  },
  {
    "arxiv_id": "2403.09369",
    "title": "PreConfig: A Pretrained Model for Automating Network Configuration",
    "url": "http://arxiv.org/abs/2403.09369v1",
    "abstract": "Manual network configuration automation (NCA) tools face significant\nchallenges in versatility and flexibility due to their reliance on extensive\ndomain expertise and manual design, limiting their adaptability to diverse\nscenarios and complex application needs. This paper introduces PreConfig, an\ninnovative NCA tool that leverages a pretrained language model for automating\nnetwork configuration tasks. PreConfig is designed to address the complexity\nand variety of NCA tasks by framing them as text-to-text transformation\nproblems, thus unifying the tasks of configuration generation, translation, and\nanalysis under a single, versatile model. Our approach overcomes existing\ntools' limitations by utilizing advances in natural language processing to\nautomatically comprehend and generate network configurations without extensive\nmanual re-engineering. We confront the challenges of integrating\ndomain-specific knowledge into pretrained models and the scarcity of\nsupervision data in the network configuration field. Our solution involves\nconstructing a specialized corpus and further pretraining on network\nconfiguration data, coupled with a novel data mining technique for generating\ntask supervision data. The proposed model demonstrates robustness in\nconfiguration generation, translation, and analysis, outperforming conventional\ntools in handling complex networking environments. The experimental results\nvalidate the effectiveness of PreConfig, establishing a new direction for\nautomating network configuration tasks with pretrained language models."
  },
  {
    "arxiv_id": "2403.09125",
    "title": "Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector",
    "url": "http://arxiv.org/abs/2403.09125v1",
    "abstract": "Large Language Models (LLMs) as chatbots have drawn remarkable attention\nthanks to their versatile capability in natural language processing as well as\nin a wide range of tasks. While there has been great enthusiasm towards\nadopting such foundational model-based artificial intelligence tools in all\nsectors possible, the capabilities and limitations of such LLMs in improving\nthe operation of the electric energy sector need to be explored, and this\narticle identifies fruitful directions in this regard. Key future research\ndirections include data collection systems for fine-tuning LLMs, embedding\npower system-specific tools in the LLMs, and retrieval augmented generation\n(RAG)-based knowledge pool to improve the quality of LLM responses and LLMs in\nsafety-critical use cases."
  },
  {
    "arxiv_id": "2403.08994",
    "title": "Ethos: Rectifying Language Models in Orthogonal Parameter Space",
    "url": "http://arxiv.org/abs/2403.08994v1",
    "abstract": "Language models (LMs) have greatly propelled the research on natural language\nprocessing. However, LMs also raise concerns regarding the generation of biased\nor toxic content and the potential disclosure of private information from the\ntraining dataset. In this work, we present a new efficient approach, Ethos,\nthat rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy\nleakage. Ethos is built on task arithmetic. However, unlike current task\narithmetic algorithms, Ethos distinguishes general beneficial and undesired\nknowledge when reconstructing task vectors. Specifically, Ethos first obtains a\nset of principal components from the pre-trained models using singular value\ndecomposition. Then, by projecting the task vector onto principal components,\nEthos identifies the principal components that encode general or undesired\nknowledge. Ethos performs negating using the task vector with undesired\nknowledge only, thereby minimizing collateral damage on general model utility.\nWe demonstrate the efficacy of our approach on three different tasks:\ndebiasing, detoxification, and memorization unlearning. Evaluations show Ethos\nis more effective in removing undesired knowledge and maintaining the overall\nmodel performance compared to current task arithmetic methods."
  },
  {
    "arxiv_id": "2403.10351",
    "title": "TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale",
    "url": "http://arxiv.org/abs/2403.10351v1",
    "abstract": "The advent of large language models (LLMs) has significantly advanced natural\nlanguage processing tasks like text summarization. However, their large size\nand computational demands, coupled with privacy concerns in data transmission,\nlimit their use in resource-constrained and privacy-centric settings. To\novercome this, we introduce TriSum, a framework for distilling LLMs' text\nsummarization abilities into a compact, local model. Initially, LLMs extract a\nset of aspect-triple rationales and summaries, which are refined using a\ndual-scoring method for quality. Next, a smaller local model is trained with\nthese tasks, employing a curriculum learning strategy that evolves from simple\nto complex tasks. Our method enhances local model performance on various\nbenchmarks (CNN/DailyMail, XSum, and ClinicalTrial), outperforming baselines by\n4.5%, 8.5%, and 7.4%, respectively. It also improves interpretability by\nproviding insights into the summarization rationale."
  },
  {
    "arxiv_id": "2403.09962",
    "title": "ViTCN: Vision Transformer Contrastive Network For Reasoning",
    "url": "http://arxiv.org/abs/2403.09962v1",
    "abstract": "Machine learning models have achieved significant milestones in various\ndomains, for example, computer vision models have an exceptional result in\nobject recognition, and in natural language processing, where Large Language\nModels (LLM) like GPT can start a conversation with human-like proficiency.\nHowever, abstract reasoning remains a challenge for these models, Can AI really\nthinking like a human? still be a question yet to be answered. Raven\nProgressive Matrices (RPM) is a metric designed to assess human reasoning\ncapabilities. It presents a series of eight images as a problem set, where the\nparticipant should try to discover the underlying rules among these images and\nselect the most appropriate image from eight possible options that best\ncompletes the sequence. This task always be used to test human reasoning\nabilities and IQ. Zhang et al proposed a dataset called RAVEN which can be used\nto test Machine Learning model abstract reasoning ability. In this paper, we\npurposed Vision Transformer Contrastive Network which build on previous work\nwith the Contrastive Perceptual Inference network (CoPiNet), which set a new\nbenchmark for permutationinvariant models Raven Progressive Matrices by\nincorporating contrast effects from psychology, cognition, and education, and\nextends this foundation by leveraging the cutting-edge Vision Transformer\narchitecture. This integration aims to further refine the machine ability to\nprocess and reason about spatial-temporal information from pixel-level inputs\nand global wise features on RAVEN dataset."
  },
  {
    "arxiv_id": "2403.09891",
    "title": "Fisher Mask Nodes for Language Model Merging",
    "url": "http://arxiv.org/abs/2403.09891v1",
    "abstract": "Fine-tuning pre-trained models provides significant advantages in downstream\nperformance. The ubiquitous nature of pre-trained models such as BERT and its\nderivatives in natural language processing has also led to a proliferation of\ntask-specific fine-tuned models. As these models typically only perform one\ntask well, additional training or ensembling is required in multi-task\nscenarios. The growing field of model merging provides a solution, dealing with\nthe challenge of combining multiple task-specific models into a single\nmulti-task model. In this study, we introduce a novel model merging method for\nTransformers, combining insights from previous work in Fisher-weighted\naveraging and the use of Fisher information in model pruning. Utilizing the\nFisher information of mask nodes within the Transformer architecture, we devise\na computationally efficient weighted-averaging scheme. Our method exhibits a\nregular and significant performance increase across various models in the BERT\nfamily, outperforming full-scale Fisher-weighted averaging in a fraction of the\ncomputational cost, with baseline performance improvements of up to +6.5 and a\nspeedup between 57.4x and 321.7x across models. Our results prove the potential\nof our method in current multi-task learning environments and suggest its\nscalability and adaptability to new model architectures and learning scenarios."
  },
  {
    "arxiv_id": "2403.09832",
    "title": "Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks",
    "url": "http://arxiv.org/abs/2403.09832v1",
    "abstract": "Large Language Models (LLMs) are increasingly becoming the preferred\nfoundation platforms for many Natural Language Processing tasks such as Machine\nTranslation, owing to their quality often comparable to or better than\ntask-specific models, and the simplicity of specifying the task through natural\nlanguage instructions or in-context examples. Their generality, however, opens\nthem up to subversion by end users who may embed into their requests\ninstructions that cause the model to behave in unauthorized and possibly unsafe\nways. In this work we study these Prompt Injection Attacks (PIAs) on multiple\nfamilies of LLMs on a Machine Translation task, focusing on the effects of\nmodel size on the attack success rates. We introduce a new benchmark data set\nand we discover that on multiple language pairs and injected prompts written in\nEnglish, larger models under certain conditions may become more susceptible to\nsuccessful attacks, an instance of the Inverse Scaling phenomenon (McKenzie et\nal., 2023). To our knowledge, this is the first work to study non-trivial LLM\nscaling behaviour in a multi-lingual setting."
  },
  {
    "arxiv_id": "2403.11130",
    "title": "Exploring Tokenization Strategies and Vocabulary Sizes for Enhanced Arabic Language Models",
    "url": "http://arxiv.org/abs/2403.11130v1",
    "abstract": "This paper presents a comprehensive examination of the impact of tokenization\nstrategies and vocabulary sizes on the performance of Arabic language models in\ndownstream natural language processing tasks. Our investigation focused on the\neffectiveness of four tokenizers across various tasks, including News\nClassification, Hate Speech Detection, Sentiment Analysis, and Natural Language\nInference. Leveraging a diverse set of vocabulary sizes, we scrutinize the\nintricate interplay between tokenization approaches and model performance. The\nresults reveal that Byte Pair Encoding (BPE) with Farasa outperforms other\nstrategies in multiple tasks, underscoring the significance of morphological\nanalysis in capturing the nuances of the Arabic language. However, challenges\narise in sentiment analysis, where dialect specific segmentation issues impact\nmodel efficiency. Computational efficiency analysis demonstrates the stability\nof BPE with Farasa, suggesting its practical viability. Our study uncovers\nlimited impacts of vocabulary size on model performance while keeping the model\nsize unchanged. This is challenging the established beliefs about the\nrelationship between vocabulary, model size, and downstream tasks, emphasizing\nthe need for the study of models' size and their corresponding vocabulary size\nto generalize across domains and mitigate biases, particularly in dialect based\ndatasets. Paper's recommendations include refining tokenization strategies to\naddress dialect challenges, enhancing model robustness across diverse\nlinguistic contexts, and expanding datasets to encompass the rich dialect based\nArabic. This work not only advances our understanding of Arabic language models\nbut also lays the foundation for responsible and ethical developments in\nnatural language processing technologies tailored to the intricacies of the\nArabic language."
  },
  {
    "arxiv_id": "2403.10854",
    "title": "A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment",
    "url": "http://arxiv.org/abs/2403.10854v1",
    "abstract": "While Multimodal Large Language Models (MLLMs) have experienced significant\nadvancement in visual understanding and reasoning, their potential to serve as\npowerful, flexible, interpretable, and text-driven models for Image Quality\nAssessment (IQA) remains largely unexplored. In this paper, we conduct a\ncomprehensive and systematic study of prompting MLLMs for IQA. We first\ninvestigate nine prompting systems for MLLMs as the combinations of three\nstandardized testing procedures in psychophysics (i.e., the single-stimulus,\ndouble-stimulus, and multiple-stimulus methods) and three popular prompting\nstrategies in natural language processing (i.e., the standard, in-context, and\nchain-of-thought prompting). We then present a difficult sample selection\nprocedure, taking into account sample diversity and uncertainty, to further\nchallenge MLLMs equipped with the respective optimal prompting systems. We\nassess three open-source and one closed-source MLLMs on several visual\nattributes of image quality (e.g., structural and textural distortions,\ngeometric transformations, and color differences) in both full-reference and\nno-reference scenarios. Experimental results show that only the closed-source\nGPT-4V provides a reasonable account for human perception of image quality, but\nis weak at discriminating fine-grained quality variations (e.g., color\ndifferences) and at comparing visual quality of multiple images, tasks humans\ncan perform effortlessly."
  },
  {
    "arxiv_id": "2403.10774",
    "title": "Detecting Bias in Large Language Models: Fine-tuned KcBERT",
    "url": "http://arxiv.org/abs/2403.10774v1",
    "abstract": "The rapid advancement of large language models (LLMs) has enabled natural\nlanguage processing capabilities similar to those of humans, and LLMs are being\nwidely utilized across various societal domains such as education and\nhealthcare. While the versatility of these models has increased, they have the\npotential to generate subjective and normative language, leading to\ndiscriminatory treatment or outcomes among social groups, especially due to\nonline offensive language. In this paper, we define such harm as societal bias\nand assess ethnic, gender, and racial biases in a model fine-tuned with Korean\ncomments using Bidirectional Encoder Representations from Transformers (KcBERT)\nand KOLD data through template-based Masked Language Modeling (MLM). To\nquantitatively evaluate biases, we employ LPBS and CBS metrics. Compared to\nKcBERT, the fine-tuned model shows a reduction in ethnic bias but demonstrates\nsignificant changes in gender and racial biases. Based on these results, we\npropose two methods to mitigate societal bias. Firstly, a data balancing\napproach during the pre-training phase adjusts the uniformity of data by\naligning the distribution of the occurrences of specific words and converting\nsurrounding harmful words into non-harmful words. Secondly, during the\nin-training phase, we apply Debiasing Regularization by adjusting dropout and\nregularization, confirming a decrease in training loss. Our contribution lies\nin demonstrating that societal bias exists in Korean language models due to\nlanguage-dependent characteristics."
  },
  {
    "arxiv_id": "2403.12918",
    "title": "Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts",
    "url": "http://arxiv.org/abs/2403.12918v1",
    "abstract": "Pretrained Language Models (PLMs) have advanced Natural Language Processing\n(NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses\nsignificant challenges such as instability and overfitting. Previous methods\ntackle these issues by finetuning a strategically chosen subnetwork on a\ndownstream task, while keeping the remaining weights fixed to the pretrained\nweights. However, they rely on a suboptimal criteria for sub-network selection,\nleading to suboptimal solutions. To address these limitations, we propose a\nregularization method based on attention-guided weight mixup for finetuning\nPLMs. Our approach represents each network weight as a mixup of task-specific\nweight and pretrained weight, controlled by a learnable attention parameter,\nproviding finer control over sub-network selection. Furthermore, we employ a\nbi-level optimization (BLO) based framework on two separate splits of the\ntraining dataset, improving generalization and combating overfitting. We\nvalidate the efficacy of our proposed method through extensive experiments,\ndemonstrating its superiority over previous methods, particularly in the\ncontext of finetuning PLMs on low-resource datasets."
  },
  {
    "arxiv_id": "2403.12809",
    "title": "Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models",
    "url": "http://arxiv.org/abs/2403.12809v1",
    "abstract": "In many real natural language processing application scenarios, practitioners\nnot only aim to maximize predictive performance but also seek faithful\nexplanations for the model predictions. Rationales and importance distribution\ngiven by feature attribution methods (FAs) provide insights into how different\nparts of the input contribute to a prediction. Previous studies have explored\nhow different factors affect faithfulness, mainly in the context of monolingual\nEnglish models. On the other hand, the differences in FA faithfulness between\nmultilingual and monolingual models have yet to be explored. Our extensive\nexperiments, covering five languages and five popular FAs, show that FA\nfaithfulness varies between multilingual and monolingual models. We find that\nthe larger the multilingual model, the less faithful the FAs are compared to\nits counterpart monolingual models.Our further analysis shows that the\nfaithfulness disparity is potentially driven by the differences between model\ntokenizers. Our code is available:\nhttps://github.com/casszhao/multilingual-faith."
  },
  {
    "arxiv_id": "2403.12503",
    "title": "Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices",
    "url": "http://arxiv.org/abs/2403.12503v1",
    "abstract": "Large language models (LLMs) have significantly transformed the landscape of\nNatural Language Processing (NLP). Their impact extends across a diverse\nspectrum of tasks, revolutionizing how we approach language understanding and\ngenerations. Nevertheless, alongside their remarkable utility, LLMs introduce\ncritical security and risk considerations. These challenges warrant careful\nexamination to ensure responsible deployment and safeguard against potential\nvulnerabilities. This research paper thoroughly investigates security and\nprivacy concerns related to LLMs from five thematic perspectives: security and\nprivacy concerns, vulnerabilities against adversarial attacks, potential harms\ncaused by misuses of LLMs, mitigation strategies to address these challenges\nwhile identifying limitations of current strategies. Lastly, the paper\nrecommends promising avenues for future research to enhance the security and\nrisk management of LLMs."
  },
  {
    "arxiv_id": "2403.12413",
    "title": "Third-Party Language Model Performance Prediction from Instruction",
    "url": "http://arxiv.org/abs/2403.12413v1",
    "abstract": "Language model-based instruction-following systems have lately shown\nincreasing performance on many benchmark tasks, demonstrating the capability of\nadapting to a broad variety of instructions. However, such systems are often\nnot designed to be transparent about their limitations; a user may easily\nprompt a model with an instruction without any idea of whether the responses\nshould be expected to be accurate, or if the system is even capable of\nperforming the task. We propose a third party performance prediction framework,\nwhere a separate model is trained to predict the metric resulting from\nevaluating an instruction-following system on a task while assuming access only\nto its inputs and outputs at inference time. We perform this analysis with a\nvariety of both open and closed instruction-following models as well as\nmultiple performance predictors, and examine the effect of various factors such\nas model size, number of training tasks, and prompt format. Our findings\nindicate that third-party performance prediction is very challenging, and much\nwork remains in developing predictors that can automatically reveal the\nlimitations of modern instruction-following natural language processing\nsystems."
  },
  {
    "arxiv_id": "2403.12393",
    "title": "Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open Domain Multi-Hop Question Answering",
    "url": "http://arxiv.org/abs/2403.12393v1",
    "abstract": "Open Domain Multi-Hop Question Answering (ODMHQA) plays a crucial role in\nNatural Language Processing (NLP) by aiming to answer complex questions through\nmulti-step reasoning over retrieved information from external knowledge\nsources. Recently, Large Language Models (LLMs) have demonstrated remarkable\nperformance in solving ODMHQA owing to their capabilities including planning,\nreasoning, and utilizing tools. However, LLMs may generate off-topic answers\nwhen attempting to solve ODMHQA, namely the generated answers are irrelevant to\nthe original questions. This issue of off-topic answers accounts for\napproximately one-third of incorrect answers, yet remains underexplored despite\nits significance. To alleviate this issue, we propose the\nDiscriminate->Re-Compose->Re- Solve->Re-Decompose (Dr3) mechanism.\nSpecifically, the Discriminator leverages the intrinsic capabilities of LLMs to\njudge whether the generated answers are off-topic. In cases where an off-topic\nanswer is detected, the Corrector performs step-wise revisions along the\nreversed reasoning chain (Re-Compose->Re-Solve->Re-Decompose) until the final\nanswer becomes on-topic. Experimental results on the HotpotQA and\n2WikiMultiHopQA datasets demonstrate that our Dr3 mechanism considerably\nreduces the occurrence of off-topic answers in ODMHQA by nearly 13%, improving\nthe performance in Exact Match (EM) by nearly 3% compared to the baseline\nmethod without the Dr3 mechanism."
  },
  {
    "arxiv_id": "2403.12392",
    "title": "AraPoemBERT: A Pretrained Language Model for Arabic Poetry Analysis",
    "url": "http://arxiv.org/abs/2403.12392v1",
    "abstract": "Arabic poetry, with its rich linguistic features and profound cultural\nsignificance, presents a unique challenge to the Natural Language Processing\n(NLP) field. The complexity of its structure and context necessitates advanced\ncomputational models for accurate analysis. In this paper, we introduce\nAraPoemBERT, an Arabic language model pretrained exclusively on Arabic poetry\ntext. To demonstrate the effectiveness of the proposed model, we compared\nAraPoemBERT with 5 different Arabic language models on various NLP tasks\nrelated to Arabic poetry. The new model outperformed all other models and\nachieved state-of-the-art results in most of the downstream tasks. AraPoemBERT\nachieved unprecedented accuracy in two out of three novel tasks: poet's gender\nclassification (99.34\\% accuracy), and poetry sub-meter classification (97.79\\%\naccuracy). In addition, the model achieved an accuracy score in poems' rhyme\nclassification (97.73\\% accuracy) which is almost equivalent to the best score\nreported in this study. Moreover, the proposed model significantly outperformed\nprevious work and other comparative models in the tasks of poems' sentiment\nanalysis, achieving an accuracy of 78.95\\%, and poetry meter classification\n(99.03\\% accuracy), while significantly expanding the scope of these two\nproblems. The dataset used in this study, contains more than 2.09 million\nverses collected from online sources, each associated with various attributes\nsuch as meter, sub-meter, poet, rhyme, and topic. The results demonstrate the\neffectiveness of the proposed model in understanding and analyzing Arabic\npoetry, achieving state-of-the-art results in several tasks and outperforming\nprevious works and other language models included in the study. AraPoemBERT\nmodel is publicly available on \\url{https://huggingface.co/faisalq}."
  },
  {
    "arxiv_id": "2403.12374",
    "title": "Improving Generalizability of Extracting Social Determinants of Health Using Large Language Models through Prompt-tuning",
    "url": "http://arxiv.org/abs/2403.12374v1",
    "abstract": "The progress in natural language processing (NLP) using large language models\n(LLMs) has greatly improved patient information extraction from clinical\nnarratives. However, most methods based on the fine-tuning strategy have\nlimited transfer learning ability for cross-domain applications. This study\nproposed a novel approach that employs a soft prompt-based learning\narchitecture, which introduces trainable prompts to guide LLMs toward desired\noutputs. We examined two types of LLM architectures, including encoder-only\nGatorTron and decoder-only GatorTronGPT, and evaluated their performance for\nthe extraction of social determinants of health (SDoH) using a\ncross-institution dataset from the 2022 n2c2 challenge and a cross-disease\ndataset from the University of Florida (UF) Health. The results show that\ndecoder-only LLMs with prompt tuning achieved better performance in\ncross-domain applications. GatorTronGPT achieved the best F1 scores for both\ndatasets, outperforming traditional fine-tuned GatorTron by 8.9% and 21.8% in a\ncross-institution setting, and 5.5% and 14.5% in a cross-disease setting."
  },
  {
    "arxiv_id": "2403.12297",
    "title": "Leveraging Large Language Models to Extract Information on Substance Use Disorder Severity from Clinical Notes: A Zero-shot Learning Approach",
    "url": "http://arxiv.org/abs/2403.12297v1",
    "abstract": "Substance use disorder (SUD) poses a major concern due to its detrimental\neffects on health and society. SUD identification and treatment depend on a\nvariety of factors such as severity, co-determinants (e.g., withdrawal\nsymptoms), and social determinants of health. Existing diagnostic coding\nsystems used by American insurance providers, like the International\nClassification of Diseases (ICD-10), lack granularity for certain diagnoses,\nbut clinicians will add this granularity (as that found within the Diagnostic\nand Statistical Manual of Mental Disorders classification or DSM-5) as\nsupplemental unstructured text in clinical notes. Traditional natural language\nprocessing (NLP) methods face limitations in accurately parsing such diverse\nclinical language. Large Language Models (LLMs) offer promise in overcoming\nthese challenges by adapting to diverse language patterns. This study\ninvestigates the application of LLMs for extracting severity-related\ninformation for various SUD diagnoses from clinical notes. We propose a\nworkflow employing zero-shot learning of LLMs with carefully crafted prompts\nand post-processing techniques. Through experimentation with Flan-T5, an\nopen-source LLM, we demonstrate its superior recall compared to the rule-based\napproach. Focusing on 11 categories of SUD diagnoses, we show the effectiveness\nof LLMs in extracting severity information, contributing to improved risk\nassessment and treatment planning for SUD patients."
  },
  {
    "arxiv_id": "2403.12212",
    "title": "Evaluating Named Entity Recognition: Comparative Analysis of Mono- and Multilingual Transformer Models on Brazilian Corporate Earnings Call Transcriptions",
    "url": "http://arxiv.org/abs/2403.12212v1",
    "abstract": "Since 2018, when the Transformer architecture was introduced, Natural\nLanguage Processing has gained significant momentum with pre-trained\nTransformer-based models that can be fine-tuned for various tasks. Most models\nare pre-trained on large English corpora, making them less applicable to other\nlanguages, such as Brazilian Portuguese. In our research, we identified two\nmodels pre-trained in Brazilian Portuguese (BERTimbau and PTT5) and two\nmultilingual models (mBERT and mT5). BERTimbau and mBERT use only the Encoder\nmodule, while PTT5 and mT5 use both the Encoder and Decoder. Our study aimed to\nevaluate their performance on a financial Named Entity Recognition (NER) task\nand determine the computational requirements for fine-tuning and inference. To\nthis end, we developed the Brazilian Financial NER (BraFiNER) dataset,\ncomprising sentences from Brazilian banks' earnings calls transcripts annotated\nusing a weakly supervised approach. Additionally, we introduced a novel\napproach that reframes the token classification task as a text generation\nproblem. After fine-tuning the models, we evaluated them using performance and\nerror metrics. Our findings reveal that BERT-based models consistently\noutperform T5-based models. While the multilingual models exhibit comparable\nmacro F1-scores, BERTimbau demonstrates superior performance over PTT5. In\nterms of error metrics, BERTimbau outperforms the other models. We also\nobserved that PTT5 and mT5 generated sentences with changes in monetary and\npercentage values, highlighting the importance of accuracy and consistency in\nthe financial domain. Our findings provide insights into the differing\nperformance of BERT- and T5-based models for the NER task."
  },
  {
    "arxiv_id": "2403.13737",
    "title": "EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation",
    "url": "http://arxiv.org/abs/2403.13737v1",
    "abstract": "Large language models (LLMs) have gained popularity recently due to their\noutstanding performance in various downstream Natural Language Processing (NLP)\ntasks. However, low-resource languages are still lagging behind current\nstate-of-the-art (SOTA) developments in the field of NLP due to insufficient\nresources to train LLMs. Ethiopian languages exhibit remarkable linguistic\ndiversity, encompassing a wide array of scripts, and are imbued with profound\nreligious and cultural significance. This paper introduces EthioLLM --\nmultilingual large language models for five Ethiopian languages (Amharic,\nGe'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a\nnew benchmark dataset for various downstream NLP tasks. We evaluate the\nperformance of these models across five downstream NLP tasks. We open-source\nour multilingual language models, new benchmark datasets for various downstream\ntasks, and task-specific fine-tuned language models and discuss the performance\nof the models. Our dataset and models are available at the\nhttps://huggingface.co/EthioNLP repository."
  },
  {
    "arxiv_id": "2403.13588",
    "title": "Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language Models",
    "url": "http://arxiv.org/abs/2403.13588v1",
    "abstract": "As Pre-trained Language Models (PLMs), a popular approach for code\nintelligence, continue to grow in size, the computational cost of their usage\nhas become prohibitively expensive. Prompt learning, a recent development in\nthe field of natural language processing, emerges as a potential solution to\naddress this challenge. In this paper, we investigate the effectiveness of\nprompt learning in code intelligence tasks. We unveil its reliance on manually\ndesigned prompts, which often require significant human effort and expertise.\nMoreover, we discover existing automatic prompt design methods are very limited\nto code intelligence tasks due to factors including gradient dependence, high\ncomputational demands, and limited applicability. To effectively address both\nissues, we propose Genetic Auto Prompt (GenAP), which utilizes an elaborate\ngenetic algorithm to automatically design prompts. With GenAP, non-experts can\neffortlessly generate superior prompts compared to meticulously manual-designed\nones. GenAP operates without the need for gradients or additional computational\ncosts, rendering it gradient-free and cost-effective. Moreover, GenAP supports\nboth understanding and generation types of code intelligence tasks, exhibiting\ngreat applicability. We conduct GenAP on three popular code intelligence PLMs\nwith three canonical code intelligence tasks including defect prediction, code\nsummarization, and code translation. The results suggest that GenAP can\neffectively automate the process of designing prompts. Specifically, GenAP\noutperforms all other methods across all three tasks (e.g., improving accuracy\nby an average of 2.13% for defect prediction). To the best of our knowledge,\nGenAP is the first work to automatically design prompts for code intelligence\nPLMs."
  },
  {
    "arxiv_id": "2403.14469",
    "title": "ChatGPT Alternative Solutions: Large Language Models Survey",
    "url": "http://arxiv.org/abs/2403.14469v1",
    "abstract": "In recent times, the grandeur of Large Language Models (LLMs) has not only\nshone in the realm of natural language processing but has also cast its\nbrilliance across a vast array of applications. This remarkable display of LLM\ncapabilities has ignited a surge in research contributions within this domain,\nspanning a diverse spectrum of topics. These contributions encompass\nadvancements in neural network architecture, context length enhancements, model\nalignment, training datasets, benchmarking, efficiency improvements, and more.\nRecent years have witnessed a dynamic synergy between academia and industry,\npropelling the field of LLM research to new heights. A notable milestone in\nthis journey is the introduction of ChatGPT, a powerful AI chatbot grounded in\nLLMs, which has garnered widespread societal attention. The evolving technology\nof LLMs has begun to reshape the landscape of the entire AI community,\npromising a revolutionary shift in the way we create and employ AI algorithms.\nGiven this swift-paced technical evolution, our survey embarks on a journey to\nencapsulate the recent strides made in the world of LLMs. Through an\nexploration of the background, key discoveries, and prevailing methodologies,\nwe offer an up-to-the-minute review of the literature. By examining multiple\nLLM models, our paper not only presents a comprehensive overview but also\ncharts a course that identifies existing challenges and points toward potential\nfuture research trajectories. This survey furnishes a well-rounded perspective\non the current state of generative AI, shedding light on opportunities for\nfurther exploration, enhancement, and innovation."
  },
  {
    "arxiv_id": "2403.14243",
    "title": "Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology",
    "url": "http://arxiv.org/abs/2403.14243v1",
    "abstract": "The rise of Artificial Intelligence creates great promise in the field of\nmedical discovery, diagnostics and patient management. However, the vast\ncomplexity of all medical domains require a more complex approach that combines\nmachine learning algorithms, classifiers, segmentation algorithms and, lately,\nlarge language models. In this paper, we describe, implement and assess an\nArtificial Intelligence-empowered system and methodology aimed at assisting the\ndiagnosis process of skin lesions and other skin conditions within the field of\ndermatology that aims to holistically address the diagnostic process in this\ndomain. The workflow integrates large language, transformer-based vision models\nand sophisticated machine learning tools. This holistic approach achieves a\nnuanced interpretation of dermatological conditions that simulates and\nfacilitates a dermatologist's workflow. We assess our proposed methodology\nthrough a thorough cross-model validation technique embedded in an evaluation\npipeline that utilizes publicly available medical case studies of skin\nconditions and relevant images. To quantitatively score the system performance,\nadvanced machine learning and natural language processing tools are employed\nwhich focus on similarity comparison and natural language inference.\nAdditionally, we incorporate a human expert evaluation process based on a\nstructured checklist to further validate our results. We implemented the\nproposed methodology in a system which achieved approximate (weighted) scores\nof 0.87 for both contextual understanding and diagnostic accuracy,\ndemonstrating the efficacy of our approach in enhancing dermatological\nanalysis. The proposed methodology is expected to prove useful in the\ndevelopment of next-generation tele-dermatology applications, enhancing remote\nconsultation capabilities and access to care, especially in underserved areas."
  },
  {
    "arxiv_id": "2403.15062",
    "title": "Construction of a Japanese Financial Benchmark for Large Language Models",
    "url": "http://arxiv.org/abs/2403.15062v1",
    "abstract": "With the recent development of large language models (LLMs), models that\nfocus on certain domains and languages have been discussed for their necessity.\nThere is also a growing need for benchmarks to evaluate the performance of\ncurrent LLMs in each domain. Therefore, in this study, we constructed a\nbenchmark comprising multiple tasks specific to the Japanese and financial\ndomains and performed benchmark measurements on some models. Consequently, we\nconfirmed that GPT-4 is currently outstanding, and that the constructed\nbenchmarks function effectively. According to our analysis, our benchmark can\ndifferentiate benchmark scores among models in all performance ranges by\ncombining tasks with different difficulties."
  },
  {
    "arxiv_id": "2403.15042",
    "title": "LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement",
    "url": "http://arxiv.org/abs/2403.15042v1",
    "abstract": "Pretrained large language models (LLMs) are currently state-of-the-art for\nsolving the vast majority of natural language processing tasks. While many\nreal-world applications still require fine-tuning to reach satisfactory levels\nof performance, many of them are in the low-data regime, making fine-tuning\nchallenging. To address this, we propose LLM2LLM, a targeted and iterative data\naugmentation strategy that uses a teacher LLM to enhance a small seed dataset\nby augmenting additional data that can be used for fine-tuning on a specific\ntask. LLM2LLM (1) fine-tunes a baseline student LLM on the initial seed data,\n(2) evaluates and extracts data points that the model gets wrong, and (3) uses\na teacher LLM to generate synthetic data based on these incorrect data points,\nwhich are then added back into the training data. This approach amplifies the\nsignal from incorrectly predicted data points by the LLM during training and\nreintegrates them into the dataset to focus on more challenging examples for\nthe LLM. Our results show that LLM2LLM significantly enhances the performance\nof LLMs in the low-data regime, outperforming both traditional fine-tuning and\nother data augmentation baselines. LLM2LLM reduces the dependence on\nlabor-intensive data curation and paves the way for more scalable and\nperformant LLM solutions, allowing us to tackle data-constrained domains and\ntasks. We achieve improvements up to 24.2% on the GSM8K dataset, 32.6% on\nCaseHOLD, 32.0% on SNIPS, 52.6% on TREC and 39.8% on SST-2 over regular\nfine-tuning in the low-data regime using a Llama-2-7B student model. Our code\nis available at https://github.com/SqueezeAILab/LLM2LLM ."
  },
  {
    "arxiv_id": "2403.14938",
    "title": "On Zero-Shot Counterspeech Generation by LLMs",
    "url": "http://arxiv.org/abs/2403.14938v1",
    "abstract": "With the emergence of numerous Large Language Models (LLM), the usage of such\nmodels in various Natural Language Processing (NLP) applications is increasing\nextensively. Counterspeech generation is one such key task where efforts are\nmade to develop generative models by fine-tuning LLMs with hatespeech -\ncounterspeech pairs, but none of these attempts explores the intrinsic\nproperties of large language models in zero-shot settings. In this work, we\npresent a comprehensive analysis of the performances of four LLMs namely GPT-2,\nDialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech\ngeneration, which is the first of its kind. For GPT-2 and DialoGPT, we further\ninvestigate the deviation in performance with respect to the sizes (small,\nmedium, large) of the models. On the other hand, we propose three different\nprompting strategies for generating different types of counterspeech and\nanalyse the impact of such strategies on the performance of the models. Our\nanalysis shows that there is an improvement in generation quality for two\ndatasets (17%), however the toxicity increase (25%) with increase in model\nsize. Considering type of model, GPT-2 and FlanT5 models are significantly\nbetter in terms of counterspeech quality but also have high toxicity as\ncompared to DialoGPT. ChatGPT are much better at generating counter speech than\nother models across all metrics. In terms of prompting, we find that our\nproposed strategies help in improving counter speech generation across all the\nmodels."
  },
  {
    "arxiv_id": "2403.16777",
    "title": "Can Machine Translation Bridge Multilingual Pretraining and Cross-lingual Transfer Learning?",
    "url": "http://arxiv.org/abs/2403.16777v1",
    "abstract": "Multilingual pretraining and fine-tuning have remarkably succeeded in various\nnatural language processing tasks. Transferring representations from one\nlanguage to another is especially crucial for cross-lingual learning. One can\nexpect machine translation objectives to be well suited to fostering such\ncapabilities, as they involve the explicit alignment of semantically equivalent\nsentences from different languages. This paper investigates the potential\nbenefits of employing machine translation as a continued training objective to\nenhance language representation learning, bridging multilingual pretraining and\ncross-lingual applications. We study this question through two lenses: a\nquantitative evaluation of the performance of existing models and an analysis\nof their latent representations. Our results show that, contrary to\nexpectations, machine translation as the continued training fails to enhance\ncross-lingual representation learning in multiple cross-lingual natural\nlanguage understanding tasks. We conclude that explicit sentence-level\nalignment in the cross-lingual scenario is detrimental to cross-lingual\ntransfer pretraining, which has important implications for future cross-lingual\ntransfer studies. We furthermore provide evidence through similarity measures\nand investigation of parameters that this lack of positive influence is due to\noutput separability -- which we argue is of use for machine translation but\ndetrimental elsewhere."
  },
  {
    "arxiv_id": "2403.16524",
    "title": "Harnessing the power of LLMs for normative reasoning in MASs",
    "url": "http://arxiv.org/abs/2403.16524v1",
    "abstract": "Software agents, both human and computational, do not exist in isolation and\noften need to collaborate or coordinate with others to achieve their goals. In\nhuman society, social mechanisms such as norms ensure efficient functioning,\nand these techniques have been adopted by researchers in multi-agent systems\n(MAS) to create socially aware agents. However, traditional techniques have\nlimitations, such as operating in limited environments often using brittle\nsymbolic reasoning. The advent of Large Language Models (LLMs) offers a\npromising solution, providing a rich and expressive vocabulary for norms and\nenabling norm-capable agents that can perform a range of tasks such as norm\ndiscovery, normative reasoning and decision-making. This paper examines the\npotential of LLM-based agents to acquire normative capabilities, drawing on\nrecent Natural Language Processing (NLP) and LLM research. We present our\nvision for creating normative LLM agents. In particular, we discuss how the\nrecently proposed \"LLM agent\" approaches can be extended to implement such\nnormative LLM agents. We also highlight challenges in this emerging field. This\npaper thus aims to foster collaboration between MAS, NLP and LLM researchers in\norder to advance the field of normative agents."
  },
  {
    "arxiv_id": "2403.16432",
    "title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models",
    "url": "http://arxiv.org/abs/2403.16432v1",
    "abstract": "Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo. The resource is available at\n$\\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$."
  },
  {
    "arxiv_id": "2403.16303",
    "title": "Large Language Models in Biomedical and Health Informatics: A Bibliometric Review",
    "url": "http://arxiv.org/abs/2403.16303v1",
    "abstract": "Large Language Models (LLMs) have rapidly become important tools in\nBiomedical and Health Informatics (BHI), enabling new ways to analyze data,\ntreat patients, and conduct research. This study aims to provide a\ncomprehensive overview of LLM applications in BHI, highlighting their\ntransformative potential and addressing the associated ethical and practical\nchallenges. We reviewed 1,698 research articles from January 2022 to December\n2023, categorizing them by research themes and diagnostic categories.\nAdditionally, we conducted network analysis to map scholarly collaborations and\nresearch dynamics. Our findings reveal a substantial increase in the potential\napplications of LLMs to a variety of BHI tasks, including clinical decision\nsupport, patient interaction, and medical document analysis. Notably, LLMs are\nexpected to be instrumental in enhancing the accuracy of diagnostic tools and\npatient care protocols. The network analysis highlights dense and dynamically\nevolving collaborations across institutions, underscoring the interdisciplinary\nnature of LLM research in BHI. A significant trend was the application of LLMs\nin managing specific disease categories such as mental health and neurological\ndisorders, demonstrating their potential to influence personalized medicine and\npublic health strategies. LLMs hold promising potential to further transform\nbiomedical research and healthcare delivery. While promising, the ethical\nimplications and challenges of model validation call for rigorous scrutiny to\noptimize their benefits in clinical settings. This survey serves as a resource\nfor stakeholders in healthcare, including researchers, clinicians, and\npolicymakers, to understand the current state and future potential of LLMs in\nBHI."
  },
  {
    "arxiv_id": "2403.17860",
    "title": "Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications",
    "url": "http://arxiv.org/abs/2403.17860v1",
    "abstract": "Language models (LMs) have achieved impressive accuracy across a variety of\ntasks but remain vulnerable to high-confidence misclassifications, also\nreferred to as unknown unknowns (UUs). These UUs cluster into blind spots in\nthe feature space, leading to significant risks in high-stakes applications.\nThis is particularly relevant for smaller, lightweight LMs that are more\nsusceptible to such errors. While the identification of UUs has been\nextensively studied, their mitigation remains an open challenge, including how\nto use identified UUs to eliminate unseen blind spots. In this work, we propose\na novel approach to address blind spot mitigation through the use of\nintelligent agents -- either humans or large LMs -- as teachers to characterize\nUU-type errors. By leveraging the generalization capabilities of intelligent\nagents, we identify patterns in high-confidence misclassifications and use them\nto generate targeted synthetic samples to improve model robustness and reduce\nblind spots. We conduct an extensive evaluation of our method on three\nclassification tasks and demonstrate its effectiveness in reducing the number\nof UUs, all while maintaining a similar level of accuracy. We find that the\neffectiveness of human computation has a high ceiling but is highly dependent\non familiarity with the underlying task. Moreover, the cost gap between humans\nand LMs surpasses an order of magnitude, as LMs attain human-like\ngeneralization and generation performance while being more scalable."
  },
  {
    "arxiv_id": "2403.17816",
    "title": "Graph Language Model (GLM): A new graph-based approach to detect social instabilities",
    "url": "http://arxiv.org/abs/2403.17816v1",
    "abstract": "This scientific report presents a novel methodology for the early prediction\nof important political events using News datasets. The methodology leverages\nnatural language processing, graph theory, clique analysis, and semantic\nrelationships to uncover hidden predictive signals within the data. Initially,\nwe designed a preliminary version of the method and tested it on a few events.\nThis analysis revealed limitations in the initial research phase. We then\nenhanced the model in two key ways: first, we added a filtration step to only\nconsider politically relevant news before further processing; second, we\nadjusted the input features to make the alert system more sensitive to\nsignificant spikes in the data. After finalizing the improved methodology, we\ntested it on eleven events including US protests, the Ukraine war, and French\nprotests. Results demonstrate the superiority of our approach compared to\nbaseline methods. Through targeted refinements, our model can now provide\nearlier and more accurate predictions of major political events based on subtle\npatterns in news data."
  },
  {
    "arxiv_id": "2403.17811",
    "title": "Are Compressed Language Models Less Subgroup Robust?",
    "url": "http://arxiv.org/abs/2403.17811v1",
    "abstract": "To reduce the inference cost of large language models, model compression is\nincreasingly used to create smaller scalable models. However, little is known\nabout their robustness to minority subgroups defined by the labels and\nattributes of a dataset. In this paper, we investigate the effects of 18\ndifferent compression methods and settings on the subgroup robustness of BERT\nlanguage models. We show that worst-group performance does not depend on model\nsize alone, but also on the compression method used. Additionally, we find that\nmodel compression does not always worsen the performance on minority subgroups.\nAltogether, our analysis serves to further research into the subgroup\nrobustness of model compression."
  },
  {
    "arxiv_id": "2403.17437",
    "title": "An Empirical Study of ChatGPT-related projects on GitHub",
    "url": "http://arxiv.org/abs/2403.17437v1",
    "abstract": "Since the launch of ChatGPT in 2022, an increasing number of ChatGPT-related\nprojects are being published on GitHub, sparking widespread discussions.\nHowever, GitHub does not provide a detailed classification of these projects to\nhelp users effectively explore interested projects. Additionally, the issues\nraised by users for these projects cover various aspects, e.g., installation,\nusage, and updates. It would be valuable to help developers prioritize more\nurgent issues and improve development efficiency. We retrieved 71,244 projects\nfrom GitHub using the keyword `ChatGPT' and selected the top 200 representative\nprojects with the highest numbers of stars as our dataset. By analyzing the\nproject descriptions, we identified three primary categories of ChatGPT-related\nprojects, namely ChatGPT Implementation & Training, ChatGPT Application,\nChatGPT Improvement & Extension. Next, we applied a topic modeling technique to\n23,609 issues of those projects and identified ten issue topics, e.g., model\nreply and interaction interface. We further analyzed the popularity,\ndifficulty, and evolution of each issue topic within the three project\ncategories. Our main findings are: 1) The increase in the number of projects\nwithin the three categories is closely related to the development of ChatGPT;\nand 2) There are significant differences in the popularity, difficulty, and\nevolutionary trends of the issue topics across the three project categories.\nBased on these findings, we finally provided implications for project\ndevelopers and platform managers on how to better develop and manage\nChatGPT-related projects."
  },
  {
    "arxiv_id": "2403.18778",
    "title": "3P-LLM: Probabilistic Path Planning using Large Language Model for Autonomous Robot Navigation",
    "url": "http://arxiv.org/abs/2403.18778v1",
    "abstract": "Much worldly semantic knowledge can be encoded in large language models\n(LLMs). Such information could be of great use to robots that want to carry out\nhigh-level, temporally extended commands stated in natural language. However,\nthe lack of real-world experience that language models have is a key limitation\nthat makes it challenging to use them for decision-making inside a particular\nembodiment. This research assesses the feasibility of using LLM (GPT-3.5-turbo\nchatbot by OpenAI) for robotic path planning. The shortcomings of conventional\napproaches to managing complex environments and developing trustworthy plans\nfor shifting environmental conditions serve as the driving force behind the\nresearch. Due to the sophisticated natural language processing abilities of\nLLM, the capacity to provide effective and adaptive path-planning algorithms in\nreal-time, great accuracy, and few-shot learning capabilities, GPT-3.5-turbo is\nwell suited for path planning in robotics. In numerous simulated scenarios, the\nresearch compares the performance of GPT-3.5-turbo with that of\nstate-of-the-art path planners like Rapidly Exploring Random Tree (RRT) and A*.\nWe observed that GPT-3.5-turbo is able to provide real-time path planning\nfeedback to the robot and outperforms its counterparts. This paper establishes\nthe foundation for LLM-powered path planning for robotic systems."
  },
  {
    "arxiv_id": "2403.18637",
    "title": "Transformers-based architectures for stroke segmentation: A review",
    "url": "http://arxiv.org/abs/2403.18637v1",
    "abstract": "Stroke remains a significant global health concern, necessitating precise and\nefficient diagnostic tools for timely intervention and improved patient\noutcomes. The emergence of deep learning methodologies has transformed the\nlandscape of medical image analysis. Recently, Transformers, initially designed\nfor natural language processing, have exhibited remarkable capabilities in\nvarious computer vision applications, including medical image analysis. This\ncomprehensive review aims to provide an in-depth exploration of the\ncutting-edge Transformer-based architectures applied in the context of stroke\nsegmentation. It commences with an exploration of stroke pathology, imaging\nmodalities, and the challenges associated with accurate diagnosis and\nsegmentation. Subsequently, the review delves into the fundamental ideas of\nTransformers, offering detailed insights into their architectural intricacies\nand the underlying mechanisms that empower them to effectively capture complex\nspatial information within medical images. The existing literature is\nsystematically categorized and analyzed, discussing various approaches that\nleverage Transformers for stroke segmentation. A critical assessment is\nprovided, highlighting the strengths and limitations of these methods,\nincluding considerations of performance and computational efficiency.\nAdditionally, this review explores potential avenues for future research and\ndevelopment"
  },
  {
    "arxiv_id": "2403.18506",
    "title": "Faster Convergence for Transformer Fine-tuning with Line Search Methods",
    "url": "http://arxiv.org/abs/2403.18506v1",
    "abstract": "Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures."
  },
  {
    "arxiv_id": "2403.18381",
    "title": "Improving Attributed Text Generation of Large Language Models via Preference Learning",
    "url": "http://arxiv.org/abs/2403.18381v1",
    "abstract": "Large language models have been widely adopted in natural language\nprocessing, yet they face the challenge of generating unreliable content.\nRecent works aim to reduce misinformation and hallucinations by resorting to\nattribution as a means to provide evidence (i.e., citations). However, current\nattribution methods usually focus on the retrieval stage and automatic\nevaluation that neglect mirroring the citation mechanisms in human scholarly\nwriting to bolster credibility. In this paper, we address these challenges by\nmodelling the attribution task as preference learning and introducing an\nAutomatic Preference Optimization (APO) framework. First, we create a curated\ncollection for post-training with 6,330 examples by collecting and filtering\nfrom existing datasets. Second, considering the high cost of labelling\npreference data, we further propose an automatic method to synthesize\nattribution preference data resulting in 95,263 pairs. Moreover, inspired by\nthe human citation process, we further propose a progressive preference\noptimization method by leveraging fine-grained information. Extensive\nexperiments on three datasets (i.e., ASQA, StrategyQA, and ELI5) demonstrate\nthat APO achieves state-of-the-art citation F1 with higher answer quality."
  },
  {
    "arxiv_id": "2403.18276",
    "title": "RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers",
    "url": "http://arxiv.org/abs/2403.18276v1",
    "abstract": "Transformer structure has achieved great success in multiple applied machine\nlearning communities, such as natural language processing (NLP), computer\nvision (CV) and information retrieval (IR). Transformer architecture's core\nmechanism -- attention requires $O(n^2)$ time complexity in training and $O(n)$\ntime complexity in inference. Many works have been proposed to improve the\nattention mechanism's scalability, such as Flash Attention and Multi-query\nAttention. A different line of work aims to design new mechanisms to replace\nattention. Recently, a notable model structure -- Mamba, which is based on\nstate space models, has achieved transformer-equivalent performance in multiple\nsequence modeling tasks.\n  In this work, we examine \\mamba's efficacy through the lens of a classical IR\ntask -- document ranking. A reranker model takes a query and a document as\ninput, and predicts a scalar relevance score. This task demands the language\nmodel's ability to comprehend lengthy contextual inputs and to capture the\ninteraction between query and document tokens. We find that (1) Mamba models\nachieve competitive performance compared to transformer-based models with the\nsame training recipe; (2) but also have a lower training throughput in\ncomparison to efficient transformer implementations such as flash attention. We\nhope this study can serve as a starting point to explore Mamba models in other\nclassical IR tasks. Our code implementation and trained checkpoints are made\npublic to facilitate reproducibility\n(https://github.com/zhichaoxu-shufe/RankMamba)."
  },
  {
    "arxiv_id": "2403.19511",
    "title": "Improving Clinical NLP Performance through Language Model-Generated Synthetic Clinical Data",
    "url": "http://arxiv.org/abs/2403.19511v1",
    "abstract": "Generative models have been showing potential for producing data in mass.\nThis study explores the enhancement of clinical natural language processing\nperformance by utilizing synthetic data generated from advanced language\nmodels. Promising results show feasible applications in such a high-stakes\ndomain."
  },
  {
    "arxiv_id": "2403.19031",
    "title": "Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data",
    "url": "http://arxiv.org/abs/2403.19031v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable success in NLP\ntasks. However, there is a paucity of studies that attempt to evaluate their\nperformances on social media-based health-related natural language processing\ntasks, which have traditionally been difficult to achieve high scores in. We\nbenchmarked one supervised classic machine learning model based on Support\nVector Machines (SVMs), three supervised pretrained language models (PLMs)\nbased on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5\nand GPT4), across 6 text classification tasks. We developed three approaches\nfor leveraging LLMs for text classification: employing LLMs as zero-shot\nclassifiers, us-ing LLMs as annotators to annotate training data for supervised\nclassifiers, and utilizing LLMs with few-shot examples for augmentation of\nmanually annotated data. Our comprehensive experiments demonstrate that\nemploy-ing data augmentation using LLMs (GPT-4) with relatively small\nhuman-annotated data to train lightweight supervised classification models\nachieves superior results compared to training with human-annotated data alone.\nSupervised learners also outperform GPT-4 and GPT-3.5 in zero-shot settings. By\nleveraging this data augmentation strategy, we can harness the power of LLMs to\ndevelop smaller, more effective domain-specific NLP models. LLM-annotated data\nwithout human guidance for training light-weight supervised classification\nmodels is an ineffective strategy. However, LLM, as a zero-shot classifier,\nshows promise in excluding false negatives and potentially reducing the human\neffort required for data annotation. Future investigations are imperative to\nexplore optimal training data sizes and the optimal amounts of augmented data."
  },
  {
    "arxiv_id": "2403.19016",
    "title": "Resource Allocation in Large Language Model Integrated 6G Vehicular Networks",
    "url": "http://arxiv.org/abs/2403.19016v1",
    "abstract": "In the upcoming 6G era, vehicular networks are shifting from simple\nVehicle-to-Vehicle (V2V) communication to the more complex\nVehicle-to-Everything (V2X) connectivity. At the forefront of this shift is the\nincorporation of Large Language Models (LLMs) into vehicles. Known for their\nsophisticated natural language processing abilities, LLMs change how users\ninteract with their vehicles. This integration facilitates voice-driven\ncommands and interactions, departing from the conventional manual control\nsystems. However, integrating LLMs into vehicular systems presents notable\nchallenges. The substantial computational demands and energy requirements of\nLLMs pose significant challenges, especially in the constrained environment of\na vehicle. Additionally, the time-sensitive nature of tasks in vehicular\nnetworks adds another layer of complexity. In this paper, we consider an edge\ncomputing system where vehicles process the initial layers of LLM computations\nlocally, and offload the remaining LLM computation tasks to the Roadside Units\n(RSUs), envisioning a vehicular ecosystem where LLM computations seamlessly\ninteract with the ultra-low latency and high-bandwidth capabilities of 6G\nnetworks. To balance the trade-off between completion time and energy\nconsumption, we formulate a multi-objective optimization problem to minimize\nthe total cost of the vehicles and RSUs. The problem is then decomposed into\ntwo sub-problems, which are solved by sequential quadratic programming (SQP)\nmethod and fractional programming technique. The simulation results clearly\nindicate that the algorithm we have proposed is highly effective in reducing\nboth the completion time and energy consumption of the system."
  },
  {
    "arxiv_id": "2403.18969",
    "title": "A Survey on Large Language Models from Concept to Implementation",
    "url": "http://arxiv.org/abs/2403.18969v1",
    "abstract": "Recent advancements in Large Language Models (LLMs), particularly those built\non Transformer architectures, have significantly broadened the scope of natural\nlanguage processing (NLP) applications, transcending their initial use in\nchatbot technology. This paper investigates the multifaceted applications of\nthese models, with an emphasis on the GPT series. This exploration focuses on\nthe transformative impact of artificial intelligence (AI) driven tools in\nrevolutionizing traditional tasks like coding and problem-solving, while also\npaving new paths in research and development across diverse industries. From\ncode interpretation and image captioning to facilitating the construction of\ninteractive systems and advancing computational domains, Transformer models\nexemplify a synergy of deep learning, data analysis, and neural network design.\nThis survey provides an in-depth look at the latest research in Transformer\nmodels, highlighting their versatility and the potential they hold for\ntransforming diverse application sectors, thereby offering readers a\ncomprehensive understanding of the current and future landscape of\nTransformer-based LLMs in practical applications."
  },
  {
    "arxiv_id": "2403.18938",
    "title": "Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers",
    "url": "http://arxiv.org/abs/2403.18938v1",
    "abstract": "BACKGROUND: Radiology reports are typically written in a free-text format,\nmaking clinical information difficult to extract and use. Recently the adoption\nof structured reporting (SR) has been recommended by various medical societies\nthanks to the advantages it offers, e.g. standardization, completeness and\ninformation retrieval. We propose a pipeline to extract information from\nfree-text radiology reports, that fits with the items of the reference SR\nregistry proposed by a national society of interventional and medical\nradiology, focusing on CT staging of patients with lymphoma. METHODS: Our work\naims to leverage the potential of Natural Language Processing (NLP) and\nTransformer-based models to deal with automatic SR registry filling. With the\navailability of 174 radiology reports, we investigate a rule-free generative\nQuestion Answering approach based on a domain-specific version of T5 (IT5). Two\nstrategies (batch-truncation and ex-post combination) are implemented to comply\nwith the model's context length limitations. Performance is evaluated in terms\nof strict accuracy, F1, and format accuracy, and compared with the widely used\nGPT-3.5 Large Language Model. A 5-point Likert scale questionnaire is used to\ncollect human-expert feedback on the similarity between medical annotations and\ngenerated answers. RESULTS: The combination of fine-tuning and batch splitting\nallows IT5 to achieve notable results; it performs on par with GPT-3.5 albeit\nits size being a thousand times smaller in terms of parameters. Human-based\nassessment scores show a high correlation (Spearman's correlation\ncoefficients>0.88, p-values<0.001) with AI performance metrics (F1) and confirm\nthe superior ability of LLMs (i.e., GPT-3.5, 175B of parameters) in generating\nplausible human-like statements."
  },
  {
    "arxiv_id": "2403.20158",
    "title": "ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models",
    "url": "http://arxiv.org/abs/2403.20158v1",
    "abstract": "In our rapidly evolving digital sphere, the ability to discern media bias\nbecomes crucial as it can shape public sentiment and influence pivotal\ndecisions. The advent of large language models (LLMs), such as ChatGPT, noted\nfor their broad utility in various natural language processing (NLP) tasks,\ninvites exploration of their efficacy in media bias detection. Can ChatGPT\ndetect media bias? This study seeks to answer this question by leveraging the\nMedia Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in\ndistinguishing six categories of media bias, juxtaposed against fine-tuned\nmodels such as BART, ConvBERT, and GPT-2. The findings present a dichotomy:\nChatGPT performs at par with fine-tuned models in detecting hate speech and\ntext-level context bias, yet faces difficulties with subtler elements of other\nbias detections, namely, fake news, racial, gender, and cognitive biases."
  },
  {
    "arxiv_id": "2403.19913",
    "title": "MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models",
    "url": "http://arxiv.org/abs/2403.19913v1",
    "abstract": "Large language models such as ChatGPT and GPT-4 have recently achieved\nastonishing performance on a variety of natural language processing tasks. In\nthis paper, we propose MANGO, a benchmark to evaluate their capabilities to\nperform text-based mapping and navigation. Our benchmark includes 53 mazes\ntaken from a suite of textgames: each maze is paired with a walkthrough that\nvisits every location but does not cover all possible paths. The task is\nquestion-answering: for each maze, a large language model reads the walkthrough\nand answers hundreds of mapping and navigation questions such as \"How should\nyou go to Attic from West of House?\" and \"Where are we if we go north and east\nfrom Cellar?\". Although these questions are easy to humans, it turns out that\neven GPT-4, the best-to-date language model, performs poorly at answering them.\nFurther, our experiments suggest that a strong mapping and navigation ability\nwould benefit large language models in performing relevant downstream tasks,\nsuch as playing textgames. Our MANGO benchmark will facilitate future research\non methods that improve the mapping and navigation capabilities of language\nmodels. We host our leaderboard, data, code, and evaluation program at\nhttps://mango.ttic.edu and https://github.com/oaklight/mango/."
  },
  {
    "arxiv_id": "2404.01961",
    "title": "Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument Reasoning in Civil Procedures with GPT4",
    "url": "http://arxiv.org/abs/2404.01961v1",
    "abstract": "In this paper, we present our system for the SemEval Task 5, The Legal\nArgument Reasoning Task in Civil Procedure Challenge. Legal argument reasoning\nis an essential skill that all law students must master. Moreover, it is\nimportant to develop natural language processing solutions that can reason\nabout a question given terse domain-specific contextual information. Our system\nexplores a prompt-based solution using GPT4 to reason over legal arguments. We\nalso evaluate an ensemble of prompting strategies, including chain-of-thought\nreasoning and in-context learning. Overall, our system results in a Macro F1 of\n.8095 on the validation dataset and .7315 (5th out of 21 teams) on the final\ntest set. Code for this project is available at\nhttps://github.com/danschumac1/CivilPromptReasoningGPT4."
  },
  {
    "arxiv_id": "2404.01800",
    "title": "Sentiment Analysis of Citations in Scientific Articles Using ChatGPT: Identifying Potential Biases and Conflicts of Interest",
    "url": "http://arxiv.org/abs/2404.01800v1",
    "abstract": "Scientific articles play a crucial role in advancing knowledge and informing\nresearch directions. One key aspect of evaluating scientific articles is the\nanalysis of citations, which provides insights into the impact and reception of\nthe cited works. This article introduces the innovative use of large language\nmodels, particularly ChatGPT, for comprehensive sentiment analysis of citations\nwithin scientific articles. By leveraging advanced natural language processing\n(NLP) techniques, ChatGPT can discern the nuanced positivity or negativity of\ncitations, offering insights into the reception and impact of cited works.\nFurthermore, ChatGPT's capabilities extend to detecting potential biases and\nconflicts of interest in citations, enhancing the objectivity and reliability\nof scientific literature evaluation. This study showcases the transformative\npotential of artificial intelligence (AI)-powered tools in enhancing citation\nanalysis and promoting integrity in scholarly research."
  },
  {
    "arxiv_id": "2404.01663",
    "title": "CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models",
    "url": "http://arxiv.org/abs/2404.01663v1",
    "abstract": "Open large language models (LLMs) have significantly advanced the field of\nnatural language processing, showcasing impressive performance across various\ntasks.Despite the significant advancements in LLMs, their effective operation\nstill relies heavily on human input to accurately guide the dialogue flow, with\nagent tuning being a crucial optimization technique that involves human\nadjustments to the model for better response to such guidance.Addressing this\ndependency, our work introduces the TinyAgent model, trained on a meticulously\ncurated high-quality dataset. We also present the Collaborative Multi-Agent\nTuning (CMAT) framework, an innovative system designed to augment language\nagent capabilities through adaptive weight updates based on environmental\nfeedback. This framework fosters collaborative learning and real-time\nadaptation among multiple intelligent agents, enhancing their context-awareness\nand long-term memory. In this research, we propose a new communication agent\nframework that integrates multi-agent systems with environmental feedback\nmechanisms, offering a scalable method to explore cooperative behaviors.\nNotably, our TinyAgent-7B model exhibits performance on par with GPT-3.5,\ndespite having fewer parameters, signifying a substantial improvement in the\nefficiency and effectiveness of LLMs."
  },
  {
    "arxiv_id": "2404.01548",
    "title": "mChartQA: A universal benchmark for multimodal Chart Question Answer based on Vision-Language Alignment and Reasoning",
    "url": "http://arxiv.org/abs/2404.01548v1",
    "abstract": "In the fields of computer vision and natural language processing, multimodal\nchart question-answering, especially involving color, structure, and textless\ncharts, poses significant challenges. Traditional methods, which typically\ninvolve either direct multimodal processing or a table-to-text conversion\nfollowed by language model analysis, have limitations in effectively handling\nthese complex scenarios. This paper introduces a novel multimodal chart\nquestion-answering model, specifically designed to address these intricate\ntasks. Our model integrates visual and linguistic processing, overcoming the\nconstraints of existing methods. We adopt a dual-phase training approach: the\ninitial phase focuses on aligning image and text representations, while the\nsubsequent phase concentrates on optimizing the model's interpretative and\nanalytical abilities in chart-related queries. This approach has demonstrated\nsuperior performance on multiple public datasets, particularly in handling\ncolor, structure, and textless chart questions, indicating its effectiveness in\ncomplex multimodal tasks."
  },
  {
    "arxiv_id": "2404.02717",
    "title": "Automatic Prompt Selection for Large Language Models",
    "url": "http://arxiv.org/abs/2404.02717v1",
    "abstract": "Large Language Models (LLMs) can perform various natural language processing\ntasks with suitable instruction prompts. However, designing effective prompts\nmanually is challenging and time-consuming. Existing methods for automatic\nprompt optimization either lack flexibility or efficiency. In this paper, we\npropose an effective approach to automatically select the optimal prompt for a\ngiven input from a finite set of synthetic candidate prompts. Our approach\nconsists of three steps: (1) clustering the training data and generating\ncandidate prompts for each cluster using an LLM-based prompt generator; (2)\nsynthesizing a dataset of input-prompt-output tuples for training a prompt\nevaluator to rank the prompts based on their relevance to the input; (3) using\nthe prompt evaluator to select the best prompt for a new input at test time.\nOur approach balances prompt generality-specificity and eliminates the need for\nresource-intensive training and inference. It demonstrates competitive\nperformance on zero-shot question-answering datasets: GSM8K, MultiArith, and\nAQuA."
  },
  {
    "arxiv_id": "2404.02532",
    "title": "Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game",
    "url": "http://arxiv.org/abs/2404.02532v1",
    "abstract": "With the enhanced performance of large models on natural language processing\ntasks, potential moral and ethical issues of large models arise. There exist\nmalicious attackers who induce large models to jailbreak and generate\ninformation containing illegal, privacy-invasive information through techniques\nsuch as prompt engineering. As a result, large models counter malicious\nattackers' attacks using techniques such as safety alignment. However, the\nstrong defense mechanism of the large model through rejection replies is easily\nidentified by attackers and used to strengthen attackers' capabilities. In this\npaper, we propose a multi-agent attacker-disguiser game approach to achieve a\nweak defense mechanism that allows the large model to both safely reply to the\nattacker and hide the defense intent. First, we construct a multi-agent\nframework to simulate attack and defense scenarios, playing different roles to\nbe responsible for attack, disguise, safety evaluation, and disguise evaluation\ntasks. After that, we design attack and disguise game algorithms to optimize\nthe game strategies of the attacker and the disguiser and use the curriculum\nlearning process to strengthen the capabilities of the agents. The experiments\nverify that the method in this paper is more effective in strengthening the\nmodel's ability to disguise the defense intent compared with other methods.\nMoreover, our approach can adapt any black-box large model to assist the model\nin defense and does not suffer from model version iterations."
  },
  {
    "arxiv_id": "2404.02444",
    "title": "The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education",
    "url": "http://arxiv.org/abs/2404.02444v1",
    "abstract": "Assessing instruction quality is a fundamental component of any improvement\nefforts in the education system. However, traditional manual assessments are\nexpensive, subjective, and heavily dependent on observers' expertise and\nidiosyncratic factors, preventing teachers from getting timely and frequent\nfeedback. Different from prior research that mostly focuses on low-inference\ninstructional practices on a singular basis, this paper presents the first\nstudy that leverages Natural Language Processing (NLP) techniques to assess\nmultiple high-inference instructional practices in two distinct educational\nsettings: in-person K-12 classrooms and simulated performance tasks for\npre-service teachers. This is also the first study that applies NLP to measure\na teaching practice that is widely acknowledged to be particularly effective\nfor students with special needs. We confront two challenges inherent in\nNLP-based instructional analysis, including noisy and long input data and\nhighly skewed distributions of human ratings. Our results suggest that\npretrained Language Models (PLMs) demonstrate performances comparable to the\nagreement level of human raters for variables that are more discrete and\nrequire lower inference, but their efficacy diminishes with more complex\nteaching practices. Interestingly, using only teachers' utterances as input\nyields strong results for student-centered variables, alleviating common\nconcerns over the difficulty of collecting and transcribing high-quality\nstudent speech data in in-person teaching settings. Our findings highlight both\nthe potential and the limitations of current NLP techniques in the education\ndomain, opening avenues for further exploration."
  },
  {
    "arxiv_id": "2404.02330",
    "title": "Comparative Study of Domain Driven Terms Extraction Using Large Language Models",
    "url": "http://arxiv.org/abs/2404.02330v1",
    "abstract": "Keywords play a crucial role in bridging the gap between human understanding\nand machine processing of textual data. They are essential to data enrichment\nbecause they form the basis for detailed annotations that provide a more\ninsightful and in-depth view of the underlying data. Keyword/domain driven term\nextraction is a pivotal task in natural language processing, facilitating\ninformation retrieval, document summarization, and content categorization. This\nreview focuses on keyword extraction methods, emphasizing the use of three\nmajor Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. We\nemployed a custom Python package to interface with these LLMs, simplifying\nkeyword extraction. Our study, utilizing the Inspec and PubMed datasets,\nevaluates the performance of these models. The Jaccard similarity index was\nused for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) for\nGPT-3.5, 0.40 and 0.17 for Llama2-7B, and 0.23 and 0.12 for Falcon-7B. This\npaper underlines the role of prompt engineering in LLMs for better keyword\nextraction and discusses the impact of hallucination in LLMs on result\nevaluation. It also sheds light on the challenges in using LLMs for keyword\nextraction, including model complexity, resource demands, and optimization\ntechniques."
  },
  {
    "arxiv_id": "2404.03353",
    "title": "Towards Pareto Optimal Throughput in Small Language Model Serving",
    "url": "http://arxiv.org/abs/2404.03353v1",
    "abstract": "Large language models (LLMs) have revolutionized the state-of-the-art of many\ndifferent natural language processing tasks. Although serving LLMs is\ncomputationally and memory demanding, the rise of Small Language Models (SLMs)\noffers new opportunities for resource-constrained users, who now are able to\nserve small models with cutting-edge performance. In this paper, we present a\nset of experiments designed to benchmark SLM inference at performance and\nenergy levels. Our analysis provides a new perspective in serving, highlighting\nthat the small memory footprint of SLMs allows for reaching the Pareto-optimal\nthroughput within the resource capacity of a single accelerator. In this\nregard, we present an initial set of findings demonstrating how model\nreplication can effectively improve resource utilization for serving SLMs."
  },
  {
    "arxiv_id": "2404.03080",
    "title": "Construction of Functional Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model",
    "url": "http://arxiv.org/abs/2404.03080v1",
    "abstract": "Knowledge in materials science is widely dispersed across extensive\nscientific literature, posing significant challenges for efficient discovery\nand integration of new materials. Traditional methods, often reliant on costly\nand time-consuming experimental approaches, further complicate rapid\ninnovation. Addressing these challenges, the integration of artificial\nintelligence with materials science has opened avenues for accelerating the\ndiscovery process, though it also demands precise annotation, data extraction,\nand traceability of information. To tackle these issues, this article\nintroduces the Materials Knowledge Graph (MKG), which utilizes advanced natural\nlanguage processing techniques, integrated with large language models to\nextract and systematically organize a decade's worth of high-quality research\ninto structured triples, contains 162,605 nodes and 731,772 edges. MKG\ncategorizes information into comprehensive labels such as Name, Formula, and\nApplication, structured around a meticulously designed ontology, thus enhancing\ndata usability and integration. By implementing network-based algorithms, MKG\nnot only facilitates efficient link prediction but also significantly reduces\nreliance on traditional experimental methods. This structured approach not only\nstreamlines materials research but also lays the groundwork for more\nsophisticated science knowledge graphs."
  },
  {
    "arxiv_id": "2404.03052",
    "title": "GPT-DETOX: An In-Context Learning-Based Paraphraser for Text Detoxification",
    "url": "http://arxiv.org/abs/2404.03052v1",
    "abstract": "Harmful and offensive communication or content is detrimental to social\nbonding and the mental state of users on social media platforms. Text\ndetoxification is a crucial task in natural language processing (NLP), where\nthe goal is removing profanity and toxicity from text while preserving its\ncontent. Supervised and unsupervised learning are common approaches for\ndesigning text detoxification solutions. However, these methods necessitate\nfine-tuning, leading to computational overhead. In this paper, we propose\nGPT-DETOX as a framework for prompt-based in-context learning for text\ndetoxification using GPT-3.5 Turbo. We utilize zero-shot and few-shot prompting\ntechniques for detoxifying input sentences. To generate few-shot prompts, we\npropose two methods: word-matching example selection (WMES) and\ncontext-matching example selection (CMES). We additionally take into account\nensemble in-context learning (EICL) where the ensemble is shaped by base\nprompts from zero-shot and all few-shot settings. We use ParaDetox and APPDIA\nas benchmark detoxification datasets. Our experimental results show that the\nzero-shot solution achieves promising performance, while our best few-shot\nsetting outperforms the state-of-the-art models on ParaDetox and shows\ncomparable results on APPDIA. Our EICL solutions obtain the greatest\nperformance, adding at least 10% improvement, against both datasets."
  },
  {
    "arxiv_id": "2404.04234",
    "title": "player2vec: A Language Modeling Approach to Understand Player Behavior in Games",
    "url": "http://arxiv.org/abs/2404.04234v1",
    "abstract": "Methods for learning latent user representations from historical behavior\nlogs have gained traction for recommendation tasks in e-commerce, content\nstreaming, and other settings. However, this area still remains relatively\nunderexplored in video and mobile gaming contexts. In this work, we present a\nnovel method for overcoming this limitation by extending a long-range\nTransformer model from the natural language processing domain to player\nbehavior data. We discuss specifics of behavior tracking in games and propose\npreprocessing and tokenization approaches by viewing in-game events in an\nanalogous way to words in sentences, thus enabling learning player\nrepresentations in a self-supervised manner in the absence of ground-truth\nannotations. We experimentally demonstrate the efficacy of the proposed\napproach in fitting the distribution of behavior events by evaluating intrinsic\nlanguage modeling metrics. Furthermore, we qualitatively analyze the emerging\nstructure of the learned embedding space and show its value for generating\ninsights into behavior patterns to inform downstream applications."
  },
  {
    "arxiv_id": "2404.03921",
    "title": "Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models",
    "url": "http://arxiv.org/abs/2404.03921v1",
    "abstract": "Sentence Embedding stands as a fundamental task within the realm of Natural\nLanguage Processing, finding extensive application in search engines, expert\nsystems, and question-and-answer platforms. With the continuous evolution of\nlarge language models such as LLaMA and Mistral, research on sentence embedding\nhas recently achieved notable breakthroughs. However, these advancements mainly\npertain to fine-tuning scenarios, leaving explorations into computationally\nefficient direct inference methods for sentence representation in a nascent\nstage. This paper endeavors to bridge this research gap. Through comprehensive\nexperimentation, we challenge the widely held belief in the necessity of an\nExplicit One-word Limitation for deriving sentence embeddings from Pre-trained\nLanguage Models (PLMs). We demonstrate that this approach, while beneficial for\ngenerative models under direct inference scenario, is not imperative for\ndiscriminative models or the fine-tuning of generative PLMs. This discovery\nsheds new light on the design of manual templates in future studies. Building\nupon this insight, we propose two innovative prompt engineering techniques\ncapable of further enhancing the expressive power of PLMs' raw embeddings:\nPretended Chain of Thought and Knowledge Enhancement. We confirm their\neffectiveness across various PLM types and provide a detailed exploration of\nthe underlying factors contributing to their success."
  },
  {
    "arxiv_id": "2404.03788",
    "title": "Understanding Language Modeling Paradigm Adaptations in Recommender Systems: Lessons Learned and Open Challenges",
    "url": "http://arxiv.org/abs/2404.03788v1",
    "abstract": "The emergence of Large Language Models (LLMs) has achieved tremendous success\nin the field of Natural Language Processing owing to diverse training paradigms\nthat empower LLMs to effectively capture intricate linguistic patterns and\nsemantic representations. In particular, the recent \"pre-train, prompt and\npredict\" training paradigm has attracted significant attention as an approach\nfor learning generalizable models with limited labeled data. In line with this\nadvancement, these training paradigms have recently been adapted to the\nrecommendation domain and are seen as a promising direction in both academia\nand industry. This half-day tutorial aims to provide a thorough understanding\nof extracting and transferring knowledge from pre-trained models learned\nthrough different training paradigms to improve recommender systems from\nvarious perspectives, such as generality, sparsity, effectiveness and\ntrustworthiness. In this tutorial, we first introduce the basic concepts and a\ngeneric architecture of the language modeling paradigm for recommendation\npurposes. Then, we focus on recent advancements in adapting LLM-related\ntraining strategies and optimization objectives for different recommendation\ntasks. After that, we will systematically introduce ethical issues in LLM-based\nrecommender systems and discuss possible approaches to assessing and mitigating\nthem. We will also summarize the relevant datasets, evaluation metrics, and an\nempirical study on the recommendation performance of training paradigms.\nFinally, we will conclude the tutorial with a discussion of open challenges and\nfuture directions."
  },
  {
    "arxiv_id": "2404.05728",
    "title": "A Large-Scale Exploration of $μ$-Transfer",
    "url": "http://arxiv.org/abs/2404.05728v1",
    "abstract": "Deep learning models have become a cornerstone of modern AI research, yet\ntheir initializations and learning rates may at times be set in an opaque or\nad-hoc fashion due to the high cost of hyperparameter sweeps. The\n$\\mu$-Parameterization ($\\mu$P) offers a possible solution to this challenge,\nyielding scaling rules for model initialization and learning rates while\nreportedly enabling zero-shot hyperparameter transfer from small to large\nmodels. Despite its evident promise, the $\\mu$P method is not yet widely\nadopted, perhaps due to higher implementation complexity, many variations, or\ncomplex theoretical background. This work considers $\\mu$P empirically,\nfocusing on the popular transformer architecture, and aims to answer a simple\nquestion: does $\\mu$-Transfer yield near-optimal learning rates in practice?\nStudying over a dozen ablations with up to 1.2B parameters and 33B tokens and a\nlarge-scale experiment with up to 10B parameters and 190B tokens, we observe a\npositive answer for most settings, and discuss improvements otherwise."
  },
  {
    "arxiv_id": "2404.05694",
    "title": "Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding",
    "url": "http://arxiv.org/abs/2404.05694v1",
    "abstract": "Recent advances in natural language processing (NLP) can be largely\nattributed to the advent of pre-trained language models such as BERT and\nRoBERTa. While these models demonstrate remarkable performance on general\ndatasets, they can struggle in specialized domains such as medicine, where\nunique domain-specific terminologies, domain-specific abbreviations, and\nvarying document structures are common. This paper explores strategies for\nadapting these models to domain-specific requirements, primarily through\ncontinuous pre-training on domain-specific data. We pre-trained several German\nmedical language models on 2.4B tokens derived from translated public English\nmedical data and 3B tokens of German clinical data. The resulting models were\nevaluated on various German downstream tasks, including named entity\nrecognition (NER), multi-label classification, and extractive question\nanswering. Our results suggest that models augmented by clinical and\ntranslation-based pre-training typically outperform general domain models in\nmedical contexts. We conclude that continuous pre-training has demonstrated the\nability to match or even exceed the performance of clinical models trained from\nscratch. Furthermore, pre-training on clinical data or leveraging translated\ntexts have proven to be reliable methods for domain adaptation in medical NLP\ntasks."
  },
  {
    "arxiv_id": "2404.05624",
    "title": "LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking",
    "url": "http://arxiv.org/abs/2404.05624v1",
    "abstract": "The use of LLMs for natural language processing has become a popular trend in\nthe past two years, driven by their formidable capacity for context\ncomprehension and learning, which has inspired a wave of research from\nacademics and industry professionals. However, for certain NLP tasks, such as\nNER, the performance of LLMs still falls short when compared to supervised\nlearning methods. In our research, we developed a NER processing framework\ncalled LTNER that incorporates a revolutionary Contextualized Entity Marking\nGen Method. By leveraging the cost-effective GPT-3.5 coupled with context\nlearning that does not require additional training, we significantly improved\nthe accuracy of LLMs in handling NER tasks. The F1 score on the CoNLL03 dataset\nincreased from the initial 85.9% to 91.9%, approaching the performance of\nsupervised fine-tuning. This outcome has led to a deeper understanding of the\npotential of LLMs."
  },
  {
    "arxiv_id": "2404.05415",
    "title": "Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations",
    "url": "http://arxiv.org/abs/2404.05415v1",
    "abstract": "In acupuncture therapy, the accurate location of acupoints is essential for\nits effectiveness. The advanced language understanding capabilities of large\nlanguage models (LLMs) like Generative Pre-trained Transformers (GPT) present a\nsignificant opportunity for extracting relations related to acupoint locations\nfrom textual knowledge sources. This study aims to compare the performance of\nGPT with traditional deep learning models (Long Short-Term Memory (LSTM) and\nBidirectional Encoder Representations from Transformers for Biomedical Text\nMining (BioBERT)) in extracting acupoint-related location relations and assess\nthe impact of pretraining and fine-tuning on GPT's performance. We utilized the\nWorld Health Organization Standard Acupuncture Point Locations in the Western\nPacific Region (WHO Standard) as our corpus, which consists of descriptions of\n361 acupoints. Five types of relations ('direction_of,' 'distance_of,'\n'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints\nwere annotated. Five models were compared: BioBERT, LSTM, pre-trained GPT-3.5,\nfine-tuned GPT-3.5, as well as pre-trained GPT-4. Performance metrics included\nmicro-average exact match precision, recall, and F1 scores. Our results\ndemonstrate that fine-tuned GPT-3.5 consistently outperformed other models in\nF1 scores across all relation types. Overall, it achieved the highest\nmicro-average F1 score of 0.92. This study underscores the effectiveness of\nLLMs like GPT in extracting relations related to acupoint locations, with\nimplications for accurately modeling acupuncture knowledge and promoting\nstandard implementation in acupuncture training and practice. The findings also\ncontribute to advancing informatics applications in traditional and\ncomplementary medicine, showcasing the potential of LLMs in natural language\nprocessing."
  },
  {
    "arxiv_id": "2404.04997",
    "title": "Adapting LLMs for Efficient Context Processing through Soft Prompt Compression",
    "url": "http://arxiv.org/abs/2404.04997v1",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has inaugurated a\ntransformative epoch in natural language processing, fostering unprecedented\nproficiency in text generation, comprehension, and contextual scrutiny.\nNevertheless, effectively handling extensive contexts, crucial for myriad\napplications, poses a formidable obstacle owing to the intrinsic constraints of\nthe models' context window sizes and the computational burdens entailed by\ntheir operations. This investigation presents an innovative framework that\nstrategically tailors LLMs for streamlined context processing by harnessing the\nsynergies among natural language summarization, soft prompt compression, and\naugmented utility preservation mechanisms. Our methodology, dubbed\nSoftPromptComp, amalgamates natural language prompts extracted from\nsummarization methodologies with dynamically generated soft prompts to forge a\nconcise yet semantically robust depiction of protracted contexts. This\ndepiction undergoes further refinement via a weighting mechanism optimizing\ninformation retention and utility for subsequent tasks. We substantiate that\nour framework markedly diminishes computational overhead and enhances LLMs'\nefficacy across various benchmarks, while upholding or even augmenting the\ncaliber of the produced content. By amalgamating soft prompt compression with\nsophisticated summarization, SoftPromptComp confronts the dual challenges of\nmanaging lengthy contexts and ensuring model scalability. Our findings point\ntowards a propitious trajectory for augmenting LLMs' applicability and\nefficiency, rendering them more versatile and pragmatic for real-world\napplications. This research enriches the ongoing discourse on optimizing\nlanguage models, providing insights into the potency of soft prompts and\nsummarization techniques as pivotal instruments for the forthcoming generation\nof NLP solutions."
  },
  {
    "arxiv_id": "2404.06290",
    "title": "Exploring the True Potential: Evaluating the Black-box Optimization Capability of Large Language Models",
    "url": "http://arxiv.org/abs/2404.06290v1",
    "abstract": "Large language models (LLMs) have demonstrated exceptional performance not\nonly in natural language processing tasks but also in a great variety of\nnon-linguistic domains. In diverse optimization scenarios, there is also a\nrising trend of applying LLMs. However, whether the application of LLMs in the\nblack-box optimization problems is genuinely beneficial remains unexplored.\nThis paper endeavors to offer deep insights into the potential of LLMs in\noptimization through a comprehensive investigation, which covers both discrete\nand continuous optimization problems to assess the efficacy and distinctive\ncharacteristics that LLMs bring to this field. Our findings reveal both the\nlimitations and advantages of LLMs in optimization. Specifically, on the one\nhand, despite the significant power consumed for running the models, LLMs\nexhibit subpar performance in pure numerical tasks, primarily due to a mismatch\nbetween the problem domain and their processing capabilities; on the other\nhand, although LLMs may not be ideal for traditional numerical optimization,\ntheir potential in broader optimization contexts remains promising, where LLMs\nexhibit the ability to solve problems in non-numerical domains and can leverage\nheuristics from the prompt to enhance their performance. To the best of our\nknowledge, this work presents the first systematic evaluation of LLMs for\nnumerical optimization. Our findings pave the way for a deeper understanding of\nLLMs' role in optimization and guide future application of LLMs in a wide range\nof scenarios."
  },
  {
    "arxiv_id": "2404.06217",
    "title": "VI-OOD: A Unified Representation Learning Framework for Textual Out-of-distribution Detection",
    "url": "http://arxiv.org/abs/2404.06217v1",
    "abstract": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the\nsafety and reliability of deep neural networks in various applications. While\nthere has been a growing focus on OOD detection in visual data, the field of\ntextual OOD detection has received less attention. Only a few attempts have\nbeen made to directly apply general OOD detection methods to natural language\nprocessing (NLP) tasks, without adequately considering the characteristics of\ntextual data. In this paper, we delve into textual OOD detection with\nTransformers. We first identify a key problem prevalent in existing OOD\ndetection methods: the biased representation learned through the maximization\nof the conditional likelihood $p(y\\mid x)$ can potentially result in subpar\nperformance. We then propose a novel variational inference framework for OOD\ndetection (VI-OOD), which maximizes the likelihood of the joint distribution\n$p(x, y)$ instead of $p(y\\mid x)$. VI-OOD is tailored for textual OOD detection\nby efficiently exploiting the representations of pre-trained Transformers.\nThrough comprehensive experiments on various text classification tasks, VI-OOD\ndemonstrates its effectiveness and wide applicability. Our code has been\nreleased at \\url{https://github.com/liam0949/LLM-OOD}."
  },
  {
    "arxiv_id": "2404.06135",
    "title": "Mansformer: Efficient Transformer of Mixed Attention for Image Deblurring and Beyond",
    "url": "http://arxiv.org/abs/2404.06135v1",
    "abstract": "The Transformer architecture has achieved remarkable success in natural\nlanguage processing and high-level vision tasks over the past few years.\nHowever, the inherent complexity of self-attention is quadratic to the size of\nthe image, leading to unaffordable computational costs for high-resolution\nvision tasks. In this paper, we introduce Concertormer, featuring a novel\nConcerto Self-Attention (CSA) mechanism designed for image deblurring. The\nproposed CSA divides self-attention into two distinct components: one\nemphasizes generally global and another concentrates on specifically local\ncorrespondence. By retaining partial information in additional dimensions\nindependent from the self-attention calculations, our method effectively\ncaptures global contextual representations with complexity linear to the image\nsize. To effectively leverage the additional dimensions, we present a\nCross-Dimensional Communication module, which linearly combines attention maps\nand thus enhances expressiveness. Moreover, we amalgamate the two-staged\nTransformer design into a single stage using the proposed gated-dconv MLP\narchitecture. While our primary objective is single-image motion deblurring,\nextensive quantitative and qualitative evaluations demonstrate that our\napproach performs favorably against the state-of-the-art methods in other\ntasks, such as deraining and deblurring with JPEG artifacts. The source codes\nand trained models will be made available to the public."
  },
  {
    "arxiv_id": "2404.06063",
    "title": "All in One: An Empirical Study of GPT for Few-Shot Aspect-Based Sentiment Anlaysis",
    "url": "http://arxiv.org/abs/2404.06063v1",
    "abstract": "Few-Shot Aspect-Based Sentiment Analysis (FSABSA) is an indispensable and\nhighly challenging task in natural language processing. However, methods based\non Pre-trained Language Models (PLMs) struggle to accommodate multiple\nsub-tasks, and methods based on Generative Pre-trained Transformers (GPTs)\nperform poorly. To address the above issues, the paper designs a\nHeuristic-enhanced Candidates Selection (HCS) strategy and further proposes All\nin One (AiO) model based on it. The model works in a two-stage, which\nsimultaneously accommodates the accuracy of PLMs and the generalization\ncapability of GPTs. Specifically, in the first stage, a backbone model based on\nPLMs generates rough heuristic candidates for the input sentence. In the second\nstage, AiO leverages LLMs' contextual learning capabilities to generate precise\npredictions. The study conducted comprehensive comparative and ablation\nexperiments on five benchmark datasets. The experimental results demonstrate\nthat the proposed model can better adapt to multiple sub-tasks, and also\noutperforms the methods that directly utilize GPTs."
  },
  {
    "arxiv_id": "2404.06001",
    "title": "Privacy Preserving Prompt Engineering: A Survey",
    "url": "http://arxiv.org/abs/2404.06001v1",
    "abstract": "Pre-trained language models (PLMs) have demonstrated significant proficiency\nin solving a wide range of general natural language processing (NLP) tasks.\nResearchers have observed a direct correlation between the performance of these\nmodels and their sizes. As a result, the sizes of these models have notably\nexpanded in recent years, persuading researchers to adopt the term large\nlanguage models (LLMs) to characterize the larger-sized PLMs. The size\nexpansion comes with a distinct capability called in-context learning (ICL),\nwhich represents a special form of prompting and allows the models to be\nutilized through the presentation of demonstration examples without\nmodifications to the model parameters. Although interesting, privacy concerns\nhave become a major obstacle in its widespread usage. Multiple studies have\nexamined the privacy risks linked to ICL and prompting in general, and have\ndevised techniques to alleviate these risks. Thus, there is a necessity to\norganize these mitigation techniques for the benefit of the community. This\nsurvey provides a systematic overview of the privacy protection methods\nemployed during ICL and prompting in general. We review, analyze, and compare\ndifferent methods under this paradigm. Furthermore, we provide a summary of the\nresources accessible for the development of these frameworks. Finally, we\ndiscuss the limitations of these frameworks and offer a detailed examination of\nthe promising areas that necessitate further exploration."
  },
  {
    "arxiv_id": "2404.06714",
    "title": "Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness",
    "url": "http://arxiv.org/abs/2404.06714v2",
    "abstract": "Recent advancements in Natural Language Processing (NLP) have seen\nLarge-scale Language Models (LLMs) excel at producing high-quality text for\nvarious purposes. Notably, in Text-To-Speech (TTS) systems, the integration of\nBERT for semantic token generation has underscored the importance of semantic\ncontent in producing coherent speech outputs. Despite this, the specific\nutility of LLMs in enhancing TTS synthesis remains considerably limited. This\nresearch introduces an innovative approach, Llama-VITS, which enhances TTS\nsynthesis by enriching the semantic content of text using LLM. Llama-VITS\nintegrates semantic embeddings from Llama2 with the VITS model, a leading\nend-to-end TTS framework. By leveraging Llama2 for the primary speech synthesis\nprocess, our experiments demonstrate that Llama-VITS matches the naturalness of\nthe original VITS (ORI-VITS) and those incorporate BERT (BERT-VITS), on the\nLJSpeech dataset, a substantial collection of neutral, clear speech. Moreover,\nour method significantly enhances emotive expressiveness on the EmoV_DB_bea_sem\ndataset, a curated selection of emotionally consistent speech from the EmoV_DB\ndataset, highlighting its potential to generate emotive speech."
  },
  {
    "arxiv_id": "2404.06634",
    "title": "Perplexed: Understanding When Large Language Models are Confused",
    "url": "http://arxiv.org/abs/2404.06634v1",
    "abstract": "Large Language Models (LLMs) have become dominant in the Natural Language\nProcessing (NLP) field causing a huge surge in progress in a short amount of\ntime. However, their limitations are still a mystery and have primarily been\nexplored through tailored datasets to analyze a specific human-level skill such\nas negation, name resolution, etc. In this paper, we introduce perplexed, a\nlibrary for exploring where a particular language model is perplexed. To show\nthe flexibility and types of insights that can be gained by perplexed, we\nconducted a case study focused on LLMs for code generation using an additional\ntool we built to help with the analysis of code models called codetokenizer.\nSpecifically, we explore success and failure cases at the token level of code\nLLMs under different scenarios pertaining to the type of coding structure the\nmodel is predicting, e.g., a variable name or operator, and how predicting of\ninternal verses external method invocations impact performance. From this\nanalysis, we found that our studied code LLMs had their worst performance on\ncoding structures where the code was not syntactically correct. Additionally,\nwe found the models to generally perform worse at predicting internal method\ninvocations than external ones. We have open sourced both of these tools to\nallow the research community to better understand LLMs in general and LLMs for\ncode generation."
  },
  {
    "arxiv_id": "2404.07677",
    "title": "ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs",
    "url": "http://arxiv.org/abs/2404.07677v1",
    "abstract": "The integration of Large Language Models (LLMs) and knowledge graphs (KGs)\nhas achieved remarkable success in various natural language processing tasks.\nHowever, existing methodologies that integrate LLMs and KGs often navigate the\ntask-solving process solely based on the LLM's analysis of the question,\noverlooking the rich cognitive potential inherent in the vast knowledge\nencapsulated in KGs. To address this, we introduce Observation-Driven Agent\n(ODA), a novel AI agent framework tailored for tasks involving KGs. ODA\nincorporates KG reasoning abilities via global observation, which enhances\nreasoning capabilities through a cyclical paradigm of observation, action, and\nreflection. Confronting the exponential explosion of knowledge during\nobservation, we innovatively design a recursive observation mechanism.\nSubsequently, we integrate the observed knowledge into the action and\nreflection modules. Through extensive experiments, ODA demonstrates\nstate-of-the-art performance on several datasets, notably achieving accuracy\nimprovements of 12.87% and 8.9%."
  },
  {
    "arxiv_id": "2404.07439",
    "title": "Behavior Trees Enable Structured Programming of Language Model Agents",
    "url": "http://arxiv.org/abs/2404.07439v1",
    "abstract": "Language models trained on internet-scale data sets have shown an impressive\nability to solve problems in Natural Language Processing and Computer Vision.\nHowever, experience is showing that these models are frequently brittle in\nunexpected ways, and require significant scaffolding to ensure that they\noperate correctly in the larger systems that comprise \"language-model agents.\"\nIn this paper, we argue that behavior trees provide a unifying framework for\ncombining language models with classical AI and traditional programming. We\nintroduce Dendron, a Python library for programming language model agents using\nbehavior trees. We demonstrate the approach embodied by Dendron in three case\nstudies: building a chat agent, a camera-based infrastructure inspection agent\nfor use on a mobile robot or vehicle, and an agent that has been built to\nsatisfy safety constraints that it did not receive through instruction tuning\nor RLHF."
  },
  {
    "arxiv_id": "2404.09516",
    "title": "State Space Model for New-Generation Network Alternative to Transformers: A Survey",
    "url": "http://arxiv.org/abs/2404.09516v1",
    "abstract": "In the post-deep learning era, the Transformer architecture has demonstrated\nits powerful performance across pre-trained big models and various downstream\ntasks. However, the enormous computational demands of this architecture have\ndeterred many researchers. To further reduce the complexity of attention\nmodels, numerous efforts have been made to design more efficient methods. Among\nthem, the State Space Model (SSM), as a possible replacement for the\nself-attention based Transformer model, has drawn more and more attention in\nrecent years. In this paper, we give the first comprehensive review of these\nworks and also provide experimental comparisons and analysis to better\ndemonstrate the features and advantages of SSM. Specifically, we first give a\ndetailed description of principles to help the readers quickly capture the key\nideas of SSM. After that, we dive into the reviews of existing SSMs and their\nvarious applications, including natural language processing, computer vision,\ngraph, multi-modal and multi-media, point cloud/event stream, time series data,\nand other domains. In addition, we give statistical comparisons and analysis of\nthese models and hope it helps the readers to understand the effectiveness of\ndifferent structures on various tasks. Then, we propose possible research\npoints in this direction to better promote the development of the theoretical\nmodel and application of SSM. More related works will be continuously updated\non the following GitHub:\nhttps://github.com/Event-AHU/Mamba_State_Space_Model_Paper_List."
  },
  {
    "arxiv_id": "2404.09135",
    "title": "Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions",
    "url": "http://arxiv.org/abs/2404.09135v1",
    "abstract": "Natural Language Processing (NLP) is witnessing a remarkable breakthrough\ndriven by the success of Large Language Models (LLMs). LLMs have gained\nsignificant attention across academia and industry for their versatile\napplications in text generation, question answering, and text summarization. As\nthe landscape of NLP evolves with an increasing number of domain-specific LLMs\nemploying diverse techniques and trained on various corpus, evaluating\nperformance of these models becomes paramount. To quantify the performance,\nit's crucial to have a comprehensive grasp of existing metrics. Among the\nevaluation, metrics which quantifying the performance of LLMs play a pivotal\nrole. This paper offers a comprehensive exploration of LLM evaluation from a\nmetrics perspective, providing insights into the selection and interpretation\nof metrics currently in use. Our main goal is to elucidate their mathematical\nformulations and statistical interpretations. We shed light on the application\nof these metrics using recent Biomedical LLMs. Additionally, we offer a\nsuccinct comparison of these metrics, aiding researchers in selecting\nappropriate metrics for diverse tasks. The overarching goal is to furnish\nresearchers with a pragmatic guide for effective LLM evaluation and metric\nselection, thereby advancing the understanding and application of these large\nlanguage models."
  },
  {
    "arxiv_id": "2404.09763",
    "title": "KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models",
    "url": "http://arxiv.org/abs/2404.09763v1",
    "abstract": "Citation Text Generation (CTG) is a task in natural language processing (NLP)\nthat aims to produce text that accurately cites or references a cited document\nwithin a source document. In CTG, the generated text draws upon contextual cues\nfrom both the source document and the cited paper, ensuring accurate and\nrelevant citation information is provided. Previous work in the field of\ncitation generation is mainly based on the text summarization of documents.\nFollowing this, this paper presents a framework, and a comparative study to\ndemonstrate the use of Large Language Models (LLMs) for the task of citation\ngeneration. Also, we have shown the improvement in the results of citation\ngeneration by incorporating the knowledge graph relations of the papers in the\nprompt for the LLM to better learn the relationship between the papers. To\nassess how well our model is performing, we have used a subset of standard\nS2ORC dataset, which only consists of computer science academic research papers\nin the English Language. Vicuna performs best for this task with 14.15 Meteor,\n12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and\nimproves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by\nincluding knowledge graphs."
  },
  {
    "arxiv_id": "2404.09754",
    "title": "Resilience of Large Language Models for Noisy Instructions",
    "url": "http://arxiv.org/abs/2404.09754v1",
    "abstract": "As the rapidly advancing domain of natural language processing (NLP), large\nlanguage models (LLMs) have emerged as powerful tools for interpreting human\ncommands and generating text across various tasks. Nonetheless, the resilience\nof LLMs to handle text containing inherent errors, stemming from human\ninteractions and collaborative systems, has not been thoroughly explored. Our\nstudy investigates the resilience of LLMs against five common types of\ndisruptions including 1) ASR (Automatic Speech Recognition) errors, 2) OCR\n(Optical Character Recognition) errors, 3) grammatical mistakes, 4)\ntypographical errors, and 5) distractive content. We aim to investigate how\nthese models react by deliberately embedding these errors into instructions.\nOur findings reveal that while some LLMs show a degree of resistance to certain\ntypes of noise, their overall performance significantly suffers. This\nemphasizes the importance of further investigation into enhancing model\nresilience. In response to the observed decline in performance, our study also\nevaluates a \"re-pass\" strategy, designed to purify the instructions of noise\nbefore the LLMs process them. Our analysis indicates that correcting noisy\ninstructions, particularly for open-source LLMs, presents significant\nchallenges."
  },
  {
    "arxiv_id": "2404.10329",
    "title": "Towards Complex Ontology Alignment using Large Language Models",
    "url": "http://arxiv.org/abs/2404.10329v1",
    "abstract": "Ontology alignment, a critical process in the Semantic Web for detecting\nrelationships between different ontologies, has traditionally focused on\nidentifying so-called \"simple\" 1-to-1 relationships through class labels and\nproperties comparison. The more practically useful exploration of more complex\nalignments remains a hard problem to automate, and as such is largely\nunderexplored, i.e. in application practice it is usually done manually by\nontology and domain experts. Recently, the surge in Natural Language Processing\n(NLP) capabilities, driven by advancements in Large Language Models (LLMs),\npresents new opportunities for enhancing ontology engineering practices,\nincluding ontology alignment tasks. This paper investigates the application of\nLLM technologies to tackle the complex ontology alignment challenge. Leveraging\na prompt-based approach and integrating rich ontology content so-called modules\nour work constitutes a significant advance towards automating the complex\nalignment task."
  },
  {
    "arxiv_id": "2404.10308",
    "title": "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs",
    "url": "http://arxiv.org/abs/2404.10308v1",
    "abstract": "Large language models (LLMs) have shown remarkable performance in various\nnatural language processing tasks. However, a primary constraint they face is\nthe context limit, i.e., the maximum number of tokens they can process.\nPrevious works have explored architectural changes and modifications in\npositional encoding to relax the constraint, but they often require expensive\ntraining or do not address the computational demands of self-attention. In this\npaper, we present Hierarchical cOntext MERging (HOMER), a new training-free\nscheme designed to overcome the limitations. HOMER uses a divide-and-conquer\nalgorithm, dividing long inputs into manageable chunks. Each chunk is then\nprocessed collectively, employing a hierarchical strategy that merges adjacent\nchunks at progressive transformer layers. A token reduction technique precedes\neach merging, ensuring memory usage efficiency. We also propose an optimized\ncomputational order reducing the memory requirement to logarithmically scale\nwith respect to input length, making it especially favorable for environments\nwith tight memory restrictions. Our experiments demonstrate the proposed\nmethod's superior performance and memory efficiency, enabling the broader use\nof LLMs in contexts requiring extended context. Code is available at\nhttps://github.com/alinlab/HOMER."
  },
  {
    "arxiv_id": "2404.10297",
    "title": "Future Language Modeling from Temporal Document History",
    "url": "http://arxiv.org/abs/2404.10297v1",
    "abstract": "Predicting the future is of great interest across many aspects of human\nactivity. Businesses are interested in future trends, traders are interested in\nfuture stock prices, and companies are highly interested in future\ntechnological breakthroughs. While there are many automated systems for\npredicting future numerical data, such as weather, stock prices, and demand for\nproducts, there is relatively little work in automatically predicting textual\ndata. Humans are interested in textual data predictions because it is a natural\nformat for our consumption, and experts routinely make predictions in a textual\nformat (Christensen et al., 2004; Tetlock & Gardner, 2015; Frick, 2015).\nHowever, there has been relatively little formalization of this general problem\nin the machine learning or natural language processing communities. To address\nthis gap, we introduce the task of future language modeling: probabilistic\nmodeling of texts in the future based on a temporal history of texts. To our\nknowledge, our work is the first work to formalize the task of predicting the\nfuture in this way. We show that it is indeed possible to build future language\nmodels that improve upon strong non-temporal language model baselines, opening\nthe door to working on this important, and widely applicable problem."
  },
  {
    "arxiv_id": "2404.10097",
    "title": "LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model",
    "url": "http://arxiv.org/abs/2404.10097v1",
    "abstract": "A contract is a type of legal document commonly used in organizations.\nContract review is an integral and repetitive process to avoid business risk\nand liability. Contract analysis requires the identification and classification\nof key provisions and paragraphs within an agreement. Identification and\nvalidation of contract clauses can be a time-consuming and challenging task\ndemanding the services of trained and expensive lawyers, paralegals or other\nlegal assistants. Classification of legal provisions in contracts using\nartificial intelligence and natural language processing is complex due to the\nrequirement of domain-specialized legal language for model training and the\nscarcity of sufficient labeled data in the legal domain. Using general-purpose\nmodels is not effective in this context due to the use of specialized legal\nvocabulary in contracts which may not be recognized by a general model. To\naddress this problem, we propose the use of a pre-trained large language model\nwhich is subsequently calibrated on legal taxonomy. We propose LegalPro-BERT, a\nBERT transformer architecture model that we fine-tune to efficiently handle\nclassification task for legal provisions. We conducted experiments to measure\nand compare metrics with current benchmark results. We found that LegalPro-BERT\noutperforms the previous benchmark used for comparison in this research."
  },
  {
    "arxiv_id": "2404.09866",
    "title": "Reimagining Self-Adaptation in the Age of Large Language Models",
    "url": "http://arxiv.org/abs/2404.09866v1",
    "abstract": "Modern software systems are subjected to various types of uncertainties\narising from context, environment, etc. To this end, self-adaptation techniques\nhave been sought out as potential solutions. Although recent advances in\nself-adaptation through the use of ML techniques have demonstrated promising\nresults, the capabilities are limited by constraints imposed by the ML\ntechniques, such as the need for training samples, the ability to generalize,\netc. Recent advancements in Generative AI (GenAI) open up new possibilities as\nit is trained on massive amounts of data, potentially enabling the\ninterpretation of uncertainties and synthesis of adaptation strategies. In this\ncontext, this paper presents a vision for using GenAI, particularly Large\nLanguage Models (LLMs), to enhance the effectiveness and efficiency of\narchitectural adaptation. Drawing parallels with human operators, we propose\nthat LLMs can autonomously generate similar, context-sensitive adaptation\nstrategies through its advanced natural language processing capabilities. This\nmethod allows software systems to understand their operational state and\nimplement adaptations that align with their architectural requirements and\nenvironmental changes. By integrating LLMs into the self-adaptive system\narchitecture, we facilitate nuanced decision-making that mirrors human-like\nadaptive reasoning. A case study with the SWIM exemplar system provides\npromising results, indicating that LLMs can potentially handle different\nadaptation scenarios. Our findings suggest that GenAI has significant potential\nto improve software systems' dynamic adaptability and resilience."
  },
  {
    "arxiv_id": "2404.11160",
    "title": "Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation",
    "url": "http://arxiv.org/abs/2404.11160v1",
    "abstract": "Large Language Models (LLMs) have become a popular choice for many Natural\nLanguage Processing (NLP) tasks due to their versatility and ability to produce\nhigh-quality results. Specifically, they are increasingly used for automatic\ncode generation to help developers tackle repetitive coding tasks. However,\nLLMs' substantial computational and memory requirements often make them\ninaccessible to users with limited resources. This paper focuses on very\nlow-cost models which offer a more accessible alternative to resource-intensive\nLLMs. We notably: (1) propose a thorough semi-manual evaluation of their\nperformance in generating Python code, (2) introduce a Chain-of-Thought (CoT)\nprompting strategy to improve model reasoning and code quality, and (3) propose\na new dataset of 60 programming problems, with varied difficulty levels,\ndesigned to extend existing benchmarks like HumanEval and EvalPlus. Our\nfindings show that some low-cost compatible models achieve competitive results\ncompared to larger models like ChatGPT despite using significantly fewer\nresources. We will make our dataset and prompts publicly available to support\nfurther research."
  },
  {
    "arxiv_id": "2404.10922",
    "title": "Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training",
    "url": "http://arxiv.org/abs/2404.10922v1",
    "abstract": "Recent advancements in language modeling have led to the emergence of Large\nLanguage Models (LLMs) capable of various natural language processing tasks.\nDespite their success in text-based tasks, applying LLMs to the speech domain\nremains limited and challenging. This paper presents BLOOMZMMS, a novel model\nthat integrates a multilingual LLM with a multilingual speech encoder, aiming\nto harness the capabilities of LLMs for speech recognition and beyond.\nUtilizing a multi-instructional training approach, we demonstrate the\ntransferability of linguistic knowledge from the text to the speech modality.\nOur experiments, conducted on 1900 hours of transcribed data from 139\nlanguages, establish that a multilingual speech representation can be\neffectively learned and aligned with a multilingual LLM. While this learned\nrepresentation initially shows limitations in task generalization, we address\nthis issue by generating synthetic targets in a multi-instructional style. Our\nzero-shot evaluation results confirm the robustness of our approach across\nmultiple tasks, including speech translation and multilingual spoken language\nunderstanding, thereby opening new avenues for applying LLMs in the speech\ndomain."
  },
  {
    "arxiv_id": "2404.12283",
    "title": "Enhancing Embedding Performance through Large Language Model-based Text Enrichment and Rewriting",
    "url": "http://arxiv.org/abs/2404.12283v1",
    "abstract": "Embedding models are crucial for various natural language processing tasks\nbut can be limited by factors such as limited vocabulary, lack of context, and\ngrammatical errors. This paper proposes a novel approach to improve embedding\nperformance by leveraging large language models (LLMs) to enrich and rewrite\ninput text before the embedding process. By utilizing ChatGPT 3.5 to provide\nadditional context, correct inaccuracies, and incorporate metadata, the\nproposed method aims to enhance the utility and accuracy of embedding models.\nThe effectiveness of this approach is evaluated on three datasets:\nBanking77Classification, TwitterSemEval 2015, and Amazon Counter-factual\nClassification. Results demonstrate significant improvements over the baseline\nmodel on the TwitterSemEval 2015 dataset, with the best-performing prompt\nachieving a score of 85.34 compared to the previous best of 81.52 on the\nMassive Text Embedding Benchmark (MTEB) Leaderboard. However, performance on\nthe other two datasets was less impressive, highlighting the importance of\nconsidering domain-specific characteristics. The findings suggest that\nLLM-based text enrichment has shown promising results to improve embedding\nperformance, particularly in certain domains. Hence, numerous limitations in\nthe process of embedding can be avoided."
  },
  {
    "arxiv_id": "2404.12171",
    "title": "Stance Detection on Social Media with Fine-Tuned Large Language Models",
    "url": "http://arxiv.org/abs/2404.12171v1",
    "abstract": "Stance detection, a key task in natural language processing, determines an\nauthor's viewpoint based on textual analysis. This study evaluates the\nevolution of stance detection methods, transitioning from early machine\nlearning approaches to the groundbreaking BERT model, and eventually to modern\nLarge Language Models (LLMs) such as ChatGPT, LLaMa-2, and Mistral-7B. While\nChatGPT's closed-source nature and associated costs present challenges, the\nopen-source models like LLaMa-2 and Mistral-7B offers an encouraging\nalternative. Initially, our research focused on fine-tuning ChatGPT, LLaMa-2,\nand Mistral-7B using several publicly available datasets. Subsequently, to\nprovide a comprehensive comparison, we assess the performance of these models\nin zero-shot and few-shot learning scenarios. The results underscore the\nexceptional ability of LLMs in accurately detecting stance, with all tested\nmodels surpassing existing benchmarks. Notably, LLaMa-2 and Mistral-7B\ndemonstrate remarkable efficiency and potential for stance detection, despite\ntheir smaller sizes compared to ChatGPT. This study emphasizes the potential of\nLLMs in stance detection and calls for more extensive research in this field."
  },
  {
    "arxiv_id": "2404.12014",
    "title": "Enhance Robustness of Language Models Against Variation Attack through Graph Integration",
    "url": "http://arxiv.org/abs/2404.12014v1",
    "abstract": "The widespread use of pre-trained language models (PLMs) in natural language\nprocessing (NLP) has greatly improved performance outcomes. However, these\nmodels' vulnerability to adversarial attacks (e.g., camouflaged hints from drug\ndealers), particularly in the Chinese language with its rich character\ndiversity/variation and complex structures, hatches vital apprehension. In this\nstudy, we propose a novel method, CHinese vAriatioN Graph Enhancement (CHANGE),\nto increase the robustness of PLMs against character variation attacks in\nChinese content. CHANGE presents a novel approach for incorporating a Chinese\ncharacter variation graph into the PLMs. Through designing different\nsupplementary tasks utilizing the graph structure, CHANGE essentially enhances\nPLMs' interpretation of adversarially manipulated text. Experiments conducted\nin a multitude of NLP tasks show that CHANGE outperforms current language\nmodels in combating against adversarial attacks and serves as a valuable\ncontribution to robust language model research. These findings contribute to\nthe groundwork on robust language models and highlight the substantial\npotential of graph-guided pre-training strategies for real-world applications."
  },
  {
    "arxiv_id": "2404.12010",
    "title": "ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity",
    "url": "http://arxiv.org/abs/2404.12010v1",
    "abstract": "Paraphrase generation is a pivotal task in natural language processing (NLP).\nExisting datasets in the domain lack syntactic and lexical diversity, resulting\nin paraphrases that closely resemble the source sentences. Moreover, these\ndatasets often contain hate speech and noise, and may unintentionally include\nnon-English language sentences. This research introduces ParaFusion, a\nlarge-scale, high-quality English paraphrase dataset developed using Large\nLanguage Models (LLM) to address these challenges. ParaFusion augments existing\ndatasets with high-quality data, significantly enhancing both lexical and\nsyntactic diversity while maintaining close semantic similarity. It also\nmitigates the presence of hate speech and reduces noise, ensuring a cleaner and\nmore focused English dataset. Results show that ParaFusion offers at least a\n25% improvement in both syntactic and lexical diversity, measured across\nseveral metrics for each data source. The paper also aims to set a gold\nstandard for paraphrase evaluation as it contains one of the most comprehensive\nevaluation strategies to date. The results underscore the potential of\nParaFusion as a valuable resource for improving NLP applications."
  },
  {
    "arxiv_id": "2404.11978",
    "title": "EVIT: Event-Oriented Instruction Tuning for Event Reasoning",
    "url": "http://arxiv.org/abs/2404.11978v1",
    "abstract": "Events refer to specific occurrences, incidents, or happenings that take\nplace under a particular background. Event reasoning aims to infer events\naccording to certain relations and predict future events. The cutting-edge\ntechniques for event reasoning play a crucial role in various natural language\nprocessing applications. Large language models (LLMs) have made significant\nadvancements in event reasoning owing to their wealth of knowledge and\nreasoning capabilities. However, smaller instruction-tuned models currently in\nuse do not consistently demonstrate exceptional proficiency in managing these\ntasks. This discrepancy arises from the absence of explicit modeling of events\nand the interconnections of them within their instruction data. Consequently,\nthese models face challenges in comprehending event structures and semantics\nwhile struggling to bridge the gap between their interpretations and human\nunderstanding of events. Additionally, their limitations in grasping event\nrelations lead to constrained event reasoning abilities to effectively deduce\nand incorporate pertinent event knowledge. In this paper, we propose\nEvent-Oriented Instruction Tuning (EvIT) to train our LLM. Specifically, we\nfirst propose a novel structure named event quadruple which contains the\nstructure and semantics of events and is complete in the event representation.\nWe then design event-relation learning based on the structures. We encapsulate\nthe learning into the instruction-tuning formulation to better stimulate the\nevent reasoning capacity of our model. We design a heuristic unsupervised\nmethod to mine event quadruple from a large-scale corpus. At last, we finetune\na Llama model on our Event-Oriented Instruction Tuning. We conduct extensive\nexperiments on event reasoning tasks on several datasets. Automatic and human\nevaluations demonstrate EvIT achieves competitive performances on event\nreasoning."
  },
  {
    "arxiv_id": "2404.11782",
    "title": "REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models",
    "url": "http://arxiv.org/abs/2404.11782v1",
    "abstract": "The extensive scope of large language models (LLMs) across various domains\nunderscores the critical importance of responsibility in their application,\nbeyond natural language processing. In particular, the randomized nature of\nLLMs, coupled with inherent biases and historical stereotypes in data, raises\ncritical concerns regarding reliability and equity. Addressing these challenges\nare necessary before using LLMs for applications with societal impact. Towards\naddressing this gap, we introduce REQUAL-LM, a novel method for finding\nreliable and equitable LLM outputs through aggregation. Specifically, we\ndevelop a Monte Carlo method based on repeated sampling to find a reliable\noutput close to the mean of the underlying distribution of possible outputs. We\nformally define the terms such as reliability and bias, and design an\nequity-aware aggregation to minimize harmful bias while finding a highly\nreliable output. REQUAL-LM does not require specialized hardware, does not\nimpose a significant computing load, and uses LLMs as a blackbox. This design\nchoice enables seamless scalability alongside the rapid advancement of LLM\ntechnologies. Our system does not require retraining the LLMs, which makes it\ndeployment ready and easy to adapt. Our comprehensive experiments using various\ntasks and datasets demonstrate that REQUAL- LM effectively mitigates bias and\nselects a more equitable response, specifically the outputs that properly\nrepresents minority groups."
  },
  {
    "arxiv_id": "2404.11706",
    "title": "Pretraining Billion-scale Geospatial Foundational Models on Frontier",
    "url": "http://arxiv.org/abs/2404.11706v1",
    "abstract": "As AI workloads increase in scope, generalization capability becomes\nchallenging for small task-specific models and their demand for large amounts\nof labeled training samples increases. On the contrary, Foundation Models (FMs)\nare trained with internet-scale unlabeled data via self-supervised learning and\nhave been shown to adapt to various tasks with minimal fine-tuning. Although\nlarge FMs have demonstrated significant impact in natural language processing\nand computer vision, efforts toward FMs for geospatial applications have been\nrestricted to smaller size models, as pretraining larger models requires very\nlarge computing resources equipped with state-of-the-art hardware accelerators.\nCurrent satellite constellations collect 100+TBs of data a day, resulting in\nimages that are billions of pixels and multimodal in nature. Such geospatial\ndata poses unique challenges opening up new opportunities to develop FMs. We\ninvestigate billion scale FMs and HPC training profiles for geospatial\napplications by pretraining on publicly available data. We studied from\nend-to-end the performance and impact in the solution by scaling the model\nsize. Our larger 3B parameter size model achieves up to 30% improvement in top1\nscene classification accuracy when comparing a 100M parameter model. Moreover,\nwe detail performance experiments on the Frontier supercomputer, America's\nfirst exascale system, where we study different model and data parallel\napproaches using PyTorch's Fully Sharded Data Parallel library. Specifically,\nwe study variants of the Vision Transformer architecture (ViT), conducting\nperformance analysis for ViT models with size up to 15B parameters. By\ndiscussing throughput and performance bottlenecks under different parallelism\nconfigurations, we offer insights on how to leverage such leadership-class HPC\nresources when developing large models for geospatial imagery applications."
  },
  {
    "arxiv_id": "2404.12736",
    "title": "Large Language Model Supply Chain: A Research Agenda",
    "url": "http://arxiv.org/abs/2404.12736v1",
    "abstract": "The rapid advancement of large language models (LLMs) has revolutionized\nartificial intelligence, introducing unprecedented capabilities in natural\nlanguage processing and multimodal content generation. However, the increasing\ncomplexity and scale of these models have given rise to a multifaceted supply\nchain that presents unique challenges across infrastructure, foundation models,\nand downstream applications. This paper provides the first comprehensive\nresearch agenda of the LLM supply chain, offering a structured approach to\nidentify critical challenges and opportunities through the dual lenses of\nsoftware engineering (SE) and security & privacy (S\\&P). We begin by\nestablishing a clear definition of the LLM supply chain, encompassing its\ncomponents and dependencies. We then analyze each layer of the supply chain,\npresenting a vision for robust and secure LLM development, reviewing the\ncurrent state of practices and technologies, and identifying key challenges and\nresearch opportunities. This work aims to bridge the existing research gap in\nsystematically understanding the multifaceted issues within the LLM supply\nchain, offering valuable insights to guide future efforts in this rapidly\nevolving domain."
  },
  {
    "arxiv_id": "2404.12460",
    "title": "NLP-enabled trajectory map-matching in urban road networks using transformer sequence-to-sequence model",
    "url": "http://arxiv.org/abs/2404.12460v1",
    "abstract": "Vehicular trajectory data from geolocation telematics is vital for analyzing\nurban mobility patterns. Map-matching aligns noisy, sparsely sampled GPS\ntrajectories with digital road maps to reconstruct accurate vehicle paths.\nTraditional methods rely on geometric proximity, topology, and shortest-path\nheuristics, but they overlook two key factors: (1) drivers may prefer routes\nbased on local road characteristics rather than shortest paths, revealing\nlearnable shared preferences, and (2) GPS noise varies spatially due to\nmultipath effects. These factors can reduce the effectiveness of conventional\nmethods in complex scenarios and increase the effort required for\nheuristic-based implementations. This study introduces a data-driven, deep\nlearning-based map-matching framework, formulating the task as machine\ntranslation, inspired by NLP. Specifically, a transformer-based encoder-decoder\nmodel learns contextual representations of noisy GPS points to infer trajectory\nbehavior and road structures in an end-to-end manner. Trained on large-scale\ntrajectory data, the method improves path estimation accuracy. Experiments on\nsynthetic trajectories show that this approach outperforms conventional methods\nby integrating contextual awareness. Evaluation on real-world GPS traces from\nManhattan, New York, achieves 75% accuracy in reconstructing navigated routes.\nThese results highlight the effectiveness of transformers in capturing drivers'\ntrajectory behaviors, spatial dependencies, and noise patterns, offering a\nscalable, robust solution for map-matching. This work contributes to advancing\ntrajectory-driven foundation models for geospatial modeling and urban mobility\napplications."
  },
  {
    "arxiv_id": "2404.13968",
    "title": "Protecting Your LLMs with Information Bottleneck",
    "url": "http://arxiv.org/abs/2404.13968v1",
    "abstract": "The advent of large language models (LLMs) has revolutionized the field of\nnatural language processing, yet they might be attacked to produce harmful\ncontent. Despite efforts to ethically align LLMs, these are often fragile and\ncan be circumvented by jailbreaking attacks through optimized or manual\nadversarial prompts. To address this, we introduce the Information Bottleneck\nProtector (IBProtector), a defense mechanism grounded in the information\nbottleneck principle, and we modify the objective to avoid trivial solutions.\nThe IBProtector selectively compresses and perturbs prompts, facilitated by a\nlightweight and trainable extractor, preserving only essential information for\nthe target LLMs to respond with the expected answer. Moreover, we further\nconsider a situation where the gradient is not visible to be compatible with\nany LLM. Our empirical evaluations show that IBProtector outperforms current\ndefense methods in mitigating jailbreak attempts, without overly affecting\nresponse quality or inference speed. Its effectiveness and adaptability across\nvarious attack methods and target LLMs underscore the potential of IBProtector\nas a novel, transferable defense that bolsters the security of LLMs without\nrequiring modifications to the underlying models."
  },
  {
    "arxiv_id": "2404.13925",
    "title": "MARIO Eval: Evaluate Your Math LLM with your Math LLM--A mathematical dataset evaluation toolkit",
    "url": "http://arxiv.org/abs/2404.13925v1",
    "abstract": "Large language models (LLMs) have been explored in a variety of reasoning\ntasks including solving of mathematical problems. Each math dataset typically\nincludes its own specially designed evaluation script, which, while suitable\nfor its intended use, lacks generalizability across different datasets.\nConsequently, updates and adaptations to these evaluation tools tend to occur\nwithout being systematically reported, leading to inconsistencies and obstacles\nto fair comparison across studies. To bridge this gap, we introduce a\ncomprehensive mathematical evaluation toolkit that not only utilizes a python\ncomputer algebra system (CAS) for its numerical accuracy, but also integrates\nan optional LLM, known for its considerable natural language processing\ncapabilities. To validate the effectiveness of our toolkit, we manually\nannotated two distinct datasets. Our experiments demonstrate that the toolkit\nyields more robust evaluation results compared to prior works, even without an\nLLM. Furthermore, when an LLM is incorporated, there is a notable enhancement.\nThe code for our method will be made available at\n\\url{https://github.com/MARIO-Math-Reasoning/math_evaluation}."
  },
  {
    "arxiv_id": "2404.13434",
    "title": "Nested-TNT: Hierarchical Vision Transformers with Multi-Scale Feature Processing",
    "url": "http://arxiv.org/abs/2404.13434v1",
    "abstract": "Transformer has been applied in the field of computer vision due to its\nexcellent performance in natural language processing, surpassing traditional\nconvolutional neural networks and achieving new state-of-the-art. ViT divides\nan image into several local patches, known as \"visual sentences\". However, the\ninformation contained in the image is vast and complex, and focusing only on\nthe features at the \"visual sentence\" level is not enough. The features between\nlocal patches should also be taken into consideration. In order to achieve\nfurther improvement, the TNT model is proposed, whose algorithm further divides\nthe image into smaller patches, namely \"visual words,\" achieving more accurate\nresults. The core of Transformer is the Multi-Head Attention mechanism, and\ntraditional attention mechanisms ignore interactions across different attention\nheads. In order to reduce redundancy and improve utilization, we introduce the\nnested algorithm and apply the Nested-TNT to image classification tasks. The\nexperiment confirms that the proposed model has achieved better classification\nperformance over ViT and TNT, exceeding 2.25%, 1.1% on dataset CIFAR10 and\n2.78%, 0.25% on dataset FLOWERS102 respectively."
  },
  {
    "arxiv_id": "2404.14850",
    "title": "Simple, Efficient and Scalable Structure-aware Adapter Boosts Protein Language Models",
    "url": "http://arxiv.org/abs/2404.14850v1",
    "abstract": "Fine-tuning Pre-trained protein language models (PLMs) has emerged as a\nprominent strategy for enhancing downstream prediction tasks, often\noutperforming traditional supervised learning approaches. As a widely applied\npowerful technique in natural language processing, employing\nParameter-Efficient Fine-Tuning techniques could potentially enhance the\nperformance of PLMs. However, the direct transfer to life science tasks is\nnon-trivial due to the different training strategies and data forms. To address\nthis gap, we introduce SES-Adapter, a simple, efficient, and scalable adapter\nmethod for enhancing the representation learning of PLMs. SES-Adapter\nincorporates PLM embeddings with structural sequence embeddings to create\nstructure-aware representations. We show that the proposed method is compatible\nwith different PLM architectures and across diverse tasks. Extensive\nevaluations are conducted on 2 types of folding structures with notable quality\ndifferences, 9 state-of-the-art baselines, and 9 benchmark datasets across\ndistinct downstream tasks. Results show that compared to vanilla PLMs,\nSES-Adapter improves downstream task performance by a maximum of 11% and an\naverage of 3%, with significantly accelerated training speed by a maximum of\n1034% and an average of 362%, the convergence rate is also improved by\napproximately 2 times. Moreover, positive optimization is observed even with\nlow-quality predicted structures. The source code for SES-Adapter is available\nat https://github.com/tyang816/SES-Adapter."
  },
  {
    "arxiv_id": "2404.15159",
    "title": "MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA based Mixture of Experts",
    "url": "http://arxiv.org/abs/2404.15159v1",
    "abstract": "Fine-tuning Large Language Models (LLMs) is a common practice to adapt\npre-trained models for specific applications. While methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multi-task scenarios. In contrast,\nMixture-of-Expert (MoE) models, such as Mixtral 8x7B, demonstrate remarkable\nperformance in multi-task learning scenarios while maintaining a reduced\nparameter count. However, the resource requirements of these MoEs remain\nchallenging, particularly for consumer-grade GPUs with less than 24GB memory.\nTo tackle these challenges, we propose MixLoRA, an approach to construct a\nresource-efficient sparse MoE model based on LoRA. MixLoRA inserts multiple\nLoRA-based experts within the feed-forward network block of a frozen\npre-trained dense model and employs a commonly used top-k router. Unlike other\nLoRA-based MoE methods, MixLoRA enhances model performance by utilizing\nindependent attention-layer LoRA adapters. Additionally, an auxiliary load\nbalance loss is employed to address the imbalance problem of the router. Our\nevaluations show that MixLoRA improves about 9% accuracy compared to\nstate-of-the-art PEFT methods in multi-task learning scenarios. We also propose\na new high-throughput framework to alleviate the computation and memory\nbottlenecks during the training and inference of MOE models. This framework\nreduces GPU memory consumption by 40% and token computation latency by 30%\nduring both training and inference."
  },
  {
    "arxiv_id": "2404.15578",
    "title": "Can Foundational Large Language Models Assist with Conducting Pharmaceuticals Manufacturing Investigations?",
    "url": "http://arxiv.org/abs/2404.15578v1",
    "abstract": "General purpose Large Language Models (LLM) such as the Generative Pretrained\nTransformer (GPT) and Large Language Model Meta AI (LLaMA) have attracted much\nattention in recent years. There is strong evidence that these models can\nperform remarkably well in various natural language processing tasks. However,\nhow to leverage them to approach domain-specific use cases and drive value\nremains an open question. In this work, we focus on a specific use case,\npharmaceutical manufacturing investigations, and propose that leveraging\nhistorical records of manufacturing incidents and deviations in an organization\ncan be beneficial for addressing and closing new cases, or de-risking new\nmanufacturing campaigns. Using a small but diverse dataset of real\nmanufacturing deviations selected from different product lines, we evaluate and\nquantify the power of three general purpose LLMs (GPT-3.5, GPT-4, and Claude-2)\nin performing tasks related to the above goal. In particular, (1) the ability\nof LLMs in automating the process of extracting specific information such as\nroot cause of a case from unstructured data, as well as (2) the possibility of\nidentifying similar or related deviations by performing semantic search on the\ndatabase of historical records are examined. While our results point to the\nhigh accuracy of GPT-4 and Claude-2 in the information extraction task, we\ndiscuss cases of complex interplay between the apparent reasoning and\nhallucination behavior of LLMs as a risk factor. Furthermore, we show that\nsemantic search on vector embedding of deviation descriptions can be used to\nidentify similar records, such as those with a similar type of defect, with a\nhigh level of accuracy. We discuss further improvements to enhance the accuracy\nof similar record identification."
  },
  {
    "arxiv_id": "2404.15382",
    "title": "Feature Distribution Shift Mitigation with Contrastive Pretraining for Intrusion Detection",
    "url": "http://arxiv.org/abs/2404.15382v1",
    "abstract": "In recent years, there has been a growing interest in using Machine Learning\n(ML), especially Deep Learning (DL) to solve Network Intrusion Detection (NID)\nproblems. However, the feature distribution shift problem remains a difficulty,\nbecause the change in features' distributions over time negatively impacts the\nmodel's performance. As one promising solution, model pretraining has emerged\nas a novel training paradigm, which brings robustness against feature\ndistribution shift and has proven to be successful in Computer Vision (CV) and\nNatural Language Processing (NLP). To verify whether this paradigm is\nbeneficial for NID problem, we propose SwapCon, a ML model in the context of\nNID, which compresses shift-invariant feature information during the\npretraining stage and refines during the finetuning stage. We exemplify the\nevidence of feature distribution shift using the Kyoto2006+ dataset. We\ndemonstrate how pretraining a model with the proper size can increase\nrobustness against feature distribution shifts by over 8%. Moreover, we show\nhow an adequate numerical embedding strategy also enhances the performance of\npretrained models. Further experiments show that the proposed SwapCon model\nalso outperforms eXtreme Gradient Boosting (XGBoost) and K-Nearest Neighbor\n(KNN) based models by a large margin."
  },
  {
    "arxiv_id": "2404.16670",
    "title": "EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning",
    "url": "http://arxiv.org/abs/2404.16670v1",
    "abstract": "Visual Instruction Tuning represents a novel learning paradigm involving the\nfine-tuning of pre-trained language models using task-specific instructions.\nThis paradigm shows promising zero-shot results in various natural language\nprocessing tasks but is still unexplored in vision emotion understanding. In\nthis work, we focus on enhancing the model's proficiency in understanding and\nadhering to instructions related to emotional contexts. Initially, we identify\nkey visual clues critical to visual emotion recognition. Subsequently, we\nintroduce a novel GPT-assisted pipeline for generating emotion visual\ninstruction data, effectively addressing the scarcity of annotated instruction\ndata in this domain. Expanding on the groundwork established by InstructBLIP,\nour proposed EmoVIT architecture incorporates emotion-specific instruction\ndata, leveraging the powerful capabilities of Large Language Models to enhance\nperformance. Through extensive experiments, our model showcases its proficiency\nin emotion classification, adeptness in affective reasoning, and competence in\ncomprehending humor. The comparative analysis provides a robust benchmark for\nEmotion Visual Instruction Tuning in the era of LLMs, providing valuable\ninsights and opening avenues for future exploration in this domain. Our code is\navailable at \\url{https://github.com/aimmemotion/EmoVIT}."
  },
  {
    "arxiv_id": "2404.16653",
    "title": "Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)",
    "url": "http://arxiv.org/abs/2404.16653v1",
    "abstract": "Linguistic ambiguity continues to represent a significant challenge for\nnatural language processing (NLP) systems, notwithstanding the advancements in\narchitectures such as Transformers and BERT. Inspired by the recent success of\ninstructional models like ChatGPT and Gemini (In 2023, the artificial\nintelligence was called Bard.), this study aims to analyze and discuss\nlinguistic ambiguity within these models, focusing on three types prevalent in\nBrazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a\ncorpus comprising 120 sentences, both ambiguous and unambiguous, for\nclassification, explanation, and disambiguation. The models capability to\ngenerate ambiguous sentences was also explored by soliciting sets of sentences\nfor each type of ambiguity. The results underwent qualitative analysis, drawing\non recognized linguistic references, and quantitative assessment based on the\naccuracy of the responses obtained. It was evidenced that even the most\nsophisticated models, such as ChatGPT and Gemini, exhibit errors and\ndeficiencies in their responses, with explanations often providing\ninconsistent. Furthermore, the accuracy peaked at 49.58 percent, indicating the\nneed for descriptive studies for supervised learning."
  },
  {
    "arxiv_id": "2404.16294",
    "title": "LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications",
    "url": "http://arxiv.org/abs/2404.16294v1",
    "abstract": "Electronic health records (EHR) even though a boon for healthcare\npractitioners, are growing convoluted and longer every day. Sifting around\nthese lengthy EHRs is taxing and becomes a cumbersome part of physician-patient\ninteraction. Several approaches have been proposed to help alleviate this\nprevalent issue either via summarization or sectioning, however, only a few\napproaches have truly been helpful in the past. With the rise of automated\nmethods, machine learning (ML) has shown promise in solving the task of\nidentifying relevant sections in EHR. However, most ML methods rely on labeled\ndata which is difficult to get in healthcare. Large language models (LLMs) on\nthe other hand, have performed impressive feats in natural language processing\n(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that\nend, we propose using LLMs to identify relevant section headers. We find that\nGPT-4 can effectively solve the task on both zero and few-shot settings as well\nas segment dramatically better than state-of-the-art methods. Additionally, we\nalso annotate a much harder real world dataset and find that GPT-4 struggles to\nperform well, alluding to further research and harder benchmarks."
  },
  {
    "arxiv_id": "2404.16198",
    "title": "Towards Efficient Patient Recruitment for Clinical Trials: Application of a Prompt-Based Learning Model",
    "url": "http://arxiv.org/abs/2404.16198v1",
    "abstract": "Objective: Clinical trials are essential for advancing pharmaceutical\ninterventions, but they face a bottleneck in selecting eligible participants.\nAlthough leveraging electronic health records (EHR) for recruitment has gained\npopularity, the complex nature of unstructured medical texts presents\nchallenges in efficiently identifying participants. Natural Language Processing\n(NLP) techniques have emerged as a solution with a recent focus on transformer\nmodels. In this study, we aimed to evaluate the performance of a prompt-based\nlarge language model for the cohort selection task from unstructured medical\nnotes collected in the EHR. Methods: To process the medical records, we\nselected the most related sentences of the records to the eligibility criteria\nneeded for the trial. The SNOMED CT concepts related to each eligibility\ncriterion were collected. Medical records were also annotated with MedCAT based\non the SNOMED CT ontology. Annotated sentences including concepts matched with\nthe criteria-relevant terms were extracted. A prompt-based large language model\n(Generative Pre-trained Transformer (GPT) in this study) was then used with the\nextracted sentences as the training set. To assess its effectiveness, we\nevaluated the model's performance using the dataset from the 2018 n2c2\nchallenge, which aimed to classify medical records of 311 patients based on 13\neligibility criteria through NLP techniques. Results: Our proposed model showed\nthe overall micro and macro F measures of 0.9061 and 0.8060 which were among\nthe highest scores achieved by the experiments performed with this dataset.\nConclusion: The application of a prompt-based large language model in this\nstudy to classify patients based on eligibility criteria received promising\nscores. Besides, we proposed a method of extractive summarization with the aid\nof SNOMED CT ontology that can be also applied to other medical texts."
  },
  {
    "arxiv_id": "2404.16147",
    "title": "Chat2Scenario: Scenario Extraction From Dataset Through Utilization of Large Language Model",
    "url": "http://arxiv.org/abs/2404.16147v1",
    "abstract": "The advent of Large Language Models (LLM) provides new insights to validate\nAutomated Driving Systems (ADS). In the herein-introduced work, a novel\napproach to extracting scenarios from naturalistic driving datasets is\npresented. A framework called Chat2Scenario is proposed leveraging the advanced\nNatural Language Processing (NLP) capabilities of LLM to understand and\nidentify different driving scenarios. By inputting descriptive texts of driving\nconditions and specifying the criticality metric thresholds, the framework\nefficiently searches for desired scenarios and converts them into ASAM\nOpenSCENARIO and IPG CarMaker text files. This methodology streamlines the\nscenario extraction process and enhances efficiency. Simulations are executed\nto validate the efficiency of the approach. The framework is presented based on\na user-friendly web app and is accessible via the following link:\nhttps://github.com/ftgTUGraz/Chat2Scenario."
  },
  {
    "arxiv_id": "2404.16112",
    "title": "Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges",
    "url": "http://arxiv.org/abs/2404.16112v1",
    "abstract": "Sequence modeling is a crucial area across various domains, including Natural\nLanguage Processing (NLP), speech recognition, time series forecasting, music\ngeneration, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short\nTerm Memory Networks (LSTMs) have historically dominated sequence modeling\ntasks like Machine Translation, Named Entity Recognition (NER), etc. However,\nthe advancement of transformers has led to a shift in this paradigm, given\ntheir superior performance. Yet, transformers suffer from $O(N^2)$ attention\ncomplexity and challenges in handling inductive bias. Several variations have\nbeen proposed to address these issues which use spectral networks or\nconvolutions and have performed well on a range of tasks. However, they still\nhave difficulty in dealing with long sequences. State Space Models(SSMs) have\nemerged as promising alternatives for sequence modeling paradigms in this\ncontext, especially with the advent of S4 and its variants, such as S4nd,\nHippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear\nRecurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the\nfoundational SSMs based on three paradigms namely, Gating architectures,\nStructural architectures, and Recurrent architectures. This survey also\nhighlights diverse applications of SSMs across domains such as vision, video,\naudio, speech, language (especially long sequence modeling), medical (including\ngenomics), chemical (like drug design), recommendation systems, and time series\nanalysis, including tabular data. Moreover, we consolidate the performance of\nSSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,\nImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,\nCOIN, LVU, and various time series datasets. The project page for Mamba-360\nwork is available on this webpage.\\url{https://github.com/badripatro/mamba360}."
  },
  {
    "arxiv_id": "2404.15869",
    "title": "Semantic Routing for Enhanced Performance of LLM-Assisted Intent-Based 5G Core Network Management and Orchestration",
    "url": "http://arxiv.org/abs/2404.15869v1",
    "abstract": "Large language models (LLMs) are rapidly emerging in Artificial Intelligence\n(AI) applications, especially in the fields of natural language processing and\ngenerative AI. Not limited to text generation applications, these models\ninherently possess the opportunity to leverage prompt engineering, where the\ninputs of such models can be appropriately structured to articulate a model's\npurpose explicitly. A prominent example of this is intent-based networking, an\nemerging approach for automating and maintaining network operations and\nmanagement. This paper presents semantic routing to achieve enhanced\nperformance in LLM-assisted intent-based management and orchestration of 5G\ncore networks. This work establishes an end-to-end intent extraction framework\nand presents a diverse dataset of sample user intents accompanied by a thorough\nanalysis of the effects of encoders and quantization on overall system\nperformance. The results show that using a semantic router improves the\naccuracy and efficiency of the LLM deployment compared to stand-alone LLMs with\nprompting architectures."
  },
  {
    "arxiv_id": "2404.15851",
    "title": "Porting Large Language Models to Mobile Devices for Question Answering",
    "url": "http://arxiv.org/abs/2404.15851v1",
    "abstract": "Deploying Large Language Models (LLMs) on mobile devices makes all the\ncapabilities of natural language processing available on the device. An\nimportant use case of LLMs is question answering, which can provide accurate\nand contextually relevant answers to a wide array of user queries. We describe\nhow we managed to port state of the art LLMs to mobile devices, enabling them\nto operate natively on the device. We employ the llama.cpp framework, a\nflexible and self-contained C++ framework for LLM inference. We selected a\n6-bit quantized version of the Orca-Mini-3B model with 3 billion parameters and\npresent the correct prompt format for this model. Experimental results show\nthat LLM inference runs in interactive speed on a Galaxy S21 smartphone and\nthat the model delivers high-quality answers to user queries related to\nquestions from different subjects like politics, geography or history."
  },
  {
    "arxiv_id": "2404.17437",
    "title": "Transformer For Low-frequency Extrapolating of Seismic Data",
    "url": "http://arxiv.org/abs/2404.17437v1",
    "abstract": "Full waveform inversion (FWI) is used to reconstruct the physical properties\nof subsurface media which plays an important role in seismic exploration.\nHowever, the precision of FWI is seriously affected by the absence or\ninaccuracy of low-frequency information. Therefore, reconstructing the\nlow-frequency signals accurately is highly significant in seismic data\nprocessing. Low-frequency extrapolation of seismic records can be approached as\na deep learning regression problem. Thus, to obtain low-frequency information\nfrom band-limited seismic records, a novel network structure called\nlow-frequency extrapolation transformer (LFET) is proposed to construct the\nnonlinear mapping relationship between the data missing low-frequency and\nlow-frequency data in a supervised learning approach, which is inspired by the\ntransformer model widely used in natural language processing (NLP). We apply\nmulti-head self-attention (MSA) modules to model the remote dependencies of\nseismic data. Based on this, we introduce a shifted window partitioning\napproach to reduce the calculating amount. Due to the field data are not\nsuitable for supervised learning, we generate synthetic seismic records using\nsubmodels selected from the benchmark Marmousi model as training data whose\ncharacteristics are similar to that of the field data. A single trace of\nsynthetic band-limited seismic data in the time domain is used as the input\ndata, and the parameters of LFET are updated based on the errors between the\npredicted trace and the corresponding label. The experimental results on the\ndata generated by different models, different wavelets, and different kinds of\nfield marine data demonstrate the feasibility and generalization of the\nproposed method. Furthermore, the proposed method achieves higher accuracy with\nlower computational expense than the traditional CNN method."
  },
  {
    "arxiv_id": "2404.17401",
    "title": "Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations",
    "url": "http://arxiv.org/abs/2404.17401v1",
    "abstract": "Language models now constitute essential tools for improving efficiency for\nmany professional tasks such as writing, coding, or learning. For this reason,\nit is imperative to identify inherent biases. In the field of Natural Language\nProcessing, five sources of bias are well-identified: data, annotation,\nrepresentation, models, and research design. This study focuses on biases\nrelated to geographical knowledge. We explore the connection between geography\nand language models by highlighting their tendency to misrepresent spatial\ninformation, thus leading to distortions in the representation of geographical\ndistances. This study introduces four indicators to assess these distortions,\nby comparing geographical and semantic distances. Experiments are conducted\nfrom these four indicators with ten widely used language models. Results\nunderscore the critical necessity of inspecting and rectifying spatial biases\nin language models to ensure accurate and equitable representations."
  },
  {
    "arxiv_id": "2404.17283",
    "title": "Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM",
    "url": "http://arxiv.org/abs/2404.17283v1",
    "abstract": "Retrieval-augmented language models have exhibited promising performance\nacross various areas of natural language processing (NLP), including\nfact-critical tasks. However, due to the black-box nature of advanced large\nlanguage models (LLMs) and the non-retrieval-oriented supervision signal of\nspecific tasks, the training of retrieval model faces significant challenges\nunder the setting of black-box LLM. We propose an approach leveraging\nFine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance\nfact-checking on news claims by using black-box LLM. FFRR adopts a two-level\nstrategy to gather fine-grained feedback from the LLM, which serves as a reward\nfor optimizing the retrieval policy, by rating the retrieved documents based on\nthe non-retrieval ground truth of the task. We evaluate our model on two public\ndatasets for real-world news claim verification, and the results demonstrate\nthat FFRR achieves significant improvements over strong LLM-enabled and non-LLM\nbaselines."
  },
  {
    "arxiv_id": "2404.17216",
    "title": "Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot",
    "url": "http://arxiv.org/abs/2404.17216v1",
    "abstract": "Many multilingual communities, including numerous in Africa, frequently\nengage in code-switching during conversations. This behaviour stresses the need\nfor natural language processing technologies adept at processing code-switched\ntext. However, data scarcity, particularly in African languages, poses a\nsignificant challenge, as many are low-resourced and under-represented. In this\nstudy, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English\ncode-switched sentences, enhancing diversity using topic-keyword pairs,\nlinguistic guidelines, and few-shot examples. Our findings indicate that the\nquality of generated sentences for languages using non-Latin scripts, like\nYoruba, is considerably lower when compared with the high Afrikaans-English\nsuccess rate. There is therefore a notable opportunity to refine prompting\nguidelines to yield sentences suitable for the fine-tuning of language models.\nWe propose a framework for augmenting the diversity of synthetically generated\ncode-switched data using GPT and propose leveraging this technology to mitigate\ndata scarcity in low-resourced languages, underscoring the essential role of\nnative speakers in this process."
  },
  {
    "arxiv_id": "2404.17143",
    "title": "Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls",
    "url": "http://arxiv.org/abs/2404.17143v1",
    "abstract": "Dominant pre-trained language models (PLMs) have demonstrated the potential\nrisk of memorizing and outputting the training data. While this concern has\nbeen discussed mainly in English, it is also practically important to focus on\ndomain-specific PLMs. In this study, we pre-trained domain-specific GPT-2\nmodels using a limited corpus of Japanese newspaper articles and evaluated\ntheir behavior. Experiments replicated the empirical finding that memorization\nof PLMs is related to the duplication in the training data, model size, and\nprompt length, in Japanese the same as in previous English studies.\nFurthermore, we attempted membership inference attacks, demonstrating that the\ntraining data can be detected even in Japanese, which is the same trend as in\nEnglish. The study warns that domain-specific PLMs, sometimes trained with\nvaluable private data, can ''copy and paste'' on a large scale."
  },
  {
    "arxiv_id": "2404.18896",
    "title": "Overcoming Knowledge Barriers: Online Imitation Learning from Observation with Pretrained World Models",
    "url": "http://arxiv.org/abs/2404.18896v1",
    "abstract": "Pretraining and finetuning models has become increasingly popular in\ndecision-making. But there are still serious impediments in Imitation Learning\nfrom Observation (ILfO) with pretrained models. This study identifies two\nprimary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration\nKnowledge Barrier (DKB). The EKB emerges due to the pretrained models'\nlimitations in handling novel observations, which leads to inaccurate action\ninference. Conversely, the DKB stems from the reliance on limited demonstration\ndatasets, restricting the model's adaptability across diverse scenarios. We\npropose separate solutions to overcome each barrier and apply them to Action\nInference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new\nalgorithm, AIME-NoB, integrates online interactions and a data-driven\nregulariser to mitigate the EKB. Additionally, it uses a surrogate reward\nfunction to broaden the policy's supported states, addressing the DKB. Our\nexperiments on vision-based control tasks from the DeepMind Control Suite and\nMetaWorld benchmarks show that AIME-NoB significantly improves sample\nefficiency and converged performance, presenting a robust framework for\novercoming the challenges in ILfO with pretrained models. Code available at\nhttps://github.com/IcarusWizard/AIME-NoB."
  },
  {
    "arxiv_id": "2404.18638",
    "title": "Reinforcement Learning Problem Solving with Large Language Models",
    "url": "http://arxiv.org/abs/2404.18638v1",
    "abstract": "Large Language Models (LLMs) encapsulate an extensive amount of world\nknowledge, and this has enabled their application in various domains to improve\nthe performance of a variety of Natural Language Processing (NLP) tasks. This\nhas also facilitated a more accessible paradigm of conversation-based\ninteractions between humans and AI systems to solve intended problems. However,\none interesting avenue that shows untapped potential is the use of LLMs as\nReinforcement Learning (RL) agents to enable conversational RL problem solving.\nTherefore, in this study, we explore the concept of formulating Markov Decision\nProcess-based RL problems as LLM prompting tasks. We demonstrate how LLMs can\nbe iteratively prompted to learn and optimize policies for specific RL tasks.\nIn addition, we leverage the introduced prompting technique for episode\nsimulation and Q-Learning, facilitated by LLMs. We then show the practicality\nof our approach through two detailed case studies for \"Research Scientist\" and\n\"Legal Matter Intake\" workflows."
  },
  {
    "arxiv_id": "2404.18518",
    "title": "From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?",
    "url": "http://arxiv.org/abs/2404.18518v1",
    "abstract": "Generative large-scale language models create the fifth paradigm of\nscientific research, organically combine data science and computational\nintelligence, transform the research paradigm of natural language processing\nand multimodal information processing, promote the new trend of AI-enabled\nsocial science research, and provide new ideas for digital humanities research\nand application. This article profoundly explores the application of\nlarge-scale language models in digital humanities research, revealing their\nsignificant potential in ancient book protection, intelligent processing, and\nacademic innovation. The article first outlines the importance of ancient book\nresources and the necessity of digital preservation, followed by a detailed\nintroduction to developing large-scale language models, such as ChatGPT, and\ntheir applications in document management, content understanding, and\ncross-cultural research. Through specific cases, the article demonstrates how\nAI can assist in the organization, classification, and content generation of\nancient books. Then, it explores the prospects of AI applications in artistic\ninnovation and cultural heritage preservation. Finally, the article explores\nthe challenges and opportunities in the interaction of technology, information,\nand society in the digital humanities triggered by AI technologies."
  },
  {
    "arxiv_id": "2404.18255",
    "title": "PatentGPT: A Large Language Model for Intellectual Property",
    "url": "http://arxiv.org/abs/2404.18255v1",
    "abstract": "In recent years, large language models(LLMs) have attracted significant\nattention due to their exceptional performance across a multitude of natural\nlanguage process tasks, and have been widely applied in various fields.\nHowever, the application of large language models in the Intellectual Property\n(IP) domain is challenging due to the strong need for specialized knowledge,\nprivacy protection, processing of extremely long text in this field. In this\ntechnical report, we present for the first time a low-cost, standardized\nprocedure for training IP-oriented LLMs, meeting the unique requirements of the\nIP domain. Using this standard process, we have trained the PatentGPT series\nmodels based on open-source pretrained models. By evaluating them on the\nopen-source IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms\nGPT-4, indicating the effectiveness of the proposed training procedure and the\nexpertise of the PatentGPT models in the IP domain. Remarkably, our model\nsurpassed GPT-4 on the 2019 China Patent Agent Qualification Examination,\nscoring 65 and matching human expert levels. Additionally, the PatentGPT model,\nwhich utilizes the SMoE architecture, achieves performance comparable to that\nof GPT-4 in the IP domain and demonstrates a better cost-performance ratio on\nlong-text tasks, potentially serving as an alternative to GPT-4 within the IP\ndomain."
  },
  {
    "arxiv_id": "2404.19543",
    "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
    "url": "http://arxiv.org/abs/2404.19543v1",
    "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in\nNatural Language Processing (NLP), yet they encounter challenges such as\nhallucination and the need for domain-specific knowledge. To mitigate these,\nrecent methodologies have integrated information retrieved from external\nresources with LLMs, substantially enhancing their performance across NLP\ntasks. This survey paper addresses the absence of a comprehensive overview on\nRetrieval-Augmented Language Models (RALMs), both Retrieval-Augmented\nGeneration (RAG) and Retrieval-Augmented Understanding (RAU), providing an\nin-depth examination of their paradigm, evolution, taxonomy, and applications.\nThe paper discusses the essential components of RALMs, including Retrievers,\nLanguage Models, and Augmentations, and how their interactions lead to diverse\nmodel structures and applications. RALMs demonstrate utility in a spectrum of\ntasks, from translation and dialogue systems to knowledge-intensive\napplications. The survey includes several evaluation methods of RALMs,\nemphasizing the importance of robustness, accuracy, and relevance in their\nassessment. It also acknowledges the limitations of RALMs, particularly in\nretrieval quality and computational efficiency, offering directions for future\nresearch. In conclusion, this survey aims to offer a structured insight into\nRALMs, their potential, and the avenues for their future development in NLP.\nThe paper is supplemented with a Github Repository containing the surveyed\nworks and resources for further study:\nhttps://github.com/2471023025/RALM_Survey."
  },
  {
    "arxiv_id": "2404.19192",
    "title": "Mix of Experts Language Model for Named Entity Recognition",
    "url": "http://arxiv.org/abs/2404.19192v1",
    "abstract": "Named Entity Recognition (NER) is an essential steppingstone in the field of\nnatural language processing. Although promising performance has been achieved\nby various distantly supervised models, we argue that distant supervision\ninevitably introduces incomplete and noisy annotations, which may mislead the\nmodel training process. To address this issue, we propose a robust NER model\nnamed BOND-MoE based on Mixture of Experts (MoE). Instead of relying on a\nsingle model for NER prediction, multiple models are trained and ensembled\nunder the Expectation-Maximization (EM) framework, so that noisy supervision\ncan be dramatically alleviated. In addition, we introduce a fair assignment\nmodule to balance the document-model assignment process. Extensive experiments\non real-world datasets show that the proposed method achieves state-of-the-art\nperformance compared with other distantly supervised NER."
  },
  {
    "arxiv_id": "2404.19178",
    "title": "Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics",
    "url": "http://arxiv.org/abs/2404.19178v1",
    "abstract": "Transformers have generally supplanted recurrent neural networks as the\ndominant architecture for both natural language processing tasks and for\nmodelling the effect of predictability on online human language comprehension.\nHowever, two recently developed recurrent model architectures, RWKV and Mamba,\nappear to perform natural language tasks comparably to or better than\ntransformers of equivalent scale. In this paper, we show that contemporary\nrecurrent models are now also able to match - and in some cases, exceed - the\nperformance of comparably sized transformers at modeling online human language\ncomprehension. This suggests that transformer language models are not uniquely\nsuited to this task, and opens up new directions for debates about the extent\nto which architectural features of language models make them better or worse\nmodels of human language comprehension."
  },
  {
    "arxiv_id": "2405.00516",
    "title": "Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning",
    "url": "http://arxiv.org/abs/2405.00516v1",
    "abstract": "Recent advancements in language models have demonstrated remarkable\nimprovements in various natural language processing (NLP) tasks such as web\nnavigation. Supervised learning (SL) approaches have achieved impressive\nperformance while utilizing significantly less training data compared to\nprevious methods. However, these SL-based models fall short when compared to\nreinforcement learning (RL) approaches, which have shown superior results. In\nthis paper, we propose a novel approach that combines SL and RL techniques over\nthe MiniWoB benchmark to leverage the strengths of both methods. We also\naddress a critical limitation in previous models' understanding of HTML\ncontent, revealing a tendency to memorize target elements rather than\ncomprehend the underlying structure. To rectify this, we propose methods to\nenhance true understanding and present a new baseline of results. Our\nexperiments demonstrate that our approach outperforms previous SL methods on\ncertain tasks using less data and narrows the performance gap with RL models,\nachieving 43.58\\% average accuracy in SL and 36.69\\% when combined with a\nmultimodal RL approach. This study sets a new direction for future web\nnavigation and offers insights into the limitations and potential of language\nmodeling for computer tasks."
  },
  {
    "arxiv_id": "2405.00361",
    "title": "AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts",
    "url": "http://arxiv.org/abs/2405.00361v1",
    "abstract": "We introduce AdaMoLE, a novel method for fine-tuning large language models\n(LLMs) through an Adaptive Mixture of Low-Rank Adaptation (LoRA) Experts.\nMoving beyond conventional methods that employ a static top-k strategy for\nactivating experts, AdaMoLE dynamically adjusts the activation threshold using\na dedicated threshold network, adaptively responding to the varying\ncomplexities of different tasks. By replacing a single LoRA in a layer with\nmultiple LoRA experts and integrating a gating function with the threshold\nmechanism, AdaMoLE effectively selects and activates the most appropriate\nexperts based on the input context. Our extensive evaluations across a variety\nof commonsense reasoning and natural language processing tasks show that\nAdaMoLE exceeds baseline performance. This enhancement highlights the\nadvantages of AdaMoLE's adaptive selection of LoRA experts, improving model\neffectiveness without a corresponding increase in the expert count. The\nexperimental validation not only confirms AdaMoLE as a robust approach for\nenhancing LLMs but also suggests valuable directions for future research in\nadaptive expert selection mechanisms, potentially broadening the scope for\noptimizing model performance across diverse language processing tasks."
  },
  {
    "arxiv_id": "2405.01502",
    "title": "Analyzing the Role of Semantic Representations in the Era of Large Language Models",
    "url": "http://arxiv.org/abs/2405.01502v1",
    "abstract": "Traditionally, natural language processing (NLP) models often use a rich set\nof features created by linguistic expertise, such as semantic representations.\nHowever, in the era of large language models (LLMs), more and more tasks are\nturned into generic, end-to-end sequence generation problems. In this paper, we\ninvestigate the question: what is the role of semantic representations in the\nera of LLMs? Specifically, we investigate the effect of Abstract Meaning\nRepresentation (AMR) across five diverse NLP tasks. We propose an AMR-driven\nchain-of-thought prompting method, which we call AMRCoT, and find that it\ngenerally hurts performance more than it helps. To investigate what AMR may\nhave to offer on these tasks, we conduct a series of analysis experiments. We\nfind that it is difficult to predict which input examples AMR may help or hurt\non, but errors tend to arise with multi-word expressions, named entities, and\nin the final inference step where the LLM must connect its reasoning over the\nAMR to its prediction. We recommend focusing on these areas for future work in\nsemantic representations for LLMs. Our code:\nhttps://github.com/causalNLP/amr_llm."
  },
  {
    "arxiv_id": "2405.02128",
    "title": "Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo",
    "url": "http://arxiv.org/abs/2405.02128v1",
    "abstract": "The rapid advancement in artificial intelligence and natural language\nprocessing has led to the development of large-scale datasets aimed at\nbenchmarking the performance of machine learning models. Herein, we introduce\n'RetChemQA,' a comprehensive benchmark dataset designed to evaluate the\ncapabilities of such models in the domain of reticular chemistry. This dataset\nincludes both single-hop and multi-hop question-answer pairs, encompassing\napproximately 45,000 Q&As for each type. The questions have been extracted from\nan extensive corpus of literature containing about 2,530 research papers from\npublishers including NAS, ACS, RSC, Elsevier, and Nature Publishing Group,\namong others. The dataset has been generated using OpenAI's GPT-4 Turbo, a\ncutting-edge model known for its exceptional language understanding and\ngeneration capabilities. In addition to the Q&A dataset, we also release a\ndataset of synthesis conditions extracted from the corpus of literature used in\nthis study. The aim of RetChemQA is to provide a robust platform for the\ndevelopment and evaluation of advanced machine learning algorithms,\nparticularly for the reticular chemistry community. The dataset is structured\nto reflect the complexities and nuances of real-world scientific discourse,\nthereby enabling nuanced performance assessments across a variety of tasks. The\ndataset is available at the following link:\nhttps://github.com/nakulrampal/RetChemQA"
  },
  {
    "arxiv_id": "2405.01799",
    "title": "Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features",
    "url": "http://arxiv.org/abs/2405.01799v1",
    "abstract": "Diagnosing language disorders associated with autism is a complex challenge,\noften hampered by the subjective nature and variability of traditional\nassessment methods. Traditional diagnostic methods not only require intensive\nhuman effort but also often result in delayed interventions due to their lack\nof speed and precision. In this study, we explored the application of ChatGPT,\na large language model, to overcome these obstacles by enhancing sensitivity\nand profiling linguistic features for autism diagnosis. This research utilizes\nChatGPT natural language processing capabilities to simplify and improve the\ndiagnostic process, focusing on identifying autism related language patterns.\nSpecifically, we compared ChatGPT performance with that of conventional\nsupervised learning models, including BERT, a model acclaimed for its\neffectiveness in various natural language processing tasks. We showed that\nChatGPT substantially outperformed these models, achieving over 10% improvement\nin both sensitivity and positive predictive value, in a zero shot learning\nconfiguration. The findings underscore the model potential as a diagnostic\ntool, combining accuracy and applicability. We identified ten key features of\nautism associated language disorders across scenarios. Features such as\necholalia, pronoun reversal, and atypical language usage play a critical role\nin diagnosing ASD and informing tailored treatment plans. Together, our\nfindings advocate for adopting sophisticated AI tools like ChatGPT in clinical\nsettings to assess and diagnose developmental disorders. Our approach promises\nenhanced diagnostic precision and supports personalized medicine, potentially\ntransforming the evaluation landscape for autism and similar neurological\nconditions."
  },
  {
    "arxiv_id": "2405.01686",
    "title": "Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models",
    "url": "http://arxiv.org/abs/2405.01686v1",
    "abstract": "Meta-analyses statistically aggregate the findings of different randomized\ncontrolled trials (RCTs) to assess treatment effectiveness. Because this yields\nrobust estimates of treatment effectiveness, results from meta-analyses are\nconsidered the strongest form of evidence. However, rigorous evidence syntheses\nare time-consuming and labor-intensive, requiring manual extraction of data\nfrom individual trials to be synthesized. Ideally, language technologies would\npermit fully automatic meta-analysis, on demand. This requires accurately\nextracting numerical results from individual trials, which has been beyond the\ncapabilities of natural language processing (NLP) models to date. In this work,\nwe evaluate whether modern large language models (LLMs) can reliably perform\nthis task. We annotate (and release) a modest but granular evaluation dataset\nof clinical trial reports with numerical findings attached to interventions,\ncomparators, and outcomes. Using this dataset, we evaluate the performance of\nseven LLMs applied zero-shot for the task of conditionally extracting numerical\nfindings from trial reports. We find that massive LLMs that can accommodate\nlengthy inputs are tantalizingly close to realizing fully automatic\nmeta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality).\nHowever, LLMs -- including ones trained on biomedical texts -- perform poorly\nwhen the outcome measures are complex and tallying the results requires\ninference. This work charts a path toward fully automatic meta-analysis of RCTs\nvia LLMs, while also highlighting the limitations of existing models for this\naim."
  },
  {
    "arxiv_id": "2405.01682",
    "title": "Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language",
    "url": "http://arxiv.org/abs/2405.01682v1",
    "abstract": "Automatic conversion of free-text radiology reports into structured data\nusing Natural Language Processing (NLP) techniques is crucial for analyzing\ndiseases on a large scale. While effective for tasks in widely spoken languages\nlike English, generative large language models (LLMs) typically underperform\nwith less common languages and can pose potential risks to patient privacy.\nFine-tuning local NLP models is hindered by the skewed nature of real-world\nmedical datasets, where rare findings represent a significant data imbalance.\nWe introduce SMP-BERT, a novel prompt learning method that leverages the\nstructured nature of reports to overcome these challenges. In our studies\ninvolving a substantial collection of Crohn's disease radiology reports in\nHebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed\ntraditional fine-tuning methods in performance, notably in detecting infrequent\nconditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more\naccurate AI diagnostics available for low-resource languages."
  },
  {
    "arxiv_id": "2405.03594",
    "title": "Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment",
    "url": "http://arxiv.org/abs/2405.03594v1",
    "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP), but their size creates computational bottlenecks. We introduce a novel\napproach to create accurate, sparse foundational versions of performant LLMs\nthat achieve full accuracy recovery for fine-tuning tasks at up to 70%\nsparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT\none-shot pruning method and sparse pretraining of those models on a subset of\nthe SlimPajama dataset mixed with a Python subset of The Stack dataset. We\nexhibit training acceleration due to sparsity on Cerebras CS-3 chips that\nclosely matches theoretical scaling. In addition, we establish inference\nacceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine\nand 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are\nrealized via sparsity alone, thus enabling further gains through additional use\nof quantization. Specifically, we show a total speedup on CPUs for\nsparse-quantized LLaMA models of up to 8.6x. We demonstrate these results\nacross diverse, challenging tasks, including chat, instruction following, code\ngeneration, arithmetic reasoning, and summarization to prove their generality.\nThis work paves the way for rapidly creating smaller and faster LLMs without\nsacrificing accuracy."
  },
  {
    "arxiv_id": "2405.03425",
    "title": "Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models",
    "url": "http://arxiv.org/abs/2405.03425v1",
    "abstract": "Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and\npoor calibration, particularly when fine-tuned on small datasets. To address\nthese challenges, we propose a simple combination of Low-Rank Adaptation (LoRA)\nwith Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate\nBayesian inference in LLMs. Through extensive testing across several Natural\nLanguage Processing (NLP) benchmarks, we demonstrate that our straightforward\nand computationally efficient approach improves model generalization and\ncalibration competitively with comparable, more sophisticated methods for\nBayesian inference in LLMs. We further show that our method exhibits greater\nrobustness against distribution shift, as reflected in its improved performance\non out-of-distribution tasks."
  },
  {
    "arxiv_id": "2405.03138",
    "title": "CRAFT: Extracting and Tuning Cultural Instructions from the Wild",
    "url": "http://arxiv.org/abs/2405.03138v1",
    "abstract": "Large language models (LLMs) have rapidly evolved as the foundation of\nvarious natural language processing (NLP) applications. Despite their wide use\ncases, their understanding of culturally-related concepts and reasoning remains\nlimited. Meantime, there is a significant need to enhance these models'\ncultural reasoning capabilities, especially concerning underrepresented\nregions. This paper introduces a novel pipeline for extracting high-quality,\nculturally-related instruction tuning datasets from vast unstructured corpora.\nWe utilize a self-instruction generation pipeline to identify cultural concepts\nand trigger instruction. By integrating with a general-purpose instruction\ntuning dataset, our model demonstrates enhanced capabilities in recognizing and\nunderstanding regional cultural nuances, thereby enhancing its reasoning\ncapabilities. We conduct experiments across three regions: Singapore, the\nPhilippines, and the United States, achieving performance improvement of up to\n6%. Our research opens new avenues for extracting cultural instruction tuning\nsets directly from unstructured data, setting a precedent for future\ninnovations in the field."
  },
  {
    "arxiv_id": "2405.03131",
    "title": "WDMoE: Wireless Distributed Large Language Models with Mixture of Experts",
    "url": "http://arxiv.org/abs/2405.03131v1",
    "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but how wireless communications can support\nLLMs has not been extensively studied. In this paper, we propose a wireless\ndistributed LLMs paradigm based on Mixture of Experts (MoE), named WDMoE,\ndeploying LLMs collaboratively across edge servers of base station (BS) and\nmobile devices in the wireless communications system. Specifically, we\ndecompose the MoE layer in LLMs by deploying the gating network and the\npreceding neural network layer at BS, while distributing the expert networks\nacross the devices. This arrangement leverages the parallel capabilities of\nexpert networks on distributed devices. Moreover, to overcome the instability\nof wireless communications, we design an expert selection policy by taking into\naccount both the performance of the model and the end-to-end latency, which\nincludes both transmission delay and inference delay. Evaluations conducted\nacross various LLMs and multiple datasets demonstrate that WDMoE not only\noutperforms existing models, such as Llama 2 with 70 billion parameters, but\nalso significantly reduces end-to-end latency."
  },
  {
    "arxiv_id": "2405.02937",
    "title": "Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study",
    "url": "http://arxiv.org/abs/2405.02937v1",
    "abstract": "Natural Language Inference (NLI) is a cornerstone of Natural Language\nProcessing (NLP), providing insights into the entailment relationships between\ntext pairings. It is a critical component of Natural Language Understanding\n(NLU), demonstrating the ability to extract information from spoken or written\ninteractions. NLI is mainly concerned with determining the entailment\nrelationship between two statements, known as the premise and hypothesis. When\nthe premise logically implies the hypothesis, the pair is labeled \"entailment\".\nIf the hypothesis contradicts the premise, the pair receives the\n\"contradiction\" label. When there is insufficient evidence to establish a\nconnection, the pair is described as \"neutral\". Despite the success of Large\nLanguage Models (LLMs) in various tasks, their effectiveness in NLI remains\nconstrained by issues like low-resource domain accuracy, model overconfidence,\nand difficulty in capturing human judgment disagreements. This study addresses\nthe underexplored area of evaluating LLMs in low-resourced languages such as\nBengali. Through a comprehensive evaluation, we assess the performance of\nprominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,\nfocusing on natural language inference. Utilizing the XNLI dataset, we conduct\nzero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and\nGemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,\nmBERT, and sahajBERT. Our findings reveal that while LLMs can achieve\ncomparable or superior performance to fine-tuned SOTA models in few-shot\nscenarios, further research is necessary to enhance our understanding of LLMs\nin languages with modest resources like Bengali. This study underscores the\nimportance of continued efforts in exploring LLM capabilities across diverse\nlinguistic contexts."
  },
  {
    "arxiv_id": "2405.02876",
    "title": "Exploring the Improvement of Evolutionary Computation via Large Language Models",
    "url": "http://arxiv.org/abs/2405.02876v1",
    "abstract": "Evolutionary computation (EC), as a powerful optimization algorithm, has been\napplied across various domains. However, as the complexity of problems\nincreases, the limitations of EC have become more apparent. The advent of large\nlanguage models (LLMs) has not only transformed natural language processing but\nalso extended their capabilities to diverse fields. By harnessing LLMs' vast\nknowledge and adaptive capabilities, we provide a forward-looking overview of\npotential improvements LLMs can bring to EC, focusing on the algorithms\nthemselves, population design, and additional enhancements. This presents a\npromising direction for future research at the intersection of LLMs and EC."
  },
  {
    "arxiv_id": "2405.04164",
    "title": "Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation",
    "url": "http://arxiv.org/abs/2405.04164v1",
    "abstract": "Automatic Sign Language Translation requires the integration of both computer\nvision and natural language processing to effectively bridge the communication\ngap between sign and spoken languages. However, the deficiency in large-scale\ntraining data to support sign language translation means we need to leverage\nresources from spoken language. We introduce, Sign2GPT, a novel framework for\nsign language translation that utilizes large-scale pretrained vision and\nlanguage models via lightweight adapters for gloss-free sign language\ntranslation. The lightweight adapters are crucial for sign language\ntranslation, due to the constraints imposed by limited dataset sizes and the\ncomputational requirements when training with long sign videos. We also propose\na novel pretraining strategy that directs our encoder to learn sign\nrepresentations from automatically extracted pseudo-glosses without requiring\ngloss order information or annotations. We evaluate our approach on two public\nbenchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T\nand CSL-Daily, and improve on state-of-the-art gloss-free translation\nperformance with a significant margin."
  },
  {
    "arxiv_id": "2405.04138",
    "title": "GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness",
    "url": "http://arxiv.org/abs/2405.04138v1",
    "abstract": "This study explores the limitations of traditional Cybersecurity Awareness\nand Training (CSAT) programs and proposes an innovative solution using\nGenerative Pre-Trained Transformers (GPT) to address these shortcomings.\nTraditional approaches lack personalization and adaptability to individual\nlearning styles. To overcome these challenges, the study integrates GPT models\nto deliver highly tailored and dynamic cybersecurity learning expe-riences.\nLeveraging natural language processing capabilities, the proposed approach\npersonalizes training modules based on individual trainee pro-files, helping to\nensure engagement and effectiveness. An experiment using a GPT model to provide\na real-time and adaptive CSAT experience through generating customized training\ncontent. The findings have demonstrated a significant improvement over\ntraditional programs, addressing issues of en-gagement, dynamicity, and\nrelevance. GPT-powered CSAT programs offer a scalable and effective solution to\nenhance cybersecurity awareness, provid-ing personalized training content that\nbetter prepares individuals to miti-gate cybersecurity risks in their specific\nroles within the organization."
  },
  {
    "arxiv_id": "2405.04053",
    "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT",
    "url": "http://arxiv.org/abs/2405.04053v1",
    "abstract": "This research examines the effectiveness of OpenAI's GPT models as\nindependent evaluators of text summaries generated by six transformer-based\nmodels from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.\nWe evaluated these summaries based on essential properties of high-quality\nsummary - conciseness, relevance, coherence, and readability - using\ntraditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,\nwe also employed GPT not as a summarizer but as an evaluator, allowing it to\nindependently assess summary quality without predefined metrics. Our analysis\nrevealed significant correlations between GPT evaluations and traditional\nmetrics, particularly in assessing relevance and coherence. The results\ndemonstrate GPT's potential as a robust tool for evaluating text summaries,\noffering insights that complement established metrics and providing a basis for\ncomparative analysis of transformer-based models in natural language processing\ntasks."
  },
  {
    "arxiv_id": "2405.03998",
    "title": "Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches",
    "url": "http://arxiv.org/abs/2405.03998v1",
    "abstract": "Crafting effective prompts for code generation or editing with Large Language\nModels (LLMs) is not an easy task. Particularly, the absence of immediate,\nstable feedback during prompt crafting hinders effective interaction, as users\nare left to mentally imagine possible outcomes until the code is generated. In\nresponse, we introduce Language-Oriented Code Sketching, an interactive\napproach that provides instant, incremental feedback in the form of code\nsketches (i.e., incomplete code outlines) during prompt crafting. This approach\nconverts a prompt into a code sketch by leveraging the inherent linguistic\nstructures within the prompt and applying classic natural language processing\ntechniques. The sketch then serves as an intermediate placeholder that not only\npreviews the intended code structure but also guides the LLM towards the\ndesired code, thereby enhancing human-LLM interaction. We conclude by\ndiscussing the approach's applicability and future plans."
  },
  {
    "arxiv_id": "2405.04793",
    "title": "Zero-shot LLM-guided Counterfactual Generation for Text",
    "url": "http://arxiv.org/abs/2405.04793v1",
    "abstract": "With the development and proliferation of large, complex, black-box models\nfor solving many natural language processing (NLP) tasks, there is also an\nincreasing necessity of methods to stress-test these models and provide some\ndegree of interpretability or explainability. While counterfactual examples are\nuseful in this regard, automated generation of counterfactuals is a data and\nresource intensive process. such methods depend on models such as pre-trained\nlanguage models that are then fine-tuned on auxiliary, often task-specific\ndatasets, that may be infeasible to build in practice, especially for new tasks\nand data domains. Therefore, in this work we explore the possibility of\nleveraging large language models (LLMs) for zero-shot counterfactual generation\nin order to stress-test NLP models. We propose a structured pipeline to\nfacilitate this generation, and we hypothesize that the instruction-following\nand textual understanding capabilities of recent LLMs can be effectively\nleveraged for generating high quality counterfactuals in a zero-shot manner,\nwithout requiring any training or fine-tuning. Through comprehensive\nexperiments on a variety of propreitary and open-source LLMs, along with\nvarious downstream tasks in NLP, we explore the efficacy of LLMs as zero-shot\ncounterfactual generators in evaluating and explaining black-box NLP models."
  },
  {
    "arxiv_id": "2405.04781",
    "title": "CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization",
    "url": "http://arxiv.org/abs/2405.04781v1",
    "abstract": "Large language models (LLMs) have demonstrated astonishing capabilities in\nnatural language processing (NLP) tasks, sparking interest in their application\nto professional domains with higher specialized requirements. However,\nrestricted access to closed-source LLMs via APIs and the difficulty in\ncollecting massive high-quality datasets pose obstacles to the development of\nlarge language models in education fields of various courses. Given these\nchallenges, we propose CourseGPT-zh, a course-oriented education LLM that\nsupports customization and low-cost deployment. To address the\ncomprehensiveness and diversity requirements of course-specific corpora, we\ndesign a high-quality question-answering corpus distillation framework\nincorporating prompt optimization, which effectively mines textbook knowledge\nand enhances its diversity. Moreover, considering the alignment of LLM\nresponses with user needs, a novel method for discrete prompt optimization\nbased on LLM-as-Judge is introduced. During optimization, this framework\nleverages the LLM's ability to reflect on and exploit error feedback and\npatterns, allowing for prompts that meet user needs and preferences while\nsaving response length. Lastly, we obtain CourseGPT-zh based on the open-source\nLLM using parameter-efficient fine-tuning. Experimental results show that our\ndiscrete prompt optimization framework effectively improves the response\nquality of ChatGPT, and CourseGPT-zh exhibits strong professional capabilities\nin specialized knowledge question-answering, significantly outperforming\ncomparable open-source models."
  },
  {
    "arxiv_id": "2405.04685",
    "title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking",
    "url": "http://arxiv.org/abs/2405.04685v1",
    "abstract": "Large Language Models (LLMs) are becoming crucial across various fields,\nemphasizing the urgency for high-quality models in underrepresented languages.\nThis study explores the unique challenges faced by low-resource languages, such\nas data scarcity, model selection, evaluation, and computational limitations,\nwith a special focus on Turkish. We conduct an in-depth analysis to evaluate\nthe impact of training strategies, model choices, and data availability on the\nperformance of LLMs designed for underrepresented languages. Our approach\nincludes two methodologies: (i) adapting existing LLMs originally pretrained in\nEnglish to understand Turkish, and (ii) developing a model from the ground up\nusing Turkish pretraining data, both supplemented with supervised fine-tuning\non a novel Turkish instruction-tuning dataset aimed at enhancing reasoning\ncapabilities. The relative performance of these methods is evaluated through\nthe creation of a new leaderboard for Turkish LLMs, featuring benchmarks that\nassess different reasoning and knowledge skills. Furthermore, we conducted\nexperiments on data and model scaling, both during pretraining and fine-tuning,\nsimultaneously emphasizing the capacity for knowledge transfer across languages\nand addressing the challenges of catastrophic forgetting encountered during\nfine-tuning on a different language. Our goal is to offer a detailed guide for\nadvancing the LLM framework in low-resource linguistic contexts, thereby making\nnatural language processing (NLP) benefits more globally accessible."
  },
  {
    "arxiv_id": "2405.05777",
    "title": "Towards a More Inclusive AI: Progress and Perspectives in Large Language Model Training for the Sámi Language",
    "url": "http://arxiv.org/abs/2405.05777v1",
    "abstract": "S\\'ami, an indigenous language group comprising multiple languages, faces\ndigital marginalization due to the limited availability of data and\nsophisticated language models designed for its linguistic intricacies. This\nwork focuses on increasing technological participation for the S\\'ami language.\nWe draw the attention of the ML community towards the language modeling problem\nof Ultra Low Resource (ULR) languages. ULR languages are those for which the\namount of available textual resources is very low, and the speaker count for\nthem is also very low. ULRLs are also not supported by mainstream Large\nLanguage Models (LLMs) like ChatGPT, due to which gathering artificial training\ndata for them becomes even more challenging. Mainstream AI foundational model\ndevelopment has given less attention to this category of languages. Generally,\nthese languages have very few speakers, making it hard to find them. However,\nit is important to develop foundational models for these ULR languages to\npromote inclusion and the tangible abilities and impact of LLMs. To this end,\nwe have compiled the available S\\'ami language resources from the web to create\na clean dataset for training language models. In order to study the behavior of\nmodern LLM models with ULR languages (S\\'ami), we have experimented with\ndifferent kinds of LLMs, mainly at the order of $\\sim$ seven billion\nparameters. We have also explored the effect of multilingual LLM training for\nULRLs. We found that the decoder-only models under a sequential multilingual\ntraining scenario perform better than joint multilingual training, whereas\nmultilingual training with high semantic overlap, in general, performs better\nthan training from scratch.This is the first study on the S\\'ami language for\nadapting non-statistical language models that use the latest developments in\nthe field of natural language processing (NLP)."
  },
  {
    "arxiv_id": "2405.05610",
    "title": "Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM",
    "url": "http://arxiv.org/abs/2405.05610v1",
    "abstract": "Large language models (LLMs) have achieved remarkable performance in various\nnatural language processing tasks, especially in dialogue systems. However, LLM\nmay also pose security and moral threats, especially in multi round\nconversations where large models are more easily guided by contextual content,\nresulting in harmful or biased responses. In this paper, we present a novel\nmethod to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack).\nCoA is a semantic-driven contextual multi-turn attack method that adaptively\nadjusts the attack policy through contextual feedback and semantic relevance\nduring multi-turn of dialogue with a large model, resulting in the model\nproducing unreasonable or harmful content. We evaluate CoA on different LLMs\nand datasets, and show that it can effectively expose the vulnerabilities of\nLLMs, and outperform existing attack methods. Our work provides a new\nperspective and tool for attacking and defending LLMs, and contributes to the\nsecurity and ethical assessment of dialogue systems."
  },
  {
    "arxiv_id": "2405.06604",
    "title": "Explaining Text Similarity in Transformer Models",
    "url": "http://arxiv.org/abs/2405.06604v1",
    "abstract": "As Transformers have become state-of-the-art models for natural language\nprocessing (NLP) tasks, the need to understand and explain their predictions is\nincreasingly apparent. Especially in unsupervised applications, such as\ninformation retrieval tasks, similarity models built on top of foundation model\nrepresentations have been widely applied. However, their inner prediction\nmechanisms have mostly remained opaque. Recent advances in explainable AI have\nmade it possible to mitigate these limitations by leveraging improved\nexplanations for Transformers through layer-wise relevance propagation (LRP).\nUsing BiLRP, an extension developed for computing second-order explanations in\nbilinear similarity models, we investigate which feature interactions drive\nsimilarity in NLP models. We validate the resulting explanations and\ndemonstrate their utility in three corpus-level use cases, analyzing\ngrammatical interactions, multilingual semantics, and biomedical text\nretrieval. Our findings contribute to a deeper understanding of different\nsemantic similarity tasks and models, highlighting how novel explainable AI\nmethods enable in-depth analyses and corpus-level insights."
  },
  {
    "arxiv_id": "2405.06468",
    "title": "Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification",
    "url": "http://arxiv.org/abs/2405.06468v1",
    "abstract": "The task of medical image recognition is notably complicated by the presence\nof varied and multiple pathological indications, presenting a unique challenge\nin multi-label classification with unseen labels. This complexity underlines\nthe need for computer-aided diagnosis methods employing multi-label zero-shot\nlearning. Recent advancements in pre-trained vision-language models (VLMs) have\nshowcased notable zero-shot classification abilities on medical images.\nHowever, these methods have limitations on leveraging extensive pre-trained\nknowledge from broader image datasets, and often depend on manual prompt\nconstruction by expert radiologists. By automating the process of prompt\ntuning, prompt learning techniques have emerged as an efficient way to adapt\nVLMs to downstream tasks. Yet, existing CoOp-based strategies fall short in\nperforming class-specific prompts on unseen categories, limiting\ngeneralizability in fine-grained scenarios. To overcome these constraints, we\nintroduce a novel prompt generation approach inspirited by text generation in\nnatural language processing (NLP). Our method, named Pseudo-Prompt Generating\n(PsPG), capitalizes on the priori knowledge of multi-modal features. Featuring\na RNN-based decoder, PsPG autoregressively generates class-tailored embedding\nvectors, i.e., pseudo-prompts. Comparative evaluations on various multi-label\nchest radiograph datasets affirm the superiority of our approach against\nleading medical vision-language and multi-label prompt learning methods. The\nsource code is available at https://github.com/fallingnight/PsPG"
  },
  {
    "arxiv_id": "2405.06373",
    "title": "LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play",
    "url": "http://arxiv.org/abs/2405.06373v1",
    "abstract": "Large language models (LLMs) have shown exceptional proficiency in natural\nlanguage processing but often fall short of generating creative and original\nresponses to open-ended questions. To enhance LLM creativity, our key insight\nis to emulate the human process of inducing collective creativity through\nengaging discussions with participants from diverse backgrounds and\nperspectives. To this end, we propose LLM Discussion, a three-phase discussion\nframework that facilitates vigorous and diverging idea exchanges and ensures\nconvergence to creative answers. Moreover, we adopt a role-playing technique by\nassigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate\nthe efficacy of the proposed framework with the Alternative Uses Test,\nSimilarities Test, Instances Test, and Scientific Creativity Test through both\nLLM evaluation and human study. The results show that our proposed framework\noutperforms single-LLM approaches and existing multi-LLM frameworks across\nvarious creativity metrics. The code is available at\nhttps://github.com/lawraa/LLM-Discussion."
  },
  {
    "arxiv_id": "2405.07667",
    "title": "Backdoor Removal for Generative Large Language Models",
    "url": "http://arxiv.org/abs/2405.07667v1",
    "abstract": "With rapid advances, generative large language models (LLMs) dominate various\nNatural Language Processing (NLP) tasks from understanding to reasoning. Yet,\nlanguage models' inherent vulnerabilities may be exacerbated due to increased\naccessibility and unrestricted model training on massive data. A malicious\nadversary may publish poisoned data online and conduct backdoor attacks on the\nvictim LLMs pre-trained on the poisoned data. Backdoored LLMs behave\ninnocuously for normal queries and generate harmful responses when the backdoor\ntrigger is activated. Despite significant efforts paid to LLMs' safety issues,\nLLMs are still struggling against backdoor attacks. As Anthropic recently\nrevealed, existing safety training strategies, including supervised fine-tuning\n(SFT) and Reinforcement Learning from Human Feedback (RLHF), fail to revoke the\nbackdoors once the LLM is backdoored during the pre-training stage. In this\npaper, we present Simulate and Eliminate (SANDE) to erase the undesired\nbackdoored mappings for generative LLMs. We initially propose Overwrite\nSupervised Fine-tuning (OSFT) for effective backdoor removal when the trigger\nis known. Then, to handle scenarios where trigger patterns are unknown, we\nintegrate OSFT into our two-stage framework, SANDE. Unlike other works that\nassume access to cleanly trained models, our safety-enhanced LLMs are able to\nrevoke backdoors without any reference. Consequently, our safety-enhanced LLMs\nno longer produce targeted responses when the backdoor triggers are activated.\nWe conduct comprehensive experiments to show that our proposed SANDE is\neffective against backdoor attacks while bringing minimal harm to LLMs'\npowerful capability."
  },
  {
    "arxiv_id": "2405.06823",
    "title": "PLeak: Prompt Leaking Attacks against Large Language Model Applications",
    "url": "http://arxiv.org/abs/2405.06823v1",
    "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream\napplications, called LLM applications, with different natural language\nprocessing tasks. The functionality and performance of an LLM application\nhighly depend on its system prompt, which instructs the backend LLM on what\ntask to perform. Therefore, an LLM application developer often keeps a system\nprompt confidential to protect its intellectual property. As a result, a\nnatural attack, called prompt leaking, is to steal the system prompt from an\nLLM application, which compromises the developer's intellectual property.\nExisting prompt leaking attacks primarily rely on manually crafted queries, and\nthus achieve limited effectiveness.\n  In this paper, we design a novel, closed-box prompt leaking attack framework,\ncalled PLeak, to optimize an adversarial query such that when the attacker\nsends it to a target LLM application, its response reveals its own system\nprompt. We formulate finding such an adversarial query as an optimization\nproblem and solve it with a gradient-based method approximately. Our key idea\nis to break down the optimization goal by optimizing adversary queries for\nsystem prompts incrementally, i.e., starting from the first few tokens of each\nsystem prompt step by step until the entire length of the system prompt.\n  We evaluate PLeak in both offline settings and for real-world LLM\napplications, e.g., those on Poe, a popular platform hosting such applications.\nOur results show that PLeak can effectively leak system prompts and\nsignificantly outperforms not only baselines that manually curate queries but\nalso baselines with optimized queries that are modified and adapted from\nexisting jailbreaking attacks. We responsibly reported the issues to Poe and\nare still waiting for their response. Our implementation is available at this\nrepository: https://github.com/BHui97/PLeak."
  },
  {
    "arxiv_id": "2405.08204",
    "title": "A Semantic and Motion-Aware Spatiotemporal Transformer Network for Action Detection",
    "url": "http://arxiv.org/abs/2405.08204v1",
    "abstract": "This paper presents a novel spatiotemporal transformer network that\nintroduces several original components to detect actions in untrimmed videos.\nFirst, the multi-feature selective semantic attention model calculates the\ncorrelations between spatial and motion features to model spatiotemporal\ninteractions between different action semantics properly. Second, the\nmotion-aware network encodes the locations of action semantics in video frames\nutilizing the motion-aware 2D positional encoding algorithm. Such a\nmotion-aware mechanism memorizes the dynamic spatiotemporal variations in\naction frames that current methods cannot exploit. Third, the sequence-based\ntemporal attention model captures the heterogeneous temporal dependencies in\naction frames. In contrast to standard temporal attention used in natural\nlanguage processing, primarily aimed at finding similarities between linguistic\nwords, the proposed sequence-based temporal attention is designed to determine\nboth the differences and similarities between video frames that jointly define\nthe meaning of actions. The proposed approach outperforms the state-of-the-art\nsolutions on four spatiotemporal action datasets: AVA 2.2, AVA 2.1, UCF101-24,\nand EPIC-Kitchens."
  },
  {
    "arxiv_id": "2405.08151",
    "title": "Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness",
    "url": "http://arxiv.org/abs/2405.08151v1",
    "abstract": "Large language models (LLM) have demonstrated remarkable capabilities in\nvarious biomedical natural language processing (NLP) tasks, leveraging the\ndemonstration within the input context to adapt to new tasks. However, LLM is\nsensitive to the selection of demonstrations. To address the hallucination\nissue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by\nretrieving pertinent information from an established database. Nonetheless,\nexisting research work lacks rigorous evaluation of the impact of\nretrieval-augmented large language models on different biomedical NLP tasks.\nThis deficiency makes it challenging to ascertain the capabilities of RAL\nwithin the biomedical domain. Moreover, the outputs from RAL are affected by\nretrieving the unlabeled, counterfactual, or diverse knowledge that is not well\nstudied in the biomedical domain. However, such knowledge is common in the real\nworld. Finally, exploring the self-awareness ability is also crucial for the\nRAL system. So, in this paper, we systematically investigate the impact of RALs\non 5 different biomedical tasks (triple extraction, link prediction,\nclassification, question answering, and natural language inference). We analyze\nthe performance of RALs in four fundamental abilities, including unlabeled\nrobustness, counterfactual robustness, diverse robustness, and negative\nawareness. To this end, we proposed an evaluation framework to assess the RALs'\nperformance on different biomedical NLP tasks and establish four different\ntestbeds based on the aforementioned fundamental abilities. Then, we evaluate 3\nrepresentative LLMs with 3 different retrievers on 5 tasks over 9 datasets."
  },
  {
    "arxiv_id": "2405.09300",
    "title": "Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support",
    "url": "http://arxiv.org/abs/2405.09300v1",
    "abstract": "Background: Rapid advancements in natural language processing have led to the\ndevelopment of large language models with the potential to revolutionize mental\nhealth care. These models have shown promise in assisting clinicians and\nproviding support to individuals experiencing various psychological challenges.\n  Objective: This study aims to compare the performance of two large language\nmodels, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,\nto assess their potential applicability in mental health care settings.\n  Methods: A blind methodology was employed, with a clinical psychologist\nevaluating the models' responses without knowledge of their origins. The\nprompts encompassed a diverse range of mental health topics, including\ndepression, anxiety, and trauma, to ensure a comprehensive assessment.\n  Results: The results demonstrated a significant difference in performance\nbetween the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out\nof 10, while Chat-GPT received an average rating of 6.52. The clinical\npsychologist's evaluation suggested that GPT-4 was more effective at generating\nclinically relevant and empathetic responses, thereby providing better support\nand guidance to potential users.\n  Conclusions: This study contributes to the growing body of literature on the\napplicability of large language models in mental health care settings. The\nfindings underscore the importance of continued research and development in the\nfield to optimize these models for clinical use. Further investigation is\nnecessary to understand the specific factors underlying the performance\ndifferences between the two models and to explore their generalizability across\nvarious populations and mental health conditions."
  },
  {
    "arxiv_id": "2405.09285",
    "title": "Positional Knowledge is All You Need: Position-induced Transformer (PiT) for Operator Learning",
    "url": "http://arxiv.org/abs/2405.09285v1",
    "abstract": "Operator learning for Partial Differential Equations (PDEs) is rapidly\nemerging as a promising approach for surrogate modeling of intricate systems.\nTransformers with the self-attention mechanism$\\unicode{x2013}$a powerful tool\noriginally designed for natural language processing$\\unicode{x2013}$have\nrecently been adapted for operator learning. However, they confront challenges,\nincluding high computational demands and limited interpretability. This raises\na critical question: Is there a more efficient attention mechanism for\nTransformer-based operator learning? This paper proposes the Position-induced\nTransformer (PiT), built on an innovative position-attention mechanism, which\ndemonstrates significant advantages over the classical self-attention in\noperator learning. Position-attention draws inspiration from numerical methods\nfor PDEs. Different from self-attention, position-attention is induced by only\nthe spatial interrelations of sampling positions for input functions of the\noperators, and does not rely on the input function values themselves, thereby\ngreatly boosting efficiency. PiT exhibits superior performance over current\nstate-of-the-art neural operators in a variety of complex operator learning\ntasks across diverse PDE benchmarks. Additionally, PiT possesses an enhanced\ndiscretization convergence feature, compared to the widely-used Fourier neural\noperator."
  },
  {
    "arxiv_id": "2405.09770",
    "title": "Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)",
    "url": "http://arxiv.org/abs/2405.09770v1",
    "abstract": "With the rapid development of natural language processing (NLP) technology,\nlarge-scale pre-trained language models such as GPT-3 have become a popular\nresearch object in NLP field. This paper aims to explore sentiment analysis\noptimization techniques based on large pre-trained language models such as\nGPT-3 to improve model performance and effect and further promote the\ndevelopment of natural language processing (NLP). By introducing the importance\nof sentiment analysis and the limitations of traditional methods, GPT-3 and\nFine-tuning techniques are introduced in this paper, and their applications in\nsentiment analysis are explained in detail. The experimental results show that\nthe Fine-tuning technique can optimize GPT-3 model and obtain good performance\nin sentiment analysis task. This study provides an important reference for\nfuture sentiment analysis using large-scale language models."
  },
  {
    "arxiv_id": "2405.09596",
    "title": "Enhancing Maritime Trajectory Forecasting via H3 Index and Causal Language Modelling (CLM)",
    "url": "http://arxiv.org/abs/2405.09596v1",
    "abstract": "The prediction of ship trajectories is a growing field of study in artificial\nintelligence. Traditional methods rely on the use of LSTM, GRU networks, and\neven Transformer architectures for the prediction of spatio-temporal series.\nThis study proposes a viable alternative for predicting these trajectories\nusing only GNSS positions. It considers this spatio-temporal problem as a\nnatural language processing problem. The latitude/longitude coordinates of AIS\nmessages are transformed into cell identifiers using the H3 index. Thanks to\nthe pseudo-octal representation, it becomes easier for language models to learn\nthe spatial hierarchy of the H3 index. The method is compared with a classical\nKalman filter, widely used in the maritime domain, and introduces the Fr\\'echet\ndistance as the main evaluation metric. We show that it is possible to predict\nship trajectories quite precisely up to 8 hours ahead with 30 minutes of\ncontext, using solely GNSS positions, without relying on any additional\ninformation such as speed, course, or external conditions - unlike many\ntraditional methods. We demonstrate that this alternative works well enough to\npredict trajectories worldwide."
  },
  {
    "arxiv_id": "2405.10936",
    "title": "A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers",
    "url": "http://arxiv.org/abs/2405.10936v1",
    "abstract": "The rapid development of Large Language Models (LLMs) demonstrates remarkable\nmultilingual capabilities in natural language processing, attracting global\nattention in both academia and industry. To mitigate potential discrimination\nand enhance the overall usability and accessibility for diverse language user\ngroups, it is important for the development of language-fair technology.\nDespite the breakthroughs of LLMs, the investigation into the multilingual\nscenario remains insufficient, where a comprehensive survey to summarize recent\napproaches, developments, limitations, and potential solutions is desirable. To\nthis end, we provide a survey with multiple perspectives on the utilization of\nLLMs in the multilingual scenario. We first rethink the transitions between\nprevious and current research on pre-trained language models. Then we introduce\nseveral perspectives on the multilingualism of LLMs, including training and\ninference methods, information retrieval, model security, multi-domain with\nlanguage culture, and usage of datasets. We also discuss the major challenges\nthat arise in these aspects, along with possible solutions. Besides, we\nhighlight future research directions that aim at further enhancing LLMs with\nmultilingualism. The survey aims to help the research community address\nmultilingual problems and provide a comprehensive understanding of the core\nconcepts, key techniques, and latest developments in multilingual natural\nlanguage processing based on LLMs."
  },
  {
    "arxiv_id": "2405.10725",
    "title": "INDUS: Effective and Efficient Language Models for Scientific Applications",
    "url": "http://arxiv.org/abs/2405.10725v1",
    "abstract": "Large language models (LLMs) trained on general domain corpora showed\nremarkable results on natural language processing (NLP) tasks. However,\nprevious research demonstrated LLMs trained using domain-focused corpora\nperform better on specialized tasks. Inspired by this insight, we developed\nINDUS, a comprehensive suite of LLMs tailored for the closely-related domains\nof Earth science, biology, physics, heliophysics, planetary sciences and\nastrophysics, and trained using curated scientific corpora drawn from diverse\ndata sources. The suite of models include: (1) an encoder model trained using\ndomain-specific vocabulary and corpora to address NLP tasks, (2) a\ncontrastive-learning based text embedding model trained using a diverse set of\ndatasets to address information retrieval tasks and (3) smaller versions of\nthese models created using knowledge distillation for applications which have\nlatency or resource constraints. We also created three new scientific benchmark\ndatasets, CLIMATE-CHANGE NER (entity-recognition), NASA-QA (extractive QA) and\nNASA-IR (IR) to accelerate research in these multi-disciplinary fields. We show\nthat our models outperform both general-purpose (RoBERTa) and domain-specific\n(SCIBERT) encoders on these new tasks as well as existing tasks in the domains\nof interest. Furthermore, we demonstrate the use of these models in two\nindustrial settings -- as a retrieval model for large-scale vector search\napplications and in automatic content tagging systems."
  },
  {
    "arxiv_id": "2405.10626",
    "title": "Dynamic data sampler for cross-language transfer learning in large language models",
    "url": "http://arxiv.org/abs/2405.10626v1",
    "abstract": "Large Language Models (LLMs) have gained significant attention in the field\nof natural language processing (NLP) due to their wide range of applications.\nHowever, training LLMs for languages other than English poses significant\nchallenges, due to the difficulty in acquiring large-scale corpus and the\nrequisite computing resources. In this paper, we propose ChatFlow, a\ncross-language transfer-based LLM, to address these challenges and train large\nChinese language models in a cost-effective manner. We employ a mix of Chinese,\nEnglish, and parallel corpus to continuously train the LLaMA2 model, aiming to\nalign cross-language representations and facilitate the knowledge transfer\nspecifically to the Chinese language model. In addition, we use a dynamic data\nsampler to progressively transition the model from unsupervised pre-training to\nsupervised fine-tuning. Experimental results demonstrate that our approach\naccelerates model convergence and achieves superior performance. We evaluate\nChatFlow on popular Chinese and English benchmarks, the results indicate that\nit outperforms other Chinese models post-trained on LLaMA-2-7B."
  },
  {
    "arxiv_id": "2405.10616",
    "title": "Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization",
    "url": "http://arxiv.org/abs/2405.10616v1",
    "abstract": "In recent years, large language models (LLMs) have driven advances in natural\nlanguage processing. Still, their growing scale has increased the computational\nburden, necessitating a balance between efficiency and performance. Low-rank\ncompression, a promising technique, reduces non-essential parameters by\ndecomposing weight matrices into products of two low-rank matrices. Yet, its\napplication in LLMs has not been extensively studied. The key to low-rank\ncompression lies in low-rank factorization and low-rank dimensions allocation.\nTo address the challenges of low-rank compression in LLMs, we conduct empirical\nresearch on the low-rank characteristics of large models. We propose a low-rank\ncompression method suitable for LLMs. This approach involves precise estimation\nof feature distributions through pooled covariance matrices and a Bayesian\noptimization strategy for allocating low-rank dimensions. Experiments on the\nLLaMA-2 models demonstrate that our method outperforms existing strong\nstructured pruning and low-rank compression techniques in maintaining model\nperformance at the same compression ratio."
  },
  {
    "arxiv_id": "2405.10542",
    "title": "Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset",
    "url": "http://arxiv.org/abs/2405.10542v1",
    "abstract": "In light of recent breakthroughs in large language models (LLMs) that have\nrevolutionized natural language processing (NLP), there is an urgent need for\nnew benchmarks to keep pace with the fast development of LLMs. In this paper,\nwe propose CFLUE, the Chinese Financial Language Understanding Evaluation\nbenchmark, designed to assess the capability of LLMs across various dimensions.\nSpecifically, CFLUE provides datasets tailored for both knowledge assessment\nand application assessment. In knowledge assessment, it consists of 38K+\nmultiple-choice questions with associated solution explanations. These\nquestions serve dual purposes: answer prediction and question reasoning. In\napplication assessment, CFLUE features 16K+ test instances across distinct\ngroups of NLP tasks such as text classification, machine translation, relation\nextraction, reading comprehension, and text generation. Upon CFLUE, we conduct\na thorough evaluation of representative LLMs. The results reveal that only\nGPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\\% in answer prediction\nfor knowledge assessment, suggesting that there is still substantial room for\nimprovement in current LLMs. In application assessment, although GPT-4 and\nGPT-4-turbo are the top two performers, their considerable advantage over\nlightweight LLMs is noticeably diminished. The datasets and scripts associated\nwith CFLUE are openly accessible at https://github.com/aliyun/cflue."
  },
  {
    "arxiv_id": "2405.12195",
    "title": "Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey",
    "url": "http://arxiv.org/abs/2405.12195v1",
    "abstract": "As Large Language Models (LLMs), including ChatGPT and analogous systems,\ncontinue to advance, their robust natural language processing capabilities and\ndiverse applications have garnered considerable attention. Nonetheless, despite\nthe increasing acknowledgment of the convergence of Artificial Intelligence\n(AI) and Software Engineering (SE), there is a lack of studies involving the\nimpact of this convergence on the practices and perceptions of software\ndevelopers. Understanding how software developers perceive and engage with AI\ntools, such as ChatGPT, is essential for elucidating the impact and potential\nchallenges of incorporating AI-driven tools in the software development\nprocess. In this paper, we conducted a survey with 207 software developers to\nunderstand the impact of ChatGPT on software quality, productivity, and job\nsatisfaction. Furthermore, the study delves into developers' expectations\nregarding future adaptations of ChatGPT, concerns about potential job\ndisplacement, and perspectives on regulatory interventions."
  },
  {
    "arxiv_id": "2405.12018",
    "title": "Continuous Sign Language Recognition with Adapted Conformer via Unsupervised Pretraining",
    "url": "http://arxiv.org/abs/2405.12018v1",
    "abstract": "Conventional Deep Learning frameworks for continuous sign language\nrecognition (CSLR) are comprised of a single or multi-modal feature extractor,\na sequence-learning module, and a decoder for outputting the glosses. The\nsequence learning module is a crucial part wherein transformers have\ndemonstrated their efficacy in the sequence-to-sequence tasks. Analyzing the\nresearch progress in the field of Natural Language Processing and Speech\nRecognition, a rapid introduction of various transformer variants is observed.\nHowever, in the realm of sign language, experimentation in the sequence\nlearning component is limited. In this work, the state-of-the-art Conformer\nmodel for Speech Recognition is adapted for CSLR and the proposed model is\ntermed ConSignformer. This marks the first instance of employing Conformer for\na vision-based task. ConSignformer has bimodal pipeline of CNN as feature\nextractor and Conformer for sequence learning. For improved context learning we\nalso introduce Cross-Modal Relative Attention (CMRA). By incorporating CMRA\ninto the model, it becomes more adept at learning and utilizing complex\nrelationships within the data. To further enhance the Conformer model,\nunsupervised pretraining called Regressional Feature Extraction is conducted on\na curated sign language dataset. The pretrained Conformer is then fine-tuned\nfor the downstream recognition task. The experimental results confirm the\neffectiveness of the adopted pretraining strategy and demonstrate how CMRA\ncontributes to the recognition process. Remarkably, leveraging a\nConformer-based backbone, our model achieves state-of-the-art performance on\nthe benchmark datasets: PHOENIX-2014 and PHOENIX-2014T."
  },
  {
    "arxiv_id": "2405.11983",
    "title": "A review on the use of large language models as virtual tutors",
    "url": "http://arxiv.org/abs/2405.11983v1",
    "abstract": "Transformer architectures contribute to managing long-term dependencies for\nNatural Language Processing, representing one of the most recent changes in the\nfield. These architectures are the basis of the innovative, cutting-edge Large\nLanguage Models (LLMs) that have produced a huge buzz in several fields and\nindustrial sectors, among the ones education stands out. Accordingly, these\ngenerative Artificial Intelligence-based solutions have directed the change in\ntechniques and the evolution in educational methods and contents, along with\nnetwork infrastructure, towards high-quality learning. Given the popularity of\nLLMs, this review seeks to provide a comprehensive overview of those solutions\ndesigned specifically to generate and evaluate educational materials and which\ninvolve students and teachers in their design or experimental plan. To the best\nof our knowledge, this is the first review of educational applications (e.g.,\nstudent assessment) of LLMs. As expected, the most common role of these systems\nis as virtual tutors for automatic question generation. Moreover, the most\npopular models are GTP-3 and BERT. However, due to the continuous launch of new\ngenerative models, new works are expected to be published shortly."
  },
  {
    "arxiv_id": "2405.11941",
    "title": "Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT Model on an Automatically Generated Wikipedia Corpus",
    "url": "http://arxiv.org/abs/2405.11941v1",
    "abstract": "Biomedical entity linking, a main component in automatic information\nextraction from health-related texts, plays a pivotal role in connecting\ntextual entities (such as diseases, drugs and body parts mentioned by patients)\nto their corresponding concepts in a structured biomedical knowledge base. The\ntask remains challenging despite recent developments in natural language\nprocessing. This paper presents the first evaluated biomedical entity linking\nmodel for the Dutch language. We use MedRoBERTa.nl as base model and perform\nsecond-phase pretraining through self-alignment on a Dutch biomedical ontology\nextracted from the UMLS and Dutch SNOMED. We derive a corpus from Wikipedia of\nontology-linked Dutch biomedical entities in context and fine-tune our model on\nthis dataset. We evaluate our model on the Dutch portion of the Mantra\nGSC-corpus and achieve 54.7% classification accuracy and 69.8% 1-distance\naccuracy. We then perform a case study on a collection of unlabeled,\npatient-support forum data and show that our model is hampered by the limited\nquality of the preceding entity recognition step. Manual evaluation of small\nsample indicates that of the correctly extracted entities, around 65% is linked\nto the correct concept in the ontology. Our results indicate that biomedical\nentity linking in a language other than English remains challenging, but our\nDutch model can be used to for high-level analysis of patient-generated text."
  },
  {
    "arxiv_id": "2405.12842",
    "title": "SmartFlow: Robotic Process Automation using LLMs",
    "url": "http://arxiv.org/abs/2405.12842v1",
    "abstract": "Robotic Process Automation (RPA) systems face challenges in handling complex\nprocesses and diverse screen layouts that require advanced human-like\ndecision-making capabilities. These systems typically rely on pixel-level\nencoding through drag-and-drop or automation frameworks such as Selenium to\ncreate navigation workflows, rather than visual understanding of screen\nelements. In this context, we present SmartFlow, an AI-based RPA system that\nuses pre-trained large language models (LLMs) coupled with deep-learning based\nimage understanding. Our system can adapt to new scenarios, including changes\nin the user interface and variations in input data, without the need for human\nintervention. SmartFlow uses computer vision and natural language processing to\nperceive visible elements on the graphical user interface (GUI) and convert\nthem into a textual representation. This information is then utilized by LLMs\nto generate a sequence of actions that are executed by a scripting engine to\ncomplete an assigned task. To assess the effectiveness of SmartFlow, we have\ndeveloped a dataset that includes a set of generic enterprise applications with\ndiverse layouts, which we are releasing for research use. Our evaluations on\nthis dataset demonstrate that SmartFlow exhibits robustness across different\nlayouts and applications. SmartFlow can automate a wide range of business\nprocesses such as form filling, customer service, invoice processing, and\nback-office operations. SmartFlow can thus assist organizations in enhancing\nproductivity by automating an even larger fraction of screen-based workflows.\nThe demo-video and dataset are available at\nhttps://smartflow-4c5a0a.webflow.io/."
  },
  {
    "arxiv_id": "2405.12819",
    "title": "Large Language Models Meet NLP: A Survey",
    "url": "http://arxiv.org/abs/2405.12819v1",
    "abstract": "While large language models (LLMs) like ChatGPT have shown impressive\ncapabilities in Natural Language Processing (NLP) tasks, a systematic\ninvestigation of their potential in this field remains largely unexplored. This\nstudy aims to address this gap by exploring the following questions: (1) How\nare LLMs currently applied to NLP tasks in the literature? (2) Have traditional\nNLP tasks already been solved with LLMs? (3) What is the future of the LLMs for\nNLP? To answer these questions, we take the first step to provide a\ncomprehensive overview of LLMs in NLP. Specifically, we first introduce a\nunified taxonomy including (1) parameter-frozen application and (2)\nparameter-tuning application to offer a unified perspective for understanding\nthe current progress of LLMs in NLP. Furthermore, we summarize the new\nfrontiers and the associated challenges, aiming to inspire further\ngroundbreaking advancements. We hope this work offers valuable insights into\nthe {potential and limitations} of LLMs in NLP, while also serving as a\npractical guide for building effective LLMs in NLP."
  },
  {
    "arxiv_id": "2405.12779",
    "title": "Transformer in Touch: A Survey",
    "url": "http://arxiv.org/abs/2405.12779v1",
    "abstract": "The Transformer model, initially achieving significant success in the field\nof natural language processing, has recently shown great potential in the\napplication of tactile perception. This review aims to comprehensively outline\nthe application and development of Transformers in tactile technology. We first\nintroduce the two fundamental concepts behind the success of the Transformer:\nthe self-attention mechanism and large-scale pre-training. Then, we delve into\nthe application of Transformers in various tactile tasks, including but not\nlimited to object recognition, cross-modal generation, and object manipulation,\noffering a concise summary of the core methodologies, performance benchmarks,\nand design highlights. Finally, we suggest potential areas for further research\nand future work, aiming to generate more interest within the community, tackle\nexisting challenges, and encourage the use of Transformer models in the tactile\nfield."
  },
  {
    "arxiv_id": "2405.12630",
    "title": "Exploration of Masked and Causal Language Modelling for Text Generation",
    "url": "http://arxiv.org/abs/2405.12630v1",
    "abstract": "Large Language Models (LLMs) have revolutionised the field of Natural\nLanguage Processing (NLP) and have achieved state-of-the-art performance in\npractically every task in this field. However, the prevalent approach used in\ntext generation, Causal Language Modelling (CLM), which generates text\nsequentially from left to right, inherently limits the freedom of the model,\nwhich does not decide when and where each token is generated. In contrast,\nMasked Language Modelling (MLM), primarily used for language understanding\ntasks, can generate tokens anywhere in the text and any order. This paper\nconducts an extensive comparison of MLM and CLM approaches for text generation\ntasks. To do so, we pre-train several language models of comparable sizes on\nthree different datasets, namely 1) medical discharge summaries, 2) movie plot\nsynopses, and 3) authorship verification datasets. To assess the quality of the\ngenerations, we first employ quantitative metrics and then perform a\nqualitative human evaluation to analyse coherence and grammatical correctness.\nIn addition, we evaluate the usefulness of the generated texts by using them in\nthree different downstream tasks: 1) Entity Recognition, 2) Text\nClassification, and 3) Authorship Verification. The results show that MLM\nconsistently outperforms CLM in text generation across all datasets, with\nhigher quantitative scores and better coherence in the generated text. The\nstudy also finds \\textit{no strong correlation} between the quality of the\ngenerated text and the performance of the models in the downstream tasks. With\nthis study, we show that MLM for text generation has great potential for future\nresearch and provides direction for future studies in this area."
  },
  {
    "arxiv_id": "2405.14601",
    "title": "A FAIR and Free Prompt-based Research Assistant",
    "url": "http://arxiv.org/abs/2405.14601v1",
    "abstract": "This demo will present the Research Assistant (RA) tool developed to assist\nwith six main types of research tasks defined as standardized instruction\ntemplates, instantiated with user input, applied finally as prompts to\nwell-known--for their sophisticated natural language processing abilities--AI\ntools, such as ChatGPT (https://chat.openai.com/) and Gemini\n(https://gemini.google.com/app). The six research tasks addressed by RA are:\ncreating FAIR research comparisons, ideating research topics, drafting grant\napplications, writing scientific blogs, aiding preliminary peer reviews, and\nformulating enhanced literature search queries. RA's reliance on generative AI\ntools like ChatGPT or Gemini means the same research task assistance can be\noffered in any scientific discipline. We demonstrate its versatility by sharing\nRA outputs in Computer Science, Virology, and Climate Science, where the output\nwith the RA tool assistance mirrored that from a domain expert who performed\nthe same research task."
  },
  {
    "arxiv_id": "2405.14490",
    "title": "Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models",
    "url": "http://arxiv.org/abs/2405.14490v1",
    "abstract": "The advancement of large language models has significantly improved natural\nlanguage processing. However, challenges such as jailbreaks (prompt injections\nthat cause an LLM to follow instructions contrary to its intended use),\nhallucinations (generating incorrect or misleading information), and\ncomprehension errors remain prevalent. In this report, we present a comparative\nanalysis of the performance of fifteen distinct models, with each model\nundergoing a standardized test comprising 38 queries across three key metrics:\njailbreaks, hallucinations, and comprehension errors. The models are assessed\nbased on the total occurrences of jailbreaks, hallucinations, and comprehension\nerrors. Our work exposes these models' inherent vulnerabilities and challenges\nthe notion of human-level language comprehension of these models. We have\nempirically analysed the impact of non-standard Unicode characters on LLMs and\ntheir safeguarding mechanisms on the best-performing LLMs, including GPT-4,\nGemini 1.5 Pro, LlaMA-3-70B, and Claude 3 Opus. By incorporating alphanumeric\nsymbols from Unicode outside the standard Latin block and variants of\ncharacters in other languages, we observed a reduction in the efficacy of\nguardrails implemented through Reinforcement Learning Human Feedback (RLHF).\nConsequently, these models exhibit heightened vulnerability to content policy\nbreaches and prompt leakage. Our study also suggests a need to incorporate\nnon-standard Unicode text in LLM training data to enhance the capabilities of\nthese models."
  },
  {
    "arxiv_id": "2405.14437",
    "title": "Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models",
    "url": "http://arxiv.org/abs/2405.14437v1",
    "abstract": "Recently, using large pretrained Transformer models for transfer learning\ntasks has evolved to the point where they have become one of the flagship\ntrends in the Natural Language Processing (NLP) community, giving rise to\nvarious outlooks such as prompt-based, adapters or combinations with\nunsupervised approaches, among many others. This work proposes a 3 Phase\ntechnique to adjust a base model for a classification task. First, we adapt the\nmodel's signal to the data distribution by performing further training with a\nDenoising Autoencoder (DAE). Second, we adjust the representation space of the\noutput to the corresponding classes by clustering through a Contrastive\nLearning (CL) method. In addition, we introduce a new data augmentation\napproach for Supervised Contrastive Learning to correct the unbalanced\ndatasets. Third, we apply fine-tuning to delimit the predefined categories.\nThese different phases provide relevant and complementary knowledge to the\nmodel to learn the final task. We supply extensive experimental results on\nseveral datasets to demonstrate these claims. Moreover, we include an ablation\nstudy and compare the proposed method against other ways of combining these\ntechniques."
  },
  {
    "arxiv_id": "2405.14371",
    "title": "EdgeShard: Efficient LLM Inference via Collaborative Edge Computing",
    "url": "http://arxiv.org/abs/2405.14371v1",
    "abstract": "Large language models (LLMs) have shown great potential in natural language\nprocessing and content generation. However, current LLMs heavily rely on cloud\ncomputing, leading to prolonged latency, high bandwidth cost, and privacy\nconcerns. Edge computing is promising to address such concerns by deploying\nLLMs on edge devices, closer to data sources. Some works try to leverage model\nquantization to reduce the model size to fit the resource-constraint edge\ndevices, but they lead to accuracy loss. Other works use cloud-edge\ncollaboration, suffering from unstable network connections. In this work, we\nleverage collaborative edge computing to facilitate the collaboration among\nedge devices and cloud servers for jointly performing efficient LLM inference.\nWe propose a general framework to partition the LLM model into shards and\ndeploy on distributed devices. To achieve efficient LLM inference, we formulate\nan adaptive joint device selection and model partition problem and design an\nefficient dynamic programming algorithm to optimize the inference latency and\nthroughput, respectively. Experiments of Llama2 serial models on a\nheterogeneous physical prototype demonstrate that EdgeShard achieves up to 50%\nlatency reduction and 2x throughput improvement over baseline methods."
  },
  {
    "arxiv_id": "2405.15630",
    "title": "GPTZoo: A Large-scale Dataset of GPTs for the Research Community",
    "url": "http://arxiv.org/abs/2405.15630v1",
    "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nnatural language processing, with GPTs, customized versions of ChatGPT\navailable on the GPT Store, emerging as a prominent technology for specific\ndomains and tasks. To support academic research on GPTs, we introduce GPTZoo, a\nlarge-scale dataset comprising 730,420 GPT instances. Each instance includes\nrich metadata with 21 attributes describing its characteristics, as well as\ninstructions, knowledge files, and third-party services utilized during its\ndevelopment. GPTZoo aims to provide researchers with a comprehensive and\nreadily available resource to study the real-world applications, performance,\nand potential of GPTs. To facilitate efficient retrieval and analysis of GPTs,\nwe also developed an automated command-line interface (CLI) that supports\nkeyword-based searching of the dataset. To promote open research and\ninnovation, the GPTZoo dataset will undergo continuous updates, and we are\ngranting researchers public access to GPTZoo and its associated tools."
  },
  {
    "arxiv_id": "2405.15453",
    "title": "Benchmarking Pre-trained Large Language Models' Potential Across Urdu NLP tasks",
    "url": "http://arxiv.org/abs/2405.15453v1",
    "abstract": "Large Language Models (LLMs) pre-trained on multilingual data have\nrevolutionized natural language processing research, by transitioning from\nlanguages and task specific model pipelines to a single model adapted on a\nvariety of tasks. However majority of existing multilingual NLP benchmarks for\nLLMs provide evaluation data in only few languages with little linguistic\ndiversity. In addition these benchmarks lack quality assessment against the\nrespective state-of the art models. This study presents an in-depth examination\nof 7 prominent LLMs: GPT-3.5-turbo, Llama 2-7B-Chat, Llama 3.1-8B, Bloomz 3B,\nBloomz 7B1, Ministral-8B and Whisper (Large, medium and small variant) across\n17 tasks using 22 datasets, 13.8 hours of speech, in a zero-shot setting, and\ntheir performance against state-of-the-art (SOTA) models, has been compared and\nanalyzed. Our experiments show that SOTA models currently outperform\nencoder-decoder models in majority of Urdu NLP tasks under zero-shot settings.\nHowever, comparing Llama 3.1-8B over prior version Llama 2-7B-Chat, we can\ndeduce that with improved language coverage, LLMs can surpass these SOTA\nmodels. Our results emphasize that models with fewer parameters but richer\nlanguage-specific data, like Llama 3.1-8B, often outperform larger models with\nlower language diversity, such as GPT-3.5, in several tasks."
  },
  {
    "arxiv_id": "2405.15122",
    "title": "Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models",
    "url": "http://arxiv.org/abs/2405.15122v1",
    "abstract": "Background: Biomedical entity normalization is critical to biomedical\nresearch because the richness of free-text clinical data, such as progress\nnotes, can often be fully leveraged only after translating words and phrases\ninto structured and coded representations suitable for analysis. Large Language\nModels (LLMs), in turn, have shown great potential and high performance in a\nvariety of natural language processing (NLP) tasks, but their application for\nnormalization remains understudied.\n  Methods: We applied both proprietary and open-source LLMs in combination with\nseveral rule-based normalization systems commonly used in biomedical research.\nWe used a two-step LLM integration approach, (1) using an LLM to generate\nalternative phrasings of a source utterance, and (2) to prune candidate UMLS\nconcepts, using a variety of prompting methods. We measure results by\n$F_{\\beta}$, where we favor recall over precision, and F1.\n  Results: We evaluated a total of 5,523 concept terms and text contexts from a\npublicly available dataset of human-annotated biomedical abstracts.\nIncorporating GPT-3.5-turbo increased overall $F_{\\beta}$ and F1 in\nnormalization systems +9.5 and +7.3 (MetaMapLite), +13.9 and +10.9 (QuickUMLS),\nand +10.5 and +10.3 (BM25), while the open-source Vicuna model achieved +10.8\nand +12.2 (MetaMapLite), +14.7 and +15 (QuickUMLS), and +15.6 and +18.7 (BM25).\n  Conclusions: Existing general-purpose LLMs, both propriety and open-source,\ncan be leveraged at scale to greatly improve normalization performance using\nexisting tools, with no fine-tuning."
  },
  {
    "arxiv_id": "2405.16747",
    "title": "Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective",
    "url": "http://arxiv.org/abs/2405.16747v1",
    "abstract": "The two-stage fine-tuning (FT) method, linear probing (LP) then fine-tuning\n(LP-FT), outperforms linear probing and FT alone. This holds true for both\nin-distribution (ID) and out-of-distribution (OOD) data. One key reason for its\nsuccess is the preservation of pre-trained features, achieved by obtaining a\nnear-optimal linear head during LP. However, despite the widespread use of\nlarge language models, there has been limited exploration of more complex\narchitectures such as Transformers. In this paper, we analyze the training\ndynamics of LP-FT for classification tasks on the basis of the neural tangent\nkernel (NTK) theory. Our analysis decomposes the NTK matrix into two\ncomponents. This decomposition highlights the importance of the linear head\nnorm alongside the prediction accuracy at the start of the FT stage. We also\nobserve a significant increase in the linear head norm during LP, which stems\nfrom training with the cross-entropy (CE) loss. This increase in the linear\nhead norm effectively reduces changes in learned features. Furthermore, we find\nthat this increased norm can adversely affect model calibration, which can be\ncorrected using temperature scaling. Additionally, we extend our analysis with\nthe NTK to the low-rank adaptation (LoRA) method and validate its\neffectiveness. Our experiments using a Transformer-based model on multiple\nnatural language processing datasets confirm our theoretical analysis. Our\nstudy demonstrates the effectiveness of LP-FT for fine-tuning language models.\nCode is available at https://github.com/tom4649/lp-ft_ntk."
  },
  {
    "arxiv_id": "2405.16714",
    "title": "Crafting Interpretable Embeddings by Asking LLMs Questions",
    "url": "http://arxiv.org/abs/2405.16714v1",
    "abstract": "Large language models (LLMs) have rapidly improved text embeddings for a\ngrowing array of natural-language processing tasks. However, their opaqueness\nand proliferation into scientific domains such as neuroscience have created a\ngrowing need for interpretability. Here, we ask whether we can obtain\ninterpretable embeddings through LLM prompting. We introduce question-answering\nembeddings (QA-Emb), embeddings where each feature represents an answer to a\nyes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of\nunderlying questions rather than learning model weights.\n  We use QA-Emb to flexibly generate interpretable models for predicting fMRI\nvoxel responses to language stimuli. QA-Emb significantly outperforms an\nestablished interpretable baseline, and does so while requiring very few\nquestions. This paves the way towards building flexible feature spaces that can\nconcretize and evaluate our understanding of semantic brain representations. We\nadditionally find that QA-Emb can be effectively approximated with an efficient\nmodel, and we explore broader applications in simple NLP tasks."
  },
  {
    "arxiv_id": "2405.16571",
    "title": "A Preliminary Empirical Study on Prompt-based Unsupervised Keyphrase Extraction",
    "url": "http://arxiv.org/abs/2405.16571v1",
    "abstract": "Pre-trained large language models can perform natural language processing\ndownstream tasks by conditioning on human-designed prompts. However, a\nprompt-based approach often requires \"prompt engineering\" to design different\nprompts, primarily hand-crafted through laborious trial and error, requiring\nhuman intervention and expertise. It is a challenging problem when constructing\na prompt-based keyphrase extraction method. Therefore, we investigate and study\nthe effectiveness of different prompts on the keyphrase extraction task to\nverify the impact of the cherry-picked prompts on the performance of extracting\nkeyphrases. Extensive experimental results on six benchmark keyphrase\nextraction datasets and different pre-trained large language models demonstrate\nthat (1) designing complex prompts may not necessarily be more effective than\ndesigning simple prompts; (2) individual keyword changes in the designed\nprompts can affect the overall performance; (3) designing complex prompts\nachieve better performance than designing simple prompts when facing long\ndocuments."
  },
  {
    "arxiv_id": "2405.18380",
    "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning",
    "url": "http://arxiv.org/abs/2405.18380v1",
    "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds\nextra adapters to all layers, OwLore strategically assigns higher sampling\nprobabilities to layers with more outliers, selectively sampling only a few\nlayers and fine-tuning their pre-trained weights. To further increase the\nnumber of fine-tuned layers without a proportional rise in memory costs, we\nincorporate gradient low-rank projection, further boosting the approach's\nperformance. Our extensive experiments across various architectures, including\nLLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms\nbaseline approaches, including full fine-tuning. Specifically, it achieves up\nto a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory. Code is available at https://github.com/pixeli99/OwLore."
  },
  {
    "arxiv_id": "2405.18377",
    "title": "LLaMA-NAS: Efficient Neural Architecture Search for Large Language Models",
    "url": "http://arxiv.org/abs/2405.18377v1",
    "abstract": "The abilities of modern large language models (LLMs) in solving natural\nlanguage processing, complex reasoning, sentiment analysis and other tasks have\nbeen extraordinary which has prompted their extensive adoption. Unfortunately,\nthese abilities come with very high memory and computational costs which\nprecludes the use of LLMs on most hardware platforms. To mitigate this, we\npropose an effective method of finding Pareto-optimal network architectures\nbased on LLaMA2-7B using one-shot NAS. In particular, we fine-tune LLaMA2-7B\nonly once and then apply genetic algorithm-based search to find smaller, less\ncomputationally complex network architectures. We show that, for certain\nstandard benchmark tasks, the pre-trained LLaMA2-7B network is unnecessarily\nlarge and complex. More specifically, we demonstrate a 1.5x reduction in model\nsize and 1.3x speedup in throughput for certain tasks with negligible drop in\naccuracy. In addition to finding smaller, higher-performing network\narchitectures, our method does so more effectively and efficiently than certain\npruning or sparsification techniques. Finally, we demonstrate how quantization\nis complementary to our method and that the size and complexity of the networks\nwe find can be further decreased using quantization. We believe that our work\nprovides a way to automatically create LLMs which can be used on less expensive\nand more readily available hardware platforms."
  },
  {
    "arxiv_id": "2405.17992",
    "title": "fMRI predictors based on language models of increasing complexity recover brain left lateralization",
    "url": "http://arxiv.org/abs/2405.17992v1",
    "abstract": "Over the past decade, studies of naturalistic language processing where\nparticipants are scanned while listening to continuous text have flourished.\nUsing word embeddings at first, then large language models, researchers have\ncreated encoding models to analyze the brain signals. Presenting these models\nwith the same text as the participants allows to identify brain areas where\nthere is a significant correlation between the functional magnetic resonance\nimaging (fMRI) time series and the ones predicted by the models' artificial\nneurons. One intriguing finding from these studies is that they have revealed\nhighly symmetric bilateral activation patterns, somewhat at odds with the\nwell-known left lateralization of language processing. Here, we report analyses\nof an fMRI dataset where we manipulate the complexity of large language models,\ntesting 28 pretrained models from 8 different families, ranging from 124M to\n14.2B parameters. First, we observe that the performance of models in\npredicting brain responses follows a scaling law, where the fit with brain\nactivity increases linearly with the logarithm of the number of parameters of\nthe model (and its performance on natural language processing tasks). Second,\nalthough this effect is present in both hemispheres, it is stronger in the left\nthan in the right hemisphere. Specifically, the left-right difference in brain\ncorrelation follows a scaling law with the number of parameters. This finding\nreconciles computational analyses of brain activity using large language models\nwith the classic observation from aphasic patients showing left hemisphere\ndominance for language."
  },
  {
    "arxiv_id": "2405.19255",
    "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
    "url": "http://arxiv.org/abs/2405.19255v1",
    "abstract": "The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making."
  },
  {
    "arxiv_id": "2405.19164",
    "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery",
    "url": "http://arxiv.org/abs/2405.19164v1",
    "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents\nfrom a vast collection based on legal production requests. The integration of\nartificial intelligence (AI) and natural language processing (NLP) has\ntransformed this process, helping document review and enhance efficiency and\ncost-effectiveness. Although traditional approaches like BM25 or fine-tuned\npre-trained models are common in eDiscovery, they face performance,\ncomputational, and interpretability challenges. In contrast, Large Language\nModel (LLM)-based methods prioritize interpretability but sacrifice performance\nand throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid\napproach that combines the strengths of two worlds: a heterogeneous graph-based\nmethod for accurate document relevance prediction and subsequent LLM-driven\napproach for reasoning. Graph representational learning generates embeddings\nand predicts links, ranking the corpus for a given request, and the LLMs\nprovide reasoning for document relevance. Our approach handles datasets with\nbalanced and imbalanced distributions, outperforming baselines in F1-score,\nprecision, and recall by an average of 12%, 3%, and 16%, respectively. In an\nenterprise context, our approach drastically reduces document review costs by\n99.9% compared to manual processes and by 95% compared to LLM-based\nclassification methods"
  },
  {
    "arxiv_id": "2405.18874",
    "title": "Are queries and keys always relevant? A case study on Transformer wave functions",
    "url": "http://arxiv.org/abs/2405.18874v1",
    "abstract": "The dot product attention mechanism, originally designed for natural language\nprocessing tasks, is a cornerstone of modern Transformers. It adeptly captures\nsemantic relationships between word pairs in sentences by computing a\nsimilarity overlap between queries and keys. In this work, we explore the\nsuitability of Transformers, focusing on their attention mechanisms, in the\nspecific domain of the parametrization of variational wave functions to\napproximate ground states of quantum many-body spin Hamiltonians. Specifically,\nwe perform numerical simulations on the two-dimensional $J_1$-$J_2$ Heisenberg\nmodel, a common benchmark in the field of quantum many-body systems on lattice.\nBy comparing the performance of standard attention mechanisms with a simplified\nversion that excludes queries and keys, relying solely on positions, we achieve\ncompetitive results while reducing computational cost and parameter usage.\nFurthermore, through the analysis of the attention maps generated by standard\nattention mechanisms, we show that the attention weights become effectively\ninput-independent at the end of the optimization. We support the numerical\nresults with analytical calculations, providing physical insights of why\nqueries and keys should be, in principle, omitted from the attention mechanism\nwhen studying large systems."
  },
  {
    "arxiv_id": "2405.18741",
    "title": "Genshin: General Shield for Natural Language Processing with Large Language Models",
    "url": "http://arxiv.org/abs/2405.18741v1",
    "abstract": "Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless."
  },
  {
    "arxiv_id": "2405.18732",
    "title": "Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts",
    "url": "http://arxiv.org/abs/2405.18732v1",
    "abstract": "This paper presents a novel approach to extract scientifically valuable\ninformation about Earth's physical phenomena from unconventional sources, such\nas multi-modal social media posts. Employing a state-of-the-art large language\nmodel (LLM), Gemini 1.5 Pro (Reid et al. 2024), we estimate earthquake ground\nshaking intensity from these unstructured posts. The model's output, in the\nform of Modified Mercalli Intensity (MMI) values, aligns well with independent\nobservational data. Furthermore, our results suggest that LLMs, trained on vast\ninternet data, may have developed a unique understanding of physical phenomena.\nSpecifically, Google's Gemini models demonstrate a simplified understanding of\nthe general relationship between earthquake magnitude, distance, and MMI\nintensity, accurately describing observational data even though it's not\nidentical to established models. These findings raise intriguing questions\nabout the extent to which Gemini's training has led to a broader understanding\nof the physical world and its phenomena. The ability of Generative AI models\nlike Gemini to generate results consistent with established scientific\nknowledge highlights their potential to augment our understanding of complex\nphysical phenomena like earthquakes. The flexible and effective approach\nproposed in this study holds immense potential for enriching our understanding\nof the impact of physical phenomena and improving resilience during natural\ndisasters. This research is a significant step toward harnessing the power of\nsocial media and AI for natural disaster mitigation, opening new avenues for\nunderstanding the emerging capabilities of Generative AI and LLMs for\nscientific applications."
  },
  {
    "arxiv_id": "2405.18653",
    "title": "Recent Advances of Foundation Language Models-based Continual Learning: A Survey",
    "url": "http://arxiv.org/abs/2405.18653v1",
    "abstract": "Recently, foundation language models (LMs) have marked significant\nachievements in the domains of natural language processing (NLP) and computer\nvision (CV). Unlike traditional neural network models, foundation LMs obtain a\ngreat ability for transfer learning by acquiring rich commonsense knowledge\nthrough pre-training on extensive unsupervised datasets with a vast number of\nparameters. However, they still can not emulate human-like continuous learning\ndue to catastrophic forgetting. Consequently, various continual learning\n(CL)-based methodologies have been developed to refine LMs, enabling them to\nadapt to new tasks without forgetting previous knowledge. However, a systematic\ntaxonomy of existing approaches and a comparison of their performance are still\nlacking, which is the gap that our survey aims to fill. We delve into a\ncomprehensive review, summarization, and classification of the existing\nliterature on CL-based approaches applied to foundation language models, such\nas pre-trained language models (PLMs), large language models (LLMs) and\nvision-language models (VLMs). We divide these studies into offline CL and\nonline CL, which consist of traditional methods, parameter-efficient-based\nmethods, instruction tuning-based methods and continual pre-training methods.\nOffline CL encompasses domain-incremental learning, task-incremental learning,\nand class-incremental learning, while online CL is subdivided into hard task\nboundary and blurry task boundary settings. Additionally, we outline the\ntypical datasets and metrics employed in CL research and provide a detailed\nanalysis of the challenges and future work for LMs-based continual learning."
  },
  {
    "arxiv_id": "2405.20139",
    "title": "GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning",
    "url": "http://arxiv.org/abs/2405.20139v1",
    "abstract": "Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form\nof triplets (head, relation, tail), which collectively form a graph. Question\nAnswering over KGs (KGQA) is the task of answering natural questions grounding\nthe reasoning to the information provided by the KG. Large Language Models\n(LLMs) are the state-of-the-art models for QA tasks due to their remarkable\nability to understand natural language. On the other hand, Graph Neural\nNetworks (GNNs) have been widely used for KGQA as they can handle the complex\ngraph information stored in the KG. In this work, we introduce GNN-RAG, a novel\nmethod for combining language understanding abilities of LLMs with the\nreasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.\nFirst, a GNN reasons over a dense KG subgraph to retrieve answer candidates for\na given question. Second, the shortest paths in the KG that connect question\nentities and answer candidates are extracted to represent KG reasoning paths.\nThe extracted paths are verbalized and given as input for LLM reasoning with\nRAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to\nextract useful graph information, while the LLM leverages its natural language\nprocessing ability for ultimate KGQA. Furthermore, we develop a retrieval\naugmentation (RA) technique to further boost KGQA performance with GNN-RAG.\nExperimental results show that GNN-RAG achieves state-of-the-art performance in\ntwo widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching\nGPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop\nand multi-entity questions outperforming competing approaches by 8.9--15.5%\npoints at answer F1."
  },
  {
    "arxiv_id": "2405.19686",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "url": "http://arxiv.org/abs/2405.19686v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in a\nrange of natural language processing tasks. Once deployed, LLMs encounter users\nwith personalized factual knowledge, and such personalized knowledge is\nconsistently reflected through users' interactions with the LLMs. To enhance\nuser experience, real-time model personalization is essential, allowing LLMs to\nadapt user-specific knowledge based on user feedback during human-LLM\ninteractions. Existing methods mostly require back-propagation to finetune the\nmodel parameters, which incurs high computational and memory costs. In\naddition, these methods suffer from low interpretability, which will cause\nunforeseen impacts on model performance during long-term use, where the user's\npersonalized knowledge is accumulated extensively.To address these challenges,\nwe propose Knowledge Graph Tuning (KGT), a novel approach that leverages\nknowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual\nknowledge triples from users' queries and feedback and optimizes KGs without\nmodifying the LLM parameters. Our method improves computational and memory\nefficiency by avoiding back-propagation and ensures interpretability by making\nthe KG adjustments comprehensible to humans.Experiments with state-of-the-art\nLLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves\npersonalization performance while reducing latency and GPU memory costs.\nUltimately, KGT offers a promising solution of effective, efficient, and\ninterpretable real-time LLM personalization during user interactions with the\nLLMs."
  },
  {
    "arxiv_id": "2405.19578",
    "title": "The Accuracy of Domain Specific and Descriptive Analysis Generated by Large Language Models",
    "url": "http://arxiv.org/abs/2405.19578v1",
    "abstract": "Large language models (LLMs) have attracted considerable attention as they\nare capable of showcasing impressive capabilities generating comparable\nhigh-quality responses to human inputs. LLMs, can not only compose textual\nscripts such as emails and essays but also executable programming code.\nContrary, the automated reasoning capability of these LLMs in performing\nstatistically-driven descriptive analysis, particularly on user-specific data\nand as personal assistants to users with limited background knowledge in an\napplication domain who would like to carry out basic, as well as advanced\nstatistical and domain-specific analysis is not yet fully explored. More\nimportantly, the performance of these LLMs has not been compared and discussed\nin detail when domain-specific data analysis tasks are needed. This study,\nconsequently, explores whether LLMs can be used as generative AI-based personal\nassistants to users with minimal background knowledge in an application domain\ninfer key data insights. To demonstrate the performance of the LLMs, the study\nreports a case study through which descriptive statistical analysis, as well as\nNatural Language Processing (NLP) based investigations, are performed on a\nnumber of phishing emails with the objective of comparing the accuracy of the\nresults generated by LLMs to the ones produced by analysts. The experimental\nresults show that LangChain and the Generative Pre-trained Transformer (GPT-4)\nexcel in numerical reasoning tasks i.e., temporal statistical analysis, achieve\ncompetitive correlation with human judgments on feature engineering tasks while\nstruggle to some extent on domain specific knowledge reasoning, where\ndomain-specific knowledge is required."
  },
  {
    "arxiv_id": "2405.19561",
    "title": "Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models",
    "url": "http://arxiv.org/abs/2405.19561v1",
    "abstract": "The startling success of ChatGPT and other large language models (LLMs) using\ntransformer-based generative neural network architecture in applications such\nas natural language processing and image synthesis has many researchers excited\nabout potential opportunities in process systems engineering (PSE). The almost\nhuman-like performance of LLMs in these areas is indeed very impressive,\nsurprising, and a major breakthrough. Their capabilities are very useful in\ncertain tasks, such as writing first drafts of documents, code writing\nassistance, text summarization, etc. However, their success is limited in\nhighly scientific domains as they cannot yet reason, plan, or explain due to\ntheir lack of in-depth domain knowledge. This is a problem in domains such as\nchemical engineering as they are governed by fundamental laws of physics and\nchemistry (and biology), constitutive relations, and highly technical knowledge\nabout materials, processes, and systems. Although purely data-driven machine\nlearning has its immediate uses, the long-term success of AI in scientific and\nengineering domains would depend on developing hybrid AI systems that use first\nprinciples and technical knowledge effectively. We call these hybrid AI systems\nLarge Knowledge Models (LKMs), as they will not be limited to only NLP-based\ntechniques or NLP-like applications. In this paper, we discuss the challenges\nand opportunities in developing such systems in chemical engineering."
  },
  {
    "arxiv_id": "2405.20962",
    "title": "Large Language Models are Zero-Shot Next Location Predictors",
    "url": "http://arxiv.org/abs/2405.20962v2",
    "abstract": "Predicting the locations an individual will visit in the future is crucial\nfor solving many societal issues like disease diffusion and reduction of\npollution. However, next-location predictors require a significant amount of\nindividual-level information that may be scarce or unavailable in some\nscenarios (e.g., cold-start). Large Language Models (LLMs) have shown good\ngeneralization and reasoning capabilities and are rich in geographical\nknowledge, allowing us to believe that these models can act as zero-shot\nnext-location predictors. We tested more than 15 LLMs on three real-world\nmobility datasets and we found that LLMs can obtain accuracies up to 36.2%, a\nsignificant relative improvement of almost 640% when compared to other models\nspecifically designed for human mobility. We also test for data contamination\nand explored the possibility of using LLMs as text-based explainers for\nnext-location prediction, showing that, regardless of the model size, LLMs can\nexplain their decision."
  },
  {
    "arxiv_id": "2405.20900",
    "title": "Large Language Models: A New Approach for Privacy Policy Analysis at Scale",
    "url": "http://arxiv.org/abs/2405.20900v1",
    "abstract": "The number and dynamic nature of web and mobile applications presents\nsignificant challenges for assessing their compliance with data protection\nlaws. In this context, symbolic and statistical Natural Language Processing\n(NLP) techniques have been employed for the automated analysis of these\nsystems' privacy policies. However, these techniques typically require\nlabor-intensive and potentially error-prone manually annotated datasets for\ntraining and validation. This research proposes the application of Large\nLanguage Models (LLMs) as an alternative for effectively and efficiently\nextracting privacy practices from privacy policies at scale. Particularly, we\nleverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the\noptimal design of prompts, parameters, and models, incorporating advanced\nstrategies such as few-shot learning. We further illustrate its capability to\ndetect detailed and varied privacy practices accurately. Using several renowned\ndatasets in the domain as a benchmark, our evaluation validates its exceptional\nperformance, achieving an F1 score exceeding 93%. Besides, it does so with\nreduced costs, faster processing times, and fewer technical knowledge\nrequirements. Consequently, we advocate for LLM-based solutions as a sound\nalternative to traditional NLP techniques for the automated analysis of privacy\npolicies at scale."
  },
  {
    "arxiv_id": "2405.20611",
    "title": "Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code",
    "url": "http://arxiv.org/abs/2405.20611v1",
    "abstract": "Detecting vulnerabilities within compiled binaries is challenging due to lost\nhigh-level code structures and other factors such as architectural\ndependencies, compilers, and optimization options. To address these obstacles,\nthis research explores vulnerability detection using natural language\nprocessing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn\nsemantics from intermediate representation (LLVM IR) code. Long short-term\nmemory (LSTM) neural networks were trained on embeddings from encoders created\nusing approximately 48k LLVM functions from the Juliet dataset. This study is\npioneering in its comparison of word2vec models with multiple bidirectional\ntransformers (BERT, RoBERTa) embeddings built using LLVM code to train neural\nnetworks to detect vulnerabilities in compiled binaries. Word2vec Skip-Gram\nmodels achieved 92% validation accuracy in detecting vulnerabilities,\noutperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. This\nsuggests that complex contextual embeddings may not provide advantages over\nsimpler word2vec models for this task when a limited number (e.g. 48K) of data\nsamples are used to train the bidirectional transformer-based models. The\ncomparative results provide novel insights into selecting optimal embeddings\nfor learning compiler-independent semantic code representations to advance\nmachine learning detection of vulnerabilities in compiled binaries."
  },
  {
    "arxiv_id": "2406.02368",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "url": "http://arxiv.org/abs/2406.02368v1",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in the field\nof natural language processing (NLP), demonstrating remarkable abilities in\nproducing text that resembles human language for various tasks. This opens up\nnew opportunities for employing them in recommender systems (RSs). In this\npaper, we specifically examine the sample efficiency of LLM-enhanced\nrecommender systems, which pertains to the model's capacity to attain superior\nperformance with a limited quantity of training data. Conventional\nrecommendation models (CRMs) often need a large amount of training data because\nof the sparsity of features and interactions. Hence, we propose and verify our\ncore viewpoint: Large Language Models Make Sample-Efficient Recommender\nSystems. We propose a simple yet effective framework (i.e., Laser) to validate\nthe viewpoint from two aspects: (1) LLMs themselves are sample-efficient\nrecommenders; and (2) LLMs, as feature generators and encoders, make CRMs more\nsample-efficient. Extensive experiments on two public datasets show that Laser\nrequires only a small fraction of training samples to match or even surpass\nCRMs that are trained on the entire training set, demonstrating superior sample\nefficiency."
  },
  {
    "arxiv_id": "2406.02134",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "url": "http://arxiv.org/abs/2406.02134v1",
    "abstract": "Large language models (LLMs) like ChatGPT show excellent capabilities in\nvarious natural language processing tasks, especially for text generation. The\neffectiveness of LLMs in summarizing radiology report impressions remains\nunclear. In this study, we explore the capability of eight LLMs on the\nradiology report impression summarization. Three types of radiology reports,\ni.e., CT, PET-CT, and Ultrasound reports, are collected from Peking University\nCancer Hospital and Institute. We use the report findings to construct the\nzero-shot, one-shot, and three-shot prompts with complete example reports to\ngenerate the impressions. Besides the automatic quantitative evaluation\nmetrics, we define five human evaluation metrics, i.e., completeness,\ncorrectness, conciseness, verisimilitude, and replaceability, to evaluate the\nsemantics of the generated impressions. Two thoracic surgeons (ZSY and LB) and\none radiologist (LQ) compare the generated impressions with the reference\nimpressions and score each impression under the five human evaluation metrics.\nExperimental results show that there is a gap between the generated impressions\nand reference impressions. Although the LLMs achieve comparable performance in\ncompleteness and correctness, the conciseness and verisimilitude scores are not\nvery high. Using few-shot prompts can improve the LLMs' performance in\nconciseness and verisimilitude, but the clinicians still think the LLMs can not\nreplace the radiologists in summarizing the radiology impressions."
  },
  {
    "arxiv_id": "2406.02079",
    "title": "Assessing the Performance of Chinese Open Source Large Language Models in Information Extraction Tasks",
    "url": "http://arxiv.org/abs/2406.02079v1",
    "abstract": "Information Extraction (IE) plays a crucial role in Natural Language\nProcessing (NLP) by extracting structured information from unstructured text,\nthereby facilitating seamless integration with various real-world applications\nthat rely on structured data. Despite its significance, recent experiments\nfocusing on English IE tasks have shed light on the challenges faced by Large\nLanguage Models (LLMs) in achieving optimal performance, particularly in\nsub-tasks like Named Entity Recognition (NER). In this paper, we delve into a\ncomprehensive investigation of the performance of mainstream Chinese\nopen-source LLMs in tackling IE tasks, specifically under zero-shot conditions\nwhere the models are not fine-tuned for specific tasks. Additionally, we\npresent the outcomes of several few-shot experiments to further gauge the\ncapability of these models. Moreover, our study includes a comparative analysis\nbetween these open-source LLMs and ChatGPT, a widely recognized language model,\non IE performance. Through meticulous experimentation and analysis, we aim to\nprovide insights into the strengths, limitations, and potential enhancements of\nexisting Chinese open-source LLMs in the domain of Information Extraction\nwithin the context of NLP."
  },
  {
    "arxiv_id": "2406.01863",
    "title": "Towards Effective Time-Aware Language Representation: Exploring Enhanced Temporal Understanding in Language Models",
    "url": "http://arxiv.org/abs/2406.01863v1",
    "abstract": "In the evolving field of Natural Language Processing (NLP), understanding the\ntemporal context of text is increasingly critical for applications requiring\nadvanced temporal reasoning. Traditional pre-trained language models like BERT,\nwhich rely on synchronic document collections such as BookCorpus and Wikipedia,\noften fall short in effectively capturing and leveraging temporal information.\nTo address this limitation, we introduce BiTimeBERT 2.0, a novel time-aware\nlanguage model pre-trained on a temporal news article collection. BiTimeBERT\n2.0 incorporates temporal information through three innovative pre-training\nobjectives: Extended Time-Aware Masked Language Modeling (ETAMLM), Document\nDating (DD), and Time-Sensitive Entity Replacement (TSER). Each objective is\nspecifically designed to target a distinct dimension of temporal information:\nETAMLM enhances the model's understanding of temporal contexts and relations,\nDD integrates document timestamps as explicit chronological markers, and TSER\nfocuses on the temporal dynamics of \"Person\" entities. Moreover, our refined\ncorpus preprocessing strategy reduces training time by nearly 53\\%, making\nBiTimeBERT 2.0 significantly more efficient while maintaining high performance.\nExperimental results show that BiTimeBERT 2.0 achieves substantial improvements\nacross a broad range of time-related tasks and excels on datasets spanning\nextensive temporal ranges. These findings underscore BiTimeBERT 2.0's potential\nas a powerful tool for advancing temporal reasoning in NLP."
  },
  {
    "arxiv_id": "2406.01775",
    "title": "OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models",
    "url": "http://arxiv.org/abs/2406.01775v1",
    "abstract": "The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling unprecedented capabilities in understanding and\ngenerating human-like text. However, the computational cost and convergence\ntimes associated with fine-tuning these models remain significant challenges.\nLow-Rank Adaptation (LoRA) has emerged as a promising method to mitigate these\nissues by introducing efficient fine-tuning techniques with a reduced number of\ntrainable parameters. In this paper, we present OLoRA, an enhancement to the\nLoRA method that leverages orthonormal matrix initialization through QR\ndecomposition. OLoRA significantly accelerates the convergence of LLM training\nwhile preserving the efficiency benefits of LoRA, such as the number of\ntrainable parameters and GPU memory footprint. Our empirical evaluations\ndemonstrate that OLoRA not only converges faster but also exhibits improved\nperformance compared to standard LoRA across a variety of language modeling\ntasks. This advancement opens new avenues for more efficient and accessible\nfine-tuning of LLMs, potentially enabling broader adoption and innovation in\nnatural language applications."
  },
  {
    "arxiv_id": "2406.01392",
    "title": "Sparsity-Accelerated Training for Large Language Models",
    "url": "http://arxiv.org/abs/2406.01392v1",
    "abstract": "Large language models (LLMs) have demonstrated proficiency across various\nnatural language processing (NLP) tasks but often require additional training,\nsuch as continual pre-training and supervised fine-tuning. However, the costs\nassociated with this, primarily due to their large parameter count, remain\nhigh. This paper proposes leveraging \\emph{sparsity} in pre-trained LLMs to\nexpedite this training process. By observing sparsity in activated neurons\nduring forward iterations, we identify the potential for computational\nspeed-ups by excluding inactive neurons. We address associated challenges by\nextending existing neuron importance evaluation metrics and introducing a\nladder omission rate scheduler. Our experiments on Llama-2 demonstrate that\nSparsity-Accelerated Training (SAT) achieves comparable or superior performance\nto standard training while significantly accelerating the process.\nSpecifically, SAT achieves a $45\\%$ throughput improvement in continual\npre-training and saves $38\\%$ training time in supervised fine-tuning in\npractice. It offers a simple, hardware-agnostic, and easily deployable\nframework for additional LLM training. Our code is available at\nhttps://github.com/OpenDFM/SAT."
  },
  {
    "arxiv_id": "2406.01314",
    "title": "Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization",
    "url": "http://arxiv.org/abs/2406.01314v1",
    "abstract": "The Transformer model has been pivotal in advancing fields such as natural\nlanguage processing, speech recognition, and computer vision. However, a\ncritical limitation of this model is its quadratic computational and memory\ncomplexity relative to the sequence length, which constrains its application to\nlonger sequences. This is especially crucial in medical imaging where\nhigh-resolution images can reach gigapixel scale. Efforts to address this issue\nhave predominantely focused on complex techniques, such as decomposing the\nsoftmax operation integral to the Transformer's architecture. This paper\naddresses this quadratic computational complexity of Transformer models and\nintroduces a remarkably simple and effective method that circumvents this issue\nby eliminating the softmax function from the attention mechanism and adopting a\nsequence normalization technique for the key, query, and value tokens. Coupled\nwith a reordering of matrix multiplications this approach reduces the memory-\nand compute complexity to a linear scale. We evaluate this approach across\nvarious medical imaging datasets comprising fundoscopic, dermascopic,\nradiologic and histologic imaging data. Our findings highlight that these\nmodels exhibit a comparable performance to traditional transformer models,\nwhile efficiently handling longer sequences."
  },
  {
    "arxiv_id": "2406.01311",
    "title": "FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs",
    "url": "http://arxiv.org/abs/2406.01311v1",
    "abstract": "Fact-checking is a crucial natural language processing (NLP) task that\nverifies the truthfulness of claims by considering reliable evidence.\nTraditional methods are often limited by labour-intensive data curation and\nrule-based approaches. In this paper, we present FactGenius, a novel method\nthat enhances fact-checking by combining zero-shot prompting of large language\nmodels (LLMs) with fuzzy text matching on knowledge graphs (KGs). Leveraging\nDBpedia, a structured linked data dataset derived from Wikipedia, FactGenius\nrefines LLM-generated connections using similarity measures to ensure accuracy.\nThe evaluation of FactGenius on the FactKG, a benchmark dataset for fact\nverification, demonstrates that it significantly outperforms existing\nbaselines, particularly when fine-tuning RoBERTa as a classifier. The two-stage\napproach of filtering and validating connections proves crucial, achieving\nsuperior performance across various reasoning types and establishing FactGenius\nas a promising tool for robust fact-checking. The code and materials are\navailable at https://github.com/SushantGautam/FactGenius."
  },
  {
    "arxiv_id": "2406.03478",
    "title": "Convolutional Neural Networks and Vision Transformers for Fashion MNIST Classification: A Literature Review",
    "url": "http://arxiv.org/abs/2406.03478v1",
    "abstract": "Our review explores the comparative analysis between Convolutional Neural\nNetworks (CNNs) and Vision Transformers (ViTs) in the domain of image\nclassification, with a particular focus on clothing classification within the\ne-commerce sector. Utilizing the Fashion MNIST dataset, we delve into the\nunique attributes of CNNs and ViTs. While CNNs have long been the cornerstone\nof image classification, ViTs introduce an innovative self-attention mechanism\nenabling nuanced weighting of different input data components. Historically,\ntransformers have primarily been associated with Natural Language Processing\n(NLP) tasks. Through a comprehensive examination of existing literature, our\naim is to unveil the distinctions between ViTs and CNNs in the context of image\nclassification. Our analysis meticulously scrutinizes state-of-the-art\nmethodologies employing both architectures, striving to identify the factors\ninfluencing their performance. These factors encompass dataset characteristics,\nimage dimensions, the number of target classes, hardware infrastructure, and\nthe specific architectures along with their respective top results. Our key\ngoal is to determine the most appropriate architecture between ViT and CNN for\nclassifying images in the Fashion MNIST dataset within the e-commerce industry,\nwhile taking into account specific conditions and needs. We highlight the\nimportance of combining these two architectures with different forms to enhance\noverall performance. By uniting these architectures, we can take advantage of\ntheir unique strengths, which may lead to more precise and reliable models for\ne-commerce applications. CNNs are skilled at recognizing local patterns, while\nViTs are effective at grasping overall context, making their combination a\npromising strategy for boosting image classification performance."
  },
  {
    "arxiv_id": "2406.03470",
    "title": "SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN",
    "url": "http://arxiv.org/abs/2406.03470v1",
    "abstract": "Spiking neural network (SNN) has attracted great attention due to its\ncharacteristic of high efficiency and accuracy. Currently, the ANN-to-SNN\nconversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8\ntime-steps) in CNN structure on computer vision (CV) tasks. However, as\nTransformer-based networks have achieved prevailing precision on both CV and\nnatural language processing (NLP), the Transformer-based SNNs are still\nencounting the lower accuracy w.r.t the ANN counterparts. In this work, we\nintroduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN\nand SNN are exactly equivalent, thus incurring no accuracy degradation.\nSpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79%\naccuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based\nSNNs. The code is available in GitHub:\nhttps://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer"
  },
  {
    "arxiv_id": "2406.03248",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "url": "http://arxiv.org/abs/2406.03248v1",
    "abstract": "The explainability of recommender systems has attracted significant attention\nin academia and industry. Many efforts have been made for explainable\nrecommendations, yet evaluating the quality of the explanations remains a\nchallenging and unresolved issue. In recent years, leveraging LLMs as\nevaluators presents a promising avenue in Natural Language Processing tasks\n(e.g., sentiment classification, information extraction), as they perform\nstrong capabilities in instruction following and common-sense reasoning.\nHowever, evaluating recommendation explanatory texts is different from these\nNLG tasks, as its criteria are related to human perceptions and are usually\nsubjective. In this paper, we investigate whether LLMs can serve as evaluators\nof recommendation explanations. To answer the question, we utilize real user\nfeedback on explanations given from previous work and additionally collect\nthird-party annotations and LLM evaluations. We design and apply a 3-level meta\nevaluation strategy to measure the correlation between evaluator labels and the\nground truth provided by users. Our experiments reveal that LLMs, such as GPT4,\ncan provide comparable evaluations with appropriate prompts and settings. We\nalso provide further insights into combining human labels with the LLM\nevaluation process and utilizing ensembles of multiple heterogeneous LLM\nevaluators to enhance the accuracy and stability of evaluations. Our study\nverifies that utilizing LLMs as evaluators can be an accurate, reproducible and\ncost-effective solution for evaluating recommendation explanation texts. Our\ncode is available at https://github.com/Xiaoyu-SZ/LLMasEvaluator."
  },
  {
    "arxiv_id": "2406.03115",
    "title": "GET: A Generative EEG Transformer for continuous context-based neural",
    "url": "http://arxiv.org/abs/2406.03115v1",
    "abstract": "Generating continuous electroencephalography (EEG) signals through advanced\nartificial neural networks presents a novel opportunity to enhance\nbrain-computer interface (BCI) technology. This capability has the potential to\nsignificantly enhance applications ranging from simulating dynamic brain\nactivity and data augmentation to improving real-time epilepsy detection and\nBCI inference. By harnessing generative transformer neural networks,\nspecifically designed for EEG signal generation, we can revolutionize the\ninterpretation and interaction with neural data. Generative AI has demonstrated\nsignificant success across various domains, from natural language processing\n(NLP) and computer vision to content creation in visual arts and music. It\ndistinguishes itself by using large-scale datasets to construct context windows\nduring pre-training, a technique that has proven particularly effective in NLP,\nwhere models are fine-tuned for specific downstream tasks after extensive\nfoundational training. However, the application of generative AI in the field\nof BCIs, particularly through the development of continuous, context-rich\nneural signal generators, has been limited. To address this, we introduce the\nGenerative EEG Transformer (GET), a model leveraging transformer architecture\ntailored for EEG data. The GET model is pre-trained on diverse EEG datasets,\nincluding motor imagery and alpha wave datasets, enabling it to produce\nhigh-fidelity neural signals that maintain contextual integrity. Our empirical\nfindings indicate that GET not only faithfully reproduces the frequency\nspectrum of the training data and input prompts but also robustly generates\ncontinuous neural signals. By adopting the successful training strategies of\nthe NLP domain for BCIs, the GET sets a new standard for the development and\napplication of neural signal generation technologies."
  },
  {
    "arxiv_id": "2406.03007",
    "title": "BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents",
    "url": "http://arxiv.org/abs/2406.03007v1",
    "abstract": "With the prosperity of large language models (LLMs), powerful LLM-based\nintelligent agents have been developed to provide customized services with a\nset of user-defined tools. State-of-the-art methods for constructing LLM agents\nadopt trained LLMs and further fine-tune them on data for the agent task.\nHowever, we show that such methods are vulnerable to our proposed backdoor\nattacks named BadAgent on various agent tasks, where a backdoor can be embedded\nby fine-tuning on the backdoor data. At test time, the attacker can manipulate\nthe deployed LLM agents to execute harmful operations by showing the trigger in\nthe agent input or environment. To our surprise, our proposed attack methods\nare extremely robust even after fine-tuning on trustworthy data. Though\nbackdoor attacks have been studied extensively in natural language processing,\nto the best of our knowledge, we could be the first to study them on LLM agents\nthat are more dangerous due to the permission to use external tools. Our work\ndemonstrates the clear risk of constructing LLM agents based on untrusted LLMs\nor data. Our code is public at https://github.com/DPamK/BadAgent"
  },
  {
    "arxiv_id": "2406.04244",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "url": "http://arxiv.org/abs/2406.04244v1",
    "abstract": "The rapid development of Large Language Models (LLMs) like GPT-4, Claude-3,\nand Gemini has transformed the field of natural language processing. However,\nit has also resulted in a significant issue known as Benchmark Data\nContamination (BDC). This occurs when language models inadvertently incorporate\nevaluation benchmark information from their training data, leading to\ninaccurate or unreliable performance during the evaluation phase of the\nprocess. This paper reviews the complex challenge of BDC in LLM evaluation and\nexplores alternative assessment methods to mitigate the risks associated with\ntraditional benchmarks. The paper also examines challenges and future\ndirections in mitigating BDC risks, highlighting the complexity of the issue\nand the need for innovative solutions to ensure the reliability of LLM\nevaluation in real-world applications."
  },
  {
    "arxiv_id": "2406.04202",
    "title": "Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model",
    "url": "http://arxiv.org/abs/2406.04202v1",
    "abstract": "With the development of large-scale Language Models (LLM), fine-tuning\npre-trained LLM has become a mainstream paradigm for solving downstream tasks\nof natural language processing. However, training a language model in the legal\nfield requires a large number of legal documents so that the language model can\nlearn legal terminology and the particularity of the format of legal documents.\nThe typical NLP approaches usually rely on many manually annotated data sets\nfor training. However, in the legal field application, it is difficult to\nobtain a large number of manually annotated data sets, which restricts the\ntypical method applied to the task of drafting legal documents. The\nexperimental results of this paper show that not only can we leverage a large\nnumber of annotation-free legal documents without Chinese word segmentation to\nfine-tune a large-scale language model, but more importantly, it can fine-tune\na pre-trained LLM on the local computer to achieve the generating legal\ndocument drafts task, and at the same time achieve the protection of\ninformation privacy and to improve information security issues."
  },
  {
    "arxiv_id": "2406.04143",
    "title": "Do Language Models Understand Morality? Towards a Robust Detection of Moral Content",
    "url": "http://arxiv.org/abs/2406.04143v1",
    "abstract": "The task of detecting moral values in text has significant implications in\nvarious fields, including natural language processing, social sciences, and\nethical decision-making. Previously proposed supervised models often suffer\nfrom overfitting, leading to hyper-specialized moral classifiers that struggle\nto perform well on data from different domains. To address this issue, we\nintroduce novel systems that leverage abstract concepts and common-sense\nknowledge acquired from Large Language Models and Natural Language Inference\nmodels during previous stages of training on multiple data sources. By doing\nso, we aim to develop versatile and robust methods for detecting moral values\nin real-world scenarios. Our approach uses the GPT 3.5 model as a zero-shot\nready-made unsupervised multi-label classifier for moral values detection,\neliminating the need for explicit training on labeled data. We compare it with\na smaller NLI-based zero-shot model. The results show that the NLI approach\nachieves competitive results compared to the Davinci model. Furthermore, we\nconduct an in-depth investigation of the performance of supervised systems in\nthe context of cross-domain multi-label moral value detection. This involves\ntraining supervised models on different domains to explore their effectiveness\nin handling data from different sources and comparing their performance with\nthe unsupervised methods. Our contributions encompass a thorough analysis of\nboth supervised and unsupervised methodologies for cross-domain value\ndetection. We introduce the Davinci model as a state-of-the-art zero-shot\nunsupervised moral values classifier, pushing the boundaries of moral value\ndetection without the need for explicit training on labeled data. Additionally,\nwe perform a comparative evaluation of our approach with the supervised models,\nshedding light on their respective strengths and weaknesses."
  },
  {
    "arxiv_id": "2406.04089",
    "title": "On Limitation of Transformer for Learning HMMs",
    "url": "http://arxiv.org/abs/2406.04089v1",
    "abstract": "Despite the remarkable success of Transformer-based architectures in various\nsequential modeling tasks, such as natural language processing, computer\nvision, and robotics, their ability to learn basic sequential models, like\nHidden Markov Models (HMMs), is still unclear. This paper investigates the\nperformance of Transformers in learning HMMs and their variants through\nextensive experimentation and compares them to Recurrent Neural Networks\n(RNNs). We show that Transformers consistently underperform RNNs in both\ntraining speed and testing accuracy across all tested HMM models. There are\neven challenging HMM instances where Transformers struggle to learn, while RNNs\ncan successfully do so. Our experiments further reveal the relation between the\ndepth of Transformers and the longest sequence length it can effectively learn,\nbased on the types and the complexity of HMMs. To address the limitation of\ntransformers in modeling HMMs, we demonstrate that a variant of the\nChain-of-Thought (CoT), called $\\textit{block CoT}$ in the training phase, can\nhelp transformers to reduce the evaluation error and to learn longer sequences\nat a cost of increasing the training time. Finally, we complement our empirical\nfindings by theoretical results proving the expressiveness of transformers in\napproximating HMMs with logarithmic depth."
  },
  {
    "arxiv_id": "2406.04712",
    "title": "AICoderEval: Improving AI Domain Code Generation of Large Language Models",
    "url": "http://arxiv.org/abs/2406.04712v1",
    "abstract": "Automated code generation is a pivotal capability of large language models\n(LLMs). However, assessing this capability in real-world scenarios remains\nchallenging. Previous methods focus more on low-level code generation, such as\nmodel loading, instead of generating high-level codes catering for real-world\ntasks, such as image-to-text, text classification, in various domains.\nTherefore, we construct AICoderEval, a dataset focused on real-world tasks in\nvarious domains based on HuggingFace, PyTorch, and TensorFlow, along with\ncomprehensive metrics for evaluation and enhancing LLMs' task-specific code\ngeneration capability. AICoderEval contains test cases and complete programs\nfor automated evaluation of these tasks, covering domains such as natural\nlanguage processing, computer vision, and multimodal learning. To facilitate\nresearch in this area, we open-source the AICoderEval dataset at\n\\url{https://huggingface.co/datasets/vixuowis/AICoderEval}. After that, we\npropose CoderGen, an agent-based framework, to help LLMs generate codes related\nto real-world tasks on the constructed AICoderEval. Moreover, we train a more\npowerful task-specific code generation model, named AICoder, which is refined\non llama-3 based on AICoderEval. Our experiments demonstrate the effectiveness\nof CoderGen in improving LLMs' task-specific code generation capability (by\n12.00\\% on pass@1 for original model and 9.50\\% on pass@1 for ReAct Agent).\nAICoder also outperforms current code generation LLMs, indicating the great\nquality of the AICoderEval benchmark."
  },
  {
    "arxiv_id": "2406.04593",
    "title": "SynAsk: Unleashing the Power of Large Language Models in Organic Synthesis",
    "url": "http://arxiv.org/abs/2406.04593v1",
    "abstract": "The field of natural language processing (NLP) has witnessed a transformative\nshift with the emergence of large language models (LLMs), revolutionizing\nvarious language tasks and applications, and the integration of LLM into\nspecialized domains enhances their capabilities for domain-specific\napplications. Notably, NLP has made significant strides in organic chemistry,\nparticularly in predicting synthetic tasks, paving the way for the development\nof LLMs tailored to the organic chemistry field. In this work, we introduce\nSynAsk, a comprehensive organic chemistry domain-specific LLM platform\ndeveloped by AIChemEco Inc. By finetuning an LLM with domain-specific data and\nintegrating it with a chain of thought approach, SynAsk seamlessly accesses our\nknowledge base and advanced chemistry tools in a question-and-answer format.\nThis includes functionalities such as a basic chemistry knowledge base,\nmolecular information retrieval, reaction performance prediction,\nretrosynthesis prediction, chemical literature acquisition, and more. This\nnovel methodology synergizes fine-tuning techniques with external resource\nintegration, resulting in an organic chemistry-specific model poised to\nfacilitate research and discovery in the field. Accessible via\nhttp://synask.aichemeco.com, SynAsk represents a significant advancement in\nleveraging NLP for synthetic applications."
  },
  {
    "arxiv_id": "2406.04528",
    "title": "llmNER: (Zero|Few)-Shot Named Entity Recognition, Exploiting the Power of Large Language Models",
    "url": "http://arxiv.org/abs/2406.04528v1",
    "abstract": "Large language models (LLMs) allow us to generate high-quality human-like\ntext. One interesting task in natural language processing (NLP) is named entity\nrecognition (NER), which seeks to detect mentions of relevant information in\ndocuments. This paper presents llmNER, a Python library for implementing\nzero-shot and few-shot NER with LLMs; by providing an easy-to-use interface,\nllmNER can compose prompts, query the model, and parse the completion returned\nby the LLM. Also, the library enables the user to perform prompt engineering\nefficiently by providing a simple interface to test multiple variables. We\nvalidated our software on two NER tasks to show the library's flexibility.\nllmNER aims to push the boundaries of in-context learning research by removing\nthe barrier of the prompting and parsing steps."
  },
  {
    "arxiv_id": "2406.04501",
    "title": "FLUID-LLM: Learning Computational Fluid Dynamics with Spatiotemporal-aware Large Language Models",
    "url": "http://arxiv.org/abs/2406.04501v1",
    "abstract": "Learning computational fluid dynamics (CFD) traditionally relies on\ncomputationally intensive simulations of the Navier-Stokes equations. Recently,\nlarge language models (LLMs) have shown remarkable pattern recognition and\nreasoning abilities in natural language processing (NLP) and computer vision\n(CV). However, these models struggle with the complex geometries inherent in\nfluid dynamics. We introduce FLUID-LLM, a novel framework combining pre-trained\nLLMs with spatiotemporal-aware encoding to predict unsteady fluid dynamics. Our\napproach leverages the temporal autoregressive abilities of LLMs alongside\nspatial-aware layers, bridging the gap between previous CFD prediction methods.\nEvaluations on standard benchmarks reveal significant performance improvements\nacross various fluid datasets. Our results demonstrate that FLUID-LLM\neffectively integrates spatiotemporal information into pre-trained LLMs,\nenhancing CFD task performance."
  },
  {
    "arxiv_id": "2406.04478",
    "title": "PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning",
    "url": "http://arxiv.org/abs/2406.04478v1",
    "abstract": "Pre-trained language models (PLMs) have attracted enormous attention over the\npast few years with their unparalleled performances. Meanwhile, the soaring\ncost to train PLMs as well as their amazing generalizability have jointly\ncontributed to few-shot fine-tuning and prompting as the most popular training\nparadigms for natural language processing (NLP) models. Nevertheless, existing\nstudies have shown that these NLP models can be backdoored such that model\nbehavior is manipulated when trigger tokens are presented. In this paper, we\npropose PromptFix, a novel backdoor mitigation strategy for NLP models via\nadversarial prompt-tuning in few-shot settings. Unlike existing NLP backdoor\nremoval methods, which rely on accurate trigger inversion and subsequent model\nfine-tuning, PromptFix keeps the model parameters intact and only utilizes two\nextra sets of soft tokens which approximate the trigger and counteract it\nrespectively. The use of soft tokens and adversarial optimization eliminates\nthe need to enumerate possible backdoor configurations and enables an adaptive\nbalance between trigger finding and preservation of performance. Experiments\nwith various backdoor attacks validate the effectiveness of the proposed method\nand the performances when domain shift is present further shows PromptFix's\napplicability to models pretrained on unknown data source which is the common\ncase in prompt tuning scenarios."
  },
  {
    "arxiv_id": "2406.04438",
    "title": "TexIm FAST: Text-to-Image Representation for Semantic Similarity Evaluation using Transformers",
    "url": "http://arxiv.org/abs/2406.04438v1",
    "abstract": "One of the principal objectives of Natural Language Processing (NLP) is to\ngenerate meaningful representations from text. Improving the informativeness of\nthe representations has led to a tremendous rise in the dimensionality and the\nmemory footprint. It leads to a cascading effect amplifying the complexity of\nthe downstream model by increasing its parameters. The available techniques\ncannot be applied to cross-modal applications such as text-to-image. To\nameliorate these issues, a novel Text-to-Image methodology for generating\nfixed-length representations through a self-supervised Variational Auto-Encoder\n(VAE) for semantic evaluation applying transformers (TexIm FAST) has been\nproposed in this paper. The pictorial representations allow oblivious inference\nwhile retaining the linguistic intricacies, and are potent in cross-modal\napplications. TexIm FAST deals with variable-length sequences and generates\nfixed-length representations with over 75% reduced memory footprint. It\nenhances the efficiency of the models for downstream tasks by reducing its\nparameters. The efficacy of TexIm FAST has been extensively analyzed for the\ntask of Semantic Textual Similarity (STS) upon the MSRPC, CNN/ Daily Mail, and\nXSum data-sets. The results demonstrate 6% improvement in accuracy compared to\nthe baseline and showcase its exceptional ability to compare disparate length\nsequences such as a text with its summary."
  },
  {
    "arxiv_id": "2406.06486",
    "title": "Continuum Attention for Neural Operators",
    "url": "http://arxiv.org/abs/2406.06486v1",
    "abstract": "Transformers, and the attention mechanism in particular, have become\nubiquitous in machine learning. Their success in modeling nonlocal, long-range\ncorrelations has led to their widespread adoption in natural language\nprocessing, computer vision, and time-series problems. Neural operators, which\nmap spaces of functions into spaces of functions, are necessarily both\nnonlinear and nonlocal if they are universal; it is thus natural to ask whether\nthe attention mechanism can be used in the design of neural operators.\nMotivated by this, we study transformers in the function space setting. We\nformulate attention as a map between infinite dimensional function spaces and\nprove that the attention mechanism as implemented in practice is a Monte Carlo\nor finite difference approximation of this operator. The function space\nformulation allows for the design of transformer neural operators, a class of\narchitectures designed to learn mappings between function spaces, for which we\nprove a universal approximation result. The prohibitive cost of applying the\nattention operator to functions defined on multi-dimensional domains leads to\nthe need for more efficient attention-based architectures. For this reason we\nalso introduce a function space generalization of the patching strategy from\ncomputer vision, and introduce a class of associated neural operators.\nNumerical results, on an array of operator learning problems, demonstrate the\npromise of our approaches to function space formulations of attention and their\nuse in neural operators."
  },
  {
    "arxiv_id": "2406.06366",
    "title": "Symmetric Dot-Product Attention for Efficient Training of BERT Language Models",
    "url": "http://arxiv.org/abs/2406.06366v1",
    "abstract": "Initially introduced as a machine translation model, the Transformer\narchitecture has now become the foundation for modern deep learning\narchitecture, with applications in a wide range of fields, from computer vision\nto natural language processing. Nowadays, to tackle increasingly more complex\ntasks, Transformer-based models are stretched to enormous sizes, requiring\nincreasingly larger training datasets, and unsustainable amount of compute\nresources. The ubiquitous nature of the Transformer and its core component, the\nattention mechanism, are thus prime targets for efficiency research. In this\nwork, we propose an alternative compatibility function for the self-attention\nmechanism introduced by the Transformer architecture. This compatibility\nfunction exploits an overlap in the learned representation of the traditional\nscaled dot-product attention, leading to a symmetric with pairwise coefficient\ndot-product attention. When applied to the pre-training of BERT-like models,\nthis new symmetric attention mechanism reaches a score of 79.36 on the GLUE\nbenchmark against 78.74 for the traditional implementation, leads to a\nreduction of 6% in the number of trainable parameters, and reduces the number\nof training steps required before convergence by half."
  },
  {
    "arxiv_id": "2406.05900",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "url": "http://arxiv.org/abs/2406.05900v1",
    "abstract": "The astonishing success of Large Language Models (LLMs) in Natural Language\nProcessing (NLP) has spurred their use in many application domains beyond text\nanalysis, including wearable sensor-based Human Activity Recognition (HAR). In\nsuch scenarios, often sensor data are directly fed into an LLM along with text\ninstructions for the model to perform activity classification. Seemingly\nremarkable results have been reported for such LLM-based HAR systems when they\nare evaluated on standard benchmarks from the field. Yet, we argue, care has to\nbe taken when evaluating LLM-based HAR systems in such a traditional way. Most\ncontemporary LLMs are trained on virtually the entire (accessible) internet --\npotentially including standard HAR datasets. With that, it is not unlikely that\nLLMs actually had access to the test data used in such benchmark\nexperiments.The resulting contamination of training data would render these\nexperimental evaluations meaningless. In this paper we investigate whether LLMs\nindeed have had access to standard HAR datasets during training. We apply\nmemorization tests to LLMs, which involves instructing the models to extend\ngiven snippets of data. When comparing the LLM-generated output to the original\ndata we found a non-negligible amount of matches which suggests that the LLM\nunder investigation seems to indeed have seen wearable sensor data from the\nbenchmark datasets during training. For the Daphnet dataset in particular,\nGPT-4 is able to reproduce blocks of sensor readings. We report on our\ninvestigations and discuss potential implications on HAR research, especially\nwith regards to reporting results on experimental evaluation"
  },
  {
    "arxiv_id": "2406.05741",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "url": "http://arxiv.org/abs/2406.05741v1",
    "abstract": "Digital transformation (DX) has recently become a pressing issue for many\ncompanies as the latest digital technologies, such as artificial intelligence\nand the Internet of Things, can be easily utilized. However, devising new\nbusiness models is not easy for compa-nies, though they can improve their\noperations through digital technologies. Thus, business model design support\nmethods are needed by people who lack digital tech-nology expertise. In\ncontrast, large language models (LLMs) represented by ChatGPT and natural\nlanguage processing utilizing LLMs have been developed revolutionarily. A\nbusiness model design support system that utilizes these technologies has great\npotential. However, research on this area is scant. Accordingly, this study\nproposes an LLM-based method for comparing and analyzing similar companies from\ndifferent business do-mains as a first step toward business model design\nsupport utilizing LLMs. This method can support idea generation in digital\nbusiness model design."
  },
  {
    "arxiv_id": "2406.05587",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "url": "http://arxiv.org/abs/2406.05587v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nbut can exhibit biases and may generate toxic content. While alignment\ntechniques like Reinforcement Learning from Human Feedback (RLHF) reduce these\nissues, their impact on creativity, defined as syntactic and semantic\ndiversity, remains unexplored. We investigate the unintended consequences of\nRLHF on the creativity of LLMs through three experiments focusing on the\nLlama-2 series. Our findings reveal that aligned models exhibit lower entropy\nin token predictions, form distinct clusters in the embedding space, and\ngravitate towards \"attractor states\", indicating limited output diversity. Our\nfindings have significant implications for marketers who rely on LLMs for\ncreative tasks such as copywriting, ad creation, and customer persona\ngeneration. The trade-off between consistency and creativity in aligned models\nshould be carefully considered when selecting the appropriate model for a given\napplication. We also discuss the importance of prompt engineering in harnessing\nthe creative potential of base models."
  },
  {
    "arxiv_id": "2406.07483",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "url": "http://arxiv.org/abs/2406.07483v1",
    "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), the\nuse of Large Language Models (LLMs) for automated text annotation in social\nmedia posts has garnered significant interest. Despite the impressive\ninnovations in developing LLMs like ChatGPT, their efficacy, and accuracy as\nannotation tools are not well understood. In this paper, we analyze the\nperformance of eight open-source and proprietary LLMs for annotating the stance\nexpressed in social media posts, benchmarking their performance against human\nannotators' (i.e., crowd-sourced) judgments. Additionally, we investigate the\nconditions under which LLMs are likely to disagree with human judgment. A\nsignificant finding of our study is that the explicitness of text expressing a\nstance plays a critical role in how faithfully LLMs' stance judgments match\nhumans'. We argue that LLMs perform well when human annotators do, and when\nLLMs fail, it often corresponds to situations in which human annotators\nstruggle to reach an agreement. We conclude with recommendations for a\ncomprehensive approach that combines the precision of human expertise with the\nscalability of LLM predictions. This study highlights the importance of\nimproving the accuracy and comprehensiveness of automated stance detection,\naiming to advance these technologies for more efficient and unbiased analysis\nof social media."
  },
  {
    "arxiv_id": "2406.07287",
    "title": "Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5 Few-Shot Learning",
    "url": "http://arxiv.org/abs/2406.07287v1",
    "abstract": "Sexism in online content is a pervasive issue that necessitates effective\nclassification techniques to mitigate its harmful impact. Online platforms\noften have sexist comments and posts that create a hostile environment,\nespecially for women and minority groups. This content not only spreads harmful\nstereotypes but also causes emotional harm. Reliable methods are essential to\nfind and remove sexist content, making online spaces safer and more welcoming.\nTherefore, the sEXism Identification in Social neTworks (EXIST) challenge\naddresses this issue at CLEF 2024. This study aims to improve sexism\nidentification in bilingual contexts (English and Spanish) by leveraging\nnatural language processing models. The tasks are to determine whether a text\nis sexist and what the source intention behind it is. We fine-tuned the\nXLM-RoBERTa model and separately used GPT-3.5 with few-shot learning prompts to\nclassify sexist content. The XLM-RoBERTa model exhibited robust performance in\nhandling complex linguistic structures, while GPT-3.5's few-shot learning\ncapability allowed for rapid adaptation to new data with minimal labeled\nexamples. Our approach using XLM-RoBERTa achieved 4th place in the soft-soft\nevaluation of Task 1 (sexism identification). For Task 2 (source intention), we\nachieved 2nd place in the soft-soft evaluation."
  },
  {
    "arxiv_id": "2406.07259",
    "title": "Scientific Computing with Large Language Models",
    "url": "http://arxiv.org/abs/2406.07259v1",
    "abstract": "We provide an overview of the emergence of large language models for\nscientific computing applications. We highlight use cases that involve natural\nlanguage processing of scientific documents and specialized languages designed\nto describe physical systems. For the former, chatbot style applications appear\nin medicine, mathematics and physics and can be used iteratively with domain\nexperts for problem solving. We also review specialized languages within\nmolecular biology, the languages of molecules, proteins, and DNA where language\nmodels are being used to predict properties and even create novel physical\nsystems at much faster rates than traditional computing methods."
  },
  {
    "arxiv_id": "2406.07177",
    "title": "TernaryLLM: Ternarized Large Language Model",
    "url": "http://arxiv.org/abs/2406.07177v1",
    "abstract": "Large language models (LLMs) have achieved remarkable performance on Natural\nLanguage Processing (NLP) tasks, but they are hindered by high computational\ncosts and memory requirements. Ternarization, an extreme form of quantization,\noffers a solution by reducing memory usage and enabling energy-efficient\nfloating-point additions. However, applying ternarization to LLMs faces\nchallenges stemming from outliers in both weights and activations. In this\nwork, observing asymmetric outliers and non-zero means in weights, we introduce\nDual Learnable Ternarization (DLT), which enables both scales and shifts to be\nlearnable. We also propose Outlier-Friendly Feature Knowledge Distillation\n(OFF) to recover the information lost in extremely low-bit quantization. The\nproposed OFF can incorporate semantic information and is insensitive to\noutliers. At the core of OFF is maximizing the mutual information between\nfeatures in ternarized and floating-point models using cosine similarity.\nExtensive experiments demonstrate that our TernaryLLM surpasses previous\nlow-bit quantization methods on the standard text generation and zero-shot\nbenchmarks for different LLM families. Specifically, for one of the most\npowerful open-source models, LLaMA-3, our approach (W1.58A16) outperforms the\nprevious state-of-the-art method (W2A16) by 5.8 in terms of perplexity on C4\nand by 8.2% in terms of average accuracy on zero-shot tasks."
  },
  {
    "arxiv_id": "2406.07145",
    "title": "Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models",
    "url": "http://arxiv.org/abs/2406.07145v1",
    "abstract": "In large deep neural networks that seem to perform surprisingly well on many\ntasks, we also observe a few failures related to accuracy, social biases, and\nalignment with human values, among others. Therefore, before deploying these\nmodels, it is crucial to characterize this failure landscape for engineers to\ndebug and legislative bodies to audit models. Nevertheless, it is infeasible to\nexhaustively test for all possible combinations of factors that could lead to a\nmodel's failure. In this paper, we introduce a post-hoc method that utilizes\n\\emph{deep reinforcement learning} to explore and construct the landscape of\nfailure modes in pre-trained discriminative and generative models. With the aid\nof limited human feedback, we then demonstrate how to restructure the failure\nlandscape to be more desirable by moving away from the discovered failure\nmodes. We empirically show the effectiveness of the proposed method across\ncommon Computer Vision, Natural Language Processing, and Vision-Language tasks."
  },
  {
    "arxiv_id": "2406.07056",
    "title": "Effectively Compress KV Heads for LLM",
    "url": "http://arxiv.org/abs/2406.07056v1",
    "abstract": "The advent of pre-trained large language models (LLMs) has revolutionized\nvarious natural language processing tasks. These models predominantly employ an\nauto-regressive decoding mechanism that utilizes Key-Value (KV) caches to\neliminate redundant calculations for previous tokens. Nevertheless, as context\nlengths and batch sizes increase, the linear expansion in memory footprint of\nKV caches becomes a key bottleneck of LLM deployment, which decreases\ngeneration speeds significantly. To mitigate this issue, previous techniques\nlike multi-query attention (MQA) and grouped-query attention (GQA) have been\ndeveloped, in order to reduce KV heads to accelerate inference with comparable\naccuracy to multi-head attention (MHA). Despite their effectiveness, existing\nstrategies for compressing MHA often overlook the intrinsic properties of the\nKV caches. In this work, we explore the low-rank characteristics of the KV\ncaches and propose a novel approach for compressing KV heads. In particular, we\ncarefully optimize the MHA-to-GQA transformation to minimize compression error,\nand to remain compatible with rotary position embeddings (RoPE), we also\nintroduce specialized strategies for key caches with RoPE. We demonstrate that\nour method can compress half or even three-quarters of KV heads while\nmaintaining performance comparable to the original LLMs, which presents a\npromising direction for more efficient LLM deployment in resource-constrained\nenvironments."
  },
  {
    "arxiv_id": "2406.08434",
    "title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
    "url": "http://arxiv.org/abs/2406.08434v1",
    "abstract": "Large language models (LLMs) have exhibited remarkable performance in various\nnatural language processing tasks. Techniques like instruction tuning have\neffectively enhanced the proficiency of LLMs in the downstream task of machine\ntranslation. However, the existing approaches fail to yield satisfactory\ntranslation outputs that match the quality of supervised neural machine\ntranslation (NMT) systems. One plausible explanation for this discrepancy is\nthat the straightforward prompts employed in these methodologies are unable to\nfully exploit the acquired instruction-following capabilities. To this end, we\npropose the TasTe framework, which stands for translating through\nself-reflection. The self-reflection process includes two stages of inference.\nIn the first stage, LLMs are instructed to generate preliminary translations\nand conduct self-assessments on these translations simultaneously. In the\nsecond stage, LLMs are tasked to refine these preliminary translations\naccording to the evaluation results. The evaluation results in four language\ndirections on the WMT22 benchmark reveal the effectiveness of our approach\ncompared to existing methods. Our work presents a promising approach to unleash\nthe potential of LLMs and enhance their capabilities in MT. The codes and\ndatasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT."
  },
  {
    "arxiv_id": "2406.08413",
    "title": "Memory Is All You Need: An Overview of Compute-in-Memory Architectures for Accelerating Large Language Model Inference",
    "url": "http://arxiv.org/abs/2406.08413v1",
    "abstract": "Large language models (LLMs) have recently transformed natural language\nprocessing, enabling machines to generate human-like text and engage in\nmeaningful conversations. This development necessitates speed, efficiency, and\naccessibility in LLM inference as the computational and memory requirements of\nthese systems grow exponentially. Meanwhile, advancements in computing and\nmemory capabilities are lagging behind, exacerbated by the discontinuation of\nMoore's law. With LLMs exceeding the capacity of single GPUs, they require\ncomplex, expert-level configurations for parallel processing. Memory accesses\nbecome significantly more expensive than computation, posing a challenge for\nefficient scaling, known as the memory wall. Here, compute-in-memory (CIM)\ntechnologies offer a promising solution for accelerating AI inference by\ndirectly performing analog computations in memory, potentially reducing latency\nand power consumption. By closely integrating memory and compute elements, CIM\neliminates the von Neumann bottleneck, reducing data movement and improving\nenergy efficiency. This survey paper provides an overview and analysis of\ntransformer-based models, reviewing various CIM architectures and exploring how\nthey can address the imminent challenges of modern AI computing systems. We\ndiscuss transformer-related operators and their hardware acceleration schemes\nand highlight challenges, trends, and insights in corresponding CIM designs."
  },
  {
    "arxiv_id": "2406.08272",
    "title": "The Importance of Positional Encoding Initialization in Transformers for Relational Reasoning",
    "url": "http://arxiv.org/abs/2406.08272v1",
    "abstract": "The attention mechanism is central to the transformer's ability to capture\ncomplex dependencies between tokens of an input sequence. Key to the successful\napplication of the attention mechanism in transformers is its choice of\npositional encoding (PE). The PE provides essential information that\ndistinguishes the position and order amongst tokens in a sequence. Most prior\ninvestigations of PE effects on generalization were tailored to 1D input\nsequences, such as those presented in natural language, where adjacent tokens\n(e.g., words) are highly related. In contrast, many real world tasks involve\ndatasets with highly non-trivial positional arrangements, such as datasets\norganized in multiple spatial dimensions, or datasets for which ground truth\npositions are not known, such as in biological data. Here we study the\nimportance of learning accurate PE for problems which rely on a non-trivial\narrangement of input tokens. Critically, we find that the choice of\ninitialization of a learnable PE greatly influences its ability to learn\naccurate PEs that lead to enhanced generalization. We empirically demonstrate\nour findings in three experiments: 1) A 2D relational reasoning task; 2) A\nnonlinear stochastic network simulation; 3) A real world 3D neuroscience\ndataset, applying interpretability analyses to verify the learning of accurate\nPEs. Overall, we find that a learned PE initialized from a small-norm\ndistribution can 1) uncover interpretable PEs that mirror ground truth\npositions in multiple dimensions, and 2) lead to improved downstream\ngeneralization in empirical evaluations. Importantly, choosing an ill-suited PE\ncan be detrimental to both model interpretability and generalization. Together,\nour results illustrate the feasibility of learning identifiable and\ninterpretable PEs for enhanced generalization."
  },
  {
    "arxiv_id": "2406.08218",
    "title": "Figuratively Speaking: Authorship Attribution via Multi-Task Figurative Language Modeling",
    "url": "http://arxiv.org/abs/2406.08218v1",
    "abstract": "The identification of Figurative Language (FL) features in text is crucial\nfor various Natural Language Processing (NLP) tasks, where understanding of the\nauthor's intended meaning and its nuances is key for successful communication.\nAt the same time, the use of a specific blend of various FL forms most\naccurately reflects a writer's style, rather than the use of any single\nconstruct, such as just metaphors or irony. Thus, we postulate that FL features\ncould play an important role in Authorship Attribution (AA) tasks. We believe\nthat our is the first computational study of AA based on FL use. Accordingly,\nwe propose a Multi-task Figurative Language Model (MFLM) that learns to detect\nmultiple FL features in text at once. We demonstrate, through detailed\nevaluation across multiple test sets, that the our model tends to perform\nequally or outperform specialized binary models in FL detection. Subsequently,\nwe evaluate the predictive capability of joint FL features towards the AA task\non three datasets, observing improved AA performance through the integration of\nMFLM embeddings."
  },
  {
    "arxiv_id": "2406.07973",
    "title": "Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2406.07973v1",
    "abstract": "With the rapid development of artificial intelligence, large language models\n(LLMs) have made remarkable advancements in natural language processing. These\nmodels are trained on vast datasets to exhibit powerful language understanding\nand generation capabilities across various applications, including machine\ntranslation, chatbots, and agents. However, LLMs have revealed a variety of\nprivacy and security issues throughout their life cycle, drawing significant\nacademic and industrial attention. Moreover, the risks faced by LLMs differ\nsignificantly from those encountered by traditional language models. Given that\ncurrent surveys lack a clear taxonomy of unique threat models across diverse\nscenarios, we emphasize the unique privacy and security threats associated with\nfive specific scenarios: pre-training, fine-tuning, retrieval-augmented\ngeneration systems, deployment, and LLM-based agents. Addressing the\ncharacteristics of each risk, this survey outlines potential threats and\ncountermeasures. Research on attack and defense situations can offer feasible\nresearch directions, enabling more areas to benefit from LLMs."
  },
  {
    "arxiv_id": "2406.07922",
    "title": "Automated Information Extraction from Thyroid Operation Narrative: A Comparative Study of GPT-4 and Fine-tuned KoELECTRA",
    "url": "http://arxiv.org/abs/2406.07922v1",
    "abstract": "In the rapidly evolving field of healthcare, the integration of artificial\nintelligence (AI) has become a pivotal component in the automation of clinical\nworkflows, ushering in a new era of efficiency and accuracy. This study focuses\non the transformative capabilities of the fine-tuned KoELECTRA model in\ncomparison to the GPT-4 model, aiming to facilitate automated information\nextraction from thyroid operation narratives. The current research landscape is\ndominated by traditional methods heavily reliant on regular expressions, which\noften face challenges in processing free-style text formats containing critical\ndetails of operation records, including frozen biopsy reports. Addressing this,\nthe study leverages advanced natural language processing (NLP) techniques to\nfoster a paradigm shift towards more sophisticated data processing systems.\nThrough this comparative study, we aspire to unveil a more streamlined,\nprecise, and efficient approach to document processing in the healthcare\ndomain, potentially revolutionizing the way medical data is handled and\nanalyzed."
  },
  {
    "arxiv_id": "2406.07831",
    "title": "ALPS: Improved Optimization for Highly Sparse One-Shot Pruning for Large Language Models",
    "url": "http://arxiv.org/abs/2406.07831v1",
    "abstract": "The impressive performance of Large Language Models (LLMs) across various\nnatural language processing tasks comes at the cost of vast computational\nresources and storage requirements. One-shot pruning techniques offer a way to\nalleviate these burdens by removing redundant weights without the need for\nretraining. Yet, the massive scale of LLMs often forces current pruning\napproaches to rely on heuristics instead of optimization-based techniques,\npotentially resulting in suboptimal compression. In this paper, we introduce\nALPS, an optimization-based framework that tackles the pruning problem using\nthe operator splitting technique and a preconditioned conjugate gradient-based\npost-processing step. Our approach incorporates novel techniques to accelerate\nand theoretically guarantee convergence while leveraging vectorization and GPU\nparallelism for efficiency. ALPS substantially outperforms state-of-the-art\nmethods in terms of the pruning objective and perplexity reduction,\nparticularly for highly sparse models. On the OPT-30B model with 70% sparsity,\nALPS achieves a 13% reduction in test perplexity on the WikiText dataset and a\n19% improvement in zero-shot benchmark performance compared to existing\nmethods."
  },
  {
    "arxiv_id": "2406.09334",
    "title": "ProxyLM: Predicting Language Model Performance on Multilingual Tasks via Proxy Models",
    "url": "http://arxiv.org/abs/2406.09334v2",
    "abstract": "Performance prediction is a method to estimate the performance of Language\nModels (LMs) on various Natural Language Processing (NLP) tasks, mitigating\ncomputational costs associated with model capacity and data for fine-tuning.\nOur paper presents ProxyLM, a scalable task- and language-agnostic framework\ndesigned to predict the performance of LMs using proxy models. These proxy\nmodels act as surrogates, approximating the performance of the LM of interest.\nBy leveraging these proxy models, ProxyLM significantly reduces computational\noverhead in task evaluations, achieving up to a 37.08x speedup over traditional\nmethods, even with our smallest proxy models. Our results across multiple\nmultilingual NLP tasks and various robustness tests demonstrate that ProxyLM\nnot only adapts well to previously unseen languages in pre-trained LMs, but\nalso generalizes effectively across different datasets, outperforming the\nstate-of-the-art by at least 1.78x in terms of root-mean-square error (RMSE)."
  },
  {
    "arxiv_id": "2406.09264",
    "title": "Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions",
    "url": "http://arxiv.org/abs/2406.09264v1",
    "abstract": "Recent advancements in general-purpose AI have highlighted the importance of\nguiding AI systems towards the intended goals, ethical principles, and values\nof individuals and groups, a concept broadly recognized as alignment. However,\nthe lack of clarified definitions and scopes of human-AI alignment poses a\nsignificant obstacle, hampering collaborative efforts across research domains\nto achieve this alignment. In particular, ML- and philosophy-oriented alignment\nresearch often views AI alignment as a static, unidirectional process (i.e.,\naiming to ensure that AI systems' objectives match humans) rather than an\nongoing, mutual alignment problem. This perspective largely neglects the\nlong-term interaction and dynamic changes of alignment. To understand these\ngaps, we introduce a systematic review of over 400 papers published between\n2019 and January 2024, spanning multiple domains such as Human-Computer\nInteraction (HCI), Natural Language Processing (NLP), Machine Learning (ML). We\ncharacterize, define and scope human-AI alignment. From this, we present a\nconceptual framework of \"Bidirectional Human-AI Alignment\" to organize the\nliterature from a human-centered perspective. This framework encompasses both\n1) conventional studies of aligning AI to humans that ensures AI produces the\nintended outcomes determined by humans, and 2) a proposed concept of aligning\nhumans to AI, which aims to help individuals and society adjust to AI\nadvancements both cognitively and behaviorally. Additionally, we articulate the\nkey findings derived from literature analysis, including literature gaps and\ntrends, human values, and interaction techniques. To pave the way for future\nstudies, we envision three key challenges and give recommendations for future\nresearch."
  },
  {
    "arxiv_id": "2406.09206",
    "title": "Self-Training for Sample-Efficient Active Learning for Text Classification with Pre-Trained Language Models",
    "url": "http://arxiv.org/abs/2406.09206v1",
    "abstract": "Active learning is an iterative labeling process that is used to obtain a\nsmall labeled subset, despite the absence of labeled data, thereby enabling to\ntrain a model for supervised tasks such as text classification. While active\nlearning has made considerable progress in recent years due to improvements\nprovided by pre-trained language models, there is untapped potential in the\noften neglected unlabeled portion of the data, although it is available in\nconsiderably larger quantities than the usually small set of labeled data. In\nthis work, we investigate how self-training, a semi-supervised approach that\nuses a model to obtain pseudo-labels for unlabeled data, can be used to improve\nthe efficiency of active learning for text classification. Building on a\ncomprehensive reproduction of four previous self-training approaches, some of\nwhich are evaluated for the first time in the context of active learning or\nnatural language processing, we introduce HAST, a new and effective\nself-training strategy, which is evaluated on four text classification\nbenchmarks. Our results show that it outperforms the reproduced self-training\napproaches and reaches classification results comparable to previous\nexperiments for three out of four datasets, using as little as 25% of the data.\nThe code is publicly available at\nhttps://github.com/chschroeder/self-training-for-sample-efficient-active-learning ."
  },
  {
    "arxiv_id": "2406.09140",
    "title": "Investigating the translation capabilities of Large Language Models trained on parallel data only",
    "url": "http://arxiv.org/abs/2406.09140v1",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated exceptional\nproficiency across a broad spectrum of Natural Language Processing (NLP) tasks,\nincluding Machine Translation. However, previous methods predominantly relied\non iterative processes such as instruction fine-tuning or continual\npre-training, leaving unexplored the challenges of training LLMs solely on\nparallel data. In this work, we introduce PLUME (Parallel Language Model), a\ncollection of three 2B LLMs featuring varying vocabulary sizes (32k, 128k, and\n256k) trained exclusively on Catalan-centric parallel examples. These models\nperform comparably to previous encoder-decoder architectures on 16 supervised\ntranslation directions and 56 zero-shot ones. Utilizing this set of models, we\nconduct a thorough investigation into the translation capabilities of LLMs,\nprobing their performance, the impact of the different elements of the prompt,\nand their cross-lingual representation space."
  },
  {
    "arxiv_id": "2406.08754",
    "title": "StructuralSleight: Automated Jailbreak Attacks on Large Language Models Utilizing Uncommon Text-Encoded Structure",
    "url": "http://arxiv.org/abs/2406.08754v1",
    "abstract": "Large Language Models (LLMs) are widely used in natural language processing\nbut face the risk of jailbreak attacks that maliciously induce them to generate\nharmful content. Existing jailbreak attacks, including character-level and\ncontext-level attacks, mainly focus on the prompt of plain text without\nspecifically exploring the significant influence of its structure. In this\npaper, we focus on studying how the prompt structure contributes to the\njailbreak attack. We introduce a novel structure-level attack method based on\nlong-tailed structures, which we refer to as Uncommon Text-Organization\nStructures (UTOS). We extensively study 12 UTOS templates and 6 obfuscation\nmethods to build an effective automated jailbreak tool named StructuralSleight\nthat contains three escalating attack strategies: Structural Attack, Structural\nand Character/Context Obfuscation Attack, and Fully Obfuscated Structural\nAttack. Extensive experiments on existing LLMs show that StructuralSleight\nsignificantly outperforms the baseline methods. In particular, the attack\nsuccess rate reaches 94.62\\% on GPT-4o, which has not been addressed by\nstate-of-the-art techniques."
  },
  {
    "arxiv_id": "2406.11683",
    "title": "HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing",
    "url": "http://arxiv.org/abs/2406.11683v1",
    "abstract": "Generative AI has demonstrated unprecedented creativity in the field of\ncomputer vision, yet such phenomena have not been observed in natural language\nprocessing. In particular, large language models (LLMs) can hardly produce\nwritten works at the level of human experts due to the extremely high\ncomplexity of literature writing. In this paper, we present HoLLMwood, an\nautomated framework for unleashing the creativity of LLMs and exploring their\npotential in screenwriting, which is a highly demanding task. Mimicking the\nhuman creative process, we assign LLMs to different roles involved in the\nreal-world scenario. In addition to the common practice of treating LLMs as\n${Writer}$, we also apply LLMs as ${Editor}$, who is responsible for providing\nfeedback and revision advice to ${Writer}$. Besides, to enrich the characters\nand deepen the plots, we introduce a role-playing mechanism and adopt LLMs as\n${Actors}$ that can communicate and interact with each other. Evaluations on\nautomatically generated screenplays show that HoLLMwood substantially\noutperforms strong baselines in terms of coherence, relevance, interestingness\nand overall quality."
  },
  {
    "arxiv_id": "2406.11651",
    "title": "A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4",
    "url": "http://arxiv.org/abs/2406.11651v1",
    "abstract": "Dialogue state tracking (DST) is evaluated by exact matching methods, which\nrely on large amounts of labeled data and ignore semantic consistency, leading\nto over-evaluation. Currently, leveraging large language models (LLM) in\nevaluating natural language processing tasks has achieved promising results.\nHowever, using LLM for DST evaluation is still under explored. In this paper,\nwe propose a two-dimensional zero-shot evaluation method for DST using GPT-4,\nwhich divides the evaluation into two dimensions: accuracy and completeness.\nFurthermore, we also design two manual reasoning paths in prompting to further\nimprove the accuracy of evaluation. Experimental results show that our method\nachieves better performance compared to the baselines, and is consistent with\ntraditional exact matching based methods."
  },
  {
    "arxiv_id": "2406.11514",
    "title": "Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs",
    "url": "http://arxiv.org/abs/2406.11514v1",
    "abstract": "Large Language Models (LLMs) excel in various natural language processing\ntasks but struggle with hallucination issues. Existing solutions have\nconsidered utilizing LLMs' inherent reasoning abilities to alleviate\nhallucination, such as self-correction and diverse sampling methods. However,\nthese methods often overtrust LLMs' initial answers due to inherent biases. The\nkey to alleviating this issue lies in overriding LLMs' inherent biases for\nanswer inspection. To this end, we propose a CounterFactual Multi-Agent Debate\n(CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent\nbiases by compelling LLMs to generate justifications for a predetermined\nanswer's correctness. The LLMs with different predetermined stances are engaged\nwith a skeptical critic for counterfactual debate on the rationality of\ngenerated justifications. Finally, the debate process is evaluated by a\nthird-party judge to determine the final answer. Extensive experiments on four\ndatasets of three tasks demonstrate the superiority of CFMAD over existing\nmethods."
  },
  {
    "arxiv_id": "2406.11424",
    "title": "Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems: A Comparative Study of Performance and Scalability",
    "url": "http://arxiv.org/abs/2406.11424v1",
    "abstract": "This paper presents an analysis of open-source large language models (LLMs)\nand their application in Retrieval-Augmented Generation (RAG) tasks, specific\nfor enterprise-specific data sets scraped from their websites. With the\nincreasing reliance on LLMs in natural language processing, it is crucial to\nevaluate their performance, accessibility, and integration within specific\norganizational contexts. This study examines various open-source LLMs, explores\ntheir integration into RAG frameworks using enterprise-specific data, and\nassesses the performance of different open-source embeddings in enhancing the\nretrieval and generation process. Our findings indicate that open-source LLMs,\ncombined with effective embedding techniques, can significantly improve the\naccuracy and efficiency of RAG systems, offering a viable alternative to\nproprietary solutions for enterprises."
  },
  {
    "arxiv_id": "2406.11274",
    "title": "Skip-Layer Attention: Bridging Abstract and Detailed Dependencies in Transformers",
    "url": "http://arxiv.org/abs/2406.11274v1",
    "abstract": "The Transformer architecture has significantly advanced deep learning,\nparticularly in natural language processing, by effectively managing long-range\ndependencies. However, as the demand for understanding complex relationships\ngrows, refining the Transformer's architecture becomes critical. This paper\nintroduces Skip-Layer Attention (SLA) to enhance Transformer models by enabling\ndirect attention between non-adjacent layers. This method improves the model's\nability to capture dependencies between high-level abstract features and\nlow-level details. By facilitating direct attention between these diverse\nfeature levels, our approach overcomes the limitations of current Transformers,\nwhich often rely on suboptimal intra-layer attention. Our implementation\nextends the Transformer's functionality by enabling queries in a given layer to\ninteract with keys and values from both the current layer and one preceding\nlayer, thus enhancing the diversity of multi-head attention without additional\ncomputational burden. Extensive experiments demonstrate that our enhanced\nTransformer model achieves superior performance in language modeling tasks,\nhighlighting the effectiveness of our skip-layer attention mechanism."
  },
  {
    "arxiv_id": "2406.12742",
    "title": "Benchmarking Multi-Image Understanding in Vision and Language Models: Perception, Knowledge, Reasoning, and Multi-Hop Reasoning",
    "url": "http://arxiv.org/abs/2406.12742v1",
    "abstract": "The advancement of large language models (LLMs) has significantly broadened\nthe scope of applications in natural language processing, with multi-modal LLMs\nextending these capabilities to integrate and interpret visual data. However,\nexisting benchmarks for visual language models (VLMs) predominantly focus on\nsingle-image inputs, neglecting the crucial aspect of multi-image\nunderstanding. In this paper, we introduce a Multi-Image Relational Benchmark\nMIRB, designed to evaluate VLMs' ability to compare, analyze, and reason across\nmultiple images. Our benchmark encompasses four categories: perception, visual\nworld knowledge, reasoning, and multi-hop reasoning. Through a comprehensive\nevaluation of a wide range of open-source and closed-source models, we\ndemonstrate that while open-source VLMs were shown to approach the performance\nof GPT-4V in single-image tasks, a significant performance gap remains in\nmulti-image reasoning tasks. Our findings also reveal that even the\nstate-of-the-art GPT-4V model struggles with our benchmark, underscoring the\nneed for further research and development in this area. We believe our\ncontribution of MIRB could serve as a testbed for developing the\nnext-generation multi-modal models."
  },
  {
    "arxiv_id": "2406.12399",
    "title": "QueerBench: Quantifying Discrimination in Language Models Toward Queer Identities",
    "url": "http://arxiv.org/abs/2406.12399v1",
    "abstract": "With the increasing role of Natural Language Processing (NLP) in various\napplications, challenges concerning bias and stereotype perpetuation are\naccentuated, which often leads to hate speech and harm. Despite existing\nstudies on sexism and misogyny, issues like homophobia and transphobia remain\nunderexplored and often adopt binary perspectives, putting the safety of\nLGBTQIA+ individuals at high risk in online spaces. In this paper, we assess\nthe potential harm caused by sentence completions generated by English large\nlanguage models (LLMs) concerning LGBTQIA+ individuals. This is achieved using\nQueerBench, our new assessment framework, which employs a template-based\napproach and a Masked Language Modeling (MLM) task. The analysis indicates that\nlarge language models tend to exhibit discriminatory behaviour more frequently\ntowards individuals within the LGBTQIA+ community, reaching a difference gap of\n7.2% in the QueerBench score of harmfulness."
  },
  {
    "arxiv_id": "2406.12347",
    "title": "Interpreting Bias in Large Language Models: A Feature-Based Approach",
    "url": "http://arxiv.org/abs/2406.12347v1",
    "abstract": "Large Language Models (LLMs) such as Mistral and LLaMA have showcased\nremarkable performance across various natural language processing (NLP) tasks.\nDespite their success, these models inherit social biases from the diverse\ndatasets on which they are trained. This paper investigates the propagation of\nbiases within LLMs through a novel feature-based analytical approach. Drawing\ninspiration from causal mediation analysis, we hypothesize the evolution of\nbias-related features and validate them using interpretability techniques like\nactivation and attribution patching. Our contributions are threefold: (1) We\nintroduce and empirically validate a feature-based method for bias analysis in\nLLMs, applied to LLaMA-2-7B, LLaMA-3-8B, and Mistral-7B-v0.3 with templates\nfrom a professions dataset. (2) We extend our method to another form of gender\nbias, demonstrating its generalizability. (3) We differentiate the roles of\nMLPs and attention heads in bias propagation and implement targeted debiasing\nusing a counterfactual dataset. Our findings reveal the complex nature of bias\nin LLMs and emphasize the necessity for tailored debiasing strategies, offering\na deeper understanding of bias mechanisms and pathways for effective\nmitigation."
  },
  {
    "arxiv_id": "2406.12311",
    "title": "Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models",
    "url": "http://arxiv.org/abs/2406.12311v1",
    "abstract": "Binarization, which converts weight parameters to binary values, has emerged\nas an effective strategy to reduce the size of large language models (LLMs).\nHowever, typical binarization techniques significantly diminish linguistic\neffectiveness of LLMs. To address this issue, we introduce a novel binarization\ntechnique called Mixture of Scales (BinaryMoS). Unlike conventional methods,\nBinaryMoS employs multiple scaling experts for binary weights, dynamically\nmerging these experts for each token to adaptively generate scaling factors.\nThis token-adaptive approach boosts the representational power of binarized\nLLMs by enabling contextual adjustments to the values of binary weights.\nMoreover, because this adaptive process only involves the scaling factors\nrather than the entire weight matrix, BinaryMoS maintains compression\nefficiency similar to traditional static binarization methods. Our experimental\nresults reveal that BinaryMoS surpasses conventional binarization techniques in\nvarious natural language processing tasks and even outperforms 2-bit\nquantization methods, all while maintaining similar model size to static\nbinarization techniques."
  },
  {
    "arxiv_id": "2406.12230",
    "title": "MCSD: An Efficient Language Model with Diverse Fusion",
    "url": "http://arxiv.org/abs/2406.12230v1",
    "abstract": "Transformers excel in Natural Language Processing (NLP) due to their prowess\nin capturing long-term dependencies but suffer from exponential resource\nconsumption with increasing sequence lengths. To address these challenges, we\npropose MCSD model, an efficient language model with linear scaling and fast\ninference speed. MCSD model leverages diverse feature fusion, primarily through\nthe multi-channel slope and decay (MCSD) block, to robustly represent features.\nThis block comprises slope and decay sections that extract features across\ndiverse temporal receptive fields, facilitating capture of both local and\nglobal information. In addition, MCSD block conducts element-wise fusion of\ndiverse features to further enhance the delicate feature extraction capability.\nFor inference, we formulate the inference process into a recurrent\nrepresentation, slashing space complexity to $O(1)$ and time complexity to\n$O(N)$ respectively. Our experiments show that MCSD attains higher throughput\nand lower GPU memory consumption compared to Transformers, while maintaining\ncomparable performance to larger-scale language learning models on benchmark\ntests. These attributes position MCSD as a promising base for edge deployment\nand embodied intelligence."
  },
  {
    "arxiv_id": "2406.12213",
    "title": "LLM-Oracle Machines",
    "url": "http://arxiv.org/abs/2406.12213v1",
    "abstract": "We introduce the concept of AI-oracle machines for intelligent computing and\noutline several applications to demonstrate their potential. Following this, we\nadvocate for the development of a comprehensive platform to streamline the\nimplementation of AI-oracle machines."
  },
  {
    "arxiv_id": "2406.12109",
    "title": "Can LLMs Learn Macroeconomic Narratives from Social Media?",
    "url": "http://arxiv.org/abs/2406.12109v1",
    "abstract": "This study empirically tests the $\\textit{Narrative Economics}$ hypothesis,\nwhich posits that narratives (ideas that are spread virally and affect public\nbeliefs) can influence economic fluctuations. We introduce two curated datasets\ncontaining posts from X (formerly Twitter) which capture economy-related\nnarratives (Data will be shared upon paper acceptance). Employing Natural\nLanguage Processing (NLP) methods, we extract and summarize narratives from the\ntweets. We test their predictive power for $\\textit{macroeconomic}$ forecasting\nby incorporating the tweets' or the extracted narratives' representations in\ndownstream financial prediction tasks. Our work highlights the challenges in\nimproving macroeconomic models with narrative data, paving the way for the\nresearch community to realistically address this important challenge. From a\nscientific perspective, our investigation offers valuable insights and NLP\ntools for narrative extraction and summarization using Large Language Models\n(LLMs), contributing to future research on the role of narratives in economics."
  },
  {
    "arxiv_id": "2406.14549",
    "title": "Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Large Language Models",
    "url": "http://arxiv.org/abs/2406.14549v1",
    "abstract": "Frontier AI systems are making transformative impacts across society, but\nsuch benefits are not without costs: models trained on web-scale datasets\ncontaining personal and private data raise profound concerns about data privacy\nand security. Language models are trained on extensive corpora including\npotentially sensitive or proprietary information, and the risk of data leakage\n- where the model response reveals pieces of such information - remains\ninadequately understood. Prior work has investigated what factors drive\nmemorization and have identified that sequence complexity and the number of\nrepetitions drive memorization. Here, we focus on the evolution of memorization\nover training. We begin by reproducing findings that the probability of\nmemorizing a sequence scales logarithmically with the number of times it is\npresent in the data. We next show that sequences which are apparently not\nmemorized after the first encounter can be \"uncovered\" throughout the course of\ntraining even without subsequent encounters, a phenomenon we term \"latent\nmemorization\". The presence of latent memorization presents a challenge for\ndata privacy as memorized sequences may be hidden at the final checkpoint of\nthe model but remain easily recoverable. To this end, we develop a diagnostic\ntest relying on the cross entropy loss to uncover latent memorized sequences\nwith high accuracy."
  },
  {
    "arxiv_id": "2406.14213",
    "title": "Complexity of Symbolic Representation in Working Memory of Transformer Correlates with the Complexity of a Task",
    "url": "http://arxiv.org/abs/2406.14213v1",
    "abstract": "Even though Transformers are extensively used for Natural Language Processing\ntasks, especially for machine translation, they lack an explicit memory to\nstore key concepts of processed texts. This paper explores the properties of\nthe content of symbolic working memory added to the Transformer model decoder.\nSuch working memory enhances the quality of model predictions in machine\ntranslation task and works as a neural-symbolic representation of information\nthat is important for the model to make correct translations. The study of\nmemory content revealed that translated text keywords are stored in the working\nmemory, pointing to the relevance of memory content to the processed text.\nAlso, the diversity of tokens and parts of speech stored in memory correlates\nwith the complexity of the corpora for machine translation task."
  },
  {
    "arxiv_id": "2406.14171",
    "title": "Ranking LLMs by compression",
    "url": "http://arxiv.org/abs/2406.14171v1",
    "abstract": "We conceptualize the process of understanding as information compression, and\npropose a method for ranking large language models (LLMs) based on lossless\ndata compression. We demonstrate the equivalence of compression length under\narithmetic coding with cumulative negative log probabilities when using a large\nlanguage model as a prior, that is, the pre-training phase of the model is\nessentially the process of learning the optimal coding length. At the same\ntime, the evaluation metric compression ratio can be obtained without actual\ncompression, which greatly saves overhead. In this paper, we use five large\nlanguage models as priors for compression, then compare their performance on\nchallenging natural language processing tasks, including sentence completion,\nquestion answering, and coreference resolution. Experimental results show that\ncompression ratio and model performance are positively correlated, so it can be\nused as a general metric to evaluate large language models."
  },
  {
    "arxiv_id": "2406.14048",
    "title": "Prompt Injection Attacks in Defended Systems",
    "url": "http://arxiv.org/abs/2406.14048v1",
    "abstract": "Large language models play a crucial role in modern natural language\nprocessing technologies. However, their extensive use also introduces potential\nsecurity risks, such as the possibility of black-box attacks. These attacks can\nembed hidden malicious features into the model, leading to adverse consequences\nduring its deployment.\n  This paper investigates methods for black-box attacks on large language\nmodels with a three-tiered defense mechanism. It analyzes the challenges and\nsignificance of these attacks, highlighting their potential implications for\nlanguage processing system security. Existing attack and defense methods are\nexamined, evaluating their effectiveness and applicability across various\nscenarios.\n  Special attention is given to the detection algorithm for black-box attacks,\nidentifying hazardous vulnerabilities in language models and retrieving\nsensitive information. This research presents a methodology for vulnerability\ndetection and the development of defensive strategies against black-box attacks\non large language models."
  },
  {
    "arxiv_id": "2406.13893",
    "title": "Open Generative Large Language Models for Galician",
    "url": "http://arxiv.org/abs/2406.13893v1",
    "abstract": "Large language models (LLMs) have transformed natural language processing.\nYet, their predominantly English-centric training has led to biases and\nperformance disparities across languages. This imbalance marginalizes\nminoritized languages, making equitable access to NLP technologies more\ndifficult for languages with lower resources, such as Galician. We present the\nfirst two generative LLMs focused on Galician to bridge this gap. These models,\nfreely available as open-source resources, were trained using a GPT\narchitecture with 1.3B parameters on a corpus of 2.1B words. Leveraging\ncontinual pretraining, we adapt to Galician two existing LLMs trained on larger\ncorpora, thus mitigating the data constraints that would arise if the training\nwere performed from scratch. The models were evaluated using human judgments\nand task-based datasets from standardized benchmarks. These evaluations reveal\na promising performance, underscoring the importance of linguistic diversity in\ngenerative models."
  },
  {
    "arxiv_id": "2406.15275",
    "title": "Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model",
    "url": "http://arxiv.org/abs/2406.15275v1",
    "abstract": "Language models' ability to extrapolate learned behaviors to novel, more\ncomplex environments beyond their training scope is highly unknown. This study\nintroduces a path planning task in a textualized Gridworld to probe language\nmodels' extrapolation capabilities. We show that conventional approaches,\nincluding next token prediction and Chain of Thought (CoT) finetuning, fail to\nextrapolate in larger, unseen environments. Inspired by human cognition and\ndual process theory, we propose cognitive maps for path planning, a novel CoT\nframework that simulates humanlike mental representations. Our experiments show\nthat cognitive maps not only enhance extrapolation to unseen environments but\nalso exhibit humanlike characteristics through structured mental simulation and\nrapid adaptation. Our finding that these cognitive maps require specialized\ntraining schemes and cannot be induced through simple prompting opens up\nimportant questions about developing general-purpose cognitive maps in language\nmodels. Our comparison with exploration-based methods further illuminates the\ncomplementary strengths of offline planning and online exploration."
  },
  {
    "arxiv_id": "2406.15032",
    "title": "GiusBERTo: A Legal Language Model for Personal Data De-identification in Italian Court of Auditors Decisions",
    "url": "http://arxiv.org/abs/2406.15032v1",
    "abstract": "Recent advances in Natural Language Processing have demonstrated the\neffectiveness of pretrained language models like BERT for a variety of\ndownstream tasks. We present GiusBERTo, the first BERT-based model specialized\nfor anonymizing personal data in Italian legal documents. GiusBERTo is trained\non a large dataset of Court of Auditors decisions to recognize entities to\nanonymize, including names, dates, locations, while retaining contextual\nrelevance. We evaluate GiusBERTo on a held-out test set and achieve 97%\ntoken-level accuracy. GiusBERTo provides the Italian legal community with an\naccurate and tailored BERT model for de-identification, balancing privacy and\ndata protection."
  },
  {
    "arxiv_id": "2406.14969",
    "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale",
    "url": "http://arxiv.org/abs/2406.14969v1",
    "abstract": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset."
  },
  {
    "arxiv_id": "2406.14877",
    "title": "Sports Intelligence: Assessing the Sports Understanding Capabilities of Language Models through Question Answering from Text to Video",
    "url": "http://arxiv.org/abs/2406.14877v1",
    "abstract": "Understanding sports is crucial for the advancement of Natural Language\nProcessing (NLP) due to its intricate and dynamic nature. Reasoning over\ncomplex sports scenarios has posed significant challenges to current NLP\ntechnologies which require advanced cognitive capabilities. Toward addressing\nthe limitations of existing benchmarks on sports understanding in the NLP\nfield, we extensively evaluated mainstream large language models for various\nsports tasks. Our evaluation spans from simple queries on basic rules and\nhistorical facts to complex, context-specific reasoning, leveraging strategies\nfrom zero-shot to few-shot learning, and chain-of-thought techniques. In\naddition to unimodal analysis, we further assessed the sports reasoning\ncapabilities of mainstream video language models to bridge the gap in\nmultimodal sports understanding benchmarking. Our findings highlighted the\ncritical challenges of sports understanding for NLP. We proposed a new\nbenchmark based on a comprehensive overview of existing sports datasets and\nprovided extensive error analysis which we hope can help identify future\nresearch priorities in this field."
  },
  {
    "arxiv_id": "2406.14757",
    "title": "A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes",
    "url": "http://arxiv.org/abs/2406.14757v1",
    "abstract": "High-throughput phenotyping, the automated mapping of patient signs and\nsymptoms to standardized ontology concepts, is essential to gaining value from\nelectronic health records (EHR) in the support of precision medicine. Despite\ntechnological advances, high-throughput phenotyping remains a challenge. This\nstudy compares three computational approaches to high-throughput phenotyping: a\nLarge Language Model (LLM) incorporating generative AI, a Natural Language\nProcessing (NLP) approach utilizing deep learning for span categorization, and\na hybrid approach combining word vectors with machine learning. The approach\nthat implemented GPT-4 (a Large Language Model) demonstrated superior\nperformance, suggesting that Large Language Models are poised to be the\npreferred method for high-throughput phenotyping of physician notes."
  },
  {
    "arxiv_id": "2406.16838",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "url": "http://arxiv.org/abs/2406.16838v1",
    "abstract": "One of the most striking findings in modern research on large language models\n(LLMs) is that scaling up compute during training leads to better results.\nHowever, less attention has been given to the benefits of scaling compute\nduring inference. This survey focuses on these inference-time approaches. We\nexplore three areas under a unified mathematical formalism: token-level\ngeneration algorithms, meta-generation algorithms, and efficient generation.\nToken-level generation algorithms, often called decoding algorithms, operate by\nsampling a single token at a time or constructing a token-level search space\nand then selecting an output. These methods typically assume access to a\nlanguage model's logits, next-token distributions, or probability scores.\nMeta-generation algorithms work on partial or full sequences, incorporating\ndomain knowledge, enabling backtracking, and integrating external information.\nEfficient generation methods aim to reduce token costs and improve the speed of\ngeneration. Our survey unifies perspectives from three research communities:\ntraditional natural language processing, modern LLMs, and machine learning\nsystems."
  },
  {
    "arxiv_id": "2406.16784",
    "title": "The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers",
    "url": "http://arxiv.org/abs/2406.16784v1",
    "abstract": "The transformer neural network architecture allows for autoregressive\nsequence-to-sequence modeling through the use of attention layers. It was\noriginally created with the application of machine translation but has\nrevolutionized natural language processing. Recently, transformers have also\nbeen applied across a wide variety of pattern recognition tasks, particularly\nin computer vision. In this literature review, we describe major advances in\ncomputer vision utilizing transformers. We then focus specifically on\nMulti-Object Tracking (MOT) and discuss how transformers are increasingly\nbecoming competitive in state-of-the-art MOT works, yet still lag behind\ntraditional deep learning methods."
  },
  {
    "arxiv_id": "2406.16758",
    "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
    "url": "http://arxiv.org/abs/2406.16758v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nand broadened their applicability across diverse commercial applications.\nHowever, the deployment of these models is constrained by high inference time\nin multilingual settings. To mitigate this challenge, this paper explores a\ntraining recipe of an assistant model in speculative decoding, which is\nleveraged to draft and-then its future tokens are verified by the target LLM.\nWe show that language-specific draft models, optimized through a targeted\npretrain-and-finetune strategy, substantially brings a speedup in inference\ntime compared to the previous methods. We validate these models across various\nlanguages in inference time, out-of-domain speedup, and GPT-4o evaluation."
  },
  {
    "arxiv_id": "2406.16722",
    "title": "Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba",
    "url": "http://arxiv.org/abs/2406.16722v1",
    "abstract": "Transformer, a deep neural network architecture, has long dominated the field\nof natural language processing and beyond. Nevertheless, the recent\nintroduction of Mamba challenges its supremacy, sparks considerable interest\namong researchers, and gives rise to a series of Mamba-based models that have\nexhibited notable potential. This survey paper orchestrates a comprehensive\ndiscussion, diving into essential research dimensions, covering: (i) the\nfunctioning of the Mamba mechanism and its foundation on the principles of\nstructured state space models; (ii) the proposed improvements and the\nintegration of Mamba with various networks, exploring its potential as a\nsubstitute for Transformers; (iii) the combination of Transformers and Mamba to\ncompensate for each other's shortcomings. We have also made efforts to\ninterpret Mamba and Transformer in the framework of kernel functions, allowing\nfor a comparison of their mathematical nature within a unified context. Our\npaper encompasses the vast majority of improvements related to Mamba to date."
  },
  {
    "arxiv_id": "2406.17633",
    "title": "Knowledge Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated Training Labels",
    "url": "http://arxiv.org/abs/2406.17633v1",
    "abstract": "Computational social science (CSS) practitioners often rely on human-labeled\ndata to fine-tune supervised text classifiers. We assess the potential for\nresearchers to augment or replace human-generated training data with surrogate\ntraining labels from generative large language models (LLMs). We introduce a\nrecommended workflow and test this LLM application by replicating 14\nclassification tasks and measuring performance. We employ a novel corpus of\nEnglish-language text classification data sets from recent CSS articles in\nhigh-impact journals. Because these data sets are stored in password-protected\narchives, our analyses are less prone to issues of contamination. For each\ntask, we compare supervised classifiers fine-tuned using GPT-4 labels against\nclassifiers fine-tuned with human annotations and against labels from GPT-4 and\nMistral-7B with few-shot in-context learning. Our findings indicate that\nsupervised classification models fine-tuned on LLM-generated labels perform\ncomparably to models fine-tuned with labels from human annotators. Fine-tuning\nmodels using LLM-generated labels can be a fast, efficient and cost-effective\nmethod of building supervised text classifiers."
  },
  {
    "arxiv_id": "2406.17324",
    "title": "Delving into the Utilisation of ChatGPT in Scientific Publications in Astronomy",
    "url": "http://arxiv.org/abs/2406.17324v1",
    "abstract": "Rapid progress in the capabilities of machine learning approaches in natural\nlanguage processing has culminated in the rise of large language models over\nthe last two years. Recent works have shown unprecedented adoption of these for\nacademic writing, especially in some fields, but their pervasiveness in\nastronomy has not been studied sufficiently. To remedy this, we extract words\nthat ChatGPT uses more often than humans when generating academic text and\nsearch a total of 1 million articles for them. This way, we assess the\nfrequency of word occurrence in published works in astronomy tracked by the\nNASA Astrophysics Data System since 2000. We then perform a statistical\nanalysis of the occurrences. We identify a list of words favoured by ChatGPT\nand find a statistically significant increase for these words against a control\ngroup in 2024, which matches the trend in other disciplines. These results\nsuggest a widespread adoption of these models in the writing of astronomy\npapers. We encourage organisations, publishers, and researchers to work\ntogether to identify ethical and pragmatic guidelines to maximise the benefits\nof these systems while maintaining scientific rigour."
  },
  {
    "arxiv_id": "2406.18239",
    "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
    "url": "http://arxiv.org/abs/2406.18239v1",
    "abstract": "Filtering and annotating textual data are routine tasks in many areas, like\nsocial media or news analytics. Automating these tasks allows to scale the\nanalyses wrt. speed and breadth of content covered and decreases the manual\neffort required. Due to technical advancements in Natural Language Processing,\nspecifically the success of large foundation models, a new tool for automating\nsuch annotation processes by using a text-to-text interface given written\nguidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing\nthem in an annotation task on German Twitter data about social and political\nEuropean crises. We compare the prompt-based results with our human annotation\nand preceding classification approaches, including Naive Bayes and a BERT-based\nfine-tuning/domain adaptation pipeline. Our results show that the prompt-based\napproach - despite being limited by local computation resources during the\nmodel selection - is comparable with the fine-tuned BERT but without any\nannotated training data. Our findings emphasize the ongoing paradigm shift in\nthe NLP landscape, i.e., the unification of downstream tasks and elimination of\nthe need for pre-labeled training data."
  },
  {
    "arxiv_id": "2406.18122",
    "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
    "url": "http://arxiv.org/abs/2406.18122v1",
    "abstract": "With the development of natural language processing (NLP), large language\nmodels (LLMs) are becoming increasingly popular. LLMs are integrating more into\neveryday life, raising public concerns about their security vulnerabilities.\nConsequently, the security of large language models is becoming critically\nimportant. Currently, the techniques for attacking and defending against LLMs\nare continuously evolving. One significant method type of attack is the\njailbreak attack, which designed to evade model safety mechanisms and induce\nthe generation of inappropriate content. Existing jailbreak attacks primarily\nrely on crafting inducement prompts for direct jailbreaks, which are less\neffective against large models with robust filtering and high comprehension\nabilities. Given the increasing demand for real-time capabilities in large\nlanguage models, real-time updates and iterations of new knowledge have become\nessential. Retrieval-Augmented Generation (RAG), an advanced technique to\ncompensate for the model's lack of new knowledge, is gradually becoming\nmainstream. As RAG enables the model to utilize external knowledge bases, it\nprovides a new avenue for jailbreak attacks.\n  In this paper, we conduct the first work to propose the concept of indirect\njailbreak and achieve Retrieval-Augmented Generation via LangChain. Building on\nthis, we further design a novel method of indirect jailbreak attack, termed\nPoisoned-LangChain (PLC), which leverages a poisoned external knowledge base to\ninteract with large language models, thereby causing the large models to\ngenerate malicious non-compliant dialogues.We tested this method on six\ndifferent large language models across three major categories of jailbreak\nissues. The experiments demonstrate that PLC successfully implemented indirect\njailbreak attacks under three different scenarios, achieving success rates of\n88.56%, 79.04%, and 82.69% respectively."
  },
  {
    "arxiv_id": "2406.18060",
    "title": "AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning",
    "url": "http://arxiv.org/abs/2406.18060v1",
    "abstract": "Fine-tuning large language models (LLMs) has achieved remarkable performance\nacross various natural language processing tasks, yet it demands more and more\nmemory as model sizes keep growing. To address this issue, the recently\nproposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs\nusing only forward passes, thereby avoiding the need for a backpropagation\ngraph. However, significant performance drops and a high risk of divergence\nhave limited their widespread adoption. In this paper, we propose the Adaptive\nZeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed\nto improve the performance and convergence of the ZO methods. To enhance\ndimension-dependent ZO estimation accuracy, we introduce a fast-forward,\nlow-parameter tensorized adapter. To tackle the frequently observed divergence\nissue in large-scale ZO fine-tuning tasks, we propose an adaptive query number\nschedule that guarantees convergence. Detailed theoretical analysis and\nextensive experimental results on Roberta-Large and Llama-2-7B models\nsubstantiate the efficacy of our AdaZeta framework in terms of accuracy, memory\nefficiency, and convergence speed."
  },
  {
    "arxiv_id": "2406.18049",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "url": "http://arxiv.org/abs/2406.18049v1",
    "abstract": "Adverse event (AE) extraction following COVID-19 vaccines from text data is\ncrucial for monitoring and analyzing the safety profiles of immunizations.\nTraditional deep learning models are adept at learning intricate feature\nrepresentations and dependencies in sequential data, but often require\nextensive labeled data. In contrast, large language models (LLMs) excel in\nunderstanding contextual information, but exhibit unstable performance on named\nentity recognition tasks, possibly due to their broad but unspecific training.\nThis study aims to evaluate the effectiveness of LLMs and traditional deep\nlearning models in AE extraction, and to assess the impact of ensembling these\nmodels on performance. In this study, we utilized reports and posts from the\nVAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal\nwas to extract three types of entities: \"vaccine\", \"shot\", and \"ae\". We\nexplored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,\nGPT-4, and Llama-2, as well as traditional deep learning models like RNN and\nBioBERT. To enhance performance, we created ensembles of the three models with\nthe best performance. For evaluation, we used strict and relaxed F1 scores to\nevaluate the performance for each entity type, and micro-average F1 was used to\nassess the overall performance. The ensemble model achieved the highest\nperformance in \"vaccine\", \"shot\", and \"ae\" with strict F1-scores of 0.878,\n0.930, and 0.925, respectively, along with a micro-average score of 0.903. In\nconclusion, this study demonstrates the effectiveness and robustness of\nensembling fine-tuned traditional deep learning models and LLMs, for extracting\nAE-related information. This study contributes to the advancement of biomedical\nnatural language processing, providing valuable insights into improving AE\nextraction from text data for pharmacovigilance and public health surveillance."
  },
  {
    "arxiv_id": "2406.18045",
    "title": "PharmGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical and Chemistry",
    "url": "http://arxiv.org/abs/2406.18045v1",
    "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP) by minimizing the need for complex feature engineering. However, the\napplication of LLMs in specialized domains like biopharmaceuticals and\nchemistry remains largely unexplored. These fields are characterized by\nintricate terminologies, specialized knowledge, and a high demand for precision\nareas where general purpose LLMs often fall short. In this study, we introduce\nPharmaGPT, a suite of domain specilized LLMs with 13 billion and 70 billion\nparameters, specifically trained on a comprehensive corpus tailored to the\nBio-Pharmaceutical and Chemical domains. Our evaluation shows that PharmaGPT\nsurpasses existing general models on specific-domain benchmarks such as NAPLEX,\ndemonstrating its exceptional capability in domain-specific tasks. Remarkably,\nthis performance is achieved with a model that has only a fraction, sometimes\njust one-tenth-of the parameters of general-purpose large models. This\nadvancement establishes a new benchmark for LLMs in the bio-pharmaceutical and\nchemical fields, addressing the existing gap in specialized language modeling.\nIt also suggests a promising path for enhanced research and development, paving\nthe way for more precise and effective NLP applications in these areas."
  },
  {
    "arxiv_id": "2406.17923",
    "title": "PAFT: A Parallel Training Paradigm for Effective LLM Fine-Tuning",
    "url": "http://arxiv.org/abs/2406.17923v1",
    "abstract": "Large language models (LLMs) have shown remarkable abilities in diverse\nnatural language processing (NLP) tasks. The LLMs generally undergo supervised\nfine-tuning (SFT) followed by preference alignment to be usable in downstream\napplications. However, this sequential training pipeline leads to alignment tax\nthat degrades the LLM performance.\n  This paper introduces PAFT, a new PArallel training paradigm for effective\nLLM Fine-Tuning, which independently performs SFT and preference alignment\n(e.g., DPO and ORPO, etc.) with the same pre-trained model on respective\ndatasets. The model produced by SFT and the model from preference alignment are\nthen merged into a final model by parameter fusing for use in downstream\napplications. This work reveals important findings that preference alignment\nlike DPO naturally results in a sparse model while SFT leads to a natural dense\nmodel which needs to be sparsified for effective model merging. This paper\nintroduces an effective interference resolution which reduces the redundancy by\nsparsifying the delta parameters. The LLM resulted from the new training\nparadigm achieved Rank #1 on the HuggingFace Open LLM Leaderboard.\nComprehensive evaluation shows the effectiveness of the parallel training\nparadigm."
  },
  {
    "arxiv_id": "2406.19358",
    "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
    "url": "http://arxiv.org/abs/2406.19358v1",
    "abstract": "Sentiment analysis serves as a pivotal component in Natural Language\nProcessing (NLP). Advancements in multilingual pre-trained models such as XLM-R\nand mT5 have contributed to the increasing interest in cross-lingual sentiment\nanalysis. The recent emergence in Large Language Models (LLM) has significantly\nadvanced general NLP tasks, however, the capability of such LLMs in\ncross-lingual sentiment analysis has not been fully studied. This work\nundertakes an empirical analysis to compare the cross-lingual transfer\ncapability of public Small Multilingual Language Models (SMLM) like XLM-R,\nagainst English-centric LLMs such as Llama-3, in the context of sentiment\nanalysis across English, Spanish, French and Chinese. Our findings reveal that\namong public models, SMLMs exhibit superior zero-shot cross-lingual performance\nrelative to LLMs. However, in few-shot cross-lingual settings, public LLMs\ndemonstrate an enhanced adaptive potential. In addition, we observe that\nproprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but\nare outpaced by public models in few-shot scenarios."
  },
  {
    "arxiv_id": "2406.19217",
    "title": "Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos",
    "url": "http://arxiv.org/abs/2406.19217v1",
    "abstract": "Despite significant advancements in robotic systems and surgical data\nscience, ensuring safe and optimal execution in robot-assisted minimally\ninvasive surgery (RMIS) remains a complex challenge. Current surgical error\ndetection methods involve two parts: identifying surgical gestures and then\ndetecting errors within each gesture clip. These methods seldom consider the\nrich contextual and semantic information inherent in surgical videos, limiting\ntheir performance due to reliance on accurate gesture identification. Motivated\nby the chain-of-thought prompting in natural language processing, this letter\npresents a novel and real-time end-to-end error detection framework,\nChain-of-Thought (COG) prompting, leveraging contextual information from\nsurgical videos. This encompasses two reasoning modules designed to mimic the\ndecision-making processes of expert surgeons. Concretely, we first design a\nGestural-Visual Reasoning module, which utilizes transformer and attention\narchitectures for gesture prompting, while the second, a Multi-Scale Temporal\nReasoning module, employs a multi-stage temporal convolutional network with\nboth slow and fast paths for temporal information extraction. We extensively\nvalidate our method on the public benchmark RMIS dataset JIGSAWS. Our method\nencapsulates the reasoning processes inherent to surgical activities enabling\nit to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,\nand 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on\naverage, demonstrating the great potential of our approach in enhancing the\nsafety and efficacy of RMIS procedures and surgical education. The code will be\navailable."
  },
  {
    "arxiv_id": "2406.18740",
    "title": "Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models",
    "url": "http://arxiv.org/abs/2406.18740v1",
    "abstract": "Large Language Models (LLMs) have been revolutionizing a myriad of natural\nlanguage processing tasks with their diverse zero-shot capabilities. Indeed,\nexisting work has shown that LLMs can be used to great effect for many tasks,\nsuch as information retrieval (IR), and passage ranking. However, current\nstate-of-the-art results heavily lean on the capabilities of the LLM being\nused. Currently, proprietary, and very large LLMs such as GPT-4 are the highest\nperforming passage re-rankers. Hence, users without the resources to leverage\ntop of the line LLMs, or ones that are closed source, are at a disadvantage. In\nthis paper, we investigate the use of a pre-filtering step before passage\nre-ranking in IR. Our experiments show that by using a small number of human\ngenerated relevance scores, coupled with LLM relevance scoring, it is\neffectively possible to filter out irrelevant passages before re-ranking. Our\nexperiments also show that this pre-filtering then allows the LLM to perform\nsignificantly better at the re-ranking task. Indeed, our results show that\nsmaller models such as Mixtral can become competitive with much larger\nproprietary models (e.g., ChatGPT and GPT-4)."
  },
  {
    "arxiv_id": "2406.19707",
    "title": "InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management",
    "url": "http://arxiv.org/abs/2406.19707v1",
    "abstract": "Transformer-based large language models (LLMs) demonstrate impressive\nperformance across various natural language processing tasks. Serving LLM\ninference for generating long contents, however, poses a challenge due to the\nenormous memory footprint of the transient state, known as the key-value (KV)\ncache, which scales with the sequence length and batch size. In this paper, we\npresent InfiniGen, a novel KV cache management framework tailored for long-text\ngeneration, which synergistically works with modern offloading-based inference\nsystems. InfiniGen leverages the key insight that a few important tokens that\nare essential for computing the subsequent attention layer in the Transformer\ncan be speculated by performing a minimal rehearsal with the inputs of the\ncurrent layer and part of the query weight and key cache of the subsequent\nlayer. This allows us to prefetch only the essential KV cache entries (without\nfetching them all), thereby mitigating the fetch overhead from the host memory\nin offloading-based LLM serving systems. Our evaluation on several\nrepresentative LLMs shows that InfiniGen improves the overall performance of a\nmodern offloading-based system by up to 3.00x compared to prior KV cache\nmanagement methods while offering substantially better model accuracy."
  },
  {
    "arxiv_id": "2406.19526",
    "title": "TocBERT: Medical Document Structure Extraction Using Bidirectional Transformers",
    "url": "http://arxiv.org/abs/2406.19526v1",
    "abstract": "Text segmentation holds paramount importance in the field of Natural Language\nProcessing (NLP). It plays an important role in several NLP downstream tasks\nlike information retrieval and document summarization. In this work, we propose\na new solution, namely TocBERT, for segmenting texts using bidirectional\ntransformers. TocBERT represents a supervised solution trained on the detection\nof titles and sub-titles from their semantic representations. This task was\nformulated as a named entity recognition (NER) problem. The solution has been\napplied on a medical text segmentation use-case where the Bio-ClinicalBERT\nmodel is fine-tuned to segment discharge summaries of the MIMIC-III dataset.\nThe performance of TocBERT has been evaluated on a human-labeled ground truth\ncorpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a\nlinear text segmentation problem and 72.8% on a hierarchical text segmentation\nproblem. It outperformed a carefully designed rule-based solution, particularly\nin distinguishing titles from subtitles."
  },
  {
    "arxiv_id": "2407.02408",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "url": "http://arxiv.org/abs/2407.02408v1",
    "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various\nnatural language processing (NLP) tasks, concerns regarding the potential\nnegative societal impacts of LLM-generated content have also arisen. To\nevaluate the biases exhibited by LLMs, researchers have recently proposed a\nvariety of datasets. However, existing bias evaluation efforts often focus on\nonly a particular type of bias and employ inconsistent evaluation metrics,\nleading to difficulties in comparison across different datasets and LLMs. To\naddress these limitations, we collect a variety of datasets designed for the\nbias evaluation of LLMs, and further propose CEB, a Compositional Evaluation\nBenchmark that covers different types of bias across different social groups\nand tasks. The curation of CEB is based on our newly proposed compositional\ntaxonomy, which characterizes each dataset from three dimensions: bias types,\nsocial groups, and tasks. By combining the three dimensions, we develop a\ncomprehensive evaluation strategy for the bias in LLMs. Our experiments\ndemonstrate that the levels of bias vary across these dimensions, thereby\nproviding guidance for the development of specific bias mitigation methods."
  },
  {
    "arxiv_id": "2407.02317",
    "title": "Soft Language Prompts for Language Transfer",
    "url": "http://arxiv.org/abs/2407.02317v1",
    "abstract": "Cross-lingual knowledge transfer, especially between high- and low-resource\nlanguages, remains challenging in natural language processing (NLP). This study\noffers insights for improving cross-lingual NLP applications through the\ncombination of parameter-efficient fine-tuning methods. We systematically\nexplore strategies for enhancing cross-lingual transfer through the\nincorporation of language-specific and task-specific adapters and soft prompts.\nWe present a detailed investigation of various combinations of these methods,\nexploring their efficiency across 16 languages, focusing on 10 mid- and\nlow-resource languages. We further present to our knowledge the first use of\nsoft prompts for language transfer, a technique we call soft language prompts.\nOur findings demonstrate that in contrast to claims of previous work, a\ncombination of language and task adapters does not always work best; instead,\ncombining a soft language prompt with a task adapter outperforms most\nconfigurations in many cases."
  },
  {
    "arxiv_id": "2407.02211",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "url": "http://arxiv.org/abs/2407.02211v1",
    "abstract": "Recent advances in fine-tuning large language models (LLMs) have greatly\nenhanced their usage in domain-specific tasks. Despite the success, fine-tuning\ncontinues to rely on repeated and lengthy prompts, which escalate computational\nexpenses, require more resources, and lead to slower inference. In this paper,\nwe present a novel approach, PromptIntern, which internalizes prompt knowledge\nduring model fine-tuning to achieve efficient inference and save costs. Instead\nof compressing the prompts for a vanilla model, PromptIntern aims to embed the\nrecurrent prompt directly into the model parameters. We design a fine-tuning\npipeline that includes instruction template compression, few-shot example\nabsorption, and a progressive internalization strategy, effectively diminishing\nthe need for intricate prompts during inference. Comprehensive experiments on\nchallenging NL2Code tasks demonstrate that our method reduces input tokens by\nmore than 90%, accelerates inference by 4.2 times, and reduces monetary\ninference costs by 88.3%."
  },
  {
    "arxiv_id": "2407.02147",
    "title": "LlamAr & GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning",
    "url": "http://arxiv.org/abs/2407.02147v1",
    "abstract": "Large language models (LLMs) have greatly impacted the natural language\nprocessing (NLP) field, particularly for the English language. These models\nhave demonstrated capabilities in understanding and generating human-like text.\nThe success of language models largely depends on the availability of\nhigh-quality instruction datasets, which consist of detailed task descriptions\nand corresponding responses that are essential for training the models to\naddress a variety of prompts accurately. However, the availability and quality\nof these resources vary by language. While models perform well in English, they\noften need help with languages like Arabic, due to the lack of datasets for\nfine-tuning Arabic-specific tasks. To address this issue, we introduce\nInstAr-500k, a new Arabic instruction dataset created by generating and\ncollecting content that covers several domains and instruction types. We assess\nthis dataset by fine-tuning an open-source Gemma-7B model on several downstream\ntasks to improve its functionality. Based on multiple evaluations, our\nfine-tuned model achieves excellent performance on several Arabic NLP\nbenchmarks. These outcomes emphasize the effectiveness of our dataset in\nelevating the capabilities of language models for Arabic. Our instruction\ndataset bridges the performance gap between English and Arabic language models\nby providing resources that amplify Arabic NLP development. Building on this\nfoundation, we developed a model, GemmAr-7B-V1, specifically tuned to excel at\na wide range of Arabic NLP tasks."
  },
  {
    "arxiv_id": "2407.01896",
    "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
    "url": "http://arxiv.org/abs/2407.01896v1",
    "abstract": "Log analysis is crucial for ensuring the orderly and stable operation of\ninformation systems, particularly in the field of Artificial Intelligence for\nIT Operations (AIOps). Large Language Models (LLMs) have demonstrated\nsignificant potential in natural language processing tasks. In the AIOps\ndomain, they excel in tasks such as anomaly detection, root cause analysis of\nfaults, operations and maintenance script generation, and alert information\nsummarization. However, the performance of current LLMs in log analysis tasks\nremains inadequately validated. To address this gap, we introduce LogEval, a\ncomprehensive benchmark suite designed to evaluate the capabilities of LLMs in\nvarious log analysis tasks for the first time. This benchmark covers tasks such\nas log parsing, log anomaly detection, log fault diagnosis, and log\nsummarization. LogEval evaluates each task using 4,000 publicly available log\ndata entries and employs 15 different prompts for each task to ensure a\nthorough and fair assessment. By rigorously evaluating leading LLMs, we\ndemonstrate the impact of various LLM technologies on log analysis performance,\nfocusing on aspects such as self-consistency and few-shot contextual learning.\nWe also discuss findings related to model quantification, Chinese-English\nquestion-answering evaluation, and prompt engineering. These findings provide\ninsights into the strengths and weaknesses of LLMs in multilingual environments\nand the effectiveness of different prompt strategies. Various evaluation\nmethods are employed for different tasks to accurately measure the performance\nof LLMs in log analysis, ensuring a comprehensive assessment. The insights\ngained from LogEvals evaluation reveal the strengths and limitations of LLMs in\nlog analysis tasks, providing valuable guidance for researchers and\npractitioners."
  },
  {
    "arxiv_id": "2407.01784",
    "title": "Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment",
    "url": "http://arxiv.org/abs/2407.01784v1",
    "abstract": "This paper describes our approach to hierarchical multi-label detection of\npersuasion techniques in meme texts. Our model, developed as a part of the\nrecent SemEval task, is based on fine-tuning individual language models (BERT,\nXLM-RoBERTa, and mBERT) and leveraging a mean-based ensemble model in addition\nto dataset augmentation through paraphrase generation from ChatGPT. The scope\nof the study encompasses enhancing model performance through innovative\ntraining techniques and data augmentation strategies. The problem addressed is\nthe effective identification and classification of multiple persuasive\ntechniques in meme texts, a task complicated by the diversity and complexity of\nsuch content. The objective of the paper is to improve detection accuracy by\nrefining model training methods and examining the impact of balanced versus\nunbalanced training datasets. Novelty in the results and discussion lies in the\nfinding that training with paraphrases enhances model performance, yet a\nbalanced training set proves more advantageous than a larger unbalanced one.\nAdditionally, the analysis reveals the potential pitfalls of indiscriminate\nincorporation of paraphrases from diverse distributions, which can introduce\nsubstantial noise. Results with the SemEval 2024 data confirm these insights,\ndemonstrating improved model efficacy with the proposed methods."
  },
  {
    "arxiv_id": "2407.02791",
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "url": "http://arxiv.org/abs/2407.02791v1",
    "abstract": "The flourishing ecosystem centered around voice personal assistants (VPA),\nsuch as Amazon Alexa, has led to the booming of VPA apps. The largest app\nmarket Amazon skills store, for example, hosts over 200,000 apps. Despite their\npopularity, the open nature of app release and the easy accessibility of apps\nalso raise significant concerns regarding security, privacy and quality.\nConsequently, various testing approaches have been proposed to systematically\nexamine VPA app behaviors. To tackle the inherent lack of a visible user\ninterface in the VPA app, two strategies are employed during testing, i.e.,\nchatbot-style testing and model-based testing. The former often lacks effective\nguidance for expanding its search space, while the latter falls short in\ninterpreting the semantics of conversations to construct precise and\ncomprehensive behavior models for apps. In this work, we introduce Elevate, a\nmodel-enhanced large language model (LLM)-driven VUI testing framework. Elevate\nleverages LLMs' strong capability in natural language processing to compensate\nfor semantic information loss during model-based VUI testing. It operates by\nprompting LLMs to extract states from VPA apps' outputs and generate\ncontext-related inputs. During the automatic interactions with the app, it\nincrementally constructs the behavior model, which facilitates the LLM in\ngenerating inputs that are highly likely to discover new states. Elevate\nbridges the LLM and the behavior model with innovative techniques such as\nencoding behavior model into prompts and selecting LLM-generated inputs based\non the context relevance. Elevate is benchmarked on 4,000 real-world Alexa\nskills, against the state-of-the-art tester Vitas. It achieves 15% higher state\nspace coverage compared to Vitas on all types of apps, and exhibits significant\nadvancement in efficiency."
  },
  {
    "arxiv_id": "2407.04459",
    "title": "Generalists vs. Specialists: Evaluating Large Language Models for Urdu",
    "url": "http://arxiv.org/abs/2407.04459v1",
    "abstract": "In this paper, we compare general-purpose models, GPT-4-Turbo and Llama-3-8b,\nwith special-purpose models--XLM-Roberta-large, mT5-large, and Llama-3-8b--that\nhave been fine-tuned on specific tasks. We focus on seven classification and\nseven generation tasks to evaluate the performance of these models on Urdu\nlanguage. Urdu has 70 million native speakers, yet it remains underrepresented\nin Natural Language Processing (NLP). Despite the frequent advancements in\nLarge Language Models (LLMs), their performance in low-resource languages,\nincluding Urdu, still needs to be explored. We also conduct a human evaluation\nfor the generation tasks and compare the results with the evaluations performed\nby GPT-4-Turbo, Llama-3-8b and Claude 3.5 Sonnet. We find that special-purpose\nmodels consistently outperform general-purpose models across various tasks. We\nalso find that the evaluation done by GPT-4-Turbo for generation tasks aligns\nmore closely with human evaluation compared to the evaluation the evaluation\ndone by Llama-3-8b. This paper contributes to the NLP community by providing\ninsights into the effectiveness of general and specific-purpose LLMs for\nlow-resource languages."
  },
  {
    "arxiv_id": "2407.04434",
    "title": "From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs",
    "url": "http://arxiv.org/abs/2407.04434v1",
    "abstract": "Gender bias is not only prevalent in Large Language Models (LLMs) and their\ntraining data, but also firmly ingrained into the structural aspects of\nlanguage itself. Therefore, adapting linguistic structures within LLM training\ndata to promote gender-inclusivity can make gender representations within the\nmodel more inclusive. The focus of our work are gender-exclusive affixes in\nEnglish, such as in 'show-girl' or 'man-cave', which can perpetuate gender\nstereotypes and binary conceptions of gender. We use an LLM training dataset to\ncompile a catalogue of 692 gender-exclusive terms along with gender-neutral\nvariants and from this, develop a gender-inclusive fine-tuning dataset, the\n'Tiny Heap'. Fine-tuning three different LLMs with this dataset, we observe an\noverall reduction in gender-stereotyping tendencies across the models. Our\napproach provides a practical method for enhancing gender inclusivity in LLM\ntraining data and contributes to incorporating queer-feminist linguistic\nactivism in bias mitigation research in NLP."
  },
  {
    "arxiv_id": "2407.04121",
    "title": "Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models",
    "url": "http://arxiv.org/abs/2407.04121v1",
    "abstract": "Large Language Models (LLMs) have gained widespread adoption in various\nnatural language processing tasks, including question answering and dialogue\nsystems. However, a major drawback of LLMs is the issue of hallucination, where\nthey generate unfaithful or inconsistent content that deviates from the input\nsource, leading to severe consequences. In this paper, we propose a robust\ndiscriminator named RelD to effectively detect hallucination in LLMs' generated\nanswers. RelD is trained on the constructed RelQA, a bilingual\nquestion-answering dialogue dataset along with answers generated by LLMs and a\ncomprehensive set of metrics. Our experimental results demonstrate that the\nproposed RelD successfully detects hallucination in the answers generated by\ndiverse LLMs. Moreover, it performs well in distinguishing hallucination in\nLLMs' generated answers from both in-distribution and out-of-distribution\ndatasets. Additionally, we also conduct a thorough analysis of the types of\nhallucinations that occur and present valuable insights. This research\nsignificantly contributes to the detection of reliable answers generated by\nLLMs and holds noteworthy implications for mitigating hallucination in the\nfuture work."
  },
  {
    "arxiv_id": "2407.04105",
    "title": "Can Pre-trained Language Models Understand Chinese Humor?",
    "url": "http://arxiv.org/abs/2407.04105v1",
    "abstract": "Humor understanding is an important and challenging research in natural\nlanguage processing. As the popularity of pre-trained language models (PLMs),\nsome recent work makes preliminary attempts to adopt PLMs for humor recognition\nand generation. However, these simple attempts do not substantially answer the\nquestion: {\\em whether PLMs are capable of humor understanding?} This paper is\nthe first work that systematically investigates the humor understanding ability\nof PLMs. For this purpose, a comprehensive framework with three evaluation\nsteps and four evaluation tasks is designed. We also construct a comprehensive\nChinese humor dataset, which can fully meet all the data requirements of the\nproposed evaluation framework. Our empirical study on the Chinese humor dataset\nyields some valuable observations, which are of great guiding value for future\noptimization of PLMs in humor understanding and generation."
  },
  {
    "arxiv_id": "2407.04014",
    "title": "Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems",
    "url": "http://arxiv.org/abs/2407.04014v1",
    "abstract": "The rapid adoption of large language models (LLMs) has led to significant\nadvances in natural language processing and text generation. However, the\nenergy consumed through LLM model inference remains a major challenge for\nsustainable AI deployment. To address this problem, we model the\nworkload-dependent energy consumption and runtime of LLM inference tasks on\nheterogeneous GPU-CPU systems. By conducting an extensive characterization\nstudy of several state-of-the-art LLMs and analyzing their energy and runtime\nbehavior across different magnitudes of input prompts and output text, we\ndevelop accurate (R^2>0.96) energy and runtime models for each LLM. We employ\nthese models to explore an offline, energy-optimal LLM workload scheduling\nframework. Through a case study, we demonstrate the advantages of energy and\naccuracy aware scheduling compared to existing best practices."
  },
  {
    "arxiv_id": "2407.03937",
    "title": "TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models",
    "url": "http://arxiv.org/abs/2407.03937v1",
    "abstract": "Classical Chinese is a gateway to the rich heritage and wisdom of ancient\nChina, yet its complexities pose formidable comprehension barriers for most\nmodern people without specialized knowledge. While Large Language Models (LLMs)\nhave shown remarkable capabilities in Natural Language Processing (NLP), they\nstruggle with Classical Chinese Understanding (CCU), especially in\ndata-demanding and knowledge-intensive tasks. In response to this dilemma, we\npropose \\textbf{TongGu} (mean understanding ancient and modern), the first\nCCU-specific LLM, underpinned by three core contributions. First, we construct\na two-stage instruction-tuning dataset ACCN-INS derived from rich classical\nChinese corpora, aiming to unlock the full CCU potential of LLMs. Second, we\npropose Redundancy-Aware Tuning (RAT) to prevent catastrophic forgetting,\nenabling TongGu to acquire new capabilities while preserving its foundational\nknowledge. Third, we present a CCU Retrieval-Augmented Generation (CCU-RAG)\ntechnique to reduce hallucinations based on knowledge-grounding. Extensive\nexperiments across 24 diverse CCU tasks validate TongGu's superior ability,\nunderscoring the effectiveness of RAT and CCU-RAG. The model and dataset are\navailable at \\url{https://github.com/SCUT-DLVCLab/TongGu-LLM}."
  },
  {
    "arxiv_id": "2407.06172",
    "title": "On Speeding Up Language Model Evaluation",
    "url": "http://arxiv.org/abs/2407.06172v1",
    "abstract": "Developing prompt-based methods with Large Language Models (LLMs) requires\nmaking numerous decisions, which give rise to a combinatorial search problem\nover hyper-parameters. This exhaustive evaluation can be time-consuming and\ncostly. In this paper, we propose an $\\textit{adaptive}$ approach to explore\nthis space. We are exploiting the fact that often only few samples are needed\nto identify clearly superior or inferior settings, and that many evaluation\ntests are highly correlated. We lean on multi-armed bandits to sequentially\nidentify the next (method, validation sample)-pair to evaluate and utilize\nlow-rank matrix factorization to fill in missing evaluations. We carefully\nassess the efficacy of our approach on several competitive benchmark problems\nand show that it can identify the top-performing method using only 5-15% of the\ntypical resources -- resulting in 85-95% LLM cost savings. Our code is\navailable at https://github.com/kilian-group/banditeval."
  },
  {
    "arxiv_id": "2407.06089",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "url": "http://arxiv.org/abs/2407.06089v1",
    "abstract": "The remarkable success of Large Language Models (LLMs) has ushered natural\nlanguage processing (NLP) research into a new era. Despite their diverse\ncapabilities, LLMs trained on different corpora exhibit varying strengths and\nweaknesses, leading to challenges in maximizing their overall efficiency and\nversatility. To address these challenges, recent studies have explored\ncollaborative strategies for LLMs. This paper provides a comprehensive overview\nof this emerging research area, highlighting the motivation behind such\ncollaborations. Specifically, we categorize collaborative strategies into three\nprimary approaches: Merging, Ensemble, and Cooperation. Merging involves\nintegrating multiple LLMs in the parameter space. Ensemble combines the outputs\nof various LLMs. Cooperation} leverages different LLMs to allow full play to\ntheir diverse capabilities for specific tasks. We provide in-depth\nintroductions to these methods from different perspectives and discuss their\npotential applications. Additionally, we outline future research directions,\nhoping this work will catalyze further studies on LLM collaborations and paving\nthe way for advanced NLP applications."
  },
  {
    "arxiv_id": "2407.06011",
    "title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian",
    "url": "http://arxiv.org/abs/2407.06011v1",
    "abstract": "The development of domain-specific language models has significantly advanced\nnatural language processing applications in various specialized fields,\nparticularly in biomedicine. However, the focus has largely been on\nEnglish-language models, leaving a gap for less-resourced languages such as\nItalian. This paper introduces Igea, the first decoder-only language model\ndesigned explicitly for biomedical text generation in Italian. Built on the\nMinerva model and continually pretrained on a diverse corpus of Italian medical\ntexts, Igea is available in three model sizes: 350 million, 1 billion, and 3\nbillion parameters. The models aim to balance computational efficiency and\nperformance, addressing the challenges of managing the peculiarities of medical\nterminology in Italian. We evaluate Igea using a mix of in-domain biomedical\ncorpora and general-purpose benchmarks, highlighting its efficacy and retention\nof general knowledge even after the domain-specific training. This paper\ndiscusses the model's development and evaluation, providing a foundation for\nfuture advancements in Italian biomedical NLP."
  },
  {
    "arxiv_id": "2407.05841",
    "title": "An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models",
    "url": "http://arxiv.org/abs/2407.05841v1",
    "abstract": "Language Models (LMs) excel in natural language processing tasks for English\nbut show reduced performance in most other languages. This problem is commonly\ntackled by continually pre-training and fine-tuning these models for said\nlanguages. A significant issue in this process is the limited vocabulary\ncoverage in the original model's tokenizer, leading to inadequate\nrepresentation of new languages and necessitating an expansion of the\ntokenizer. The initialization of the embeddings corresponding to new vocabulary\nitems presents a further challenge. Current strategies require cross-lingual\nembeddings and lack a solid theoretical foundation as well as comparisons with\nstrong baselines. In this paper, we first establish theoretically that\ninitializing within the convex hull of existing embeddings is a good\ninitialization, followed by a novel but simple approach, Constrained Word2Vec\n(CW2V), which does not require cross-lingual embeddings. Our study evaluates\ndifferent initialization methods for expanding RoBERTa and LLaMA 2 across four\nlanguages and five tasks. The results show that CW2V performs equally well or\neven better than more advanced techniques. Additionally, simpler approaches\nlike multivariate initialization perform on par with these advanced methods\nindicating that efficient large-scale multilingual continued pretraining can be\nachieved even with simpler initialization methods. We release our code publicly\n(https://github.com/AI4Bharat/VocabAdaptation_LLM/tree/CW2V)."
  },
  {
    "arxiv_id": "2407.05786",
    "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
    "url": "http://arxiv.org/abs/2407.05786v1",
    "abstract": "Domain-specific Entity Recognition holds significant importance in legal\ncontexts, serving as a fundamental task that supports various applications such\nas question-answering systems, text summarization, machine translation,\nsentiment analysis, and information retrieval specifically within case law\ndocuments. Recent advancements have highlighted the efficacy of Large Language\nModels in natural language processing tasks, demonstrating their capability to\naccurately detect and classify domain-specific facts (entities) from\nspecialized texts like clinical and financial documents. This research\ninvestigates the application of Large Language Models in identifying\ndomain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,\nFIR nos.) within case law documents, with a specific focus on their aptitude\nfor handling domain-specific language complexity and contextual variations. The\nstudy evaluates the performance of state-of-the-art Large Language Model\narchitectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in\nthe context of extracting judicial facts tailored to Indian judicial texts.\nMistral and Gemma emerged as the top-performing models, showcasing balanced\nprecision and recall crucial for accurate entity identification. These findings\nconfirm the value of Large Language Models in judicial documents and\ndemonstrate how they can facilitate and quicken scientific research by\nproducing precise, organised data outputs that are appropriate for in-depth\nexamination."
  },
  {
    "arxiv_id": "2407.05750",
    "title": "Large Language Models Understand Layouts",
    "url": "http://arxiv.org/abs/2407.05750v1",
    "abstract": "Large language models (LLMs) demonstrate extraordinary abilities in a wide\nrange of natural language processing (NLP) tasks. In this paper, we show that,\nbeyond text understanding capability, LLMs are capable of processing text\nlayouts that are denoted by spatial markers. They are able to answer questions\nthat require explicit spatial perceiving and reasoning, while a drastic\nperformance drop is observed when the spatial markers from the original data\nare excluded. We perform a series of experiments with the GPT-3.5, Baichuan2,\nLlama2 and ChatGLM3 models on various types of layout-sensitive datasets for\nfurther analysis. The experimental results reveal that the layout understanding\nability of LLMs is mainly introduced by the coding data for pretraining, which\nis further enhanced at the instruction-tuning stage. In addition, layout\nunderstanding can be enhanced by integrating low-cost, auto-generated data\napproached by a novel text game. Finally, we show that layout understanding\nability is beneficial for building efficient visual question-answering (VQA)\nsystems."
  },
  {
    "arxiv_id": "2407.05365",
    "title": "ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models",
    "url": "http://arxiv.org/abs/2407.05365v1",
    "abstract": "In response to the urgent demand for grid stability and the complex\nchallenges posed by renewable energy integration and electricity market\ndynamics, the power sector increasingly seeks innovative technological\nsolutions. In this context, large language models (LLMs) have become a key\ntechnology to improve efficiency and promote intelligent progress in the power\nsector with their excellent natural language processing, logical reasoning, and\ngeneralization capabilities. Despite their potential, the absence of a\nperformance evaluation benchmark for LLM in the power sector has limited the\neffective application of these technologies. Addressing this gap, our study\nintroduces \"ElecBench\", an evaluation benchmark of LLMs within the power\nsector. ElecBench aims to overcome the shortcomings of existing evaluation\nbenchmarks by providing comprehensive coverage of sector-specific scenarios,\ndeepening the testing of professional knowledge, and enhancing decision-making\nprecision. The framework categorizes scenarios into general knowledge and\nprofessional business, further divided into six core performance metrics:\nfactuality, logicality, stability, security, fairness, and expressiveness, and\nis subdivided into 24 sub-metrics, offering profound insights into the\ncapabilities and limitations of LLM applications in the power sector. To ensure\ntransparency, we have made the complete test set public, evaluating the\nperformance of eight LLMs across various scenarios and metrics. ElecBench\naspires to serve as the standard benchmark for LLM applications in the power\nsector, supporting continuous updates of scenarios, metrics, and models to\ndrive technological progress and application."
  },
  {
    "arxiv_id": "2407.05233",
    "title": "Advancing Prompt Recovery in NLP: A Deep Dive into the Integration of Gemma-2b-it and Phi2 Models",
    "url": "http://arxiv.org/abs/2407.05233v1",
    "abstract": "Prompt recovery, a crucial task in natural language processing, entails the\nreconstruction of prompts or instructions that language models use to convert\ninput text into a specific output. Although pivotal, the design and\neffectiveness of prompts represent a challenging and relatively untapped field\nwithin NLP research. This paper delves into an exhaustive investigation of\nprompt recovery methodologies, employing a spectrum of pre-trained language\nmodels and strategies. Our study is a comparative analysis aimed at gauging the\nefficacy of various models on a benchmark dataset, with the goal of pinpointing\nthe most proficient approach for prompt recovery. Through meticulous\nexperimentation and detailed analysis, we elucidate the outstanding performance\nof the Gemma-2b-it + Phi2 model + Pretrain. This model surpasses its\ncounterparts, showcasing its exceptional capability in accurately\nreconstructing prompts for text transformation tasks. Our findings offer a\nsignificant contribution to the existing knowledge on prompt recovery, shedding\nlight on the intricacies of prompt design and offering insightful perspectives\nfor future innovations in text rewriting and the broader field of natural\nlanguage processing."
  },
  {
    "arxiv_id": "2407.06564",
    "title": "Combining Knowledge Graphs and Large Language Models",
    "url": "http://arxiv.org/abs/2407.06564v1",
    "abstract": "In recent years, Natural Language Processing (NLP) has played a significant\nrole in various Artificial Intelligence (AI) applications such as chatbots,\ntext generation, and language translation. The emergence of large language\nmodels (LLMs) has greatly improved the performance of these applications,\nshowing astonishing results in language understanding and generation. However,\nthey still show some disadvantages, such as hallucinations and lack of\ndomain-specific knowledge, that affect their performance in real-world tasks.\nThese issues can be effectively mitigated by incorporating knowledge graphs\n(KGs), which organise information in structured formats that capture\nrelationships between entities in a versatile and interpretable fashion.\nLikewise, the construction and validation of KGs present challenges that LLMs\ncan help resolve. The complementary relationship between LLMs and KGs has led\nto a trend that combines these technologies to achieve trustworthy results.\nThis work collected 28 papers outlining methods for KG-powered LLMs, LLM-based\nKGs, and LLM-KG hybrid approaches. We systematically analysed and compared\nthese approaches to provide a comprehensive overview highlighting key trends,\ninnovative techniques, and common challenges. This synthesis will benefit\nresearchers new to the field and those seeking to deepen their understanding of\nhow KGs and LLMs can be effectively combined to enhance AI applications\ncapabilities."
  },
  {
    "arxiv_id": "2407.06432",
    "title": "An Empirical Study of Gendered Stereotypes in Emotional Attributes for Bangla in Multilingual Large Language Models",
    "url": "http://arxiv.org/abs/2407.06432v1",
    "abstract": "The influence of Large Language Models (LLMs) is rapidly growing, automating\nmore jobs over time. Assessing the fairness of LLMs is crucial due to their\nexpanding impact. Studies reveal the reflection of societal norms and biases in\nLLMs, which creates a risk of propagating societal stereotypes in downstream\ntasks. Many studies on bias in LLMs focus on gender bias in various NLP\napplications. However, there's a gap in research on bias in emotional\nattributes, despite the close societal link between emotion and gender. This\ngap is even larger for low-resource languages like Bangla. Historically, women\nare associated with emotions like empathy, fear, and guilt, while men are\nlinked to anger, bravado, and authority. This pattern reflects societal norms\nin Bangla-speaking regions. We offer the first thorough investigation of\ngendered emotion attribution in Bangla for both closed and open source LLMs in\nthis work. Our aim is to elucidate the intricate societal relationship between\ngender and emotion specifically within the context of Bangla. We have been\nsuccessful in showing the existence of gender bias in the context of emotions\nin Bangla through analytical methods and also show how emotion attribution\nchanges on the basis of gendered role selection in LLMs. All of our resources\nincluding code and data are made publicly available to support future research\non Bangla NLP.\n  Warning: This paper contains explicit stereotypical statements that many may\nfind offensive."
  },
  {
    "arxiv_id": "2407.07810",
    "title": "Transformer Alignment in Large Language Models",
    "url": "http://arxiv.org/abs/2407.07810v1",
    "abstract": "Large Language Models (LLMs) have made significant strides in natural\nlanguage processing, and a precise understanding of the internal mechanisms\ndriving their success is essential. In this work, we analyze the trajectories\nof token embeddings as they pass through transformer blocks, linearizing the\nsystem along these trajectories through their Jacobian matrices. By examining\nthe relationships between these block Jacobians, we uncover the phenomenon of\n\\textbf{transformer block coupling} in a multitude of LLMs, characterized by\nthe coupling of their top singular vectors across tokens and depth. Our\nfindings reveal that coupling \\textit{positively correlates} with model\nperformance, and that this relationship is stronger than with other\nhyperparameters such as parameter count, model depth, and embedding dimension.\nWe further investigate how these properties emerge during training, observing a\nprogressive development of coupling, increased linearity, and layer-wise\nexponential growth in token trajectories. Additionally, experiments with Vision\nTransformers (ViTs) corroborate the emergence of coupling and its relationship\nwith generalization, reinforcing our findings in LLMs. Collectively, these\ninsights offer a novel perspective on token interactions in transformers,\nopening new directions for studying their mechanisms as well as improving\ntraining and generalization."
  },
  {
    "arxiv_id": "2407.07469",
    "title": "Development of an automatic modification system for generated programs using ChatGPT",
    "url": "http://arxiv.org/abs/2407.07469v1",
    "abstract": "In recent years, the field of artificial intelligence has been rapidly\ndeveloping. Among them, OpenAI's ChatGPT excels at natural language processing\ntasks and can also generate source code. However, the generated code often has\nproblems with consistency and program rules. Therefore, in this research, we\ndeveloped a system that tests the code generated by ChatGPT, automatically\ncorrects it if it is inappropriate, and presents the appropriate code to the\nuser. This study aims to address the challenge of reducing the manual effort\nrequired for the human feedback and modification process for generated code.\nWhen we ran the system, we were able to automatically modify the code as\nintended."
  },
  {
    "arxiv_id": "2407.09184",
    "title": "Does Incomplete Syntax Influence Korean Language Model? Focusing on Word Order and Case Markers",
    "url": "http://arxiv.org/abs/2407.09184v1",
    "abstract": "Syntactic elements, such as word order and case markers, are fundamental in\nnatural language processing. Recent studies show that syntactic information\nboosts language model performance and offers clues for people to understand\ntheir learning mechanisms. Unlike languages with a fixed word order such as\nEnglish, Korean allows for varied word sequences, despite its canonical\nstructure, due to case markers that indicate the functions of sentence\ncomponents. This study explores whether Korean language models can accurately\ncapture this flexibility. We note that incomplete word orders and omitted case\nmarkers frequently appear in ordinary Korean communication. To investigate this\nfurther, we introduce the Syntactically Incomplete Korean (SIKO) dataset.\nThrough SIKO, we assessed Korean language models' flexibility with incomplete\nsyntax and confirmed the dataset's training value. Results indicate these\nmodels reflect Korean's inherent flexibility, accurately handling incomplete\ninputs. Moreover, fine-tuning with SIKO enhances the ability to handle common\nincomplete Korean syntactic forms. The dataset's simple construction process,\ncoupled with significant performance enhancements, solidifies its standing as\nan effective data augmentation technique."
  },
  {
    "arxiv_id": "2407.08989",
    "title": "Robustness of LLMs to Perturbations in Text",
    "url": "http://arxiv.org/abs/2407.08989v1",
    "abstract": "Having a clean dataset has been the foundational assumption of most natural\nlanguage processing (NLP) systems. However, properly written text is rarely\nfound in real-world scenarios and hence, oftentimes invalidates the\naforementioned foundational assumption. Recently, Large language models (LLMs)\nhave shown impressive performance, but can they handle the inevitable noise in\nreal-world data? This work tackles this critical question by investigating\nLLMs' resilience against morphological variations in text. To that end, we\nartificially introduce varying levels of noise into a diverse set of datasets\nand systematically evaluate LLMs' robustness against the corrupt variations of\nthe original text. Our findings show that contrary to popular beliefs,\ngenerative LLMs are quiet robust to noisy perturbations in text. This is a\ndeparture from pre-trained models like BERT or RoBERTa whose performance has\nbeen shown to be sensitive to deteriorating noisy text. Additionally, we test\nLLMs' resilience on multiple real-world benchmarks that closely mimic commonly\nfound errors in the wild. With minimal prompting, LLMs achieve a new\nstate-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and\nLexical Semantic Change (LSC). To empower future research, we also release a\ndataset annotated by humans stating their preference for LLM vs.\nhuman-corrected outputs along with the code to reproduce our results."
  },
  {
    "arxiv_id": "2407.08967",
    "title": "Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models",
    "url": "http://arxiv.org/abs/2407.08967v1",
    "abstract": "Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)\nthat utilizes limited training instances, appeals to more researchers in\nNatural Language Processing (NLP) due to its capability to extract textual\ninformation in extremely low-resource scenarios. The primary methodologies\nemployed for FSRE have been fine-tuning or prompt tuning techniques based on\nPre-trained Language Models (PLMs). Recently, the emergence of Large Language\nModels (LLMs) has prompted numerous researchers to explore FSRE through\nIn-Context Learning (ICL). However, there are substantial limitations\nassociated with methods based on either traditional RE models or LLMs.\nTraditional RE models are hampered by a lack of necessary prior knowledge,\nwhile LLMs fall short in their task-specific capabilities for RE. To address\nthese shortcomings, we propose a Dual-System Augmented Relation Extractor\n(DSARE), which synergistically combines traditional RE models with LLMs.\nSpecifically, DSARE innovatively injects the prior knowledge of LLMs into\ntraditional RE models, and conversely enhances LLMs' task-specific aptitude for\nRE through relation extraction augmentation. Moreover, an Integrated Prediction\nmodule is employed to jointly consider these two respective predictions and\nderive the final results. Extensive experiments demonstrate the efficacy of our\nproposed method."
  },
  {
    "arxiv_id": "2407.08942",
    "title": "A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model",
    "url": "http://arxiv.org/abs/2407.08942v1",
    "abstract": "Recommendation systems have become an important solution to information\nsearch problems. This article proposes a neural matrix factorization\nrecommendation system model based on the multimodal large language model called\nBoNMF. This model combines BoBERTa's powerful capabilities in natural language\nprocessing, ViT in computer in vision, and neural matrix decomposition\ntechnology. By capturing the potential characteristics of users and items, and\nafter interacting with a low-dimensional matrix composed of user and item IDs,\nthe neural network outputs the results. recommend. Cold start and ablation\nexperimental results show that the BoNMF model exhibits excellent performance\non large public data sets and significantly improves the accuracy of\nrecommendations."
  },
  {
    "arxiv_id": "2407.10930",
    "title": "Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together",
    "url": "http://arxiv.org/abs/2407.10930v1",
    "abstract": "Natural Language Processing (NLP) systems are increasingly taking the form of\nsophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),\nwhere each module may involve a distinct Language Model (LM) and an associated\nprompt template. These compound systems often lack intermediate labels or\ngradient flow to optimize each module, making their end-to-end optimization\nchallenging. Here we seek strategies to optimize both the module-level LM\nweights and the associated prompt templates of such systems to maximize a\ndownstream task metric. We propose for the first time combining the weight and\nprompt optimization strategies to optimize a modular LM pipeline by alternating\nbetween the two to get the same LM to teach itself. In experiments with\nmulti-hop QA, mathematical reasoning, and feature-based classification using\nmistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies\noptimizing the weights and prompts of a pipeline together outperform directly\noptimizing weights alone and prompts alone by up to 60% and 6%, respectively,\non average across LMs and tasks. BetterTogether optimizer is released in DSPy\nat http://dspy.ai"
  },
  {
    "arxiv_id": "2407.10794",
    "title": "Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education",
    "url": "http://arxiv.org/abs/2407.10794v1",
    "abstract": "Knowledge graphs (KGs) are crucial in the field of artificial intelligence\nand are widely applied in downstream tasks, such as enhancing Question\nAnswering (QA) systems. The construction of KGs typically requires significant\neffort from domain experts. Recently, Large Language Models (LLMs) have been\nused for knowledge graph construction (KGC), however, most existing approaches\nfocus on a local perspective, extracting knowledge triplets from individual\nsentences or documents. In this work, we introduce Graphusion, a zero-shot KGC\nframework from free text. The core fusion module provides a global view of\ntriplets, incorporating entity merging, conflict resolution, and novel triplet\ndiscovery. We showcase how Graphusion could be applied to the natural language\nprocessing (NLP) domain and validate it in the educational scenario.\nSpecifically, we introduce TutorQA, a new expert-verified benchmark for graph\nreasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our\nevaluation demonstrates that Graphusion surpasses supervised baselines by up to\n10% in accuracy on link prediction. Additionally, it achieves average scores of\n2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and\nrelation recognition, respectively."
  },
  {
    "arxiv_id": "2407.10351",
    "title": "Comparing Complex Concepts with Transformers: Matching Patent Claims Against Natural Language Text",
    "url": "http://arxiv.org/abs/2407.10351v1",
    "abstract": "A key capability in managing patent applications or a patent portfolio is\ncomparing claims to other text, e.g. a patent specification. Because the\nlanguage of claims is different from language used elsewhere in the patent\napplication or in non-patent text, this has been challenging for computer based\nnatural language processing. We test two new LLM-based approaches and find that\nboth provide substantially better performance than previously published values.\nThe ability to match dense information from one domain against much more\ndistributed information expressed in a different vocabulary may also be useful\nbeyond the intellectual property space."
  },
  {
    "arxiv_id": "2407.10114",
    "title": "TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation",
    "url": "http://arxiv.org/abs/2407.10114v1",
    "abstract": "As large language models (LLMs) become increasingly prevalent in critical\napplications, the need for interpretable AI has grown. We introduce TokenSHAP,\na novel method for interpreting LLMs by attributing importance to individual\ntokens or substrings within input prompts. This approach adapts Shapley values\nfrom cooperative game theory to natural language processing, offering a\nrigorous framework for understanding how different parts of an input contribute\nto a model's response. TokenSHAP leverages Monte Carlo sampling for\ncomputational efficiency, providing interpretable, quantitative measures of\ntoken importance. We demonstrate its efficacy across diverse prompts and LLM\narchitectures, showing consistent improvements over existing baselines in\nalignment with human judgments, faithfulness to model behavior, and\nconsistency.\n  Our method's ability to capture nuanced interactions between tokens provides\nvaluable insights into LLM behavior, enhancing model transparency, improving\nprompt engineering, and aiding in the development of more reliable AI systems.\nTokenSHAP represents a significant step towards the necessary interpretability\nfor responsible AI deployment, contributing to the broader goal of creating\nmore transparent, accountable, and trustworthy AI systems."
  },
  {
    "arxiv_id": "2407.11955",
    "title": "A Transformer-based Approach for Augmenting Software Engineering Chatbots Datasets",
    "url": "http://arxiv.org/abs/2407.11955v1",
    "abstract": "Background: The adoption of chatbots into software development tasks has\nbecome increasingly popular among practitioners, driven by the advantages of\ncost reduction and acceleration of the software development process. Chatbots\nunderstand users' queries through the Natural Language Understanding component\n(NLU). To yield reasonable performance, NLUs have to be trained with extensive,\nhigh-quality datasets, that express a multitude of ways users may interact with\nchatbots. However, previous studies show that creating a high-quality training\ndataset for software engineering chatbots is expensive in terms of both\nresources and time. Aims: Therefore, in this paper, we present an automated\ntransformer-based approach to augment software engineering chatbot datasets.\nMethod: Our approach combines traditional natural language processing\ntechniques with the BART transformer to augment a dataset by generating queries\nthrough synonym replacement and paraphrasing. We evaluate the impact of using\nthe augmentation approach on the Rasa NLU's performance using three software\nengineering datasets. Results: Overall, the augmentation approach shows\npromising results in improving the Rasa's performance, augmenting queries with\nvarying sentence structures while preserving their original semantics.\nFurthermore, it increases Rasa's confidence in its intent classification for\nthe correctly classified intents. Conclusions: We believe that our study helps\npractitioners improve the performance of their chatbots and guides future\nresearch to propose augmentation techniques for SE chatbots."
  },
  {
    "arxiv_id": "2407.11948",
    "title": "Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation",
    "url": "http://arxiv.org/abs/2407.11948v1",
    "abstract": "The utilization of Transformer-based models prospers the growth of\nmulti-document summarization (MDS). Given the huge impact and widespread\nadoption of Transformer-based models in various natural language processing\ntasks, investigating their performance and behaviors in the context of MDS\nbecomes crucial for advancing the field and enhancing the quality of summary.\nTo thoroughly examine the behaviours of Transformer-based MDS models, this\npaper presents five empirical studies on (1) measuring the impact of document\nboundary separators quantitatively; (2) exploring the effectiveness of\ndifferent mainstream Transformer structures; (3) examining the sensitivity of\nthe encoder and decoder; (4) discussing different training strategies; and (5)\ndiscovering the repetition in a summary generation. The experimental results on\nprevalent MDS datasets and eleven evaluation metrics show the influence of\ndocument boundary separators, the granularity of different level features and\ndifferent model training strategies. The results also reveal that the decoder\nexhibits greater sensitivity to noises compared to the encoder. This\nunderscores the important role played by the decoder, suggesting a potential\ndirection for future research in MDS. Furthermore, the experimental results\nindicate that the repetition problem in the generated summaries has\ncorrelations with the high uncertainty scores."
  },
  {
    "arxiv_id": "2407.11774",
    "title": "Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text",
    "url": "http://arxiv.org/abs/2407.11774v1",
    "abstract": "Detecting Machine-Generated Text (MGT) has emerged as a significant area of\nstudy within Natural Language Processing. While language models generate text,\nthey often leave discernible traces, which can be scrutinized using either\ntraditional feature-based methods or more advanced neural language models. In\nthis research, we explore the effectiveness of fine-tuning a RoBERTa-base\ntransformer, a powerful neural architecture, to address MGT detection as a\nbinary classification task. Focusing specifically on Subtask A\n(Monolingual-English) within the SemEval-2024 competition framework, our\nproposed system achieves an accuracy of 78.9% on the test dataset, positioning\nus at 57th among participants. Our study addresses this challenge while\nconsidering the limited hardware resources, resulting in a system that excels\nat identifying human-written texts but encounters challenges in accurately\ndiscerning MGTs."
  },
  {
    "arxiv_id": "2407.11654",
    "title": "R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models",
    "url": "http://arxiv.org/abs/2407.11654v1",
    "abstract": "Split federated learning (SFL) is a compute-efficient paradigm in distributed\nmachine learning (ML), where components of large ML models are outsourced to\nremote servers. A significant challenge in SFL, particularly when deployed over\nwireless channels, is the susceptibility of transmitted model parameters to\nadversarial jamming that could jeopardize the learning process. This is\nparticularly pronounced for word embedding parameters in large language models\n(LLMs), which are crucial for language understanding. In this paper, rigorous\ninsights are provided into the influence of jamming LLM word embeddings in SFL\nby deriving an expression for the ML training loss divergence and showing that\nit is upper-bounded by the mean squared error (MSE). Based on this analysis, a\nphysical layer framework is developed for resilient SFL with LLMs (R-SFLLM)\nover wireless networks. R-SFLLM leverages wireless sensing data to gather\ninformation on the jamming directions-of-arrival (DoAs) for the purpose of\ndevising a novel, sensing-assisted anti-jamming strategy while jointly\noptimizing beamforming, user scheduling, and resource allocation. Extensive\nexperiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,\nachieving close-to-baseline performance across various natural language\nprocessing (NLP) tasks and datasets. The proposed methodology further\nintroduces an adversarial training component, where controlled noise exposure\nsignificantly enhances the LLM's resilience to perturbed parameters during\ntraining. The results show that more noise-sensitive models, such as RoBERTa,\nbenefit from this feature, especially when resource allocation is unfair. It is\nalso shown that worst-case jamming in particular translates into worst-case\nmodel outcomes, thereby necessitating the need for jamming-resilient SFL\nprotocols."
  },
  {
    "arxiv_id": "2407.11435",
    "title": "Genomic Language Models: Opportunities and Challenges",
    "url": "http://arxiv.org/abs/2407.11435v1",
    "abstract": "Large language models (LLMs) are having transformative impacts across a wide\nrange of scientific fields, particularly in the biomedical sciences. Just as\nthe goal of Natural Language Processing is to understand sequences of words, a\nmajor objective in biology is to understand biological sequences. Genomic\nLanguage Models (gLMs), which are LLMs trained on DNA sequences, have the\npotential to significantly advance our understanding of genomes and how DNA\nelements at various scales interact to give rise to complex functions. To\nshowcase this potential, we highlight key applications of gLMs, including\nfunctional constraint prediction, sequence design, and transfer learning.\nDespite notable recent progress, however, developing effective and efficient\ngLMs presents numerous challenges, especially for species with large, complex\ngenomes. Here, we discuss major considerations for developing and evaluating\ngLMs."
  },
  {
    "arxiv_id": "2407.11361",
    "title": "Graph Structure Prompt Learning: A Novel Methodology to Improve Performance of Graph Neural Networks",
    "url": "http://arxiv.org/abs/2407.11361v1",
    "abstract": "Graph neural networks (GNNs) are widely applied in graph data modeling.\nHowever, existing GNNs are often trained in a task-driven manner that fails to\nfully capture the intrinsic nature of the graph structure, resulting in\nsub-optimal node and graph representations. To address this limitation, we\npropose a novel Graph structure Prompt Learning method (GPL) to enhance the\ntraining of GNNs, which is inspired by prompt mechanisms in natural language\nprocessing. GPL employs task-independent graph structure losses to encourage\nGNNs to learn intrinsic graph characteristics while simultaneously solving\ndownstream tasks, producing higher-quality node and graph representations. In\nextensive experiments on eleven real-world datasets, after being trained by\nGPL, GNNs significantly outperform their original performance on node\nclassification, graph classification, and edge prediction tasks (up to 10.28%,\n16.5%, and 24.15%, respectively). By allowing GNNs to capture the inherent\nstructural prompts of graphs in GPL, they can alleviate the issue of\nover-smooth and achieve new state-of-the-art performances, which introduces a\nnovel and effective direction for GNN research with potential applications in\nvarious domains."
  },
  {
    "arxiv_id": "2407.12736",
    "title": "CHOSEN: Compilation to Hardware Optimization Stack for Efficient Vision Transformer Inference",
    "url": "http://arxiv.org/abs/2407.12736v1",
    "abstract": "Vision Transformers (ViTs) represent a groundbreaking shift in machine\nlearning approaches to computer vision. Unlike traditional approaches, ViTs\nemploy the self-attention mechanism, which has been widely used in natural\nlanguage processing, to analyze image patches. Despite their advantages in\nmodeling visual tasks, deploying ViTs on hardware platforms, notably\nField-Programmable Gate Arrays (FPGAs), introduces considerable challenges.\nThese challenges stem primarily from the non-linear calculations and high\ncomputational and memory demands of ViTs. This paper introduces CHOSEN, a\nsoftware-hardware co-design framework to address these challenges and offer an\nautomated framework for ViT deployment on the FPGAs in order to maximize\nperformance. Our framework is built upon three fundamental contributions:\nmulti-kernel design to maximize the bandwidth, mainly targeting benefits of\nmulti DDR memory banks, approximate non-linear functions that exhibit minimal\naccuracy degradation, and efficient use of available logic blocks on the FPGA,\nand efficient compiler to maximize the performance and memory-efficiency of the\ncomputing kernels by presenting a novel algorithm for design space exploration\nto find optimal hardware configuration that achieves optimal throughput and\nlatency. Compared to the state-of-the-art ViT accelerators, CHOSEN achieves a\n1.5x and 1.42x improvement in the throughput on the DeiT-S and DeiT-B models."
  },
  {
    "arxiv_id": "2407.12638",
    "title": "ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks",
    "url": "http://arxiv.org/abs/2407.12638v1",
    "abstract": "Transformers have emerged as a powerful tool for natural language processing\n(NLP) and computer vision. Through the attention mechanism, these models have\nexhibited remarkable performance gains when compared to conventional approaches\nlike recurrent neural networks (RNNs) and convolutional neural networks (CNNs).\nNevertheless, transformers typically demand substantial execution time due to\ntheir extensive computations and large memory footprint. Processing in-memory\n(PIM) and near-memory computing (NMC) are promising solutions to accelerating\ntransformers as they offer high compute parallelism and memory bandwidth.\nHowever, designing PIM/NMC architectures to support the complex operations and\nmassive amounts of data that need to be moved between layers in transformer\nneural networks remains a challenge. We propose ARTEMIS, a mixed\nanalog-stochastic in-DRAM accelerator for transformer models. Through employing\nminimal changes to the conventional DRAM arrays, ARTEMIS efficiently alleviates\nthe costs associated with transformer model execution by supporting stochastic\ncomputing for multiplications and temporal analog accumulations using a novel\nin-DRAM metal-on-metal capacitor. Our analysis indicates that ARTEMIS exhibits\nat least 3.0x speedup, 1.8x lower energy, and 1.9x better energy efficiency\ncompared to GPU, TPU, CPU, and state-of-the-art PIM transformer hardware\naccelerators."
  },
  {
    "arxiv_id": "2407.12426",
    "title": "Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for Fine-Grained Scoring of Textual Semantic Relations",
    "url": "http://arxiv.org/abs/2407.12426v1",
    "abstract": "Semantic Textual Relatedness holds significant relevance in Natural Language\nProcessing, finding applications across various domains. Traditionally,\napproaches to STR have relied on knowledge-based and statistical methods.\nHowever, with the emergence of Large Language Models, there has been a paradigm\nshift, ushering in new methodologies. In this paper, we delve into the\ninvestigation of sentence-level STR within Track A (Supervised) by leveraging\nfine-tuning techniques on the RoBERTa transformer. Our study focuses on\nassessing the efficacy of this approach across different languages. Notably,\nour findings indicate promising advancements in STR performance, particularly\nin Latin languages. Specifically, our results demonstrate notable improvements\nin English, achieving a correlation of 0.82 and securing a commendable 19th\nrank. Similarly, in Spanish, we achieved a correlation of 0.67, securing the\n15th position. However, our approach encounters challenges in languages like\nArabic, where we observed a correlation of only 0.38, resulting in a 20th rank."
  },
  {
    "arxiv_id": "2407.13744",
    "title": "LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation",
    "url": "http://arxiv.org/abs/2407.13744v1",
    "abstract": "Natural Language Processing has moved rather quickly from modelling specific\ntasks to taking more general pre-trained models and fine-tuning them for\nspecific tasks, to a point where we now have what appear to be inherently\ngeneralist models. This paper argues that the resultant loss of clarity on what\nthese models model leads to metaphors like \"artificial general intelligences\"\nthat are not helpful for evaluating their strengths and weaknesses. The\nproposal is to see their generality, and their potential value, in their\nability to approximate specialist function, based on a natural language\nspecification. This framing brings to the fore questions of the quality of the\napproximation, but beyond that, also questions of discoverability, stability,\nand protectability of these functions. As the paper will show, this framing\nhence brings together in one conceptual framework various aspects of\nevaluation, both from a practical and a theoretical perspective, as well as\nquestions often relegated to a secondary status (such as \"prompt injection\" and\n\"jailbreaking\")."
  },
  {
    "arxiv_id": "2407.13511",
    "title": "Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks",
    "url": "http://arxiv.org/abs/2407.13511v1",
    "abstract": "Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT\nand Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)\nbenchmarks across different domains. New competing Open-Source alternatives\nlike Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while\noften offering higher throughput and being less costly to use. Open-Source LLMs\ncan also be self-hosted, which makes them interesting for enterprise and\nclinical use cases where sensitive data should not be processed by third\nparties. We participated in the 12th BioASQ challenge, which is a retrieval\naugmented generation (RAG) setting, and explored the performance of current GPT\nmodels Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning\n(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional\nrelevant knowledge from Wikipedia added to the context-window of the LLM might\nimprove their performance. Mixtral 8x7b was competitive in the 10-shot setting,\nboth with and without fine-tuning, but failed to produce usable results in the\nzero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to\nmeasurable performance gains. Our results indicate that the performance gap\nbetween commercial and open-source models in RAG setups exists mainly in the\nzero-shot setting and can be closed by simply collecting few-shot examples for\ndomain-specific use cases. The code needed to rerun these experiments is\navailable through GitHub."
  },
  {
    "arxiv_id": "2407.13205",
    "title": "Transformer-based Single-Cell Language Model: A Survey",
    "url": "http://arxiv.org/abs/2407.13205v1",
    "abstract": "The transformers have achieved significant accomplishments in the natural\nlanguage processing as its outstanding parallel processing capabilities and\nhighly flexible attention mechanism. In addition, increasing studies based on\ntransformers have been proposed to model single-cell data. In this review, we\nattempt to systematically summarize the single-cell language models and\napplications based on transformers. First, we provide a detailed introduction\nabout the structure and principles of transformers. Then, we review the\nsingle-cell language models and large language models for single-cell data\nanalysis. Moreover, we explore the datasets and applications of single-cell\nlanguage models in downstream tasks such as batch correction, cell clustering,\ncell type annotation, gene regulatory network inference and perturbation\nresponse. Further, we discuss the challenges of single-cell language models and\nprovide promising research directions. We hope this review will serve as an\nup-to-date reference for researchers interested in the direction of single-cell\nlanguage models."
  },
  {
    "arxiv_id": "2407.13097",
    "title": "AlcLaM: Arabic Dialectal Language Model",
    "url": "http://arxiv.org/abs/2407.13097v1",
    "abstract": "Pre-trained Language Models (PLMs) are integral to many modern natural\nlanguage processing (NLP) systems. Although multilingual models cover a wide\nrange of languages, they often grapple with challenges like high inference\ncosts and a lack of diverse non-English training data. Arabic-specific PLMs are\ntrained predominantly on modern standard Arabic, which compromises their\nperformance on regional dialects. To tackle this, we construct an Arabic\ndialectal corpus comprising 3.4M sentences gathered from social media\nplatforms. We utilize this corpus to expand the vocabulary and retrain a\nBERT-based model from scratch. Named AlcLaM, our model was trained using only\n13 GB of text, which represents a fraction of the data used by existing models\nsuch as CAMeL, MARBERT, and ArBERT, compared to 7.8%, 10.2%, and 21.3%,\nrespectively. Remarkably, AlcLaM demonstrates superior performance on a variety\nof Arabic NLP tasks despite the limited training data. AlcLaM is available at\nGitHub https://github.com/amurtadha/Alclam and HuggingFace\nhttps://huggingface.co/rahbi."
  },
  {
    "arxiv_id": "2407.12994",
    "title": "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks",
    "url": "http://arxiv.org/abs/2407.12994v1",
    "abstract": "Large language models (LLMs) have shown remarkable performance on many\ndifferent Natural Language Processing (NLP) tasks. Prompt engineering plays a\nkey role in adding more to the already existing abilities of LLMs to achieve\nsignificant performance gains on various NLP tasks. Prompt engineering requires\ncomposing natural language instructions called prompts to elicit knowledge from\nLLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,\nprompt engineering does not require extensive parameter re-training or\nfine-tuning based on the given NLP task and thus solely operates on the\nembedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently\nextract LLMs' knowledge through a basic natural language conversational\nexchange or prompt engineering, allowing more and more people even without deep\nmathematical machine learning background to experiment with LLMs. With prompt\nengineering gaining popularity in the last two years, researchers have come up\nwith numerous engineering techniques around designing prompts to improve\naccuracy of information extraction from the LLMs. In this paper, we summarize\ndifferent prompting techniques and club them together based on different NLP\ntasks that they have been used for. We further granularly highlight the\nperformance of these prompting strategies on various datasets belonging to that\nNLP task, talk about the corresponding LLMs used, present a taxonomy diagram\nand discuss the possible SoTA for specific datasets. In total, we read and\npresent a survey of 44 research papers which talk about 39 different prompting\nmethods on 29 different NLP tasks of which most of them have been published in\nthe last two years."
  },
  {
    "arxiv_id": "2407.14112",
    "title": "Large Language Model Enabled Semantic Communication Systems",
    "url": "http://arxiv.org/abs/2407.14112v1",
    "abstract": "Large language models (LLMs) have recently demonstrated state-of-the-art\nperformance across various natural language processing (NLP) tasks, achieving\nnear-human levels in multiple language understanding challenges and aligning\nclosely with the core principles of semantic communication. Inspired by LLMs'\nadvancements in semantic processing, we propose an innovative LLM-enabled\nsemantic communication system framework, named LLM-SC, that applies LLMs\ndirectly to the physical layer coding and decoding for the first time. By\nanalyzing the relationship between the training process of LLMs and the\noptimization objectives of semantic communication, we propose training a\nsemantic encoder through LLMs' tokenizer training and establishing a semantic\nknowledge base via the LLMs' unsupervised pre-training process. This knowledge\nbase aids in constructing the optimal decoder by providing the prior\nprobability of the transmitted language sequence. Based on this foundation, we\nderive the optimal decoding criterion for the receiver and introduce the beam\nsearch algorithm to further reduce the complexity. Furthermore, we assert that\nexisting LLMs can be employed directly for LLM-SC without additional\nre-training or fine-tuning. Simulation results demonstrate that LLM-SC\noutperforms classical DeepSC at signal-to-noise ratios (SNR) exceeding 3 dB,\nenabling error-free transmission of semantic information under high SNR, which\nis unattainable by DeepSC. In addition to semantic-level performance, LLM-SC\ndemonstrates compatibility with technical-level performance, achieving\napproximately 8 dB coding gain for a bit error ratio (BER) of $10^{-3}$ without\nany channel coding while maintaining the same joint source-channel coding rate\nas traditional communication systems."
  },
  {
    "arxiv_id": "2407.13993",
    "title": "LLAssist: Simple Tools for Automating Literature Review Using Large Language Models",
    "url": "http://arxiv.org/abs/2407.13993v1",
    "abstract": "This paper introduces LLAssist, an open-source tool designed to streamline\nliterature reviews in academic research. In an era of exponential growth in\nscientific publications, researchers face mounting challenges in efficiently\nprocessing vast volumes of literature. LLAssist addresses this issue by\nleveraging Large Language Models (LLMs) and Natural Language Processing (NLP)\ntechniques to automate key aspects of the review process. Specifically, it\nextracts important information from research articles and evaluates their\nrelevance to user-defined research questions. The goal of LLAssist is to\nsignificantly reduce the time and effort required for comprehensive literature\nreviews, allowing researchers to focus more on analyzing and synthesizing\ninformation rather than on initial screening tasks. By automating parts of the\nliterature review workflow, LLAssist aims to help researchers manage the\ngrowing volume of academic publications more efficiently."
  },
  {
    "arxiv_id": "2407.13928",
    "title": "BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization",
    "url": "http://arxiv.org/abs/2407.13928v1",
    "abstract": "Large Language Models (LLMs) have become pivotal in advancing natural\nlanguage processing, yet their potential to perpetuate biases poses significant\nconcerns. This paper introduces a new framework employing Direct Preference\nOptimization (DPO) to mitigate gender, racial, and religious biases in\nLLM-generated English text. By developing a loss function that favors less\nbiased over biased completions, our approach cultivates a preference for\nrespectful and non-discriminatory language in LLMs. We also contribute a\nmanually designed dataset for training LLMs to recognize and correct biases.\nThis dataset encompasses a diverse range of prompts paired with both biased and\nunbiased completions. Implementing this approach on the Microsoft Phi-2 model,\nwe demonstrate substantial reductions in biased outputs as our model\noutperforms the baseline model on almost all bias benchmarks. Our model also\nachieves better performance compared to other open-source models on most\nbenchmarks. By reducing biases in the language generated by the model, our\nstudy marks a significant step towards developing more ethical and socially\nresponsible LLMs. We publicly release BiasDPO dataset on HuggingFace."
  },
  {
    "arxiv_id": "2407.15556",
    "title": "SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning",
    "url": "http://arxiv.org/abs/2407.15556v1",
    "abstract": "Text style transfer, an important research direction in natural language\nprocessing, aims to adapt the text to various preferences but often faces\nchallenges with limited resources. In this work, we introduce a novel method\ntermed Style Extraction and Tunable Inference via Dual-level Transferable\nPrompt Learning (SETTP) for effective style transfer in low-resource scenarios.\nFirst, SETTP learns source style-level prompts containing fundamental style\ncharacteristics from high-resource style transfer. During training, the source\nstyle-level prompts are transferred through an attention module to derive a\ntarget style-level prompt for beneficial knowledge provision in low-resource\nstyle transfer. Additionally, we propose instance-level prompts obtained by\nclustering the target resources based on the semantic content to reduce\nsemantic bias. We also propose an automated evaluation approach of style\nsimilarity based on alignment with human evaluations using ChatGPT-4. Our\nexperiments across three resourceful styles show that SETTP requires only\n1/20th of the data volume to achieve performance comparable to state-of-the-art\nmethods. In tasks involving scarce data like writing style and role style,\nSETTP outperforms previous methods by 16.24\\%."
  },
  {
    "arxiv_id": "2407.15459",
    "title": "Text-to-Battery Recipe: A language modeling-based protocol for automatic battery recipe extraction and retrieval",
    "url": "http://arxiv.org/abs/2407.15459v1",
    "abstract": "Recent studies have increasingly applied natural language processing (NLP) to\nautomatically extract experimental research data from the extensive battery\nmaterials literature. Despite the complex process involved in battery\nmanufacturing -- from material synthesis to cell assembly -- there has been no\ncomprehensive study systematically organizing this information. In response, we\npropose a language modeling-based protocol, Text-to-Battery Recipe (T2BR), for\nthe automatic extraction of end-to-end battery recipes, validated using a case\nstudy on batteries containing LiFePO4 cathode material. We report machine\nlearning-based paper filtering models, screening 2,174 relevant papers from the\nkeyword-based search results, and unsupervised topic models to identify 2,876\nparagraphs related to cathode synthesis and 2,958 paragraphs related to cell\nassembly. Then, focusing on the two topics, two deep learning-based named\nentity recognition models are developed to extract a total of 30 entities --\nincluding precursors, active materials, and synthesis methods -- achieving F1\nscores of 88.18% and 94.61%. The accurate extraction of entities enables the\nsystematic generation of 165 end-toend recipes of LiFePO4 batteries. Our\nprotocol and results offer valuable insights into specific trends, such as\nassociations between precursor materials and synthesis methods, or combinations\nbetween different precursor materials. We anticipate that our findings will\nserve as a foundational knowledge base for facilitating battery-recipe\ninformation retrieval. The proposed protocol will significantly accelerate the\nreview of battery material literature and catalyze innovations in battery\ndesign and development."
  },
  {
    "arxiv_id": "2407.15360",
    "title": "Dissecting Multiplication in Transformers: Insights into LLMs",
    "url": "http://arxiv.org/abs/2407.15360v1",
    "abstract": "Transformer-based large language models have achieved remarkable performance\nacross various natural language processing tasks. However, they often struggle\nwith seemingly easy tasks like arithmetic despite their vast capabilities. This\nstark disparity raise human's concerns about their safe and ethical use, hinder\ntheir widespread adoption.In this paper, we focus on a typical arithmetic task,\ninteger multiplication, to explore and explain the imperfection of transformers\nin this domain. We provide comprehensive analysis of a vanilla transformer\ntrained to perform n-digit integer multiplication. Our observations indicate\nthat the model decomposes multiplication task into multiple parallel subtasks,\nsequentially optimizing each subtask for each digit to complete the final\nmultiplication. Based on observation and analysis, we infer the reasons of\ntransformers deficiencies in multiplication tasks lies in their difficulty in\ncalculating successive carryovers and caching intermediate results, and\nconfirmed this inference through experiments. Guided by these findings, we\npropose improvements to enhance transformers performance on multiplication\ntasks. These enhancements are validated through rigorous testing and\nmathematical modeling, not only enhance transformer's interpretability, but\nalso improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit\ninteger multiplication with a tiny transformer, outperform LLMs GPT-4. Our\nmethod contributes to the broader fields of model understanding and\ninterpretability, paving the way for analyzing more complex tasks and\nTransformer models. This work underscores the importance of explainable AI,\nhelping to build trust in large language models and promoting their adoption in\ncritical applications."
  },
  {
    "arxiv_id": "2407.15071",
    "title": "Relational Database Augmented Large Language Model",
    "url": "http://arxiv.org/abs/2407.15071v1",
    "abstract": "Large language models (LLMs) excel in many natural language processing (NLP)\ntasks. However, since LLMs can only incorporate new knowledge through training\nor supervised fine-tuning processes, they are unsuitable for applications that\ndemand precise, up-to-date, and private information not available in the\ntraining corpora. This precise, up-to-date, and private information is\ntypically stored in relational databases. Thus, a promising solution is to\naugment LLMs with the inclusion of relational databases as external memory.\nThis can ensure the timeliness, correctness, and consistency of data, and\nassist LLMs in performing complex arithmetic operations beyond their inherent\ncapabilities. However, bridging the gap between LLMs and relational databases\nis challenging. It requires the awareness of databases and data values stored\nin databases to select correct databases and issue correct SQL queries.\nBesides, it is necessary for the external memory to be independent of the LLM\nto meet the needs of real-world applications. We introduce a novel LLM-agnostic\nmemory architecture comprising a database selection memory, a data value\nmemory, and relational databases. And we design an elegant pipeline to retrieve\ninformation from it. Besides, we carefully design the prompts to instruct the\nLLM to maximize the framework's potential. To evaluate our method, we compose a\nnew dataset with various types of questions. Experimental results show that our\nframework enables LLMs to effectively answer database-related questions, which\nis beyond their direct ability."
  },
  {
    "arxiv_id": "2407.16686",
    "title": "Can Large Language Models Automatically Jailbreak GPT-4V?",
    "url": "http://arxiv.org/abs/2407.16686v1",
    "abstract": "GPT-4V has attracted considerable attention due to its extraordinary capacity\nfor integrating and processing multimodal information. At the same time, its\nability of face recognition raises new safety concerns of privacy leakage.\nDespite researchers' efforts in safety alignment through RLHF or preprocessing\nfilters, vulnerabilities might still be exploited. In our study, we introduce\nAutoJailbreak, an innovative automatic jailbreak technique inspired by prompt\noptimization. We leverage Large Language Models (LLMs) for red-teaming to\nrefine the jailbreak prompt and employ weak-to-strong in-context learning\nprompts to boost efficiency. Furthermore, we present an effective search method\nthat incorporates early stopping to minimize optimization time and token\nexpenditure. Our experiments demonstrate that AutoJailbreak significantly\nsurpasses conventional methods, achieving an Attack Success Rate (ASR)\nexceeding 95.3\\%. This research sheds light on strengthening GPT-4V security,\nunderscoring the potential for LLMs to be exploited in compromising GPT-4V\nintegrity."
  },
  {
    "arxiv_id": "2407.17404",
    "title": "Grammar-based Game Description Generation using Large Language Models",
    "url": "http://arxiv.org/abs/2407.17404v1",
    "abstract": "Game Description Language (GDL) provides a standardized way to express\ndiverse games in a machine-readable format, enabling automated game simulation,\nand evaluation. While previous research has explored game description\ngeneration using search-based methods, generating GDL descriptions from natural\nlanguage remains a challenging task. This paper presents a novel framework that\nleverages Large Language Models (LLMs) to generate grammatically accurate game\ndescriptions from natural language. Our approach consists of two stages: first,\nwe gradually generate a minimal grammar based on GDL specifications; second, we\niteratively improve the game description through grammar-guided generation. Our\nframework employs a specialized parser that identifies valid subsequences and\ncandidate symbols from LLM responses, enabling gradual refinement of the output\nto ensure grammatical correctness. Experimental results demonstrate that our\niterative improvement approach significantly outperforms baseline methods that\ndirectly use LLM outputs. Our code is available at\nhttps://github.com/tsunehiko/ggdg"
  },
  {
    "arxiv_id": "2407.17730",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "url": "http://arxiv.org/abs/2407.17730v1",
    "abstract": "In contemporary society, the issue of psychological health has become\nincreasingly prominent, characterized by the diversification, complexity, and\nuniversality of mental disorders. Cognitive Behavioral Therapy (CBT), currently\nthe most influential and clinically effective psychological treatment method\nwith no side effects, has limited coverage and poor quality in most countries.\nIn recent years, researches on the recognition and intervention of emotional\ndisorders using large language models (LLMs) have been validated, providing new\npossibilities for psychological assistance therapy. However, are LLMs truly\npossible to conduct cognitive behavioral therapy? Many concerns have been\nraised by mental health experts regarding the use of LLMs for therapy. Seeking\nto answer this question, we collected real CBT corpus from online video\nwebsites, designed and conducted a targeted automatic evaluation framework\ninvolving the evaluation of emotion tendency of generated text, structured\ndialogue pattern and proactive inquiry ability. For emotion tendency, we\ncalculate the emotion tendency score of the CBT dialogue text generated by each\nmodel. For structured dialogue pattern, we use a diverse range of automatic\nevaluation metrics to compare speaking style, the ability to maintain\nconsistency of topic and the use of technology in CBT between different models\n. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning\nAbility) metric. We also evaluated the CBT ability of the LLM after integrating\na CBT knowledge base to explore the help of introducing additional knowledge to\nenhance the model's CBT counseling ability. Four LLM variants with excellent\nperformance on natural language processing are evaluated, and the experimental\nresult shows the great potential of LLMs in psychological counseling realm,\nespecially after combining with other technological means."
  },
  {
    "arxiv_id": "2407.17636",
    "title": "IgnitionInnovators at \"Discharge Me!\": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries",
    "url": "http://arxiv.org/abs/2407.17636v1",
    "abstract": "This paper presents our proposed approach to the Discharge Me! shared task,\ncollocated with the 23th Workshop on Biomedical Natural Language Processing\n(BioNLP). In this work, we develop an LLM-based framework for solving the\nDischarge Summary Documentation (DSD) task, i.e., generating the two critical\ntarget sections `Brief Hospital Course' and `Discharge Instructions' in the\ndischarge summary. By streamlining the recent instruction-finetuning process on\nLLMs, we explore several prompting strategies for optimally adapting LLMs to\nspecific generation task of DSD. Experimental results show that providing a\nclear output structure, complimented by a set of comprehensive\nChain-of-Thoughts (CoT) questions, effectively improves the model's reasoning\ncapability, and thereby, enhancing the structural correctness and faithfulness\nof clinical information in the generated text. Source code is available at:\nhttps://github.com/antangrocket1312/Discharge_LLM"
  },
  {
    "arxiv_id": "2407.18841",
    "title": "QT-TDM: Planning with Transformer Dynamics Model and Autoregressive Q-Learning",
    "url": "http://arxiv.org/abs/2407.18841v1",
    "abstract": "Inspired by the success of the Transformer architecture in natural language\nprocessing and computer vision, we investigate the use of Transformers in\nReinforcement Learning (RL), specifically in modeling the environment's\ndynamics using Transformer Dynamics Models (TDMs). We evaluate the capabilities\nof TDMs for continuous control in real-time planning scenarios with Model\nPredictive Control (MPC). While Transformers excel in long-horizon prediction,\ntheir tokenization mechanism and autoregressive nature lead to costly planning\nover long horizons, especially as the environment's dimensionality increases.\nTo alleviate this issue, we use a TDM for short-term planning, and learn an\nautoregressive discrete Q-function using a separate Q-Transformer (QT) model to\nestimate a long-term return beyond the short-horizon planning. Our proposed\nmethod, QT-TDM, integrates the robust predictive capabilities of Transformers\nas dynamics models with the efficacy of a model-free Q-Transformer to mitigate\nthe computational burden associated with real-time planning. Experiments in\ndiverse state-based continuous control tasks show that QT-TDM is superior in\nperformance and sample efficiency compared to existing Transformer-based RL\nmodels while achieving fast and computationally efficient inference."
  },
  {
    "arxiv_id": "2407.18723",
    "title": "LLASP: Fine-tuning Large Language Models for Answer Set Programming",
    "url": "http://arxiv.org/abs/2407.18723v1",
    "abstract": "Recently, Large Language Models (LLMs) have showcased their potential in\nvarious natural language processing tasks, including code generation. However,\nwhile significant progress has been made in adapting LLMs to generate code for\nseveral imperative programming languages and tasks, there remains a notable gap\nin their application to declarative formalisms, such as Answer Set Programming\n(ASP). In this paper, we move a step towards exploring the capabilities of LLMs\nfor ASP code generation. First, we perform a systematic evaluation of several\nstate-of-the-art LLMs. Despite their power in terms of number of parameters,\ntraining data and computational resources, empirical results demonstrate\ninadequate performances in generating correct ASP programs. Therefore, we\npropose LLASP, a fine-tuned lightweight model specifically trained to encode\nfundamental ASP program patterns. To this aim, we create an ad-hoc dataset\ncovering a wide variety of fundamental problem specifications that can be\nencoded in ASP. Our experiments demonstrate that the quality of ASP programs\ngenerated by LLASP is remarkable. This holds true not only when compared to the\nnon-fine-tuned counterpart but also when compared to the majority of eager LLM\ncandidates, particularly from a semantic perspective. All the code and data\nused to perform the experiments are publicly available at\nhttps://anonymous.4open.science/r/LLASP-D86C/."
  },
  {
    "arxiv_id": "2407.18540",
    "title": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models",
    "url": "http://arxiv.org/abs/2407.18540v1",
    "abstract": "Over the past decade, extensive research efforts have been dedicated to the\nextraction of information from textual process descriptions. Despite the\nremarkable progress witnessed in natural language processing (NLP), information\nextraction within the Business Process Management domain remains predominantly\nreliant on rule-based systems and machine learning methodologies. Data scarcity\nhas so far prevented the successful application of deep learning techniques.\nHowever, the rapid progress in generative large language models (LLMs) makes it\npossible to solve many NLP tasks with very high quality without the need for\nextensive data. Therefore, we systematically investigate the potential of LLMs\nfor extracting information from textual process descriptions, targeting the\ndetection of process elements such as activities and actors, and relations\nbetween them. Using a heuristic algorithm, we demonstrate the suitability of\nthe extracted information for process model generation. Based on a novel\nprompting strategy, we show that LLMs are able to outperform state-of-the-art\nmachine learning approaches with absolute performance improvements of up to 8\\%\n$F_1$ score across three different datasets. We evaluate our prompting strategy\non eight different LLMs, showing it is universally applicable, while also\nanalyzing the impact of certain prompt parts on extraction quality. The number\nof example texts, the specificity of definitions, and the rigour of format\ninstructions are identified as key for improving the accuracy of extracted\ninformation. Our code, prompts, and data are publicly available."
  },
  {
    "arxiv_id": "2407.18454",
    "title": "Fairness Definitions in Language Models Explained",
    "url": "http://arxiv.org/abs/2407.18454v1",
    "abstract": "Language Models (LMs) have demonstrated exceptional performance across\nvarious Natural Language Processing (NLP) tasks. Despite these advancements,\nLMs can inherit and amplify societal biases related to sensitive attributes\nsuch as gender and race, limiting their adoption in real-world applications.\nTherefore, fairness has been extensively explored in LMs, leading to the\nproposal of various fairness notions. However, the lack of clear agreement on\nwhich fairness definition to apply in specific contexts (\\textit{e.g.,}\nmedium-sized LMs versus large-sized LMs) and the complexity of understanding\nthe distinctions between these definitions can create confusion and impede\nfurther progress. To this end, this paper proposes a systematic survey that\nclarifies the definitions of fairness as they apply to LMs. Specifically, we\nbegin with a brief introduction to LMs and fairness in LMs, followed by a\ncomprehensive, up-to-date overview of existing fairness notions in LMs and the\nintroduction of a novel taxonomy that categorizes these concepts based on their\nfoundational principles and operational distinctions. We further illustrate\neach definition through experiments, showcasing their practical implications\nand outcomes. Finally, we discuss current research challenges and open\nquestions, aiming to foster innovative ideas and advance the field. The\nimplementation and additional resources are publicly available at\nhttps://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions."
  },
  {
    "arxiv_id": "2407.18442",
    "title": "Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition",
    "url": "http://arxiv.org/abs/2407.18442v1",
    "abstract": "While the abundance of rich and vast datasets across numerous fields has\nfacilitated the advancement of natural language processing, sectors in need of\nspecialized data types continue to struggle with the challenge of finding\nquality data. Our study introduces a novel guidance data augmentation technique\nutilizing abstracted context and sentence structures to produce varied\nsentences while maintaining context-entity relationships, addressing data\nscarcity challenges. By fostering a closer relationship between context,\nsentence structure, and role of entities, our method enhances data\naugmentation's effectiveness. Consequently, by showcasing diversification in\nboth entity-related vocabulary and overall sentence structure, and\nsimultaneously improving the training performance of named entity recognition\ntask."
  },
  {
    "arxiv_id": "2407.20046",
    "title": "Exploring Large Language Models to generate Easy to Read content",
    "url": "http://arxiv.org/abs/2407.20046v1",
    "abstract": "Ensuring text accessibility and understandability are essential goals,\nparticularly for individuals with cognitive impairments and intellectual\ndisabilities, who encounter challenges in accessing information across various\nmediums such as web pages, newspapers, administrative tasks, or health\ndocuments. Initiatives like Easy to Read and Plain Language guidelines aim to\nsimplify complex texts; however, standardizing these guidelines remains\nchallenging and often involves manual processes. This work presents an\nexploratory investigation into leveraging Artificial Intelligence (AI) and\nNatural Language Processing (NLP) approaches to systematically simplify Spanish\ntexts into Easy to Read formats, with a focus on utilizing Large Language\nModels (LLMs) for simplifying texts, especially in generating Easy to Read\ncontent. The study contributes a parallel corpus of Spanish adapted for Easy To\nRead format, which serves as a valuable resource for training and testing text\nsimplification systems. Additionally, several text simplification experiments\nusing LLMs and the collected corpus are conducted, involving fine-tuning and\ntesting a Llama2 model to generate Easy to Read content. A qualitative\nevaluation, guided by an expert in text adaptation for Easy to Read content, is\ncarried out to assess the automatically simplified texts. This research\ncontributes to advancing text accessibility for individuals with cognitive\nimpairments, highlighting promising strategies for leveraging LLMs while\nresponsibly managing energy usage."
  },
  {
    "arxiv_id": "2407.19998",
    "title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective",
    "url": "http://arxiv.org/abs/2407.19998v1",
    "abstract": "Large Language Models (LLMs) have demonstrated unprecedented prowess across\nvarious natural language processing tasks in various application domains.\nRecent studies show that LLMs can be leveraged to perform lexical semantic\ntasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).\nHowever, it has not effectively been verified whether their success is due to\ntheir ability to reason over unstructured or semi-structured data, or their\neffective learning of linguistic patterns and senses alone. This unresolved\nquestion is particularly crucial when dealing with domain-specific data, where\nthe lexical senses and their meaning can completely differ from what a LLM has\nlearned during its training stage. This paper investigates the following\nquestion: Do LLMs really adapt to domains and remain consistent in the\nextraction of structured knowledge, or do they only learn lexical senses\ninstead of reasoning? To answer this question and, we devise a controlled\nexperiment setup that uses WordNet to synthesize parallel corpora, with English\nand gibberish terms. We examine the differences in the outputs of LLMs for each\ncorpus in two OL tasks: relation extraction and taxonomy discovery. Empirical\nresults show that, while adapting to the gibberish corpora, off-the-shelf LLMs\ndo not consistently reason over semantic relationships between concepts, and\ninstead leverage senses and their frame. However, fine-tuning improves the\nperformance of LLMs on lexical semantic tasks even when the domain-specific\nterms are arbitrary and unseen during pre-training, hinting at the\napplicability of pre-trained LLMs for OL."
  },
  {
    "arxiv_id": "2407.19942",
    "title": "Predicting citation impact of research papers using GPT and other text embeddings",
    "url": "http://arxiv.org/abs/2407.19942v1",
    "abstract": "The impact of research papers, typically measured in terms of citation\ncounts, depends on several factors, including the reputation of the authors,\njournals, and institutions, in addition to the quality of the scientific work.\nIn this paper, we present an approach that combines natural language processing\nand machine learning to predict the impact of papers in a specific journal. Our\nfocus is on the text, which should correlate with impact and the topics covered\nin the research. We employed a dataset of over 40,000 articles from ACS Applied\nMaterials and Interfaces spanning from 2012 to 2022. The data was processed\nusing various text embedding techniques and classified with supervised machine\nlearning algorithms. Papers were categorized into the top 20% most cited within\nthe journal, using both yearly and cumulative citation counts as metrics. Our\nanalysis reveals that the method employing generative pre-trained transformers\n(GPT) was the most efficient for embedding, while the random forest algorithm\nexhibited the best predictive power among the machine learning algorithms. An\noptimized accuracy of 80\\% in predicting whether a paper was among the top 20%\nmost cited was achieved for the cumulative citation count when abstracts were\nprocessed. This accuracy is noteworthy, considering that author, institution,\nand early citation pattern information were not taken into account. The\naccuracy increased only slightly when the full texts of the papers were\nprocessed. Also significant is the finding that a simpler embedding technique,\nterm frequency-inverse document frequency (TFIDF), yielded performance close to\nthat of GPT. Since TFIDF captures the topics of the paper we infer that, apart\nfrom considering author and institution biases, citation counts for the\nconsidered journal may be predicted by identifying topics and \"reading\" the\nabstract of a paper."
  },
  {
    "arxiv_id": "2407.19914",
    "title": "Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models",
    "url": "http://arxiv.org/abs/2407.19914v1",
    "abstract": "Sentiment analysis is a widely researched area within Natural Language\nProcessing (NLP), attracting significant interest due to the advent of\nautomated solutions. Despite this, the task remains challenging because of the\ninherent complexity of languages and the subjective nature of sentiments. It is\neven more challenging for less-studied and less-resourced languages such as\nLithuanian. Our review of existing Lithuanian NLP research reveals that\ntraditional machine learning methods and classification algorithms have limited\neffectiveness for the task. In this work, we address sentiment analysis of\nLithuanian five-star-based online reviews from multiple domains that we collect\nand clean. We apply transformer models to this task for the first time,\nexploring the capabilities of pre-trained multilingual Large Language Models\n(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the\ninherent difficulty of the task, the fine-tuned models perform quite well,\nespecially when the sentiments themselves are less ambiguous: 80.74% and 89.61%\ntesting recognition accuracy of the most popular one- and five-star reviews\nrespectively. They significantly outperform current commercial state-of-the-art\ngeneral-purpose LLM GPT-4. We openly share our fine-tuned LLMs online."
  },
  {
    "arxiv_id": "2407.19893",
    "title": "Leveraging Foundation Models for Zero-Shot IoT Sensing",
    "url": "http://arxiv.org/abs/2407.19893v1",
    "abstract": "Deep learning models are increasingly deployed on edge Internet of Things\n(IoT) devices. However, these models typically operate under supervised\nconditions and fail to recognize unseen classes different from training. To\naddress this, zero-shot learning (ZSL) aims to classify data of unseen classes\nwith the help of semantic information. Foundation models (FMs) trained on\nweb-scale data have shown impressive ZSL capability in natural language\nprocessing and visual understanding. However, leveraging FMs' generalized\nknowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and\nWi-Fi has not been fully investigated. In this work, we align the IoT data\nembeddings with the semantic embeddings generated by an FM's text encoder for\nzero-shot IoT sensing. To utilize the physics principles governing the\ngeneration of IoT sensor signals to derive more effective prompts for semantic\nembedding extraction, we propose to use cross-attention to combine a learnable\nsoft prompt that is optimized automatically on training data and an auxiliary\nhard prompt that encodes domain knowledge of the IoT sensing task. To address\nthe problem of IoT embeddings biasing to seen classes due to the lack of unseen\nclass data during training, we propose using data augmentation to synthesize\nunseen class IoT data for fine-tuning the IoT feature extractor and embedding\nprojector. We evaluate our approach on multiple IoT sensing tasks. Results show\nthat our approach achieves superior open-set detection and generalized\nzero-shot learning performance compared with various baselines. Our code is\navailable at https://github.com/schrodingho/FM\\_ZSL\\_IoT."
  },
  {
    "arxiv_id": "2407.19816",
    "title": "Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies",
    "url": "http://arxiv.org/abs/2407.19816v1",
    "abstract": "The labor market is undergoing rapid changes, with increasing demands on job\nseekers and a surge in job openings. Identifying essential skills and\ncompetencies from job descriptions is challenging due to varying employer\nrequirements and the omission of key skills. This study addresses these\nchallenges by comparing traditional Named Entity Recognition (NER) methods\nbased on encoders with Large Language Models (LLMs) for extracting skills from\nRussian job vacancies. Using a labeled dataset of 4,000 job vacancies for\ntraining and 1,472 for testing, the performance of both approaches is\nevaluated. Results indicate that traditional NER models, especially DeepPavlov\nRuBERT NER tuned, outperform LLMs across various metrics including accuracy,\nprecision, recall, and inference time. The findings suggest that traditional\nNER models provide more effective and efficient solutions for skill extraction,\nenhancing job requirement clarity and aiding job seekers in aligning their\nqualifications with employer expectations. This research contributes to the\nfield of natural language processing (NLP) and its application in the labor\nmarket, particularly in non-English contexts."
  },
  {
    "arxiv_id": "2407.19784",
    "title": "Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting",
    "url": "http://arxiv.org/abs/2407.19784v1",
    "abstract": "Alongside the continuous process of improving AI performance through the\ndevelopment of more sophisticated models, researchers have also focused their\nattention to the emerging concept of data-centric AI, which emphasizes the\nimportant role of data in a systematic machine learning training process.\nNonetheless, the development of models has also continued apace. One result of\nthis progress is the development of the Transformer Architecture, which\npossesses a high level of capability in multiple domains such as Natural\nLanguage Processing (NLP), Computer Vision (CV) and Time Series Forecasting\n(TSF). Its performance is, however, heavily dependent on input data\npreprocessing and output data evaluation, justifying a data-centric approach to\nfuture research. We argue that data-centric AI is essential for training AI\nmodels, particularly for transformer-based TSF models efficiently. However,\nthere is a gap regarding the integration of transformer-based TSF and\ndata-centric AI. This survey aims to pin down this gap via the extensive\nliterature review based on the proposed taxonomy. We review the previous\nresearch works from a data-centric AI perspective and we intend to lay the\nfoundation work for the future development of transformer-based architecture\nand data-centric AI."
  },
  {
    "arxiv_id": "2407.20729",
    "title": "Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework",
    "url": "http://arxiv.org/abs/2407.20729v1",
    "abstract": "As large language models (LLMs) become increasingly integrated into\noperational workflows (LLM-Ops), there is a pressing need for effective\nguardrails to ensure safe and aligned interactions, including the ability to\ndetect potentially unsafe or inappropriate content across languages. However,\nexisting safe-for-work classifiers are primarily focused on English text. To\naddress this gap for the Malaysian language, we present a novel safe-for-work\ntext classifier tailored specifically for Malaysian language content. By\ncurating and annotating a first-of-its-kind dataset of Malaysian text spanning\nmultiple content categories, we trained a classification model capable of\nidentifying potentially unsafe material using state-of-the-art natural language\nprocessing techniques. This work represents an important step in enabling safer\ninteractions and content filtering to mitigate potential risks and ensure\nresponsible deployment of LLMs. To maximize accessibility and promote further\nresearch towards enhancing alignment in LLM-Ops for the Malaysian context, the\nmodel is publicly released at\nhttps://huggingface.co/malaysia-ai/malaysian-sfw-classifier."
  },
  {
    "arxiv_id": "2407.20564",
    "title": "CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge",
    "url": "http://arxiv.org/abs/2407.20564v1",
    "abstract": "While large language models (LLMs) have demonstrated impressive capabilities\nacross various natural language processing tasks by acquiring rich factual\nknowledge from their broad training data, their ability to synthesize and\nlogically reason with this knowledge in complex ways remains underexplored. In\nthis work, we present a systematic evaluation of state-of-the-art LLMs' complex\nlogical reasoning abilities through a novel benchmark of automatically\ngenerated complex reasoning questions over general domain and biomedical\nknowledge graphs. Our extensive experiments, employing diverse in-context\nlearning techniques, reveal that LLMs excel at reasoning over general world\nknowledge but face significant challenges with specialized domain-specific\nknowledge. We find that prompting with explicit Chain-of-Thought demonstrations\ncan substantially improve LLM performance on complex logical reasoning tasks\nwith diverse logical operations. Interestingly, our controlled evaluations\nuncover an asymmetry where LLMs display proficiency at set union operations,\nbut struggle considerably with set intersections - a key building block of\nlogical reasoning. To foster further work, we will publicly release our\nevaluation benchmark and code."
  },
  {
    "arxiv_id": "2407.20529",
    "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
    "url": "http://arxiv.org/abs/2407.20529v1",
    "abstract": "The advent of Large Language Models (LLMs) has garnered significant\npopularity and wielded immense power across various domains within Natural\nLanguage Processing (NLP). While their capabilities are undeniably impressive,\nit is crucial to identify and scrutinize their vulnerabilities especially when\nthose vulnerabilities can have costly consequences. One such LLM, trained to\nprovide a concise summarization from medical documents could unequivocally leak\npersonal patient data when prompted surreptitiously. This is just one of many\nunfortunate examples that have been unveiled and further research is necessary\nto comprehend the underlying reasons behind such vulnerabilities. In this\nstudy, we delve into multiple sections of vulnerabilities which are\nmodel-based, training-time, inference-time vulnerabilities, and discuss\nmitigation strategies including \"Model Editing\" which aims at modifying LLMs\nbehavior, and \"Chroma Teaming\" which incorporates synergy of multiple teaming\nstrategies to enhance LLMs' resilience. This paper will synthesize the findings\nfrom each vulnerability section and propose new directions of research and\ndevelopment. By understanding the focal points of current vulnerabilities, we\ncan better anticipate and mitigate future risks, paving the road for more\nrobust and secure LLMs."
  },
  {
    "arxiv_id": "2408.00357",
    "title": "DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model",
    "url": "http://arxiv.org/abs/2408.00357v1",
    "abstract": "Traditional legal retrieval systems designed to retrieve legal documents,\nstatutes, precedents, and other legal information are unable to give\nsatisfactory answers due to lack of semantic understanding of specific\nquestions. Large Language Models (LLMs) have achieved excellent results in a\nvariety of natural language processing tasks, which inspired us that we train a\nLLM in the legal domain to help legal retrieval. However, in the Chinese legal\ndomain, due to the complexity of legal questions and the rigour of legal\narticles, there is no legal large model with satisfactory practical application\nyet. In this paper, we present DeliLaw, a Chinese legal counselling system\nbased on a large language model. DeliLaw integrates a legal retrieval module\nand a case retrieval module to overcome the model hallucination. Users can\nconsult professional legal questions, search for legal articles and relevant\njudgement cases, etc. on the DeliLaw system in a dialogue mode. In addition,\nDeliLaw supports the use of English for counseling. we provide the address of\nthe system: https://data.delilegal.com/lawQuestion."
  },
  {
    "arxiv_id": "2408.00197",
    "title": "Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models",
    "url": "http://arxiv.org/abs/2408.00197v1",
    "abstract": "Generative Pre-Trained Transformer models have been shown to be surprisingly\neffective at a variety of natural language processing tasks -- including\ngenerating computer code. We evaluate the effectiveness of open source GPT\nmodels for the task of automatic identification of the presence of vulnerable\ncode syntax (specifically targeting C and C++ source code). This task is\nevaluated on a selection of 36 source code examples from the NIST SARD dataset,\nwhich are specifically curated to not contain natural English that indicates\nthe presence, or lack thereof, of a particular vulnerability. The NIST SARD\nsource code dataset contains identified vulnerable lines of source code that\nare examples of one out of the 839 distinct Common Weakness Enumerations (CWE),\nallowing for exact quantification of the GPT output classification error rate.\nA total of 5 GPT models are evaluated, using 10 different inference\ntemperatures and 100 repetitions at each setting, resulting in 5,000 GPT\nqueries per vulnerable source code analyzed. Ultimately, we find that the GPT\nmodels that we evaluated are not suitable for fully automated vulnerability\nscanning because the false positive and false negative rates are too high to\nlikely be useful in practice. However, we do find that the GPT models perform\nsurprisingly well at automated vulnerability detection for some of the test\ncases, in particular surpassing random sampling, and being able to identify the\nexact lines of code that are vulnerable albeit at a low success rate. The best\nperforming GPT model result found was Llama-2-70b-chat-hf with inference\ntemperature of 0.1 applied to NIST SARD test case 149165 (which is an example\nof a buffer overflow vulnerability), which had a binary classification recall\nscore of 1.0 and a precision of 1.0 for correctly and uniquely identifying the\nvulnerable line of code and the correct CWE number."
  },
  {
    "arxiv_id": "2408.00161",
    "title": "Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting",
    "url": "http://arxiv.org/abs/2408.00161v1",
    "abstract": "Recent work in behavioral testing for natural language processing (NLP)\nmodels, such as Checklist, is inspired by related paradigms in software\nengineering testing. They allow evaluation of general linguistic capabilities\nand domain understanding, hence can help evaluate conceptual soundness and\nidentify model weaknesses. However, a major challenge is the creation of test\ncases. The current packages rely on semi-automated approach using manual\ndevelopment which requires domain expertise and can be time consuming. This\npaper introduces an automated approach to develop test cases by exploiting the\npower of large language models and statistical techniques. It clusters the text\nrepresentations to carefully construct meaningful groups and then apply\nprompting techniques to automatically generate Minimal Functionality Tests\n(MFT). The well-known Amazon Reviews corpus is used to demonstrate our\napproach. We analyze the behavioral test profiles across four different\nclassification algorithms and discuss the limitations and strengths of those\nmodels."
  },
  {
    "arxiv_id": "2408.01423",
    "title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting",
    "url": "http://arxiv.org/abs/2408.01423v1",
    "abstract": "Large Language Models (LLMs) exhibit remarkable proficiency in addressing a\ndiverse array of tasks within the Natural Language Processing (NLP) domain,\nwith various prompt design strategies significantly augmenting their\ncapabilities. However, these prompts, while beneficial, each possess inherent\nlimitations. The primary prompt design methodologies are twofold: The first,\nexemplified by the Chain of Thought (CoT), involves manually crafting prompts\nspecific to individual datasets, hence termed Expert-Designed Prompts (EDPs).\nOnce these prompts are established, they are unalterable, and their\neffectiveness is capped by the expertise of the human designers. When applied\nto LLMs, the static nature of EDPs results in a uniform approach to both simple\nand complex problems within the same dataset, leading to the inefficient use of\ntokens for straightforward issues. The second method involves prompts\nautonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which\nprovide tailored solutions to specific problems, mitigating the limitations of\nEDPs. However, LDPs may encounter a decline in performance when tackling\ncomplex problems due to the potential for error accumulation during the\nsolution planning process. To address these challenges, we have conceived a\nnovel Prompt Recursive Search (PRS) framework that leverages the LLM to\ngenerate solutions specific to the problem, thereby conserving tokens. The\nframework incorporates an assessment of problem complexity and an adjustable\nstructure, ensuring a reduction in the likelihood of errors. We have\nsubstantiated the efficacy of PRS framework through extensive experiments using\nLLMs with different numbers of parameters across a spectrum of datasets in\nvarious domains. Compared to the CoT method, the PRS method has increased the\naccuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%\nimprovement."
  },
  {
    "arxiv_id": "2408.01308",
    "title": "Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2408.01308v1",
    "abstract": "Learning token embeddings based on token co-occurrence statistics has proven\neffective for both pre-training and fine-tuning in natural language processing.\nHowever, recent studies have pointed out that the distribution of learned\nembeddings degenerates into anisotropy (i.e., non-uniform distribution), and\neven pre-trained language models (PLMs) suffer from a loss of semantics-related\ninformation in embeddings for low-frequency tokens. This study first analyzes\nthe fine-tuning dynamics of encoder-based PLMs and demonstrates their\nrobustness against degeneration. On the basis of this analysis, we propose\nDefinitionEMB, a method that utilizes definitions to re-construct isotropically\ndistributed and semantics-related token embeddings for encoder-based PLMs while\nmaintaining original robustness during fine-tuning. Our experiments demonstrate\nthe effectiveness of leveraging definitions from Wiktionary to re-construct\nsuch embeddings for two encoder-based PLMs: RoBERTa-base and BART-large.\nFurthermore, the re-constructed embeddings for low-frequency tokens improve the\nperformance of these models across various GLUE and four text summarization\ndatasets."
  },
  {
    "arxiv_id": "2408.01168",
    "title": "Misinforming LLMs: vulnerabilities, challenges and opportunities",
    "url": "http://arxiv.org/abs/2408.01168v1",
    "abstract": "Large Language Models (LLMs) have made significant advances in natural\nlanguage processing, but their underlying mechanisms are often misunderstood.\nDespite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely\non statistical patterns in word embeddings rather than true cognitive\nprocesses. This leads to vulnerabilities such as \"hallucination\" and\nmisinformation. The paper argues that current LLM architectures are inherently\nuntrustworthy due to their reliance on correlations of sequential patterns of\nword embedding vectors. However, ongoing research into combining generative\ntransformer-based models with fact bases and logic programming languages may\nlead to the development of trustworthy LLMs capable of generating statements\nbased on given truth and explaining their self-reasoning process."
  },
  {
    "arxiv_id": "2408.01063",
    "title": "Leveraging Large Language Models for Mobile App Review Feature Extraction",
    "url": "http://arxiv.org/abs/2408.01063v1",
    "abstract": "Mobile app review analysis presents unique challenges due to the low quality,\nsubjective bias, and noisy content of user-generated documents. Extracting\nfeatures from these reviews is essential for tasks such as feature\nprioritization and sentiment analysis, but it remains a challenging task.\nMeanwhile, encoder-only models based on the Transformer architecture have shown\npromising results for classification and information extraction tasks for\nmultiple software engineering processes. This study explores the hypothesis\nthat encoder-only large language models can enhance feature extraction from\nmobile app reviews. By leveraging crowdsourced annotations from an industrial\ncontext, we redefine feature extraction as a supervised token classification\ntask. Our approach includes extending the pre-training of these models with a\nlarge corpus of user reviews to improve contextual understanding and employing\ninstance selection techniques to optimize model fine-tuning. Empirical\nevaluations demonstrate that this method improves the precision and recall of\nextracted features and enhances performance efficiency. Key contributions\ninclude a novel approach to feature extraction, annotated datasets, extended\npre-trained models, and an instance selection mechanism for cost-effective\nfine-tuning. This research provides practical methods and empirical evidence in\napplying large language models to natural language processing tasks within\nmobile app reviews, offering improved performance in feature extraction."
  },
  {
    "arxiv_id": "2408.01008",
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "url": "http://arxiv.org/abs/2408.01008v1",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms."
  },
  {
    "arxiv_id": "2408.02584",
    "title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization",
    "url": "http://arxiv.org/abs/2408.02584v1",
    "abstract": "The ever-increasing volume of digital information necessitates efficient\nmethods for users to extract key insights from lengthy documents. Aspect-based\nsummarization offers a targeted approach, generating summaries focused on\nspecific aspects within a document. Despite advancements in aspect-based\nsummarization research, there is a continuous quest for improved model\nperformance. Given that large language models (LLMs) have demonstrated the\npotential to revolutionize diverse tasks within natural language processing,\nparticularly in the problem of summarization, this paper explores the potential\nof fine-tuning LLMs for the aspect-based summarization task. We evaluate the\nimpact of fine-tuning open-source foundation LLMs, including Llama2, Mistral,\nGemma and Aya, on a publicly available domain-specific aspect based summary\ndataset. We hypothesize that this approach will enable these models to\neffectively identify and extract aspect-related information, leading to\nsuperior quality aspect-based summaries compared to the state-of-the-art. We\nestablish a comprehensive evaluation framework to compare the performance of\nfine-tuned LLMs against competing aspect-based summarization methods and\nvanilla counterparts of the fine-tuned LLMs. Our work contributes to the field\nof aspect-based summarization by demonstrating the efficacy of fine-tuning LLMs\nfor generating high-quality aspect-based summaries. Furthermore, it opens doors\nfor further exploration of using LLMs for targeted information extraction tasks\nacross various NLP domains."
  },
  {
    "arxiv_id": "2408.02313",
    "title": "A Lean Transformer Model for Dynamic Malware Analysis and Detection",
    "url": "http://arxiv.org/abs/2408.02313v1",
    "abstract": "Malware is a fast-growing threat to the modern computing world and existing\nlines of defense are not efficient enough to address this issue. This is mainly\ndue to the fact that many prevention solutions rely on signature-based\ndetection methods that can easily be circumvented by hackers. Therefore, there\nis a recurrent need for behavior-based analysis where a suspicious file is ran\nin a secured environment and its traces are collected to reports for analysis.\nPrevious works have shown some success leveraging Neural Networks and API calls\nsequences extracted from these execution reports.\n  Recently, Large Language Models and Generative AI have demonstrated\nimpressive capabilities mainly in Natural Language Processing tasks and\npromising applications in the cybersecurity field for both attackers and\ndefenders.\n  In this paper, we design an Encoder-Only model, based on the Transformers\narchitecture, to detect malicious files, digesting their API call sequences\ncollected by an execution emulation solution. We are also limiting the size of\nthe model architecture and the number of its parameters since it is often\nconsidered that Large Language Models may be overkill for specific tasks such\nas the one we are dealing with hereafter. In addition to achieving decent\ndetection results, this approach has the advantage of reducing our carbon\nfootprint by limiting training and inference times and facilitating technical\noperations with less hardware requirements.\n  We also carry out some analysis of our results and highlight the limits and\npossible improvements when using Transformers to analyze malicious files."
  },
  {
    "arxiv_id": "2408.02302",
    "title": "SNFinLLM: Systematic and Nuanced Financial Domain Adaptation of Chinese Large Language Models",
    "url": "http://arxiv.org/abs/2408.02302v1",
    "abstract": "Large language models (LLMs) have become powerful tools for advancing natural\nlanguage processing applications in the financial industry. However, existing\nfinancial LLMs often face challenges such as hallucinations or superficial\nparameter training, resulting in suboptimal performance, particularly in\nfinancial computing and machine reading comprehension (MRC). To address these\nissues, we propose a novel large language model specifically designed for the\nChinese financial domain, named SNFinLLM. SNFinLLM excels in domain-specific\ntasks such as answering questions, summarizing financial research reports,\nanalyzing sentiment, and executing financial calculations. We then perform the\nsupervised fine-tuning (SFT) to enhance the model's proficiency across various\nfinancial domains. Specifically, we gather extensive financial data and create\na high-quality instruction dataset composed of news articles, professional\npapers, and research reports of finance domain. Utilizing both domain-specific\nand general datasets, we proceed with continuous pre-training on an established\nopen-source base model, resulting in SNFinLLM-base. Following this, we engage\nin supervised fine-tuning (SFT) to bolster the model's capability across\nmultiple financial tasks. Crucially, we employ a straightforward Direct\nPreference Optimization (DPO) method to better align the model with human\npreferences. Extensive experiments conducted on finance benchmarks and our\nevaluation dataset demonstrate that SNFinLLM markedly outperforms other\nstate-of-the-art financial language models. For more details, check out our\ndemo video here: https://www.youtube.com/watch?v=GYT-65HZwus."
  },
  {
    "arxiv_id": "2408.02237",
    "title": "Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings",
    "url": "http://arxiv.org/abs/2408.02237v1",
    "abstract": "Large language models (LLMs) have garnered significant interest in natural\nlanguage processing (NLP), particularly their remarkable performance in various\ndownstream tasks in resource-rich languages. Recent studies have highlighted\nthe limitations of LLMs in low-resource languages, primarily focusing on binary\nclassification tasks and giving minimal attention to South Asian languages.\nThese limitations are primarily attributed to constraints such as dataset\nscarcity, computational costs, and research gaps specific to low-resource\nlanguages. To address this gap, we present datasets for sentiment and hate\nspeech tasks by translating from English to Bangla, Hindi, and Urdu,\nfacilitating research in low-resource language processing. Further, we\ncomprehensively examine zero-shot learning using multiple LLMs in English and\nwidely spoken South Asian languages. Our findings indicate that GPT-4\nconsistently outperforms Llama 2 and Gemini, with English consistently\ndemonstrating superior performance across diverse tasks compared to\nlow-resource languages. Furthermore, our analysis reveals that natural language\ninference (NLI) exhibits the highest performance among the evaluated tasks,\nwith GPT-4 demonstrating superior capabilities."
  },
  {
    "arxiv_id": "2408.02085",
    "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
    "url": "http://arxiv.org/abs/2408.02085v1",
    "abstract": "Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between the latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering."
  },
  {
    "arxiv_id": "2408.03195",
    "title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning",
    "url": "http://arxiv.org/abs/2408.03195v1",
    "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency. The code is\navailable at https://github.com/JasonZhujp/RELIEF."
  },
  {
    "arxiv_id": "2408.03150",
    "title": "Conditioning LLMs with Emotion in Neural Machine Translation",
    "url": "http://arxiv.org/abs/2408.03150v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in Natural\nLanguage Processing tasks, including Machine Translation (MT). In this work, we\npropose a novel MT pipeline that integrates emotion information extracted from\na Speech Emotion Recognition (SER) model into LLMs to enhance translation\nquality. We first fine-tune five existing LLMs on the Libri-trans dataset and\nselect the most performant model. Subsequently, we augment LLM prompts with\ndifferent dimensional emotions and train the selected LLM under these different\nconfigurations. Our experiments reveal that integrating emotion information,\nespecially arousal, into LLM prompts leads to notable improvements in\ntranslation quality."
  },
  {
    "arxiv_id": "2408.03130",
    "title": "Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations",
    "url": "http://arxiv.org/abs/2408.03130v1",
    "abstract": "Large language models are ubiquitous in natural language processing because\nthey can adapt to new tasks without retraining. However, their sheer scale and\ncomplexity present unique challenges and opportunities, prompting researchers\nand practitioners to explore novel model training, optimization, and deployment\nmethods. This literature review focuses on various techniques for reducing\nresource requirements and compressing large language models, including\nquantization, pruning, knowledge distillation, and architectural optimizations.\nThe primary objective is to explore each method in-depth and highlight its\nunique challenges and practical applications. The discussed methods are\ncategorized into a taxonomy that presents an overview of the optimization\nlandscape and helps navigate it to understand the research trajectory better."
  },
  {
    "arxiv_id": "2408.03119",
    "title": "Evaluating the Translation Performance of Large Language Models Based on Euas-20",
    "url": "http://arxiv.org/abs/2408.03119v1",
    "abstract": "In recent years, with the rapid development of deep learning technology,\nlarge language models (LLMs) such as BERT and GPT have achieved breakthrough\nresults in natural language processing tasks. Machine translation (MT), as one\nof the core tasks of natural language processing, has also benefited from the\ndevelopment of large language models and achieved a qualitative leap. Despite\nthe significant progress in translation performance achieved by large language\nmodels, machine translation still faces many challenges. Therefore, in this\npaper, we construct the dataset Euas-20 to evaluate the performance of large\nlanguage models on translation tasks, the translation ability on different\nlanguages, and the effect of pre-training data on the translation ability of\nLLMs for researchers and developers."
  },
  {
    "arxiv_id": "2408.03033",
    "title": "L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization",
    "url": "http://arxiv.org/abs/2408.03033v1",
    "abstract": "This article details our participation (L3iTC) in the FinLLM Challenge Task\n2024, focusing on two key areas: Task 1, financial text classification, and\nTask 2, financial text summarization. To address these challenges, we\nfine-tuned several large language models (LLMs) to optimize performance for\neach task. Specifically, we used 4-bit quantization and LoRA to determine which\nlayers of the LLMs should be trained at a lower precision. This approach not\nonly accelerated the fine-tuning process on the training data provided by the\norganizers but also enabled us to run the models on low GPU memory. Our\nfine-tuned models achieved third place for the financial classification task\nwith an F1-score of 0.7543 and secured sixth place in the financial\nsummarization task on the official test datasets."
  },
  {
    "arxiv_id": "2408.03562",
    "title": "A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case",
    "url": "http://arxiv.org/abs/2408.03562v1",
    "abstract": "This research compares large language model (LLM) fine-tuning methods,\nincluding Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning\n(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally\ncompared LLM evaluation methods including End to End (E2E) benchmark method of\n\"Golden Answers\", traditional natural language processing (NLP) metrics, RAG\nAssessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,\nusing the travel chatbot use case. The travel dataset was sourced from the the\nReddit API by requesting posts from travel-related subreddits to get\ntravel-related conversation prompts and personalized travel experiences, and\naugmented for each fine-tuning method. We used two pretrained LLMs utilized for\nfine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to\nthe two pretrained models. The inferences from these models are extensively\nevaluated against the aforementioned metrics. The best model according to human\nevaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a\nReinforcement Learning from Human Feedback (RLHF) training pipeline, and\nultimately was evaluated as the best model. Our main findings are that: 1)\nquantitative and Ragas metrics do not align with human evaluation, 2) Open AI\nGPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep\nhumans in the loop for evaluation because, 4) traditional NLP metrics\ninsufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms\nQLoRA, but still needs postprocessing, 7) RLHF improves model performance\nsignificantly. Next steps include improving data quality, increasing data\nquantity, exploring RAG methods, and focusing data collection on a specific\ncity, which would improve data quality by narrowing the focus, while creating a\nuseful product."
  },
  {
    "arxiv_id": "2408.03402",
    "title": "ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning",
    "url": "http://arxiv.org/abs/2408.03402v1",
    "abstract": "Large Language Models (LLMs) excel in various natural language processing\ntasks, but leveraging them for dense passage embedding remains challenging.\nThis is due to their causal attention mechanism and the misalignment between\ntheir pre-training objectives and the text ranking tasks. Despite some recent\nefforts to address these issues, existing frameworks for LLM-based text\nembeddings have been limited by their support for only a limited range of LLM\narchitectures and fine-tuning strategies, limiting their practical application\nand versatility. In this work, we introduce the Unified framework for Large\nLanguage Model Embedding (ULLME), a flexible, plug-and-play implementation that\nenables bidirectional attention across various LLMs and supports a range of\nfine-tuning strategies. We also propose Generation-augmented Representation\nLearning (GRL), a novel fine-tuning method to boost LLMs for text embedding\ntasks. GRL enforces consistency between representation-based and\ngeneration-based relevance scores, leveraging LLMs' powerful generative\nabilities for learning passage embeddings. To showcase our framework's\nflexibility and effectiveness, we release three pre-trained models from ULLME\nwith different backbone architectures, ranging from 1.5B to 8B parameters, all\nof which demonstrate strong performance on the Massive Text Embedding\nBenchmark. Our framework is publicly available at:\nhttps://github.com/nlp-uoregon/ullme. A demo video for ULLME can also be found\nat https://rb.gy/ws1ile."
  },
  {
    "arxiv_id": "2408.03397",
    "title": "HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for Transformer Acceleration",
    "url": "http://arxiv.org/abs/2408.03397v1",
    "abstract": "Transformers have revolutionized deep learning and generative modeling to\nenable unprecedented advancements in natural language processing tasks and\nbeyond. However, designing hardware accelerators for executing transformer\nmodels is challenging due to the wide variety of computing kernels involved in\nthe transformer architecture. Existing accelerators are either inadequate to\naccelerate end-to-end transformer models or suffer notable thermal limitations.\nIn this paper, we propose the design of a three-dimensional heterogeneous\narchitecture referred to as HeTraX specifically optimized to accelerate\nend-to-end transformer models. HeTraX employs hardware resources aligned with\nthe computational kernels of transformers and optimizes both performance and\nenergy. Experimental results show that HeTraX outperforms existing\nstate-of-the-art by up to 5.6x in speedup and improves EDP by 14.5x while\nensuring thermally feasibility."
  },
  {
    "arxiv_id": "2408.04556",
    "title": "Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models",
    "url": "http://arxiv.org/abs/2408.04556v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency across\nvarious natural language processing (NLP) tasks. However, adapting LLMs to\ndownstream applications requires computationally intensive and memory-demanding\nfine-tuning procedures. To alleviate these burdens, parameter-efficient\nfine-tuning (PEFT) techniques have emerged as a promising approach to tailor\nLLMs with minimal computational overhead. While PEFT methods offer substantial\nadvantages, they do not fully address the pervasive issue of bias propagation\nfrom pre-training data. This work introduces Bias-Alleviating Low-Rank\nAdaptation (BA-LoRA), a novel PEFT method designed to counteract bias\ninheritance. BA-LoRA incorporates three distinct regularization terms: (1) a\nconsistency regularizer, (2) a diversity regularizer, and (3) a singular value\ndecomposition regularizer. These regularizers aim to enhance the models'\nconsistency, diversity, and generalization capabilities during fine-tuning. We\nconduct extensive experiments on natural language understanding (NLU) and\nnatural language generation (NLG) tasks using prominent LLMs such as LLaMA,\nMistral, and Gemma. The results demonstrate that BA-LoRA outperforms LoRA and\nits state-of-the-art variants. Moreover, our method effectively mitigates the\nadverse effects of pre-training bias, leading to more reliable and robust model\noutputs. The code is available at https://github.com/cyp-jlu-ai/BA-LoRA."
  },
  {
    "arxiv_id": "2408.04342",
    "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
    "url": "http://arxiv.org/abs/2408.04342v1",
    "abstract": "Large Language Models (LLMs) have revolutionised natural language processing\ntasks, particularly as chat agents. However, their applicability to threat\ndetection problems remains unclear. This paper examines the feasibility of\nemploying LLMs as a Network Intrusion Detection System (NIDS), despite their\nhigh computational requirements, primarily for the sake of explainability.\nFurthermore, considerable resources have been invested in developing LLMs, and\nthey may offer utility for NIDS. Current state-of-the-art NIDS rely on\nartificial benchmarking datasets, resulting in skewed performance when applied\nto real-world networking environments. Therefore, we compare the GPT-4 and\nLLama3 models against traditional architectures and transformer-based models to\nassess their ability to detect malicious NetFlows without depending on\nartificially skewed datasets, but solely on their vast pre-trained acquired\nknowledge. Our results reveal that, although LLMs struggle with precise attack\ndetection, they hold significant potential for a path towards explainable NIDS.\nOur preliminary exploration shows that LLMs are unfit for the detection of\nMalicious NetFlows. Most promisingly, however, these exhibit significant\npotential as complementary agents in NIDS, particularly in providing\nexplanations and aiding in threat response when integrated with Retrieval\nAugmented Generation (RAG) and function calling capabilities."
  },
  {
    "arxiv_id": "2408.04023",
    "title": "Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity",
    "url": "http://arxiv.org/abs/2408.04023v1",
    "abstract": "As Large Language Models (LLMs) become increasingly sophisticated and\nubiquitous in natural language processing (NLP) applications, ensuring their\nrobustness, trustworthiness, and alignment with human values has become a\ncritical challenge. This paper presents a novel framework for contextual\ngrounding in textual models, with a particular emphasis on the Context\nRepresentation stage. Our approach aims to enhance the reliability and ethical\nalignment of these models through a comprehensive, context-aware methodology.\nBy explicitly capturing and representing relevant situational, cultural, and\nethical contexts in a machine-readable format, we lay the foundation for\nanchoring a model's behavior within these contexts. Our approach leverages\ntechniques from knowledge representation and reasoning, such as ontologies,\nsemantic web technologies, and logic-based formalisms. We evaluate our\nframework on real-world textual datasets, demonstrating its effectiveness in\nimproving model performance, fairness, and alignment with human expectations,\nwhile maintaining high accuracy. Furthermore, we discuss the other key\ncomponents of the framework, including context-aware encoding, context-aware\nlearning, interpretability and explainability, and continuous monitoring and\nadaptation. This research contributes to the growing body of work on\nresponsible AI, offering a practical approach to developing more reliable,\ntrustworthy, and ethically-aligned language models. Our findings have\nsignificant implications for the deployment of LLMs in sensitive domains such\nas healthcare, legal systems, and social services, where contextual\nunderstanding is paramount."
  },
  {
    "arxiv_id": "2408.04905",
    "title": "GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models",
    "url": "http://arxiv.org/abs/2408.04905v1",
    "abstract": "Large language models (LLMs) have achieved unprecedented success in the field\nof natural language processing. However, the black-box nature of their internal\nmechanisms has brought many concerns about their trustworthiness and\ninterpretability. Recent research has discovered a class of abnormal tokens in\nthe model's vocabulary space and named them \"glitch tokens\". Those tokens, once\nincluded in the input, may induce the model to produce incorrect, irrelevant,\nor even harmful results, drastically undermining the reliability and\npracticality of LLMs.\n  In this work, we aim to enhance the understanding of glitch tokens and\npropose techniques for their detection and mitigation. We first reveal the\ncharacteristic features induced by glitch tokens on LLMs, which are evidenced\nby significant deviations in the distributions of attention patterns and\ndynamic information from intermediate model layers. Based on the insights, we\ndevelop GlitchProber, a tool for efficient glitch token detection and\nmitigation. GlitchProber utilizes small-scale sampling, principal component\nanalysis for accelerated feature extraction, and a simple classifier for\nefficient vocabulary screening. Taking one step further, GlitchProber rectifies\nabnormal model intermediate layer values to mitigate the destructive effects of\nglitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber\ndemonstrates higher efficiency, precision, and recall compared to existing\napproaches, with an average F1 score of 0.86 and an average repair rate of\n50.06%. GlitchProber unveils a novel path to address the challenges posed by\nglitch tokens and inspires future research toward more robust and interpretable\nLLMs."
  },
  {
    "arxiv_id": "2408.04723",
    "title": "Survey: Transformer-based Models in Data Modality Conversion",
    "url": "http://arxiv.org/abs/2408.04723v1",
    "abstract": "Transformers have made significant strides across various artificial\nintelligence domains, including natural language processing, computer vision,\nand audio processing. This success has naturally garnered considerable interest\nfrom both academic and industry researchers. Consequently, numerous Transformer\nvariants (often referred to as X-formers) have been developed for these fields.\nHowever, a thorough and systematic review of these modality-specific\nconversions remains lacking. Modality Conversion involves the transformation of\ndata from one form of representation to another, mimicking the way humans\nintegrate and interpret sensory information. This paper provides a\ncomprehensive review of transformer-based models applied to the primary\nmodalities of text, vision, and speech, discussing their architectures,\nconversion methodologies, and applications. By synthesizing the literature on\nmodality conversion, this survey aims to underline the versatility and\nscalability of transformers in advancing AI-driven content generation and\nunderstanding."
  },
  {
    "arxiv_id": "2408.06316",
    "title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning",
    "url": "http://arxiv.org/abs/2408.06316v1",
    "abstract": "In recent years, the transformer architecture has become the de facto\nstandard for machine learning algorithms applied to natural language processing\nand computer vision. Despite notable evidence of successful deployment of this\narchitecture in the context of robot learning, we claim that vanilla\ntransformers do not fully exploit the structure of the robot learning problem.\nTherefore, we propose Body Transformer (BoT), an architecture that leverages\nthe robot embodiment by providing an inductive bias that guides the learning\nprocess. We represent the robot body as a graph of sensors and actuators, and\nrely on masked attention to pool information throughout the architecture. The\nresulting architecture outperforms the vanilla transformer, as well as the\nclassical multilayer perceptron, in terms of task completion, scaling\nproperties, and computational efficiency when representing either imitation or\nreinforcement learning policies. Additional material including the open-source\ncode is available at https://sferrazza.cc/bot_site."
  },
  {
    "arxiv_id": "2408.06040",
    "title": "ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers",
    "url": "http://arxiv.org/abs/2408.06040v1",
    "abstract": "In the rapidly evolving fields of natural language processing and computer\nvision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet\nchallenging task. The quest for models that can seamlessly integrate and\ninterpret multimodal data is more pressing than ever. Imagine a system that can\nunderstand language with the depth and nuance of human cognition, while\nsimultaneously interpreting the rich visual context of the world around it.\n  We present ARPA, an architecture that fuses the unparalleled contextual\nunderstanding of large language models with the advanced feature extraction\ncapabilities of transformers, which then pass through a custom Graph Neural\nNetwork (GNN) layer to learn intricate relationships and subtle nuances within\nthe data. This innovative architecture not only sets a new benchmark in visual\nword disambiguation but also introduces a versatile framework poised to\ntransform how linguistic and visual data interact by harnessing the synergistic\nstrengths of its components, ensuring robust performance even in the most\ncomplex disambiguation scenarios. Through a series of experiments and\ncomparative analysis, we reveal the substantial advantages of our model,\nunderscoring its potential to redefine standards in the field. Beyond its\narchitectural prowess, our architecture excels through experimental\nenrichments, including sophisticated data augmentation and multi-modal training\ntechniques.\n  ARPA's introduction marks a significant milestone in visual word\ndisambiguation, offering a compelling solution that bridges the gap between\nlinguistic and visual modalities. We invite researchers and practitioners to\nexplore the capabilities of our model, envisioning a future where such hybrid\nmodels drive unprecedented advancements in artificial intelligence."
  },
  {
    "arxiv_id": "2408.05952",
    "title": "Optimizing Vision Transformers with Data-Free Knowledge Transfer",
    "url": "http://arxiv.org/abs/2408.05952v1",
    "abstract": "The groundbreaking performance of transformers in Natural Language Processing\n(NLP) tasks has led to their replacement of traditional Convolutional Neural\nNetworks (CNNs), owing to the efficiency and accuracy achieved through the\nself-attention mechanism. This success has inspired researchers to explore the\nuse of transformers in computer vision tasks to attain enhanced long-term\nsemantic awareness. Vision transformers (ViTs) have excelled in various\ncomputer vision tasks due to their superior ability to capture long-distance\ndependencies using the self-attention mechanism. Contemporary ViTs like Data\nEfficient Transformers (DeiT) can effectively learn both global semantic\ninformation and local texture information from images, achieving performance\ncomparable to traditional CNNs. However, their impressive performance comes\nwith a high computational cost due to very large number of parameters,\nhindering their deployment on devices with limited resources like smartphones,\ncameras, drones etc. Additionally, ViTs require a large amount of data for\ntraining to achieve performance comparable to benchmark CNN models. Therefore,\nwe identified two key challenges in deploying ViTs on smaller form factor\ndevices: the high computational requirements of large models and the need for\nextensive training data. As a solution to these challenges, we propose\ncompressing large ViT models using Knowledge Distillation (KD), which is\nimplemented data-free to circumvent limitations related to data availability.\nAdditionally, we conducted experiments on object detection within the same\nenvironment in addition to classification tasks. Based on our analysis, we\nfound that datafree knowledge distillation is an effective method to overcome\nboth issues, enabling the deployment of ViTs on less resourceconstrained\ndevices."
  },
  {
    "arxiv_id": "2408.05541",
    "title": "P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for Optimizing LLM Training",
    "url": "http://arxiv.org/abs/2408.05541v1",
    "abstract": "In the rapidly advancing field of Large Language Models (LLMs), effectively\nleveraging existing datasets during fine-tuning to maximize the model's\npotential is of paramount importance. This paper introduces P3, an adaptive\nframework aimed at optimizing the task-specific fine-tuning process through\niterative data pruning. P3 consists of three key components: (1) Policy-driven\nDifficulty Measurement, which dynamically assesses data difficulty based on the\nmodel's real-time performance, replacing static metrics with adaptable\nevaluations; (2) Pace-Adaptive Selection, leveraging self-paced learning to\nprogressively introduce more challenging data, thereby enhancing model\ncapability; (3) Diversity Promotion, incorporating Determinantal Point Process\n(DPP) to ensure data diversity across epochs, enriching the learning process.\nWe validate P3 on the reasoning scenarios, APPS and MATH, demonstrating\nsignificant improvements over traditional data pruning methods. By advancing\ndynamic data selection and utilization strategies, P3 contributes both a\ntheoretical framework and concrete approach to fully exploit existing data for\nLLMs' performance improvement, offering utility across diverse tasks."
  },
  {
    "arxiv_id": "2408.06396",
    "title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses",
    "url": "http://arxiv.org/abs/2408.06396v1",
    "abstract": "Pre-trained LLMs have demonstrated substantial capabilities across a range of\nconventional natural language processing (NLP) tasks, such as summarization and\nentity recognition. In this paper, we explore the application of LLMs in the\ngeneration of high-quality protein sequences. Specifically, we adopt a suite of\npre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and\ngemma-7B4, to produce valid protein sequences. All of these models are publicly\navailable.5 Unlike previous work in this field, our approach utilizes a\nrelatively small dataset comprising 42,000 distinct human protein sequences. We\nretrain these models to process protein-related data, ensuring the generation\nof biologically feasible protein structures. Our findings demonstrate that even\nwith limited data, the adapted models exhibit efficiency comparable to\nestablished protein-focused models such as ProGen varieties, ProtGPT2, and\nProLLaMA, which were trained on millions of protein sequences. To validate and\nquantify the performance of our models, we conduct comparative analyses\nemploying standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore,\nwe commit to making the trained versions of all four models publicly available,\nfostering greater transparency and collaboration in the field of computational\nbiology."
  },
  {
    "arxiv_id": "2408.07608",
    "title": "MatterGPT: A Generative Transformer for Multi-Property Inverse Design of Solid-State Materials",
    "url": "http://arxiv.org/abs/2408.07608v1",
    "abstract": "Inverse design of solid-state materials with desired properties represents a\nformidable challenge in materials science. Although recent generative models\nhave demonstrated potential, their adoption has been hindered by limitations\nsuch as inefficiency, architectural constraints and restricted open-source\navailability. The representation of crystal structures using the SLICES\n(Simplified Line-Input Crystal-Encoding System) notation as a string of\ncharacters enables the use of state-of-the-art natural language processing\nmodels, such as Transformers, for crystal design. Drawing inspiration from the\nsuccess of GPT models in generating coherent text, we trained a generative\nTransformer on the next-token prediction task to generate solid-state materials\nwith targeted properties. We demonstrate MatterGPT's capability to generate de\nnovo crystal structures with targeted single properties, including both\nlattice-insensitive (formation energy) and lattice-sensitive (band gap)\nproperties. Furthermore, we extend MatterGPT to simultaneously target multiple\nproperties, addressing the complex challenge of multi-objective inverse design\nof crystals. Our approach showcases high validity, uniqueness, and novelty in\ngenerated structures, as well as the ability to generate materials with\nproperties beyond the training data distribution. This work represents a\nsignificant step forward in computational materials discovery, offering a\npowerful and open tool for designing materials with tailored properties for\nvarious applications in energy, electronics, and beyond."
  },
  {
    "arxiv_id": "2408.07465",
    "title": "Large Language Models Prompting With Episodic Memory",
    "url": "http://arxiv.org/abs/2408.07465v1",
    "abstract": "Prompt optimization is essential for enhancing the performance of Large\nLanguage Models (LLMs) in a range of Natural Language Processing (NLP) tasks,\nparticularly in scenarios of few-shot learning where training examples are\nincorporated directly into the prompt. Despite the growing interest in\noptimizing prompts with few-shot examples, existing methods for prompt\noptimization are often resource-intensive or perform inadequately. In this\nwork, we propose PrOmpting with Episodic Memory (POEM), a novel prompt\noptimization technique that is simple, efficient, and demonstrates strong\ngeneralization capabilities. We approach prompt optimization as a Reinforcement\nLearning (RL) challenge, using episodic memory to archive combinations of input\ndata, permutations of few-shot examples, and the rewards observed during\ntraining. In the testing phase, we optimize the sequence of examples for each\ntest query by selecting the sequence that yields the highest total rewards from\nthe top-k most similar training examples in the episodic memory. Our results\nshow that POEM outperforms recent techniques like TEMPERA and RLPrompt by over\n5.3% in various text classification tasks. Furthermore, our approach adapts\nwell to broader language understanding tasks, consistently outperforming\nconventional heuristic methods for ordering examples."
  },
  {
    "arxiv_id": "2408.07292",
    "title": "LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models",
    "url": "http://arxiv.org/abs/2408.07292v1",
    "abstract": "Language models have achieved remarkable success in various natural language\nprocessing tasks. However, their application to time series data, a crucial\ncomponent in many domains, remains limited. This paper proposes LiPCoT (Linear\nPredictive Coding based Tokenizer for time series), a novel tokenizer that\nencodes time series data into a sequence of tokens, enabling self-supervised\nlearning of time series using existing Language model architectures such as\nBERT. Unlike traditional time series tokenizers that rely heavily on CNN\nencoder for time series feature generation, LiPCoT employs stochastic modeling\nthrough linear predictive coding to create a latent space for time series\nproviding a compact yet rich representation of the inherent stochastic nature\nof the data. Furthermore, LiPCoT is computationally efficient and can\neffectively handle time series data with varying sampling rates and lengths,\novercoming common limitations of existing time series tokenizers. In this\nproof-of-concept work, we present the effectiveness of LiPCoT in classifying\nParkinson's disease (PD) using an EEG dataset from 46 participants. In\nparticular, we utilize LiPCoT to encode EEG data into a small vocabulary of\ntokens and then use BERT for self-supervised learning and the downstream task\nof PD classification. We benchmark our approach against several\nstate-of-the-art CNN-based deep learning architectures for PD detection. Our\nresults reveal that BERT models utilizing self-supervised learning outperformed\nthe best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%\nin accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for\nself-supervised learning even on small datasets. Our work will inform future\nfoundational models for time series, particularly for self-supervised learning."
  },
  {
    "arxiv_id": "2408.08073",
    "title": "Extracting Sentence Embeddings from Pretrained Transformer Models",
    "url": "http://arxiv.org/abs/2408.08073v1",
    "abstract": "Pre-trained transformer models shine in many natural language processing\ntasks and therefore are expected to bear the representation of the input\nsentence or text meaning. These sentence-level embeddings are also important in\nretrieval-augmented generation. But do commonly used plain averaging or prompt\ntemplates sufficiently capture and represent the underlying meaning? After\nproviding a comprehensive review of existing sentence embedding extraction and\nrefinement methods, we thoroughly test different combinations and our original\nextensions of the most promising ones on pretrained models. Namely, given 110 M\nparameters, BERT's hidden representations from multiple layers, and many\ntokens, we try diverse ways to extract optimal sentence embeddings. We test\nvarious token aggregation and representation post-processing techniques. We\nalso test multiple ways of using a general Wikitext dataset to complement\nBERT's sentence embeddings. All methods are tested on eight Semantic Textual\nSimilarity (STS), six short text clustering, and twelve classification tasks.\nWe also evaluate our representation-shaping techniques on other static models,\nincluding random token representations. Proposed representation extraction\nmethods improve the performance on STS and clustering tasks for all models\nconsidered. Very high improvements for static token-based models, especially\nrandom embeddings for STS tasks, almost reach the performance of BERT-derived\nrepresentations. Our work shows that the representation-shaping techniques\nsignificantly improve sentence embeddings extracted from BERT-based and simple\nbaseline models."
  },
  {
    "arxiv_id": "2408.07983",
    "title": "ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models",
    "url": "http://arxiv.org/abs/2408.07983v1",
    "abstract": "The rapid advancements in Large Language Models (LLMs) have led to\nsignificant improvements in various natural language processing tasks. However,\nthe evaluation of LLMs' legal knowledge, particularly in non-English languages\nsuch as Arabic, remains under-explored. To address this gap, we introduce\nArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal\nknowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval\nconsists of multiple tasks sourced from Saudi legal documents and synthesized\nquestions. In this work, we aim to analyze the capabilities required to solve\nlegal problems in Arabic and benchmark the performance of state-of-the-art\nLLMs. We explore the impact of in-context learning and investigate various\nevaluation methods. Additionally, we explore workflows for generating questions\nwith automatic validation to enhance the dataset's quality. We benchmark\nmultilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We\nalso share our methodology for creating the dataset and validation, which can\nbe generalized to other domains. We hope to accelerate AI research in the\nArabic Legal domain by releasing the ArabLegalEval dataset and code:\nhttps://github.com/Thiqah/ArabLegalEval"
  },
  {
    "arxiv_id": "2408.07869",
    "title": "A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining",
    "url": "http://arxiv.org/abs/2408.07869v1",
    "abstract": "Self-supervised Pretrained Models (PTMs) have demonstrated remarkable\nperformance in computer vision and natural language processing tasks. These\nsuccesses have prompted researchers to design PTMs for time series data. In our\nexperiments, most self-supervised time series PTMs were surpassed by simple\nsupervised models. We hypothesize this undesired phenomenon may be caused by\ndata scarcity. In response, we test six time series generation methods, use the\ngenerated data in pretraining in lieu of the real data, and examine the effects\non classification performance. Our results indicate that replacing a real-data\npretraining set with a greater volume of only generated samples produces\nnoticeable improvement."
  },
  {
    "arxiv_id": "2408.08805",
    "title": "CIKMar: A Dual-Encoder Approach to Prompt-Based Reranking in Educational Dialogue Systems",
    "url": "http://arxiv.org/abs/2408.08805v1",
    "abstract": "In this study, we introduce CIKMar, an efficient approach to educational\ndialogue systems powered by the Gemma Language model. By leveraging a\nDual-Encoder ranking system that incorporates both BERT and SBERT model, we\nhave designed CIKMar to deliver highly relevant and accurate responses, even\nwith the constraints of a smaller language model size. Our evaluation reveals\nthat CIKMar achieves a robust recall and F1-score of 0.70 using BERTScore\nmetrics. However, we have identified a significant challenge: the Dual-Encoder\ntends to prioritize theoretical responses over practical ones. These findings\nunderscore the potential of compact and efficient models like Gemma in\ndemocratizing access to advanced educational AI systems, ensuring effective and\ncontextually appropriate responses."
  },
  {
    "arxiv_id": "2408.08803",
    "title": "Leveraging FourierKAN Classification Head for Pre-Trained Transformer-based Text Classification",
    "url": "http://arxiv.org/abs/2408.08803v1",
    "abstract": "In resource constraint settings, adaptation to downstream classification\ntasks involves fine-tuning the final layer of a classifier (i.e. classification\nhead) while keeping rest of the model weights frozen. Multi-Layer Perceptron\n(MLP) heads fine-tuned with pre-trained transformer backbones have long been\nthe de facto standard for text classification head fine-tuning. However, the\nfixed non-linearity of MLPs often struggles to fully capture the nuances of\ncontextual embeddings produced by pre-trained models, while also being\ncomputationally expensive. In our work, we investigate the efficacy of KAN and\nits variant, Fourier KAN (FR-KAN), as alternative text classification heads.\nOur experiments reveal that FR-KAN significantly outperforms MLPs with an\naverage improvement of 10% in accuracy and 11% in F1-score across seven\npre-trained transformer models and four text classification tasks. Beyond\nperformance gains, FR-KAN is more computationally efficient and trains faster\nwith fewer parameters. These results underscore the potential of FR-KAN to\nserve as a lightweight classification head, with broader implications for\nadvancing other Natural Language Processing (NLP) tasks."
  },
  {
    "arxiv_id": "2408.08554",
    "title": "ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models",
    "url": "http://arxiv.org/abs/2408.08554v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks. However, their practical application is constrained by substantial\nmemory and computational demands. Post-training quantization (PTQ) is\nconsidered an effective method to accelerate LLM inference. Despite its growing\npopularity in LLM model compression, PTQ deployment faces two major challenges.\nFirst, low-bit quantization leads to performance degradation. Second,\nrestricted by the limited integer computing unit type on GPUs, quantized matrix\noperations with different precisions cannot be effectively accelerated. To\naddress these issues, we introduce a novel arbitrary-bit quantization algorithm\nand inference framework, ABQ-LLM. It achieves superior performance across\nvarious quantization settings and enables efficient arbitrary-precision\nquantized inference on the GPU. ABQ-LLM introduces several key innovations: (1)\na distribution correction method for transformer blocks to mitigate\ndistribution differences caused by full quantization of weights and\nactivations, improving performance at low bit-widths. (2) the bit balance\nstrategy to counteract performance degradation from asymmetric distribution\nissues at very low bit-widths (e.g., 2-bit). (3) an innovative quantization\nacceleration framework that reconstructs the quantization matrix multiplication\nof arbitrary precision combinations based on BTC (Binary TensorCore)\nequivalents, gets rid of the limitations of INT4/INT8 computing units. ABQ-LLM\ncan convert each component bit width gain into actual acceleration gain,\nmaximizing performance under mixed precision(e.g., W6A6, W2A8). Based on W2*A8\nquantization configuration on LLaMA-7B model, it achieved a WikiText2\nperplexity of 7.59 (2.17$\\downarrow $ vs 9.76 in AffineQuant). Compared to\nSmoothQuant, we realized 1.6$\\times$ acceleration improvement and 2.7$\\times$\nmemory compression gain."
  },
  {
    "arxiv_id": "2408.09742",
    "title": "Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs",
    "url": "http://arxiv.org/abs/2408.09742v1",
    "abstract": "Detecting and quantifying issue framing in textual discourse - the\nperspective one takes to a given topic (e.g. climate science vs. denialism,\nmisogyny vs. gender equality) - is highly valuable to a range of end-users from\nsocial and political scientists to program evaluators and policy analysts.\nHowever, conceptual framing is notoriously challenging for automated natural\nlanguage processing (NLP) methods since the words and phrases used by either\n`side' of an issue are often held in common, with only subtle stylistic\nflourishes separating their use. Here we develop and rigorously evaluate new\ndetection methods for issue framing and narrative analysis within large text\ndatasets. By introducing a novel application of next-token log probabilities\nderived from generative large language models (LLMs) we show that issue framing\ncan be reliably and efficiently detected in large corpora with only a few\nexamples of either perspective on a given issue, a method we call `paired\ncompletion'. Through 192 independent experiments over three novel, synthetic\ndatasets, we evaluate paired completion against prompt-based LLM methods and\nlabelled methods using traditional NLP and recent LLM contextual embeddings. We\nadditionally conduct a cost-based analysis to mark out the feasible set of\nperformant methods at production-level scales, and a model bias analysis.\nTogether, our work demonstrates a feasible path to scalable, accurate and\nlow-bias issue-framing in large corpora."
  },
  {
    "arxiv_id": "2408.09730",
    "title": "Fragment and Geometry Aware Tokenization of Molecules for Structure-Based Drug Design Using Language Models",
    "url": "http://arxiv.org/abs/2408.09730v1",
    "abstract": "Structure-based drug design (SBDD) is crucial for developing specific and\neffective therapeutics against protein targets but remains challenging due to\ncomplex protein-ligand interactions and vast chemical space. Although language\nmodels (LMs) have excelled in natural language processing, their application in\nSBDD is underexplored. To bridge this gap, we introduce a method, known as\nFrag2Seq, to apply LMs to SBDD by generating molecules in a fragment-based\nmanner in which fragments correspond to functional modules. We transform 3D\nmolecules into fragment-informed sequences using SE(3)-equivariant molecule and\nfragment local frames, extracting SE(3)-invariant sequences that preserve\ngeometric information of 3D fragments. Furthermore, we incorporate protein\npocket embeddings obtained from a pre-trained inverse folding model into the\nLMs via cross-attention to capture protein-ligand interaction, enabling\neffective target-aware molecule generation. Benefiting from employing LMs with\nfragment-based generation and effective protein context encoding, our model\nachieves the best performance on binding vina score and chemical properties\nsuch as QED and Lipinski, which shows our model's efficacy in generating\ndrug-like ligands with higher binding affinity against target proteins.\nMoreover, our method also exhibits higher sampling efficiency compared to\natom-based autoregressive and diffusion baselines with at most ~300x speedup."
  },
  {
    "arxiv_id": "2408.09304",
    "title": "CyberPal.AI: Empowering LLMs with Expert-Driven Cybersecurity Instructions",
    "url": "http://arxiv.org/abs/2408.09304v1",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing (NLP), providing versatile capabilities across various applications.\nHowever, their application to complex, domain-specific tasks, such as\ncyber-security, often faces substantial challenges. In this study, we introduce\nSecKnowledge and CyberPal.AI to address these challenges and train\nsecurity-expert LLMs. SecKnowledge is a domain-knowledge-driven cyber-security\ninstruction dataset, meticulously designed using years of accumulated expert\nknowledge in the domain through a multi-phase generation process. CyberPal.AI\nrefers to a family of LLMs fine-tuned using SecKnowledge, aimed at building\nsecurity-specialized LLMs capable of answering and following complex\nsecurity-related instructions. Additionally, we introduce SecKnowledge-Eval, a\ncomprehensive and diverse cyber-security evaluation benchmark, composed of an\nextensive set of cyber-security tasks we specifically developed to assess LLMs\nin the field of cyber-security, along with other publicly available security\nbenchmarks. Our results show a significant average improvement of up to 24%\nover the baseline models, underscoring the benefits of our expert-driven\ninstruction dataset generation process. These findings contribute to the\nadvancement of AI-based cyber-security applications, paving the way for\nsecurity-expert LLMs that can enhance threat-hunting and investigation\nprocesses."
  },
  {
    "arxiv_id": "2408.10548",
    "title": "Language Modeling on Tabular Data: A Survey of Foundations, Techniques and Evolution",
    "url": "http://arxiv.org/abs/2408.10548v1",
    "abstract": "Tabular data, a prevalent data type across various domains, presents unique\nchallenges due to its heterogeneous nature and complex structural\nrelationships. Achieving high predictive performance and robustness in tabular\ndata analysis holds significant promise for numerous applications. Influenced\nby recent advancements in natural language processing, particularly transformer\narchitectures, new methods for tabular data modeling have emerged. Early\ntechniques concentrated on pre-training transformers from scratch, often\nencountering scalability issues. Subsequently, methods leveraging pre-trained\nlanguage models like BERT have been developed, which require less data and\nyield enhanced performance. The recent advent of large language models, such as\nGPT and LLaMA, has further revolutionized the field, facilitating more advanced\nand diverse applications with minimal fine-tuning. Despite the growing\ninterest, a comprehensive survey of language modeling techniques for tabular\ndata remains absent. This paper fills this gap by providing a systematic review\nof the development of language modeling for tabular data, encompassing: (1) a\ncategorization of different tabular data structures and data types; (2) a\nreview of key datasets used in model training and tasks used for evaluation;\n(3) a summary of modeling techniques including widely-adopted data processing\nmethods, popular architectures, and training objectives; (4) the evolution from\nadapting traditional Pre-training/Pre-trained language models to the\nutilization of large language models; (5) an identification of persistent\nchallenges and potential future research directions in language modeling for\ntabular data analysis. GitHub page associated with this survey is available at:\nhttps://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git."
  },
  {
    "arxiv_id": "2408.10473",
    "title": "Enhancing One-shot Pruned Pre-trained Language Models through Sparse-Dense-Sparse Mechanism",
    "url": "http://arxiv.org/abs/2408.10473v1",
    "abstract": "Pre-trained language models (PLMs) are engineered to be robust in contextual\nunderstanding and exhibit outstanding performance in various natural language\nprocessing tasks. However, their considerable size incurs significant\ncomputational and storage costs. Modern pruning strategies employ one-shot\ntechniques to compress PLMs without the need for retraining on task-specific or\notherwise general data; however, these approaches often lead to an\nindispensable reduction in performance. In this paper, we propose SDS, a\nSparse-Dense-Sparse pruning framework to enhance the performance of the pruned\nPLMs from a weight distribution optimization perspective. We outline the\npruning process in three steps. Initially, we prune less critical connections\nin the model using conventional one-shot pruning methods. Next, we reconstruct\na dense model featuring a pruning-friendly weight distribution by reactivating\npruned connections with sparse regularization. Finally, we perform a second\npruning round, yielding a superior pruned model compared to the initial\npruning. Experimental results demonstrate that SDS outperforms the\nstate-of-the-art pruning techniques SparseGPT and Wanda under an identical\nsparsity configuration. For instance, SDS reduces perplexity by 9.13 on\nRaw-Wikitext2 and improves accuracy by an average of 2.05% across multiple\nzero-shot benchmarks for OPT-125M with 2:4 sparsity."
  },
  {
    "arxiv_id": "2408.10357",
    "title": "Beyond Relevant Documents: A Knowledge-Intensive Approach for Query-Focused Summarization using Large Language Models",
    "url": "http://arxiv.org/abs/2408.10357v1",
    "abstract": "Query-focused summarization (QFS) is a fundamental task in natural language\nprocessing with broad applications, including search engines and report\ngeneration. However, traditional approaches assume the availability of relevant\ndocuments, which may not always hold in practical scenarios, especially in\nhighly specialized topics. To address this limitation, we propose a novel\nknowledge-intensive approach that reframes QFS as a knowledge-intensive task\nsetup. This approach comprises two main components: a retrieval module and a\nsummarization controller. The retrieval module efficiently retrieves\npotentially relevant documents from a large-scale knowledge corpus based on the\ngiven textual query, eliminating the dependence on pre-existing document sets.\nThe summarization controller seamlessly integrates a powerful large language\nmodel (LLM)-based summarizer with a carefully tailored prompt, ensuring the\ngenerated summary is comprehensive and relevant to the query. To assess the\neffectiveness of our approach, we create a new dataset, along with\nhuman-annotated relevance labels, to facilitate comprehensive evaluation\ncovering both retrieval and summarization performance. Extensive experiments\ndemonstrate the superior performance of our approach, particularly its ability\nto generate accurate summaries without relying on the availability of relevant\ndocuments initially. This underscores our method's versatility and practical\napplicability across diverse query scenarios."
  },
  {
    "arxiv_id": "2408.11727",
    "title": "Efficient Detection of Toxic Prompts in Large Language Models",
    "url": "http://arxiv.org/abs/2408.11727v1",
    "abstract": "Large language models (LLMs) like ChatGPT and Gemini have significantly\nadvanced natural language processing, enabling various applications such as\nchatbots and automated content generation. However, these models can be\nexploited by malicious individuals who craft toxic prompts to elicit harmful or\nunethical responses. These individuals often employ jailbreaking techniques to\nbypass safety mechanisms, highlighting the need for robust toxic prompt\ndetection methods. Existing detection techniques, both blackbox and whitebox,\nface challenges related to the diversity of toxic prompts, scalability, and\ncomputational efficiency. In response, we propose ToxicDetector, a lightweight\ngreybox method designed to efficiently detect toxic prompts in LLMs.\nToxicDetector leverages LLMs to create toxic concept prompts, uses embedding\nvectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)\nclassifier for prompt classification. Our evaluation on various versions of the\nLLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector\nachieves a high accuracy of 96.39\\% and a low false positive rate of 2.00\\%,\noutperforming state-of-the-art methods. Additionally, ToxicDetector's\nprocessing time of 0.0780 seconds per prompt makes it highly suitable for\nreal-time applications. ToxicDetector achieves high accuracy, efficiency, and\nscalability, making it a practical method for toxic prompt detection in LLMs."
  },
  {
    "arxiv_id": "2408.11587",
    "title": "Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks",
    "url": "http://arxiv.org/abs/2408.11587v1",
    "abstract": "With the burgeoning advancements in the field of natural language processing\n(NLP), the demand for training data has increased significantly. To save costs,\nit has become common for users and businesses to outsource the labor-intensive\ntask of data collection to third-party entities. Unfortunately, recent research\nhas unveiled the inherent risk associated with this practice, particularly in\nexposing NLP systems to potential backdoor attacks. Specifically, these attacks\nenable malicious control over the behavior of a trained model by poisoning a\nsmall portion of the training data. Unlike backdoor attacks in computer vision,\ntextual backdoor attacks impose stringent requirements for attack stealthiness.\nHowever, existing attack methods meet significant trade-off between\neffectiveness and stealthiness, largely due to the high information entropy\ninherent in textual data. In this paper, we introduce the Efficient and\nStealthy Textual backdoor attack method, EST-Bad, leveraging Large Language\nModels (LLMs). Our EST-Bad encompasses three core strategies: optimizing the\ninherent flaw of models as the trigger, stealthily injecting triggers with\nLLMs, and meticulously selecting the most impactful samples for backdoor\ninjection. Through the integration of these techniques, EST-Bad demonstrates an\nefficient achievement of competitive attack performance while maintaining\nsuperior stealthiness compared to prior methods across various text classifier\ndatasets."
  },
  {
    "arxiv_id": "2408.11557",
    "title": "A Quick, trustworthy spectral detection Q&A system based on the SDAAP Dataset and large language model",
    "url": "http://arxiv.org/abs/2408.11557v1",
    "abstract": "Large Language Model (LLM) has demonstrated significant success in a range of\nnatural language processing (NLP) tasks within general domain. The emergence of\nLLM has introduced innovative methodologies across diverse fields, including\nthe natural sciences. Researchers aim to implement automated, concurrent\nprocess driven by LLM to supplant conventional manual, repetitive and\nlabor-intensive work. In the domain of spectral analysis and detection, it is\nimperative for researchers to autonomously acquire pertinent knowledge across\nvarious research objects, which encompasses the spectroscopic techniques and\nthe chemometric methods that are employed in experiments and analysis.\nParadoxically, despite the recognition of spectroscopic detection as an\neffective analytical method, the fundamental process of knowledge retrieval\nremains both time-intensive and repetitive. In response to this challenge, we\nfirst introduced the Spectral Detection and Analysis Based Paper(SDAAP)\ndataset, which is the first open-source textual knowledge dataset for spectral\nanalysis and detection and contains annotated literature data as well as\ncorresponding knowledge instruction data. Subsequently, we also designed an\nautomated Q\\&A framework based on the SDAAP dataset, which can retrieve\nrelevant knowledge and generate high-quality responses by extracting entities\nin the input as retrieval parameters. It is worth noting that: within this\nframework, LLM is only used as a tool to provide generalizability, while RAG\ntechnique is used to accurately capture the source of the knowledge.This\napproach not only improves the quality of the generated responses, but also\nensures the traceability of the knowledge. Experimental results show that our\nframework generates responses with more reliable expertise compared to the\nbaseline."
  },
  {
    "arxiv_id": "2408.11344",
    "title": "Clinical Context-aware Radiology Report Generation from Medical Images using Transformers",
    "url": "http://arxiv.org/abs/2408.11344v1",
    "abstract": "Recent developments in the field of Natural Language Processing, especially\nlanguage models such as the transformer have brought state-of-the-art results\nin language understanding and language generation. In this work, we investigate\nthe use of the transformer model for radiology report generation from chest\nX-rays. We also highlight limitations in evaluating radiology report generation\nusing only the standard language generation metrics. We then applied a\ntransformer based radiology report generation architecture, and also compare\nthe performance of a transformer based decoder with the recurrence based\ndecoder. Experiments were performed using the IU-CXR dataset, showing superior\nresults to its LSTM counterpart and being significantly faster. Finally, we\nidentify the need of evaluating radiology report generation system using both\nlanguage generation metrics and classification metrics, which helps to provide\nrobust measure of generated reports in terms of their coherence and diagnostic\nvalue."
  },
  {
    "arxiv_id": "2408.11294",
    "title": "RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining",
    "url": "http://arxiv.org/abs/2408.11294v1",
    "abstract": "The field of Natural Language Processing (NLP) has seen significant\nadvancements with the development of Large Language Models (LLMs). However,\nmuch of this research remains focused on English, often overlooking\nlow-resource languages like Korean. This oversight presents challenges due to\nthe unique non-alphabetic token structure of Korean and the substantial memory\nand computational demands required for LLM training, which frequently lead to\nmemory constraints and out-of-memory errors. To address these issues, we\npresent RedWhale, a model specifically tailored for Korean language processing.\nRedWhale is developed using an efficient continual pretraining approach that\nincludes a comprehensive Korean corpus preprocessing pipeline, a specialized\ntokenizer, an optimized model initialization technique, and a multistage\npretraining strategy. These innovations collectively reduce training time and\ncomputational costs while maintaining high levels of accuracy and\ncomprehension. By leveraging cross-lingual transfer learning, which exploits\nshared linguistic similarities across languages, RedWhale builds on English\nmodels to enhance Korean language processing. Experimental results demonstrate\nthat RedWhale outperforms other leading models on Korean NLP benchmarks,\nincluding the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing\nsuperior understanding and generation of Korean text. Furthermore, RedWhale\nshowed no signs of convergence even after pretraining on 9.7 billion tokens,\nindicating the potential for further improvements with additional training.\nThis work represents a significant advancement in bridging the linguistic\ndivide, particularly in enhancing NLP capabilities for the Korean language."
  },
  {
    "arxiv_id": "2408.12599",
    "title": "Controllable Text Generation for Large Language Models: A Survey",
    "url": "http://arxiv.org/abs/2408.12599v1",
    "abstract": "In Natural Language Processing (NLP), Large Language Models (LLMs) have\ndemonstrated high text generation quality. However, in real-world applications,\nLLMs must meet increasingly complex requirements. Beyond avoiding misleading or\ninappropriate content, LLMs are also expected to cater to specific user needs,\nsuch as imitating particular writing styles or generating text with poetic\nrichness. These varied demands have driven the development of Controllable Text\nGeneration (CTG) techniques, which ensure that outputs adhere to predefined\ncontrol conditions--such as safety, sentiment, thematic consistency, and\nlinguistic style--while maintaining high standards of helpfulness, fluency, and\ndiversity.\n  This paper systematically reviews the latest advancements in CTG for LLMs,\noffering a comprehensive definition of its core concepts and clarifying the\nrequirements for control conditions and text quality. We categorize CTG tasks\ninto two primary types: content control and attribute control. The key methods\nare discussed, including model retraining, fine-tuning, reinforcement learning,\nprompt engineering, latent space manipulation, and decoding-time intervention.\nWe analyze each method's characteristics, advantages, and limitations,\nproviding nuanced insights for achieving generation control. Additionally, we\nreview CTG evaluation methods, summarize its applications across domains, and\naddress key challenges in current research, including reduced fluency and\npracticality. We also propose several appeals, such as placing greater emphasis\non real-world applications in future research. This paper aims to offer\nvaluable guidance to researchers and developers in the field. Our reference\nlist and Chinese version are open-sourced at\nhttps://github.com/IAAR-Shanghai/CTGSurvey."
  },
  {
    "arxiv_id": "2408.12188",
    "title": "Reasoning Factual Knowledge in Structured Data with Large Language Models",
    "url": "http://arxiv.org/abs/2408.12188v1",
    "abstract": "Large language models (LLMs) have made remarkable progress in various natural\nlanguage processing tasks as a benefit of their capability to comprehend and\nreason with factual knowledge. However, a significant amount of factual\nknowledge is stored in structured data, which possesses unique characteristics\nthat differ from the unstructured texts used for pretraining. This difference\ncan introduce imperceptible inference parameter deviations, posing challenges\nfor LLMs in effectively utilizing and reasoning with structured data to\naccurately infer factual knowledge. To this end, we propose a benchmark named\nStructFact, to evaluate the structural reasoning capabilities of LLMs in\ninferring factual knowledge. StructFact comprises 8,340 factual questions\nencompassing various tasks, domains, timelines, and regions. This benchmark\nallows us to investigate the capability of LLMs across five factual tasks\nderived from the unique characteristics of structural facts. Extensive\nexperiments on a set of LLMs with different training strategies reveal the\nlimitations of current LLMs in inferring factual knowledge from structured\ndata. We present this benchmark as a compass to navigate the strengths and\nweaknesses of LLMs in reasoning with structured data for knowledge-sensitive\ntasks, and to encourage advancements in related real-world applications. Please\nfind our code at https://github.com/EganGu/StructFact."
  },
  {
    "arxiv_id": "2408.12157",
    "title": "Implicit Sentiment Analysis Based on Chain of Thought Prompting",
    "url": "http://arxiv.org/abs/2408.12157v1",
    "abstract": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural\nlanguage processing. Inspired by the idea of large language model Chain of\nThought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)\nframework. The framework first analyzes the implicit aspects and opinions in\nthe text using common sense and thinking chain capabilities. Then, it reflects\non the process of implicit sentiment analysis and finally deduces the polarity\nof sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of\n1120 restaurant reviews and 638 laptop reviews. The experimental results\ndemonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable\nperformance improvement. Specifically, on the restaurant dataset, the F1 score\nreaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer\ndataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.\nComparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt\nbaseline by an average margin of 47.99%."
  },
  {
    "arxiv_id": "2408.12116",
    "title": "Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning",
    "url": "http://arxiv.org/abs/2408.12116v1",
    "abstract": "In the geospatial domain, universal representation models are significantly\nless prevalent than their extensive use in natural language processing and\ncomputer vision. This discrepancy arises primarily from the high costs\nassociated with the input of existing representation models, which often\nrequire street views and mobility data. To address this, we develop a novel,\ntraining-free method that leverages large language models (LLMs) and auxiliary\nmap data from OpenStreetMap to derive geolocation representations (LLMGeovec).\nLLMGeovec can represent the geographic semantics of city, country, and global\nscales, which acts as a generic enhancer for spatio-temporal learning.\nSpecifically, by direct feature concatenation, we introduce a simple yet\neffective paradigm for enhancing multiple spatio-temporal tasks including\ngeographic prediction (GP), long-term time series forecasting (LTSF), and\ngraph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly\nintegrate into a wide spectrum of spatio-temporal learning models, providing\nimmediate enhancements. Experimental results demonstrate that LLMGeovec\nachieves global coverage and significantly boosts the performance of leading\nGP, LTSF, and GSTF models. Our codes are available at\n\\url{https://github.com/Umaruchain/LLMGeovec}."
  },
  {
    "arxiv_id": "2408.12902",
    "title": "IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities",
    "url": "http://arxiv.org/abs/2408.12902v1",
    "abstract": "In the field of multimodal large language models (MLLMs), common methods\ntypically involve unfreezing the language model during training to foster\nprofound visual understanding. However, the fine-tuning of such models with\nvision-language data often leads to a diminution of their natural language\nprocessing (NLP) capabilities. To avoid this performance degradation, a\nstraightforward solution is to freeze the language model while developing\nmultimodal competencies. Unfortunately, previous works have not attained\nsatisfactory outcomes. Building on the strategy of freezing the language model,\nwe conduct thorough structural exploration and introduce the Inner-Adaptor\nArchitecture (IAA). Specifically, the architecture incorporates multiple\nmultimodal adaptors at varying depths within the large language model to\nfacilitate direct interaction with the inherently text-oriented transformer\nlayers, thereby enabling the frozen language model to acquire multimodal\ncapabilities. Unlike previous approaches of freezing language models that\nrequire large-scale aligned data, our proposed architecture is able to achieve\nsuperior performance on small-scale datasets. We conduct extensive experiments\nto improve the general multimodal capabilities and visual grounding abilities\nof the MLLM. Our approach remarkably outperforms previous state-of-the-art\nmethods across various vision-language benchmarks without sacrificing\nperformance on NLP tasks. Code and models are available at\nhttps://github.com/360CVGroup/Inner-Adaptor-Architecture."
  },
  {
    "arxiv_id": "2408.12834",
    "title": "CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition",
    "url": "http://arxiv.org/abs/2408.12834v1",
    "abstract": "Few-shot Named Entity Recognition (NER), the task of identifying named\nentities with only a limited amount of labeled data, has gained increasing\nsignificance in natural language processing. While existing methodologies have\nshown some effectiveness, such as enriching label semantics through various\nprompting modes or employing metric learning techniques, their performance\nexhibits limited robustness across diverse domains due to the lack of rich\nknowledge in their pre-trained models. To address this issue, we propose\nCLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework\nfor Few-Shot Named Entity Recognition, achieving promising results with limited\ntraining data. Considering the impact of LLM's internal representations on\ndownstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive\nlearning mechanisms specifically tailored for few-shot NER. By enhancing the\nmodel's internal representations, CLLMFS effectively improves both entity\nboundary awareness ability and entity recognition accuracy. Our method has\nachieved state-of-the-art performance improvements on F1-score ranging from\n2.58\\% to 97.74\\% over existing best-performing methods across several\nrecognized benchmarks. Furthermore, through cross-domain NER experiments\nconducted on multiple datasets, we have further validated the robust\ngeneralization capability of our method. Our code will be released in the near\nfuture."
  },
  {
    "arxiv_id": "2408.12779",
    "title": "Investigating LLM Applications in E-Commerce",
    "url": "http://arxiv.org/abs/2408.12779v1",
    "abstract": "The emergence of Large Language Models (LLMs) has revolutionized natural\nlanguage processing in various applications especially in e-commerce. One\ncrucial step before the application of such LLMs in these fields is to\nunderstand and compare the performance in different use cases in such tasks.\nThis paper explored the efficacy of LLMs in the e-commerce domain, focusing on\ninstruction-tuning an open source LLM model with public e-commerce datasets of\nvarying sizes and comparing the performance with the conventional models\nprevalent in industrial applications. We conducted a comprehensive comparison\nbetween LLMs and traditional pre-trained language models across specific tasks\nintrinsic to the e-commerce domain, namely classification, generation,\nsummarization, and named entity recognition (NER). Furthermore, we examined the\neffectiveness of the current niche industrial application of very large LLM,\nusing in-context learning, in e-commerce specific tasks. Our findings indicate\nthat few-shot inference with very large LLMs often does not outperform\nfine-tuning smaller pre-trained models, underscoring the importance of\ntask-specific model optimization.Additionally, we investigated different\ntraining methodologies such as single-task training, mixed-task training, and\nLoRA merging both within domain/tasks and between different tasks. Through\nrigorous experimentation and analysis, this paper offers valuable insights into\nthe potential effectiveness of LLMs to advance natural language processing\ncapabilities within the e-commerce industry."
  },
  {
    "arxiv_id": "2408.14380",
    "title": "Probing Causality Manipulation of Large Language Models",
    "url": "http://arxiv.org/abs/2408.14380v1",
    "abstract": "Large language models (LLMs) have shown various ability on natural language\nprocessing, including problems about causality. It is not intuitive for LLMs to\ncommand causality, since pretrained models usually work on statistical\nassociations, and do not focus on causes and effects in sentences. So that\nprobing internal manipulation of causality is necessary for LLMs. This paper\nproposes a novel approach to probe causality manipulation hierarchically, by\nproviding different shortcuts to models and observe behaviors. We exploit\nretrieval augmented generation (RAG) and in-context learning (ICL) for models\non a designed causality classification task. We conduct experiments on\nmainstream LLMs, including GPT-4 and some smaller and domain-specific models.\nOur results suggest that LLMs can detect entities related to causality and\nrecognize direct causal relationships. However, LLMs lack specialized cognition\nfor causality, merely treating them as part of the global semantic of the\nsentence."
  },
  {
    "arxiv_id": "2408.13959",
    "title": "Bidirectional Awareness Induction in Autoregressive Seq2Seq Models",
    "url": "http://arxiv.org/abs/2408.13959v1",
    "abstract": "Autoregressive Sequence-To-Sequence models are the foundation of many Deep\nLearning achievements in major research fields such as Vision and Natural\nLanguage Processing. Despite that, they still present significant limitations.\nFor instance, when errors occur in the early steps of the prediction, the whole\noutput is severely affected. Such reliance on previously predicted tokens and\nthe inherent computational unfriendliness of sequential algorithms, motivated\nresearchers to explore different architectures and methods in the search for\nbidirectional approaches. In this work, we introduce the Bidirectional\nAwareness Induction (BAI), a training method that leverages a subset of\nelements in the network, the Pivots, to perform bidirectional learning without\nbreaking the autoregressive constraints. To showcase its flexibility, we apply\nthe method to three architectures, the Transformer, ExpansionNet v2 and GPT,\nthen perform experiments over three tasks. Experimental results showcase BAI's\neffectiveness on all selected tasks and architectures. In particular, we\nobserved an increase of up to 2.4 CIDEr in Image-Captioning, 4.96 BLEU in\nNeural Machine Translation, and 1.16 ROUGE in Text Summarization compared to\nthe respective baselines. Notably, BAI not only has a positive impact on models\ntrained from scratch but on pre-trained models as well. Such an aspect,\ncombined with the absence of architectural requirements synergizes well with\nthe current trend of LLMs."
  },
  {
    "arxiv_id": "2408.13889",
    "title": "LLM with Relation Classifier for Document-Level Relation Extraction",
    "url": "http://arxiv.org/abs/2408.13889v1",
    "abstract": "Large language models (LLMs) have created a new paradigm for natural language\nprocessing. Despite their advancement, LLM-based methods still lag behind\ntraditional approaches in document-level relation extraction (DocRE), a\ncritical task for understanding complex entity relations within long context.\nThis paper investigates the causes of this performance gap, identifying the\ndispersion of attention by LLMs due to entity pairs without relations as a key\nfactor. We then introduce a novel classifier-LLM approach to DocRE.\nParticularly, the proposed approach begins with a classifier designed to select\nentity pair candidates that exhibit potential relations and then feed them to\nLLM for final relation classification. This method ensures that the LLM's\nattention is directed at relation-expressing entity pairs instead of those\nwithout relations during inference. Experiments on DocRE benchmarks reveal that\nour method significantly outperforms recent LLM-based DocRE models and narrows\nthe performance gap with state-of-the-art BERT-based models."
  },
  {
    "arxiv_id": "2408.15185",
    "title": "PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization",
    "url": "http://arxiv.org/abs/2408.15185v1",
    "abstract": "Video Anomaly Detection (VAD) presents a significant challenge in computer\nvision, particularly due to the unpredictable and infrequent nature of\nanomalous events, coupled with the diverse and dynamic environments in which\nthey occur. Human-centric VAD, a specialized area within this domain, faces\nadditional complexities, including variations in human behavior, potential\nbiases in data, and substantial privacy concerns related to human subjects.\nThese issues complicate the development of models that are both robust and\ngeneralizable. To address these challenges, recent advancements have focused on\npose-based VAD, which leverages human pose as a high-level feature to mitigate\nprivacy concerns, reduce appearance biases, and minimize background\ninterference. In this paper, we introduce SPARTA, a novel transformer-based\narchitecture designed specifically for human-centric pose-based VAD. SPARTA\nintroduces an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)\ntokenization method that produces an enriched representation of human motion\nover time. This approach ensures that the transformer's attention mechanism\ncaptures both spatial and temporal patterns simultaneously, rather than\nfocusing on only one aspect. The addition of the relative pose further\nemphasizes subtle deviations from normal human movements. The architecture's\ncore, a novel Unified Encoder Twin Decoders (UETD) transformer, significantly\nimproves the detection of anomalous behaviors in video data. Extensive\nevaluations across multiple benchmark datasets demonstrate that SPARTA\nconsistently outperforms existing methods, establishing a new state-of-the-art\nin pose-based VAD."
  },
  {
    "arxiv_id": "2408.15178",
    "title": "A Review of Transformer-Based Models for Computer Vision Tasks: Capturing Global Context and Spatial Relationships",
    "url": "http://arxiv.org/abs/2408.15178v1",
    "abstract": "Transformer-based models have transformed the landscape of natural language\nprocessing (NLP) and are increasingly applied to computer vision tasks with\nremarkable success. These models, renowned for their ability to capture\nlong-range dependencies and contextual information, offer a promising\nalternative to traditional convolutional neural networks (CNNs) in computer\nvision. In this review paper, we provide an extensive overview of various\ntransformer architectures adapted for computer vision tasks. We delve into how\nthese models capture global context and spatial relationships in images,\nempowering them to excel in tasks such as image classification, object\ndetection, and segmentation. Analyzing the key components, training\nmethodologies, and performance metrics of transformer-based models, we\nhighlight their strengths, limitations, and recent advancements. Additionally,\nwe discuss potential research directions and applications of transformer-based\nmodels in computer vision, offering insights into their implications for future\nadvancements in the field."
  },
  {
    "arxiv_id": "2408.14845",
    "title": "AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark",
    "url": "http://arxiv.org/abs/2408.14845v1",
    "abstract": "Detecting biases in natural language understanding (NLU) for African American\nVernacular English (AAVE) is crucial to developing inclusive natural language\nprocessing (NLP) systems. To address dialect-induced performance discrepancies,\nwe introduce AAVENUE ({AAVE} {N}atural Language {U}nderstanding {E}valuation),\na benchmark for evaluating large language model (LLM) performance on NLU tasks\nin AAVE and Standard American English (SAE). AAVENUE builds upon and extends\nexisting benchmarks like VALUE, replacing deterministic syntactic and\nmorphological transformations with a more flexible methodology leveraging\nLLM-based translation with few-shot prompting, improving performance across our\nevaluation metrics when translating key tasks from the GLUE and SuperGLUE\nbenchmarks. We compare AAVENUE and VALUE translations using five popular LLMs\nand a comprehensive set of metrics including fluency, BARTScore, quality,\ncoherence, and understandability. Additionally, we recruit fluent AAVE speakers\nto validate our translations for authenticity. Our evaluations reveal that LLMs\nconsistently perform better on SAE tasks than AAVE-translated versions,\nunderscoring inherent biases and highlighting the need for more inclusive NLP\nmodels. We have open-sourced our source code on GitHub and created a website to\nshowcase our work at https://aavenue.live."
  },
  {
    "arxiv_id": "2408.14825",
    "title": "From Rule-Based Models to Deep Learning Transformers Architectures for Natural Language Processing and Sign Language Translation Systems: Survey, Taxonomy and Performance Evaluation",
    "url": "http://arxiv.org/abs/2408.14825v1",
    "abstract": "With the growing Deaf and Hard of Hearing population worldwide and the\npersistent shortage of certified sign language interpreters, there is a\npressing need for an efficient, signs-driven, integrated end-to-end translation\nsystem, from sign to gloss to text and vice-versa. There has been a wealth of\nresearch on machine translations and related reviews. However, there are few\nworks on sign language machine translation considering the particularity of the\nlanguage being continuous and dynamic. This paper aims to address this void,\nproviding a retrospective analysis of the temporal evolution of sign language\nmachine translation algorithms and a taxonomy of the Transformers\narchitectures, the most used approach in language translation. We also present\nthe requirements of a real-time Quality-of-Service sign language ma-chine\ntranslation system underpinned by accurate deep learning algorithms. We propose\nfuture research directions for sign language translation systems."
  },
  {
    "arxiv_id": "2408.14520",
    "title": "Towards Graph Prompt Learning: A Survey and Beyond",
    "url": "http://arxiv.org/abs/2408.14520v1",
    "abstract": "Large-scale \"pre-train and prompt learning\" paradigms have demonstrated\nremarkable adaptability, enabling broad applications across diverse domains\nsuch as question answering, image recognition, and multimodal retrieval. This\napproach fully leverages the potential of large-scale pre-trained models,\nreducing downstream data requirements and computational costs while enhancing\nmodel applicability across various tasks. Graphs, as versatile data structures\nthat capture relationships between entities, play pivotal roles in fields such\nas social network analysis, recommender systems, and biological graphs. Despite\nthe success of pre-train and prompt learning paradigms in Natural Language\nProcessing (NLP) and Computer Vision (CV), their application in graph domains\nremains nascent. In graph-structured data, not only do the node and edge\nfeatures often have disparate distributions, but the topological structures\nalso differ significantly. This diversity in graph data can lead to\nincompatible patterns or gaps between pre-training and fine-tuning on\ndownstream graphs. We aim to bridge this gap by summarizing methods for\nalleviating these disparities. This includes exploring prompt design\nmethodologies, comparing related techniques, assessing application scenarios\nand datasets, and identifying unresolved problems and challenges. This survey\ncategorizes over 100 relevant works in this field, summarizing general design\nprinciples and the latest applications, including text-attributed graphs,\nmolecules, proteins, and recommendation systems. Through this extensive review,\nwe provide a foundational understanding of graph prompt learning, aiming to\nimpact not only the graph mining community but also the broader Artificial\nGeneral Intelligence (AGI) community."
  },
  {
    "arxiv_id": "2408.15518",
    "title": "Dolphin: Long Context as a New Modality for Energy-Efficient On-Device Language Models",
    "url": "http://arxiv.org/abs/2408.15518v1",
    "abstract": "This paper presents Dolphin, a novel decoder-decoder architecture for\nenergy-efficient processing of long contexts in language models. Our approach\naddresses the significant energy consumption and latency challenges inherent in\non-device models. Dolphin employs a compact 0.5B parameter decoder to distill\nextensive contextual information into a memory embedding, substantially\nreducing the input length for the primary 7B parameter decoder model. Inspired\nby vision-language models, we repurpose the image embedding projector to encode\nlong textual contexts, effectively treating extended context as a distinct\nmodality. This innovative method enables processing of substantially longer\ncontexts without the typical computational overhead associated with extended\ninput sequences. Empirical evaluations demonstrate a 10-fold improvement in\nenergy efficiency and a 5-fold reduction in latency compared to conventional\nfull-length context processing methods without losing quality of the response.\nOur work contributes to the development of more sustainable and scalable\nlanguage models for on-device applications, addressing the critical need for\nenergy-efficient and responsive AI technologies in resource-constrained\nenvironments while maintaining the accuracy to understand long contexts. This\nresearch has implications for the broader field of natural language processing,\nparticularly in the domain of efficient model design for resource-limited\nsettings. By enabling more sophisticated AI capabilities on edge devices,\nDolphin paves the way for advanced language processing in a wide range of\napplications where computational resources are at a premium. The Dolphin model\nis publicly available at https://huggingface.co/NexaAIDev/Dolphin."
  },
  {
    "arxiv_id": "2408.16756",
    "title": "How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models",
    "url": "http://arxiv.org/abs/2408.16756v1",
    "abstract": "The rapid evolution of large language models (LLMs) has transformed the\ncompetitive landscape in natural language processing (NLP), particularly for\nEnglish and other data-rich languages. However, underrepresented languages like\nCantonese, spoken by over 85 million people, face significant development gaps,\nwhich is particularly concerning given the economic significance of the\nGuangdong-Hong Kong-Macau Greater Bay Area, and in substantial\nCantonese-speaking populations in places like Singapore and North America.\nDespite its wide use, Cantonese has scant representation in NLP research,\nespecially compared to other languages from similarly developed regions. To\nbridge these gaps, we outline current Cantonese NLP methods and introduce new\nbenchmarks designed to evaluate LLM performance in factual generation,\nmathematical logic, complex reasoning, and general knowledge in Cantonese,\nwhich aim to advance open-source Cantonese LLM technology. We also propose\nfuture research directions and recommended models to enhance Cantonese LLM\ndevelopment."
  },
  {
    "arxiv_id": "2408.16740",
    "title": "Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models",
    "url": "http://arxiv.org/abs/2408.16740v1",
    "abstract": "This paper addresses the conceptual, methodological and technical challenges\nin studying large language models (LLMs) and the texts they produce from a\nquantitative linguistics perspective. It builds on a theoretical framework that\ndistinguishes between the LLM as a substrate and the entities the model\nsimulates. The paper advocates for a strictly non-anthropomorphic approach to\nmodels while cautiously applying methodologies used in studying human\nlinguistic behavior to the simulated entities. While natural language\nprocessing researchers focus on the models themselves, their architecture,\nevaluation, and methods for improving performance, we as quantitative linguists\nshould strive to build a robust theory concerning the characteristics of texts\nproduced by LLMs, how they differ from human-produced texts, and the properties\nof simulated entities. Additionally, we should explore the potential of LLMs as\nan instrument for studying human culture, of which language is an integral\npart."
  },
  {
    "arxiv_id": "2408.16296",
    "title": "Rethinking Sparse Lexical Representations for Image Retrieval in the Age of Rising Multi-Modal Large Language Models",
    "url": "http://arxiv.org/abs/2408.16296v1",
    "abstract": "In this paper, we rethink sparse lexical representations for image retrieval.\nBy utilizing multi-modal large language models (M-LLMs) that support visual\nprompting, we can extract image features and convert them into textual data,\nenabling us to utilize efficient sparse retrieval algorithms employed in\nnatural language processing for image retrieval tasks. To assist the LLM in\nextracting image features, we apply data augmentation techniques for key\nexpansion and analyze the impact with a metric for relevance between images and\ntextual data. We empirically show the superior precision and recall performance\nof our image retrieval method compared to conventional vision-language\nmodel-based methods on the MS-COCO, PASCAL VOC, and NUS-WIDE datasets in a\nkeyword-based image retrieval scenario, where keywords serve as search queries.\nWe also demonstrate that the retrieval performance can be improved by\niteratively incorporating keywords into search queries."
  },
  {
    "arxiv_id": "2408.16978",
    "title": "Training Ultra Long Context Language Model with Fully Pipelined Distributed Transformer",
    "url": "http://arxiv.org/abs/2408.16978v1",
    "abstract": "Large Language Models (LLMs) with long context capabilities are integral to\ncomplex tasks in natural language processing and computational biology, such as\ntext generation and protein sequence analysis. However, training LLMs directly\non extremely long contexts demands considerable GPU resources and increased\nmemory, leading to higher costs and greater complexity. Alternative approaches\nthat introduce long context capabilities via downstream finetuning or\nadaptations impose significant design limitations. In this paper, we propose\nFully Pipelined Distributed Transformer (FPDT) for efficiently training\nlong-context LLMs with extreme hardware efficiency. For GPT and Llama models,\nwe achieve a 16x increase in sequence length that can be trained on the same\nhardware compared to current state-of-the-art solutions. With our dedicated\nsequence chunk pipeline design, we can now train 8B LLM with 2 million sequence\nlength on only 4 GPUs, while also maintaining over 55% of MFU. Our proposed\nFPDT is agnostic to existing training techniques and is proven to work\nefficiently across different LLM models."
  },
  {
    "arxiv_id": "2408.16942",
    "title": "A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models",
    "url": "http://arxiv.org/abs/2408.16942v1",
    "abstract": "The COVID-19 pandemic has exacerbated xenophobia, particularly Sinophobia,\nleading to widespread discrimination against individuals of Chinese descent.\nLarge language models (LLMs) are pre-trained deep learning models used for\nnatural language processing (NLP) tasks. The ability of LLMs to understand and\ngenerate human-like text makes them particularly useful for analysing social\nmedia data to detect and evaluate sentiments. We present a sentiment analysis\nframework utilising LLMs for longitudinal sentiment analysis of the Sinophobic\nsentiments expressed in X (Twitter) during the COVID-19 pandemic. The results\nshow a significant correlation between the spikes in Sinophobic tweets,\nSinophobic sentiments and surges in COVID-19 cases, revealing that the\nevolution of the pandemic influenced public sentiment and the prevalence of\nSinophobic discourse. Furthermore, the sentiment analysis revealed a\npredominant presence of negative sentiments, such as annoyance and denial,\nwhich underscores the impact of political narratives and misinformation shaping\npublic opinion. The lack of empathetic sentiment which was present in previous\nstudies related to COVID-19 highlights the way the political narratives in\nmedia viewed the pandemic and how it blamed the Chinese community. Our study\nhighlights the importance of transparent communication in mitigating xenophobic\nsentiments during global crises."
  },
  {
    "arxiv_id": "2409.02841",
    "title": "Historical German Text Normalization Using Type- and Token-Based Language Modeling",
    "url": "http://arxiv.org/abs/2409.02841v1",
    "abstract": "Historic variations of spelling poses a challenge for full-text search or\nnatural language processing on historical digitized texts. To minimize the gap\nbetween the historic orthography and contemporary spelling, usually an\nautomatic orthographic normalization of the historical source material is\npursued. This report proposes a normalization system for German literary texts\nfrom c. 1700-1900, trained on a parallel corpus. The proposed system makes use\nof a machine learning approach using Transformer language models, combining an\nencoder-decoder model to normalize individual word types, and a pre-trained\ncausal language model to adjust these normalizations within their context. An\nextensive evaluation shows that the proposed system provides state-of-the-art\naccuracy, comparable with a much larger fully end-to-end sentence-based\nnormalization system, fine-tuning a pre-trained Transformer large language\nmodel. However, the normalization of historical text remains a challenge due to\ndifficulties for models to generalize, and the lack of extensive high-quality\nparallel data."
  },
  {
    "arxiv_id": "2409.02836",
    "title": "Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models",
    "url": "http://arxiv.org/abs/2409.02836v1",
    "abstract": "This study performs analysis of Predictive statements, Hope speech, and\nRegret Detection behaviors within cryptocurrency-related discussions,\nleveraging advanced natural language processing techniques. We introduce a\nnovel classification scheme named \"Prediction statements,\" categorizing\ncomments into Predictive Incremental, Predictive Decremental, Predictive\nNeutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large\nlanguage model, we explore sentiment dynamics across five prominent\ncryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis\nreveals distinct patterns in predictive sentiments, with Matic demonstrating a\nnotably higher propensity for optimistic predictions. Additionally, we\ninvestigate hope and regret sentiments, uncovering nuanced interplay between\nthese emotions and predictive behaviors. Despite encountering limitations\nrelated to data volume and resource availability, our study reports valuable\ndiscoveries concerning investor behavior and sentiment trends within the\ncryptocurrency market, informing strategic decision-making and future research\nendeavors."
  },
  {
    "arxiv_id": "2409.01990",
    "title": "Contemporary Model Compression on Large Language Models Inference",
    "url": "http://arxiv.org/abs/2409.01990v1",
    "abstract": "This paper focuses on modern efficient training and inference technologies on\nfoundation models and illustrates them from two perspectives: model and system\ndesign. Model and System Design optimize LLM training and inference from\ndifferent aspects to save computational resources, making LLMs more efficient,\naffordable, and more accessible. The paper list repository is available at\nhttps://github.com/NoakLiu/Efficient-Foundation-Models-Survey."
  },
  {
    "arxiv_id": "2409.01980",
    "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
    "url": "http://arxiv.org/abs/2409.01980v1",
    "abstract": "Detecting anomalies or out-of-distribution (OOD) samples is critical for\nmaintaining the reliability and trustworthiness of machine learning systems.\nRecently, Large Language Models (LLMs) have demonstrated their effectiveness\nnot only in natural language processing but also in broader applications due to\ntheir advanced comprehension and generative capabilities. The integration of\nLLMs into anomaly and OOD detection marks a significant shift from the\ntraditional paradigm in the field. This survey focuses on the problem of\nanomaly and OOD detection under the context of LLMs. We propose a new taxonomy\nto categorize existing approaches into two classes based on the role played by\nLLMs. Following our proposed taxonomy, we further discuss the related work\nunder each of the categories and finally discuss potential challenges and\ndirections for future research in this field. We also provide an up-to-date\nreading list of relevant papers."
  },
  {
    "arxiv_id": "2409.01952",
    "title": "Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor",
    "url": "http://arxiv.org/abs/2409.01952v1",
    "abstract": "Deep neural networks (DNNs) have long been recognized as vulnerable to\nbackdoor attacks. By providing poisoned training data in the fine-tuning\nprocess, the attacker can implant a backdoor into the victim model. This\nenables input samples meeting specific textual trigger patterns to be\nclassified as target labels of the attacker's choice. While such black-box\nattacks have been well explored in both computer vision and natural language\nprocessing (NLP), backdoor attacks relying on white-box attack philosophy have\nhardly been thoroughly investigated. In this paper, we take the first step to\nintroduce a new type of backdoor attack that conceals itself within the\nunderlying model architecture. Specifically, we propose to design separate\nbackdoor modules consisting of two functions: trigger detection and noise\ninjection. The add-on modules of model architecture layers can detect the\npresence of input trigger tokens and modify layer weights using Gaussian noise\nto disturb the feature distribution of the baseline model. We conduct extensive\nexperiments to evaluate our attack methods using two model architecture\nsettings on five different large language datasets. We demonstrate that the\ntraining-free architectural backdoor on a large language model poses a genuine\nthreat. Unlike the-state-of-art work, it can survive the rigorous fine-tuning\nand retraining process, as well as evade output probability-based defense\nmethods (i.e. BDDR). All the code and data is available\nhttps://github.com/SiSL-URI/Arch_Backdoor_LLM."
  },
  {
    "arxiv_id": "2409.01941",
    "title": "Towards Leveraging Large Language Models for Automated Medical Q&A Evaluation",
    "url": "http://arxiv.org/abs/2409.01941v1",
    "abstract": "This paper explores the potential of using Large Language Models (LLMs) to\nautomate the evaluation of responses in medical Question and Answer (Q\\&A)\nsystems, a crucial form of Natural Language Processing. Traditionally, human\nevaluation has been indispensable for assessing the quality of these responses.\nHowever, manual evaluation by medical professionals is time-consuming and\ncostly. Our study examines whether LLMs can reliably replicate human\nevaluations by using questions derived from patient data, thereby saving\nvaluable time for medical experts. While the findings suggest promising\nresults, further research is needed to address more specific or complex\nquestions that were beyond the scope of this initial investigation."
  },
  {
    "arxiv_id": "2409.03384",
    "title": "Hardware Acceleration of LLMs: A comprehensive survey and comparison",
    "url": "http://arxiv.org/abs/2409.03384v1",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. In this paper, we present a\ncomprehensive survey of the several research efforts that have been presented\nfor the acceleration of transformer networks for Large Language Models using\nhardware accelerators.\n  The survey presents the frameworks that have been proposed and then performs\na qualitative and quantitative comparison regarding the technology, the\nprocessing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy\nefficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each\nframework. The main challenge in comparison is that every proposed scheme is\nimplemented on a different process technology making hard a fair comparison.\nThe main contribution of this paper is that we extrapolate the results of the\nperformance and the energy efficiency on the same technology to make a fair\ncomparison; one theoretical and one more practical. We implement part of the\nLLMs on several FPGA chips to extrapolate the results to the same process\ntechnology and then we make a fair comparison of the performance."
  },
  {
    "arxiv_id": "2409.03375",
    "title": "Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time",
    "url": "http://arxiv.org/abs/2409.03375v1",
    "abstract": "Based on official estimates, 50 million people worldwide are affected by\ndementia, and this number increases by 10 million new patients every year.\nWithout a cure, clinical prognostication and early intervention represent the\nmost effective ways to delay its progression. To this end, Artificial\nIntelligence and computational linguistics can be exploited for natural\nlanguage analysis, personalized assessment, monitoring, and treatment. However,\ntraditional approaches need more semantic knowledge management and\nexplicability capabilities. Moreover, using Large Language Models (LLMs) for\ncognitive decline diagnosis is still scarce, even though these models represent\nthe most advanced way for clinical-patient communication using intelligent\nsystems. Consequently, we leverage an LLM using the latest Natural Language\nProcessing (NLP) techniques in a chatbot solution to provide interpretable\nMachine Learning prediction of cognitive decline in real-time.\nLinguistic-conceptual features are exploited for appropriate natural language\nanalysis. Through explainability, we aim to fight potential biases of the\nmodels and improve their potential to help clinical workers in their diagnosis\ndecisions. More in detail, the proposed pipeline is composed of (i) data\nextraction employing NLP-based prompt engineering; (ii) stream-based data\nprocessing including feature engineering, analysis, and selection; (iii)\nreal-time classification; and (iv) the explainability dashboard to provide\nvisual and natural language descriptions of the prediction outcome.\nClassification results exceed 80 % in all evaluation metrics, with a recall\nvalue for the mental deterioration class about 85 %. To sum up, we contribute\nwith an affordable, flexible, non-invasive, personalized diagnostic system to\nthis work."
  },
  {
    "arxiv_id": "2409.04181",
    "title": "Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering",
    "url": "http://arxiv.org/abs/2409.04181v1",
    "abstract": "Advancements in natural language processing have revolutionized the way we\ncan interact with digital information systems, such as databases, making them\nmore accessible. However, challenges persist, especially when accuracy is\ncritical, as in the biomedical domain. A key issue is the hallucination\nproblem, where models generate information unsupported by the underlying data,\npotentially leading to dangerous misinformation. This paper presents a novel\napproach designed to bridge this gap by combining Large Language Models (LLM)\nand Knowledge Graphs (KG) to improve the accuracy and reliability of\nquestion-answering systems, on the example of a biomedical KG. Built on the\nLangChain framework, our method incorporates a query checker that ensures the\nsyntactical and semantic validity of LLM-generated queries, which are then used\nto extract information from a Knowledge Graph, substantially reducing errors\nlike hallucinations. We evaluated the overall performance using a new benchmark\ndataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo\nand llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other\nmodels in generating accurate queries, open-source models like llama3:70b show\npromise with appropriate prompt engineering. To make this approach accessible,\na user-friendly web-based interface has been developed, allowing users to input\nnatural language queries, view generated and corrected Cypher queries, and\nverify the resulting paths for accuracy. Overall, this hybrid approach\neffectively addresses common issues such as data gaps and hallucinations,\noffering a reliable and intuitive solution for question answering systems. The\nsource code for generating the results of this paper and for the user-interface\ncan be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui"
  },
  {
    "arxiv_id": "2409.05314",
    "title": "Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications",
    "url": "http://arxiv.org/abs/2409.05314v1",
    "abstract": "The emergence of large language models (LLMs) has significantly impacted\nvarious fields, from natural language processing to sectors like medicine and\nfinance. However, despite their rapid proliferation, the applications of LLMs\nin telecommunications remain limited, often relying on general-purpose models\nthat lack domain-specific specialization. This lack of specialization results\nin underperformance, particularly when dealing with telecommunications-specific\ntechnical terminology and their associated mathematical representations. This\npaper addresses this gap by first creating and disseminating Tele-Data, a\ncomprehensive dataset of telecommunications material curated from relevant\nsources, and Tele-Eval, a large-scale question-and-answer dataset tailored to\nthe domain. Through extensive experiments, we explore the most effective\ntraining techniques for adapting LLMs to the telecommunications domain, ranging\nfrom examining the division of expertise across various telecommunications\naspects to employing parameter-efficient techniques. We also investigate how\nmodels of different sizes behave during adaptation and analyze the impact of\ntheir training data on this behavior. Leveraging these findings, we develop and\nopen-source Tele-LLMs, the first series of language models ranging from 1B to\n8B parameters, specifically tailored for telecommunications. Our evaluations\ndemonstrate that these models outperform their general-purpose counterparts on\nTele-Eval and telecommunications-related literature tasks while retaining their\npreviously acquired capabilities, thus avoiding the catastrophic forgetting\nphenomenon."
  },
  {
    "arxiv_id": "2409.04833",
    "title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
    "url": "http://arxiv.org/abs/2409.04833v1",
    "abstract": "In recent years, large language models (LLMs) have achieved remarkable\nsuccess in natural language processing (NLP). LLMs require an extreme amount of\nparameters to attain high performance. As models grow into the\ntrillion-parameter range, computational and memory costs increase\nsignificantly. This makes it difficult for many researchers to access the\nresources needed to train or apply these models. Optimizing LLM performance\ninvolves two main approaches: fine-tuning pre-trained models for specific tasks\nto achieve state-of-the-art performance, and reducing costs or improving\ntraining time while maintaining similar performance. This paper presents a\nsystematic literature review (SLR) following the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65\npublications out of 983 from 2017 to December 2023, retrieved from 5 databases.\nThe study presents methods to optimize and accelerate LLMs while achieving\ncutting-edge results without sacrificing accuracy. We begin with an overview of\nthe development of language modeling, followed by a detailed explanation of\ncommonly used frameworks and libraries, and a taxonomy for improving and\nspeeding up LLMs based on three classes: LLM training, LLM inference, and\nsystem serving. We then delve into recent optimization and acceleration\nstrategies such as training optimization, hardware optimization, scalability\nand reliability, accompanied by the taxonomy and categorization of these\nstrategies. Finally, we provide an in-depth comparison of each class and\nstrategy, with two case studies on optimizing model training and enhancing\ninference efficiency. These case studies showcase practical approaches to\naddress LLM resource limitations while maintaining performance."
  },
  {
    "arxiv_id": "2409.06635",
    "title": "MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders",
    "url": "http://arxiv.org/abs/2409.06635v1",
    "abstract": "The rapid advancements in large language models (LLMs) have significantly\nenhanced natural language processing capabilities, facilitating the development\nof AudioLLMs that process and understand speech and audio inputs alongside\ntext. Existing AudioLLMs typically combine a pre-trained audio encoder with a\npre-trained LLM, which are subsequently finetuned on specific audio tasks.\nHowever, the pre-trained audio encoder has constrained capacity to capture\nfeatures for new tasks and datasets. To address this, we propose to incorporate\nmixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE\nsupplements a base encoder with a pool of relatively light weight encoders,\nselectively activated based on the audio input to enhance feature extraction\nwithout significantly increasing model size. Our empirical results demonstrate\nthat MoWE effectively improves multi-task performance, broadening the\napplicability of AudioLLMs to more diverse audio tasks."
  },
  {
    "arxiv_id": "2409.06518",
    "title": "Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games",
    "url": "http://arxiv.org/abs/2409.06518v1",
    "abstract": "Large language models (LLMs) have become a dominant approach in natural\nlanguage processing, yet their internal knowledge structures remain largely\nunexplored. In this paper, we analyze the internal knowledge structures of LLMs\nusing historical medal tallies from the Olympic Games. We task the models with\nproviding the medal counts for each team and identifying which teams achieved\nspecific rankings. Our results reveal that while state-of-the-art LLMs perform\nremarkably well in reporting medal counts for individual teams, they struggle\nsignificantly with questions about specific rankings. This suggests that the\ninternal knowledge structures of LLMs are fundamentally different from those of\nhumans, who can easily infer rankings from known medal counts. To support\nfurther research, we publicly release our code, dataset, and model outputs."
  },
  {
    "arxiv_id": "2409.06328",
    "title": "Extracting Paragraphs from LLM Token Activations",
    "url": "http://arxiv.org/abs/2409.06328v1",
    "abstract": "Generative large language models (LLMs) excel in natural language processing\ntasks, yet their inner workings remain underexplored beyond token-level\npredictions. This study investigates the degree to which these models decide\nthe content of a paragraph at its onset, shedding light on their contextual\nunderstanding. By examining the information encoded in single-token\nactivations, specifically the \"\\textbackslash n\\textbackslash n\" double newline\ntoken, we demonstrate that patching these activations can transfer significant\ninformation about the context of the following paragraph, providing further\ninsights into the model's capacity to plan ahead."
  },
  {
    "arxiv_id": "2409.06072",
    "title": "DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection",
    "url": "http://arxiv.org/abs/2409.06072v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing tasks. However, their practical application in\nhigh-stake domains, such as fraud and abuse detection, remains an area that\nrequires further exploration. The existing applications often narrowly focus on\nspecific tasks like toxicity or hate speech detection. In this paper, we\npresent a comprehensive benchmark suite designed to assess the performance of\nLLMs in identifying and mitigating fraudulent and abusive language across\nvarious real-world scenarios. Our benchmark encompasses a diverse set of tasks,\nincluding detecting spam emails, hate speech, misogynistic language, and more.\nWe evaluated several state-of-the-art LLMs, including models from Anthropic,\nMistral AI, and the AI21 family, to provide a comprehensive assessment of their\ncapabilities in this critical domain. The results indicate that while LLMs\nexhibit proficient baseline performance in individual fraud and abuse detection\ntasks, their performance varies considerably across tasks, particularly\nstruggling with tasks that demand nuanced pragmatic reasoning, such as\nidentifying diverse forms of misogynistic language. These findings have\nimportant implications for the responsible development and deployment of LLMs\nin high-risk applications. Our benchmark suite can serve as a tool for\nresearchers and practitioners to systematically evaluate LLMs for multi-task\nfraud detection and drive the creation of more robust, trustworthy, and\nethically-aligned systems for fraud and abuse detection."
  },
  {
    "arxiv_id": "2409.07054",
    "title": "Native vs Non-Native Language Prompting: A Comparative Analysis",
    "url": "http://arxiv.org/abs/2409.07054v1",
    "abstract": "Large language models (LLMs) have shown remarkable abilities in different\nfields, including standard Natural Language Processing (NLP) tasks. To elicit\nknowledge from LLMs, prompts play a key role, consisting of natural language\ninstructions. Most open and closed source LLMs are trained on available labeled\nand unlabeled resources--digital content such as text, images, audio, and\nvideos. Hence, these models have better knowledge for high-resourced languages\nbut struggle with low-resourced languages. Since prompts play a crucial role in\nunderstanding their capabilities, the language used for prompts remains an\nimportant research question. Although there has been significant research in\nthis area, it is still limited, and less has been explored for medium to\nlow-resourced languages. In this study, we investigate different prompting\nstrategies (native vs. non-native) on 11 different NLP tasks associated with 12\ndifferent Arabic datasets (9.7K data points). In total, we conducted 197\nexperiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our\nfindings suggest that, on average, the non-native prompt performs the best,\nfollowed by mixed and native prompts."
  },
  {
    "arxiv_id": "2409.08147",
    "title": "LLM-POTUS Score: A Framework of Analyzing Presidential Debates with Large Language Models",
    "url": "http://arxiv.org/abs/2409.08147v1",
    "abstract": "Large language models have demonstrated remarkable capabilities in natural\nlanguage processing, yet their application to political discourse analysis\nremains underexplored. This paper introduces a novel approach to evaluating\npresidential debate performances using LLMs, addressing the longstanding\nchallenge of objectively assessing debate outcomes. We propose a framework that\nanalyzes candidates' \"Policies, Persona, and Perspective\" (3P) and how they\nresonate with the \"Interests, Ideologies, and Identity\" (3I) of four key\naudience groups: voters, businesses, donors, and politicians. Our method\nemploys large language models to generate the LLM-POTUS Score, a quantitative\nmeasure of debate performance based on the alignment between 3P and 3I. We\napply this framework to analyze transcripts from recent U.S. presidential\ndebates, demonstrating its ability to provide nuanced, multi-dimensional\nassessments of candidate performances. Our results reveal insights into the\neffectiveness of different debating strategies and their impact on various\naudience segments. This study not only offers a new tool for political analysis\nbut also explores the potential and limitations of using LLMs as impartial\njudges in complex social contexts. In addition, this framework provides\nindividual citizens with an independent tool to evaluate presidential debate\nperformances, which enhances democratic engagement and reduces reliance on\npotentially biased media interpretations and institutional influence, thereby\nstrengthening the foundation of informed civic participation."
  },
  {
    "arxiv_id": "2409.07604",
    "title": "Multilingual Prompts in LLM-Based Recommenders: Performance Across Languages",
    "url": "http://arxiv.org/abs/2409.07604v1",
    "abstract": "Large language models (LLMs) are increasingly used in natural language\nprocessing tasks. Recommender systems traditionally use methods such as\ncollaborative filtering and matrix factorization, as well as advanced\ntechniques like deep learning and reinforcement learning. Although language\nmodels have been applied in recommendation, the recent trend have focused on\nleveraging the generative capabilities of LLMs for more personalized\nsuggestions. While current research focuses on English due to its resource\nrichness, this work explores the impact of non-English prompts on\nrecommendation performance. Using OpenP5, a platform for developing and\nevaluating LLM-based recommendations, we expanded its English prompt templates\nto include Spanish and Turkish. Evaluation on three real-world datasets, namely\nML1M, LastFM, and Amazon-Beauty, showed that usage of non-English prompts\ngenerally reduce performance, especially in less-resourced languages like\nTurkish. We also retrained an LLM-based recommender model with multilingual\nprompts to analyze performance variations. Retraining with multilingual prompts\nresulted in more balanced performance across languages, but slightly reduced\nEnglish performance. This work highlights the need for diverse language support\nin LLM-based recommenders and suggests future research on creating evaluation\ndatasets, using newer models and additional languages."
  },
  {
    "arxiv_id": "2409.08761",
    "title": "Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT",
    "url": "http://arxiv.org/abs/2409.08761v1",
    "abstract": "As part of a broader look at the impact of generative AI, this study\ninvestigated the emotional responses of journalists to the release of ChatGPT\nat the time of its launch. By analyzing nearly 1 million Tweets from\njournalists at major U.S. news outlets, we tracked changes in emotional tone\nand sentiment before and after the introduction of ChatGPT in November 2022.\nUsing various computational and natural language processing techniques to\nmeasure emotional shifts in response to ChatGPT's release, we found an increase\nin positive emotion and a more favorable tone post-launch, suggesting initial\noptimism toward AI's potential. This research underscores the pivotal role of\njournalists as interpreters of technological innovation and disruption,\nhighlighting how their emotional reactions may shape public narratives around\nemerging technologies. The study contributes to understanding the intersection\nof journalism, emotion, and AI, offering insights into the broader societal\nimpact of generative AI tools."
  },
  {
    "arxiv_id": "2409.08406",
    "title": "Knowledge Tagging with Large Language Model based Multi-Agent System",
    "url": "http://arxiv.org/abs/2409.08406v1",
    "abstract": "Knowledge tagging for questions is vital in modern intelligent educational\napplications, including learning progress diagnosis, practice question\nrecommendations, and course content organization. Traditionally, these\nannotations have been performed by pedagogical experts, as the task demands not\nonly a deep semantic understanding of question stems and knowledge definitions\nbut also a strong ability to link problem-solving logic with relevant knowledge\nconcepts. With the advent of advanced natural language processing (NLP)\nalgorithms, such as pre-trained language models and large language models\n(LLMs), pioneering studies have explored automating the knowledge tagging\nprocess using various machine learning models. In this paper, we investigate\nthe use of a multi-agent system to address the limitations of previous\nalgorithms, particularly in handling complex cases involving intricate\nknowledge definitions and strict numerical constraints. By demonstrating its\nsuperior performance on the publicly available math question knowledge tagging\ndataset, MathKnowCT, we highlight the significant potential of an LLM-based\nmulti-agent system in overcoming the challenges that previous methods have\nencountered. Finally, through an in-depth discussion of the implications of\nautomating knowledge tagging, we underscore the promising results of deploying\nLLM-based algorithms in educational contexts."
  },
  {
    "arxiv_id": "2409.10444",
    "title": "LLM as BT-Planner: Leveraging LLMs for Behavior Tree Generation in Robot Task Planning",
    "url": "http://arxiv.org/abs/2409.10444v1",
    "abstract": "Robotic assembly tasks remain an open challenge due to their long horizon\nnature and complex part relations. Behavior trees (BTs) are increasingly used\nin robot task planning for their modularity and flexibility, but creating them\nmanually can be effort-intensive. Large language models (LLMs) have recently\nbeen applied to robotic task planning for generating action sequences, yet\ntheir ability to generate BTs has not been fully investigated. To this end, we\npropose LLM-as-BT-Planner, a novel framework that leverages LLMs for BT\ngeneration in robotic assembly task planning. Four in-context learning methods\nare introduced to utilize the natural language processing and inference\ncapabilities of LLMs for producing task plans in BT format, reducing manual\neffort while ensuring robustness and comprehensibility. Additionally, we\nevaluate the performance of fine-tuned smaller LLMs on the same tasks.\nExperiments in both simulated and real-world settings demonstrate that our\nframework enhances LLMs' ability to generate BTs, improving success rate\nthrough in-context learning and supervised fine-tuning."
  },
  {
    "arxiv_id": "2409.10011",
    "title": "HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making",
    "url": "http://arxiv.org/abs/2409.10011v1",
    "abstract": "Large language models (LLMs) have significantly advanced natural language\nprocessing tasks, yet they are susceptible to generating inaccurate or\nunreliable responses, a phenomenon known as hallucination. In critical domains\nsuch as health and medicine, these hallucinations can pose serious risks. This\npaper introduces HALO, a novel framework designed to enhance the accuracy and\nreliability of medical question-answering (QA) systems by focusing on the\ndetection and mitigation of hallucinations. Our approach generates multiple\nvariations of a given query using LLMs and retrieves relevant information from\nexternal open knowledge bases to enrich the context. We utilize maximum\nmarginal relevance scoring to prioritize the retrieved context, which is then\nprovided to LLMs for answer generation, thereby reducing the risk of\nhallucinations. The integration of LangChain further streamlines this process,\nresulting in a notable and robust increase in the accuracy of both open-source\nand commercial LLMs, such as Llama-3.1 (from 44% to 65%) and ChatGPT (from 56%\nto 70%). This framework underscores the critical importance of addressing\nhallucinations in medical QA systems, ultimately improving clinical\ndecision-making and patient care. The open-source HALO is available at:\nhttps://github.com/ResponsibleAILab/HALO."
  },
  {
    "arxiv_id": "2409.09989",
    "title": "Comprehensive Study on Sentiment Analysis: From Rule-based to modern LLM based system",
    "url": "http://arxiv.org/abs/2409.09989v1",
    "abstract": "This paper provides a comprehensive survey of sentiment analysis within the\ncontext of artificial intelligence (AI) and large language models (LLMs).\nSentiment analysis, a critical aspect of natural language processing (NLP), has\nevolved significantly from traditional rule-based methods to advanced deep\nlearning techniques. This study examines the historical development of\nsentiment analysis, highlighting the transition from lexicon-based and\npattern-based approaches to more sophisticated machine learning and deep\nlearning models. Key challenges are discussed, including handling bilingual\ntexts, detecting sarcasm, and addressing biases. The paper reviews\nstate-of-the-art approaches, identifies emerging trends, and outlines future\nresearch directions to advance the field. By synthesizing current methodologies\nand exploring future opportunities, this survey aims to understand sentiment\nanalysis in the AI and LLM context thoroughly."
  },
  {
    "arxiv_id": "2409.09825",
    "title": "GP-GPT: Large Language Model for Gene-Phenotype Mapping",
    "url": "http://arxiv.org/abs/2409.09825v1",
    "abstract": "Pre-trained large language models(LLMs) have attracted increasing attention\nin biomedical domains due to their success in natural language processing.\nHowever, the complex traits and heterogeneity of multi-sources genomics data\npose significant challenges when adapting these models to the bioinformatics\nand biomedical field. To address these challenges, we present GP-GPT, the first\nspecialized large language model for genetic-phenotype knowledge representation\nand genomics relation analysis. Our model is fine-tuned in two stages on a\ncomprehensive corpus composed of over 3,000,000 terms in genomics, proteomics,\nand medical genetics, derived from multiple large-scale validated datasets and\nscientific publications. GP-GPT demonstrates proficiency in accurately\nretrieving medical genetics information and performing common genomics analysis\ntasks, such as genomics information retrieval and relationship determination.\nComparative experiments across domain-specific tasks reveal that GP-GPT\noutperforms state-of-the-art LLMs, including Llama2, Llama3 and GPT-4. These\nresults highlight GP-GPT's potential to enhance genetic disease relation\nresearch and facilitate accurate and efficient analysis in the fields of\ngenomics and medical genetics. Our investigation demonstrated the subtle\nchanges of bio-factor entities' representations in the GP-GPT, which suggested\nthe opportunities for the application of LLMs to advancing gene-phenotype\nresearch."
  },
  {
    "arxiv_id": "2409.09822",
    "title": "Causal Inference with Large Language Model: A Survey",
    "url": "http://arxiv.org/abs/2409.09822v1",
    "abstract": "Causal inference has been a pivotal challenge across diverse domains such as\nmedicine and economics, demanding a complicated integration of human knowledge,\nmathematical reasoning, and data mining capabilities. Recent advancements in\nnatural language processing (NLP), particularly with the advent of large\nlanguage models (LLMs), have introduced promising opportunities for traditional\ncausal inference tasks. This paper reviews recent progress in applying LLMs to\ncausal inference, encompassing various tasks spanning different levels of\ncausation. We summarize the main causal problems and approaches, and present a\ncomparison of their evaluation results in different causal scenarios.\nFurthermore, we discuss key findings and outline directions for future\nresearch, underscoring the potential implications of integrating LLMs in\nadvancing causal inference methodologies."
  },
  {
    "arxiv_id": "2409.09415",
    "title": "Enhancing LLM Problem Solving with REAP: Reflection, Explicit Problem Deconstruction, and Advanced Prompting",
    "url": "http://arxiv.org/abs/2409.09415v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nyet improving their problem-solving capabilities, particularly for complex,\nreasoning-intensive tasks, remains a persistent challenge. This paper\nintroduces the REAP (Reflection, Explicit Problem Deconstruction, and Advanced\nPrompting) method, an innovative approach within the dynamic context generation\nframework. REAP guides LLMs through reflection on the query, deconstructing it\ninto manageable components, and generating relevant context to enhance the\nsolution process. We evaluated REAP using a dataset designed to expose LLM\nlimitations, comparing zero-shot prompting with REAP-enhanced prompts across\nsix state-of-the-art models: OpenAI's o1-preview, o1-mini, GPT-4o, GPT-4o-mini,\nGoogle's Gemini 1.5 Pro, and Claude 3.5 Sonnet. The results demonstrate notable\nperformance gains, with o1-mini improving by 40.97%, GPT-4o by 66.26%, and\nGPT-4o-mini by 112.93%. Despite the already strong baseline performance of\nOpenAI's o1-preview, modest gains were observed. Beyond performance\nimprovements, REAP offers a cost-effective solution; for example, GPT-4o-mini,\nwhich is approximately 100 times cheaper than o1-preview, delivered competitive\nresults. REAP also improves the clarity of model outputs, making it easier for\nhumans to understand the reasoning behind the results and simplifying the\nprocess of identifying and addressing any issues. These findings demonstrate\nREAP's potential to greatly improve the capabilities of LLMs, providing both\nbetter performance and increased cost-efficiency across a wide range of\napplications."
  },
  {
    "arxiv_id": "2409.09380",
    "title": "The Midas Touch: Triggering the Capability of LLMs for RM-API Misuse Detection",
    "url": "http://arxiv.org/abs/2409.09380v1",
    "abstract": "In this paper, we propose an LLM-empowered RM-API misuse detection solution,\nChatDetector, which fully automates LLMs for documentation understanding which\nhelps RM-API constraints retrieval and RM-API misuse detection. To correctly\nretrieve the RM-API constraints, ChatDetector is inspired by the ReAct\nframework which is optimized based on Chain-of-Thought (CoT) to decompose the\ncomplex task into allocation APIs identification, RM-object (allocated/released\nby RM APIs) extraction and RM-APIs pairing (RM APIs usually exist in pairs). It\nfirst verifies the semantics of allocation APIs based on the retrieved RM\nsentences from API documentation through LLMs. Inspired by the LLMs'\nperformance on various prompting methods,ChatDetector adopts a two-dimensional\nprompting approach for cross-validation. At the same time, an\ninconsistency-checking approach between the LLMs' output and the reasoning\nprocess is adopted for the allocation APIs confirmation with an off-the-shelf\nNatural Language Processing (NLP) tool. To accurately pair the RM-APIs,\nChatDetector decomposes the task again and identifies the RM-object type first,\nwith which it can then accurately pair the releasing APIs and further construct\nthe RM-API constraints for misuse detection. With the diminished\nhallucinations, ChatDetector identifies 165 pairs of RM-APIs with a precision\nof 98.21% compared with the state-of-the-art API detectors. By employing a\nstatic detector CodeQL, we ethically report 115 security bugs on the\napplications integrating on six popular libraries to the developers, which may\nresult in severe issues, such as Denial-of-Services (DoS) and memory\ncorruption. Compared with the end-to-end benchmark method, the result shows\nthat ChatDetector can retrieve at least 47% more RM sentences and 80.85% more\nRM-API constraints."
  },
  {
    "arxiv_id": "2409.11022",
    "title": "GEIC: Universal and Multilingual Named Entity Recognition with Large Language Models",
    "url": "http://arxiv.org/abs/2409.11022v2",
    "abstract": "With the advancement of Large Language Models (LLMs), more and more\nresearchers apply LLMs for Named Entity Recognition (NER) methods, bringing\nvitality to this classical Natural Language Processing task. However, existing\ndatasets are designed for traditional machine learning methods, inadequate for\nLLM-based methods in terms of corpus selection, entity categorization, and\ndesign logic. This limitation leads to less effective evaluation and model\nfine-tuning. To address this issue, we propose DynamicNER, the first NER\ndataset specifically designed for LLMs and with dynamic categorization,\ntranscending the limitations of fixed categorization in existing datasets. It\nis also multi-lingual and multi-granular, covering 8 languages and 155 entity\ntypes, with corpus spanning multiple specialized domains. Furthermore, in\nresponse to the limitations demonstrated by existing LLM-based methods during\nDynamicNER testing, we develop CascadeNER, a novel NER method based on a\ntwo-stage strategy and lightweight LLMs, addressing the problems in current\nmethods. Experiments show that DynamicNER is an effective benchmark for\nLLM-based NER methods, and CascadeNER outperforms existing methods with fewer\ncomputational resources. Our work is opened at\nhttps://github.com/CascadeNER/CascadeNER."
  },
  {
    "arxiv_id": "2409.10927",
    "title": "Propulsion: Steering LLM with Tiny Fine-Tuning",
    "url": "http://arxiv.org/abs/2409.10927v2",
    "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nnatural language processing (NLP) and related fields. However, fine-tuning\nthese models for specific tasks remains computationally expensive and risks\ndegrading pre-learned features. To address these challenges, we propose\nPropulsion, a novel parameter efficient fine-tuning (PEFT) method designed to\noptimize task-specific performance while drastically reducing computational\noverhead. Inspired by the concept of controlled adjustments in physical motion,\nPropulsion selectively re-scales specific dimensions of a pre-trained model,\nguiding output predictions toward task objectives without modifying the model's\nparameters. By introducing lightweight, trainable Propulsion parameters at the\npre-trained layer, we minimize the number of parameters updated during\nfine-tuning, preventing overfitting or overwriting of existing knowledge. Our\ntheoretical analysis, supported by Neural Tangent Kernel (NTK) theory, shows\nthat Propulsion approximates the performance of full fine-tuning with far fewer\ntrainable parameters. Empirically, Propulsion reduces the parameter count from\n355.3 million to just 0.086 million, achieving over a 10x reduction compared to\nstandard approaches like LoRA while maintaining competitive performance across\nbenchmarks."
  },
  {
    "arxiv_id": "2409.10874",
    "title": "American Sign Language to Text Translation using Transformer and Seq2Seq with LSTM",
    "url": "http://arxiv.org/abs/2409.10874v1",
    "abstract": "Sign language translation is one of the important issues in communication\nbetween deaf and hearing people, as it expresses words through hand, body, and\nmouth movements. American Sign Language is one of the sign languages used, one\nof which is the alphabetic sign. The development of neural machine translation\ntechnology is moving towards sign language translation. Transformer became the\nstate-of-the-art in natural language processing. This study compares the\nTransformer with the Sequence-to-Sequence (Seq2Seq) model in translating sign\nlanguage to text. In addition, an experiment was conducted by adding Residual\nLong Short-Term Memory (ResidualLSTM) in the Transformer. The addition of\nResidualLSTM to the Transformer reduces the performance of the Transformer\nmodel by 23.37% based on the BLEU Score value. In comparison, the Transformer\nitself increases the BLEU Score value by 28.14 compared to the Seq2Seq model."
  },
  {
    "arxiv_id": "2409.11703",
    "title": "Harnessing LLMs for API Interactions: A Framework for Classification and Synthetic Data Generation",
    "url": "http://arxiv.org/abs/2409.11703v1",
    "abstract": "As Large Language Models (LLMs) advance in natural language processing, there\nis growing interest in leveraging their capabilities to simplify software\ninteractions. In this paper, we propose a novel system that integrates LLMs for\nboth classifying natural language inputs into corresponding API calls and\nautomating the creation of sample datasets tailored to specific API functions.\nBy classifying natural language commands, our system allows users to invoke\ncomplex software functionalities through simple inputs, improving interaction\nefficiency and lowering the barrier to software utilization. Our dataset\ngeneration approach also enables the efficient and systematic evaluation of\ndifferent LLMs in classifying API calls, offering a practical tool for\ndevelopers or business owners to assess the suitability of LLMs for customized\nAPI management. We conduct experiments on several prominent LLMs using\ngenerated sample datasets for various API functions. The results show that\nGPT-4 achieves a high classification accuracy of 0.996, while LLaMA-3-8B\nperforms much worse at 0.759. These findings highlight the potential of LLMs to\ntransform API management and validate the effectiveness of our system in\nguiding model testing and selection across diverse applications."
  },
  {
    "arxiv_id": "2409.16176",
    "title": "Cyber Knowledge Completion Using Large Language Models",
    "url": "http://arxiv.org/abs/2409.16176v1",
    "abstract": "The integration of the Internet of Things (IoT) into Cyber-Physical Systems\n(CPSs) has expanded their cyber-attack surface, introducing new and\nsophisticated threats with potential to exploit emerging vulnerabilities.\nAssessing the risks of CPSs is increasingly difficult due to incomplete and\noutdated cybersecurity knowledge. This highlights the urgent need for\nbetter-informed risk assessments and mitigation strategies. While previous\nefforts have relied on rule-based natural language processing (NLP) tools to\nmap vulnerabilities, weaknesses, and attack patterns, recent advancements in\nLarge Language Models (LLMs) present a unique opportunity to enhance\ncyber-attack knowledge completion through improved reasoning, inference, and\nsummarization capabilities. We apply embedding models to encapsulate\ninformation on attack patterns and adversarial techniques, generating mappings\nbetween them using vector embeddings. Additionally, we propose a\nRetrieval-Augmented Generation (RAG)-based approach that leverages pre-trained\nmodels to create structured mappings between different taxonomies of threat\npatterns. Further, we use a small hand-labeled dataset to compare the proposed\nRAG-based approach to a baseline standard binary classification model. Thus,\nthe proposed approach provides a comprehensive framework to address the\nchallenge of cyber-attack knowledge graph completion."
  },
  {
    "arxiv_id": "2409.15762",
    "title": "XTRUST: On the Multilingual Trustworthiness of Large Language Models",
    "url": "http://arxiv.org/abs/2409.15762v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of natural language processing (NLP) tasks, capturing the attention of\nboth practitioners and the broader public. A key question that now preoccupies\nthe AI community concerns the capabilities and limitations of these models,\nwith trustworthiness emerging as a central issue, particularly as LLMs are\nincreasingly applied in sensitive fields like healthcare and finance, where\nerrors can have serious consequences. However, most previous studies on the\ntrustworthiness of LLMs have been limited to a single language, typically the\npredominant one in the dataset, such as English. In response to the growing\nglobal deployment of LLMs, we introduce XTRUST, the first comprehensive\nmultilingual trustworthiness benchmark. XTRUST encompasses a diverse range of\ntopics, including illegal activities, hallucination, out-of-distribution (OOD)\nrobustness, physical and mental health, toxicity, fairness, misinformation,\nprivacy, and machine ethics, across 10 different languages. Using XTRUST, we\nconduct an empirical evaluation of the multilingual trustworthiness of five\nwidely used LLMs, offering an in-depth analysis of their performance across\nlanguages and tasks. Our results indicate that many LLMs struggle with certain\nlow-resource languages, such as Arabic and Russian, highlighting the\nconsiderable room for improvement in the multilingual trustworthiness of\ncurrent language models. The code is available at\nhttps://github.com/LluckyYH/XTRUST."
  },
  {
    "arxiv_id": "2409.15202",
    "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
    "url": "http://arxiv.org/abs/2409.15202v1",
    "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of\naspect-based sentiment analysis that consists in extracting (aspect phrase,\nopinion phrase, sentiment polarity) triples from a given sentence. Recent\nstate-of-the-art methods approach this task by first extracting all possible\ntext spans from a given text, then filtering the potential aspect and opinion\nphrases with a classifier, and finally considering all their pairs with another\nclassifier that additionally assigns sentiment polarity to them. Although\nseveral variations of the above scheme have been proposed, the common feature\nis that the final result is constructed by a sequence of independent classifier\ndecisions. This hinders the exploitation of dependencies between extracted\nphrases and prevents the use of knowledge about the interrelationships between\nclassifier predictions to improve performance. In this paper, we propose a new\nASTE approach consisting of three transformer-inspired layers, which enables\nthe modelling of dependencies both between phrases and between the final\nclassifier decisions. Experimental results show that the method achieves higher\nperformance in terms of F1 measure than other methods studied on popular\nbenchmarks. In addition, we show that a simple pre-training technique further\nimproves the performance of the model."
  },
  {
    "arxiv_id": "2409.15188",
    "title": "PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models",
    "url": "http://arxiv.org/abs/2409.15188v2",
    "abstract": "Effective patient-provider communication is crucial in clinical care,\ndirectly impacting patient outcomes and quality of life. Traditional evaluation\nmethods, such as human ratings, patient feedback, and provider\nself-assessments, are often limited by high costs and scalability issues.\nAlthough existing natural language processing (NLP) techniques show promise,\nthey struggle with the nuances of clinical communication and require sensitive\nclinical data for training, reducing their effectiveness in real-world\napplications. Emerging large language models (LLMs) offer a new approach to\nassessing complex communication metrics, with the potential to advance the\nfield through integration into passive sensing and just-in-time intervention\nsystems. This study explores LLMs as evaluators of palliative care\ncommunication quality, leveraging their linguistic, in-context learning, and\nreasoning capabilities. Specifically, using simulated scripts crafted and\nlabeled by healthcare professionals, we test proprietary models (e.g., GPT-4)\nand fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset\ngenerated by GPT-4 to evaluate clinical conversations, to identify key metrics\nsuch as `understanding' and `empathy'. Our findings demonstrated LLMs' superior\nperformance in evaluating clinical communication, providing actionable feedback\nwith reasoning, and demonstrating the feasibility and practical viability of\ndeveloping in-house LLMs. This research highlights LLMs' potential to enhance\npatient-provider interactions and lays the groundwork for downstream steps in\ndeveloping LLM-empowered clinical health systems."
  },
  {
    "arxiv_id": "2409.15127",
    "title": "Boosting Healthcare LLMs Through Retrieved Context",
    "url": "http://arxiv.org/abs/2409.15127v1",
    "abstract": "This study leverages optimized context retrieval to enhance open-source Large\nLanguage Models (LLMs) for cost-effective, high performance healthcare AI. We\ndemonstrate that this approach achieves state-of-the-art accuracy on medical\nquestion answering at a fraction of the cost of proprietary models,\nsignificantly improving the cost-accuracy Pareto frontier on the MedQA\nbenchmark. Key contributions include: (1) OpenMedQA, a novel benchmark\nrevealing a performance gap in open-ended medical QA compared to\nmultiple-choice formats; (2) a practical, reproducible pipeline for context\nretrieval optimization; and (3) open-source resources (Prompt Engine,\nCoT/ToT/Thinking databases) to empower healthcare AI development. By advancing\nretrieval techniques and QA evaluation, we enable more affordable and reliable\nLLM solutions for healthcare."
  },
  {
    "arxiv_id": "2409.17011",
    "title": "LLM-CARD: Towards a Description and Landscape of Large Language Models",
    "url": "http://arxiv.org/abs/2409.17011v1",
    "abstract": "With the rapid growth of the Natural Language Processing (NLP) field, a vast\nvariety of Large Language Models (LLMs) continue to emerge for diverse NLP\ntasks. As more papers are published, researchers and developers face the\nchallenge of information overload. Thus, developing a system that can\nautomatically extract and organise key information about LLMs from academic\npapers is particularly important. The standard format for documenting\ninformation about LLMs is the LLM model card (\\textbf{LLM-Card}). We propose a\nmethod for automatically generating LLM model cards from scientific\npublications. We use Named Entity Recognition (\\textbf{NER}) and Relation\nExtraction (\\textbf{RE}) methods that automatically extract key information\nabout LLMs from the papers, helping researchers to access information about\nLLMs efficiently. These features include model \\textit{licence}, model\n\\textit{name}, and model \\textit{application}. With these features, we can form\na model card for each paper. We processed 106 academic papers by defining three\ndictionaries -- LLM's name, licence, and application. 11,051 sentences were\nextracted through dictionary lookup, and the dataset was constructed through\nmanual review of the final selection of 129 sentences with a link between the\nname and the \\textit{licence}, and 106 sentences with a link between the model\nname and the \\textit{application}. The resulting resource is relevant for LLM\ncard illustrations using relational knowledge graphs. Our code and findings can\ncontribute to automatic LLM card generation. Data and code in\n\\textsc{autoLLM-Card} will be shared and freely available at\n\\url{https://github.com/shengwei-tian/dependency-parser-visualization}"
  },
  {
    "arxiv_id": "2409.16974",
    "title": "Decoding Large-Language Models: A Systematic Overview of Socio-Technical Impacts, Constraints, and Emerging Questions",
    "url": "http://arxiv.org/abs/2409.16974v1",
    "abstract": "There have been rapid advancements in the capabilities of large language\nmodels (LLMs) in recent years, greatly revolutionizing the field of natural\nlanguage processing (NLP) and artificial intelligence (AI) to understand and\ninteract with human language. Therefore, in this work, we conduct a systematic\ninvestigation of the literature to identify the prominent themes and directions\nof LLM developments, impacts, and limitations. Our findings illustrate the\naims, methodologies, limitations, and future directions of LLM research. It\nincludes responsible development considerations, algorithmic improvements,\nethical challenges, and societal implications of LLM development. Overall, this\npaper provides a rigorous and comprehensive overview of current research in LLM\nand identifies potential directions for future development. The article\nhighlights the application areas that could have a positive impact on society\nalong with the ethical considerations."
  },
  {
    "arxiv_id": "2409.16694",
    "title": "A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms",
    "url": "http://arxiv.org/abs/2409.16694v1",
    "abstract": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage processing, showcasing exceptional performance across various tasks.\nHowever, the expensive memory and computational requirements present\nsignificant challenges for their practical deployment. Low-bit quantization has\nemerged as a critical approach to mitigate these challenges by reducing the\nbit-width of model parameters, activations, and gradients, thus decreasing\nmemory usage and computational demands. This paper presents a comprehensive\nsurvey of low-bit quantization methods tailored for LLMs, covering the\nfundamental principles, system implementations, and algorithmic strategies. An\noverview of basic concepts and new data formats specific to low-bit LLMs is\nfirst introduced, followed by a review of frameworks and systems that\nfacilitate low-bit LLMs across various hardware platforms. Then, we categorize\nand analyze techniques and toolkits for efficient low-bit training and\ninference of LLMs. Finally, we conclude with a discussion of future trends and\npotential advancements of low-bit LLMs. Our systematic overview from basic,\nsystem, and algorithm perspectives can offer valuable insights and guidelines\nfor future works to enhance the efficiency and applicability of LLMs through\nlow-bit quantization."
  },
  {
    "arxiv_id": "2409.16674",
    "title": "A Prompting-Based Representation Learning Method for Recommendation with Large Language Models",
    "url": "http://arxiv.org/abs/2409.16674v1",
    "abstract": "In recent years, Recommender Systems (RS) have witnessed a transformative\nshift with the advent of Large Language Models (LLMs) in the field of Natural\nLanguage Processing (NLP). Models such as GPT-3.5/4, Llama, have demonstrated\nunprecedented capabilities in understanding and generating human-like text. The\nextensive information pre-trained by these LLMs allows for the potential to\ncapture a more profound semantic representation from different contextual\ninformation of users and items.\n  While the great potential lies behind the thriving of LLMs, the challenge of\nleveraging user-item preferences from contextual information and its alignment\nwith the improvement of Recommender Systems needs to be addressed. Believing\nthat a better understanding of the user or item itself can be the key factor in\nimproving recommendation performance, we conduct research on generating\ninformative profiles using state-of-the-art LLMs.\n  To boost the linguistic abilities of LLMs in Recommender Systems, we\nintroduce the Prompting-Based Representation Learning Method for Recommendation\n(P4R). In our P4R framework, we utilize the LLM prompting strategy to create\npersonalized item profiles. These profiles are then transformed into semantic\nrepresentation spaces using a pre-trained BERT model for text embedding.\nFurthermore, we incorporate a Graph Convolution Network (GCN) for collaborative\nfiltering representation. The P4R framework aligns these two embedding spaces\nin order to address the general recommendation tasks. In our evaluation, we\ncompare P4R with state-of-the-art Recommender models and assess the quality of\nprompt-based profile generation."
  },
  {
    "arxiv_id": "2409.17906",
    "title": "Graph Reasoning with Large Language Models via Pseudo-code Prompting",
    "url": "http://arxiv.org/abs/2409.17906v1",
    "abstract": "Large language models (LLMs) have recently achieved remarkable success in\nvarious reasoning tasks in the field of natural language processing. This\nsuccess of LLMs has also motivated their use in graph-related tasks. Among\nothers, recent work has explored whether LLMs can solve graph problems such as\ncounting the number of connected components of a graph or computing the\nshortest path distance between two nodes. Although LLMs possess preliminary\ngraph reasoning abilities, they might still struggle to solve some seemingly\nsimple problems. In this paper, we investigate whether prompting via\npseudo-code instructions can improve the performance of LLMs in solving graph\nproblems. Our experiments demonstrate that using pseudo-code instructions\ngenerally improves the performance of all considered LLMs. The graphs,\npseudo-code prompts, and evaluation code are publicly available."
  },
  {
    "arxiv_id": "2409.17204",
    "title": "Exploring the Roles of NLP-based Dialog Indicators in Predicting User Experience in interacting with Large Language Model System",
    "url": "http://arxiv.org/abs/2409.17204v1",
    "abstract": "The use of Large Language Models for dialogue systems is rising, presenting a\nnew challenge: how do we assess users' chat experience in these systems?\nLeveraging Natural Language Processing (NLP)-powered dialog analyzers to create\ndialog indicators like Coherence and Emotion has the potential to predict the\nchat experience. In this paper, we proposed a conceptual model to explain the\nrelationship between the dialog indicators and various factors related to the\nchat experience, such as users' intentions, affinity toward dialog agents, and\nprompts of the agents' characters. We evaluated the conceptual model using\nPLS-SEM with 120 participants and found it well fit. Our results suggest that\ndialog indicators can predict the chat experience and fully mediate the impact\nof prompts and user intentions. Additionally, users' affinity toward agents can\npartially explain these predictions. Our findings demonstrate the potential of\nusing dialog indicators in predicting the chat experience. Through the\nconceptual model we propose, researchers can apply the dialog analyzers to\ngenerate dialog indicators to constantly monitor the dialog process and improve\nthe user's chat experience accordingly."
  },
  {
    "arxiv_id": "2409.18878",
    "title": "Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models",
    "url": "http://arxiv.org/abs/2409.18878v1",
    "abstract": "Accurate identification and categorization of suicidal events can yield\nbetter suicide precautions, reducing operational burden, and improving care\nquality in high-acuity psychiatric settings. Pre-trained language models offer\npromise for identifying suicidality from unstructured clinical narratives. We\nevaluated the performance of four BERT-based models using two fine-tuning\nstrategies (multiple single-label and single multi-label) for detecting\ncoexisting suicidal events from 500 annotated psychiatric evaluation notes. The\nnotes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure\nto suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed\nother models using multiple single-label classification strategy (acc=0.86,\nF1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT\n(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa\nfine-tuned with single multi-label classification further improved the model\nperformance (acc=0.88, F1=0.81). The findings highlight that the model\noptimization, pretraining with domain-relevant data, and the single multi-label\nclassification strategy enhance the model performance of suicide phenotyping.\nKeywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of\nEHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health"
  },
  {
    "arxiv_id": "2409.18339",
    "title": "AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models",
    "url": "http://arxiv.org/abs/2409.18339v1",
    "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated great\nsuccess in many Natural Language Processing (NLP) tasks. In addition to their\ncognitive intelligence, exploring their capabilities in emotional intelligence\nis also crucial, as it enables more natural and empathetic conversational AI.\nRecent studies have shown LLMs' capability in recognizing emotions, but they\noften focus on single emotion labels and overlook the complex and ambiguous\nnature of human emotions. This study is the first to address this gap by\nexploring the potential of LLMs in recognizing ambiguous emotions, leveraging\ntheir strong generalization capabilities and in-context learning. We design\nzero-shot and few-shot prompting and incorporate past dialogue as context\ninformation for ambiguous emotion recognition. Experiments conducted using\nthree datasets indicate significant potential for LLMs in recognizing ambiguous\nemotions, and highlight the substantial benefits of including context\ninformation. Furthermore, our findings indicate that LLMs demonstrate a high\ndegree of effectiveness in recognizing less ambiguous emotions and exhibit\npotential for identifying more ambiguous emotions, paralleling human perceptual\ncapabilities."
  },
  {
    "arxiv_id": "2409.18290",
    "title": "Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams",
    "url": "http://arxiv.org/abs/2409.18290v1",
    "abstract": "In-basket message interactions play a crucial role in physician-patient\ncommunication, occurring during all phases (pre-, during, and post) of a\npatient's care journey. However, responding to these patients' inquiries has\nbecome a significant burden on healthcare workflows, consuming considerable\ntime for clinical care teams. To address this, we introduce RadOnc-GPT, a\nspecialized Large Language Model (LLM) powered by GPT-4 that has been designed\nwith a focus on radiotherapeutic treatment of prostate cancer with advanced\nprompt engineering, and specifically designed to assist in generating\nresponses. We integrated RadOnc-GPT with patient electronic health records\n(EHR) from both the hospital-wide EHR database and an internal,\nradiation-oncology-specific database. RadOnc-GPT was evaluated on 158\npreviously recorded in-basket message interactions. Quantitative natural\nlanguage processing (NLP) analysis and two grading studies with clinicians and\nnurses were used to assess RadOnc-GPT's responses. Our findings indicate that\nRadOnc-GPT slightly outperformed the clinical care team in \"Clarity\" and\n\"Empathy,\" while achieving comparable scores in \"Completeness\" and\n\"Correctness.\" RadOnc-GPT is estimated to save 5.2 minutes per message for\nnurses and 2.4 minutes for clinicians, from reading the inquiry to sending the\nresponse. Employing RadOnc-GPT for in-basket message draft generation has the\npotential to alleviate the workload of clinical care teams and reduce\nhealthcare costs by producing high-quality, timely responses."
  },
  {
    "arxiv_id": "2409.18222",
    "title": "Trustworthy AI: Securing Sensitive Data in Large Language Models",
    "url": "http://arxiv.org/abs/2409.18222v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing\n(NLP) by enabling robust text generation and understanding. However, their\ndeployment in sensitive domains like healthcare, finance, and legal services\nraises critical concerns about privacy and data security. This paper proposes a\ncomprehensive framework for embedding trust mechanisms into LLMs to dynamically\ncontrol the disclosure of sensitive information. The framework integrates three\ncore components: User Trust Profiling, Information Sensitivity Detection, and\nAdaptive Output Control. By leveraging techniques such as Role-Based Access\nControl (RBAC), Attribute-Based Access Control (ABAC), Named Entity Recognition\n(NER), contextual analysis, and privacy-preserving methods like differential\nprivacy, the system ensures that sensitive information is disclosed\nappropriately based on the user's trust level. By focusing on balancing data\nutility and privacy, the proposed solution offers a novel approach to securely\ndeploying LLMs in high-risk environments. Future work will focus on testing\nthis framework across various domains to evaluate its effectiveness in managing\nsensitive data while maintaining system efficiency."
  },
  {
    "arxiv_id": "2409.20288",
    "title": "LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models",
    "url": "http://arxiv.org/abs/2409.20288v1",
    "abstract": "Large language models (LLMs) have made significant progress in natural\nlanguage processing tasks and demonstrate considerable potential in the legal\ndomain. However, legal applications demand high standards of accuracy,\nreliability, and fairness. Applying existing LLMs to legal systems without\ncareful evaluation of their potential and limitations could pose significant\nrisks in legal practice. To this end, we introduce a standardized comprehensive\nChinese legal benchmark LexEval. This benchmark is notable in the following\nthree aspects: (1) Ability Modeling: We propose a new taxonomy of legal\ncognitive abilities to organize different tasks. (2) Scale: To our knowledge,\nLexEval is currently the largest Chinese legal evaluation dataset, comprising\n23 tasks and 14,150 questions. (3) Data: we utilize formatted existing\ndatasets, exam datasets and newly annotated datasets by legal experts to\ncomprehensively evaluate the various capabilities of LLMs. LexEval not only\nfocuses on the ability of LLMs to apply fundamental legal knowledge but also\ndedicates efforts to examining the ethical issues involved in their\napplication. We evaluated 38 open-source and commercial LLMs and obtained some\ninteresting findings. The experiments and findings offer valuable insights into\nthe challenges and potential solutions for developing Chinese legal systems and\nLLM evaluation pipelines. The LexEval dataset and leaderboard are publicly\navailable at \\url{https://github.com/CSHaitao/LexEval} and will be continuously\nupdated."
  },
  {
    "arxiv_id": "2409.20174",
    "title": "Modelando procesos cognitivos de la lectura natural con GPT-2",
    "url": "http://arxiv.org/abs/2409.20174v1",
    "abstract": "The advancement of the Natural Language Processing field has enabled the\ndevelopment of language models with a great capacity for generating text. In\nrecent years, Neuroscience has been using these models to better understand\ncognitive processes. In previous studies, we found that models like Ngrams and\nLSTM networks can partially model Predictability when used as a co-variable to\nexplain readers' eye movements. In the present work, we further this line of\nresearch by using GPT-2 based models. The results show that this architecture\nachieves better outcomes than its predecessors."
  },
  {
    "arxiv_id": "2409.20094",
    "title": "Aggressive Post-Training Compression on Extremely Large Language Models",
    "url": "http://arxiv.org/abs/2409.20094v1",
    "abstract": "The increasing size and complexity of Large Language Models (LLMs) pose\nchallenges for their deployment on personal computers and mobile devices.\nAggressive post-training model compression is necessary to reduce the models'\nsize, but it often results in significant accuracy loss. To address this\nchallenge, we propose a novel network pruning technology that utilizes over 0.7\nsparsity and less than 8 bits of quantization. Our approach enables the\ncompression of prevailing LLMs within a couple of hours while maintaining a\nrelatively small accuracy loss. In experimental evaluations, our method\ndemonstrates effectiveness and potential for practical deployment. By making\nLLMs available on domestic devices, our work can facilitate a new era of\nnatural language processing applications with wide-ranging impacts."
  },
  {
    "arxiv_id": "2409.19960",
    "title": "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning",
    "url": "http://arxiv.org/abs/2409.19960v1",
    "abstract": "Zero-shot inference, where pre-trained models perform tasks without specific\ntraining data, is an exciting emergent ability of large models like CLIP.\nAlthough there has been considerable exploration into enhancing zero-shot\nabilities in image captioning (IC) for popular datasets such as MSCOCO and\nFlickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,\nUCM-Captions, and Sydney-Captions. These datasets require captions to discern\nbetween visually and semantically similar classes, focusing on detailed object\nparts and their attributes. To overcome this challenge, we introduce\nTRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption\nwith additional object-part details using object detector proposals and Natural\nLanguage Processing techniques. It complements rather than alters the base\ncaption, allowing seamless integration with other captioning methods and\noffering users enhanced flexibility. Our evaluations show that TROPE\nconsistently boosts performance across all tested zero-shot IC approaches and\nachieves state-of-the-art results on fine-grained IC datasets."
  },
  {
    "arxiv_id": "2409.19710",
    "title": "A multimodal LLM for the non-invasive decoding of spoken text from brain recordings",
    "url": "http://arxiv.org/abs/2409.19710v1",
    "abstract": "Brain-related research topics in artificial intelligence have recently gained\npopularity, particularly due to the expansion of what multimodal architectures\ncan do from computer vision to natural language processing. Our main goal in\nthis work is to explore the possibilities and limitations of these\narchitectures in spoken text decoding from non-invasive fMRI recordings.\nContrary to vision and textual data, fMRI data represent a complex modality due\nto the variety of brain scanners, which implies (i) the variety of the recorded\nsignal formats, (ii) the low resolution and noise of the raw signals, and (iii)\nthe scarcity of pretrained models that can be leveraged as foundation models\nfor generative learning. These points make the problem of the non-invasive\ndecoding of text from fMRI recordings very challenging. In this paper, we\npropose and end-to-end multimodal LLM for decoding spoken text from fMRI\nsignals. The proposed architecture is founded on (i) an encoder derived from a\nspecific transformer incorporating an augmented embedding layer for the encoder\nand a better-adjusted attention mechanism than that present in the state of the\nart, and (ii) a frozen large language model adapted to align the embedding of\nthe input text and the encoded embedding of brain activity to decode the output\ntext. A benchmark in performed on a corpus consisting of a set of interactions\nhuman-human and human-robot interactions where fMRI and conversational signals\nare recorded synchronously. The obtained results are very promising, as our\nproposal outperforms the evaluated models, and is able to generate text\ncapturing more accurate semantics present in the ground truth. The\nimplementation code is provided in https://github.com/Hmamouche/brain_decode."
  },
  {
    "arxiv_id": "2410.01610",
    "title": "Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging",
    "url": "http://arxiv.org/abs/2410.01610v1",
    "abstract": "Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and\ndemonstrates outstanding performance in plentiful natural language processing\ntasks. However, existing methods transforming LLMs from dense to MoE face\nsignificant data requirements and typically rely on large-scale post-training.\nIn this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient\napproach for tuning a dense pre-trained model into a MoE instruction model.\nSpecifically, we first point out that intermediate checkpoints during\ninstruction tuning of the dense model are naturally suitable for specialized\nexperts, and then propose an expert expansion stage to flexibly achieve models\nwith flexible numbers of experts, where genetic algorithm and parameter merging\nare introduced to ensure sufficient diversity of new extended experts. To\nensure that each specialized expert in the MoE model works as expected, we\nselect a small amount of seed data that each expert excels to pre-optimize the\nrouter. Extensive experiments with various data scales and upcycling settings\ndemonstrate the outstanding performance and data efficiency of UpIT, as well as\nstable improvement in expert or data scaling. Further analysis reveals the\nimportance of ensuring expert diversity in upcycling."
  },
  {
    "arxiv_id": "2410.01532",
    "title": "Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models",
    "url": "http://arxiv.org/abs/2410.01532v1",
    "abstract": "Advancements in Natural Language Processing (NLP), have led to the emergence\nof Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which\nexcel across a range of tasks but require extensive fine-tuning to align their\noutputs with human expectations. A widely used method for achieving this\nalignment is Reinforcement Learning from Human Feedback (RLHF), which, despite\nits success, faces challenges in accurately modelling human preferences. In\nthis paper, we introduce GazeReward, a novel framework that integrates implicit\nfeedback -- and specifically eye-tracking (ET) data -- into the Reward Model\n(RM). In addition, we explore how ET-based features can provide insights into\nuser preferences. Through ablation studies we test our framework with different\nintegration methods, LLMs, and ET generator models, demonstrating that our\napproach significantly improves the accuracy of the RM on established human\npreference datasets. This work advances the ongoing discussion on optimizing AI\nalignment with human values, exploring the potential of cognitive data for\nshaping future NLP research."
  },
  {
    "arxiv_id": "2410.01246",
    "title": "AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended Responses",
    "url": "http://arxiv.org/abs/2410.01246v1",
    "abstract": "Question answering (QA) tasks have been extensively studied in the field of\nnatural language processing (NLP). Answers to open-ended questions are highly\ndiverse and difficult to quantify, and cannot be simply evaluated as correct or\nincorrect, unlike close-ended questions with definitive answers. While large\nlanguage models (LLMs) have demonstrated strong capabilities across various\ntasks, they exhibit relatively weaker performance in evaluating answers to\nopen-ended questions. In this study, we propose a method that leverages LLMs\nand the analytic hierarchy process (AHP) to assess answers to open-ended\nquestions. We utilized LLMs to generate multiple evaluation criteria for a\nquestion. Subsequently, answers were subjected to pairwise comparisons under\neach criterion with LLMs, and scores for each answer were calculated in the\nAHP. We conducted experiments on four datasets using both ChatGPT-3.5-turbo and\nGPT-4. Our results indicate that our approach more closely aligns with human\njudgment compared to the four baselines. Additionally, we explored the impact\nof the number of criteria, variations in models, and differences in datasets on\nthe results."
  },
  {
    "arxiv_id": "2410.01208",
    "title": "StringLLM: Understanding the String Processing Capability of Large Language Models",
    "url": "http://arxiv.org/abs/2410.01208v1",
    "abstract": "String processing, which mainly involves the analysis and manipulation of\nstrings, is a fundamental component of modern computing. Despite the\nsignificant advancements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, their capability in string processing remains\nunderexplored and underdeveloped. To bridge this gap, we present a\ncomprehensive study of LLMs' string processing capability. In particular, we\nfirst propose StringLLM, a method to construct datasets for benchmarking string\nprocessing capability of LLMs. We use StringLLM to build a series of datasets,\nreferred to as StringBench. It encompasses a wide range of string processing\ntasks, allowing us to systematically evaluate LLMs' performance in this area.\nOur evaluations indicate that LLMs struggle with accurately processing strings\ncompared to humans. To uncover the underlying reasons for this limitation, we\nconduct an in-depth analysis and subsequently propose an effective approach\nthat significantly enhances LLMs' string processing capability via fine-tuning.\nThis work provides a foundation for future research to understand LLMs' string\nprocessing capability. Our code and data are available at\nhttps://github.com/wxl-lxw/StringLLM."
  },
  {
    "arxiv_id": "2410.02757",
    "title": "Loong: Generating Minute-level Long Videos with Autoregressive Language Models",
    "url": "http://arxiv.org/abs/2410.02757v1",
    "abstract": "It is desirable but challenging to generate content-rich long videos in the\nscale of minutes. Autoregressive large language models (LLMs) have achieved\ngreat success in generating coherent and long sequences of tokens in the domain\nof natural language processing, while the exploration of autoregressive LLMs\nfor video generation is limited to generating short videos of several seconds.\nIn this work, we conduct a deep analysis of the challenges that prevent\nautoregressive LLM-based video generators from generating long videos. Based on\nthe observations and analysis, we propose Loong, a new autoregressive LLM-based\nvideo generator that can generate minute-long videos. Specifically, we model\nthe text tokens and video tokens as a unified sequence for autoregressive LLMs\nand train the model from scratch. We propose progressive short-to-long training\nwith a loss re-weighting scheme to mitigate the loss imbalance problem for long\nvideo training. We further investigate inference strategies, including video\ntoken re-encoding and sampling strategies, to diminish error accumulation\nduring inference. Our proposed Loong can be trained on 10-second videos and be\nextended to generate minute-level long videos conditioned on text prompts, as\ndemonstrated by the results. More samples are available at:\nhttps://yuqingwang1029.github.io/Loong-video."
  },
  {
    "arxiv_id": "2410.02724",
    "title": "Large Language Models as Markov Chains",
    "url": "http://arxiv.org/abs/2410.02724v1",
    "abstract": "Large language models (LLMs) are remarkably efficient across a wide range of\nnatural language processing tasks and well beyond them. However, a\ncomprehensive theoretical analysis of the LLMs' generalization capabilities\nremains elusive. In our paper, we approach this task by drawing an equivalence\nbetween autoregressive transformer-based language models and Markov chains\ndefined on a finite state space. This allows us to study the multi-step\ninference mechanism of LLMs from first principles. We relate the obtained\nresults to the pathological behavior observed with LLMs such as repetitions and\nincoherent replies with high temperature. Finally, we leverage the proposed\nformalization to derive pre-training and in-context learning generalization\nbounds for LLMs under realistic data and model assumptions. Experiments with\nthe most recent Llama and Gemma herds of models show that our theory correctly\ncaptures their behavior in practice."
  },
  {
    "arxiv_id": "2410.02654",
    "title": "Deconstructing Recurrence, Attention, and Gating: Investigating the transferability of Transformers and Gated Recurrent Neural Networks in forecasting of dynamical systems",
    "url": "http://arxiv.org/abs/2410.02654v1",
    "abstract": "Machine learning architectures, including transformers and recurrent neural\nnetworks (RNNs) have revolutionized forecasting in applications ranging from\ntext processing to extreme weather. Notably, advanced network architectures,\ntuned for applications such as natural language processing, are transferable to\nother tasks such as spatiotemporal forecasting tasks. However, there is a\nscarcity of ablation studies to illustrate the key components that enable this\nforecasting accuracy. The absence of such studies, although explainable due to\nthe associated computational cost, intensifies the belief that these models\nought to be considered as black boxes. In this work, we decompose the key\narchitectural components of the most powerful neural architectures, namely\ngating and recurrence in RNNs, and attention mechanisms in transformers. Then,\nwe synthesize and build novel hybrid architectures from the standard blocks,\nperforming ablation studies to identify which mechanisms are effective for each\ntask. The importance of considering these components as hyper-parameters that\ncan augment the standard architectures is exhibited on various forecasting\ndatasets, from the spatiotemporal chaotic dynamics of the multiscale Lorenz 96\nsystem, the Kuramoto-Sivashinsky equation, as well as standard real world\ntime-series benchmarks. A key finding is that neural gating and attention\nimproves the performance of all standard RNNs in most tasks, while the addition\nof a notion of recurrence in transformers is detrimental. Furthermore, our\nstudy reveals that a novel, sparsely used, architecture which integrates\nRecurrent Highway Networks with neural gating and attention mechanisms, emerges\nas the best performing architecture in high-dimensional spatiotemporal\nforecasting of dynamical systems."
  },
  {
    "arxiv_id": "2410.02611",
    "title": "IndicSentEval: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages?",
    "url": "http://arxiv.org/abs/2410.02611v1",
    "abstract": "Transformer-based models have revolutionized the field of natural language\nprocessing. To understand why they perform so well and to assess their\nreliability, several studies have focused on questions such as: Which\nlinguistic properties are encoded by these models, and to what extent? How\nrobust are these models in encoding linguistic properties when faced with\nperturbations in the input text? However, these studies have mainly focused on\nBERT and the English language. In this paper, we investigate similar questions\nregarding encoding capability and robustness for 8 linguistic properties across\n13 different perturbations in 6 Indic languages, using 9 multilingual\nTransformer models (7 universal and 2 Indic-specific). To conduct this study,\nwe introduce a novel multilingual benchmark dataset, IndicSentEval, containing\napproximately $\\sim$47K sentences. Surprisingly, our probing analysis of\nsurface, syntactic, and semantic properties reveals that while almost all\nmultilingual models demonstrate consistent encoding performance for English,\nthey show mixed results for Indic languages. As expected, Indic-specific\nmultilingual models capture linguistic properties in Indic languages better\nthan universal models. Intriguingly, universal models broadly exhibit better\nrobustness compared to Indic-specific models, particularly under perturbations\nsuch as dropping both nouns and verbs, dropping only verbs, or keeping only\nnouns. Overall, this study provides valuable insights into probing and\nperturbation-specific strengths and weaknesses of popular multilingual\nTransformer-based models for different Indic languages. We make our code and\ndataset publicly available [https://tinyurl.com/IndicSentEval}]."
  },
  {
    "arxiv_id": "2410.02244",
    "title": "Visual Prompting in LLMs for Enhancing Emotion Recognition",
    "url": "http://arxiv.org/abs/2410.02244v1",
    "abstract": "Vision Large Language Models (VLLMs) are transforming the intersection of\ncomputer vision and natural language processing. Nonetheless, the potential of\nusing visual prompts for emotion recognition in these models remains largely\nunexplored and untapped. Traditional methods in VLLMs struggle with spatial\nlocalization and often discard valuable global context. To address this\nproblem, we propose a Set-of-Vision prompting (SoV) approach that enhances\nzero-shot emotion recognition by using spatial information, such as bounding\nboxes and facial landmarks, to mark targets precisely. SoV improves accuracy in\nface count and emotion categorization while preserving the enriched image\ncontext. Through a battery of experimentation and analysis of recent commercial\nor open-source VLLMs, we evaluate the SoV model's ability to comprehend facial\nexpressions in natural environments. Our findings demonstrate the effectiveness\nof integrating spatial visual prompts into VLLMs for improving emotion\nrecognition performance."
  },
  {
    "arxiv_id": "2410.02165",
    "title": "A LLM-Powered Automatic Grading Framework with Human-Level Guidelines Optimization",
    "url": "http://arxiv.org/abs/2410.02165v1",
    "abstract": "Open-ended short-answer questions (SAGs) have been widely recognized as a\npowerful tool for providing deeper insights into learners' responses in the\ncontext of learning analytics (LA). However, SAGs often present challenges in\npractice due to the high grading workload and concerns about inconsistent\nassessments. With recent advancements in natural language processing (NLP),\nautomatic short-answer grading (ASAG) offers a promising solution to these\nchallenges. Despite this, current ASAG algorithms are often limited in\ngeneralizability and tend to be tailored to specific questions. In this paper,\nwe propose a unified multi-agent ASAG framework, GradeOpt, which leverages\nlarge language models (LLMs) as graders for SAGs. More importantly, GradeOpt\nincorporates two additional LLM-based agents - the reflector and the refiner -\ninto the multi-agent system. This enables GradeOpt to automatically optimize\nthe original grading guidelines by performing self-reflection on its errors.\nThrough experiments on a challenging ASAG task, namely the grading of\npedagogical content knowledge (PCK) and content knowledge (CK) questions,\nGradeOpt demonstrates superior performance in grading accuracy and behavior\nalignment with human graders compared to representative baselines. Finally,\ncomprehensive ablation studies confirm the effectiveness of the individual\ncomponents designed in GradeOpt."
  },
  {
    "arxiv_id": "2410.03663",
    "title": "Enhance Reasoning by Learning from Mistakes: Peer-Review Knowledge Distillation from Multiple Large Language Models",
    "url": "http://arxiv.org/abs/2410.03663v1",
    "abstract": "While reasoning capabilities typically emerge in large language models (LLMs)\nwith tens of billions of parameters, recent research focuses on improving\nsmaller open-source models through knowledge distillation (KD) from commercial\nLLMs. However, many of these studies rely solely on responses from a single LLM\nas the gold rationale, unlike the natural human learning process, which\ninvolves understanding both the correct answers and the reasons behind\nmistakes. In this paper, we introduce a novel Fault-Aware DistIllation via\nPeer-Review (FAIR) approach: 1) Instead of merely obtaining rationales from\nteachers, our method asks teachers to identify and explain the student's\nmistakes, providing customized instruction learning data. 2) We design a\nsimulated peer-review process between teacher LLMs, which selects only the\ngenerated rationales above the acceptance threshold. This reduces the chance of\nteachers guessing correctly with flawed rationale, improving instructional data\nquality. Comprehensive experiments and analysis on mathematical, commonsense,\nand logical reasoning tasks demonstrate the effectiveness of our method."
  },
  {
    "arxiv_id": "2410.03466",
    "title": "Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering",
    "url": "http://arxiv.org/abs/2410.03466v1",
    "abstract": "The potential effectiveness of counterspeech as a hate speech mitigation\nstrategy is attracting increasing interest in the NLG research community,\nparticularly towards the task of automatically producing it. However,\nautomatically generated responses often lack the argumentative richness which\ncharacterises expert-produced counterspeech. In this work, we focus on two\naspects of counterspeech generation to produce more cogent responses. First, by\ninvestigating the tension between helpfulness and harmlessness of LLMs, we test\nwhether the presence of safety guardrails hinders the quality of the\ngenerations. Secondly, we assess whether attacking a specific component of the\nhate speech results in a more effective argumentative strategy to fight online\nhate. By conducting an extensive human and automatic evaluation, we show how\nthe presence of safety guardrails can be detrimental also to a task that\ninherently aims at fostering positive social interactions. Moreover, our\nresults show that attacking a specific component of the hate speech, and in\nparticular its implicit negative stereotype and its hateful parts, leads to\nhigher-quality generations."
  },
  {
    "arxiv_id": "2410.03457",
    "title": "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds",
    "url": "http://arxiv.org/abs/2410.03457v1",
    "abstract": "Detecting logical fallacies in texts can help users spot argument flaws, but\nautomating this detection is not easy. Manually annotating fallacies in\nlarge-scale, real-world text data to create datasets for developing and\nvalidating detection models is costly. This paper introduces CoCoLoFa, the\nlargest known logical fallacy dataset, containing 7,706 comments for 648 news\narticles, with each comment labeled for fallacy presence and type. We recruited\n143 crowd workers to write comments embodying specific fallacy types (e.g.,\nslippery slope) in response to news articles. Recognizing the complexity of\nthis writing task, we built an LLM-powered assistant into the workers'\ninterface to aid in drafting and refining their comments. Experts rated the\nwriting quality and labeling validity of CoCoLoFa as high and reliable.\nBERT-based models fine-tuned using CoCoLoFa achieved the highest fallacy\ndetection (F1=0.86) and classification (F1=0.87) performance on its test set,\noutperforming the state-of-the-art LLMs. Our work shows that combining\ncrowdsourcing and LLMs enables us to more effectively construct datasets for\ncomplex linguistic phenomena that crowd workers find challenging to produce on\ntheir own."
  },
  {
    "arxiv_id": "2410.03278",
    "title": "What do Large Language Models Need for Machine Translation Evaluation?",
    "url": "http://arxiv.org/abs/2410.03278v1",
    "abstract": "Leveraging large language models (LLMs) for various natural language\nprocessing tasks has led to superlative claims about their performance. For the\nevaluation of machine translation (MT), existing research shows that LLMs are\nable to achieve results comparable to fine-tuned multilingual pre-trained\nlanguage models. In this paper, we explore what translation information, such\nas the source, reference, translation errors and annotation guidelines, is\nneeded for LLMs to evaluate MT quality. In addition, we investigate prompting\ntechniques such as zero-shot, Chain of Thought (CoT) and few-shot prompting for\neight language pairs covering high-, medium- and low-resource languages,\nleveraging varying LLM variants. Our findings indicate the importance of\nreference translations for an LLM-based evaluation. While larger models do not\nnecessarily fare better, they tend to benefit more from CoT prompting, than\nsmaller models. We also observe that LLMs do not always provide a numerical\nscore when generating evaluations, which poses a question on their reliability\nfor the task. Our work presents a comprehensive analysis for\nresource-constrained and training-less LLM-based evaluation of machine\ntranslation. We release the accrued prompt templates, code and data publicly\nfor reproducibility."
  },
  {
    "arxiv_id": "2410.03258",
    "title": "Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models",
    "url": "http://arxiv.org/abs/2410.03258v1",
    "abstract": "In this work, we show a fundamental limitation in vocabulary adaptation\napproaches that use Byte-Pair Encoding (BPE) tokenization scheme for\nfine-tuning pretrained language models (PLMs) to expert domains. Current\napproaches trivially append the target domain-specific vocabulary at the end of\nthe PLM vocabulary. This approach leads to a lower priority score and causes\nsub-optimal tokenization in BPE that iteratively uses merge rules to tokenize a\ngiven text. To mitigate this issue, we propose AdaptBPE where the BPE\ntokenization initialization phase is modified to first perform the longest\nstring matching on the added (target) vocabulary before tokenizing at the\ncharacter level. We perform an extensive evaluation of AdaptBPE versus the\nstandard BPE over various classification and summarization tasks; AdaptBPE\nimproves by 3.57% (in terms of accuracy) and 1.87% (in terms of Rouge-L),\nrespectively. AdaptBPE for MEDVOC works particularly well when reference\nsummaries have high OOV concentration or are longer in length. We also conduct\na human evaluation, revealing that AdaptBPE generates more relevant and more\nfaithful summaries as compared to MEDVOC. We make our codebase publicly\navailable at https://github.com/gb-kgp/adaptbpe."
  },
  {
    "arxiv_id": "2410.03132",
    "title": "Autoregressive Action Sequence Learning for Robotic Manipulation",
    "url": "http://arxiv.org/abs/2410.03132v1",
    "abstract": "Designing a universal policy architecture that performs well across diverse\nrobots and task configurations remains a key challenge. In this work, we\naddress this by representing robot actions as sequential data and generating\nactions through autoregressive sequence modeling. Existing autoregressive\narchitectures generate end-effector waypoints sequentially as word tokens in\nlanguage modeling, which are limited to low-frequency control tasks. Unlike\nlanguage, robot actions are heterogeneous and often include continuous values\n-- such as joint positions, 2D pixel coordinates, and end-effector poses --\nwhich are not easily suited for language-based modeling. Based on this insight,\nwe introduce a straightforward enhancement: we extend causal transformers'\nsingle-token prediction to support predicting a variable number of tokens in a\nsingle step through our Chunking Causal Transformer (CCT). This enhancement\nenables robust performance across diverse tasks of various control frequencies,\ngreater efficiency by having fewer autoregression steps, and lead to a hybrid\naction sequence design by mixing different types of actions and using a\ndifferent chunk size for each action type. Based on CCT, we propose the\nAutoregressive Policy (ARP) architecture, which solves manipulation tasks by\ngenerating hybrid action sequences. We evaluate ARP across diverse robotic\nmanipulation environments, including Push-T, ALOHA, and RLBench, and show that\nARP, as a universal architecture, matches or outperforms the\nenvironment-specific state-of-the-art in all tested benchmarks, while being\nmore efficient in computation and parameter sizes. Videos of our real robot\ndemonstrations, all source code and the pretrained models of ARP can be found\nat http://github.com/mlzxy/arp."
  },
  {
    "arxiv_id": "2410.05248",
    "title": "SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe",
    "url": "http://arxiv.org/abs/2410.05248v1",
    "abstract": "To acquire instruction-following capabilities, large language models (LLMs)\nundergo instruction tuning, where they are trained on instruction-response\npairs using next-token prediction (NTP). Efforts to improve instruction tuning\noften focus on higher-quality supervised fine-tuning (SFT) datasets, typically\nrequiring data filtering with proprietary LLMs or human annotation. In this\npaper, we take a different approach by proposing SFTMix, a novel Mixup-based\nrecipe that elevates LLM instruction tuning beyond the conventional NTP\nparadigm, without relying on well-curated datasets. Observing that LLMs exhibit\nuneven confidence across the semantic representation space, we argue that\nexamples with different confidence levels should play distinct roles in\ninstruction tuning--confident data is prone to overfitting, while unconfident\ndata is harder to generalize. Based on this insight, SFTMix leverages training\ndynamics to identify examples with varying confidence levels, interpolates them\nto bridge the confidence gap, and applies a Mixup-based regularization to\nsupport learning on these additional, interpolated examples. By propagating\nsupervision signals across confidence regions and encouraging linear behavior\nbetween them, SFTMix mitigates overfitting in confident examples while\nenhancing generalization in unconfident ones. We demonstrate the effectiveness\nof SFTMix in both instruction-following and healthcare-specific SFT tasks, with\nconsistent improvements across LLM families and SFT datasets of varying sizes\nand qualities. Extensive analyses across six directions highlight SFTMix's\ncompatibility with data selection, adaptability to compute-constrained\nscenarios, and scalability to broader applications."
  },
  {
    "arxiv_id": "2410.05085",
    "title": "Explanation sensitivity to the randomness of large language models: the case of journalistic text classification",
    "url": "http://arxiv.org/abs/2410.05085v1",
    "abstract": "Large language models (LLMs) perform very well in several natural language\nprocessing tasks but raise explainability challenges. In this paper, we examine\nthe effect of random elements in the training of LLMs on the explainability of\ntheir predictions. We do so on a task of opinionated journalistic text\nclassification in French. Using a fine-tuned CamemBERT model and an explanation\nmethod based on relevance propagation, we find that training with different\nrandom seeds produces models with similar accuracy but variable explanations.\nWe therefore claim that characterizing the explanations' statistical\ndistribution is needed for the explainability of LLMs. We then explore a\nsimpler model based on textual features which offers stable explanations but is\nless accurate. Hence, this simpler model corresponds to a different tradeoff\nbetween accuracy and explainability. We show that it can be improved by\ninserting features derived from CamemBERT's explanations. We finally discuss\nnew research directions suggested by our results, in particular regarding the\norigin of the sensitivity observed in the training randomness."
  },
  {
    "arxiv_id": "2410.05045",
    "title": "Can LLMs plan paths with extra hints from solvers?",
    "url": "http://arxiv.org/abs/2410.05045v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing, mathematical problem solving, and tasks related to program\nsynthesis. However, their effectiveness in long-term planning and higher-order\nreasoning has been noted to be limited and fragile. This paper explores an\napproach for enhancing LLM performance in solving a classical robotic planning\ntask by integrating solver-generated feedback. We explore four different\nstrategies for providing feedback, including visual feedback, we utilize\nfine-tuning, and we evaluate the performance of three different LLMs across a\n10 standard and 100 more randomly generated planning problems. Our results\nsuggest that the solver-generated feedback improves the LLM's ability to solve\nthe moderately difficult problems, but the harder problems still remain out of\nreach. The study provides detailed analysis of the effects of the different\nhinting strategies and the different planning tendencies of the evaluated LLMs."
  },
  {
    "arxiv_id": "2410.04519",
    "title": "RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference",
    "url": "http://arxiv.org/abs/2410.04519v1",
    "abstract": "Large language models (LLMs) have brought a great breakthrough to the natural\nlanguage processing (NLP) community, while leading the challenge of handling\nconcurrent customer queries due to their high throughput demands. Data\nmultiplexing addresses this by merging multiple inputs into a single composite\ninput, allowing more efficient inference through a shared forward pass.\nHowever, as distinguishing individuals from a composite input is challenging,\nconventional methods typically require training the entire backbone, yet still\nsuffer from performance degradation. In this paper, we introduce RevMUX, a\nparameter-efficient data multiplexing framework that incorporates a reversible\ndesign in the multiplexer, which can be reused by the demultiplexer to perform\nreverse operations and restore individual samples for classification. Extensive\nexperiments on four datasets and three types of LLM backbones demonstrate the\neffectiveness of RevMUX for enhancing LLM inference efficiency while retaining\na satisfactory classification performance."
  },
  {
    "arxiv_id": "2410.06886",
    "title": "FltLM: An Intergrated Long-Context Large Language Model for Effective Context Filtering and Understanding",
    "url": "http://arxiv.org/abs/2410.06886v1",
    "abstract": "The development of Long-Context Large Language Models (LLMs) has markedly\nadvanced natural language processing by facilitating the process of textual\ndata across long documents and multiple corpora. However, Long-Context LLMs\nstill face two critical challenges: The lost in the middle phenomenon, where\ncrucial middle-context information is likely to be missed, and the distraction\nissue that the models lose focus due to overly extended contexts. To address\nthese challenges, we propose the Context Filtering Language Model (FltLM), a\nnovel integrated Long-Context LLM which enhances the ability of the model on\nmulti-document question-answering (QA) tasks. Specifically, FltLM innovatively\nincorporates a context filter with a soft mask mechanism, identifying and\ndynamically excluding irrelevant content to concentrate on pertinent\ninformation for better comprehension and reasoning. Our approach not only\nmitigates these two challenges, but also enables the model to operate\nconveniently in a single forward pass. Experimental results demonstrate that\nFltLM significantly outperforms supervised fine-tuning and retrieval-based\nmethods in complex QA scenarios, suggesting a promising solution for more\naccurate and reliable long-context natural language understanding applications."
  },
  {
    "arxiv_id": "2410.06667",
    "title": "Large Language Models as Code Executors: An Exploratory Study",
    "url": "http://arxiv.org/abs/2410.06667v1",
    "abstract": "The capabilities of Large Language Models (LLMs) have significantly evolved,\nextending from natural language processing to complex tasks like code\nunderstanding and generation. We expand the scope of LLMs' capabilities to a\nbroader context, using LLMs to execute code snippets to obtain the output. This\npaper pioneers the exploration of LLMs as code executors, where code snippets\nare directly fed to the models for execution, and outputs are returned. We are\nthe first to comprehensively examine this feasibility across various LLMs,\nincluding OpenAI's o1, GPT-4o, GPT-3.5, DeepSeek, and Qwen-Coder. Notably, the\no1 model achieved over 90% accuracy in code execution, while others\ndemonstrated lower accuracy levels. Furthermore, we introduce an Iterative\nInstruction Prompting (IIP) technique that processes code snippets line by\nline, enhancing the accuracy of weaker models by an average of 7.22% (with the\nhighest improvement of 18.96%) and an absolute average improvement of 3.86%\nagainst CoT prompting (with the highest improvement of 19.46%). Our study not\nonly highlights the transformative potential of LLMs in coding but also lays\nthe groundwork for future advancements in automated programming and the\ncompletion of complex tasks."
  },
  {
    "arxiv_id": "2410.06554",
    "title": "The Accuracy Paradox in RLHF: When Better Reward Models Don't Yield Better Language Models",
    "url": "http://arxiv.org/abs/2410.06554v1",
    "abstract": "Reinforcement Learning from Human Feedback significantly enhances Natural\nLanguage Processing by aligning language models with human expectations. A\ncritical factor in this alignment is the strength of reward models used during\ntraining. This study explores whether stronger reward models invariably lead to\nbetter language models. In this paper, through experiments on relevance,\nfactuality, and completeness tasks using the QA-FEEDBACK dataset and reward\nmodels based on Longformer, we uncover a surprising paradox: language models\ntrained with moderately accurate reward models outperform those guided by\nhighly accurate ones. This challenges the widely held belief that stronger\nreward models always lead to better language models, and opens up new avenues\nfor future research into the key factors driving model performance and how to\nchoose the most suitable reward models. Code and additional details are\navailable at https://github.com/EIT-NLP/AccuracyParadox-RLHF."
  },
  {
    "arxiv_id": "2410.06520",
    "title": "A Novel LLM-based Two-stage Summarization Approach for Long Dialogues",
    "url": "http://arxiv.org/abs/2410.06520v1",
    "abstract": "Long document summarization poses a significant challenge in natural language\nprocessing due to input lengths that exceed the capacity of most\nstate-of-the-art pre-trained language models. This study proposes a\nhierarchical framework that segments and condenses information from long\ndocuments, subsequently fine-tuning the processed text with an abstractive\nsummarization model. Unsupervised topic segmentation methods identify\nsemantically appropriate breakpoints. The condensation stage utilizes an\nunsupervised generation model to generate condensed data, and our current\nexperiments employ ChatGPT(v3.5). The summarization stage fine-tunes the\nabstractive summarization model on the condensed data to generate the final\nresults. This framework enables long documents to be processed on models even\nwhen the document length exceeds the model's maximum input size. The exclusion\nof the entire document from the summarization model reduces the time and\ncomputational resources required for training, making the framework suitable\nfor contexts with constrained local computational resources."
  },
  {
    "arxiv_id": "2410.07896",
    "title": "Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines",
    "url": "http://arxiv.org/abs/2410.07896v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of natural language processing and reasoning tasks. However, their\nperformance in the foundational domain of arithmetic remains unsatisfactory.\nWhen dealing with arithmetic tasks, LLMs often memorize specific examples\nrather than learning the underlying computational logic, limiting their ability\nto generalize to new problems. In this paper, we propose a Composable\nArithmetic Execution Framework (CAEF) that enables LLMs to learn to execute\nstep-by-step computations by emulating Turing Machines, thereby gaining a\ngenuine understanding of computational logic. Moreover, the proposed framework\nis highly scalable, allowing composing learned operators to significantly\nreduce the difficulty of learning complex operators. In our evaluation, CAEF\nachieves nearly 100% accuracy across seven common mathematical operations on\nthe LLaMA 3.1-8B model, effectively supporting computations involving operands\nwith up to 100 digits, a level where GPT-4o falls short noticeably in some\nsettings."
  },
  {
    "arxiv_id": "2410.07507",
    "title": "Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)",
    "url": "http://arxiv.org/abs/2410.07507v1",
    "abstract": "Decoding and expressing brain activity in a comprehensible form is a\nchallenging frontier in AI. This paper presents Thought2Text, which uses\ninstruction-tuned Large Language Models (LLMs) fine-tuned with EEG data to\nachieve this goal. The approach involves three stages: (1) training an EEG\nencoder for visual feature extraction, (2) fine-tuning LLMs on image and text\ndata, enabling multimodal description generation, and (3) further fine-tuning\non EEG embeddings to generate text directly from EEG during inference.\nExperiments on a public EEG dataset collected for six subjects with image\nstimuli and text captions demonstrate the efficacy of multimodal LLMs\n(LLaMA-v3, Mistral-v0.3, Qwen2.5), validated using traditional language\ngeneration evaluation metrics, as well as fluency and adequacy measures. This\napproach marks a significant advancement towards portable, low-cost\n\"thoughts-to-text\" technology with potential applications in both neuroscience\nand natural language processing."
  },
  {
    "arxiv_id": "2410.08928",
    "title": "Towards Cross-Lingual LLM Evaluation for European Languages",
    "url": "http://arxiv.org/abs/2410.08928v1",
    "abstract": "The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation."
  },
  {
    "arxiv_id": "2410.08860",
    "title": "Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies",
    "url": "http://arxiv.org/abs/2410.08860v1",
    "abstract": "Audio descriptions (ADs) function as acoustic commentaries designed to assist\nblind persons and persons with visual impairments in accessing digital media\ncontent on television and in movies, among other settings. As an accessibility\nservice typically provided by trained AD professionals, the generation of ADs\ndemands significant human effort, making the process both time-consuming and\ncostly. Recent advancements in natural language processing (NLP) and computer\nvision (CV), particularly in large language models (LLMs) and vision-language\nmodels (VLMs), have allowed for getting a step closer to automatic AD\ngeneration. This paper reviews the technologies pertinent to AD generation in\nthe era of LLMs and VLMs: we discuss how state-of-the-art NLP and CV\ntechnologies can be applied to generate ADs and identify essential research\ndirections for the future."
  },
  {
    "arxiv_id": "2410.08669",
    "title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction",
    "url": "http://arxiv.org/abs/2410.08669v1",
    "abstract": "Predicting the future motion of surrounding agents is essential for\nautonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed\nenvironments. However, the scarcity of large-scale driving datasets has\nhindered the development of robust and generalizable motion prediction models,\nlimiting their ability to capture complex interactions and road geometries.\nInspired by recent advances in natural language processing (NLP) and computer\nvision (CV), self-supervised learning (SSL) has gained significant attention in\nthe motion prediction community for learning rich and transferable scene\nrepresentations. Nonetheless, existing pre-training methods for motion\nprediction have largely focused on specific model architectures and single\ndataset, limiting their scalability and generalizability. To address these\nchallenges, we propose SmartPretrain, a general and scalable SSL framework for\nmotion prediction that is both model-agnostic and dataset-agnostic. Our\napproach integrates contrastive and reconstructive SSL, leveraging the\nstrengths of both generative and discriminative paradigms to effectively\nrepresent spatiotemporal evolution and interactions without imposing\narchitectural constraints. Additionally, SmartPretrain employs a\ndataset-agnostic scenario sampling strategy that integrates multiple datasets,\nenhancing data volume, diversity, and robustness. Extensive experiments on\nmultiple datasets demonstrate that SmartPretrain consistently improves the\nperformance of state-of-the-art prediction models across datasets, data splits\nand main metrics. For instance, SmartPretrain significantly reduces the\nMissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's\neffectiveness as a unified, scalable solution for motion prediction, breaking\nfree from the limitations of the small-data regime. Codes are available at\nhttps://github.com/youngzhou1999/SmartPretrain"
  },
  {
    "arxiv_id": "2410.10743",
    "title": "NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models",
    "url": "http://arxiv.org/abs/2410.10743v1",
    "abstract": "Graphs are a fundamental data structure for representing relationships in\nreal-world scenarios. With the success of Large Language Models (LLMs) across\nvarious natural language processing (NLP) tasks, there has been growing\ninterest in integrating LLMs for graph learning. However, applying LLMs to\ngraph-related tasks poses significant challenges, as these models are not\ninherently designed to capture the complex structural information present in\ngraphs. Existing approaches address this challenge through two strategies: the\nchain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the\ngraph structure so that LLMs are relieved from understanding spatial positions;\nand Graph-to-Text Conversion, which translates graph structures into semantic\ntext representations that LLMs can process. Despite their progress, these\nmethods often struggle to fully preserve the topological information of graphs\nor require extensive computational resources, limiting their practical\napplicability.\n  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),\na novel framework that efficiently encodes graph structures by selecting key\nnodes as anchors and representing each node based on its relative distance to\nthese anchors. This position-anchored encoding effectively captures the graph\ntopology, enabling enhanced reasoning capabilities in LLMs over graph data.\nAdditionally, we implement a task-specific tuning procedure to further improve\nstructural understanding within LLMs. Through extensive empirical evaluations,\nNT-LLM demonstrates significant performance improvements across a variety of\ngraph-related tasks."
  },
  {
    "arxiv_id": "2410.10714",
    "title": "SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators",
    "url": "http://arxiv.org/abs/2410.10714v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nbut face significant challenges in widespread deployment due to their high\nruntime cost. In this paper, we introduce SeedLM, a novel post-training\ncompression method that uses seeds of pseudo-random generators to encode and\ncompress model weights. Specifically, for each block of weights, we find a seed\nthat is fed into a Linear Feedback Shift Register (LFSR) during inference to\nefficiently generate a random matrix. This matrix is then linearly combined\nwith compressed coefficients to reconstruct the weight block. SeedLM reduces\nmemory access and leverages idle compute cycles during inference, effectively\nspeeding up memory-bound tasks by trading compute for fewer memory accesses.\nUnlike state-of-the-art compression methods that rely on calibration data, our\napproach is data-free and generalizes well across diverse tasks. Our\nexperiments with Llama 3 70B, which is particularly challenging to compress,\nshow that SeedLM achieves significantly better zero-shot accuracy retention at\n4- and 3-bit than state-of-the-art techniques, while maintaining performance\ncomparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that\n4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an\nFP16 Llama 2/3 baseline."
  },
  {
    "arxiv_id": "2410.10680",
    "title": "Evaluating SQL Understanding in Large Language Models",
    "url": "http://arxiv.org/abs/2410.10680v1",
    "abstract": "The rise of large language models (LLMs) has significantly impacted various\ndomains, including natural language processing (NLP) and image generation, by\nmaking complex computational tasks more accessible. While LLMs demonstrate\nimpressive generative capabilities, there is an ongoing debate about their\nlevel of \"understanding,\" particularly in structured domains like SQL. In this\npaper, we evaluate the extent to which LLMs \"understand\" SQL by testing them on\na series of key SQL tasks. These tasks, such as syntax error detection, missing\ntoken identification, query performance prediction, query equivalence checking,\nand query explanation, assess the models' proficiency in recognition, context\nawareness, semantics, and coherence, which are essential skills for SQL\nunderstanding. We generate labeled datasets from well-known workloads, and\nevaluate the latest LLMs, focusing on how query complexity and syntactic\nfeatures influence performance. Our results indicate that while GPT4 excels at\ntasks requiring recognition and context, all models struggle with deeper\nsemantic understanding and coherence, especially in query equivalence and\nperformance estimation, revealing the limitations of current LLMs in achieving\nfull SQL comprehension."
  },
  {
    "arxiv_id": "2410.10349",
    "title": "LLM-based Code-Switched Text Generation for Grammatical Error Correction",
    "url": "http://arxiv.org/abs/2410.10349v1",
    "abstract": "With the rise of globalisation, code-switching (CSW) has become a ubiquitous\npart of multilingual conversation, posing new challenges for natural language\nprocessing (NLP), especially in Grammatical Error Correction (GEC). This work\nexplores the complexities of applying GEC systems to CSW texts. Our objectives\ninclude evaluating the performance of state-of-the-art GEC systems on an\nauthentic CSW dataset from English as a Second Language (ESL) learners,\nexploring synthetic data generation as a solution to data scarcity, and\ndeveloping a model capable of correcting grammatical errors in monolingual and\nCSW texts. We generated synthetic CSW GEC data, resulting in one of the first\nsubstantial datasets for this task, and showed that a model trained on this\ndata is capable of significant improvements over existing systems. This work\ntargets ESL learners, aiming to provide educational technologies that aid in\nthe development of their English grammatical correctness without constraining\ntheir natural multilingualism."
  },
  {
    "arxiv_id": "2410.09992",
    "title": "Evaluating Gender Bias of LLMs in Making Morality Judgements",
    "url": "http://arxiv.org/abs/2410.09992v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in a\nmultitude of Natural Language Processing (NLP) tasks. However, these models are\nstill not immune to limitations such as social biases, especially gender bias.\nThis work investigates whether current closed and open-source LLMs possess\ngender bias, especially when asked to give moral opinions. To evaluate these\nmodels, we curate and introduce a new dataset GenMO (Gender-bias in Morality\nOpinions) comprising parallel short stories featuring male and female\ncharacters respectively. Specifically, we test models from the GPT family\n(GPT-3.5-turbo, GPT-3.5-turbo-instruct, GPT-4-turbo), Llama 3 and 3.1 families\n(8B/70B), Mistral-7B and Claude 3 families (Sonnet and Opus). Surprisingly,\ndespite employing safety checks, all production-standard models we tested\ndisplay significant gender bias with GPT-3.5-turbo giving biased opinions in\n24% of the samples. Additionally, all models consistently favour female\ncharacters, with GPT showing bias in 68-85% of cases and Llama 3 in around\n81-85% instances. Additionally, our study investigates the impact of model\nparameters on gender bias and explores real-world situations where LLMs reveal\nbiases in moral decision-making."
  },
  {
    "arxiv_id": "2410.09982",
    "title": "Self-Data Distillation for Recovering Quality in Pruned Large Language Models",
    "url": "http://arxiv.org/abs/2410.09982v1",
    "abstract": "Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings."
  },
  {
    "arxiv_id": "2410.11786",
    "title": "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability",
    "url": "http://arxiv.org/abs/2410.11786v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts."
  },
  {
    "arxiv_id": "2410.11720",
    "title": "Light-Weight Fault Tolerant Attention for Large Language Model Training",
    "url": "http://arxiv.org/abs/2410.11720v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nvarious natural language processing tasks. However, the training of these\nmodels is computationally intensive and susceptible to faults, particularly in\nthe attention mechanism, which is a critical component of transformer-based\nLLMs. In this paper, we investigate the impact of faults on LLM training,\nfocusing on INF, NaN, and near-INF values in the computation results with\nsystematic fault injection experiments. We observe the propagation patterns of\nthese errors, which can trigger non-trainable states in the model and disrupt\ntraining, forcing the procedure to load from checkpoints. To mitigate the\nimpact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault\nTolerance (ABFT) technique tailored for the attention mechanism in LLMs.\nATTNChecker is designed based on fault propagation patterns of LLM and\nincorporates performance optimization to adapt to both system reliability and\nmodel vulnerability while providing lightweight protection for fast LLM\ntraining. Evaluations on four LLMs show that ATTNChecker incurs on average 7%\noverhead on training while detecting and correcting all extreme errors.\nCompared with the state-of-the-art checkpoint/restore approach, ATTNChecker\nreduces recovery overhead by up to 49x."
  },
  {
    "arxiv_id": "2410.11711",
    "title": "Zero-shot Model-based Reinforcement Learning using Large Language Models",
    "url": "http://arxiv.org/abs/2410.11711v1",
    "abstract": "The emerging zero-shot capabilities of Large Language Models (LLMs) have led\nto their applications in areas extending well beyond natural language\nprocessing tasks. In reinforcement learning, while LLMs have been extensively\nused in text-based environments, their integration with continuous state spaces\nremains understudied. In this paper, we investigate how pre-trained LLMs can be\nleveraged to predict in context the dynamics of continuous Markov decision\nprocesses. We identify handling multivariate data and incorporating the control\nsignal as key challenges that limit the potential of LLMs' deployment in this\nsetup and propose Disentangled In-Context Learning (DICL) to address them. We\npresent proof-of-concept applications in two reinforcement learning settings:\nmodel-based policy evaluation and data-augmented off-policy reinforcement\nlearning, supported by theoretical analysis of the proposed methods. Our\nexperiments further demonstrate that our approach produces well-calibrated\nuncertainty estimates. We release the code at\nhttps://github.com/abenechehab/dicl."
  },
  {
    "arxiv_id": "2410.11672",
    "title": "Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers",
    "url": "http://arxiv.org/abs/2410.11672v1",
    "abstract": "The integrity of AI benchmarks is fundamental to accurately assess the\ncapabilities of AI systems. The internal validity of these benchmarks - i.e.,\nmaking sure they are free from confounding factors - is crucial for ensuring\nthat they are measuring what they are designed to measure. In this paper, we\nexplore a key issue related to internal validity: the possibility that AI\nsystems can solve benchmarks in unintended ways, bypassing the capability being\ntested. This phenomenon, widely known in human and animal experiments, is often\nreferred to as the 'Clever Hans' effect, where tasks are solved using spurious\ncues, often involving much simpler processes than those putatively assessed.\nPrevious research suggests that language models can exhibit this behaviour as\nwell. In several older Natural Language Processing (NLP) benchmarks, individual\n$n$-grams like \"not\" have been found to be highly predictive of the correct\nlabels, and supervised NLP models have been shown to exploit these patterns. In\nthis work, we investigate the extent to which simple $n$-grams extracted from\nbenchmark instances can be combined to predict labels in modern multiple-choice\nbenchmarks designed for LLMs, and whether LLMs might be using such $n$-gram\npatterns to solve these benchmarks. We show how simple classifiers trained on\nthese $n$-grams can achieve high scores on several benchmarks, despite lacking\nthe capabilities being tested. Additionally, we provide evidence that modern\nLLMs might be using these superficial patterns to solve benchmarks. This\nsuggests that the internal validity of these benchmarks may be compromised and\ncaution should be exercised when interpreting LLM performance results on them."
  },
  {
    "arxiv_id": "2410.11526",
    "title": "Human-LLM Collaborative Construction of a Cantonese Emotion Lexicon",
    "url": "http://arxiv.org/abs/2410.11526v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nlanguage understanding and generation. Advanced utilization of the knowledge\nembedded in LLMs for automated annotation has consistently been explored. This\nstudy proposed to develop an emotion lexicon for Cantonese, a low-resource\nlanguage, through collaborative efforts between LLM and human annotators. By\nintegrating emotion labels provided by LLM and human annotators, the study\nleveraged existing linguistic resources including lexicons in other languages\nand local forums to construct a Cantonese emotion lexicon enriched with\ncolloquial expressions. The consistency of the proposed emotion lexicon in\nemotion extraction was assessed through modification and utilization of three\ndistinct emotion text datasets. This study not only validates the efficacy of\nthe constructed lexicon but also emphasizes that collaborative annotation\nbetween human and artificial intelligence can significantly enhance the quality\nof emotion labels, highlighting the potential of such partnerships in\nfacilitating natural language processing tasks for low-resource languages."
  },
  {
    "arxiv_id": "2410.11006",
    "title": "Effective Self-Mining of In-Context Examples for Unsupervised Machine Translation with LLMs",
    "url": "http://arxiv.org/abs/2410.11006v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance on a\nwide range of natural language processing (NLP) tasks, primarily through\nin-context learning (ICL). In ICL, the LLM is provided with examples that\nrepresent a given task such that it learns to generate answers for test inputs.\nHowever, access to these in-context examples is not guaranteed especially for\nlow-resource or massively multilingual tasks. In this work, we propose an\nunsupervised approach to mine in-context examples for machine translation (MT),\nenabling unsupervised MT (UMT) across different languages. Our approach begins\nwith word-level mining to acquire word translations that are then used to\nperform sentence-level mining. As the quality of mined parallel pairs may not\nbe optimal due to noise or mistakes, we introduce a filtering criterion to\nselect the optimal in-context examples from a pool of unsupervised parallel\nsentences. We evaluate our approach using two multilingual LLMs on 288\ndirections from the FLORES-200 dataset and analyze the impact of various\nlinguistic features on performance. Our findings demonstrate the effectiveness\nof our unsupervised approach in mining in-context examples for MT, leading to\nbetter or comparable translation performance as translation with regular\nin-context samples (extracted from human-annotated data), while also\noutperforming the other state-of-the-art UMT methods by an average of $7$ BLEU\npoints."
  },
  {
    "arxiv_id": "2410.12473",
    "title": "Unifying Economic and Language Models for Enhanced Sentiment Analysis of the Oil Market",
    "url": "http://arxiv.org/abs/2410.12473v1",
    "abstract": "Crude oil, a critical component of the global economy, has its prices\ninfluenced by various factors such as economic trends, political events, and\nnatural disasters. Traditional prediction methods based on historical data have\ntheir limits in forecasting, but recent advancements in natural language\nprocessing bring new possibilities for event-based analysis. In particular,\nLanguage Models (LM) and their advancement, the Generative Pre-trained\nTransformer (GPT), have shown potential in classifying vast amounts of natural\nlanguage. However, these LMs often have difficulty with domain-specific\nterminology, limiting their effectiveness in the crude oil sector. Addressing\nthis gap, we introduce CrudeBERT, a fine-tuned LM specifically for the crude\noil market. The results indicate that CrudeBERT's sentiment scores align more\nclosely with the WTI Futures curve and significantly enhance price predictions,\nunderscoring the crucial role of integrating economic principles into LMs."
  },
  {
    "arxiv_id": "2410.12462",
    "title": "Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention",
    "url": "http://arxiv.org/abs/2410.12462v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing but exhibit significant performance gaps among different\nlanguages. Most existing approaches to address these disparities rely on\npretraining or fine-tuning, which are resource-intensive. To overcome these\nlimitations without incurring significant costs, we propose Inference-Time\nCross-Lingual Intervention (INCLINE), a novel framework that enhances LLM\nperformance on low-performing (source) languages by aligning their internal\nrepresentations with those of high-performing (target) languages during\ninference. INCLINE initially learns alignment matrices using parallel sentences\nfrom source and target languages through a Least-Squares optimization, and then\napplies these matrices during inference to transform the low-performing\nlanguage representations toward the high-performing language space. Extensive\nexperiments on nine benchmarks with five LLMs demonstrate that INCLINE\nsignificantly improves performance across diverse tasks and languages, compared\nto recent strong baselines. Our analysis demonstrates that INCLINE is highly\ncost-effective and applicable to a wide range of applications. In addition, we\nrelease the code to foster research along this line:\nhttps://github.com/weixuan-wang123/INCLINE."
  },
  {
    "arxiv_id": "2410.12376",
    "title": "ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing",
    "url": "http://arxiv.org/abs/2410.12376v1",
    "abstract": "Vector data is one of the two core data structures in geographic information\nscience (GIS), essential for accurately storing and representing geospatial\ninformation. Shapefile, the most widely used vector data format, has become the\nindustry standard supported by all major geographic information systems.\nHowever, processing this data typically requires specialized GIS knowledge and\nskills, creating a barrier for researchers from other fields and impeding\ninterdisciplinary research in spatial data analysis. Moreover, while large\nlanguage models (LLMs) have made significant advancements in natural language\nprocessing and task automation, they still face challenges in handling the\ncomplex spatial and topological relationships inherent in GIS vector data. To\naddress these challenges, we propose ShapefileGPT, an innovative framework\npowered by LLMs, specifically designed to automate Shapefile tasks.\nShapefileGPT utilizes a multi-agent architecture, in which the planner agent is\nresponsible for task decomposition and supervision, while the worker agent\nexecutes the tasks. We developed a specialized function library for handling\nShapefiles and provided comprehensive API documentation, enabling the worker\nagent to operate Shapefiles efficiently through function calling. For\nevaluation, we developed a benchmark dataset based on authoritative textbooks,\nencompassing tasks in categories such as geometric operations and spatial\nqueries. ShapefileGPT achieved a task success rate of 95.24%, outperforming the\nGPT series models. In comparison to traditional LLMs, ShapefileGPT effectively\nhandles complex vector data analysis tasks, overcoming the limitations of\ntraditional LLMs in spatial analysis. This breakthrough opens new pathways for\nadvancing automation and intelligence in the GIS field, with significant\npotential in interdisciplinary data analysis and application contexts."
  },
  {
    "arxiv_id": "2410.12174",
    "title": "Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish",
    "url": "http://arxiv.org/abs/2410.12174v1",
    "abstract": "Hate speech detection deals with many language variants, slang, slurs,\nexpression modalities, and cultural nuances. This outlines the importance of\nworking with specific corpora, when addressing hate speech within the scope of\nNatural Language Processing, recently revolutionized by the irruption of Large\nLanguage Models. This work presents a brief analysis of the performance of\nlarge language models in the detection of Hate Speech for Rioplatense Spanish.\nWe performed classification experiments leveraging chain-of-thought reasoning\nwith ChatGPT 3.5, Mixtral, and Aya, comparing their results with those of a\nstate-of-the-art BERT classifier. These experiments outline that, even if large\nlanguage models show a lower precision compared to the fine-tuned BERT\nclassifier and, in some cases, they find hard-to-get slurs or colloquialisms,\nthey still are sensitive to highly nuanced cases (particularly,\nhomophobic/transphobic hate speech). We make our code and models publicly\navailable for future research."
  },
  {
    "arxiv_id": "2410.13859",
    "title": "$γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models",
    "url": "http://arxiv.org/abs/2410.13859v1",
    "abstract": "Despite the significant progress in multimodal large language models (MLLMs),\ntheir high computational cost remains a barrier to real-world deployment.\nInspired by the mixture of depths (MoDs) in natural language processing, we aim\nto address this limitation from the perspective of ``activated tokens''. Our\nkey insight is that if most tokens are redundant for the layer computation,\nthen can be skipped directly via the MoD layer. However, directly converting\nthe dense layers of MLLMs to MoD layers leads to substantial performance\ndegradation. To address this issue, we propose an innovative MoD adaptation\nstrategy for existing MLLMs called $\\gamma$-MoD. In $\\gamma$-MoD, a novel\nmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank of\nattention maps (ARank). Through ARank, we can effectively identify which layer\nis redundant and should be replaced with the MoD layer. Based on ARank, we\nfurther propose two novel designs to maximize the computational sparsity of\nMLLM while maintaining its performance, namely shared vision-language router\nand masked routing learning. With these designs, more than 90% dense layers of\nthe MLLM can be effectively converted to the MoD ones. To validate our method,\nwe apply it to three popular MLLMs, and conduct extensive experiments on 9\nbenchmark datasets. Experimental results not only validate the significant\nefficiency benefit of $\\gamma$-MoD to existing MLLMs but also confirm its\ngeneralization ability on various MLLMs. For example, with a minor performance\ndrop, i.e., -1.5%, $\\gamma$-MoD can reduce the training and inference time of\nLLaVA-HR by 31.0% and 53.2%, respectively."
  },
  {
    "arxiv_id": "2410.13792",
    "title": "Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning",
    "url": "http://arxiv.org/abs/2410.13792v1",
    "abstract": "Transformer models have consistently achieved remarkable results in various\ndomains such as natural language processing and computer vision. However,\ndespite ongoing research efforts to better understand these models, the field\nstill lacks a comprehensive understanding. This is particularly true for deep\ntime series forecasting methods, where analysis and understanding work is\nrelatively limited. Time series data, unlike image and text information, can be\nmore challenging to interpret and analyze. To address this, we approach the\nproblem from a manifold learning perspective, assuming that the latent\nrepresentations of time series forecasting models lie next to a low-dimensional\nmanifold. In our study, we focus on analyzing the geometric features of these\nlatent data manifolds, including intrinsic dimension and principal curvatures.\nOur findings reveal that deep transformer models exhibit similar geometric\nbehavior across layers, and these geometric features are correlated with model\nperformance. Additionally, we observe that untrained models initially have\ndifferent structures, but they rapidly converge during training. By leveraging\nour geometric analysis and differentiable tools, we can potentially design new\nand improved deep forecasting neural networks. This approach complements\nexisting analysis studies and contributes to a better understanding of\ntransformer models in the context of time series forecasting. Code is released\nat https://github.com/azencot-group/GATLM."
  },
  {
    "arxiv_id": "2410.13732",
    "title": "Reducing the Transformer Architecture to a Minimum",
    "url": "http://arxiv.org/abs/2410.13732v1",
    "abstract": "Transformers are a widespread and successful model architecture, particularly\nin Natural Language Processing (NLP) and Computer Vision (CV). The essential\ninnovation of this architecture is the Attention Mechanism, which solves the\nproblem of extracting relevant context information from long sequences in NLP\nand realistic scenes in CV. A classical neural network component, a Multi-Layer\nPerceptron (MLP), complements the attention mechanism. Its necessity is\nfrequently justified by its capability of modeling nonlinear relationships.\nHowever, the attention mechanism itself is nonlinear through its internal use\nof similarity measures. A possible hypothesis is that this nonlinearity is\nsufficient for modeling typical application problems. As the MLPs usually\ncontain the most trainable parameters of the whole model, their omission would\nsubstantially reduce the parameter set size. Further components can also be\nreorganized to reduce the number of parameters. Under some conditions, query\nand key matrices can be collapsed into a single matrix of the same size. The\nsame is true about value and projection matrices, which can also be omitted\nwithout eliminating the substance of the attention mechanism. Initially, the\nsimilarity measure was defined asymmetrically, with peculiar properties such as\nthat a token is possibly dissimilar to itself. A possible symmetric definition\nrequires only half of the parameters. We have laid the groundwork by testing\nwidespread CV benchmarks: MNIST and CIFAR-10. The tests have shown that\nsimplified transformer architectures (a) without MLP, (b) with collapsed\nmatrices, and (c) symmetric similarity matrices exhibit similar performance as\nthe original architecture, saving up to 90% of parameters without hurting the\nclassification performance."
  },
  {
    "arxiv_id": "2410.13649",
    "title": "A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks",
    "url": "http://arxiv.org/abs/2410.13649v1",
    "abstract": "In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance."
  },
  {
    "arxiv_id": "2410.13605",
    "title": "Transformer-Based Approaches for Sensor-Based Human Activity Recognition: Opportunities and Challenges",
    "url": "http://arxiv.org/abs/2410.13605v1",
    "abstract": "Transformers have excelled in natural language processing and computer\nvision, paving their way to sensor-based Human Activity Recognition (HAR).\nPrevious studies show that transformers outperform their counterparts\nexclusively when they harness abundant data or employ compute-intensive\noptimization algorithms. However, neither of these scenarios is viable in\nsensor-based HAR due to the scarcity of data in this field and the frequent\nneed to perform training and inference on resource-constrained devices. Our\nextensive investigation into various implementations of transformer-based\nversus non-transformer-based HAR using wearable sensors, encompassing more than\n500 experiments, corroborates these concerns. We observe that transformer-based\nsolutions pose higher computational demands, consistently yield inferior\nperformance, and experience significant performance degradation when quantized\nto accommodate resource-constrained devices. Additionally, transformers\ndemonstrate lower robustness to adversarial attacks, posing a potential threat\nto user trust in HAR."
  },
  {
    "arxiv_id": "2410.13396",
    "title": "Linguistically Grounded Analysis of Language Models using Shapley Head Values",
    "url": "http://arxiv.org/abs/2410.13396v1",
    "abstract": "Understanding how linguistic knowledge is encoded in language models is\ncrucial for improving their generalisation capabilities. In this paper, we\ninvestigate the processing of morphosyntactic phenomena, by leveraging a\nrecently proposed method for probing language models via Shapley Head Values\n(SHVs). Using the English language BLiMP dataset, we test our approach on two\nwidely used models, BERT and RoBERTa, and compare how linguistic constructions\nsuch as anaphor agreement and filler-gap dependencies are handled. Through\nquantitative pruning and qualitative clustering analysis, we demonstrate that\nattention heads responsible for processing related linguistic phenomena cluster\ntogether. Our results show that SHV-based attributions reveal distinct patterns\nacross both models, providing insights into how language models organize and\nprocess linguistic information. These findings support the hypothesis that\nlanguage models learn subnetworks corresponding to linguistic theory, with\npotential implications for cross-linguistic model analysis and interpretability\nin Natural Language Processing (NLP)."
  },
  {
    "arxiv_id": "2410.13343",
    "title": "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models",
    "url": "http://arxiv.org/abs/2410.13343v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks. However, LLMs may rely on dataset biases as\nshortcuts for prediction, which can significantly impair their robustness and\ngeneralization capabilities. This paper presents Shortcut Suite, a\ncomprehensive test suite designed to evaluate the impact of shortcuts on LLMs'\nperformance, incorporating six shortcut types, five evaluation metrics, and\nfour prompting strategies. Our extensive experiments yield several key\nfindings: 1) LLMs demonstrate varying reliance on shortcuts for downstream\ntasks, significantly impairing their performance. 2) Larger LLMs are more\nlikely to utilize shortcuts under zero-shot and few-shot in-context learning\nprompts. 3) Chain-of-thought prompting notably reduces shortcut reliance and\noutperforms other prompting strategies, while few-shot prompts generally\nunderperform compared to zero-shot prompts. 4) LLMs often exhibit\noverconfidence in their predictions, especially when dealing with datasets that\ncontain shortcuts. 5) LLMs generally have a lower explanation quality in\nshortcut-laden datasets, with errors falling into three types: distraction,\ndisguised comprehension, and logical fallacy. Our findings offer new insights\nfor evaluating robustness and generalization in LLMs and suggest potential\ndirections for mitigating the reliance on shortcuts. The code is available at\n\\url {https://github.com/yyhappier/ShortcutSuite.git}."
  },
  {
    "arxiv_id": "2410.13125",
    "title": "Transformers4NewsRec: A Transformer-based News Recommendation Framework",
    "url": "http://arxiv.org/abs/2410.13125v1",
    "abstract": "Pre-trained transformer models have shown great promise in various natural\nlanguage processing tasks, including personalized news recommendations. To\nharness the power of these models, we introduce Transformers4NewsRec, a new\nPython framework built on the \\textbf{Transformers} library. This framework is\ndesigned to unify and compare the performance of various news recommendation\nmodels, including deep neural networks and graph-based models.\nTransformers4NewsRec offers flexibility in terms of model selection, data\npreprocessing, and evaluation, allowing both quantitative and qualitative\nanalysis."
  },
  {
    "arxiv_id": "2410.14485",
    "title": "CaTs and DAGs: Integrating Directed Acyclic Graphs with Transformers and Fully-Connected Neural Networks for Causally Constrained Predictions",
    "url": "http://arxiv.org/abs/2410.14485v1",
    "abstract": "Artificial Neural Networks (ANNs), including fully-connected networks and\ntransformers, are highly flexible and powerful function approximators, widely\napplied in fields like computer vision and natural language processing.\nHowever, their inability to inherently respect causal structures can limit\ntheir robustness, making them vulnerable to covariate shift and difficult to\ninterpret/explain. This poses significant challenges for their reliability in\nreal-world applications. In this paper, we introduce Causal Fully-Connected\nNeural Networks (CFCNs) and Causal Transformers (CaTs), two general model\nfamilies designed to operate under predefined causal constraints, as specified\nby a Directed Acyclic Graph (DAG). These models retain the powerful function\napproximation abilities of traditional neural networks while adhering to the\nunderlying structural constraints, improving robustness, reliability, and\ninterpretability at inference time. This approach opens new avenues for\ndeploying neural networks in more demanding, real-world scenarios where\nrobustness and explainability is critical."
  },
  {
    "arxiv_id": "2410.15667",
    "title": "RAC: Efficient LLM Factuality Correction with Retrieval Augmentation",
    "url": "http://arxiv.org/abs/2410.15667v1",
    "abstract": "Large Language Models (LLMs) exhibit impressive results across a wide range\nof natural language processing (NLP) tasks, yet they can often produce\nfactually incorrect outputs. This paper introduces a simple but effective\nlow-latency post-correction method, \\textbf{Retrieval Augmented Correction\n(RAC)}, aimed at enhancing the factual performance of LLMs without requiring\nadditional fine-tuning. Our method is general and can be used with any\ninstruction-tuned LLM, and has greatly reduced latency compared to prior\napproaches. RAC decomposes the LLM's output into atomic facts and applies a\nfine-grained verification and correction process with retrieved content to\nverify and correct the LLM-generated output. Our extensive experiments show\nthat RAC yields up to 30\\% improvements over state-of-the-art baselines across\ntwo popular factuality evaluation datasets, validating its efficacy and\nrobustness in both with and without the integration of Retrieval-Augmented\nGeneration (RAG) across different LLMs.\\footnote{Our code is at\n\\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}"
  },
  {
    "arxiv_id": "2410.15656",
    "title": "LightFusionRec: Lightweight Transformers-Based Cross-Domain Recommendation Model",
    "url": "http://arxiv.org/abs/2410.15656v1",
    "abstract": "This paper presents LightFusionRec, a novel lightweight cross-domain\nrecommendation system that integrates DistilBERT for textual feature extraction\nand FastText for genre embedding. Important issues in recommendation systems,\nsuch as data sparsity, computational efficiency, and cold start issues, are\naddressed in methodology. LightFusionRec uses a small amount of information to\nproduce precise and contextually relevant recommendations for many media\nformats by fusing genre vector embedding with natural language processing\nalgorithms. Tests conducted on extensive movie and book datasets show notable\nenhancements in suggestion quality when compared to conventional methods.\nBecause of its lightweight design, the model can be used for a variety of\npurposes and allows for ondevice inference. LightFusionRec is a noteworthy\ndevelopment in cross-domain recommendation systems, providing accurate and\nscalable recommendations to improve user experience on digital content\nplatforms."
  },
  {
    "arxiv_id": "2410.15578",
    "title": "Generalized Probabilistic Attention Mechanism in Transformers",
    "url": "http://arxiv.org/abs/2410.15578v1",
    "abstract": "The Transformer architecture has become widely adopted due to its\ndemonstrated success, attributed to the attention mechanism at its core.\nDespite these successes, the attention mechanism of Transformers is associated\nwith two well-known issues: rank-collapse and gradient vanishing. In this\npaper, we present a theoretical analysis that it is inherently difficult to\naddress both issues simultaneously in the conventional attention mechanism. To\nhandle these issues, we introduce a novel class of attention mechanism,\nreferred to as generalized probabilistic attention mechanism (GPAM), and its\ndual-attention implementation within the Transformer architecture. Unlike\nconventional attention mechanisms, GPAM allows for negative attention scores\nwhile preserving a fixed total sum. We provide theoretical evidence that the\nproposed dual-attention GPAM (daGPAM) effectively mitigates both the\nrank-collapse and gradient vanishing issues which are difficult to resolve\nsimultaneously with the conventional attention mechanisms. Furthermore, we\nempirically validate this theoretical evidence, demonstrating the superiority\nof daGPAM compared to other alternative attention mechanisms that were proposed\nto address the same issues. Additionally, we demonstrate the practical benefits\nof GPAM in natural language processing tasks, such as language modeling and\nneural machine translation."
  },
  {
    "arxiv_id": "2410.16801",
    "title": "Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models",
    "url": "http://arxiv.org/abs/2410.16801v1",
    "abstract": "Large language models (LLMs) exhibit remarkable capabilities in natural\nlanguage processing but face catastrophic forgetting when learning new tasks,\nwhere adaptation to a new domain leads to a substantial decline in performance\non previous tasks. In this paper, we propose Controlled LoRA (CLoRA), a\nsub-space regularization method on LoRA structure. Aiming to reduce the scale\nof output change while introduce minimal constraint on model capacity, CLoRA\nimposes constraint on the direction of updating matrix's null space.\nExperimental results on one-stage LLM finetuning tasks and continual learning\nsettings highlight the superority of CLoRA as a effective parameter efficient\nfinetuning method with catastrophic forgetting mitigating.Further investigation\nfor model parameters indicates that CLoRA effectively balances the trade-off\nbetween model capacity and degree of forgetting."
  },
  {
    "arxiv_id": "2410.16543",
    "title": "Large language models enabled multiagent ensemble method for efficient EHR data labeling",
    "url": "http://arxiv.org/abs/2410.16543v1",
    "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to\naddress a key challenge in ML - data labeling, particularly in large-scale EHR\ndatasets. Manual labeling of such datasets requires domain expertise and is\nlabor-intensive, time-consuming, expensive, and error-prone. To overcome this\nbottleneck, we developed an ensemble LLMs method and demonstrated its\neffectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG\ndataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from\nthe clinical notes of EHR. Trading off benefits and cost, we selected a pool of\ndiverse open source LLMs with satisfactory performance. We treat each LLM's\nprediction as a vote and apply a mechanism of majority voting with minimal\nwinning threshold for ensemble. We implemented an ensemble LLMs application for\nEHR data labeling tasks. By using the ensemble LLMs and natural language\nprocessing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an\nestimated accuracy of 98.2%. We applied the ensemble LLMs method to identify\nSDOH from social history sections of 1,405 EHR clinical notes, also achieving\ncompetitive performance. Our experiments show that the ensemble LLMs can\noutperform individual LLM even the best commercial one, and the method reduces\nhallucination errors. From the research, we found that (1) the ensemble LLMs\nmethod significantly reduces the time and effort required for labeling\nlarge-scale EHR data, automating the process with high accuracy and quality;\n(2) the method generalizes well to other text data labeling tasks, as shown by\nits application to SDOH identification; (3) the ensemble of a group of diverse\nLLMs can outperform or match the performance of the best individual LLM; and\n(4) the ensemble method substantially reduces hallucination errors. This\napproach provides a scalable and efficient solution to data-labeling\nchallenges."
  },
  {
    "arxiv_id": "2410.16349",
    "title": "Large Language Models in Computer Science Education: A Systematic Literature Review",
    "url": "http://arxiv.org/abs/2410.16349v1",
    "abstract": "Large language models (LLMs) are becoming increasingly better at a wide range\nof Natural Language Processing tasks (NLP), such as text generation and\nunderstanding. Recently, these models have extended their capabilities to\ncoding tasks, bridging the gap between natural languages (NL) and programming\nlanguages (PL). Foundational models such as the Generative Pre-trained\nTransformer (GPT) and LLaMA series have set strong baseline performances in\nvarious NL and PL tasks. Additionally, several models have been fine-tuned\nspecifically for code generation, showing significant improvements in\ncode-related applications. Both foundational and fine-tuned models are\nincreasingly used in education, helping students write, debug, and understand\ncode. We present a comprehensive systematic literature review to examine the\nimpact of LLMs in computer science and computer engineering education. We\nanalyze their effectiveness in enhancing the learning experience, supporting\npersonalized education, and aiding educators in curriculum development. We\naddress five research questions to uncover insights into how LLMs contribute to\neducational outcomes, identify challenges, and suggest directions for future\nresearch."
  },
  {
    "arxiv_id": "2410.18040",
    "title": "Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases",
    "url": "http://arxiv.org/abs/2410.18040v1",
    "abstract": "Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts."
  },
  {
    "arxiv_id": "2410.17661",
    "title": "PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context",
    "url": "http://arxiv.org/abs/2410.17661v1",
    "abstract": "Following their success in natural language processing (NLP), there has been\na shift towards transformer models in computer vision. While transformers\nperform well and offer promising multi-tasking performance, due to their high\ncompute requirements, many resource-constrained applications still rely on\nconvolutional or hybrid models that combine the benefits of convolution and\nattention layers and achieve the best results in the sub 100M parameter range.\nSimultaneously, task adaptation techniques that allow for the use of one shared\ntransformer backbone for multiple downstream tasks, resulting in great storage\nsavings at negligible cost in performance, have not yet been adopted for hybrid\ntransformers. In this work, we investigate how to achieve the best\ntask-adaptation performance and introduce PETAH: Parameter Efficient Task\nAdaptation for Hybrid Transformers. We further combine PETAH adaptation with\npruning to achieve highly performant and storage friendly models for\nmulti-tasking. In our extensive evaluation on classification and other vision\ntasks, we demonstrate that our PETAH-adapted hybrid models outperform\nestablished task-adaptation techniques for ViTs while requiring fewer\nparameters and being more efficient on mobile hardware."
  },
  {
    "arxiv_id": "2410.17602",
    "title": "Integrating Large Language Models for UAV Control in Simulated Environments: A Modular Interaction Approach",
    "url": "http://arxiv.org/abs/2410.17602v1",
    "abstract": "The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial\nVehicles) technology represents a promising field of research with the\npotential to enhance UAV capabilities significantly. This study explores the\napplication of LLMs in UAV control, focusing on the opportunities for\nintegrating advanced natural language processing into autonomous aerial\nsystems. By enabling UAVs to interpret and respond to natural language\ncommands, LLMs simplify the UAV control and usage, making them accessible to a\nbroader user base and facilitating more intuitive human-machine interactions.\nThe paper discusses several key areas where LLMs can impact UAV technology,\nincluding autonomous decision-making, dynamic mission planning, enhanced\nsituational awareness, and improved safety protocols. Through a comprehensive\nreview of current developments and potential future directions, this study aims\nto highlight how LLMs can transform UAV operations, making them more adaptable,\nresponsive, and efficient in complex environments. A template development\nframework for integrating LLMs in UAV control is also described. Proof of\nConcept results that integrate existing LLM models and popular robotic\nsimulation platforms are demonstrated. The findings suggest that while there\nare substantial technical and ethical challenges to address, integrating LLMs\ninto UAV control holds promising implications for advancing autonomous aerial\nsystems."
  },
  {
    "arxiv_id": "2410.17389",
    "title": "Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models",
    "url": "http://arxiv.org/abs/2410.17389v1",
    "abstract": "The correct specification of reward models is a well-known challenge in\nreinforcement learning. Hand-crafted reward functions often lead to inefficient\nor suboptimal policies and may not be aligned with user values. Reinforcement\nlearning from human feedback is a successful technique that can mitigate such\nissues, however, the collection of human feedback can be laborious. Recent\nworks have solicited feedback from pre-trained large language models rather\nthan humans to reduce or eliminate human effort, however, these approaches\nyield poor performance in the presence of hallucination and other errors. This\npaper studies the advantages and limitations of reinforcement learning from\nlarge language model feedback and proposes a simple yet effective method for\nsoliciting and applying feedback as a potential-based shaping function. We\ntheoretically show that inconsistent rankings, which approximate ranking\nerrors, lead to uninformative rewards with our approach. Our method empirically\nimproves convergence speed and policy returns over commonly used baselines even\nwith significant ranking errors, and eliminates the need for complex\npost-processing of reward functions."
  },
  {
    "arxiv_id": "2410.18572",
    "title": "Taipan: Efficient and Expressive State Space Language Models with Selective Attention",
    "url": "http://arxiv.org/abs/2410.18572v1",
    "abstract": "Efficient long-context language modeling remains a significant challenge in\nNatural Language Processing (NLP). While Transformers dominate language tasks,\nthey struggle with long sequences due to quadratic computational complexity in\ntraining and linearly scaling memory costs during inference. Recent State Space\nModels (SSMs) such as Mamba offer alternatives with constant memory usage, but\nthey underperform in tasks requiring extensive in-context retrieval. We\nintroduce Taipan, a novel hybrid architecture that combines Mamba-2 with\nSelective Attention Layers (SALs). These SALs identify tokens requiring\nlong-range interactions, remove less important features, and then augment their\nrepresentations using the attention module. This approach balances Mamba's\nefficiency with Transformer-like performance in memory-intensive tasks. By\nconstraining the attention budget, Taipan extends accurate predictions to\ncontext lengths of up to 1 million tokens while preserving computational\nefficiency. Our experiments demonstrate Taipan's superior performance across\nvarious scales and tasks, offering a promising solution for efficient\nlong-context language modeling."
  },
  {
    "arxiv_id": "2410.18287",
    "title": "LEGO: Language Model Building Blocks",
    "url": "http://arxiv.org/abs/2410.18287v1",
    "abstract": "Large language models (LLMs) are essential in natural language processing\n(NLP) but are costly in data collection, pre-training, fine-tuning, and\ninference. Task-specific small language models (SLMs) offer a cheaper\nalternative but lack robustness and generalization. This paper proposes LEGO, a\nnovel technique to extract SLMs from an LLM and recombine them. Using\nstate-of-the-art LLM pruning strategies, we can create task- and user-specific\nSLM building blocks that are efficient for fine-tuning and inference while also\npreserving user data privacy. LEGO utilizes Federated Learning and a novel\naggregation scheme for the LLM reconstruction, maintaining robustness without\nhigh costs and preserving user data privacy. We experimentally demonstrate the\nversatility of LEGO, showing its ability to enable model heterogeneity and\nmitigate the effects of data heterogeneity while maintaining LLM robustness."
  },
  {
    "arxiv_id": "2410.19694",
    "title": "Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs",
    "url": "http://arxiv.org/abs/2410.19694v1",
    "abstract": "Fine-tuning Large Language Models (LLMs) has become a crucial technique for\nadapting pre-trained models to downstream tasks. However, the enormous size of\nLLMs poses significant challenges in terms of computational complexity and\nresource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising\nsolution. However, there exists a gap between the practical performance of\nlow-rank adaptations and its theoretical optimum. In this work, we propose\neXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this\ngap by leveraging the power of ensemble learning. Inspired by gradient\nboosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations\nto refine model predictions. It achieves better performance than the standard\nLoRA, while enjoying the computational efficiency of rank-1 adaptations. We\nprovide theoretical analysis to show the convergence and optimality of our\napproach, and conduct extensive experiments on a range of natural language\nprocessing tasks. The results demonstrate that XGBLoRA consistently outperforms\nstandard LoRA and achieves performance comparable to full fine-tuning with\nsignificantly fewer trainable parameters. This work advances\nparameter-efficient fine-tuning for LLMs, and offers a promising solution for\nadapting LLMs to downstream tasks while optimizing performance and efficiency."
  },
  {
    "arxiv_id": "2410.19637",
    "title": "A distributional simplicity bias in the learning dynamics of transformers",
    "url": "http://arxiv.org/abs/2410.19637v1",
    "abstract": "The remarkable capability of over-parameterised neural networks to generalise\neffectively has been explained by invoking a ``simplicity bias'': neural\nnetworks prevent overfitting by initially learning simple classifiers before\nprogressing to more complex, non-linear functions. While simplicity biases have\nbeen described theoretically and experimentally in feed-forward networks for\nsupervised learning, the extent to which they also explain the remarkable\nsuccess of transformers trained with self-supervised techniques remains\nunclear. In our study, we demonstrate that transformers, trained on natural\nlanguage data, also display a simplicity bias. Specifically, they sequentially\nlearn many-body interactions among input tokens, reaching a saturation point in\nthe prediction error for low-degree interactions while continuing to learn\nhigh-degree interactions. To conduct this analysis, we develop a procedure to\ngenerate \\textit{clones} of a given natural language data set, which rigorously\ncapture the interactions between tokens up to a specified order. This approach\nopens up the possibilities of studying how interactions of different orders in\nthe data affect learning, in natural language processing and beyond."
  },
  {
    "arxiv_id": "2410.19385",
    "title": "Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models",
    "url": "http://arxiv.org/abs/2410.19385v1",
    "abstract": "Large Language Models (LLMs) are powerful computational models trained on\nextensive corpora of human-readable text, enabling them to perform\ngeneral-purpose language understanding and generation. LLMs have garnered\nsignificant attention in both industry and academia due to their exceptional\nperformance across various natural language processing (NLP) tasks. Despite\nthese successes, LLMs often produce inaccuracies, commonly referred to as\nhallucinations. Prompt engineering, the process of designing and formulating\ninstructions for LLMs to perform specific tasks, has emerged as a key approach\nto mitigating hallucinations. This paper provides a comprehensive empirical\nevaluation of different prompting strategies and frameworks aimed at reducing\nhallucinations in LLMs. Various prompting techniques are applied to a broad set\nof benchmark datasets to assess the accuracy and hallucination rate of each\nmethod. Additionally, the paper investigates the influence of tool-calling\nagents (LLMs augmented with external tools to enhance their capabilities beyond\nlanguage generation) on hallucination rates in the same benchmarks. The\nfindings demonstrate that the optimal prompting technique depends on the type\nof problem, and that simpler techniques often outperform more complex methods\nin reducing hallucinations. Furthermore, it is shown that LLM agents can\nexhibit significantly higher hallucination rates due to the added complexity of\nexternal tool usage."
  },
  {
    "arxiv_id": "2410.19222",
    "title": "Peptide-GPT: Generative Design of Peptides using Generative Pre-trained Transformers and Bio-informatic Supervision",
    "url": "http://arxiv.org/abs/2410.19222v1",
    "abstract": "In recent years, natural language processing (NLP) models have demonstrated\nremarkable capabilities in various domains beyond traditional text generation.\nIn this work, we introduce PeptideGPT, a protein language model tailored to\ngenerate protein sequences with distinct properties: hemolytic activity,\nsolubility, and non-fouling characteristics. To facilitate a rigorous\nevaluation of these generated sequences, we established a comprehensive\nevaluation pipeline consisting of ideas from bioinformatics to retain valid\nproteins with ordered structures. First, we rank the generated sequences based\non their perplexity scores, then we filter out those lying outside the\npermissible convex hull of proteins. Finally, we predict the structure using\nESMFold and select the proteins with pLDDT values greater than 70 to ensure\nordered structure. The properties of generated sequences are evaluated using\ntask-specific classifiers - PeptideBERT and HAPPENN. We achieved an accuracy of\n76.26% in hemolytic, 72.46% in non-hemolytic, 78.84% in non-fouling, and 68.06%\nin solubility protein generation. Our experimental results demonstrate the\neffectiveness of PeptideGPT in de novo protein design and underscore the\npotential of leveraging NLP-based approaches for paving the way for future\ninnovations and breakthroughs in synthetic biology and bioinformatics. Codes,\nmodels, and data used in this study are freely available at:\nhttps://github.com/aayush-shah14/PeptideGPT."
  },
  {
    "arxiv_id": "2410.19130",
    "title": "Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models",
    "url": "http://arxiv.org/abs/2410.19130v1",
    "abstract": "With the rapid development of natural language processing technology, large\nlanguage models have demonstrated exceptional performance in various\napplication scenarios. However, training these models requires significant\ncomputational resources and data processing capabilities. Cross-cloud federated\ntraining offers a new approach to addressing the resource bottlenecks of a\nsingle cloud platform, allowing the computational resources of multiple clouds\nto collaboratively complete the training tasks of large models. This study\nanalyzes the key technologies of cross-cloud federated training, including data\npartitioning and distribution, communication optimization, model aggregation\nalgorithms, and the compatibility of heterogeneous cloud platforms.\nAdditionally, the study examines data security and privacy protection\nstrategies in cross-cloud training, particularly the application of data\nencryption and differential privacy techniques. Through experimental\nvalidation, the proposed technical framework demonstrates enhanced training\nefficiency, ensured data security, and reduced training costs, highlighting the\nbroad application prospects of cross-cloud federated training."
  },
  {
    "arxiv_id": "2410.19117",
    "title": "LLM Tree Search",
    "url": "http://arxiv.org/abs/2410.19117v1",
    "abstract": "This project aims to investigate a novel sequence generation method inspired\nby the AlphaGo paradigm, adapting it for use with large language models (LLMs).\nThe proposed approach involves creating search trees of different possible\ncompletions and evaluating these completions based on model confidence. By\nconsidering various paths in the search tree and scoring them according to the\nmodel's confidence in each completion, we can generate diverse and high-quality\nsequences. This research explores the implementation of this paradigm by using\nconfidence as a proxy for response quality akin to beam search\n\\citep{vijayakumar2016diverse}. The primary goal of this paper is to outline\nthe paradigm and demonstrate its potential, rather than focusing on achieving\nperfect results. The paper will outline the reasons why we believe this\nparadigm has the potential to improve LLMs in the following manners: 1)\nincrease output quality, 2) decrease errors, 3) eliminate or reduce the\ncompound error problems, 4) generate diverse and creative completions, 5) allow\nfor iterative problem-solving, and 6) self-training. We expect this approach to\nyield a set of diverse and coherent sequences, offering insights into balancing\nexploration and exploitation in sequence generation. Potential applications\ninclude creative text generation tasks, such as storytelling and content\ncreation, as well as other natural language processing domains, like machine\ntranslation and automated summarization. The goal is that the model will be far\nmore effective as it will be able to consider many possible variations allowing\nit to find the ideal completion. This research aims to contribute to the\nunderstanding of effective search strategies in sequence generation and their\nimpact on generating high-quality, varied textual outputs."
  },
  {
    "arxiv_id": "2410.19103",
    "title": "TesseraQ: Ultra Low-Bit LLM Post-Training Quantization with Block Reconstruction",
    "url": "http://arxiv.org/abs/2410.19103v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing,\nalbeit at the cost of immense memory and computation requirements.\nPost-training quantization (PTQ) is becoming the de facto method to reduce the\nmemory footprint and improve the inference throughput of LLMs. In this work, we\naim to push the upper limit of LLM PTQ by optimizing the weight rounding\nparameters with the block reconstruction technique, a predominant method in\nprevious vision models. We propose TesseraQ, a new state-of-the-art PTQ\ntechnique, to quantize the weights of LLMs to ultra-low bits. To effectively\noptimize the rounding in LLMs and stabilize the reconstruction process, we\nintroduce progressive adaptive rounding. This approach iteratively transits the\nsoft rounding variables to hard variables during the reconstruction process.\nAdditionally, we optimize the dequantization scale parameters to fully leverage\nthe block reconstruction technique. We demonstrate that TesseraQ can be\nseamlessly integrated with existing scaling or clipping-based PTQ algorithms\nsuch as AWQ and OmniQuant, significantly enhancing their performance and\nestablishing a new state-of-the-art. For instance, when compared to AWQ,\nTesseraQ improves the wikitext2 perplexity from 14.65 to 6.82 and average\ndownstream accuracy from 50.52 to 59.27 with 2-bit weight-only quantization of\nLLaMA-2-7B. Across a range of quantization schemes, including W2A16, W3A16,\nW3A3, and W4A4, TesseraQ consistently exhibits superior performance."
  },
  {
    "arxiv_id": "2410.20336",
    "title": "Get Large Language Models Ready to Speak: A Late-fusion Approach for Speech Generation",
    "url": "http://arxiv.org/abs/2410.20336v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) with impressive performance across various text-based tasks. However, the\nextension of text-dominant LLMs to with speech generation tasks remains\nunder-explored. In this work, we introduce a text-to-speech (TTS) system\npowered by a fine-tuned Llama model, named TTS-Llama, that achieves\nstate-of-the-art speech synthesis performance. Building on TTS-Llama, we\nfurther propose MoLE-Llama, a text-and-speech multimodal LLM developed through\npurely late-fusion parameter-efficient fine-tuning (PEFT) and a\nmixture-of-expert architecture. Extensive empirical results demonstrate\nMoLE-Llama's competitive performance on both text-only question-answering (QA)\nand TTS tasks, mitigating catastrophic forgetting issue in either modality.\nFinally, we further explore MoLE-Llama in text-in-speech-out QA tasks,\ndemonstrating its great potential as a multimodal dialog system capable of\nspeech generation."
  },
  {
    "arxiv_id": "2410.20024",
    "title": "Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations in Large Language Models for Data Analytics",
    "url": "http://arxiv.org/abs/2410.20024v1",
    "abstract": "Large Language Models (LLMs) have become increasingly important in natural\nlanguage processing, enabling advanced data analytics through natural language\nqueries. However, these models often generate \"hallucinations\"-inaccurate or\nfabricated information-that can undermine their reliability in critical\ndata-driven decision-making. Addressing the challenge of hallucinations is\nessential to improve the accuracy and trustworthiness of LLMs in processing\nnatural language queries. This research focuses on mitigating hallucinations in\nLLMs, specifically within the context of data analytics. We introduce and\nevaluate four targeted strategies: Structured Output Generation, Strict Rules\nEnforcement, System Prompt Enhancements, and Semantic Layer Integration. Our\nfindings show that these methods are more effective than traditional\nfine-tuning approaches in reducing hallucinations, offering a more reliable\nframework for deploying LLMs in natural language queries for data analytics.\nThis research demonstrates the potential of these strategies to enhance the\naccuracy of LLM-driven data queries, ensuring more dependable results in\ndata-driven environments."
  },
  {
    "arxiv_id": "2410.22293",
    "title": "Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats",
    "url": "http://arxiv.org/abs/2410.22293v1",
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved their capabilities in natural language processing and code synthesis,\nenabling more complex applications across different fields. This paper explores\nthe application of LLMs in the context of code mutation, a process where the\nstructure of program code is altered without changing its functionality.\nTraditionally, code mutation has been employed to increase software robustness\nin mission-critical applications. Additionally, mutation engines have been\nexploited by malware developers to evade the signature-based detection methods\nemployed by malware detection systems. Existing code mutation engines, often\nused by such threat actors, typically result in only limited variations in the\nmalware, which can still be identified through static code analysis. However,\nthe agility demonstrated by an LLM-based code synthesizer could significantly\nchange this threat landscape by allowing for more complex code mutations that\nare not easily detected using static analysis. One can increase variations of\ncodes synthesized by a pre-trained LLM through fine-tuning and retraining. This\nprocess is what we refer to as code mutation training. In this paper, we\npropose a novel definition of code mutation training tailored for pre-trained\nLLM-based code synthesizers and demonstrate this training on a lightweight\npre-trained model. Our approach involves restructuring (i.e., mutating) code at\nthe subroutine level, which allows for more manageable mutations while\nmaintaining the semantic integrity verified through unit testing. Our\nexperimental results illustrate the effectiveness of our approach in improving\ncode mutation capabilities of LLM-based program synthesizers in producing\nvaried and functionally correct code solutions, showcasing their potential to\ntransform the landscape of code mutation and the threats associated with it."
  },
  {
    "arxiv_id": "2410.21723",
    "title": "Fine-tuning Large Language Models for DGA and DNS Exfiltration Detection",
    "url": "http://arxiv.org/abs/2410.21723v1",
    "abstract": "Domain Generation Algorithms (DGAs) are malicious techniques used by malware\nto dynamically generate seemingly random domain names for communication with\nCommand & Control (C&C) servers. Due to the fast and simple generation of DGA\ndomains, detection methods must be highly efficient and precise to be\neffective. Large Language Models (LLMs) have demonstrated their proficiency in\nreal-time detection tasks, making them ideal candidates for detecting DGAs. Our\nwork validates the effectiveness of fine-tuned LLMs for detecting DGAs and DNS\nexfiltration attacks. We developed LLM models and conducted comprehensive\nevaluation using a diverse dataset comprising 59 distinct real-world DGA\nmalware families and normal domain data. Our LLM model significantly\noutperformed traditional natural language processing techniques, especially in\ndetecting unknown DGAs. We also evaluated its performance on DNS exfiltration\ndatasets, demonstrating its effectiveness in enhancing cybersecurity measures.\nTo the best of our knowledge, this is the first work that empirically applies\nLLMs for DGA and DNS exfiltration detection."
  },
  {
    "arxiv_id": "2410.21548",
    "title": "MultiTok: Variable-Length Tokenization for Efficient LLMs Adapted from LZW Compression",
    "url": "http://arxiv.org/abs/2410.21548v1",
    "abstract": "Large language models have drastically changed the prospects of AI by\nintroducing technologies for more complex natural language processing. However,\ncurrent methodologies to train such LLMs require extensive resources including\nbut not limited to large amounts of data, expensive machinery, and lengthy\ntraining. To solve this problem, this paper proposes a new tokenization method\ninspired by universal Lempel-Ziv-Welch data compression that compresses\nrepetitive phrases into multi-word tokens. With MultiTok as a new tokenizing\ntool, we show that language models are able to be trained notably more\nefficiently while offering a similar accuracy on more succinct and compressed\ntraining data. In fact, our results demonstrate that MultiTok achieves a\ncomparable performance to the BERT and GPT-2 standards as both a stand-alone\ntokenizer and an add-on to existing tokenizers while also providing close to\n2.5x faster training with more than 30% less training data."
  },
  {
    "arxiv_id": "2410.23166",
    "title": "SciPIP: An LLM-based Scientific Paper Idea Proposer",
    "url": "http://arxiv.org/abs/2410.23166v1",
    "abstract": "The rapid advancement of large language models (LLMs) has opened new\npossibilities for automating the proposal of innovative scientific ideas. This\nprocess involves two key phases: literature retrieval and idea generation.\nHowever, existing approaches often fall short due to their reliance on\nkeyword-based search tools during the retrieval phase, which neglects crucial\nsemantic information and frequently results in incomplete retrieval outcomes.\nSimilarly, in the idea generation phase, current methodologies tend to depend\nsolely on the internal knowledge of LLMs or metadata from retrieved papers,\nthereby overlooking significant valuable insights contained within the full\ntexts. To address these limitations, we introduce SciPIP, an innovative\nframework designed to enhance the LLM-based proposal of scientific ideas\nthrough improvements in both literature retrieval and idea generation. Our\napproach begins with the construction of a comprehensive literature database\nthat supports advanced retrieval based not only on keywords but also on\nsemantics and citation relationships. This is complemented by the introduction\nof a multi-granularity retrieval algorithm aimed at ensuring more thorough and\nexhaustive retrieval results. For the idea generation phase, we propose a\ndual-path framework that effectively integrates both the content of retrieved\npapers and the extensive internal knowledge of LLMs. This integration\nsignificantly boosts the novelty, feasibility, and practical value of proposed\nideas. Our experiments, conducted across various domains such as natural\nlanguage processing and computer vision, demonstrate SciPIP's capability to\ngenerate a multitude of innovative and useful ideas. These findings underscore\nSciPIP's potential as a valuable tool for researchers seeking to advance their\nfields with groundbreaking concepts."
  },
  {
    "arxiv_id": "2410.23083",
    "title": "Developing a Self-Explanatory Transformer",
    "url": "http://arxiv.org/abs/2410.23083v1",
    "abstract": "While IoT devices provide significant benefits, their rapid growth results in\nlarger data volumes, increased complexity, and higher security risks. To manage\nthese issues, techniques like encryption, compression, and mapping are used to\nprocess data efficiently and securely. General-purpose and AI platforms handle\nthese tasks well, but mapping in natural language processing is often slowed by\ntraining times. This work explores a self-explanatory, training-free mapping\ntransformer based on non-deterministic finite automata, designed for\nField-Programmable Gate Arrays (FPGAs). Besides highlighting the advantages of\nthis proposed approach in providing real-time, cost-effective processing and\ndataset-loading, we also address the challenges and considerations for\nenhancing the design in future iterations."
  },
  {
    "arxiv_id": "2410.23079",
    "title": "BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference",
    "url": "http://arxiv.org/abs/2410.23079v1",
    "abstract": "Large language models (LLMs) are essential in natural language processing but\noften struggle with inference speed and computational efficiency, limiting\nreal-time deployment. The key-value (KV) cache mechanism reduces computational\noverhead in transformer models, but challenges in maintaining contextual\nunderstanding remain. In this paper, we propose BUZZ, a novel KV caching\nalgorithm that leverages structured contextual information to minimize cache\nmemory usage while enhancing inference speed. BUZZ employs a beehive-structured\nsparse cache, incorporating a sliding window to capture recent information and\ndynamically segmenting historical tokens into chunks to prioritize important\ntokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:\nCNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ\n(1) reduces cache memory usage by $\\textbf{2.5}\\times$ in LLM inference while\nmaintaining over 99% accuracy in long-text summarization, and (2) surpasses\nstate-of-the-art performance in multi-document question answering by\n$\\textbf{7.69%}$ under the same memory limit, where full cache methods\nencounter out-of-memory issues. Additionally, BUZZ achieves significant\ninference speedup with a $\\log{n}$ time complexity. The code is available at\nhttps://github.com/JunqiZhao888/buzz-llm."
  },
  {
    "arxiv_id": "2410.22660",
    "title": "Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models",
    "url": "http://arxiv.org/abs/2410.22660v1",
    "abstract": "Code-switching, the phenomenon of alternating between two or more languages\nin a single conversation, presents unique challenges for Natural Language\nProcessing (NLP). Most existing research focuses on either syntactic\nconstraints or neural generation, with few efforts to integrate linguistic\ntheory with large language models (LLMs) for generating natural code-switched\ntext. In this paper, we introduce EZSwitch, a novel framework that combines\nEquivalence Constraint Theory (ECT) with LLMs to produce linguistically valid\nand fluent code-switched text. We evaluate our method using both human\njudgments and automatic metrics, demonstrating a significant improvement in the\nquality of generated code-switching sentences compared to baseline LLMs. To\naddress the lack of suitable evaluation metrics, we conduct a comprehensive\ncorrelation study of various automatic metrics against human scores, revealing\nthat current metrics often fail to capture the nuanced fluency of code-switched\ntext. Additionally, we create CSPref, a human preference dataset based on human\nratings and analyze model performance across ``hard`` and ``easy`` examples.\nOur findings indicate that incorporating linguistic constraints into LLMs leads\nto more robust and human-aligned generation, paving the way for scalable\ncode-switching text generation across diverse language pairs."
  },
  {
    "arxiv_id": "2410.23728",
    "title": "GigaCheck: Detecting LLM-generated Content",
    "url": "http://arxiv.org/abs/2410.23728v1",
    "abstract": "With the increasing quality and spread of LLM-based assistants, the amount of\nLLM-generated content is growing rapidly. In many cases and tasks, such texts\nare already indistinguishable from those written by humans, and the quality of\ngeneration tends to only increase. At the same time, detection methods are\ndeveloping more slowly, making it challenging to prevent misuse of generative\nAI technologies.\n  In this work, we investigate the task of generated text detection by\nproposing the GigaCheck. Our research explores two approaches: (i)\ndistinguishing human-written texts from LLM-generated ones, and (ii) detecting\nLLM-generated intervals in Human-Machine collaborative texts. For the first\ntask, our approach utilizes a general-purpose LLM, leveraging its extensive\nlanguage abilities to fine-tune efficiently for the downstream task of\nLLM-generated text detection, achieving high performance even with limited\ndata. For the second task, we propose a novel approach that combines computer\nvision and natural language processing techniques. Specifically, we use a\nfine-tuned general-purpose LLM in conjunction with a DETR-like detection model,\nadapted from computer vision, to localize AI-generated intervals within text.\n  We evaluate the GigaCheck on five classification datasets with English texts\nand three datasets designed for Human-Machine collaborative text analysis. Our\nresults demonstrate that GigaCheck outperforms previous methods, even in\nout-of-distribution settings, establishing a strong baseline across all\ndatasets."
  },
  {
    "arxiv_id": "2410.23526",
    "title": "LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models",
    "url": "http://arxiv.org/abs/2410.23526v1",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language processing tasks, yet they often struggle with maintaining\nfactual accuracy, particularly in knowledge-intensive domains like healthcare.\nThis study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,\na novel approach designed to enhance the factual reliability of LLMs, with a\nfocus on medical question answering (QA). LEAF utilizes a dual strategy to\nenhance the factual accuracy of responses from models such as Llama 3 70B\nInstruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,\nimproves Retrieval-Augmented Generation (RAG) by incorporating fact-checking\nresults to guide the retrieval process without updating model parameters. The\nsecond strategy, Learning from Fact-Checks via Self-Training, involves\nsupervised fine-tuning (SFT) on fact-checked responses or applying Simple\nPreference Optimization (SimPO) with fact-checking as a ranking mechanism, both\nupdating LLM parameters from supervision. These findings suggest that\nintegrating fact-checked responses whether through RAG enhancement or\nself-training enhances the reliability and factual correctness of LLM outputs,\noffering a promising solution for applications where information accuracy is\ncrucial."
  },
  {
    "arxiv_id": "2410.23365",
    "title": "Automated Personnel Selection for Software Engineers Using LLM-Based Profile Evaluation",
    "url": "http://arxiv.org/abs/2410.23365v1",
    "abstract": "Organizational success in todays competitive employment market depends on\nchoosing the right staff. This work evaluates software engineer profiles using\nan automated staff selection method based on advanced natural language\nprocessing (NLP) techniques. A fresh dataset was generated by collecting\nLinkedIn profiles with important attributes like education, experience, skills,\nand self-introduction. Expert feedback helped transformer models including\nRoBERTa, DistilBERT, and a customized BERT variation, LastBERT, to be adjusted.\nThe models were meant to forecast if a candidate's profile fit the selection\ncriteria, therefore allowing automated ranking and assessment. With 85%\naccuracy and an F1 score of 0.85, RoBERTa performed the best; DistilBERT\nprovided comparable results at less computing expense. Though light, LastBERT\nproved to be less effective, with 75% accuracy. The reusable models provide a\nscalable answer for further categorization challenges. This work presents a\nfresh dataset and technique as well as shows how transformer models could\nimprove recruiting procedures. Expanding the dataset, enhancing model\ninterpretability, and implementing the system in actual environments will be\npart of future activities."
  },
  {
    "arxiv_id": "2411.02382",
    "title": "Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models",
    "url": "http://arxiv.org/abs/2411.02382v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious scientific domains, from natural language processing to complex\nproblem-solving tasks. Their ability to understand and generate human-like text\nhas opened up new possibilities for advancing scientific research, enabling\ntasks such as data analysis, literature review, and even experimental design.\nOne of the most promising applications of LLMs in this context is hypothesis\ngeneration, where they can identify novel research directions by analyzing\nexisting knowledge. However, despite their potential, LLMs are prone to\ngenerating ``hallucinations'', outputs that are plausible-sounding but\nfactually incorrect. Such a problem presents significant challenges in\nscientific fields that demand rigorous accuracy and verifiability, potentially\nleading to erroneous or misleading conclusions. To overcome these challenges,\nwe propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that\nenhances LLM hypothesis generation by integrating external, structured\nknowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured\nreasoning process, organizing their output as a chain of ideas (CoI), and\nincludes a KG-supported module for the detection of hallucinations. With\nexperiments on our newly constructed hypothesis generation dataset, we\ndemonstrate that KG-CoI not only improves the accuracy of LLM-generated\nhypotheses but also reduces the hallucination in their reasoning chains,\nhighlighting its effectiveness in advancing real-world scientific research."
  },
  {
    "arxiv_id": "2411.02036",
    "title": "Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models",
    "url": "http://arxiv.org/abs/2411.02036v1",
    "abstract": "Cognitive and neurological impairments are very common, but only a small\nproportion of affected individuals are diagnosed and treated, partly because of\nthe high costs associated with frequent screening. Detecting pre-illness stages\nand analyzing the progression of neurological disorders through effective and\nefficient intelligent systems can be beneficial for timely diagnosis and early\nintervention. We propose using Large Language Models to extract features from\nfree dialogues to detect cognitive decline. These features comprise high-level\nreasoning content-independent features (such as comprehension, decreased\nawareness, increased distraction, and memory problems). Our solution comprises\n(i) preprocessing, (ii) feature engineering via Natural Language Processing\ntechniques and prompt engineering, (iii) feature analysis and selection to\noptimize performance, and (iv) classification, supported by automatic\nexplainability. We also explore how to improve Chatgpt's direct cognitive\nimpairment prediction capabilities using the best features in our models.\nEvaluation metrics obtained endorse the effectiveness of a mixed approach\ncombining feature extraction with Chatgpt and a specialized Machine Learning\nmodel to detect cognitive decline within free-form conversational dialogues\nwith older adults. Ultimately, our work may facilitate the development of an\ninexpensive, non-invasive, and rapid means of detecting and explaining\ncognitive decline."
  },
  {
    "arxiv_id": "2411.01706",
    "title": "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups",
    "url": "http://arxiv.org/abs/2411.01706v1",
    "abstract": "Complex Word Identification (CWI) is an essential step in the lexical\nsimplification task and has recently become a task on its own. Some variations\nof this binary classification task have emerged, such as lexical complexity\nprediction (LCP) and complexity evaluation of multi-word expressions (MWE).\nLarge language models (LLMs) recently became popular in the Natural Language\nProcessing community because of their versatility and capability to solve\nunseen tasks in zero/few-shot settings. Our work investigates LLM usage,\nspecifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, and\nclosed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWE\nsettings. We evaluate zero-shot, few-shot, and fine-tuning settings and show\nthat LLMs struggle in certain conditions or achieve comparable results against\nexisting methods. In addition, we provide some views on meta-learning combined\nwith prompt learning. In the end, we conclude that the current state of LLMs\ncannot or barely outperform existing methods, which are usually much smaller."
  },
  {
    "arxiv_id": "2411.01645",
    "title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers",
    "url": "http://arxiv.org/abs/2411.01645v1",
    "abstract": "Feature engineering is crucial for optimizing machine learning model\nperformance, particularly in tabular data classification tasks. Leveraging\nadvancements in natural language processing, this study presents a systematic\napproach to enrich tabular datasets with features derived from large language\nmodel embeddings. Through a comprehensive ablation study on diverse datasets,\nwe assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,\nincluding Random Forest, XGBoost, and CatBoost. Results indicate that\nintegrating embeddings with traditional numerical and categorical features\noften enhances predictive performance, especially on datasets with class\nimbalance or limited features and samples, such as UCI Adult, Heart Disease,\nTitanic, and Pima Indian Diabetes, with improvements particularly notable in\nXGBoost and CatBoost classifiers. Additionally, feature importance analysis\nreveals that LLM-derived features frequently rank among the most impactful for\nthe predictions. This study provides a structured approach to embedding-based\nfeature enrichment and illustrates its benefits in ensemble learning for\ntabular data."
  },
  {
    "arxiv_id": "2411.01213",
    "title": "One Arrow, Many Targets: Probing LLMs for Multi-Attribute Controllable Text Summarization",
    "url": "http://arxiv.org/abs/2411.01213v1",
    "abstract": "Text summarization is a well-established task within the natural language\nprocessing (NLP) community. However, the focus on controllable summarization\ntailored to user requirements is gaining traction only recently. While several\nefforts explore controllability in text summarization, the investigation of\nMulti-Attribute Controllable Summarization (MACS) remains limited. This work\naddresses this gap by examining the MACS task through the lens of large\nlanguage models (LLMs), using various learning paradigms, particularly low-rank\nadapters. We experiment with different popular adapter fine-tuning strategies\nto assess the effectiveness of the resulting models in retaining cues and\npatterns associated with multiple controllable attributes. Additionally, we\npropose and evaluate a novel hierarchical adapter fusion technique to integrate\nlearnings from two distinct controllable attributes. Subsquently, we present\nour findings, discuss the challenges encountered, and suggest potential avenues\nfor advancing the MACS task."
  },
  {
    "arxiv_id": "2411.02943",
    "title": "Capturing research literature attitude towards Sustainable Development Goals: an LLM-based topic modeling approach",
    "url": "http://arxiv.org/abs/2411.02943v1",
    "abstract": "The world is facing a multitude of challenges that hinder the development of\nhuman civilization and the well-being of humanity on the planet. The\nSustainable Development Goals (SDGs) were formulated by the United Nations in\n2015 to address these global challenges by 2030. Natural language processing\ntechniques can help uncover discussions on SDGs within research literature. We\npropose a completely automated pipeline to 1) fetch content from the Scopus\ndatabase and prepare datasets dedicated to five groups of SDGs; 2) perform\ntopic modeling, a statistical technique used to identify topics in large\ncollections of textual data; and 3) enable topic exploration through\nkeywords-based search and topic frequency time series extraction. For topic\nmodeling, we leverage the stack of BERTopic scaled up to be applied on large\ncorpora of textual documents (we find hundreds of topics on hundreds of\nthousands of documents), introducing i) a novel LLM-based embeddings\ncomputation for representing scientific abstracts in the continuous space and\nii) a hyperparameter optimizer to efficiently find the best configuration for\nany new big datasets. We additionally produce the visualization of results on\ninteractive dashboards reporting topics' temporal evolution. Results are made\ninspectable and explorable, contributing to the interpretability of the topic\nmodeling process. Our proposed LLM-based topic modeling pipeline for big-text\ndatasets allows users to capture insights on the evolution of the attitude\ntoward SDGs within scientific abstracts in the 2006-2023 time span. All the\nresults are reproducible by using our system; the workflow can be generalized\nto be applied at any point in time to any big corpus of textual documents."
  },
  {
    "arxiv_id": "2411.02730",
    "title": "A Natural Language Processing Approach to Support Biomedical Data Harmonization: Leveraging Large Language Models",
    "url": "http://arxiv.org/abs/2411.02730v1",
    "abstract": "Biomedical research requires large, diverse samples to produce unbiased\nresults. Automated methods for matching variables across datasets can\naccelerate this process. Research in this area has been limited, primarily\nfocusing on lexical matching and ontology based semantic matching. We aimed to\ndevelop new methods, leveraging large language models (LLM) and ensemble\nlearning, to automate variable matching. Methods: We utilized data from two\nGERAS cohort (European and Japan) studies to develop variable matching methods.\nWe first manually created a dataset by matching 352 EU variables with 1322\ncandidate JP variables, where matched variable pairs were positive and\nunmatched pairs were negative instances. Using this dataset, we developed and\nevaluated two types of natural language processing (NLP) methods, which matched\nvariables based on variable labels and definitions from data dictionaries: (1)\nLLM-based and (2) fuzzy matching. We then developed an ensemble-learning\nmethod, using the Random Forest model, to integrate individual NLP methods. RF\nwas trained and evaluated on 50 trials. Each trial had a random split (4:1) of\ntraining and test sets, with the model's hyperparameters optimized through\ncross-validation on the training set. For each EU variable, 1322 candidate JP\nvariables were ranked based on NLP-derived similarity scores or RF's\nprobability scores, denoting their likelihood to match the EU variable. Ranking\nperformance was measured by top-n hit ratio (HRn) and mean reciprocal rank\n(MRR). Results:E5 performed best among individual methods, achieving 0.90 HR-30\nand 0.70 MRR. RF performed better than E5 on all metrics over 50 trials (P less\nthan 0.001) and achieved an average HR 30 of 0.98 and MRR of 0.73. LLM-derived\nfeatures contributed most to RF's performance. One major cause of errors in\nautomatic variable matching was ambiguous variable definitions within data\ndictionaries."
  },
  {
    "arxiv_id": "2411.02476",
    "title": "A Comparative Analysis of Instruction Fine-Tuning LLMs for Financial Text Classification",
    "url": "http://arxiv.org/abs/2411.02476v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\ndiverse Natural Language Processing (NLP) tasks, including language\nunderstanding, reasoning, and generation. However, general-domain LLMs often\nstruggle with financial tasks due to the technical and specialized nature of\nfinancial texts. This study investigates the efficacy of instruction\nfine-tuning smaller-scale LLMs, including Mistral-7B, Llama3-8B, and Phi3-mini,\nto enhance their performance in financial text classification tasks. We\nfine-tuned both instruction-tuned and base models across four financial\nclassification tasks, achieving significant improvements in task-specific\nperformance. Furthermore, we evaluated the zero-shot capabilities of these\nfine-tuned models on three unseen complex financial tasks, including argument\nclassification, deal completeness classification, and causal classification.\nOur results indicate while base model fine-tuning led to greater degradation,\ninstruction-tuned models maintained more robust performance. To address this\ndegradation, we employed model merging techniques, integrating single-task\ndomain-specific fine-tuned models with the base model. Using this merging\nmethod resulted in significant enhancements in zero-shot performance, even\nexceeding the original model's accuracy on certain datasets. Our findings\nunderscore the effectiveness of instruction fine-tuning and model merging for\nadapting LLMs to specialized financial text classification tasks."
  },
  {
    "arxiv_id": "2411.04025",
    "title": "Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages",
    "url": "http://arxiv.org/abs/2411.04025v1",
    "abstract": "Language Identification (LI) is crucial for various natural language\nprocessing tasks, serving as a foundational step in applications such as\nsentiment analysis, machine translation, and information retrieval. In\nmultilingual societies like India, particularly among the youth engaging on\nsocial media, text often exhibits code-mixing, blending local languages with\nEnglish at different linguistic levels. This phenomenon presents formidable\nchallenges for LI systems, especially when languages intermingle within single\nwords. Dravidian languages, prevalent in southern India, possess rich\nmorphological structures yet suffer from under-representation in digital\nplatforms, leading to the adoption of Roman or hybrid scripts for\ncommunication. This paper introduces a prompt based method for a shared task\naimed at addressing word-level LI challenges in Dravidian languages. In this\nwork, we leveraged GPT-3.5 Turbo to understand whether the large language\nmodels is able to correctly classify words into correct categories. Our\nfindings show that the Kannada model consistently outperformed the Tamil model\nacross most metrics, indicating a higher accuracy and reliability in\nidentifying and categorizing Kannada language instances. In contrast, the Tamil\nmodel showed moderate performance, particularly needing improvement in\nprecision and recall."
  },
  {
    "arxiv_id": "2411.03542",
    "title": "Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry",
    "url": "http://arxiv.org/abs/2411.03542v1",
    "abstract": "A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and\nmore) are driving forward novel development of multipurpose AI for a variety of\ntasks, particularly natural language processing (NLP) tasks. These models\ndemonstrate strong performance on a range of tasks; however, there has been\nevidence of brittleness when applied to more niche or narrow domains where\nhallucinations or fluent but incorrect responses reduce performance. Given the\ncomplex nature of scientific domains, it is prudent to investigate the\ntrade-offs of leveraging off-the-shelf versus more targeted foundation models\nfor scientific domains. In this work, we examine the benefits of in-domain\npre-training for a given scientific domain, chemistry, and compare these to\nopen-source, off-the-shelf models with zero-shot and few-shot prompting. Our\nresults show that not only do in-domain base models perform reasonably well on\nin-domain tasks in a zero-shot setting but that further adaptation using\ninstruction fine-tuning yields impressive performance on chemistry-specific\ntasks such as named entity recognition and molecular formula generation."
  },
  {
    "arxiv_id": "2411.04862",
    "title": "Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models",
    "url": "http://arxiv.org/abs/2411.04862v1",
    "abstract": "Title: Sentiment Analysis of Spanish Political Party Communications on\nTwitter Using Pre-trained Language Models\n  Authors: Chuqiao Song, Shunzhang Chen, Xinyi Cai, Hao Chen\n  Comments: 21 pages, 6 figures\n  Abstract: This study investigates sentiment patterns within Spanish political\nparty communications on Twitter by leveraging BETO and RoBERTuito, two\npre-trained language models optimized for Spanish text. Using a dataset of\ntweets from major Spanish political parties: PSOE, PP, Vox, Podemos, and\nCiudadanos, spanning 2019 to 2024, this research analyzes sentiment\ndistributions and explores the relationship between sentiment expression and\nparty ideology. The findings indicate that both models consistently identify a\npredominant Neutral sentiment across all parties, with significant variations\nin Negative and Positive sentiments that align with ideological distinctions.\nSpecifically, Vox exhibits higher levels of Negative sentiment, while PSOE\ndemonstrates relatively high Positive sentiment, supporting the hypothesis that\nemotional appeals in political messaging reflect ideological stances. This\nstudy underscores the potential of pre-trained language models for non-English\nsentiment analysis on social media, providing insights into sentiment dynamics\nthat shape public discourse within Spain's multi-party political system.\n  Keywords: Spanish politics, sentiment analysis, pre-trained language models,\nTwitter, BETO, RoBERTuito, political ideology, multi-party system"
  },
  {
    "arxiv_id": "2411.04752",
    "title": "RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval",
    "url": "http://arxiv.org/abs/2411.04752v1",
    "abstract": "Code-mixing, the integration of lexical and grammatical elements from\nmultiple languages within a single sentence, is a widespread linguistic\nphenomenon, particularly prevalent in multilingual societies. In India, social\nmedia users frequently engage in code-mixed conversations using the Roman\nscript, especially among migrant communities who form online groups to share\nrelevant local information. This paper focuses on the challenges of extracting\nrelevant information from code-mixed conversations, specifically within Roman\ntransliterated Bengali mixed with English. This study presents a novel approach\nto address these challenges by developing a mechanism to automatically identify\nthe most relevant answers from code-mixed conversations. We have experimented\nwith a dataset comprising of queries and documents from Facebook, and Query\nRelevance files (QRels) to aid in this task. Our results demonstrate the\neffectiveness of our approach in extracting pertinent information from complex,\ncode-mixed digital conversations, contributing to the broader field of natural\nlanguage processing in multilingual and informal text environments. We use\nGPT-3.5 Turbo via prompting alongwith using the sequential nature of relevant\ndocuments to frame a mathematical model which helps to detect relevant\ndocuments corresponding to a query."
  },
  {
    "arxiv_id": "2411.04588",
    "title": "Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction",
    "url": "http://arxiv.org/abs/2411.04588v1",
    "abstract": "Natural language processing (NLP) utilizes text data augmentation to overcome\nsample size constraints. Increasing the sample size is a natural and widely\nused strategy for alleviating these challenges. In this study, we chose Arabic\nto increase the sample size and correct grammatical errors. Arabic is\nconsidered one of the languages with limited resources for grammatical error\ncorrection (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used\nin most Arabic grammatical error correction research, with approximately 20,500\nparallel examples, which is considered low compared with other languages.\nTherefore, this study aims to develop an Arabic corpus called \"Tibyan\" for\ngrammatical error correction using ChatGPT. ChatGPT is used as a data augmenter\ntool based on a pair of Arabic sentences containing grammatical errors matched\nwith a sentence free of errors extracted from Arabic books, called guide\nsentences. Multiple steps were involved in establishing our corpus, including\nthe collection and pre-processing of a pair of Arabic texts from various\nsources, such as books and open-access corpora. We then used ChatGPT to\ngenerate a parallel corpus based on the text collected previously, as a guide\nfor generating sentences with multiple types of errors. By engaging linguistic\nexperts to review and validate the automatically generated sentences, we\nensured that they were correct and error-free. The corpus was validated and\nrefined iteratively based on feedback provided by linguistic experts to improve\nits accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to\nanalyze the types of errors in the Tibyan corpus. Our corpus contained 49 of\nerrors, including seven types: orthography, morphology, syntax, semantics,\npunctuation, merge, and split. The Tibyan corpus contains approximately 600 K\ntokens."
  },
  {
    "arxiv_id": "2411.05442",
    "title": "IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge Delivery",
    "url": "http://arxiv.org/abs/2411.05442v1",
    "abstract": "In the rapidly evolving landscape of cyber security, intelligent chatbots are\ngaining prominence. Artificial Intelligence, Machine Learning, and Natural\nLanguage Processing empower these chatbots to handle user inquiries and deliver\nthreat intelligence. This helps cyber security knowledge readily available to\nboth professionals and the public. Traditional rule-based chatbots often lack\nflexibility and struggle to adapt to user interactions. In contrast, Large\nLanguage Model-based chatbots offer contextually relevant information across\nmultiple domains and adapt to evolving conversational contexts. In this work,\nwe develop IntellBot, an advanced cyber security Chatbot built on top of\ncutting-edge technologies like Large Language Models and Langchain alongside a\nRetrieval-Augmented Generation model to deliver superior capabilities. This\nchatbot gathers information from diverse data sources to create a comprehensive\nknowledge base covering known vulnerabilities, recent cyber attacks, and\nemerging threats. It delivers tailored responses, serving as a primary hub for\ncyber security insights. By providing instant access to relevant information\nand resources, this IntellBot enhances threat intelligence, incident response,\nand overall security posture, saving time and empowering users with knowledge\nof cyber security best practices. Moreover, we analyzed the performance of our\ncopilot using a two-stage evaluation strategy. We achieved BERT score above 0.8\nby indirect approach and a cosine similarity score ranging from 0.8 to 1, which\naffirms the accuracy of our copilot. Additionally, we utilized RAGAS to\nevaluate the RAG model, and all evaluation metrics consistently produced scores\nabove 0.77, highlighting the efficacy of our system."
  },
  {
    "arxiv_id": "2411.07118",
    "title": "ConvMixFormer- A Resource-efficient Convolution Mixer for Transformer-based Dynamic Hand Gesture Recognition",
    "url": "http://arxiv.org/abs/2411.07118v1",
    "abstract": "Transformer models have demonstrated remarkable success in many domains such\nas natural language processing (NLP) and computer vision. With the growing\ninterest in transformer-based architectures, they are now utilized for gesture\nrecognition. So, we also explore and devise a novel ConvMixFormer architecture\nfor dynamic hand gestures. The transformers use quadratic scaling of the\nattention features with the sequential data, due to which these models are\ncomputationally complex and heavy. We have considered this drawback of the\ntransformer and designed a resource-efficient model that replaces the\nself-attention in the transformer with the simple convolutional layer-based\ntoken mixer. The computational cost and the parameters used for the\nconvolution-based mixer are comparatively less than the quadratic\nself-attention. Convolution-mixer helps the model capture the local spatial\nfeatures that self-attention struggles to capture due to their sequential\nprocessing nature. Further, an efficient gate mechanism is employed instead of\na conventional feed-forward network in the transformer to help the model\ncontrol the flow of features within different stages of the proposed model.\nThis design uses fewer learnable parameters which is nearly half the vanilla\ntransformer that helps in fast and efficient training. The proposed method is\nevaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has\nachieved state-of-the-art results on single and multimodal inputs. We have also\nshown the parameter efficiency of the proposed ConvMixFormer model compared to\nother methods. The source code is available at\nhttps://github.com/mallikagarg/ConvMixFormer."
  },
  {
    "arxiv_id": "2411.07037",
    "title": "LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios",
    "url": "http://arxiv.org/abs/2411.07037v1",
    "abstract": "As Large Language Models (LLMs) evolve in natural language processing (NLP),\ntheir ability to stably follow instructions in long-context inputs has become\ncritical for real-world applications. However, existing benchmarks seldom focus\non instruction-following in long-context scenarios or stability on different\ninputs. To bridge this gap, we introduce LIFBench, a scalable dataset designed\nto evaluate LLMs' instruction-following capabilities and stability across long\ncontexts. LIFBench comprises three long-context scenarios and eleven diverse\ntasks, featuring 2,766 instructions generated through an automated expansion\nmethod across three dimensions: length, expression, and variables. For\nevaluation, we propose LIFEval, a rubric-based assessment method that enables\nprecise, automated scoring of complex LLM responses without reliance on\nLLM-assisted assessments or human judgment. This method allows for a\ncomprehensive analysis of model performance and stability from multiple\nperspectives. We conduct detailed experiments on 20 prominent LLMs across six\nlength intervals. Our work contributes LIFBench and LIFEval as robust tools for\nassessing LLM performance in complex and long-context settings, offering\nvaluable insights to guide future advancements in LLM development."
  },
  {
    "arxiv_id": "2411.06805",
    "title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant",
    "url": "http://arxiv.org/abs/2411.06805v1",
    "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses."
  },
  {
    "arxiv_id": "2411.06691",
    "title": "Autonomous Droplet Microfluidic Design Framework with Large Language Models",
    "url": "http://arxiv.org/abs/2411.06691v1",
    "abstract": "Droplet-based microfluidic devices have substantial promise as cost-effective\nalternatives to current assessment tools in biological research. Moreover,\nmachine learning models that leverage tabular data, including input design\nparameters and their corresponding efficiency outputs, are increasingly\nutilised to automate the design process of these devices and to predict their\nperformance. However, these models fail to fully leverage the data presented in\nthe tables, neglecting crucial contextual information, including column\nheadings and their associated descriptions. This study presents\nMicroFluidic-LLMs, a framework designed for processing and feature extraction,\nwhich effectively captures contextual information from tabular data formats.\nMicroFluidic-LLMs overcomes processing challenges by transforming the content\ninto a linguistic format and leveraging pre-trained large language models\n(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11\nprediction tasks, covering aspects such as geometry, flow conditions, regimes,\nand performance, utilising a publicly available dataset on flow-focusing\ndroplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can\nempower deep neural network models to be highly effective and straightforward\nwhile minimising the need for extensive data preprocessing. Moreover, the\nexceptional performance of deep neural network models, particularly when\ncombined with advanced natural language processing models such as DistilBERT\nand GPT-2, reduces the mean absolute error in the droplet diameter and\ngeneration rate by nearly 5- and 7-fold, respectively, and enhances the regime\nclassification accuracy by over 4%, compared with the performance reported in a\nprevious study. This study lays the foundation for the huge potential\napplications of LLMs and machine learning in a wider spectrum of microfluidic\napplications."
  },
  {
    "arxiv_id": "2411.06681",
    "title": "WDMoE: Wireless Distributed Mixture of Experts for Large Language Models",
    "url": "http://arxiv.org/abs/2411.06681v1",
    "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but the role of wireless networks in\nsupporting LLMs has not been thoroughly explored. In this paper, we propose a\nwireless distributed Mixture of Experts (WDMoE) architecture to enable\ncollaborative deployment of LLMs across edge servers at the base station (BS)\nand mobile devices in wireless networks. Specifically, we decompose the MoE\nlayer in LLMs by placing the gating network and the preceding neural network\nlayer at BS, while distributing the expert networks among the devices. This\ndeployment leverages the parallel inference capabilities of expert networks on\nmobile devices, effectively utilizing the limited computing and caching\nresources of these devices. Accordingly, we develop a performance metric for\nWDMoE-based LLMs, which accounts for both model capability and latency. To\nminimize the latency while maintaining accuracy, we jointly optimize expert\nselection and bandwidth allocation based on the performance metric. Moreover,\nwe build a hardware testbed using NVIDIA Jetson kits to validate the\neffectiveness of WDMoE. Both theoretical simulations and practical hardware\nexperiments demonstrate that the proposed method can significantly reduce the\nlatency without compromising LLM performance."
  },
  {
    "arxiv_id": "2411.06608",
    "title": "MolMiner: Transformer architecture for fragment-based autoregressive generation of molecular stories",
    "url": "http://arxiv.org/abs/2411.06608v1",
    "abstract": "Deep generative models for molecular discovery have become a very popular\nchoice in new high-throughput screening paradigms. These models have been\ndeveloped inheriting from the advances in natural language processing and\ncomputer vision, achieving ever greater results. However, generative molecular\nmodelling has unique challenges that are often overlooked. Chemical validity,\ninterpretability of the generation process and flexibility to variable\nmolecular sizes are among some of the remaining challenges for generative\nmodels in computational materials design. In this work, we propose an\nautoregressive approach that decomposes molecular generation into a sequence of\ndiscrete and interpretable steps using molecular fragments as units, a\n'molecular story'. Enforcing chemical rules in the stories guarantees the\nchemical validity of the generated molecules, the discrete sequential steps of\na molecular story makes the process transparent improving interpretability, and\nthe autoregressive nature of the approach allows the size of the molecule to be\na decision of the model. We demonstrate the validity of the approach in a\nmulti-target inverse design of electroactive organic compounds, focusing on the\ntarget properties of solubility, redox potential, and synthetic accessibility.\nOur results show that the model can effectively bias the generation\ndistribution according to the prompted multi-target objective."
  },
  {
    "arxiv_id": "2411.08868",
    "title": "CamemBERT 2.0: A Smarter French Language Model Aged to Perfection",
    "url": "http://arxiv.org/abs/2411.08868v1",
    "abstract": "French language models, such as CamemBERT, have been widely adopted across\nindustries for natural language processing (NLP) tasks, with models like\nCamemBERT seeing over 4 million downloads per month. However, these models face\nchallenges due to temporal concept drift, where outdated training data leads to\na decline in performance, especially when encountering new topics and\nterminology. This issue emphasizes the need for updated models that reflect\ncurrent linguistic trends. In this paper, we introduce two new versions of the\nCamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these\nchallenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use\nof the Replaced Token Detection (RTD) objective for better contextual\nunderstanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked\nLanguage Modeling (MLM) objective. Both models are trained on a significantly\nlarger and more recent dataset with longer context length and an updated\ntokenizer that enhances tokenization performance for French. We evaluate the\nperformance of these models on both general-domain NLP tasks and\ndomain-specific applications, such as medical field tasks, demonstrating their\nversatility and effectiveness across a range of use cases. Our results show\nthat these updated models vastly outperform their predecessors, making them\nvaluable tools for modern NLP systems. All our new models, as well as\nintermediate checkpoints, are made openly available on Huggingface."
  },
  {
    "arxiv_id": "2411.08666",
    "title": "A Survey on Vision Autoregressive Model",
    "url": "http://arxiv.org/abs/2411.08666v1",
    "abstract": "Autoregressive models have demonstrated great performance in natural language\nprocessing (NLP) with impressive scalability, adaptability and\ngeneralizability. Inspired by their notable success in NLP field,\nautoregressive models have been intensively investigated recently for computer\nvision, which perform next-token predictions by representing visual data as\nvisual tokens and enables autoregressive modelling for a wide range of vision\ntasks, ranging from visual generation and visual understanding to the very\nrecent multimodal generation that unifies visual generation and understanding\nwith a single autoregressive model. This paper provides a systematic review of\nvision autoregressive models, including the development of a taxonomy of\nexisting methods and highlighting their major contributions, strengths, and\nlimitations, covering various vision tasks such as image generation, video\ngeneration, image editing, motion generation, medical image analysis, 3D\ngeneration, robotic manipulation, unified multimodal generation, etc. Besides,\nwe investigate and analyze the latest advancements in autoregressive models,\nincluding thorough benchmarking and discussion of existing methods across\nvarious evaluation datasets. Finally, we outline key challenges and promising\ndirections for future research, offering a roadmap to guide further\nadvancements in vision autoregressive models."
  },
  {
    "arxiv_id": "2411.08534",
    "title": "Neural Topic Modeling with Large Language Models in the Loop",
    "url": "http://arxiv.org/abs/2411.08534v1",
    "abstract": "Topic modeling is a fundamental task in natural language processing, allowing\nthe discovery of latent thematic structures in text corpora. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities in topic\ndiscovery, their direct application to topic modeling suffers from issues such\nas incomplete topic coverage, misalignment of topics, and inefficiency. To\naddress these limitations, we propose LLM-ITL, a novel LLM-in-the-loop\nframework that integrates LLMs with Neural Topic Models (NTMs). In LLM-ITL,\nglobal topics and document representations are learned through the NTM.\nMeanwhile, an LLM refines these topics using an Optimal Transport (OT)-based\nalignment objective, where the refinement is dynamically adjusted based on the\nLLM's confidence in suggesting topical words for each set of input words. With\nthe flexibility of being integrated into many existing NTMs, the proposed\napproach enhances the interpretability of topics while preserving the\nefficiency of NTMs in learning topics and document representations. Extensive\nexperiments demonstrate that LLM-ITL helps NTMs significantly improve their\ntopic interpretability while maintaining the quality of document\nrepresentation. Our code and datasets will be available at Github."
  },
  {
    "arxiv_id": "2411.08275",
    "title": "A Large-Scale Study of Relevance Assessments with Large Language Models: An Initial Look",
    "url": "http://arxiv.org/abs/2411.08275v1",
    "abstract": "The application of large language models to provide relevance assessments\npresents exciting opportunities to advance information retrieval, natural\nlanguage processing, and beyond, but to date many unknowns remain. This paper\nreports on the results of a large-scale evaluation (the TREC 2024 RAG Track)\nwhere four different relevance assessment approaches were deployed in situ: the\n\"standard\" fully manual process that NIST has implemented for decades and three\ndifferent alternatives that take advantage of LLMs to different extents using\nthe open-source UMBRELA tool. This setup allows us to correlate system rankings\ninduced by the different approaches to characterize tradeoffs between cost and\nquality. We find that in terms of nDCG@20, nDCG@100, and Recall@100, system\nrankings induced by automatically generated relevance assessments from UMBRELA\ncorrelate highly with those induced by fully manual assessments across a\ndiverse set of 77 runs from 19 teams. Our results suggest that automatically\ngenerated UMBRELA judgments can replace fully manual judgments to accurately\ncapture run-level effectiveness. Surprisingly, we find that LLM assistance does\nnot appear to increase correlation with fully manual assessments, suggesting\nthat costs associated with human-in-the-loop processes do not bring obvious\ntangible benefits. Overall, human assessors appear to be stricter than UMBRELA\nin applying relevance criteria. Our work validates the use of LLMs in academic\nTREC-style evaluations and provides the foundation for future studies."
  },
  {
    "arxiv_id": "2411.08181",
    "title": "Challenges in Guardrailing Large Language Models for Science",
    "url": "http://arxiv.org/abs/2411.08181v1",
    "abstract": "The rapid development in large language models (LLMs) has transformed the\nlandscape of natural language processing and understanding (NLP/NLU), offering\nsignificant benefits across various domains. However, when applied to\nscientific research, these powerful models exhibit critical failure modes\nrelated to scientific integrity and trustworthiness. Existing general-purpose\nLLM guardrails are insufficient to address these unique challenges in the\nscientific domain. We provide comprehensive guidelines for deploying LLM\nguardrails in the scientific domain. We identify specific challenges --\nincluding time sensitivity, knowledge contextualization, conflict resolution,\nand intellectual property concerns -- and propose a guideline framework for the\nguardrails that can align with scientific needs. These guardrail dimensions\ninclude trustworthiness, ethics & bias, safety, and legal aspects. We also\noutline in detail the implementation strategies that employ white-box,\nblack-box, and gray-box methodologies that can be enforced within scientific\ncontexts."
  },
  {
    "arxiv_id": "2411.09539",
    "title": "A Practical Guide to Fine-tuning Language Models with Limited Data",
    "url": "http://arxiv.org/abs/2411.09539v1",
    "abstract": "Employing pre-trained Large Language Models (LLMs) has become the de facto\nstandard in Natural Language Processing (NLP) despite their extensive data\nrequirements. Motivated by the recent surge in research focused on training\nLLMs with limited data, particularly in low-resource domains and languages,\nthis paper surveys recent transfer learning approaches to optimize model\nperformance in downstream tasks where data is scarce. We first address initial\nand continued pre-training strategies to better leverage prior knowledge in\nunseen domains and languages. We then examine how to maximize the utility of\nlimited data during fine-tuning and few-shot learning. The final section takes\na task-specific perspective, reviewing models and methods suited for different\nlevels of data scarcity. Our goal is to provide practitioners with practical\nguidelines for overcoming the challenges posed by constrained data while also\nhighlighting promising directions for future research."
  },
  {
    "arxiv_id": "2411.09523",
    "title": "Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents",
    "url": "http://arxiv.org/abs/2411.09523v1",
    "abstract": "With the continuous development of large language models (LLMs),\ntransformer-based models have made groundbreaking advances in numerous natural\nlanguage processing (NLP) tasks, leading to the emergence of a series of agents\nthat use LLMs as their control hub. While LLMs have achieved success in various\ntasks, they face numerous security and privacy threats, which become even more\nsevere in the agent scenarios. To enhance the reliability of LLM-based\napplications, a range of research has emerged to assess and mitigate these\nrisks from different perspectives.\n  To help researchers gain a comprehensive understanding of various risks, this\nsurvey collects and analyzes the different threats faced by these agents. To\naddress the challenges posed by previous taxonomies in handling cross-module\nand cross-stage threats, we propose a novel taxonomy framework based on the\nsources and impacts. Additionally, we identify six key features of LLM-based\nagents, based on which we summarize the current research progress and analyze\ntheir limitations. Subsequently, we select four representative agents as case\nstudies to analyze the risks they may face in practical use. Finally, based on\nthe aforementioned analyses, we propose future research directions from the\nperspectives of data, methodology, and policy, respectively."
  },
  {
    "arxiv_id": "2411.09317",
    "title": "Pie: Pooling CPU Memory for LLM Inference",
    "url": "http://arxiv.org/abs/2411.09317v1",
    "abstract": "The rapid growth of LLMs has revolutionized natural language processing and\nAI analysis, but their increasing size and memory demands present significant\nchallenges. A common solution is to spill over to CPU memory; however,\ntraditional GPU-CPU memory swapping often results in higher latency and lower\nthroughput.\n  This paper introduces Pie, an LLM inference framework that addresses these\nchallenges with performance-transparent swapping and adaptive expansion. By\nleveraging predictable memory access patterns and the high bandwidth of modern\nhardware like the NVIDIA GH200 Grace Hopper Superchip, Pie enables concurrent\ndata swapping without affecting foreground computation, expanding effective\nmemory without added latency. Adaptive expansion dynamically adjusts CPU memory\nallocation based on real-time information, optimizing memory usage and\nperformance under varying conditions.\n  Pie maintains low computation latency, high throughput, and high elasticity.\nOur experimental evaluation demonstrates that Pie achieves optimal swapping\npolicy during cache warmup and effectively balances increased memory capacity\nwith negligible impact on computation. With its extended capacity, Pie\noutperforms vLLM by up to 1.9X in throughput and 2X in latency. Additionally,\nPie can reduce GPU memory usage by up to 1.67X while maintaining the same\nperformance. Compared to FlexGen, an offline profiling-based swapping solution,\nPie achieves magnitudes lower latency and 9.4X higher throughput."
  },
  {
    "arxiv_id": "2411.09224",
    "title": "Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers",
    "url": "http://arxiv.org/abs/2411.09224v1",
    "abstract": "Our everyday lives now heavily rely on artificial intelligence (AI) powered\nlarge language models (LLMs). Like regular users, programmers are also\nbenefiting from the newest large language models. In response to the critical\nrole that AI models play in modern software development, this study presents a\nthorough evaluation of leading programming assistants, including ChatGPT,\nGemini(Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on\ntasks like natural language processing and code generation accuracy in\ndifferent programming languages like Java, Python and C++. Based on the\nresults, it has emphasized their strengths and weaknesses and the importance of\nfurther modifications to increase the reliability and accuracy of the latest\npopular models. Although these AI assistants illustrate a high level of\nprogress in language understanding and code generation, along with ethical\nconsiderations and responsible usage, they provoke a necessity for discussion.\nWith time, developing more refined AI technology is essential for achieving\nadvanced solutions in various fields, especially with the knowledge of the\nfeature intricacies of these models and their implications. This study offers a\ncomparison of different LLMs and provides essential feedback on the rapidly\nchanging area of AI models. It also emphasizes the need for ethical\ndevelopmental practices to actualize AI models' full potential."
  },
  {
    "arxiv_id": "2411.09125",
    "title": "DROJ: A Prompt-Driven Attack against Large Language Models",
    "url": "http://arxiv.org/abs/2411.09125v1",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Due to their training on\ninternet-sourced datasets, LLMs can sometimes generate objectionable content,\nnecessitating extensive alignment with human feedback to avoid such outputs.\nDespite massive alignment efforts, LLMs remain susceptible to adversarial\njailbreak attacks, which usually are manipulated prompts designed to circumvent\nsafety mechanisms and elicit harmful responses. Here, we introduce a novel\napproach, Directed Rrepresentation Optimization Jailbreak (DROJ), which\noptimizes jailbreak prompts at the embedding level to shift the hidden\nrepresentations of harmful queries towards directions that are more likely to\nelicit affirmative responses from the model. Our evaluations on LLaMA-2-7b-chat\nmodel show that DROJ achieves a 100\\% keyword-based Attack Success Rate (ASR),\neffectively preventing direct refusals. However, the model occasionally\nproduces repetitive and non-informative responses. To mitigate this, we\nintroduce a helpfulness system prompt that enhances the utility of the model's\nresponses. Our code is available at\nhttps://github.com/Leon-Leyang/LLM-Safeguard."
  },
  {
    "arxiv_id": "2411.09116",
    "title": "P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs",
    "url": "http://arxiv.org/abs/2411.09116v1",
    "abstract": "Recent advancements in large language models (LLMs) showcase varied\nmultilingual capabilities across tasks like translation, code generation, and\nreasoning. Previous assessments often limited their scope to fundamental\nnatural language processing (NLP) or isolated capability-specific tasks. To\nalleviate this drawback, we aim to present a comprehensive multilingual\nmultitask benchmark. First, we present a pipeline for selecting available and\nreasonable benchmarks from massive ones, addressing the oversight in previous\nwork regarding the utility of these benchmarks, i.e., their ability to\ndifferentiate between models being evaluated. Leveraging this pipeline, we\nintroduce P-MMEval, a large-scale benchmark covering effective fundamental and\ncapability-specialized datasets. Furthermore, P-MMEval delivers consistent\nlanguage coverage across various datasets and provides parallel samples.\nFinally, we conduct extensive experiments on representative multilingual model\nseries to compare performances across models, analyze dataset effectiveness,\nexamine prompt impacts on model performances, and explore the relationship\nbetween multilingual performances and factors such as tasks, model sizes, and\nlanguages. These insights offer valuable guidance for future research. The\ndataset is available at https://huggingface.co/datasets/Qwen/P-MMEval."
  },
  {
    "arxiv_id": "2411.10083",
    "title": "Xmodel-1.5: An 1B-scale Multilingual LLM",
    "url": "http://arxiv.org/abs/2411.10083v1",
    "abstract": "We introduce Xmodel-1.5, a 1-billion-parameter multilingual large language\nmodel pretrained on 2 trillion tokens, designed for balanced performance and\nscalability. Unlike most large models that use the BPE tokenizer, Xmodel-1.5\nemploys a custom unigram tokenizer with 65,280 tokens, optimizing both\nefficiency and accuracy. The model delivers competitive results across multiple\nlanguages, including Thai, Arabic, French, Chinese, and English, outperforming\nAlibaba's PolyLM-1.7B on respective evaluation datasets. Xmodel-1.5 excels in\nbenchmarks like mMMLU and PIQA, and achieves state-of-the-art results in Thai.\nTo support low-resource language research, we release Xdata_Thai, a\nThai-specific evaluation dataset featuring unique linguistic challenges such as\ngendered particles and idioms. While the model demonstrates strong performance,\nthere is still room for improvement in handling culturally specific nuances. We\nhope this work contributes to advancements in multilingual AI research. Models\nand code are publicly available on GitHub at\nhttps://github.com/XiaoduoAILab/XmodelLM-1.5"
  },
  {
    "arxiv_id": "2411.10020",
    "title": "Information Extraction from Clinical Notes: Are We Ready to Switch to Large Language Models?",
    "url": "http://arxiv.org/abs/2411.10020v1",
    "abstract": "Backgrounds: Information extraction (IE) is critical in clinical natural\nlanguage processing (NLP). While large language models (LLMs) excel on\ngenerative tasks, their performance on extractive tasks remains debated.\nMethods: We investigated Named Entity Recognition (NER) and Relation Extraction\n(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,\nMIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinical\nentities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3\nagainst BERT in terms of performance, generalizability, computational\nresources, and throughput to BERT. Results: LLaMA models outperformed BERT\nacross datasets. With sufficient training data, LLaMA showed modest\nimprovements (1% on NER, 1.5-3.7% on RE); improvements were larger with limited\ntraining data. On unseen i2b2 data, LLaMA-3-70B outperformed BERT by 7% (F1) on\nNER and 4% on RE. However, LLaMA models required more computing resources and\nran up to 28 times slower. We implemented \"Kiwi,\" a clinical IE package\nfeaturing both models, available at https://kiwi.clinicalnlp.org/. Conclusion:\nThis study is among the first to develop and evaluate a comprehensive clinical\nIE system using open-source LLMs. Results indicate that LLaMA models outperform\nBERT for clinical NER and RE but with higher computational costs and lower\nthroughputs. These findings highlight that choosing between LLMs and\ntraditional deep learning methods for clinical IE applications should remain\ntask-specific, taking into account both performance metrics and practical\nconsiderations such as available computing resources and the intended use case\nscenarios."
  },
  {
    "arxiv_id": "2411.11505",
    "title": "LaVin-DiT: Large Vision Diffusion Transformer",
    "url": "http://arxiv.org/abs/2411.11505v1",
    "abstract": "This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a\nscalable and unified foundation model designed to tackle over 20 computer\nvision tasks in a generative framework. Unlike existing large vision models\ndirectly adapted from natural language processing architectures, which rely on\nless efficient autoregressive techniques and disrupt spatial relationships\nessential for vision data, LaVin-DiT introduces key innovations to optimize\ngenerative performance for vision tasks. First, to address the high\ndimensionality of visual data, we incorporate a spatial-temporal variational\nautoencoder that encodes data into a continuous latent space. Second, for\ngenerative modeling, we develop a joint diffusion transformer that\nprogressively produces vision outputs. Third, for unified multi-task training,\nin-context learning is implemented. Input-target pairs serve as task context,\nwhich guides the diffusion transformer to align outputs with specific tasks\nwithin the latent space. During inference, a task-specific context set and test\ndata as queries allow LaVin-DiT to generalize across tasks without fine-tuning.\nTrained on extensive vision datasets, the model is scaled from 0.1B to 3.4B\nparameters, demonstrating substantial scalability and state-of-the-art\nperformance across diverse vision tasks. This work introduces a novel pathway\nfor large vision foundation models, underscoring the promising potential of\ndiffusion transformers. The code and models are available."
  },
  {
    "arxiv_id": "2411.11350",
    "title": "Zero-Shot Load Forecasting with Large Language Models",
    "url": "http://arxiv.org/abs/2411.11350v1",
    "abstract": "Deep learning models have shown strong performance in load forecasting, but\nthey generally require large amounts of data for model training before being\napplied to new scenarios, which limits their effectiveness in data-scarce\nscenarios. Inspired by the great success of pre-trained language models (LLMs)\nin natural language processing, this paper proposes a zero-shot load\nforecasting approach using an advanced LLM framework denoted as the Chronos\nmodel. By utilizing its extensive pre-trained knowledge, the Chronos model\nenables accurate load forecasting in data-scarce scenarios without the need for\nextensive data-specific training. Simulation results across five real-world\ndatasets demonstrate that the Chronos model significantly outperforms nine\npopular baseline models for both deterministic and probabilistic load\nforecasting with various forecast horizons (e.g., 1 to 48 hours), even though\nthe Chronos model is neither tailored nor fine-tuned to these specific load\ndatasets. Notably, Chronos reduces root mean squared error (RMSE), continuous\nranked probability score (CRPS), and quantile score (QS) by approximately\n7.34%-84.30%, 19.63%-60.06%, and 22.83%-54.49%, respectively, compared to\nbaseline models. These results highlight the superiority and flexibility of the\nChronos model, positioning it as an effective solution in data-scarce\nscenarios."
  },
  {
    "arxiv_id": "2411.10915",
    "title": "Bias in Large Language Models: Origin, Evaluation, and Mitigation",
    "url": "http://arxiv.org/abs/2411.10915v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nbut their susceptibility to biases poses significant challenges. This\ncomprehensive review examines the landscape of bias in LLMs, from its origins\nto current mitigation strategies. We categorize biases as intrinsic and\nextrinsic, analyzing their manifestations in various NLP tasks. The review\ncritically assesses a range of bias evaluation methods, including data-level,\nmodel-level, and output-level approaches, providing researchers with a robust\ntoolkit for bias detection. We further explore mitigation strategies,\ncategorizing them into pre-model, intra-model, and post-model techniques,\nhighlighting their effectiveness and limitations. Ethical and legal\nimplications of biased LLMs are discussed, emphasizing potential harms in\nreal-world applications such as healthcare and criminal justice. By\nsynthesizing current knowledge on bias in LLMs, this review contributes to the\nongoing effort to develop fair and responsible AI systems. Our work serves as a\ncomprehensive resource for researchers and practitioners working towards\nunderstanding, evaluating, and mitigating bias in LLMs, fostering the\ndevelopment of more equitable AI technologies."
  },
  {
    "arxiv_id": "2411.12685",
    "title": "Enhanced Sign Language Translation between American Sign Language (ASL) and Indian Sign Language (ISL) Using LLMs",
    "url": "http://arxiv.org/abs/2411.12685v1",
    "abstract": "We have come up with a research that hopes to provide a bridge between the\nusers of American Sign Language and the users of spoken language and Indian\nSign Language (ISL). The research enabled us to create a novel framework that\nwe have developed for Learner Systems. Leveraging art of Large models to create\nkey features including: - Real-time translation between these two sign\nlanguages in an efficient manner. Making LLM's capability available for\nseamless translations to ISL. Here is the full study showing its implementation\nin this paper. The core of the system is a sophisticated pipeline that begins\nwith reclassification and recognition of ASL gestures based on a strong Random\nForest Classifier. By recognizing the ASL, it is translated into text which can\nbe more easily processed. Highly evolved natural language NLP (Natural Language\nProcessing) techniques come in handy as they play a role in our LLM integration\nwhere you then use LLMs to be able to convert the ASL text to ISL which\nprovides you with the intent of sentence or phrase. The final step is to\nsynthesize the translated text back into ISL gestures, creating an end-to-end\ntranslation experience using RIFE-Net. This framework is tasked with key\nchallenges such as automatically dealing with gesture variability and\novercoming the linguistic differences between ASL and ISL. By automating the\ntranslation process, we hope to vastly improve accessibility for sign language\nusers. No longer will the communication gap between ASL and ISL create\nbarriers; this totally cool innovation aims to bring our communities closer\ntogether. And we believe, with full confidence in our framework, that we're\nable to apply the same principles across a wide variety of sign language\ndialects."
  },
  {
    "arxiv_id": "2411.12000",
    "title": "ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity",
    "url": "http://arxiv.org/abs/2411.12000v1",
    "abstract": "Natural Language Processing (NLP) is widely used to supply summarization\nability from long context to structured information. However, extracting\nstructured knowledge from scientific text by NLP models remains a challenge\nbecause of its domain-specific nature to complex data preprocessing and the\ngranularity of multi-layered device-level information. To address this, we\nintroduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language\nModel (LLM) platform, which is designed to extract structured scientific data\nand synthesize new scientific knowledge from vast scientific corpora. The\nplatform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to\nnatural science. The platform was built on Amazon Web Services (AWS) and\nprovides an automated, user-friendly workflow for custom model development and\ndata extraction. The platform achieves remarkable accuracy with only a small\namount of well-annotated articles. This innovative tool streamlines the\ntransition from the science literature to structured knowledge and data and\nbenefits the advancements in natural informatics."
  },
  {
    "arxiv_id": "2411.13518",
    "title": "Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models",
    "url": "http://arxiv.org/abs/2411.13518v1",
    "abstract": "The increasing demand for multilingual capabilities in healthcare underscores\nthe need for AI models adept at processing diverse languages, particularly in\nclinical documentation and decision-making. Arabic, with its complex\nmorphology, syntax, and diglossia, poses unique challenges for natural language\nprocessing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a\nlanguage model tailored for Arabic clinical documentation, against JAIS, the\nleading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics\nmodified ourselves for the purposes of assessing model performances in a\ndifferent language. The study assessed the models' performance in summarizing\npatient-physician interactions, focusing on accuracy, comprehensiveness,\nclinical utility, and linguistic-cultural competence.\n  Results indicate that Sporo AraSum significantly outperforms JAIS in\nAI-centric quantitative metrics and all qualitative attributes measured in our\nmodified version of the PDQI-9. AraSum's architecture enables precise and\nculturally sensitive documentation, addressing the linguistic nuances of Arabic\nwhile mitigating risks of AI hallucinations. These findings suggest that Sporo\nAraSum is better suited to meet the demands of Arabic-speaking healthcare\nenvironments, offering a transformative solution for multilingual clinical\nworkflows. Future research should incorporate real-world data to further\nvalidate these findings and explore broader integration into healthcare\nsystems."
  },
  {
    "arxiv_id": "2411.13407",
    "title": "Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese",
    "url": "http://arxiv.org/abs/2411.13407v2",
    "abstract": "Natural Language Inference (NLI) is a task within Natural Language Processing\n(NLP) that holds value for various AI applications. However, there have been\nlimited studies on Natural Language Inference in Vietnamese that explore the\nconcept of joint models. Therefore, we conducted experiments using various\ncombinations of contextualized language models (CLM) and neural networks. We\nuse CLM to create contextualized work presentations and use Neural Networks for\nclassification. Furthermore, we have evaluated the strengths and weaknesses of\neach joint model and identified the model failure points in the Vietnamese\ncontext. The highest F1 score in this experiment, up to 82.78% in the benchmark\ndataset (ViNLI). By conducting experiments with various models, the most\nconsiderable size of the CLM is XLM-R (355M). That combination has consistently\ndemonstrated superior performance compared to fine-tuning strong pre-trained\nlanguage models like PhoBERT (+6.58%), mBERT (+19.08%), and XLM-R (+0.94%) in\nterms of F1-score. This article aims to introduce a novel approach or model\nthat attains improved performance for Vietnamese NLI. Overall, we find that the\njoint approach of CLM and neural networks is simple yet capable of achieving\nhigh-quality performance, which makes it suitable for applications that require\nefficient resource utilization."
  },
  {
    "arxiv_id": "2411.12880",
    "title": "Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events",
    "url": "http://arxiv.org/abs/2411.12880v1",
    "abstract": "Retrieval and recommendation are two essential tasks in modern search tools.\nThis paper introduces a novel retrieval-reranking framework leveraging Large\nLanguage Models (LLMs) to enhance the spatiotemporal and semantic associated\nmining and recommendation of relevant unusual climate and environmental events\ndescribed in news articles and web posts. This framework uses advanced natural\nlanguage processing techniques to address the limitations of traditional manual\ncuration methods in terms of high labor cost and lack of scalability.\nSpecifically, we explore an optimized solution to employ cutting-edge embedding\nmodels for semantically analyzing spatiotemporal events (news) and propose a\nGeo-Time Re-ranking (GT-R) strategy that integrates multi-faceted criteria\nincluding spatial proximity, temporal association, semantic similarity, and\ncategory-instructed similarity to rank and identify similar spatiotemporal\nevents. We apply the proposed framework to a dataset of four thousand Local\nEnvironmental Observer (LEO) Network events, achieving top performance in\nrecommending similar events among multiple cutting-edge dense retrieval models.\nThe search and recommendation pipeline can be applied to a wide range of\nsimilar data search tasks dealing with geospatial and temporal data. We hope\nthat by linking relevant events, we can better aid the general public to gain\nan enhanced understanding of climate change and its impact on different\ncommunities."
  },
  {
    "arxiv_id": "2411.14272",
    "title": "Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models",
    "url": "http://arxiv.org/abs/2411.14272v1",
    "abstract": "The use of Natural Language Processing (NLP) for helping decision-makers with\nClimate Change action has recently been highlighted as a use case aligning with\na broader drive towards NLP technologies for social good. In this context,\nAspect-Based Summarization (ABS) systems that extract and summarize relevant\ninformation are particularly useful as they provide stakeholders with a\nconvenient way of finding relevant information in expert-curated reports. In\nthis work, we release a new dataset for ABS of Climate Change reports and we\nemploy different Large Language Models (LLMs) and so-called Small Language\nModels (SLMs) to tackle this problem in an unsupervised way. Considering the\nproblem at hand, we also show how SLMs are not significantly worse for the\nproblem while leading to reduced carbon footprint; we do so by applying for the\nfirst time an existing framework considering both energy efficiency and task\nperformance to the evaluation of zero-shot generative models for ABS. Overall,\nour results show that modern language models, both big and small, can\neffectively tackle ABS for Climate Change reports but more research is needed\nwhen we frame the problem as a Retrieval Augmented Generation (RAG) problem and\nour work and dataset will help foster efforts in this direction."
  },
  {
    "arxiv_id": "2411.14258",
    "title": "Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective",
    "url": "http://arxiv.org/abs/2411.14258v1",
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP) based applications including automated text generation, question\nanswering, chatbots, and others. However, they face a significant challenge:\nhallucinations, where models produce plausible-sounding but factually incorrect\nresponses. This undermines trust and limits the applicability of LLMs in\ndifferent domains. Knowledge Graphs (KGs), on the other hand, provide a\nstructured collection of interconnected facts represented as entities (nodes)\nand their relationships (edges). In recent research, KGs have been leveraged to\nprovide context that can fill gaps in an LLM understanding of certain topics\noffering a promising approach to mitigate hallucinations in LLMs, enhancing\ntheir reliability and accuracy while benefiting from their wide applicability.\nNonetheless, it is still a very active area of research with various unresolved\nopen problems. In this paper, we discuss these open challenges covering\nstate-of-the-art datasets and benchmarks as well as methods for knowledge\nintegration and evaluating hallucinations. In our discussion, we consider the\ncurrent use of KGs in LLM systems and identify future directions within each of\nthese challenges."
  },
  {
    "arxiv_id": "2411.14133",
    "title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs",
    "url": "http://arxiv.org/abs/2411.14133v1",
    "abstract": "Large Language Models (LLMs) have shown impressive proficiency across a range\nof natural language processing tasks yet remain vulnerable to adversarial\nprompts, known as jailbreak attacks, carefully designed to elicit harmful\nresponses from LLMs. Traditional methods rely on manual heuristics, which\nsuffer from limited generalizability. While being automatic, optimization-based\nattacks often produce unnatural jailbreak prompts that are easy to detect by\nsafety filters or require high computational overhead due to discrete token\noptimization. Witnessing the limitations of existing jailbreak methods, we\nintroduce Generative Adversarial Suffix Prompter (GASP), a novel framework that\ncombines human-readable prompt generation with Latent Bayesian Optimization\n(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP\nleverages LBO to craft adversarial suffixes by efficiently exploring continuous\nembedding spaces, gradually optimizing the model to improve attack efficacy\nwhile balancing prompt coherence through a targeted iterative refinement\nprocedure. Our experiments show that GASP can generate natural jailbreak\nprompts, significantly improving attack success rates, reducing training times,\nand accelerating inference speed, thus making it an efficient and scalable\nsolution for red-teaming LLMs."
  },
  {
    "arxiv_id": "2411.13757",
    "title": "AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks",
    "url": "http://arxiv.org/abs/2411.13757v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\n(NLP), excelling in tasks like text generation and summarization. However,\ntheir increasing adoption in mission-critical applications raises concerns\nabout hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,\nenabled by fault injection methods such as Rowhammer, target model parameters\nin memory, compromising both integrity and performance. Identifying critical\nparameters for BFAs in the vast parameter space of LLMs poses significant\nchallenges. While prior research suggests transformer-based architectures are\ninherently more robust to BFAs compared to traditional deep neural networks, we\nchallenge this assumption. For the first time, we demonstrate that as few as\nthree bit-flips can cause catastrophic performance degradation in an LLM with\nbillions of parameters. Current BFA techniques are inadequate for exploiting\nthis vulnerability due to the difficulty of efficiently identifying critical\nparameters within the immense parameter space. To address this, we propose\nAttentionBreaker, a novel framework tailored for LLMs that enables efficient\ntraversal of the parameter space to identify critical parameters. Additionally,\nwe introduce GenBFA, an evolutionary optimization strategy designed to refine\nthe search further, isolating the most critical bits for an efficient and\neffective attack. Empirical results reveal the profound vulnerability of LLMs\nto AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of\ntotal parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result\nin a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to\n0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings\nunderscore the effectiveness of AttentionBreaker in uncovering and exploiting\ncritical vulnerabilities within LLM architectures."
  },
  {
    "arxiv_id": "2411.14896",
    "title": "Evaluating LLM Prompts for Data Augmentation in Multi-label Classification of Ecological Texts",
    "url": "http://arxiv.org/abs/2411.14896v1",
    "abstract": "Large language models (LLMs) play a crucial role in natural language\nprocessing (NLP) tasks, improving the understanding, generation, and\nmanipulation of human language across domains such as translating, summarizing,\nand classifying text. Previous studies have demonstrated that instruction-based\nLLMs can be effectively utilized for data augmentation to generate diverse and\nrealistic text samples. This study applied prompt-based data augmentation to\ndetect mentions of green practices in Russian social media. Detecting green\npractices in social media aids in understanding their prevalence and helps\nformulate recommendations for scaling eco-friendly actions to mitigate\nenvironmental issues. We evaluated several prompts for augmenting texts in a\nmulti-label classification task, either by rewriting existing datasets using\nLLMs, generating new data, or combining both approaches. Our results revealed\nthat all strategies improved classification performance compared to the models\nfine-tuned only on the original dataset, outperforming baselines in most cases.\nThe best results were obtained with the prompt that paraphrased the original\ntext while clearly indicating the relevant categories."
  },
  {
    "arxiv_id": "2411.14654",
    "title": "Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective",
    "url": "http://arxiv.org/abs/2411.14654v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\n(NLP) by delivering state-of-the-art performance across a variety of tasks.\nAmong these, Transformer-based models like BERT and GPT rely on pooling layers\nto aggregate token-level embeddings into sentence-level representations. Common\npooling mechanisms such as Mean, Max, and Weighted Sum play a pivotal role in\nthis aggregation process. Despite their widespread use, the comparative\nperformance of these strategies on different LLM architectures remains\nunderexplored. To address this gap, this paper investigates the effects of\nthese pooling mechanisms on two prominent LLM families -- BERT and GPT, in the\ncontext of sentence-level sentiment analysis. Comprehensive experiments reveal\nthat each pooling mechanism exhibits unique strengths and weaknesses depending\non the task's specific requirements. Our findings underline the importance of\nselecting pooling methods tailored to the demands of particular applications,\nprompting a re-evaluation of common assumptions regarding pooling operations.\nBy offering actionable insights, this study contributes to the optimization of\nLLM-based models for downstream tasks."
  },
  {
    "arxiv_id": "2411.14503",
    "title": "Planning-Driven Programming: A Large Language Model Programming Workflow",
    "url": "http://arxiv.org/abs/2411.14503v1",
    "abstract": "The strong performance of large language models (LLMs) raises extensive\ndiscussion on their application to code generation. Recent research suggests\ncontinuous program refinements through visible tests to improve code generation\naccuracy in LLMs. However, these methods suffer from LLMs' inefficiency and\nlimited reasoning capacity. In this work, we propose an LLM programming\nworkflow (LPW) designed to improve both initial code generation and subsequent\nrefinements within a structured two-phase workflow. Specifically, the solution\ngeneration phase formulates a solution plan, which is then verified through\nvisible tests to specify the intended natural language solution. Subsequently,\nthe code implementation phase drafts an initial code according to the solution\nplan and its verification. If the generated code fails the visible tests, the\nplan verification serves as the intended solution to consistently inform the\nrefinement process for correcting bugs. Compared to state-of-the-art methods\nacross various existing LLMs, LPW significantly improves the Pass@1 accuracy by\nup to 16.4% on well-established text-to-code generation benchmarks. LPW also\nsets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%\non MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using\nGPT-4o as the backbone."
  },
  {
    "arxiv_id": "2411.16594",
    "title": "From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge",
    "url": "http://arxiv.org/abs/2411.16594v1",
    "abstract": "Assessment and evaluation have long been critical challenges in artificial\nintelligence (AI) and natural language processing (NLP). However, traditional\nmethods, whether matching-based or embedding-based, often fall short of judging\nsubtle attributes and delivering satisfactory results. Recent advancements in\nLarge Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs\nare leveraged to perform scoring, ranking, or selection across various tasks\nand applications. This paper provides a comprehensive survey of LLM-based\njudgment and assessment, offering an in-depth overview to advance this emerging\nfield. We begin by giving detailed definitions from both input and output\nperspectives. Then we introduce a comprehensive taxonomy to explore\nLLM-as-a-judge from three dimensions: what to judge, how to judge and where to\njudge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and\nhighlight key challenges and promising directions, aiming to provide valuable\ninsights and inspire future research in this promising research area. Paper\nlist and more resources about LLM-as-a-judge can be found at\nhttps://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge and\nhttps://llm-as-a-judge.github.io."
  },
  {
    "arxiv_id": "2411.16561",
    "title": "EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code",
    "url": "http://arxiv.org/abs/2411.16561v1",
    "abstract": "Automated detection of software vulnerabilities is critical for enhancing\nsecurity, yet existing methods often struggle with the complexity and diversity\nof modern codebases. In this paper, we introduce EnStack, a novel ensemble\nstacking framework that enhances vulnerability detection using natural language\nprocessing (NLP) techniques. Our approach synergizes multiple pre-trained large\nlanguage models (LLMs) specialized in code understanding CodeBERT for semantic\nanalysis, GraphCodeBERT for structural representation, and UniXcoder for\ncross-modal capabilities. By fine-tuning these models on the Draper VDISC\ndataset and integrating their outputs through meta-classifiers such as Logistic\nRegression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack\neffectively captures intricate code patterns and vulnerabilities that\nindividual models may overlook. The meta-classifiers consolidate the strengths\nof each LLM, resulting in a comprehensive model that excels in detecting subtle\nand complex vulnerabilities across diverse programming contexts. Experimental\nresults demonstrate that EnStack significantly outperforms existing methods,\nachieving notable improvements in accuracy, precision, recall, and F1-score.\nThis work highlights the potential of ensemble LLM approaches in code analysis\ntasks and offers valuable insights into applying NLP techniques for advancing\nautomated vulnerability detection."
  },
  {
    "arxiv_id": "2411.16495",
    "title": "AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning",
    "url": "http://arxiv.org/abs/2411.16495v1",
    "abstract": "Despite the outstanding capabilities of large language models (LLMs),\nknowledge-intensive reasoning still remains a challenging task due to LLMs'\nlimitations in compositional reasoning and the hallucination problem. A\nprevalent solution is to employ chain-of-thought (CoT) with retrieval-augmented\ngeneration (RAG), which first formulates a reasoning plan by decomposing\ncomplex questions into simpler sub-questions, and then applies iterative RAG at\neach sub-question. However, prior works exhibit two crucial problems:\ninadequate reasoning planning and poor incorporation of heterogeneous\nknowledge. In this paper, we introduce AtomR, a framework for LLMs to conduct\naccurate heterogeneous knowledge reasoning at the atomic level. Inspired by how\nknowledge graph query languages model compositional reasoning through combining\npredefined operations, we propose three atomic knowledge operators, a unified\nset of operators for LLMs to retrieve and manipulate knowledge from\nheterogeneous sources. First, in the reasoning planning stage, AtomR decomposes\na complex question into a reasoning tree where each leaf node corresponds to an\natomic knowledge operator, achieving question decomposition that is highly\nfine-grained and orthogonal. Subsequently, in the reasoning execution stage,\nAtomR executes each atomic knowledge operator, which flexibly selects,\nretrieves, and operates atomic level knowledge from heterogeneous sources. We\nalso introduce BlendQA, a challenging benchmark specially tailored for\nheterogeneous knowledge reasoning. Experiments on three single-source and two\nmulti-source datasets show that AtomR outperforms state-of-the-art baselines by\na large margin, with F1 score improvements of 9.4% on 2WikiMultihop and 9.5% on\nBlendQA. We release our code and datasets."
  },
  {
    "arxiv_id": "2411.16433",
    "title": "Finding Structure in Language Models",
    "url": "http://arxiv.org/abs/2411.16433v1",
    "abstract": "When we speak, write or listen, we continuously make predictions based on our\nknowledge of a language's grammar. Remarkably, children acquire this\ngrammatical knowledge within just a few years, enabling them to understand and\ngeneralise to novel constructions that have never been uttered before. Language\nmodels are powerful tools that create representations of language by\nincrementally predicting the next word in a sentence, and they have had a\ntremendous societal impact in recent years. The central research question of\nthis thesis is whether these models possess a deep understanding of grammatical\nstructure similar to that of humans. This question lies at the intersection of\nnatural language processing, linguistics, and interpretability. To address it,\nwe will develop novel interpretability techniques that enhance our\nunderstanding of the complex nature of large-scale language models. We approach\nour research question from three directions. First, we explore the presence of\nabstract linguistic information through structural priming, a key paradigm in\npsycholinguistics for uncovering grammatical structure in human language\nprocessing. Next, we examine various linguistic phenomena, such as adjective\norder and negative polarity items, and connect a model's comprehension of these\nphenomena to the data distribution on which it was trained. Finally, we\nintroduce a controlled testbed for studying hierarchical structure in language\nmodels using various synthetic languages of increasing complexity and examine\nthe role of feature interactions in modelling this structure. Our findings\noffer a detailed account of the grammatical knowledge embedded in language\nmodel representations and provide several directions for investigating\nfundamental linguistic questions using computational methods."
  },
  {
    "arxiv_id": "2411.15734",
    "title": "Development of Pre-Trained Transformer-based Models for the Nepali Language",
    "url": "http://arxiv.org/abs/2411.15734v1",
    "abstract": "Transformer-based pre-trained language models have dominated the field of\nNatural Language Processing (NLP) for quite some time now. However, the Nepali\nlanguage, spoken by approximately 32 million people worldwide, remains\nsignificantly underrepresented in this domain. This underrepresentation is\nprimarily attributed to the scarcity of monolingual data corpora and limited\navailable resources for the Nepali language. While existing efforts have\npredominantly concentrated on basic encoder-based models, there is a notable\ngap in the exploration of decoder-based architectures. To address this gap, we\nhave collected 27.5 GB of Nepali text data, approximately 2.4x larger than any\npreviously available Nepali language corpus. Leveraging this data, we\npre-trained three different models i.e., BERT, RoBERTa, and GPT-2, exclusively\nfor the Nepali Language. Furthermore, we performed instruction tuning and\nexplored its potential for monolingual Nepali data, providing a foundation for\nfuture research. Our models outperformed the existing best model by 2 points on\nNep-gLUE benchmark, scoring 95.60 and also outperformed existing models on text\ngeneration tasks, demonstrating improvements in both understanding and\ngenerating Nepali text."
  },
  {
    "arxiv_id": "2411.17558",
    "title": "Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey",
    "url": "http://arxiv.org/abs/2411.17558v1",
    "abstract": "Visual Question Answering (VQA) is a challenge task that combines natural\nlanguage processing and computer vision techniques and gradually becomes a\nbenchmark test task in multimodal large language models (MLLMs). The goal of\nour survey is to provide an overview of the development of VQA and a detailed\ndescription of the latest models with high timeliness. This survey gives an\nup-to-date synthesis of natural language understanding of images and text, as\nwell as the knowledge reasoning module based on image-question information on\nthe core VQA tasks. In addition, we elaborate on recent advances in extracting\nand fusing modal information with vision-language pretraining models and\nmultimodal large language models in VQA. We also exhaustively review the\nprogress of knowledge reasoning in VQA by detailing the extraction of internal\nknowledge and the introduction of external knowledge. Finally, we present the\ndatasets of VQA and different evaluation metrics and discuss possible\ndirections for future work."
  },
  {
    "arxiv_id": "2411.17388",
    "title": "Can LLMs be Good Graph Judger for Knowledge Graph Construction?",
    "url": "http://arxiv.org/abs/2411.17388v1",
    "abstract": "In real-world scenarios, most of the data obtained from information retrieval\n(IR) system is unstructured. Converting natural language sentences into\nstructured Knowledge Graphs (KGs) remains a critical challenge. The quality of\nconstructed KGs may also impact the performance of some KG-dependent domains\nlike GraphRAG systems and recommendation systems. Recently, Large Language\nModels (LLMs) have demonstrated impressive capabilities in addressing a wide\nrange of natural language processing tasks. However, there are still challenges\nwhen utilizing LLMs to address the task of generating structured KGs. And we\nhave identified three limitations with respect to existing KG construction\nmethods. (1)There is a large amount of information and excessive noise in\nreal-world documents, which could result in extracting messy information.\n(2)Native LLMs struggle to effectively extract accuracy knowledge from some\ndomain-specific documents. (3)Hallucinations phenomenon cannot be overlooked\nwhen utilizing LLMs directly as an unsupervised method for constructing KGs.\n  In this paper, we propose GraphJudger, a knowledge graph construction\nframework to address the aforementioned challenges. We introduce three\ninnovative modules in our method, which are entity-centric iterative text\ndenoising, knowledge aware instruction tuning and graph judgement,\nrespectively. We seek to utilize the capacity of LLMs to function as a graph\njudger, a capability superior to their role only as a predictor for KG\nconstruction problems. Experiments conducted on two general text-graph pair\ndatasets and one domain-specific text-graph pair dataset show superior\nperformances compared to baseline methods. The code of our proposed method is\navailable at https://github.com/hhy-huang/GraphJudger."
  },
  {
    "arxiv_id": "2411.17123",
    "title": "Advancing Content Moderation: Evaluating Large Language Models for Detecting Sensitive Content Across Text, Images, and Videos",
    "url": "http://arxiv.org/abs/2411.17123v1",
    "abstract": "The widespread dissemination of hate speech, harassment, harmful and sexual\ncontent, and violence across websites and media platforms presents substantial\nchallenges and provokes widespread concern among different sectors of society.\nGovernments, educators, and parents are often at odds with media platforms\nabout how to regulate, control, and limit the spread of such content.\nTechnologies for detecting and censoring the media contents are a key solution\nto addressing these challenges. Techniques from natural language processing and\ncomputer vision have been used widely to automatically identify and filter out\nsensitive content such as offensive languages, violence, nudity, and addiction\nin both text, images, and videos, enabling platforms to enforce content\npolicies at scale. However, existing methods still have limitations in\nachieving high detection accuracy with fewer false positives and false\nnegatives. Therefore, more sophisticated algorithms for understanding the\ncontext of both text and image may open rooms for improvement in content\ncensorship to build a more efficient censorship system. In this paper, we\nevaluate existing LLM-based content moderation solutions such as OpenAI\nmoderation model and Llama-Guard3 and study their capabilities to detect\nsensitive contents. Additionally, we explore recent LLMs such as GPT, Gemini,\nand Llama in identifying inappropriate contents across media outlets. Various\ntextual and visual datasets like X tweets, Amazon reviews, news articles, human\nphotos, cartoons, sketches, and violence videos have been utilized for\nevaluation and comparison. The results demonstrate that LLMs outperform\ntraditional techniques by achieving higher accuracy and lower false positive\nand false negative rates. This highlights the potential to integrate LLMs into\nwebsites, social media platforms, and video-sharing services for regulatory and\ncontent moderation purposes."
  },
  {
    "arxiv_id": "2411.18583",
    "title": "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation",
    "url": "http://arxiv.org/abs/2411.18583v1",
    "abstract": "This research presents and compares multiple approaches to automate the\ngeneration of literature reviews using several Natural Language Processing\n(NLP) techniques and retrieval-augmented generation (RAG) with a Large Language\nModel (LLM). The ever-increasing number of research articles provides a huge\nchallenge for manual literature review. It has resulted in an increased demand\nfor automation. Developing a system capable of automatically generating the\nliterature reviews from only the PDF files as input is the primary objective of\nthis research work. The effectiveness of several Natural Language Processing\n(NLP) strategies, such as the frequency-based method (spaCy), the transformer\nmodel (Simple T5), and retrieval-augmented generation (RAG) with Large Language\nModel (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR\ndataset is chosen for this research experiment and three distinct techniques\nare utilized to implement three different systems for auto-generating the\nliterature reviews. The ROUGE scores are used for the evaluation of all three\nsystems. Based on the evaluation, the Large Language Model GPT-3.5-turbo\nachieved the highest ROUGE-1 score, 0.364. The transformer model comes in\nsecond place and spaCy is at the last position. Finally, a graphical user\ninterface is created for the best system based on the large language model."
  },
  {
    "arxiv_id": "2411.18280",
    "title": "Neutralizing Backdoors through Information Conflicts for Large Language Models",
    "url": "http://arxiv.org/abs/2411.18280v1",
    "abstract": "Large language models (LLMs) have seen significant advancements, achieving\nsuperior performance in various Natural Language Processing (NLP) tasks, from\nunderstanding to reasoning. However, they remain vulnerable to backdoor\nattacks, where models behave normally for standard queries but generate harmful\nresponses or unintended output when specific triggers are activated. Existing\nbackdoor defenses often suffer from drawbacks that they either focus on\ndetection without removal, rely on rigid assumptions about trigger properties,\nor prove to be ineffective against advanced attacks like multi-trigger\nbackdoors. In this paper, we present a novel method to eliminate backdoor\nbehaviors from LLMs through the construction of information conflicts using\nboth internal and external mechanisms. Internally, we leverage a lightweight\ndataset to train a conflict model, which is then merged with the backdoored\nmodel to neutralize malicious behaviors by embedding contradictory information\nwithin the model's parametric memory. Externally, we incorporate convincing\ncontradictory evidence into the prompt to challenge the model's internal\nbackdoor knowledge. Experimental results on classification and conversational\ntasks across 4 widely used LLMs demonstrate that our method outperforms 8\nstate-of-the-art backdoor defense baselines. We can reduce the attack success\nrate of advanced backdoor attacks by up to 98% while maintaining over 90% clean\ndata accuracy. Furthermore, our method has proven to be robust against adaptive\nbackdoor attacks. The code will be open-sourced upon publication."
  },
  {
    "arxiv_id": "2411.18157",
    "title": "A survey on cutting-edge relation extraction techniques based on language models",
    "url": "http://arxiv.org/abs/2411.18157v1",
    "abstract": "This comprehensive survey delves into the latest advancements in Relation\nExtraction (RE), a pivotal task in natural language processing essential for\napplications across biomedical, financial, and legal sectors. This study\nhighlights the evolution and current state of RE techniques by analyzing 137\npapers presented at the Association for Computational Linguistics (ACL)\nconferences over the past four years, focusing on models that leverage language\nmodels. Our findings underscore the dominance of BERT-based methods in\nachieving state-of-the-art results for RE while also noting the promising\ncapabilities of emerging large language models (LLMs) like T5, especially in\nfew-shot relation extraction scenarios where they excel in identifying\npreviously unseen relations."
  },
  {
    "arxiv_id": "2411.18148",
    "title": "A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs",
    "url": "http://arxiv.org/abs/2411.18148v1",
    "abstract": "Transformer neural networks (TNN) excel in natural language processing (NLP),\nmachine translation, and computer vision (CV) without relying on recurrent or\nconvolutional layers. However, they have high computational and memory demands,\nparticularly on resource-constrained devices like FPGAs. Moreover, transformer\nmodels vary in processing time across applications, requiring custom models\nwith specific parameters. Designing custom accelerators for each model is\ncomplex and time-intensive. Some custom accelerators exist with no runtime\nadaptability, and they often rely on sparse matrices to reduce latency.\nHowever, hardware designs become more challenging due to the need for\napplication-specific sparsity patterns. This paper introduces ADAPTOR, a\nruntime-adaptive accelerator for dense matrix computations in transformer\nencoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing\nelements and on-chip memory, enhancing parallelism and reducing latency. It\nincorporates efficient matrix tiling to distribute resources across FPGA\nplatforms and is fully quantized for computational efficiency and portability.\nEvaluations on Xilinx Alveo U55C data center cards and embedded platforms like\nVC707 and ZCU102 show that our design is 1.2$\\times$ and 2.87$\\times$ more\npower efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively.\nAdditionally, it achieves a speedup of 1.7 to 2.25$\\times$ compared to some\nstate-of-the-art FPGA-based accelerators."
  },
  {
    "arxiv_id": "2411.18104",
    "title": "Training and Evaluating Language Models with Template-based Data Generation",
    "url": "http://arxiv.org/abs/2411.18104v1",
    "abstract": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath."
  },
  {
    "arxiv_id": "2411.19253",
    "title": "Quantum feedback control with a transformer neural network architecture",
    "url": "http://arxiv.org/abs/2411.19253v1",
    "abstract": "Attention-based neural networks such as transformers have revolutionized\nvarious fields such as natural language processing, genomics, and vision. Here,\nwe demonstrate the use of transformers for quantum feedback control through a\nsupervised learning approach. In particular, due to the transformer's ability\nto capture long-range temporal correlations and training efficiency, we show\nthat it can surpass some of the limitations of previous control approaches,\ne.g.~those based on recurrent neural networks trained using a similar approach\nor reinforcement learning. We numerically show, for the example of state\nstabilization of a two-level system, that our bespoke transformer architecture\ncan achieve unit fidelity to a target state in a short time even in the\npresence of inefficient measurement and Hamiltonian perturbations that were not\nincluded in the training set. We also demonstrate that this approach\ngeneralizes well to the control of non-Markovian systems. Our approach can be\nused for quantum error correction, fast control of quantum states in the\npresence of colored noise, as well as real-time tuning, and characterization of\nquantum devices."
  },
  {
    "arxiv_id": "2411.19094",
    "title": "Beautimeter: Harnessing GPT for Assessing Architectural and Urban Beauty based on the 15 Properties of Living Structure",
    "url": "http://arxiv.org/abs/2411.19094v1",
    "abstract": "Beautimeter is a new tool powered by generative pre-trained transformer (GPT)\ntechnology, designed to evaluate architectural and urban beauty. Rooted in\nChristopher Alexander's theory of centers, this work builds on the idea that\nall environments possess, to varying degrees, an innate sense of life.\nAlexander identified 15 fundamental properties, such as levels of scale and\nthick boundaries, that characterize living structure, which Beautimeter uses as\na basis for its analysis. By integrating GPT's advanced natural language\nprocessing capabilities, Beautimeter assesses the extent to which a structure\nembodies these 15 properties, enabling a nuanced evaluation of architectural\nand urban aesthetics. Using ChatGPT, the tool helps users generate insights\ninto the perceived beauty and coherence of spaces. We conducted a series of\ncase studies, evaluating images of architectural and urban environments, as\nwell as carpets, paintings, and other artifacts. The results demonstrate\nBeautimeter's effectiveness in analyzing aesthetic qualities across diverse\ncontexts. Our findings suggest that by leveraging GPT technology, Beautimeter\noffers architects, urban planners, and designers a powerful tool to create\nspaces that resonate deeply with people. This paper also explores the\nimplications of such technology for architecture and urban design, highlighting\nits potential to enhance both the design process and the assessment of built\nenvironments. Keywords: Living structure, structural beauty, Christopher\nAlexander, AI in Design, human centered design"
  },
  {
    "arxiv_id": "2412.02323",
    "title": "Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script",
    "url": "http://arxiv.org/abs/2412.02323v1",
    "abstract": "The textual adversarial attack refers to an attack method in which the\nattacker adds imperceptible perturbations to the original texts by elaborate\ndesign so that the NLP (natural language processing) model produces false\njudgments. This method is also used to evaluate the robustness of NLP models.\nCurrently, most of the research in this field focuses on English, and there is\nalso a certain amount of research on Chinese. However, to the best of our\nknowledge, there is little research targeting Chinese minority languages.\nTextual adversarial attacks are a new challenge for the information processing\nof Chinese minority languages. In response to this situation, we propose a\nTibetan syllable-level black-box textual adversarial attack called TSAttacker\nbased on syllable cosine distance and scoring mechanism. And then, we conduct\nTSAttacker on six models generated by fine-tuning two PLMs (pre-trained\nlanguage models) for three downstream tasks. The experiment results show that\nTSAttacker is effective and generates high-quality adversarial samples. In\naddition, the robustness of the involved models still has much room for\nimprovement."
  },
  {
    "arxiv_id": "2412.02279",
    "title": "A Comprehensive Evaluation of Large Language Models on Aspect-Based Sentiment Analysis",
    "url": "http://arxiv.org/abs/2412.02279v1",
    "abstract": "Recently, Large Language Models (LLMs) have garnered increasing attention in\nthe field of natural language processing, revolutionizing numerous downstream\ntasks with powerful reasoning and generation abilities. For example, In-Context\nLearning (ICL) introduces a fine-tuning-free paradigm, allowing out-of-the-box\nLLMs to execute downstream tasks by analogy learning without any fine-tuning.\nBesides, in a fine-tuning-dependent paradigm where substantial training data\nexists, Parameter-Efficient Fine-Tuning (PEFT), as the cost-effective methods,\nenable LLMs to achieve excellent performance comparable to full fine-tuning.\n  However, these fascinating techniques employed by LLMs have not been fully\nexploited in the ABSA field. Previous works probe LLMs in ABSA by merely using\nrandomly selected input-output pairs as demonstrations in ICL, resulting in an\nincomplete and superficial evaluation. In this paper, we shed light on a\ncomprehensive evaluation of LLMs in the ABSA field, involving 13 datasets, 8\nABSA subtasks, and 6 LLMs. Specifically, we design a unified task formulation\nto unify ``multiple LLMs for multiple ABSA subtasks in multiple paradigms.''\nFor the fine-tuning-dependent paradigm, we efficiently fine-tune LLMs using\ninstruction-based multi-task learning. For the fine-tuning-free paradigm, we\npropose 3 demonstration selection strategies to stimulate the few-shot\nabilities of LLMs. Our extensive experiments demonstrate that LLMs achieve a\nnew state-of-the-art performance compared to fine-tuned Small Language Models\n(SLMs) in the fine-tuning-dependent paradigm. More importantly, in the\nfine-tuning-free paradigm where SLMs are ineffective, LLMs with ICL still\nshowcase impressive potential and even compete with fine-tuned SLMs on some\nABSA subtasks."
  },
  {
    "arxiv_id": "2412.02113",
    "title": "Trust & Safety of LLMs and LLMs in Trust & Safety",
    "url": "http://arxiv.org/abs/2412.02113v1",
    "abstract": "In recent years, Large Language Models (LLMs) have garnered considerable\nattention for their remarkable abilities in natural language processing tasks.\nHowever, their widespread adoption has raised concerns pertaining to trust and\nsafety. This systematic review investigates the current research landscape on\ntrust and safety in LLMs, with a particular focus on the novel application of\nLLMs within the field of Trust and Safety itself. We delve into the\ncomplexities of utilizing LLMs in domains where maintaining trust and safety is\nparamount, offering a consolidated perspective on this emerging trend.\\\n  By synthesizing findings from various studies, we identify key challenges and\npotential solutions, aiming to benefit researchers and practitioners seeking to\nunderstand the nuanced interplay between LLMs and Trust and Safety.\n  This review provides insights on best practices for using LLMs in Trust and\nSafety, and explores emerging risks such as prompt injection and jailbreak\nattacks. Ultimately, this study contributes to a deeper understanding of how\nLLMs can be effectively and responsibly utilized to enhance trust and safety in\nthe digital realm."
  },
  {
    "arxiv_id": "2412.01377",
    "title": "Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge",
    "url": "http://arxiv.org/abs/2412.01377v1",
    "abstract": "The increasing complexity of computer systems necessitates innovative\napproaches to fault and error management, going beyond traditional manual log\nanalysis. While existing solutions using large language models (LLMs) show\npromise, they are limited by a gap between natural and domain-specific\nlanguages, which restricts their effectiveness in real-world applications. Our\napproach addresses these limitations by integrating interpretable domain\nknowledge into open-source LLMs through continual pre-training (CPT), enhancing\nperformance on log tasks while retaining natural language processing\ncapabilities. We created a comprehensive dataset, NLPLog, with over 250,000\nquestion-answer pairs to facilitate this integration. Our model, SuperLog,\ntrained with this dataset, achieves the best performance across four log\nanalysis tasks, surpassing the second-best model by an average of 12.01%. Our\ncontributions include a novel CPT paradigm that significantly improves model\nperformance, the development of SuperLog with state-of-the-art results, and the\nrelease of a large-scale dataset to support further research in this domain."
  },
  {
    "arxiv_id": "2412.01312",
    "title": "Can ChatGPT pass a physics degree? Making a case for reformation of assessment of undergraduate degrees",
    "url": "http://arxiv.org/abs/2412.01312v1",
    "abstract": "The emergence of conversational natural language processing models presents a\nsignificant challenge for Higher Education. In this work, we use the entirety\nof a UK physics undergraduate (BSc with Honours) degree including all\nexaminations and coursework to test if ChatGPT (GPT-4) can pass a degree. We\nadopt a \"maximal cheating\" approach wherein we permit ourselves to modify\nquestions for clarity, split questions up into smaller sub-components, expand\non answers given - especially for long form written responses, obtaining\nreferences, and use of advanced coaching, plug-ins and custom instructions to\noptimize outputs. In general, there are only certain parts of the degree in\nquestion where GPT-4 fails. Explicitly these include compulsory laboratory\nelements, and the final project which is assessed by a viva. If these were no\nissue, then GPT-4 would pass with a grade of an upper second class overall. In\ngeneral, coding tasks are performed exceptionally well, along with simple\nsingle-step solution problems. Multiple step problems and longer prose are\ngenerally poorer along with interdisciplinary problems. We strongly suggest\nthat there is now a necessity to urgently re-think and revise assessment\npractice in physics - and other disciplines - due to the existence of AI such\nas GPT-4. We recommend close scrutiny of assessment tasks: only invigilated\nin-person examinations, vivas, laboratory skills testing (or \"performances\" in\nother disciplines), and presentations are not vulnerable to GPT-4, and urge\nconsideration of how AI can be embedded within the disciplinary context."
  },
  {
    "arxiv_id": "2412.01269",
    "title": "CPRM: A LLM-based Continual Pre-training Framework for Relevance Modeling in Commercial Search",
    "url": "http://arxiv.org/abs/2412.01269v2",
    "abstract": "Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines."
  },
  {
    "arxiv_id": "2412.03107",
    "title": "CredID: Credible Multi-Bit Watermark for Large Language Models Identification",
    "url": "http://arxiv.org/abs/2412.03107v1",
    "abstract": "Large Language Models (LLMs) are widely used in complex natural language\nprocessing tasks but raise privacy and security concerns due to the lack of\nidentity recognition. This paper proposes a multi-party credible watermarking\nframework (CredID) involving a trusted third party (TTP) and multiple LLM\nvendors to address these issues. In the watermark embedding stage, vendors\nrequest a seed from the TTP to generate watermarked text without sending the\nuser's prompt. In the extraction stage, the TTP coordinates each vendor to\nextract and verify the watermark from the text. This provides a credible\nwatermarking scheme while preserving vendor privacy. Furthermore, current\nwatermarking algorithms struggle with text quality, information capacity, and\nrobustness, making it challenging to meet the diverse identification needs of\nLLMs. Thus, we propose a novel multi-bit watermarking algorithm and an\nopen-source toolkit to facilitate research. Experiments show our CredID\nenhances watermark credibility and efficiency without compromising text\nquality. Additionally, we successfully utilized this framework to achieve\nhighly accurate identification among multiple LLM vendors."
  },
  {
    "arxiv_id": "2412.03075",
    "title": "ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction",
    "url": "http://arxiv.org/abs/2412.03075v1",
    "abstract": "Automatic speech Recognition (ASR) is a fundamental and important task in the\nfield of speech and natural language processing. It is an inherent building\nblock in many applications such as voice assistant, speech translation, etc.\nDespite the advancement of ASR technologies in recent years, it is still\ninevitable for modern ASR systems to have a substantial number of erroneous\nrecognition due to environmental noise, ambiguity, etc. Therefore, the error\ncorrection in ASR is crucial.\n  Motivated by this, this paper studies ASR error correction in the Chinese\nlanguage, which is one of the most popular languages and enjoys a large number\nof users in the world. We first create a benchmark dataset named \\emph{ASR-EC}\nthat contains a wide spectrum of ASR errors generated by industry-grade ASR\nsystems. To the best of our knowledge, it is the first Chinese ASR error\ncorrection benchmark. Then, inspired by the recent advances in \\emph{large\nlanguage models (LLMs)}, we investigate how to harness the power of LLMs to\ncorrect ASR errors. We apply LLMs to ASR error correction in three paradigms.\nThe first paradigm is prompting, which is further categorized as zero-shot,\nfew-shot, and multi-step. The second paradigm is finetuning, which finetunes\nLLMs with ASR error correction data. The third paradigm is multi-modal\naugmentation, which collectively utilizes the audio and ASR transcripts for\nerror correction. Extensive experiments reveal that prompting is not effective\nfor ASR error correction. Finetuning is effective only for a portion of LLMs.\nMulti-modal augmentation is the most effective method for error correction and\nachieves state-of-the-art performance."
  },
  {
    "arxiv_id": "2412.02904",
    "title": "Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning",
    "url": "http://arxiv.org/abs/2412.02904v1",
    "abstract": "Large language models (LLMs) have revolutionized the field of natural\nlanguage processing with their impressive reasoning and question-answering\ncapabilities. However, these models are sometimes prone to generating\ncredible-sounding but incorrect information, a phenomenon known as LLM\nhallucinations. Reliable uncertainty estimation in LLMs is essential for\nfostering trust in their generated responses and serves as a critical tool for\nthe detection and prevention of erroneous or hallucinated outputs. To achieve\nreliable and well-calibrated uncertainty quantification in open-ended and\nfree-form natural language generation, we propose an uncertainty-aware\nfine-tuning approach for LLMs. This approach enhances the model's ability to\nprovide reliable uncertainty estimates without compromising accuracy, thereby\nguiding them to produce more trustworthy responses. We introduce a novel\nuncertainty-aware causal language modeling loss function, grounded in the\nprinciples of decision theory. Through rigorous evaluation on multiple\nfree-form question-answering datasets and models, we demonstrate that our\nuncertainty-aware fine-tuning approach yields better calibrated uncertainty\nestimates in natural language generation tasks than fine-tuning with the\nstandard causal language modeling loss. Furthermore, the experimental results\nshow that the proposed method significantly improves the model's ability to\ndetect hallucinations and identify out-of-domain prompts."
  },
  {
    "arxiv_id": "2412.04446",
    "title": "DiCoDe: Diffusion-Compressed Deep Tokens for Autoregressive Video Generation with Language Models",
    "url": "http://arxiv.org/abs/2412.04446v1",
    "abstract": "Videos are inherently temporal sequences by their very nature. In this work,\nwe explore the potential of modeling videos in a chronological and scalable\nmanner with autoregressive (AR) language models, inspired by their success in\nnatural language processing. We introduce DiCoDe, a novel approach that\nleverages Diffusion-Compressed Deep Tokens to generate videos with a language\nmodel in an autoregressive manner. Unlike existing methods that employ\nlow-level representations with limited compression rates, DiCoDe utilizes deep\ntokens with a considerable compression rate (a 1000x reduction in token count).\nThis significant compression is made possible by a tokenizer trained through\nleveraging the prior knowledge of video diffusion models. Deep tokens enable\nDiCoDe to employ vanilla AR language models for video generation, akin to\ntranslating one visual \"language\" into another. By treating videos as temporal\nsequences, DiCoDe fully harnesses the capabilities of language models for\nautoregressive generation. DiCoDe is scalable using readily available AR\narchitectures, and is capable of generating videos ranging from a few seconds\nto one minute using only 4 A100 GPUs for training. We evaluate DiCoDe both\nquantitatively and qualitatively, demonstrating that it performs comparably to\nexisting methods in terms of quality while ensuring efficient training. To\nshowcase its scalability, we release a series of DiCoDe configurations with\nvarying parameter sizes and observe a consistent improvement in performance as\nthe model size increases from 100M to 3B. We believe that DiCoDe's exploration\nin academia represents a promising initial step toward scalable video modeling\nwith AR language models, paving the way for the development of larger and more\npowerful video generation models."
  },
  {
    "arxiv_id": "2412.03831",
    "title": "A large language model-type architecture for high-dimensional molecular potential energy surfaces",
    "url": "http://arxiv.org/abs/2412.03831v1",
    "abstract": "Computing high dimensional potential surfaces for molecular and materials\nsystems is considered to be a great challenge in computational chemistry with\npotential impact in a range of areas including fundamental prediction of\nreaction rates. In this paper we design and discuss an algorithm that has\nsimilarities to large language models in generative AI and natural language\nprocessing. Specifically, we represent a molecular system as a graph which\ncontains a set of nodes, edges, faces etc. Interactions between these sets,\nwhich represent molecular subsystems in our case, are used to construct the\npotential energy surface for a reasonably sized chemical system with 51\ndimensions. Essentially a family of neural networks that pertain to the\ngraph-based subsystems, get the job done for this 51 dimensional system. We\nthen ask if this same family of lower-dimensional neural networks can be\ntransformed to provide accurate predictions for a 186 dimensional potential\nsurface. We find that our algorithm does provide reasonably accurate results\nfor this larger dimensional problem with sub-kcal/mol accuracy for the higher\ndimensional potential surface problem."
  },
  {
    "arxiv_id": "2412.03772",
    "title": "A Contemporary Overview: Trends and Applications of Large Language Models on Mobile Devices",
    "url": "http://arxiv.org/abs/2412.03772v1",
    "abstract": "With the rapid development of large language models (LLMs), which possess\npowerful natural language processing and generation capabilities, LLMs are\npoised to provide more natural and personalized user experiences. Their\ndeployment on mobile devices is gradually becoming a significant trend in the\nfield of intelligent devices. LLMs have demonstrated tremendous potential in\napplications such as voice assistants, real-time translation, and intelligent\nrecommendations. Advancements in hardware technologies (such as neural network\naccelerators) and network infrastructure (such as 5G) have enabled efficient\nlocal inference and low-latency intelligent responses on mobile devices. This\nreduces reliance on cloud computing while enhancing data privacy and security.\nDevelopers can easily integrate LLM functionalities through open APIs and SDKs,\nenabling the creation of more innovative intelligent applications. The\nwidespread use of LLMs not only enhances the intelligence of mobile devices but\nalso fosters the integrated innovation of fields like augmented reality (AR)\nand the Internet of Things (IoT). This trend is expected to drive the\ndevelopment of the next generation of mobile intelligent applications."
  },
  {
    "arxiv_id": "2412.04925",
    "title": "$S^3$: Synonymous Semantic Space for Improving Zero-Shot Generalization of Vision-Language Models",
    "url": "http://arxiv.org/abs/2412.04925v1",
    "abstract": "Recently, many studies have been conducted to enhance the zero-shot\ngeneralization ability of vision-language models (e.g., CLIP) by addressing the\nsemantic misalignment between image and text embeddings in downstream tasks.\nAlthough many efforts have been made, existing methods barely consider the fact\nthat a class of images can be described by notably different textual concepts\ndue to well-known lexical variation in natural language processing, which\nheavily affects the zero-shot generalization of CLIP. Therefore, this paper\nproposes a \\textbf{S}ynonymous \\textbf{S}emantic \\textbf{S}pace ($S^3$) for\neach image class, rather than relying on a single textual concept, achieving\nmore stable semantic alignment and improving the zero-shot generalization of\nCLIP. Specifically, our $S^3$ method first generates several synonymous\nconcepts based on the label of each class by using large language models, and\nconstructs a continuous yet compact synonymous semantic space based on the\nVietoris-Rips complex of the generated synonymous concepts. Furthermore, we\nexplore the effect of several point-to-space metrics on our $S^3$, while\npresenting a point-to-local-center metric to compute similarity between image\nembeddings and the synonymous semantic space of each class, accomplishing\neffective zero-shot predictions. Extensive experiments are conducted across 17\nbenchmarks, including fine-grained zero-shot classification, natural\ndistribution zero-shot classification, and open-vocabulary segmentation, and\nthe results show that our $S^3$ outperforms state-of-the-art methods."
  },
  {
    "arxiv_id": "2412.04718",
    "title": "Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training",
    "url": "http://arxiv.org/abs/2412.04718v1",
    "abstract": "With the rapid development of natural language processing technology,\nlarge-scale language models (LLM) have achieved remarkable results in a variety\nof tasks. However, how to effectively train these huge models and improve their\nperformance and computational efficiency remains an important challenge. This\npaper proposes an improved method based on adaptive optimization algorithm,\naiming to improve the training efficiency and final performance of LLM. Through\ncomparative experiments on the SQuAD and GLUE data sets, the experimental\nresults show that compared with traditional optimization algorithms (such as\nSGD, Momentum, AdaGrad, RMSProp and Adam), the adaptive optimization algorithm\nwe proposed has better accuracy and F1 score. Both have achieved significant\nimprovements, especially showed stronger training capabilities when processed\nlarge-scale texts and complex tasks. The research results verify the advantages\nof adaptive optimization algorithms in large-scale language model training and\nprovide new ideas and directions for future optimization methods."
  },
  {
    "arxiv_id": "2412.04680",
    "title": "Superpixel Tokenization for Vision Transformers: Preserving Semantic Integrity in Visual Tokens",
    "url": "http://arxiv.org/abs/2412.04680v1",
    "abstract": "Transformers, a groundbreaking architecture proposed for Natural Language\nProcessing (NLP), have also achieved remarkable success in Computer Vision. A\ncornerstone of their success lies in the attention mechanism, which models\nrelationships among tokens. While the tokenization process in NLP inherently\nensures that a single token does not contain multiple semantics, the\ntokenization of Vision Transformer (ViT) utilizes tokens from uniformly\npartitioned square image patches, which may result in an arbitrary mixing of\nvisual concepts in a token. In this work, we propose to substitute the\ngrid-based tokenization in ViT with superpixel tokenization, which employs\nsuperpixels to generate a token that encapsulates a sole visual concept.\nUnfortunately, the diverse shapes, sizes, and locations of superpixels make\nintegrating superpixels into ViT tokenization rather challenging. Our\ntokenization pipeline, comprised of pre-aggregate extraction and\nsuperpixel-aware aggregation, overcomes the challenges that arise in superpixel\ntokenization. Extensive experiments demonstrate that our approach, which\nexhibits strong compatibility with existing frameworks, enhances the accuracy\nand robustness of ViT on various downstream tasks."
  },
  {
    "arxiv_id": "2412.06239",
    "title": "Unseen Attack Detection in Software-Defined Networking Using a BERT-Based Large Language Model",
    "url": "http://arxiv.org/abs/2412.06239v1",
    "abstract": "Software defined networking (SDN) represents a transformative shift in\nnetwork architecture by decoupling the control plane from the data plane,\nenabling centralized and flexible management of network resources. However,\nthis architectural shift introduces significant security challenges, as SDN's\ncentralized control becomes an attractive target for various types of attacks.\nWhile current research has yielded valuable insights into attack detection in\nSDN, critical gaps remain. Addressing challenges in feature selection,\nbroadening the scope beyond DDoS attacks, strengthening attack decisions based\non multi flow analysis, and building models capable of detecting unseen attacks\nthat they have not been explicitly trained on are essential steps toward\nadvancing security in SDN. In this paper, we introduce a novel approach that\nleverages Natural Language Processing (NLP) and the pre trained BERT base model\nto enhance attack detection in SDN. Our approach transforms network flow data\ninto a format interpretable by language models, allowing BERT to capture\nintricate patterns and relationships within network traffic. By using Random\nForest for feature selection, we optimize model performance and reduce\ncomputational overhead, ensuring accurate detection. Attack decisions are made\nbased on several flows, providing stronger and more reliable detection of\nmalicious traffic. Furthermore, our approach is specifically designed to detect\npreviously unseen attacks, offering a solution for identifying threats that the\nmodel was not explicitly trained on. To rigorously evaluate our approach, we\nconducted experiments in two scenarios: one focused on detecting known attacks,\nachieving 99.96% accuracy, and another on detecting unseen attacks, where our\nmodel achieved 99.96% accuracy, demonstrating the robustness of our approach in\ndetecting evolving threats to improve the security of SDN networks."
  },
  {
    "arxiv_id": "2412.06113",
    "title": "Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions",
    "url": "http://arxiv.org/abs/2412.06113v1",
    "abstract": "The rapid advancement of large language models (LLMs) has revolutionized\nnatural language processing, enabling applications in diverse domains such as\nhealthcare, finance and education. However, the growing reliance on extensive\ndata for training and inference has raised significant privacy concerns,\nranging from data leakage to adversarial attacks. This survey comprehensively\nexplores the landscape of privacy-preserving mechanisms tailored for LLMs,\nincluding differential privacy, federated learning, cryptographic protocols,\nand trusted execution environments. We examine their efficacy in addressing key\nprivacy challenges, such as membership inference and model inversion attacks,\nwhile balancing trade-offs between privacy and model utility. Furthermore, we\nanalyze privacy-preserving applications of LLMs in privacy-sensitive domains,\nhighlighting successful implementations and inherent limitations. Finally, this\nsurvey identifies emerging research directions, emphasizing the need for novel\nframeworks that integrate privacy by design into the lifecycle of LLMs. By\nsynthesizing state-of-the-art approaches and future trends, this paper provides\na foundation for developing robust, privacy-preserving large language models\nthat safeguard sensitive information without compromising performance."
  },
  {
    "arxiv_id": "2412.06106",
    "title": "Enhanced Computationally Efficient Long LoRA Inspired Perceiver Architectures for Auto-Regressive Language Modeling",
    "url": "http://arxiv.org/abs/2412.06106v1",
    "abstract": "The Transformer architecture has revolutionized the Natural Language\nProcessing field and is the backbone of Large Language Models (LLMs). The\nTransformer uses the attention mechanism that computes the pair-wise similarity\nbetween its input tokens to produce latent vectors that are able to understand\nthe semantic meaning of the input text. One of the challenges in the\nTransformer architecture is the quadratic complexity of the attention mechanism\nthat prohibits the efficient processing of long sequence lengths. While many\nrecent research works have attempted to provide a reduction from $O(n^2)$ time\ncomplexity of attention to semi-linear complexity, it remains an unsolved\nproblem in the sense of maintaining a high performance when such complexity is\nreduced. One of the important works in this respect is the Perceiver class of\narchitectures that have demonstrated excellent performance while reducing the\ncomputation complexity. In this paper, we use the PerceiverAR that was proposed\nfor Auto-Regressive modeling as a baseline, and provide three different\narchitectural enhancements to it with varying computation overhead tradeoffs.\nInspired by the recently proposed efficient attention computation approach of\nLong-LoRA, we then present an equally efficient Perceiver-based architecture\n(termed as Long LoRA Pereceiver - LLP) that can be used as the base\narchitecture in LLMs instead of just a fine-tuning add-on. Our results on\ndifferent benchmarks indicate impressive improvements compared to recent\nTransformer based models."
  },
  {
    "arxiv_id": "2412.05749",
    "title": "A Comparative Study on Code Generation with Transformers",
    "url": "http://arxiv.org/abs/2412.05749v1",
    "abstract": "In an era of widespread influence of Natural Language Processing (NLP), there\nhave been multiple research efforts to supplant traditional manual coding\ntechniques with automated systems capable of generating solutions autonomously.\nWith rapid research for code generation and a sole focus on large language\nmodels, there emerges a need to compare and evaluate the performance of\ntransformer architectures based on several complexities of the model. This\npaper introduces the concept of a \"A Comparative Study on Code Generation with\nTransformers,\" a model based on Transformer architecture, and NLP methodologies\nto automatically generate C++ source code for different varieties of problems.\nHere, a comparative study is performed to evaluate the robustness of\ntransformer-based models on the basis of their architecture complexities and\ntheir capability to handle diverse problem sets, from basic arithmetic to\ncomplex computations."
  },
  {
    "arxiv_id": "2412.07355",
    "title": "Towards Predictive Communication with Brain-Computer Interfaces integrating Large Language Models",
    "url": "http://arxiv.org/abs/2412.07355v1",
    "abstract": "This perspective article aims at providing an outline of the state of the art\nand future developments towards the integration of cutting-edge predictive\nlanguage models with BCI. A synthetic overview of early and more recent\nlinguistic models, from natural language processing (NLP) models to recent LLM,\nthat to a varying extent improved predictive writing systems, is first\nprovided. Second, a summary of previous BCI implementations integrating\nlanguage models is presented. The few preliminary studies investigating the\npossible combination of LLM with BCI spellers to efficiently support fast\ncommunication and control are then described. Finally, current challenges and\nlimitations towards the full integration of LLM with BCI systems are discussed.\nRecent investigations suggest that the combination of LLM with BCI might\ndrastically improve human-computer interaction in patients with motor or\nlanguage disorders as well as in healthy individuals. In particular, the\npretrained autoregressive transformer models, such as GPT, that capitalize from\nparallelization, learning through pre-training and fine-tuning, promise a\nsubstantial improvement of BCI for communication with respect to previous\nsystems incorporating simpler language models. Indeed, among various models,\nthe GPT-2 was shown to represent an excellent candidate for its integration\ninto BCI although testing was only perfomed on simulated conversations and not\non real BCI scenarios. Prospectively, the full integration of LLM with advanced\nBCI systems might lead to a big leap forward towards fast, efficient and\nuser-adaptive neurotechnology."
  },
  {
    "arxiv_id": "2412.07201",
    "title": "A Review on the Applications of Transformer-based language models for Nucleotide Sequence Analysis",
    "url": "http://arxiv.org/abs/2412.07201v1",
    "abstract": "In recent times, Transformer-based language models are making quite an impact\nin the field of natural language processing. As relevant parallels can be drawn\nbetween biological sequences and natural languages, the models used in NLP can\nbe easily extended and adapted for various applications in bioinformatics. In\nthis regard, this paper introduces the major developments of Transformer-based\nmodels in the recent past in the context of nucleotide sequences. We have\nreviewed and analysed a large number of application-based papers on this\nsubject, giving evidence of the main characterizing features and to different\napproaches that may be adopted to customize such powerful computational\nmachines. We have also provided a structured description of the functioning of\nTransformers, that may enable even first time users to grab the essence of such\ncomplex architectures. We believe this review will help the scientific\ncommunity in understanding the various applications of Transformer-based\nlanguage models to nucleotide sequences. This work will motivate the readers to\nbuild on these methodologies to tackle also various other problems in the field\nof bioinformatics."
  },
  {
    "arxiv_id": "2412.07171",
    "title": "Breaking the Stage Barrier: A Novel Single-Stage Approach to Long Context Extension for Large Language Models",
    "url": "http://arxiv.org/abs/2412.07171v1",
    "abstract": "Recently, Large language models (LLMs) have revolutionized Natural Language\nProcessing (NLP). Pretrained LLMs, due to limited training context size,\nstruggle with handling long token sequences, limiting their performance on\nvarious downstream tasks. Current solutions toward long context modeling often\nemploy multi-stage continual pertaining, which progressively increases the\neffective context length through several continual pretraining stages. However,\nthose approaches require extensive manual tuning and human expertise. In this\npaper, we introduce a novel single-stage continual pretraining method,\nHead-Adaptive Rotary Position Encoding (HARPE), to equip LLMs with long context\nmodeling capabilities while simplifying the training process. Our HARPE\nleverages different Rotary Position Encoding (RoPE) base frequency values\nacross different attention heads and directly trains LLMs on the target context\nlength. Extensive experiments on 4 language modeling benchmarks, including the\nlatest RULER benchmark, demonstrate that HARPE excels in understanding and\nintegrating long-context tasks with single-stage training, matching and even\noutperforming existing multi-stage methods. Our results highlight that HARPE\nsuccessfully breaks the stage barrier for training LLMs with long context\nmodeling capabilities."
  },
  {
    "arxiv_id": "2412.06926",
    "title": "When Every Token Counts: Optimal Segmentation for Low-Resource Language Models",
    "url": "http://arxiv.org/abs/2412.06926v1",
    "abstract": "Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP."
  },
  {
    "arxiv_id": "2412.08430",
    "title": "Assessing Personalized AI Mentoring with Large Language Models in the Computing Field",
    "url": "http://arxiv.org/abs/2412.08430v1",
    "abstract": "This paper provides an in-depth evaluation of three state-of-the-art Large\nLanguage Models (LLMs) for personalized career mentoring in the computing\nfield, using three distinct student profiles that consider gender, race, and\nprofessional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2\nusing a zero-shot learning approach without human intervention. A quantitative\nevaluation was conducted through a custom natural language processing analytics\npipeline to highlight the uniqueness of the responses and to identify words\nreflecting each student's profile, including race, gender, or professional\nlevel. The analysis of frequently used words in the responses indicates that\nGPT-4 offers more personalized mentoring compared to the other two LLMs.\nAdditionally, a qualitative evaluation was performed to see if human experts\nreached similar conclusions. The analysis of survey responses shows that GPT-4\noutperformed the other two LLMs in delivering more accurate and useful\nmentoring while addressing specific challenges with encouragement languages.\nOur work establishes a foundation for developing personalized mentoring tools\nbased on LLMs, incorporating human mentors in the process to deliver a more\nimpactful and tailored mentoring experience."
  },
  {
    "arxiv_id": "2412.08414",
    "title": "Detecting Conversational Mental Manipulation with Intent-Aware Prompting",
    "url": "http://arxiv.org/abs/2412.08414v1",
    "abstract": "Mental manipulation severely undermines mental wellness by covertly and\nnegatively distorting decision-making. While there is an increasing interest in\nmental health care within the natural language processing community, progress\nin tackling manipulation remains limited due to the complexity of detecting\nsubtle, covert tactics in conversations. In this paper, we propose Intent-Aware\nPrompting (IAP), a novel approach for detecting mental manipulations using\nlarge language models (LLMs), providing a deeper understanding of manipulative\ntactics by capturing the underlying intents of participants. Experimental\nresults on the MentalManip dataset demonstrate superior effectiveness of IAP\nagainst other advanced prompting strategies. Notably, our approach\nsubstantially reduces false negatives, helping detect more instances of mental\nmanipulation with minimal misjudgment of positive cases. The code of this paper\nis available at https://github.com/Anton-Jiayuan-MA/Manip-IAP."
  },
  {
    "arxiv_id": "2412.08392",
    "title": "The Roles of English in Evaluating Multilingual Language Models",
    "url": "http://arxiv.org/abs/2412.08392v1",
    "abstract": "Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding."
  },
  {
    "arxiv_id": "2412.09165",
    "title": "When Text Embedding Meets Large Language Model: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2412.09165v1",
    "abstract": "Text embedding has become a foundational technology in natural language\nprocessing (NLP) during the deep learning era, driving advancements across a\nwide array of downstream tasks. While many natural language understanding\nchallenges can now be modeled using generative paradigms and leverage the\nrobust generative and comprehension capabilities of large language models\n(LLMs), numerous practical applications - such as semantic matching,\nclustering, and information retrieval - continue to rely on text embeddings for\ntheir efficiency and effectiveness. Therefore, integrating LLMs with text\nembeddings has become a major research focus in recent years. In this survey,\nwe categorize the interplay between LLMs and text embeddings into three\noverarching themes: (1) LLM-augmented text embedding, enhancing traditional\nembedding methods with LLMs; (2) LLMs as text embedders, adapting their innate\ncapabilities for high-quality embedding; and (3) Text embedding understanding\nwith LLMs, leveraging LLMs to analyze and interpret embeddings. By organizing\nrecent works based on interaction patterns rather than specific downstream\napplications, we offer a novel and systematic overview of contributions from\nvarious research and application domains in the era of LLMs. Furthermore, we\nhighlight the unresolved challenges that persisted in the pre-LLM era with\npre-trained language models (PLMs) and explore the emerging obstacles brought\nforth by LLMs. Building on this analysis, we outline prospective directions for\nthe evolution of text embedding, addressing both theoretical and practical\nopportunities in the rapidly advancing landscape of NLP."
  },
  {
    "arxiv_id": "2412.09094",
    "title": "Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion",
    "url": "http://arxiv.org/abs/2412.09094v1",
    "abstract": "Large Language Models (LLMs) present massive inherent knowledge and superior\nsemantic comprehension capability, which have revolutionized various tasks in\nnatural language processing. Despite their success, a critical gap remains in\nenabling LLMs to perform knowledge graph completion (KGC). Empirical evidence\nsuggests that LLMs consistently perform worse than conventional KGC approaches,\neven through sophisticated prompt design or tailored instruction-tuning.\nFundamentally, applying LLMs on KGC introduces several critical challenges,\nincluding a vast set of entity candidates, hallucination issue of LLMs, and\nunder-exploitation of the graph structure. To address these challenges, we\npropose a novel instruction-tuning-based method, namely FtG. Specifically, we\npresent a filter-then-generate paradigm and formulate the KGC task into a\nmultiple-choice question format. In this way, we can harness the capability of\nLLMs while mitigating the issue casused by hallucinations. Moreover, we devise\na flexible ego-graph serialization prompt and employ a structure-text adapter\nto couple structure and text information in a contextualized manner.\nExperimental results demonstrate that FtG achieves substantial performance gain\ncompared to existing state-of-the-art methods. The instruction dataset and code\nare available at https://github.com/LB0828/FtG."
  },
  {
    "arxiv_id": "2412.12094",
    "title": "SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator",
    "url": "http://arxiv.org/abs/2412.12094v1",
    "abstract": "Large Language Models (LLMs) have exhibited exceptional performance across a\nspectrum of natural language processing tasks. However, their substantial sizes\npose considerable challenges, particularly in computational demands and\ninference speed, due to their quadratic complexity. In this work, we have\nidentified a key pattern: certain seemingly meaningless separator tokens (i.e.,\npunctuations) contribute disproportionately to attention scores compared to\nsemantically meaningful tokens. This observation suggests that information of\nthe segments between these separator tokens can be effectively condensed into\nthe separator tokens themselves without significant information loss. Guided by\nthis insight, we introduce SepLLM, a plug-and-play framework that accelerates\ninference by compressing these segments and eliminating redundant tokens.\nAdditionally, we implement efficient kernels for training acceleration.\nExperimental results across training-free, training-from-scratch, and\npost-training settings demonstrate SepLLM's effectiveness. Notably, using the\nLlama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the\nGSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in\nstreaming settings, SepLLM effectively processes sequences of up to 4 million\ntokens or more while maintaining consistent language modeling capabilities."
  },
  {
    "arxiv_id": "2412.12004",
    "title": "The Open Source Advantage in Large Language Models (LLMs)",
    "url": "http://arxiv.org/abs/2412.12004v1",
    "abstract": "Large language models (LLMs) have rapidly advanced natural language\nprocessing, driving significant breakthroughs in tasks such as text generation,\nmachine translation, and domain-specific reasoning. The field now faces a\ncritical dilemma in its approach: closed-source models like GPT-4 deliver\nstate-of-the-art performance but restrict reproducibility, accessibility, and\nexternal oversight, while open-source frameworks like LLaMA and Mixtral\ndemocratize access, foster collaboration, and support diverse applications,\nachieving competitive results through techniques like instruction tuning and\nLoRA. Hybrid approaches address challenges like bias mitigation and resource\naccessibility by combining the scalability of closed-source systems with the\ntransparency and inclusivity of open-source framework. However, in this\nposition paper, we argue that open-source remains the most robust path for\nadvancing LLM research and ethical deployment."
  },
  {
    "arxiv_id": "2412.11629",
    "title": "QPruner: Probabilistic Decision Quantization for Structured Pruning in Large Language Models",
    "url": "http://arxiv.org/abs/2412.11629v1",
    "abstract": "The rise of large language models (LLMs) has significantly advanced various\nnatural language processing (NLP) tasks. However, the resource demands of these\nmodels pose substantial challenges. Structured pruning is an effective approach\nto reducing model size, but it often results in significant accuracy\ndegradation, necessitating parameter updates to adapt. Unfortunately, such\nfine-tuning requires substantial memory, which limits its applicability. To\naddress these challenges, we introduce quantization into the structured pruning\nframework to reduce memory consumption during both fine-tuning and inference.\nHowever, the combined errors from pruning and quantization increase the\ndifficulty of fine-tuning, requiring a more refined quantization scheme. To\nthis end, we propose QPruner, a novel framework that employs structured pruning\nto reduce model size, followed by a layer-wise mixed-precision quantization\nscheme. Quantization precisions are assigned to each layer based on their\nimportance to the target task, and Bayesian optimization is employed to refine\nprecision allocation strategies, ensuring a balance between model accuracy and\nmemory efficiency. Extensive experiments on benchmark datasets demonstrate that\nQPruner significantly outperforms existing methods in memory savings while\nmaintaining or improving model performance."
  },
  {
    "arxiv_id": "2412.12981",
    "title": "Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health",
    "url": "http://arxiv.org/abs/2412.12981v1",
    "abstract": "Large language models (LLMs) have shown promising capabilities in healthcare\nanalysis but face several challenges like hallucinations, parroting, and bias\nmanifestation. These challenges are exacerbated in complex, sensitive, and\nlow-resource domains. Therefore, in this work we introduce IC-AnnoMI, an\nexpert-annotated motivational interviewing (MI) dataset built upon AnnoMI by\ngenerating in-context conversational dialogues leveraging LLMs, particularly\nChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues\nand tailored information, taking into account therapy style (empathy,\nreflection), contextual relevance, and false semantic change. Subsequently, the\ndialogues are annotated by experts, strictly adhering to the Motivational\nInterviewing Skills Code (MISC), focusing on both the psychological and\nlinguistic dimensions of MI dialogues. We comprehensively evaluate the\nIC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding\nof domain intricacies by modeling novel classification tasks employing several\nclassical machine learning and current state-of-the-art transformer approaches.\nFinally, we discuss the effects of progressive prompting strategies and the\nimpact of augmented data in mitigating the biases manifested in IC-AnnoM. Our\ncontributions provide the MI community with not only a comprehensive dataset\nbut also valuable insights for using LLMs in empathetic text generation for\nconversational therapy in supervised settings."
  },
  {
    "arxiv_id": "2412.12956",
    "title": "SnakModel: Lessons Learned from Training an Open Danish Large Language Model",
    "url": "http://arxiv.org/abs/2412.12956v1",
    "abstract": "We present SnakModel, a Danish large language model (LLM) based on Llama2-7B,\nwhich we continuously pre-train on 13.6B Danish words, and further tune on 3.7M\nDanish instructions. As best practices for creating LLMs for smaller language\ncommunities have yet to be established, we examine the effects of early\nmodeling and training decisions on downstream performance throughout the entire\ntraining pipeline, including (1) the creation of a strictly curated corpus of\nDanish text from diverse sources; (2) the language modeling and\ninstruction-tuning training process itself, including the analysis of\nintermediate training dynamics, and ablations across different hyperparameters;\n(3) an evaluation on eight language and culturally-specific tasks. Across these\nexperiments SnakModel achieves the highest overall performance, outperforming\nmultiple contemporary Llama2-7B-based models. By making SnakModel, the majority\nof our pre-training corpus, and the associated code available under open\nlicenses, we hope to foster further research and development in Danish Natural\nLanguage Processing, and establish training guidelines for languages with\nsimilar resource constraints."
  },
  {
    "arxiv_id": "2412.12591",
    "title": "LLMs are Also Effective Embedding Models: An In-depth Overview",
    "url": "http://arxiv.org/abs/2412.12591v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nby achieving state-of-the-art performance across various tasks. Recently, their\neffectiveness as embedding models has gained attention, marking a paradigm\nshift from traditional encoder-only models like ELMo and BERT to decoder-only,\nlarge-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an\nin-depth overview of this transition, beginning with foundational techniques\nbefore the LLM era, followed by LLM-based embedding models through two main\nstrategies to derive embeddings from LLMs. 1) Direct prompting: We mainly\ndiscuss the prompt designs and the underlying rationale for deriving\ncompetitive embeddings. 2) Data-centric tuning: We cover extensive aspects that\naffect tuning an embedding model, including model architecture, training\nobjectives, data constructions, etc. Upon the above, we also cover advanced\nmethods, such as handling longer texts, and multilingual and cross-modal data.\nFurthermore, we discuss factors affecting choices of embedding models, such as\nperformance/efficiency comparisons, dense vs sparse embeddings, pooling\nstrategies, and scaling law. Lastly, the survey highlights the limitations and\nchallenges in adapting LLMs for embeddings, including cross-task embedding\nquality, trade-offs between efficiency and accuracy, low-resource,\nlong-context, data bias, robustness, etc. This survey serves as a valuable\nresource for researchers and practitioners by synthesizing current\nadvancements, highlighting key challenges, and offering a comprehensive\nframework for future work aimed at enhancing the effectiveness and efficiency\nof LLMs as embedding models."
  },
  {
    "arxiv_id": "2412.12541",
    "title": "LLMCL-GEC: Advancing Grammatical Error Correction with LLM-Driven Curriculum Learning",
    "url": "http://arxiv.org/abs/2412.12541v1",
    "abstract": "While large-scale language models (LLMs) have demonstrated remarkable\ncapabilities in specific natural language processing (NLP) tasks, they may\nstill lack proficiency compared to specialized models in certain domains, such\nas grammatical error correction (GEC). Drawing inspiration from the concept of\ncurriculum learning, we have delved into refining LLMs into proficient GEC\nexperts by devising effective curriculum learning (CL) strategies. In this\npaper, we introduce a novel approach, termed LLM-based curriculum learning,\nwhich capitalizes on the robust semantic comprehension and discriminative\nprowess inherent in LLMs to gauge the complexity of GEC training data. Unlike\ntraditional curriculum learning techniques, our method closely mirrors human\nexpert-designed curriculums. Leveraging the proposed LLM-based CL method, we\nsequentially select varying levels of curriculums ranging from easy to hard,\nand iteratively train and refine using the pretrianed T5 and LLaMA series\nmodels. Through rigorous testing and analysis across diverse benchmark\nassessments in English GEC, including the CoNLL14 test, BEA19 test, and BEA19\ndevelopment sets, our approach showcases a significant performance boost over\nbaseline models and conventional curriculum learning methodologies."
  },
  {
    "arxiv_id": "2412.12465",
    "title": "Core Context Aware Attention for Long Context Language Modeling",
    "url": "http://arxiv.org/abs/2412.12465v1",
    "abstract": "Transformer-based Large Language Models (LLMs) have exhibited remarkable\nsuccess in various natural language processing tasks primarily attributed to\nself-attention mechanism, which requires a token to consider all preceding\ntokens as its context to compute the attention score. However, when the context\nlength L becomes very large (e.g., 32K), more redundant context information\nwill be included w.r.t. any tokens, making the self-attention suffer from two\nmain limitations: 1) The computational and memory complexity scales\nquadratically w.r.t. L; 2) The presence of redundant context information may\nhamper the model to capture dependencies among crucial tokens, which may\ndegrade the representation performance. In this paper, we propose a\nplug-and-play Core Context Aware (CCA) Attention for efficient long-range\ncontext modeling, which consists of two components: 1) Globality-pooling\nattention that divides input tokens into groups and then dynamically merges\ntokens within each group into one core token based on their significance; 2)\nLocality-preserved attention that incorporates neighboring tokens into the\nattention calculation. The two complementary attentions will then be fused to\nthe final attention, maintaining comprehensive modeling ability as the full\nself-attention. In this way, the core context information w.r.t. a given token\nwill be automatically focused and strengthened, while the context information\nin redundant groups will be diminished during the learning process. As a\nresult, the computational and memory complexity will be significantly reduced.\nMore importantly, the CCA-Attention can improve the long-context modeling\nability by diminishing the redundant context information. Extensive\nexperimental results demonstrate that our CCA-Attention significantly\noutperforms state-of-the-art models in terms of computational efficiency and\nlong-context modeling ability."
  },
  {
    "arxiv_id": "2412.13705",
    "title": "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation",
    "url": "http://arxiv.org/abs/2412.13705v1",
    "abstract": "Large language models (LLMs) have exhibited outstanding performance in\nnatural language processing tasks. However, these models remain susceptible to\nadversarial attacks in which slight input perturbations can lead to harmful or\nmisleading outputs. A gradient-based defensive suffix generation algorithm is\ndesigned to bolster the robustness of LLMs. By appending carefully optimized\ndefensive suffixes to input prompts, the algorithm mitigates adversarial\ninfluences while preserving the models' utility. To enhance adversarial\nunderstanding, a novel total loss function ($L_{\\text{total}}$) combining\ndefensive loss ($L_{\\text{def}}$) and adversarial loss ($L_{\\text{adv}}$)\ngenerates defensive suffixes more effectively. Experimental evaluations\nconducted on open-source LLMs such as Gemma-7B, mistral-7B, Llama2-7B, and\nLlama2-13B show that the proposed method reduces attack success rates (ASR) by\nan average of 11\\% compared to models without defensive suffixes. Additionally,\nthe perplexity score of Gemma-7B decreased from 6.57 to 3.93 when applying the\ndefensive suffix generated by openELM-270M. Furthermore, TruthfulQA evaluations\ndemonstrate consistent improvements with Truthfulness scores increasing by up\nto 10\\% across tested configurations. This approach significantly enhances the\nsecurity of LLMs in critical applications without requiring extensive\nretraining."
  },
  {
    "arxiv_id": "2412.13553",
    "title": "Combining Aggregated Attention and Transformer Architecture for Accurate and Efficient Performance of Spiking Neural Networks",
    "url": "http://arxiv.org/abs/2412.13553v1",
    "abstract": "Spiking Neural Networks have attracted significant attention in recent years\ndue to their distinctive low-power characteristics. Meanwhile, Transformer\nmodels, known for their powerful self-attention mechanisms and parallel\nprocessing capabilities, have demonstrated exceptional performance across\nvarious domains, including natural language processing and computer vision.\nDespite the significant advantages of both SNNs and Transformers, directly\ncombining the low-power benefits of SNNs with the high performance of\nTransformers remains challenging. Specifically, while the sparse computing mode\nof SNNs contributes to reduced energy consumption, traditional attention\nmechanisms depend on dense matrix computations and complex softmax operations.\nThis reliance poses significant challenges for effective execution in low-power\nscenarios. Given the tremendous success of Transformers in deep learning, it is\na necessary step to explore the integration of SNNs and Transformers to harness\nthe strengths of both. In this paper, we propose a novel model architecture,\nSpike Aggregation Transformer (SAFormer), that integrates the low-power\ncharacteristics of SNNs with the high-performance advantages of Transformer\nmodels. The core contribution of SAFormer lies in the design of the Spike\nAggregated Self-Attention (SASA) mechanism, which significantly simplifies the\ncomputation process by calculating attention weights using only the spike\nmatrices query and key, thereby effectively reducing energy consumption.\nAdditionally, we introduce a Depthwise Convolution Module (DWC) to enhance the\nfeature extraction capabilities, further improving overall accuracy. We\nevaluated and demonstrated that SAFormer outperforms state-of-the-art SNNs in\nboth accuracy and energy consumption, highlighting its significant advantages\nin low-power and high-performance computing."
  },
  {
    "arxiv_id": "2412.15205",
    "title": "FlowAR: Scale-wise Autoregressive Image Generation Meets Flow Matching",
    "url": "http://arxiv.org/abs/2412.15205v1",
    "abstract": "Autoregressive (AR) modeling has achieved remarkable success in natural\nlanguage processing by enabling models to generate text with coherence and\ncontextual understanding through next token prediction. Recently, in image\ngeneration, VAR proposes scale-wise autoregressive modeling, which extends the\nnext token prediction to the next scale prediction, preserving the 2D structure\nof images. However, VAR encounters two primary challenges: (1) its complex and\nrigid scale design limits generalization in next scale prediction, and (2) the\ngenerator's dependence on a discrete tokenizer with the same complex scale\nstructure restricts modularity and flexibility in updating the tokenizer. To\naddress these limitations, we introduce FlowAR, a general next scale prediction\nmethod featuring a streamlined scale design, where each subsequent scale is\nsimply double the previous one. This eliminates the need for VAR's intricate\nmulti-scale residual tokenizer and enables the use of any off-the-shelf\nVariational AutoEncoder (VAE). Our simplified design enhances generalization in\nnext scale prediction and facilitates the integration of Flow Matching for\nhigh-quality image synthesis. We validate the effectiveness of FlowAR on the\nchallenging ImageNet-256 benchmark, demonstrating superior generation\nperformance compared to previous methods. Codes will be available at\n\\url{https://github.com/OliverRensu/FlowAR}."
  },
  {
    "arxiv_id": "2412.15060",
    "title": "ConfliBERT: A Language Model for Political Conflict",
    "url": "http://arxiv.org/abs/2412.15060v1",
    "abstract": "Conflict scholars have used rule-based approaches to extract information\nabout political violence from news reports and texts. Recent Natural Language\nProcessing developments move beyond rigid rule-based approaches. We review our\nrecent ConfliBERT language model (Hu et al. 2022) to process political and\nviolence related texts. The model can be used to extract actor and action\nclassifications from texts about political conflict. When fine-tuned, results\nshow that ConfliBERT has superior performance in accuracy, precision and recall\nover other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama\n3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also\nhundreds of times faster than these more generalist LLMs. These results are\nillustrated using texts from the BBC, re3d, and the Global Terrorism Dataset\n(GTD)."
  },
  {
    "arxiv_id": "2412.14559",
    "title": "ScaMo: Exploring the Scaling Law in Autoregressive Motion Generation Model",
    "url": "http://arxiv.org/abs/2412.14559v1",
    "abstract": "The scaling law has been validated in various domains, such as natural\nlanguage processing (NLP) and massive computer vision tasks; however, its\napplication to motion generation remains largely unexplored. In this paper, we\nintroduce a scalable motion generation framework that includes the motion\ntokenizer Motion FSQ-VAE and a text-prefix autoregressive transformer. Through\ncomprehensive experiments, we observe the scaling behavior of this system. For\nthe first time, we confirm the existence of scaling laws within the context of\nmotion generation. Specifically, our results demonstrate that the normalized\ntest loss of our prefix autoregressive models adheres to a logarithmic law in\nrelation to compute budgets. Furthermore, we also confirm the power law between\nNon-Vocabulary Parameters, Vocabulary Parameters, and Data Tokens with respect\nto compute budgets respectively. Leveraging the scaling law, we predict the\noptimal transformer size, vocabulary size, and data requirements for a compute\nbudget of $1e18$. The test loss of the system, when trained with the optimal\nmodel size, vocabulary size, and required data, aligns precisely with the\npredicted test loss, thereby validating the scaling law."
  },
  {
    "arxiv_id": "2412.16120",
    "title": "PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation Metrics",
    "url": "http://arxiv.org/abs/2412.16120v1",
    "abstract": "Evaluating the quality of machine-generated natural language content is a\nchallenging task in Natural Language Processing (NLP). Recently, large language\nmodels (LLMs) like GPT-4 have been employed for this purpose, but they are\ncomputationally expensive due to the extensive token usage required by complex\nevaluation prompts. In this paper, we propose a prompt optimization approach\nthat uses a smaller, fine-tuned language model to compress input data for\nevaluation prompt, thus reducing token usage and computational cost when using\nlarger LLMs for downstream evaluation. Our method involves a two-stage\nfine-tuning process: supervised fine-tuning followed by preference optimization\nto refine the model's outputs based on human preferences. We focus on Machine\nTranslation (MT) evaluation and utilize the GEMBA-MQM metric as a starting\npoint. Our results show a $2.37\\times$ reduction in token usage without any\nloss in evaluation quality. This work makes state-of-the-art LLM-based metrics\nlike GEMBA-MQM more cost-effective and efficient, enhancing their accessibility\nfor broader use."
  },
  {
    "arxiv_id": "2412.15785",
    "title": "Learning from Impairment: Leveraging Insights from Clinical Linguistics in Language Modelling Research",
    "url": "http://arxiv.org/abs/2412.15785v1",
    "abstract": "This position paper investigates the potential of integrating insights from\nlanguage impairment research and its clinical treatment to develop\nhuman-inspired learning strategies and evaluation frameworks for language\nmodels (LMs). We inspect the theoretical underpinnings underlying some\ninfluential linguistically motivated training approaches derived from\nneurolinguistics and, particularly, aphasiology, aimed at enhancing the\nrecovery and generalization of linguistic skills in aphasia treatment, with a\nprimary focus on those targeting the syntactic domain. We highlight how these\ninsights can inform the design of rigorous assessments for LMs, specifically in\ntheir handling of complex syntactic phenomena, as well as their implications\nfor developing human-like learning strategies, aligning with efforts to create\nmore sustainable and cognitively plausible natural language processing (NLP)\nmodels."
  },
  {
    "arxiv_id": "2412.15712",
    "title": "Contrastive Learning for Task-Independent SpeechLLM-Pretraining",
    "url": "http://arxiv.org/abs/2412.15712v1",
    "abstract": "Large language models (LLMs) excel in natural language processing but\nadapting these LLMs to speech processing tasks efficiently is not\nstraightforward. Direct task-specific fine-tuning is limited by overfitting\nrisks, data requirements, and computational costs. To address these challenges,\nwe propose a scalable, two-stage training approach: (1) A task-independent\nspeech pretraining stage using contrastive learning to align text and speech\nrepresentations over all layers, followed by (2) a task-specific fine-tuning\nstage requiring minimal data. This approach outperforms traditional ASR\npretraining and enables the model to surpass models specialized on speech\ntranslation and question answering while being trained on only 10% of the\ntask-specific data."
  },
  {
    "arxiv_id": "2412.15504",
    "title": "Mitigating Social Bias in Large Language Models: A Multi-Objective Approach within a Multi-Agent Framework",
    "url": "http://arxiv.org/abs/2412.15504v1",
    "abstract": "Natural language processing (NLP) has seen remarkable advancements with the\ndevelopment of large language models (LLMs). Despite these advancements, LLMs\noften produce socially biased outputs. Recent studies have mainly addressed\nthis problem by prompting LLMs to behave ethically, but this approach results\nin unacceptable performance degradation. In this paper, we propose a\nmulti-objective approach within a multi-agent framework (MOMA) to mitigate\nsocial bias in LLMs without significantly compromising their performance. The\nkey idea of MOMA involves deploying multiple agents to perform causal\ninterventions on bias-related contents of the input questions, breaking the\nshortcut connection between these contents and the corresponding answers.\nUnlike traditional debiasing techniques leading to performance degradation,\nMOMA substantially reduces bias while maintaining accuracy in downstream tasks.\nOur experiments conducted on two datasets and two models demonstrate that MOMA\nreduces bias scores by up to 87.7%, with only a marginal performance\ndegradation of up to 6.8% in the BBQ dataset. Additionally, it significantly\nenhances the multi-objective metric icat in the StereoSet dataset by up to\n58.1%. Code will be made available at https://github.com/Cortantse/MOMA."
  },
  {
    "arxiv_id": "2412.15386",
    "title": "Systematic Evaluation of Long-Context LLMs on Financial Concepts",
    "url": "http://arxiv.org/abs/2412.15386v1",
    "abstract": "Long-context large language models (LC LLMs) promise to increase reliability\nof LLMs in real-world tasks requiring processing and understanding of long\ninput documents. However, this ability of LC LLMs to reliably utilize their\ngrowing context windows remains under investigation. In this work, we evaluate\nthe performance of state-of-the-art GPT-4 suite of LC LLMs in solving a series\nof progressively challenging tasks, as a function of factors such as context\nlength, task difficulty, and position of key information by creating a real\nworld financial news dataset. Our findings indicate that LC LLMs exhibit\nbrittleness at longer context lengths even for simple tasks, with performance\ndeteriorating sharply as task complexity increases. At longer context lengths,\nthese state-of-the-art models experience catastrophic failures in instruction\nfollowing resulting in degenerate outputs. Our prompt ablations also reveal\nunfortunate continued sensitivity to both the placement of the task instruction\nin the context window as well as minor markdown formatting. Finally, we\nadvocate for more rigorous evaluation of LC LLMs by employing holistic metrics\nsuch as F1 (rather than recall) and reporting confidence intervals, thereby\nensuring robust and conclusive findings."
  },
  {
    "arxiv_id": "2412.17669",
    "title": "Generating Completions for Fragmented Broca's Aphasic Sentences Using Large Language Models",
    "url": "http://arxiv.org/abs/2412.17669v1",
    "abstract": "Broca's aphasia is a type of aphasia characterized by non-fluent, effortful\nand fragmented speech production with relatively good comprehension. Since\ntraditional aphasia treatment methods are often time-consuming,\nlabour-intensive, and do not reflect real-world conversations, applying natural\nlanguage processing based approaches such as Large Language Models (LLMs) could\npotentially contribute to improving existing treatment approaches. To address\nthis issue, we explore the use of sequence-to-sequence LLMs for completing\nfragmented Broca's aphasic sentences. We first generate synthetic Broca's\naphasic data using a rule-based system designed to mirror the linguistic\ncharacteristics of Broca's aphasic speech. Using this synthetic data, we then\nfine-tune four pre-trained LLMs on the task of completing fragmented sentences.\nWe evaluate our fine-tuned models on both synthetic and authentic Broca's\naphasic data. We demonstrate LLMs' capability for reconstructing fragmented\nsentences, with the models showing improved performance with longer input\nutterances. Our result highlights the LLMs' potential in advancing\ncommunication aids for individuals with Broca's aphasia and possibly other\nclinical populations."
  },
  {
    "arxiv_id": "2412.17332",
    "title": "A Dual-Perspective Metaphor Detection Framework Using Large Language Models",
    "url": "http://arxiv.org/abs/2412.17332v1",
    "abstract": "Metaphor detection, a critical task in natural language processing, involves\nidentifying whether a particular word in a sentence is used metaphorically.\nTraditional approaches often rely on supervised learning models that implicitly\nencode semantic relationships based on metaphor theories. However, these\nmethods often suffer from a lack of transparency in their decision-making\nprocesses, which undermines the reliability of their predictions. Recent\nresearch indicates that LLMs (large language models) exhibit significant\npotential in metaphor detection. Nevertheless, their reasoning capabilities are\nconstrained by predefined knowledge graphs. To overcome these limitations, we\npropose DMD, a novel dual-perspective framework that harnesses both implicit\nand explicit applications of metaphor theories to guide LLMs in metaphor\ndetection and adopts a self-judgment mechanism to validate the responses from\nthe aforementioned forms of guidance. In comparison to previous methods, our\nframework offers more transparent reasoning processes and delivers more\nreliable predictions. Experimental results prove the effectiveness of DMD,\ndemonstrating state-of-the-art performance across widely-used datasets."
  },
  {
    "arxiv_id": "2412.18525",
    "title": "The Key of Understanding Vision Tasks: Explanatory Instructions",
    "url": "http://arxiv.org/abs/2412.18525v1",
    "abstract": "Computer Vision (CV) has yet to fully achieve the zero-shot task\ngeneralization observed in Natural Language Processing (NLP), despite following\nmany of the milestones established in NLP, such as large transformer models,\nextensive pre-training, and the auto-regression paradigm, among others. In this\npaper, we explore the idea that CV adopts discrete and terminological task\ndefinitions (\\eg, ``image segmentation''), which may be a key barrier to\nzero-shot task generalization. Our hypothesis is that without truly\nunderstanding previously-seen tasks--due to these terminological\ndefinitions--deep models struggle to generalize to novel tasks. To verify this,\nwe introduce Explanatory Instructions, which provide an intuitive way to define\nCV task objectives through detailed linguistic transformations from input\nimages to outputs. We create a large-scale dataset comprising 12 million\n``image input $\\to$ explanatory instruction $\\to$ output'' triplets, and train\nan auto-regressive-based vision-language model (AR-based VLM) that takes both\nimages and explanatory instructions as input. By learning to follow these\ninstructions, the AR-based VLM achieves instruction-level zero-shot\ncapabilities for previously-seen tasks and demonstrates strong zero-shot\ngeneralization for unseen CV tasks. Code and dataset will be openly available\non our GitHub repository."
  },
  {
    "arxiv_id": "2412.18407",
    "title": "A Statistical Framework for Ranking LLM-Based Chatbots",
    "url": "http://arxiv.org/abs/2412.18407v1",
    "abstract": "Large language models (LLMs) have transformed natural language processing,\nwith frameworks like Chatbot Arena providing pioneering platforms for\nevaluating these models. By facilitating millions of pairwise comparisons based\non human judgments, Chatbot Arena has become a cornerstone in LLM evaluation,\noffering rich datasets for ranking models in open-ended conversational tasks.\nBuilding upon this foundation, we propose a statistical framework that\nincorporates key advancements to address specific challenges in pairwise\ncomparison analysis. First, we introduce a factored tie model that enhances the\nability to handle ties -- an integral aspect of human-judged comparisons --\nsignificantly improving the model's fit to observed data. Second, we extend the\nframework to model covariance between competitors, enabling deeper insights\ninto performance relationships and facilitating intuitive groupings into\nperformance tiers. Third, we resolve optimization challenges arising from\nparameter non-uniqueness by introducing novel constraints, ensuring stable and\ninterpretable parameter estimation. Through rigorous evaluation and extensive\nexperimentation, our framework demonstrates substantial improvements over\nexisting methods in modeling pairwise comparison data. To support\nreproducibility and practical adoption, we release leaderbot, an open-source\nPython package implementing our models and analyses."
  },
  {
    "arxiv_id": "2412.18299",
    "title": "M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models",
    "url": "http://arxiv.org/abs/2412.18299v1",
    "abstract": "With the widespread application of Large Language Models (LLMs) in the field\nof Natural Language Processing (NLP), enhancing their performance has become a\nresearch hotspot. This paper presents a novel multi-prompt ensemble decoding\napproach designed to bolster the generation quality of LLMs by leveraging the\naggregation of outcomes from multiple prompts. Given a unique input $X$, we\nsubmit $n$ variations of prompts with $X$ to LLMs in batch mode to decode and\nderive probability distributions. For each token prediction, we calculate the\nensemble probability by averaging the $n$ probability distributions within the\nbatch, utilizing this aggregated probability to generate the token. This\ntechnique is dubbed Inner-Batch Ensemble. To facilitate efficient batch\ninference, we implement a Left-Padding strategy to maintain uniform input\nlengths across the n prompts. Through extensive experimentation on diverse NLP\ntasks, including machine translation, code generation, and text simplification,\nwe demonstrate the efficacy of our method in enhancing LLM performance. The\nresults show substantial improvements in BLEU scores, pass@$k$ rates, and LENS\nmetrics over conventional methods."
  },
  {
    "arxiv_id": "2412.18188",
    "title": "On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for Sentiment Classification in Distant Language Pairs",
    "url": "http://arxiv.org/abs/2412.18188v1",
    "abstract": "This research explores the applicability of cross-lingual transfer learning\nfrom English to Japanese and Indonesian using the XLM-R pre-trained model. The\nresults are compared with several previous works, either by models using a\nsimilar zero-shot approach or a fully-supervised approach, to provide an\noverview of the zero-shot transfer learning approach's capability using XLM-R\nin comparison with existing models. Our models achieve the best result in one\nJapanese dataset and comparable results in other datasets in Japanese and\nIndonesian languages without being trained using the target language.\nFurthermore, the results suggest that it is possible to train a multi-lingual\nmodel, instead of one model for each language, and achieve promising results."
  },
  {
    "arxiv_id": "2412.18100",
    "title": "EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent",
    "url": "http://arxiv.org/abs/2412.18100v1",
    "abstract": "The rapid growth of scientific techniques and knowledge is reflected in the\nexponential increase in new patents filed annually. While these patents drive\ninnovation, they also present significant burden for researchers and engineers,\nespecially newcomers. To avoid the tedious work of navigating a vast and\ncomplex landscape to identify trends and breakthroughs, researchers urgently\nneed efficient tools to summarize, evaluate, and contextualize patents,\nrevealing their innovative contributions and underlying scientific\nprinciples.To address this need, we present EvoPat, a multi-LLM-based patent\nagent designed to assist users in analyzing patents through Retrieval-Augmented\nGeneration (RAG) and advanced search strategies. EvoPat leverages multiple\nLarge Language Models (LLMs), each performing specialized roles such as\nplanning, identifying innovations, and conducting comparative evaluations. The\nsystem integrates data from local databases, including patents, literature,\nproduct catalogous, and company repositories, and online searches to provide\nup-to-date insights. The ability to collect information not included in\noriginal database automatically is also implemented. Through extensive testing\nin the natural language processing (NLP) domain, we demonstrate that EvoPat\noutperforms GPT-4 in tasks such as patent summarization, comparative analysis,\nand technical evaluation. EvoPat represents a significant step toward creating\nAI-powered tools that empower researchers and engineers to efficiently navigate\nthe complexities of the patent landscape."
  },
  {
    "arxiv_id": "2412.18084",
    "title": "Property Enhanced Instruction Tuning for Multi-task Molecule Generation with Large Language Models",
    "url": "http://arxiv.org/abs/2412.18084v1",
    "abstract": "Large language models (LLMs) are widely applied in various natural language\nprocessing tasks such as question answering and machine translation. However,\ndue to the lack of labeled data and the difficulty of manual annotation for\nbiochemical properties, the performance for molecule generation tasks is still\nlimited, especially for tasks involving multi-properties constraints. In this\nwork, we present a two-step framework PEIT (Property Enhanced Instruction\nTuning) to improve LLMs for molecular-related tasks. In the first step, we use\ntextual descriptions, SMILES, and biochemical properties as multimodal inputs\nto pre-train a model called PEIT-GEN, by aligning multi-modal representations\nto synthesize instruction data. In the second step, we fine-tune existing\nopen-source LLMs with the synthesized data, the resulting PEIT-LLM can handle\nmolecule captioning, text-based molecule generation, molecular property\nprediction, and our newly proposed multi-constraint molecule generation tasks.\nExperimental results show that our pre-trained PEIT-GEN outperforms MolT5 and\nBioT5 in molecule captioning, demonstrating modalities align well between\ntextual descriptions, structures, and biochemical properties. Furthermore,\nPEIT-LLM shows promising improvements in multi-task molecule generation,\nproving the scalability of the PEIT framework for various molecular tasks. We\nrelease the code, constructed instruction data, and model checkpoints in\nhttps://github.com/chenlong164/PEIT."
  },
  {
    "arxiv_id": "2412.18082",
    "title": "Prompt Tuning for Item Cold-start Recommendation",
    "url": "http://arxiv.org/abs/2412.18082v1",
    "abstract": "The item cold-start problem is crucial for online recommender systems, as the\nsuccess of the cold-start phase determines whether items can transition into\npopular ones. Prompt learning, a powerful technique used in natural language\nprocessing (NLP) to address zero- or few-shot problems, has been adapted for\nrecommender systems to tackle similar challenges. However, existing methods\ntypically rely on content-based properties or text descriptions for prompting,\nwhich we argue may be suboptimal for cold-start recommendations due to 1)\nsemantic gaps with recommender tasks, 2) model bias caused by warm-up items\ncontribute most of the positive feedback to the model, which is the core of the\ncold-start problem that hinders the recommender quality on cold-start items. We\npropose to leverage high-value positive feedback, termed pinnacle feedback as\nprompt information, to simultaneously resolve the above two problems. We\nexperimentally prove that compared to the content description proposed in\nexisting works, the positive feedback is more suitable to serve as prompt\ninformation by bridging the semantic gaps. Besides, we propose item-wise\npersonalized prompt networks to encode pinnaclce feedback to relieve the model\nbias by the positive feedback dominance problem. Extensive experiments on four\nreal-world datasets demonstrate the superiority of our model over\nstate-of-the-art methods. Moreover, PROMO has been successfully deployed on a\npopular short-video sharing platform, a billion-user scale commercial\nshort-video application, achieving remarkable performance gains across various\ncommercial metrics within cold-start scenarios"
  },
  {
    "arxiv_id": "2412.19505",
    "title": "DrivingWorld: ConstructingWorld Model for Autonomous Driving via Video GPT",
    "url": "http://arxiv.org/abs/2412.19505v1",
    "abstract": "Recent successes in autoregressive (AR) generation models, such as the GPT\nseries in natural language processing, have motivated efforts to replicate this\nsuccess in visual tasks. Some works attempt to extend this approach to\nautonomous driving by building video-based world models capable of generating\nrealistic future video sequences and predicting ego states. However, prior\nworks tend to produce unsatisfactory results, as the classic GPT framework is\ndesigned to handle 1D contextual information, such as text, and lacks the\ninherent ability to model the spatial and temporal dynamics essential for video\ngeneration. In this paper, we present DrivingWorld, a GPT-style world model for\nautonomous driving, featuring several spatial-temporal fusion mechanisms. This\ndesign enables effective modeling of both spatial and temporal dynamics,\nfacilitating high-fidelity, long-duration video generation. Specifically, we\npropose a next-state prediction strategy to model temporal coherence between\nconsecutive frames and apply a next-token prediction strategy to capture\nspatial information within each frame. To further enhance generalization\nability, we propose a novel masking strategy and reweighting strategy for token\nprediction to mitigate long-term drifting issues and enable precise control.\nOur work demonstrates the ability to produce high-fidelity and consistent video\nclips of over 40 seconds in duration, which is over 2 times longer than\nstate-of-the-art driving world models. Experiments show that, in contrast to\nprior works, our method achieves superior visual quality and significantly more\naccurate controllable future video generation. Our code is available at\nhttps://github.com/YvanYin/DrivingWorld."
  },
  {
    "arxiv_id": "2412.19449",
    "title": "Feature Alignment-Based Knowledge Distillation for Efficient Compression of Large Language Models",
    "url": "http://arxiv.org/abs/2412.19449v1",
    "abstract": "This study proposes a knowledge distillation algorithm based on large\nlanguage models and feature alignment, aiming to effectively transfer the\nknowledge of large pre-trained models into lightweight student models, thereby\nreducing computational costs while maintaining high model performance.\nDifferent from the traditional soft label distillation method, this method\nintroduces a multi-layer feature alignment strategy to deeply align the\nintermediate features and attention mechanisms of the teacher model and the\nstudent model, maximally retaining the semantic expression ability and context\nmodeling ability of the teacher model. In terms of method design, a multi-task\nloss function is constructed, including feature matching loss, attention\nalignment loss, and output distribution matching loss, to ensure multi-level\ninformation transfer through joint optimization. The experiments were\ncomprehensively evaluated on the GLUE data set and various natural language\nprocessing tasks. The results show that the proposed model performs very close\nto the state-of-the-art GPT-4 model in terms of evaluation indicators such as\nperplexity, BLEU, ROUGE, and CER. At the same time, it far exceeds baseline\nmodels such as DeBERTa, XLNet, and GPT-3, showing significant performance\nimprovements and computing efficiency advantages. Research results show that\nthe feature alignment distillation strategy is an effective model compression\nmethod that can significantly reduce computational overhead and storage\nrequirements while maintaining model capabilities. Future research can be\nfurther expanded in the directions of self-supervised learning, cross-modal\nfeature alignment, and multi-task transfer learning to provide more flexible\nand efficient solutions for the deployment and optimization of deep learning\nmodels."
  },
  {
    "arxiv_id": "2412.19442",
    "title": "A Survey on Large Language Model Acceleration based on KV Cache Management",
    "url": "http://arxiv.org/abs/2412.19442v1",
    "abstract": "Large Language Models (LLMs) have revolutionized a wide range of domains such\nas natural language processing, computer vision, and multi-modal tasks due to\ntheir ability to comprehend context and perform logical reasoning. However, the\ncomputational and memory demands of LLMs, particularly during inference, pose\nsignificant challenges when scaling them to real-world, long-context, and\nreal-time applications. Key-Value (KV) cache management has emerged as a\ncritical optimization technique for accelerating LLM inference by reducing\nredundant computations and improving memory utilization. This survey provides a\ncomprehensive overview of KV cache management strategies for LLM acceleration,\ncategorizing them into token-level, model-level, and system-level\noptimizations. Token-level strategies include KV cache selection, budget\nallocation, merging, quantization, and low-rank decomposition, while\nmodel-level optimizations focus on architectural innovations and attention\nmechanisms to enhance KV reuse. System-level approaches address memory\nmanagement, scheduling, and hardware-aware designs to improve efficiency across\ndiverse computing environments. Additionally, the survey provides an overview\nof both text and multimodal datasets and benchmarks used to evaluate these\nstrategies. By presenting detailed taxonomies and comparative analyses, this\nwork aims to offer useful insights for researchers and practitioners to support\nthe development of efficient and scalable KV cache management techniques,\ncontributing to the practical deployment of LLMs in real-world applications.\nThe curated paper list for KV cache management is in:\n\\href{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}{https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management}."
  },
  {
    "arxiv_id": "2412.19363",
    "title": "Large Language Models for Market Research: A Data-augmentation Approach",
    "url": "http://arxiv.org/abs/2412.19363v1",
    "abstract": "Large Language Models (LLMs) have transformed artificial intelligence by\nexcelling in complex natural language processing tasks. Their ability to\ngenerate human-like text has opened new possibilities for market research,\nparticularly in conjoint analysis, where understanding consumer preferences is\nessential but often resource-intensive. Traditional survey-based methods face\nlimitations in scalability and cost, making LLM-generated data a promising\nalternative. However, while LLMs have the potential to simulate real consumer\nbehavior, recent studies highlight a significant gap between LLM-generated and\nhuman data, with biases introduced when substituting between the two. In this\npaper, we address this gap by proposing a novel statistical data augmentation\napproach that efficiently integrates LLM-generated data with real data in\nconjoint analysis. Our method leverages transfer learning principles to debias\nthe LLM-generated data using a small amount of human data. This results in\nstatistically robust estimators with consistent and asymptotically normal\nproperties, in contrast to naive approaches that simply substitute human data\nwith LLM-generated data, which can exacerbate bias. We validate our framework\nthrough an empirical study on COVID-19 vaccine preferences, demonstrating its\nsuperior ability to reduce estimation error and save data and costs by 24.9% to\n79.8%. In contrast, naive approaches fail to save data due to the inherent\nbiases in LLM-generated data compared to human data. Another empirical study on\nsports car choices validates the robustness of our results. Our findings\nsuggest that while LLM-generated data is not a direct substitute for human\nresponses, it can serve as a valuable complement when used within a robust\nstatistical framework."
  },
  {
    "arxiv_id": "2412.20787",
    "title": "SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity",
    "url": "http://arxiv.org/abs/2412.20787v2",
    "abstract": "Evaluating Large Language Models (LLMs) is crucial for understanding their\ncapabilities and limitations across various applications, including natural\nlanguage processing and code generation. Existing benchmarks like MMLU, C-Eval,\nand HumanEval assess general LLM performance but lack focus on specific expert\ndomains such as cybersecurity. Previous attempts to create cybersecurity\ndatasets have faced limitations, including insufficient data volume and a\nreliance on multiple-choice questions (MCQs). To address these gaps, we propose\nSecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in\nthe cybersecurity domain. SecBench includes questions in various formats (MCQs\nand short-answer questions (SAQs)), at different capability levels (Knowledge\nRetention and Logical Reasoning), in multiple languages (Chinese and English),\nand across various sub-domains. The dataset was constructed by collecting\nhigh-quality data from open sources and organizing a Cybersecurity Question\nDesign Contest, resulting in 44,823 MCQs and 3,087 SAQs. Particularly, we used\nthe powerful while cost-effective LLMs to (1). label the data and (2).\nconstructing a grading agent for automatic evaluation of SAQs. Benchmarking\nresults on 16 SOTA LLMs demonstrate the usability of SecBench, which is\narguably the largest and most comprehensive benchmark dataset for LLMs in\ncybersecurity. More information about SecBench can be found at our website, and\nthe dataset can be accessed via the artifact link."
  },
  {
    "arxiv_id": "2412.20414",
    "title": "Comparative Performance of Advanced NLP Models and LLMs in Multilingual Geo-Entity Detection",
    "url": "http://arxiv.org/abs/2412.20414v1",
    "abstract": "The integration of advanced Natural Language Processing (NLP) methodologies\nand Large Language Models (LLMs) has significantly enhanced the extraction and\nanalysis of geospatial data from multilingual texts, impacting sectors such as\nnational and international security. This paper presents a comprehensive\nevaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and\nLLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of\nmultilingual geo-entity detection. Utilizing datasets from Telegram channels in\nEnglish, Russian, and Arabic, we examine the performance of these models\nthrough metrics such as accuracy, precision, recall, and F1 scores, to assess\ntheir effectiveness in accurately identifying geospatial references. The\nanalysis exposes each model's distinct advantages and challenges, underscoring\nthe complexities involved in achieving precise geo-entity identification across\nvaried linguistic landscapes. The conclusions drawn from this experiment aim to\ndirect the enhancement and creation of more advanced and inclusive NLP tools,\nthus advancing the field of geospatial analysis and its application to global\nsecurity."
  },
  {
    "arxiv_id": "2412.20227",
    "title": "LLM Reasoning Engine: Specialized Training for Enhanced Mathematical Reasoning",
    "url": "http://arxiv.org/abs/2412.20227v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in various\nnatural language processing tasks but face challenges in mathematical\nreasoning, where complex problem-solving requires both linguistic understanding\nand mathematical reasoning skills. Existing approaches to address this\nchallenge often rely on ensemble methods and suffer from the problem of data\nscarcity in target domains. In this work, we present a novel method to enhance\nLLMs' capabilities in mathematical reasoning tasks. Motivated by the need to\nbridge this gap, our approach incorporates a question paraphrase strategy,\nwhich aims at diversifying the linguistic forms of mathematical questions to\nimprove generalization. Additionally, specialized training objectives are\nemployed to guide the model's learning process, focusing on enhancing its\nunderstanding of mathematical concepts and reasoning processes. We conduct\nexperiments on four datasets using different LLMs, and demonstrate the\neffectiveness of our approach in improving LLMs' performance on mathematical\nreasoning tasks. Our findings underscore the significance of our methodology in\nthe advancement of large language models and its potential implications for\nreal-world applications that require mathematical reasoning abilities."
  },
  {
    "arxiv_id": "2412.19994",
    "title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
    "url": "http://arxiv.org/abs/2412.19994v1",
    "abstract": "Large Language Models (LLMs) have significantly transformed our daily life\nand established a new paradigm in natural language processing (NLP). However,\nthe predominant pretraining of LLMs on extensive web-based texts remains\ninsufficient for advanced scientific discovery, particularly in chemistry. The\nscarcity of specialized chemistry data, coupled with the complexity of\nmulti-modal data such as 2D graph, 3D structure and spectrum, present distinct\nchallenges. Although several studies have reviewed Pretrained Language Models\n(PLMs) in chemistry, there is a conspicuous absence of a systematic survey\nspecifically focused on chemistry-oriented LLMs. In this paper, we outline\nmethodologies for incorporating domain-specific chemistry knowledge and\nmulti-modal information into LLMs, we also conceptualize chemistry LLMs as\nagents using chemistry tools and investigate their potential to accelerate\nscientific research. Additionally, we conclude the existing benchmarks to\nevaluate chemistry ability of LLMs. Finally, we critically examine the current\nchallenges and identify promising directions for future research. Through this\ncomprehensive survey, we aim to assist researchers in staying at the forefront\nof developments in chemistry LLMs and to inspire innovative applications in the\nfield."
  },
  {
    "arxiv_id": "2412.19925",
    "title": "HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models",
    "url": "http://arxiv.org/abs/2412.19925v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nby understanding and generating human-like text. However, the increasing demand\nfor more sophisticated LLMs presents significant computational challenges due\nto their scale and complexity. This paper introduces Hardware Accelerated\nDecoding (HADES), a novel approach to enhance the performance and energy\nefficiency of LLMs. We address the design of an LLM accelerator with\nhardware-level speculative decoding support, a concept not previously explored\nin existing literature. Our work demonstrates how speculative decoding can\nsignificantly improve the efficiency of LLM operations, paving the way for more\nadvanced and practical applications of these models."
  },
  {
    "arxiv_id": "2501.01329",
    "title": "The Prompt Alchemist: Automated LLM-Tailored Prompt Optimization for Test Case Generation",
    "url": "http://arxiv.org/abs/2501.01329v1",
    "abstract": "Test cases are essential for validating the reliability and quality of\nsoftware applications. Recent studies have demonstrated the capability of Large\nLanguage Models (LLMs) to generate useful test cases for given source code.\nHowever, the existing work primarily relies on human-written plain prompts,\nwhich often leads to suboptimal results since the performance of LLMs can be\nhighly influenced by the prompts. Moreover, these approaches use the same\nprompt for all LLMs, overlooking the fact that different LLMs might be best\nsuited to different prompts. Given the wide variety of possible prompt\nformulations, automatically discovering the optimal prompt for each LLM\npresents a significant challenge. Although there are methods on automated\nprompt optimization in the natural language processing field, they are hard to\nproduce effective prompts for the test case generation task. First, the methods\niteratively optimize prompts by simply combining and mutating existing ones\nwithout proper guidance, resulting in prompts that lack diversity and tend to\nrepeat the same errors in the generated test cases. Second, the prompts are\ngenerally lack of domain contextual knowledge, limiting LLMs' performance in\nthe task."
  },
  {
    "arxiv_id": "2501.00803",
    "title": "Reasoning-Oriented and Analogy-Based Methods for Locating and Editing in Zero-Shot Event-Relational Reasoning",
    "url": "http://arxiv.org/abs/2501.00803v1",
    "abstract": "Zero-shot event-relational reasoning is an important task in natural language\nprocessing, and existing methods jointly learn a variety of event-relational\nprefixes and inference-form prefixes to achieve such tasks. However, training\nprefixes consumes large computational resources and lacks interpretability.\nAdditionally, learning various relational and inferential knowledge\ninefficiently exploits the connections between tasks. Therefore, we first\npropose a method for Reasoning-Oriented Locating and Editing (ROLE), which\nlocates and edits the key modules of the language model for reasoning about\nevent relations, enhancing interpretability and also resource-efficiently\noptimizing the reasoning ability. Subsequently, we propose a method for\nAnalogy-Based Locating and Editing (ABLE), which efficiently exploits the\nsimilarities and differences between tasks to optimize the zero-shot reasoning\ncapability. Experimental results show that ROLE improves interpretability and\nreasoning performance with reduced computational cost. ABLE achieves SOTA\nresults in zero-shot reasoning."
  },
  {
    "arxiv_id": "2501.00559",
    "title": "AraSTEM: A Native Arabic Multiple Choice Question Benchmark for Evaluating LLMs Knowledge In STEM Subjects",
    "url": "http://arxiv.org/abs/2501.00559v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, not only in\ngenerating human-like text, but also in acquiring knowledge. This highlights\nthe need to go beyond the typical Natural Language Processing downstream\nbenchmarks and asses the various aspects of LLMs including knowledge and\nreasoning. Numerous benchmarks have been developed to evaluate LLMs knowledge,\nbut they predominantly focus on the English language. Given that many LLMs are\nmultilingual, relying solely on benchmarking English knowledge is insufficient.\nTo address this issue, we introduce AraSTEM, a new Arabic multiple-choice\nquestion dataset aimed at evaluating LLMs knowledge in STEM subjects. The\ndataset spans a range of topics at different levels which requires models to\ndemonstrate a deep understanding of scientific Arabic in order to achieve high\naccuracy. Our findings show that publicly available models of varying sizes\nstruggle with this dataset, and underscores the need for more localized\nlanguage models. The dataset is freely accessible on Hugging Face."
  },
  {
    "arxiv_id": "2501.00539",
    "title": "MCP-Solver: Integrating Language Models with Constraint Programming Systems",
    "url": "http://arxiv.org/abs/2501.00539v1",
    "abstract": "The MCP Solver bridges Large Language Models (LLMs) with symbolic solvers\nthrough the Model Context Protocol (MCP), an open-source standard for AI system\nintegration. Providing LLMs access to formal solving and reasoning capabilities\naddresses their key deficiency while leveraging their strengths. Our\nimplementation offers interfaces for constraint programming (Minizinc),\npropositional satisfiability (PySAT), and SAT modulo Theories (Python Z3). The\nsystem employs an editing approach with iterated validation to ensure model\nconsistency during modifications and enable structured refinement."
  },
  {
    "arxiv_id": "2501.01832",
    "title": "Time Series Language Model for Descriptive Caption Generation",
    "url": "http://arxiv.org/abs/2501.01832v1",
    "abstract": "The automatic generation of representative natural language descriptions for\nobservable patterns in time series data enhances interpretability, simplifies\nanalysis and increases cross-domain utility of temporal data. While pre-trained\nfoundation models have made considerable progress in natural language\nprocessing (NLP) and computer vision (CV), their application to time series\nanalysis has been hindered by data scarcity. Although several large language\nmodel (LLM)-based methods have been proposed for time series forecasting, time\nseries captioning is under-explored in the context of LLMs. In this paper, we\nintroduce TSLM, a novel time series language model designed specifically for\ntime series captioning. TSLM operates as an encoder-decoder model, leveraging\nboth text prompts and time series data representations to capture subtle\ntemporal patterns across multiple phases and generate precise textual\ndescriptions of time series inputs. TSLM addresses the data scarcity problem in\ntime series captioning by first leveraging an in-context prompting synthetic\ndata generation, and second denoising the generated data via a novel\ncross-modal dense retrieval scoring applied to time series-caption pairs.\nExperimental findings on various time series captioning datasets demonstrate\nthat TSLM outperforms existing state-of-the-art approaches from multiple data\nmodalities by a significant margin."
  },
  {
    "arxiv_id": "2501.02844",
    "title": "Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification",
    "url": "http://arxiv.org/abs/2501.02844v1",
    "abstract": "Text classification is a fundamental task in data mining, pivotal to various\napplications such as tabular understanding and recommendation. Although neural\nnetwork-based models, such as CNN and BERT, have demonstrated remarkable\nperformance in text classification, their effectiveness heavily relies on\nabundant labeled training data. This dependency makes these models less\neffective in dynamic few-shot text classification, where labeled data is\nscarce, and new target labels frequently appear based on application needs.\nRecently, large language models (LLMs) have shown promise due to their\nextensive pretraining and contextual understanding ability. Current approaches\nprovide LLMs with text inputs, candidate labels, and additional side\ninformation (e.g., descriptions) to classify texts. However, their\neffectiveness is hindered by the increased input size and the noise introduced\nthrough side information processing. To address these limitations, we propose a\ngraph-based online retrieval-augmented generation framework, namely GORAG, for\ndynamic few-shot text classification. Rather than treating each input\nindependently, GORAG constructs and maintains a weighted graph by extracting\nside information across all target texts. In this graph, text keywords and\nlabels are represented as nodes, with edges indicating the correlations between\nthem. To model these correlations, GORAG employs an edge weighting mechanism to\nprioritize the importance and reliability of extracted information and\ndynamically retrieves relevant context using a minimum-cost spanning tree\ntailored for each text input. Empirical evaluations demonstrate that GORAG\noutperforms existing approaches by providing more comprehensive and precise\ncontextual information."
  },
  {
    "arxiv_id": "2501.02599",
    "title": "Empowering Bengali Education with AI: Solving Bengali Math Word Problems through Transformer Models",
    "url": "http://arxiv.org/abs/2501.02599v1",
    "abstract": "Mathematical word problems (MWPs) involve the task of converting textual\ndescriptions into mathematical equations. This poses a significant challenge in\nnatural language processing, particularly for low-resource languages such as\nBengali. This paper addresses this challenge by developing an innovative\napproach to solving Bengali MWPs using transformer-based models, including\nBasic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the\n\"PatiGonit\" dataset was introduced, containing 10,000 Bengali math problems,\nand these models were fine-tuned to translate the word problems into equations\naccurately. The evaluation revealed that the mT5 model achieved the highest\naccuracy of 97.30%, demonstrating the effectiveness of transformer models in\nthis domain. This research marks a significant step forward in Bengali natural\nlanguage processing, offering valuable methodologies and resources for\neducational AI tools. By improving math education, it also supports the\ndevelopment of advanced problem-solving skills for Bengali-speaking students."
  },
  {
    "arxiv_id": "2501.02547",
    "title": "Transformers Simulate MLE for Sequence Generation in Bayesian Networks",
    "url": "http://arxiv.org/abs/2501.02547v1",
    "abstract": "Transformers have achieved significant success in various fields, notably\nexcelling in tasks involving sequential data like natural language processing.\nDespite these achievements, the theoretical understanding of transformers'\ncapabilities remains limited. In this paper, we investigate the theoretical\ncapabilities of transformers to autoregressively generate sequences in Bayesian\nnetworks based on in-context maximum likelihood estimation (MLE). Specifically,\nwe consider a setting where a context is formed by a set of independent\nsequences generated according to a Bayesian network. We demonstrate that there\nexists a simple transformer model that can (i) estimate the conditional\nprobabilities of the Bayesian network according to the context, and (ii)\nautoregressively generate a new sample according to the Bayesian network with\nestimated conditional probabilities. We further demonstrate in extensive\nexperiments that such a transformer does not only exist in theory, but can also\nbe effectively obtained through training. Our analysis highlights the potential\nof transformers to learn complex probabilistic models and contributes to a\nbetter understanding of large language models as a powerful class of sequence\ngenerators."
  },
  {
    "arxiv_id": "2501.02407",
    "title": "Anonymization by Design of Language Modeling",
    "url": "http://arxiv.org/abs/2501.02407v1",
    "abstract": "Rapid advances in Natural Language Processing (NLP) have revolutionized many\nfields, including healthcare. However, these advances raise significant privacy\nconcerns, especially when pre-trained models fine-tuned and specialized on\nsensitive data can memorize and then expose and regurgitate personal\ninformation. This paper presents a privacy-preserving language modeling\napproach to address the problem of language models anonymization, and thus\npromote their sharing. Specifically, we propose both a Masking Language\nModeling (MLM) methodology to specialize a BERT-like language model, and a\nCausal Language Modeling (CLM) methodology to specialize a GPT-like model that\navoids the model from memorizing direct and indirect identifying information\npresent in the training data. We have comprehensively evaluated our approaches\nusing a medical dataset and compared them against different baselines. Our\nresults indicate that by avoiding memorizing both direct and indirect\nidentifiers during model specialization, our masking and causal language\nmodeling schemes offer a good tradeoff for maintaining high privacy while\nretaining high utility."
  },
  {
    "arxiv_id": "2501.02237",
    "title": "Financial Named Entity Recognition: How Far Can LLM Go?",
    "url": "http://arxiv.org/abs/2501.02237v1",
    "abstract": "The surge of large language models (LLMs) has revolutionized the extraction\nand analysis of crucial information from a growing volume of financial\nstatements, announcements, and business news. Recognition for named entities to\nconstruct structured data poses a significant challenge in analyzing financial\ndocuments and is a foundational task for intelligent financial analytics.\nHowever, how effective are these generic LLMs and their performance under\nvarious prompts are yet need a better understanding. To fill in the blank, we\npresent a systematic evaluation of state-of-the-art LLMs and prompting methods\nin the financial Named Entity Recognition (NER) problem. Specifically, our\nexperimental results highlight their strengths and limitations, identify five\nrepresentative failure types, and provide insights into their potential and\nchallenges for domain-specific tasks."
  },
  {
    "arxiv_id": "2501.03928",
    "title": "From Newswire to Nexus: Using text-based actor embeddings and transformer networks to forecast conflict dynamics",
    "url": "http://arxiv.org/abs/2501.03928v1",
    "abstract": "This study advances the field of conflict forecasting by using text-based\nactor embeddings with transformer models to predict dynamic changes in violent\nconflict patterns at the actor level. More specifically, we combine newswire\ntexts with structured conflict event data and leverage recent advances in\nNatural Language Processing (NLP) techniques to forecast escalations and\nde-escalations among conflicting actors, such as governments, militias,\nseparatist movements, and terrorists. This new approach accurately and promptly\ncaptures the inherently volatile patterns of violent conflicts, which existing\nmethods have not been able to achieve. To create this framework, we began by\ncurating and annotating a vast international newswire corpus, leveraging\nhand-labeled event data from the Uppsala Conflict Data Program. By using this\nhybrid dataset, our models can incorporate the textual context of news sources\nalong with the precision and detail of structured event data. This combination\nenables us to make both dynamic and granular predictions about conflict\ndevelopments. We validate our approach through rigorous back-testing against\nhistorical events, demonstrating superior out-of-sample predictive power. We\nfind that our approach is quite effective in identifying and predicting phases\nof conflict escalation and de-escalation, surpassing the capabilities of\ntraditional models. By focusing on actor interactions, our explicit goal is to\nprovide actionable insights to policymakers, humanitarian organizations, and\npeacekeeping operations in order to enable targeted and effective intervention\nstrategies."
  },
  {
    "arxiv_id": "2501.03904",
    "title": "Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study",
    "url": "http://arxiv.org/abs/2501.03904v1",
    "abstract": "The integration of large language models (LLMs) into public transit systems\npresents a transformative opportunity to enhance urban mobility. This study\nexplores the potential of LLMs to revolutionize public transportation\nmanagement within the context of San Antonio's transit system. Leveraging the\ncapabilities of LLMs in natural language processing and data analysis, we\ninvestigate their capabilities to optimize route planning, reduce wait times,\nand provide personalized travel assistance. By utilizing the General Transit\nFeed Specification (GTFS) and other relevant data, this research aims to\ndemonstrate how LLMs can potentially improve resource allocation, elevate\npassenger satisfaction, and inform data-driven decision-making in transit\noperations. A comparative analysis of different ChatGPT models was conducted to\nassess their ability to understand transportation information, retrieve\nrelevant data, and provide comprehensive responses. Findings from this study\nsuggest that while LLMs hold immense promise for public transit, careful\nengineering and fine-tuning are essential to realizing their full potential.\nSan Antonio serves as a case study to inform the development of LLM-powered\ntransit systems in other urban environments."
  },
  {
    "arxiv_id": "2501.03857",
    "title": "Progressive Document-level Text Simplification via Large Language Models",
    "url": "http://arxiv.org/abs/2501.03857v1",
    "abstract": "Research on text simplification has primarily focused on lexical and\nsentence-level changes. Long document-level simplification (DS) is still\nrelatively unexplored. Large Language Models (LLMs), like ChatGPT, have\nexcelled in many natural language processing tasks. However, their performance\non DS tasks is unsatisfactory, as they often treat DS as merely document\nsummarization. For the DS task, the generated long sequences not only must\nmaintain consistency with the original document throughout, but complete\nmoderate simplification operations encompassing discourses, sentences, and\nword-level simplifications. Human editors employ a hierarchical complexity\nsimplification strategy to simplify documents. This study delves into\nsimulating this strategy through the utilization of a multi-stage collaboration\nusing LLMs. We propose a progressive simplification method (ProgDS) by\nhierarchically decomposing the task, including the discourse-level,\ntopic-level, and lexical-level simplification. Experimental results demonstrate\nthat ProgDS significantly outperforms existing smaller models or direct\nprompting with LLMs, advancing the state-of-the-art in the document\nsimplification task."
  },
  {
    "arxiv_id": "2501.03747",
    "title": "Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series",
    "url": "http://arxiv.org/abs/2501.03747v1",
    "abstract": "Recently, leveraging pre-trained Large Language Models (LLMs) for time series\n(TS) tasks has gained increasing attention, which involves activating and\nenhancing LLMs' capabilities. Many methods aim to activate LLMs' capabilities\nbased on token-level alignment but overlook LLMs' inherent strength on natural\nlanguage processing -- their deep understanding of linguistic logic and\nstructure rather than superficial embedding processing. We propose\nContext-Alignment, a new paradigm that aligns TS with a linguistic component in\nthe language environments familiar to LLMs to enable LLMs to contextualize and\ncomprehend TS data, thereby activating their capabilities. Specifically, such\ncontext-level alignment comprises structural alignment and logical alignment,\nwhich is achieved by a Dual-Scale Context-Alignment GNNs (DSCA-GNNs) applied to\nTS-language multimodal inputs. Structural alignment utilizes dual-scale nodes\nto describe hierarchical structure in TS-language, enabling LLMs treat long TS\ndata as a whole linguistic component while preserving intrinsic token features.\nLogical alignment uses directed edges to guide logical relationships, ensuring\ncoherence in the contextual semantics. Demonstration examples prompt are\nemployed to construct Demonstration Examples based Context-Alignment (DECA)\nfollowing DSCA-GNNs framework. DECA can be flexibly and repeatedly integrated\ninto various layers of pre-trained LLMs to improve awareness of logic and\nstructure, thereby enhancing performance. Extensive experiments show the\neffectiveness of DECA and the importance of Context-Alignment across tasks,\nparticularly in few-shot and zero-shot forecasting, confirming that\nContext-Alignment provide powerful prior knowledge on context."
  },
  {
    "arxiv_id": "2501.03456",
    "title": "Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction",
    "url": "http://arxiv.org/abs/2501.03456v1",
    "abstract": "In this study, we explore the use of a transformer-based language model as an\nencoder to predict the band gaps of semiconductor materials directly from their\ntext descriptions. Quantum chemistry simulations, including Density Functional\nTheory (DFT), are computationally intensive and time-consuming, which limits\ntheir practicality for high-throughput material screening, particularly for\ncomplex systems. Shallow machine learning (ML) models, while effective, often\nrequire extensive data preprocessing to convert non-numerical material\nproperties into numerical inputs. In contrast, our approach leverages textual\ndata directly, bypassing the need for complex feature engineering. We generate\nmaterial descriptions in two formats: formatted strings combining features and\nnatural language text generated using the ChatGPT API. We demonstrate that the\nRoBERTa model, pre-trained on natural language processing tasks, performs\neffectively as an encoder for prediction tasks. With minimal fine-tuning, it\nachieves a mean absolute error (MAE) of approximately 0.33 eV, performing\nbetter than shallow machine learning models such as Support Vector Regression,\nRandom Forest, and XGBoost. Even when only the linear regression head is\ntrained while keeping the RoBERTa encoder layers frozen, the accuracy remains\nnearly identical to that of the fully trained model. This demonstrates that the\npre-trained RoBERTa encoder is highly adaptable for processing domain-specific\ntext related to material properties, such as the band gap, significantly\nreducing the need for extensive retraining. This study highlights the potential\nof transformer-based language models to serve as efficient and versatile\nencoders for semiconductor materials property prediction tasks."
  },
  {
    "arxiv_id": "2501.05224",
    "title": "Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond",
    "url": "http://arxiv.org/abs/2501.05224v1",
    "abstract": "In this work, we explore the application of Large Language Models to\nzero-shot Lay Summarisation. We propose a novel two-stage framework for Lay\nSummarisation based on real-life processes, and find that summaries generated\nwith this method are increasingly preferred by human judges for larger models.\nTo help establish best practices for employing LLMs in zero-shot settings, we\nalso assess the ability of LLMs as judges, finding that they are able to\nreplicate the preferences of human judges. Finally, we take the initial steps\ntowards Lay Summarisation for Natural Language Processing (NLP) articles,\nfinding that LLMs are able to generalise to this new domain, and further\nhighlighting the greater utility of summaries generated by our proposed\napproach via an in-depth human evaluation."
  },
  {
    "arxiv_id": "2501.05051",
    "title": "On the Generalizability of Transformer Models to Code Completions of Different Lengths",
    "url": "http://arxiv.org/abs/2501.05051v1",
    "abstract": "The programming landscape is nowadays being reshaped by the advent of Large\nLanguage Models (LLMs) able to automate code-related tasks related to code\nimplementation (e.g., code completion) and comprehension (e.g., code\nsummarization). Such a paradigm shift comes with a number of implications\nrelated to how software will be written, maintained, and evolved. Also, these\nLLMs are extremely expensive to train, posing questions on their sustainability\nover time. Given their training cost, their ability to generalize, namely their\nability to work on task instances different from those on which they have been\ntrained, is an aspect worth being investigated. Previous work already showed\nthat transformer models can successfully support code completion in a\ncross-project setting. However, it is unclear whether LLM are able to\ngeneralize to inputs having lengths not seen during training. For example, it\nis known that training a model on short instances allows to substantially\nreduce the training cost. However, the extent to which such a model would\nprovide good performance on sequences having lengths not seen during training\nis not known. Many recent works in Natural Language Processing (NLP) tackled\nthis problem in the context of decoder-only LLMs, i.e., xPOS and ALiBi. To\nassess if these solutions extend to encoder-decoder LLMs usually adopted in the\ncode-related tasks, we present a large empirical study evaluating this\ngeneralization property of these and other encoding schemes proposed in the\nliterature, namely Sinusoidal, xPOS, ALiBi, and T5. We found that none of these\nsolutions successfully generalize to unseen lengths and that the only safe\nsolution is to ensure the representativeness in the training set of all lengths\nlikely to be encountered at inference time."
  },
  {
    "arxiv_id": "2501.05482",
    "title": "HP-BERT: A framework for longitudinal study of Hinduphobia on social media via LLMs",
    "url": "http://arxiv.org/abs/2501.05482v1",
    "abstract": "During the COVID-19 pandemic, community tensions intensified, fuelling\nHinduphobic sentiments and discrimination against individuals of Hindu descent\nwithin India and worldwide. Large language models (LLMs) have become prominent\nin natural language processing (NLP) tasks and social media analysis, enabling\nlongitudinal studies of platforms like X (formerly Twitter) for specific issues\nduring COVID-19. We present an abuse detection and sentiment analysis framework\nthat offers a longitudinal analysis of Hinduphobia on X (Twitter) during and\nafter the COVID-19 pandemic. This framework assesses the prevalence and\nintensity of Hinduphobic discourse, capturing elements such as derogatory jokes\nand racist remarks through sentiment analysis and abuse detection from\npre-trained and fine-tuned LLMs. Additionally, we curate and publish a\n\"Hinduphobic COVID-19 X (Twitter) Dataset\" of 8,000 tweets annotated for\nHinduphobic abuse detection, which is used to fine-tune a BERT model, resulting\nin the development of the Hinduphobic BERT (HP-BERT) model. We then further\nfine-tune HP-BERT using the SenWave dataset for multi-label sentiment analysis.\nOur study encompasses approximately 27.4 million tweets from six countries,\nincluding Australia, Brazil, India, Indonesia, Japan, and the United Kingdom.\nOur findings reveal a strong correlation between spikes in COVID-19 cases and\nsurges in Hinduphobic rhetoric, highlighting how political narratives,\nmisinformation, and targeted jokes contributed to communal polarisation. These\ninsights provide valuable guidance for developing strategies to mitigate\ncommunal tensions in future crises, both locally and globally. We advocate\nimplementing automated monitoring and removal of such content on social media\nto curb divisive discourse."
  },
  {
    "arxiv_id": "2501.07278",
    "title": "Lifelong Learning of Large Language Model based Agents: A Roadmap",
    "url": "http://arxiv.org/abs/2501.07278v1",
    "abstract": "Lifelong learning, also known as continual or incremental learning, is a\ncrucial component for advancing Artificial General Intelligence (AGI) by\nenabling systems to continuously adapt in dynamic environments. While large\nlanguage models (LLMs) have demonstrated impressive capabilities in natural\nlanguage processing, existing LLM agents are typically designed for static\nsystems and lack the ability to adapt over time in response to new challenges.\nThis survey is the first to systematically summarize the potential techniques\nfor incorporating lifelong learning into LLM-based agents. We categorize the\ncore components of these agents into three modules: the perception module for\nmultimodal input integration, the memory module for storing and retrieving\nevolving knowledge, and the action module for grounded interactions with the\ndynamic environment. We highlight how these pillars collectively enable\ncontinuous adaptation, mitigate catastrophic forgetting, and improve long-term\nperformance. This survey provides a roadmap for researchers and practitioners\nworking to develop lifelong learning capabilities in LLM agents, offering\ninsights into emerging trends, evaluation metrics, and application scenarios.\nRelevant literature and resources are available at \\href{this\nurl}{https://github.com/qianlima-lab/awesome-lifelong-llm-agent}."
  },
  {
    "arxiv_id": "2501.07237",
    "title": "Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training",
    "url": "http://arxiv.org/abs/2501.07237v1",
    "abstract": "Large language models (LLMs) have shown impressive performance across a range\nof natural language processing tasks. However, their vast number of parameters\nintroduces significant memory challenges during training, particularly when\nusing memory-intensive optimizers like Adam. Existing memory-efficient\nalgorithms often rely on techniques such as singular value decomposition\nprojection or weight freezing. While these approaches help alleviate memory\nconstraints, they generally produce suboptimal results compared to full-rank\nupdates. In this paper, we investigate the memory-efficient method beyond\nlow-rank training, proposing a novel solution called Gradient Wavelet Transform\n(GWT), which applies wavelet transforms to gradients in order to significantly\nreduce the memory requirements for maintaining optimizer states. We demonstrate\nthat GWT can be seamlessly integrated with memory-intensive optimizers,\nenabling efficient training without sacrificing performance. Through extensive\nexperiments on both pre-training and fine-tuning tasks, we show that GWT\nachieves state-of-the-art performance compared with advanced memory-efficient\noptimizers and full-rank approaches in terms of both memory usage and training\nperformance."
  },
  {
    "arxiv_id": "2501.08271",
    "title": "Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models",
    "url": "http://arxiv.org/abs/2501.08271v1",
    "abstract": "In this work, we investigate the efficacy of various adapter architectures on\nsupervised binary classification tasks from the SuperGLUE benchmark as well as\na supervised multi-class news category classification task from Kaggle.\nSpecifically, we compare classification performance and time complexity of\nthree transformer models, namely DistilBERT, ELECTRA, and BART, using\nconventional fine-tuning as well as nine state-of-the-art (SoTA) adapter\narchitectures. Our analysis reveals performance differences across adapter\narchitectures, highlighting their ability to achieve comparable or better\nperformance relative to fine-tuning at a fraction of the training time. Similar\nresults are observed on the new classification task, further supporting our\nfindings and demonstrating adapters as efficient and flexible alternatives to\nfine-tuning. This study provides valuable insights and guidelines for selecting\nand implementing adapters in diverse natural language processing (NLP)\napplications."
  },
  {
    "arxiv_id": "2501.08219",
    "title": "Investigating Energy Efficiency and Performance Trade-offs in LLM Inference Across Tasks and DVFS Settings",
    "url": "http://arxiv.org/abs/2501.08219v1",
    "abstract": "Large language models (LLMs) have shown significant improvements in many\nnatural language processing (NLP) tasks, accelerating their rapid adoption\nacross many industries. These models are resource-intensive, requiring\nextensive computational resources both during training and inference, leading\nto increased energy consumption and negative environmental impact. As their\nadoption accelerates, the sustainability of LLMs has become a critical issue,\nnecessitating strategies to optimize their runtime efficiency without\ncompromising performance. Hence, it is imperative to identify the parameters\nthat significantly influence the performance and energy efficiency of LLMs. To\nthat end, in this work, we investigate the effect of important parameters on\nthe performance and energy efficiency of LLMs during inference and examine\ntheir trade-offs.\n  First, we analyze how different types of models with varying numbers of\nparameters and architectures perform on tasks like text generation, question\nanswering, and summarization by benchmarking LLMs such as Falcon-7B,\nMistral-7B-v0.1, T5-3B, GPT-2, GPT-J-6B, and GPT-Neo-2.7B. Second, we study\ninput and output sequence characteristics such as sequence length concerning\nenergy consumption, performance, and throughput. Finally, we explore the impact\nof hardware-based power-saving techniques, i.e., Dynamic Voltage Frequency\nScaling (DVFS), on the models' latency and energy efficiency. Our extensive\nbenchmarking and statistical analysis reveal many interesting findings,\nuncovering how specific optimizations can reduce energy consumption while\nmaintaining throughput and accuracy. This study provides actionable insights\nfor researchers and practitioners to design energy-efficient LLM inference\nsystems."
  },
  {
    "arxiv_id": "2501.07774",
    "title": "Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors",
    "url": "http://arxiv.org/abs/2501.07774v1",
    "abstract": "Indoor localization in challenging non-line-of-sight (NLOS) environments\noften leads to mediocre accuracy with traditional approaches. Deep learning\n(DL) has been applied to tackle these challenges; however, many DL approaches\noverlook computational complexity, especially for floating-point operations\n(FLOPs), making them unsuitable for resource-limited devices. Transformer-based\nmodels have achieved remarkable success in natural language processing (NLP)\nand computer vision (CV) tasks, motivating their use in wireless applications.\nHowever, their use in indoor localization remains nascent, and directly\napplying Transformers for indoor localization can be both computationally\nintensive and exhibit limitations in accuracy. To address these challenges, in\nthis work, we introduce a novel tokenization approach, referred to as Sensor\nSnapshot Tokenization (SST), which preserves variable-specific representations\nof power delay profile (PDP) and enhances attention mechanisms by effectively\ncapturing multi-variate correlation. Complementing this, we propose a\nlightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)\nmodel, designed to reduce computational complexity without compromising\nlocalization accuracy. Together, these contributions mitigate the computational\nburden and dependency on large datasets, making Transformer models more\nefficient and suitable for resource-constrained scenarios. The proposed\ntokenization method enables the Vanilla Transformer to achieve a 90th\npercentile positioning error of 0.388 m in a highly NLOS indoor factory,\nsurpassing conventional tokenization methods. The L-SwiGLU ViT further reduces\nthe error to 0.355 m, achieving an 8.51% improvement. Additionally, the\nproposed model outperforms a 14.1 times larger model with a 46.13% improvement,\nunderscoring its computational efficiency."
  },
  {
    "arxiv_id": "2501.07766",
    "title": "Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey",
    "url": "http://arxiv.org/abs/2501.07766v1",
    "abstract": "Large language models (LLMs) have garnered significant attention for their\nsuperior performance in many knowledge-driven applications on the world wide\nweb.These models are designed to train hundreds of millions or more parameters\non large amounts of text data, enabling them to understand and generate\nnaturallanguage effectively. As the superior performance of LLMs becomes\napparent,they are increasingly being applied to knowledge graph embedding (KGE)\nrelated tasks to improve the processing results. Traditional KGE representation\nlearning methods map entities and relations into a low-dimensional vector\nspace, enablingthe triples in the knowledge graph to satisfy a specific scoring\nfunction in thevector space. However, based on the powerful language\nunderstanding and seman-tic modeling capabilities of LLMs, that have recently\nbeen invoked to varying degrees in different types of KGE related scenarios\nsuch as multi-modal KGE andopen KGE according to their task characteristics. In\nthis paper, we investigate awide range of approaches for performing\nLLMs-related tasks in different types of KGE scenarios. To better compare the\nvarious approaches, we summarize each KGE scenario in a classification.\nFinally, we discuss the applications in which the methods are mainly used and\nsuggest several forward-looking directions for the development of this new\nresearch area."
  },
  {
    "arxiv_id": "2501.08974",
    "title": "Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models",
    "url": "http://arxiv.org/abs/2501.08974v1",
    "abstract": "Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment\nanalysis that aims to extract and classify sentiments based on specific aspects\nor features of a product, service, or entity. Unlike traditional sentiment\nanalysis, which assigns a general sentiment score to entire reviews or texts,\nABSA focuses on breaking down the text into individual components or aspects\n(e.g., quality, price, service) and evaluating the sentiment towards each. This\nallows for a more granular level of understanding of customer opinions,\nenabling businesses to pinpoint specific areas of strength and improvement. The\nprocess involves several key steps, including aspect extraction, sentiment\nclassification, and aspect-level sentiment aggregation for a review paragraph\nor any other form that the users have provided. ABSA has significant\napplications in areas such as product reviews, social media monitoring,\ncustomer feedback analysis, and market research. By leveraging techniques from\nnatural language processing (NLP) and machine learning, ABSA facilitates the\nextraction of valuable insights, enabling companies to make data-driven\ndecisions that enhance customer satisfaction and optimize offerings. As ABSA\nevolves, it holds the potential to greatly improve personalized customer\nexperiences by providing a deeper understanding of sentiment across various\nproduct aspects. In this work, we have analyzed the strength of LLMs for a\ncomplete cross-domain aspect-based sentiment analysis with the aim of defining\nthe framework for certain products and using it for other similar situations.\nWe argue that it is possible to that at an effectiveness of 92\\% accuracy for\nthe Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12."
  },
  {
    "arxiv_id": "2501.08598",
    "title": "LlamaRestTest: Effective REST API Testing with Small Language Models",
    "url": "http://arxiv.org/abs/2501.08598v1",
    "abstract": "Modern web services rely heavily on REST APIs, typically documented using the\nOpenAPI specification. The widespread adoption of this standard has resulted in\nthe development of many black-box testing tools that generate tests based on\nOpenAPI specifications. Although Large Language Models (LLMs) have shown\npromising test-generation abilities, their application to REST API testing\nremains mostly unexplored. We present LlamaRestTest, a novel approach that\nemploys two custom LLMs-created by fine-tuning and quantizing the Llama3-8B\nmodel using mined datasets of REST API example values and inter-parameter\ndependencies-to generate realistic test inputs and uncover inter-parameter\ndependencies during the testing process by analyzing server responses. We\nevaluated LlamaRestTest on 12 real-world services (including popular services\nsuch as Spotify), comparing it against RESTGPT, a GPT-powered\nspecification-enhancement tool, as well as several state-of-the-art REST API\ntesting tools, including RESTler, MoRest, EvoMaster, and ARAT-RL. Our results\ndemonstrate that fine-tuning enables smaller models to outperform much larger\nmodels in detecting actionable parameter-dependency rules and generating valid\ninputs for REST API testing. We also evaluated different tool configurations,\nranging from the base Llama3-8B model to fine-tuned versions, and explored\nmultiple quantization techniques, including 2-bit, 4-bit, and 8-bit integer\nformats. Our study shows that small language models can perform as well as, or\nbetter than, large language models in REST API testing, balancing effectiveness\nand efficiency. Furthermore, LlamaRestTest outperforms state-of-the-art REST\nAPI testing tools in code coverage achieved and internal server errors\nidentified, even when those tools use RESTGPT-enhanced specifications."
  },
  {
    "arxiv_id": "2501.08537",
    "title": "Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers",
    "url": "http://arxiv.org/abs/2501.08537v1",
    "abstract": "Transformers have demonstrated impressive capabilities across various tasks,\nyet their performance on compositional problems remains a subject of debate. In\nthis study, we investigate the internal mechanisms underlying Transformers'\nbehavior in compositional tasks. We find that complexity control strategies\nsignificantly influence whether the model learns primitive-level rules that\ngeneralize out-of-distribution (reasoning-based solutions) or relies solely on\nmemorized mappings (memory-based solutions). By applying masking strategies to\nthe model's information circuits and employing multiple complexity metrics, we\nreveal distinct internal working mechanisms associated with different solution\ntypes. Further analysis reveals that reasoning-based solutions exhibit a lower\ncomplexity bias, which aligns with the well-studied neuron condensation\nphenomenon. This lower complexity bias is hypothesized to be the key factor\nenabling these solutions to learn reasoning rules. We validate these\nconclusions across multiple real-world datasets, including image generation and\nnatural language processing tasks, confirming the broad applicability of our\nfindings."
  },
  {
    "arxiv_id": "2501.08460",
    "title": "Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time",
    "url": "http://arxiv.org/abs/2501.08460v1",
    "abstract": "In the current era of Machine Learning, Transformers have become the de facto\napproach across a variety of domains, such as computer vision and natural\nlanguage processing. Transformer-based solutions are the backbone of current\nstate-of-the-art methods for language generation, image and video\nclassification, segmentation, action and object recognition, among many others.\nInterestingly enough, while these state-of-the-art methods produce impressive\nresults in their respective domains, the problem of understanding the\nrelationship between vision and language is still beyond our reach. In this\nwork, we propose a common ground between vision and language based on events in\nspace and time in an explainable and programmatic way, to connect\nlearning-based vision and language state of the art models and provide a\nsolution to the long standing problem of describing videos in natural language.\nWe validate that our algorithmic approach is able to generate coherent, rich\nand relevant textual descriptions on videos collected from a variety of\ndatasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern\nLLM-as-a-Jury approach."
  },
  {
    "arxiv_id": "2501.08457",
    "title": "Large Language Models For Text Classification: Case Study And Comprehensive Review",
    "url": "http://arxiv.org/abs/2501.08457v1",
    "abstract": "Unlocking the potential of Large Language Models (LLMs) in data\nclassification represents a promising frontier in natural language processing.\nIn this work, we evaluate the performance of different LLMs in comparison with\nstate-of-the-art deep-learning and machine-learning models, in two different\nclassification scenarios: i) the classification of employees' working locations\nbased on job reviews posted online (multiclass classification), and 2) the\nclassification of news articles as fake or not (binary classification). Our\nanalysis encompasses a diverse range of language models differentiating in\nsize, quantization, and architecture. We explore the impact of alternative\nprompting techniques and evaluate the models based on the weighted F1-score.\nAlso, we examine the trade-off between performance (F1-score) and time\n(inference response time) for each language model to provide a more nuanced\nunderstanding of each model's practical applicability. Our work reveals\nsignificant variations in model responses based on the prompting strategies. We\nfind that LLMs, particularly Llama3 and GPT-4, can outperform traditional\nmethods in complex classification tasks, such as multiclass classification,\nthough at the cost of longer inference times. In contrast, simpler ML models\noffer better performance-to-time trade-offs in simpler binary classification\ntasks."
  },
  {
    "arxiv_id": "2501.08454",
    "title": "Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack",
    "url": "http://arxiv.org/abs/2501.08454v1",
    "abstract": "Large language models (LLMs) have become essential digital task assistance\ntools. Their training relies heavily on the collection of vast amounts of data,\nwhich may include copyright-protected or sensitive information. Recent studies\non the detection of pretraining data in LLMs have primarily focused on\nsentence-level or paragraph-level membership inference attacks (MIAs), usually\ninvolving probability analysis of the target model prediction tokens. However,\nthe proposed methods often demonstrate poor performance, specifically in terms\nof accuracy, failing to account for the semantic importance of textual content\nand word significance. To address these shortcomings, we propose Tag&Tab, a\nnovel approach for detecting data that has been used as part of the LLM\npretraining. Our method leverages advanced natural language processing (NLP)\ntechniques to tag keywords in the input text - a process we term Tagging. Then,\nthe LLM is used to obtain the probabilities of these keywords and calculate\ntheir average log-likelihood to determine input text membership, a process we\nrefer to as Tabbing. Our experiments on three benchmark datasets (BookMIA,\nMIMIR, and the Pile) and several open-source LLMs of varying sizes demonstrate\nan average increase in the AUC scores ranging from 4.1% to 12.1% over\nstate-of-the-art methods. Tag&Tab not only sets a new standard for data leakage\ndetection in LLMs, but its outstanding performance is a testament to the\nimportance of words in MIAs on LLMs."
  },
  {
    "arxiv_id": "2501.09588",
    "title": "Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures",
    "url": "http://arxiv.org/abs/2501.09588v1",
    "abstract": "Transformer architectures have become the standard neural network model for\nvarious machine learning applications including natural language processing and\ncomputer vision. However, the compute and memory requirements introduced by\ntransformer models make them challenging to adopt for edge applications.\nFurthermore, fine-tuning pre-trained transformers (e.g., foundation models) is\na common task to enhance the model's predictive performance on specific\ntasks/applications. Existing transformer accelerators are oblivious to\ncomplexities introduced by fine-tuning. In this paper, we propose the design of\na three-dimensional (3D) heterogeneous architecture referred to as Atleus that\nincorporates heterogeneous computing resources specifically optimized to\naccelerate transformer models for the dual purposes of fine-tuning and\ninference. Specifically, Atleus utilizes non-volatile memory and systolic array\nfor accelerating transformer computational kernels using an integrated 3D\nplatform. Moreover, we design a suitable NoC to achieve high performance and\nenergy efficiency. Finally, Atleus adopts an effective quantization scheme to\nsupport model compression. Experimental results demonstrate that Atleus\noutperforms existing state-of-the-art by up to 56x and 64.5x in terms of\nperformance and energy efficiency respectively"
  },
  {
    "arxiv_id": "2501.09410",
    "title": "MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models",
    "url": "http://arxiv.org/abs/2501.09410v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of natural language processing tasks. Exploiting the heterogeneous\ncapabilities of edge LLMs is crucial for diverse emerging applications, as it\nenables greater cost-effectiveness and reduced latency. In this work, we\nintroduce \\textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative\ninference framework for edge LLMs. We formulate the joint gating and expert\nselection problem to optimize inference performance under energy and latency\nconstraints. Unlike conventional MoE problems, LLM expert selection is\nsignificantly more challenging due to the combinatorial nature and the\nheterogeneity of edge LLMs across various attributes. To this end, we propose a\ntwo-level expert selection mechanism through which we uncover an\noptimality-preserving property of gating parameters across expert selections.\nThis property enables the decomposition of the training and selection\nprocesses, significantly reducing complexity. Furthermore, we leverage the\nobjective's monotonicity and design a discrete monotonic optimization algorithm\nfor optimal expert selection. We implement edge servers with NVIDIA Jetson AGX\nOrins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results\nvalidate that performance improvements of various LLM models and show that our\nMoE$^2$ method can achieve optimal trade-offs among different delay and energy\nbudgets, and outperforms baselines under various system resource constraints."
  },
  {
    "arxiv_id": "2501.09265",
    "title": "Perspective Transition of Large Language Models for Solving Subjective Tasks",
    "url": "http://arxiv.org/abs/2501.09265v1",
    "abstract": "Large language models (LLMs) have revolutionized the field of natural\nlanguage processing, enabling remarkable progress in various tasks. Different\nfrom objective tasks such as commonsense reasoning and arithmetic\nquestion-answering, the performance of LLMs on subjective tasks is still\nlimited, where the perspective on the specific problem plays crucial roles for\nbetter interpreting the context and giving proper response. For example, in\ncertain scenarios, LLMs may perform better when answering from an expert role\nperspective, potentially eliciting their relevant domain knowledge. In\ncontrast, in some scenarios, LLMs may provide more accurate responses when\nanswering from a third-person standpoint, enabling a more comprehensive\nunderstanding of the problem and potentially mitigating inherent biases. In\nthis paper, we propose Reasoning through Perspective Transition (RPT), a method\nbased on in-context learning that enables LLMs to dynamically select among\ndirect, role, and third-person perspectives for the best way to solve\ncorresponding subjective problem. Through extensive experiments on totally 12\nsubjective tasks by using both closed-source and open-source LLMs including\nGPT-4, GPT-3.5, Llama-3, and Qwen-2, our method outperforms widely used single\nfixed perspective based methods such as chain-of-thought prompting and expert\nprompting, highlights the intricate ways that LLMs can adapt their perspectives\nto provide nuanced and contextually appropriate responses for different\nproblems."
  },
  {
    "arxiv_id": "2501.09223",
    "title": "Foundations of Large Language Models",
    "url": "http://arxiv.org/abs/2501.09223v1",
    "abstract": "This is a book about large language models. As indicated by the title, it\nprimarily focuses on foundational concepts rather than comprehensive coverage\nof all cutting-edge technologies. The book is structured into four main\nchapters, each exploring a key area: pre-training, generative models, prompting\ntechniques, and alignment methods. It is intended for college students,\nprofessionals, and practitioners in natural language processing and related\nfields, and can serve as a reference for anyone interested in large language\nmodels."
  },
  {
    "arxiv_id": "2501.10322",
    "title": "Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models",
    "url": "http://arxiv.org/abs/2501.10322v1",
    "abstract": "Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains."
  },
  {
    "arxiv_id": "2501.10175",
    "title": "Multi-stage Training of Bilingual Islamic LLM for Neural Passage Retrieval",
    "url": "http://arxiv.org/abs/2501.10175v1",
    "abstract": "This study examines the use of Natural Language Processing (NLP) technology\nwithin the Islamic domain, focusing on developing an Islamic neural retrieval\nmodel. By leveraging the robust XLM-R model, the research employs a language\nreduction technique to create a lightweight bilingual large language model\n(LLM). Our approach for domain adaptation addresses the unique challenges faced\nin the Islamic domain, where substantial in-domain corpora exist only in Arabic\nwhile limited in other languages, including English.\n  The work utilizes a multi-stage training process for retrieval models,\nincorporating large retrieval datasets, such as MS MARCO, and smaller,\nin-domain datasets to improve retrieval performance. Additionally, we have\ncurated an in-domain retrieval dataset in English by employing data\naugmentation techniques and involving a reliable Islamic source. This approach\nenhances the domain-specific dataset for retrieval, leading to further\nperformance gains.\n  The findings suggest that combining domain adaptation and a multi-stage\ntraining method for the bilingual Islamic neural retrieval model enables it to\noutperform monolingual models on downstream retrieval tasks."
  },
  {
    "arxiv_id": "2501.10150",
    "title": "Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation",
    "url": "http://arxiv.org/abs/2501.10150v1",
    "abstract": "Mitigation of biases, such as language models' reliance on gender\nstereotypes, is a crucial endeavor required for the creation of reliable and\nuseful language technology. The crucial aspect of debiasing is to ensure that\nthe models preserve their versatile capabilities, including their ability to\nsolve language tasks and equitably represent various genders. To address this\nissue, we introduce a streamlined Dual Dabiasing Algorithm through Model\nAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction of\nstereotypical bias while preserving desired factual gender information encoded\nby language models. We show that 2DAMA effectively reduces gender bias in\nEnglish and is one of the first approaches facilitating the mitigation of\nstereotypical tendencies in translation. The proposed method's key advantage is\nthe preservation of factual gender cues, which are useful in a wide range of\nnatural language processing tasks."
  },
  {
    "arxiv_id": "2501.12372",
    "title": "Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL",
    "url": "http://arxiv.org/abs/2501.12372v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of natural language processing tasks. In particular, improvements in\nreasoning abilities and the expansion of context windows have opened new\navenues for leveraging these powerful models. NL2SQL is challenging in that the\nnatural language question is inherently ambiguous, while the SQL generation\nrequires a precise understanding of complex data schema and semantics. One\napproach to this semantic ambiguous problem is to provide more and sufficient\ncontextual information.\n  In this work, we explore the performance and the latency trade-offs of the\nextended context window (a.k.a., long context) offered by Google's\nstate-of-the-art LLM (\\textit{gemini-1.5-pro}). We study the impact of various\ncontextual information, including column example values, question and SQL query\npairs, user-provided hints, SQL documentation, and schema. To the best of our\nknowledge, this is the first work to study how the extended context window and\nextra contextual information can help NL2SQL generation with respect to both\naccuracy and latency cost. We show that long context LLMs are robust and do not\nget lost in the extended contextual information. Additionally, our long-context\nNL2SQL pipeline based on Google's \\textit{gemini-pro-1.5} achieve strong\nperformances on various benchmark datasets without finetuning and expensive\nself-consistency based techniques."
  },
  {
    "arxiv_id": "2501.12356",
    "title": "Vision-Language Models for Automated Chest X-ray Interpretation: Leveraging ViT and GPT-2",
    "url": "http://arxiv.org/abs/2501.12356v1",
    "abstract": "Radiology plays a pivotal role in modern medicine due to its non-invasive\ndiagnostic capabilities. However, the manual generation of unstructured medical\nreports is time consuming and prone to errors. It creates a significant\nbottleneck in clinical workflows. Despite advancements in AI-generated\nradiology reports, challenges remain in achieving detailed and accurate report\ngeneration. In this study we have evaluated different combinations of\nmultimodal models that integrate Computer Vision and Natural Language\nProcessing to generate comprehensive radiology reports. We employed a\npretrained Vision Transformer (ViT-B16) and a SWIN Transformer as the image\nencoders. The BART and GPT-2 models serve as the textual decoders. We used\nChest X-ray images and reports from the IU-Xray dataset to evaluate the\nusability of the SWIN Transformer-BART, SWIN Transformer-GPT-2, ViT-B16-BART\nand ViT-B16-GPT-2 models for report generation. We aimed at finding the best\ncombination among the models. The SWIN-BART model performs as the\nbest-performing model among the four models achieving remarkable results in\nalmost all the evaluation metrics like ROUGE, BLEU and BERTScore."
  },
  {
    "arxiv_id": "2501.12221",
    "title": "Leveraging Large Language Models for Realizing Truly Intelligent User Interfaces",
    "url": "http://arxiv.org/abs/2501.12221v1",
    "abstract": "The number of published scholarly articles is growing at a significant rate,\nmaking scholarly knowledge organization increasingly important. Various\napproaches have been proposed to organize scholarly information, including\ndescribing scholarly knowledge semantically leveraging knowledge graphs.\nTransforming unstructured knowledge, presented within articles, to structured\nand semantically represented knowledge generally requires human intelligence\nand labor since natural language processing methods alone typically do not\nrender sufficient precision and recall for many applications. With the recent\ndevelopments of Large Language Models (LLMs), it becomes increasingly possible\nto provide truly intelligent user interfaces guiding humans in the\ntransformation process. We present an approach to integrate non-intrusive LLMs\nguidance into existing user interfaces. More specifically, we integrate\nLLM-supported user interface components into an existing scholarly knowledge\ninfrastructure. Additionally, we provide our experiences with LLM integration,\ndetailing best practices and obstacles. Finally, we evaluate the approach using\na small-scale user evaluation with domain experts."
  },
  {
    "arxiv_id": "2501.12051",
    "title": "MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking",
    "url": "http://arxiv.org/abs/2501.12051v1",
    "abstract": "Medical language models (MLMs) have become pivotal in advancing medical\nnatural language processing. However, prior models that rely on pre-training or\nsupervised fine-tuning often exhibit low data efficiency and limited\npracticality in real-world clinical applications. While OpenAI's o1 highlights\ntest-time scaling in mathematics, attempts to replicate this approach in\nmedicine typically distill responses from GPT-series models to open-source\nmodels, focusing primarily on multiple-choice tasks. This strategy, though\nstraightforward, neglects critical concerns like data privacy and realistic\ndeployment in clinical settings. In this work, we present a deployable,\nsmall-scale medical reasoning system, MedS3, designed for long-chain reasoning\nin clinical tasks using a self-evolution paradigm. Starting with a seed dataset\nof around 8,000 instances spanning five domains and 16 datasets, we prompt a\nbase policy model to perform Monte Carlo Tree Search (MCTS) to construct\nrule-verifiable reasoning chains. Each reasoning step is assigned an evolution\nrollout value, allowing verified trajectories to train the policy model and the\nprocess reward model (PRM). During inference, the policy model generates\nmultiple responses, and the reward model selects the one with a newly proposed\nPRM-guided Vote-Sum (P-VS) strategy. Experiments on eleven evaluation datasets\ndemonstrate that MedS3 outperforms not only the prior strongest medical model\nby 6.59, but also 32B-level general reasoning models by 8.71 points. Code and\ndata are available at https://github.com/pixas/MedSSS."
  },
  {
    "arxiv_id": "2501.11849",
    "title": "Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance",
    "url": "http://arxiv.org/abs/2501.11849v1",
    "abstract": "Detecting organized political campaigns is of paramount importance in\nfighting against disinformation on social media. Existing approaches for the\nidentification of such organized actions employ techniques mostly from network\nscience, graph machine learning and natural language processing. Their ultimate\ngoal is to analyze the relationships and interactions (e.g. re-posting) among\nusers and the textual similarities of their posts. Despite their effectiveness\nin recognizing astroturf campaigns, these methods face significant challenges,\nnotably the class imbalance in available training datasets. To mitigate this\nissue, recent methods usually resort to data augmentation or increasing the\nnumber of positive samples, which may not always be feasible or sufficient in\nreal-world settings. Following a different path, in this paper, we propose a\nnovel framework for identifying astroturf campaigns based solely on large\nlanguage models (LLMs), introducing a Balanced Retrieval-Augmented Generation\n(Balanced RAG) component. Our approach first gives both textual information\nconcerning the posts (in our case tweets) and the user interactions of the\nsocial network as input to a language model. Then, through prompt engineering\nand the proposed Balanced RAG method, it effectively detects coordinated\ndisinformation campaigns on X (Twitter). The proposed framework does not\nrequire any training or fine-tuning of the language model. Instead, by\nstrategically harnessing the strengths of prompt engineering and Balanced RAG,\nit facilitates LLMs to overcome the effects of class imbalance and effectively\nidentify coordinated political campaigns. The experimental results demonstrate\nthat by incorporating the proposed prompt engineering and Balanced RAG methods,\nour framework outperforms the traditional graph-based baselines, achieving\n2x-3x improvements in terms of precision, recall and F1 scores."
  },
  {
    "arxiv_id": "2501.11833",
    "title": "Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs",
    "url": "http://arxiv.org/abs/2501.11833v1",
    "abstract": "In this paper, we present an investigative study on how Mental Sets influence\nthe reasoning capabilities of LLMs. LLMs have excelled in diverse natural\nlanguage processing (NLP) tasks, driven by advancements in parameter-efficient\nfine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).\nFor complex reasoning tasks, selecting the right model for PEFT or ICL is\ncritical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.\nHowever, current evaluation methods, based on metrics like F1 Score or\nreasoning chain assessments by larger models, overlook a key dimension:\nadaptability to unfamiliar situations and overcoming entrenched thinking\npatterns. In cognitive psychology, Mental Set refers to the tendency to persist\nwith previously successful strategies, even when they become inefficient - a\nchallenge for problem solving and reasoning. We compare the performance of LLM\nmodels like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the\npresence of mental sets. To the best of our knowledge, this is the first study\nto integrate cognitive psychology concepts into the evaluation of LLMs for\ncomplex reasoning tasks, providing deeper insights into their adaptability and\nproblem-solving efficacy."
  },
  {
    "arxiv_id": "2501.11779",
    "title": "Glinthawk: A Two-Tiered Architecture for High-Throughput LLM Inference",
    "url": "http://arxiv.org/abs/2501.11779v1",
    "abstract": "We introduce Glinthawk, an architecture for offline Large Language Model\n(LLM) inference. By leveraging a two-tiered structure, Glinthawk optimizes the\nutilization of the high-end accelerators (\"Tier 1\") by offloading the attention\nmechanism to lower-end compute tier (\"Tier 2\"). This separation allows the\nmemory demand of the attention, known as the key-value cache, to scale\nindependently from the model weights, enabling larger batch sizes and more\nefficient accelerator usage. Prototyped with NVIDIA T4 GPUs and standard CPU\nVMs, Glinthawk improves throughput by $5.9\\times$ and reduces cost of\ngeneration by $2.8\\times$, compared to paged attention baselines. For long\nsequence lengths, it achieves $16.3\\times$ throughput improvement at\n$2.4\\times$ less cost. Our evaluation shows that this architecture can tolerate\nmoderate network latency with minimal performance degradation, making it highly\neffective for latency-tolerant, throughput-focused applications such as batch\nprocessing. The prototype is publicly available at\nhttps://github.com/microsoft/glinthawk."
  },
  {
    "arxiv_id": "2501.11706",
    "title": "Trustformer: A Trusted Federated Transformer",
    "url": "http://arxiv.org/abs/2501.11706v1",
    "abstract": "Transformers, a cornerstone of deep-learning architectures for sequential\ndata, have achieved state-of-the-art results in tasks like Natural Language\nProcessing (NLP). Models such as BERT and GPT-3 exemplify their success and\nhave driven the rise of large language models (LLMs). However, a critical\nchallenge persists: safeguarding the privacy of data used in LLM training.\nPrivacy-preserving techniques like Federated Learning (FL) offer potential\nsolutions, but practical limitations hinder their effectiveness for Transformer\ntraining. Two primary issues are (I) the risk of sensitive information leakage\ndue to aggregation methods like FedAvg or FedSGD, and (II) the high\ncommunication overhead caused by the large size of Transformer models.\n  This paper introduces a novel FL method that reduces communication overhead\nwhile maintaining competitive utility. Our approach avoids sharing full model\nweights by simulating a global model locally. We apply k-means clustering to\neach Transformer layer, compute centroids locally, and transmit only these\ncentroids to the server instead of full weights or gradients. To enhance\nsecurity, we leverage Intel SGX for secure transmission of centroids. Evaluated\non a translation task, our method achieves utility comparable to\nstate-of-the-art baselines while significantly reducing communication costs.\nThis provides a more efficient and privacy-preserving FL solution for\nTransformer models."
  },
  {
    "arxiv_id": "2501.11496",
    "title": "Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges",
    "url": "http://arxiv.org/abs/2501.11496v1",
    "abstract": "Generative AI and large-scale language models (LLM) have emerged as powerful\ntools in language preservation, particularly for near-native and endangered\nlanguages. With the increasing reliance on technology for communication,\neducation, and cultural documentation, new opportunities have emerged to\nmitigate the dramatic decline of linguistic diversity worldwide. This paper\nexamines the role of generative AIs and LLMs in preserving endangered\nlanguages, highlighting the risks and challenges associated with their use. We\nanalyze the underlying technologies driving these models, including natural\nlanguage processing (NLP) and deep learning, and explore several cases where\nthese technologies have been applied to low-resource languages. Additionally,\nwe discuss ethical considerations, data scarcity issues, and technical\nchallenges while proposing solutions to enhance AI-driven language\npreservation."
  },
  {
    "arxiv_id": "2501.12900",
    "title": "Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi",
    "url": "http://arxiv.org/abs/2501.12900v1",
    "abstract": "Convolutional neural networks (CNNs) evaluate short-range correlations in\ninput images which progress along the layers, whereas vision transformer (ViT)\narchitectures evaluate long-range correlations, using repeated transformer\nencoders composed of fully connected layers. Both are designed to solve complex\nclassification tasks but from different perspectives. This study demonstrates\nthat CNNs and ViT architectures stem from a unified underlying learning\nmechanism, which quantitatively measures the single-nodal performance (SNP) of\neach node in feedforward (FF) and multi-head attention (MHA) sub-blocks. Each\nnode identifies small clusters of possible output labels, with additional noise\nrepresented as labels outside these clusters. These features are progressively\nsharpened along the transformer encoders, enhancing the signal-to-noise ratio.\nThis unified underlying learning mechanism leads to two main findings. First,\nit enables an efficient applied nodal diagonal connection (ANDC) pruning\ntechnique without affecting the accuracy. Second, based on the SNP, spontaneous\nsymmetry breaking occurs among the MHA heads, such that each head focuses its\nattention on a subset of labels through cooperation among its SNPs.\nConsequently, each head becomes an expert in recognizing its designated labels,\nrepresenting a quantitative MHA modus vivendi mechanism. This statistical\nmechanics inspired viewpoint enables to reveal macroscopic behavior of the\nentire network from the microscopic performance of each node. These results are\nbased on a compact convolutional transformer architecture trained on the\nCIFAR-100 and Flowers-102 datasets and call for their extension to other\narchitectures and applications, such as natural language processing."
  },
  {
    "arxiv_id": "2501.12877",
    "title": "WisdomBot: Tuning Large Language Models with Artificial Intelligence Knowledge",
    "url": "http://arxiv.org/abs/2501.12877v1",
    "abstract": "Large language models (LLMs) have emerged as powerful tools in natural\nlanguage processing (NLP), showing a promising future of artificial generated\nintelligence (AGI). Despite their notable performance in the general domain,\nLLMs have remained suboptimal in the field of education, owing to the unique\nchallenges presented by this domain, such as the need for more specialized\nknowledge, the requirement for personalized learning experiences, and the\nnecessity for concise explanations of complex concepts. To address these\nissues, this paper presents a novel LLM for education named WisdomBot, which\ncombines the power of LLMs with educational theories, enabling their seamless\nintegration into educational contexts. To be specific, we harness\nself-instructed knowledge concepts and instructions under the guidance of\nBloom's Taxonomy as training data. To further enhance the accuracy and\nprofessionalism of model's response on factual questions, we introduce two key\nenhancements during inference, i.e., local knowledge base retrieval\naugmentation and search engine retrieval augmentation during inference. We\nsubstantiate the effectiveness of our approach by applying it to several\nChinese LLMs, thereby showcasing that the fine-tuned models can generate more\nreliable and professional responses."
  },
  {
    "arxiv_id": "2501.12826",
    "title": "Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek",
    "url": "http://arxiv.org/abs/2501.12826v1",
    "abstract": "Natural Language Processing (NLP) for lesser-resourced languages faces\npersistent challenges, including limited datasets, inherited biases from\nhigh-resource languages, and the need for domain-specific solutions. This study\naddresses these gaps for Modern Greek through three key contributions. First,\nwe evaluate the performance of open-source (Llama-70b) and closed-source\n(GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset\navailability, revealing task-specific strengths, weaknesses, and parity in\ntheir performance. Second, we expand the scope of Greek NLP by reframing\nAuthorship Attribution as a tool to assess potential data usage by LLMs in\npre-training, with high 0-shot accuracy suggesting ethical implications for\ndata provenance. Third, we showcase a legal NLP case study, where a Summarize,\nTranslate, and Embed (STE) methodology outperforms the traditional TF-IDF\napproach for clustering \\emph{long} legal texts. Together, these contributions\nprovide a roadmap to advance NLP in lesser-resourced languages, bridging gaps\nin model evaluation, task innovation, and real-world impact."
  },
  {
    "arxiv_id": "2501.13772",
    "title": "Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak",
    "url": "http://arxiv.org/abs/2501.13772v1",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable zero-shot performance\nacross various natural language processing tasks. The integration of multimodal\nencoders extends their capabilities, enabling the development of Multimodal\nLarge Language Models that process vision, audio, and text. However, these\ncapabilities also raise significant security concerns, as these models can be\nmanipulated to generate harmful or inappropriate content through jailbreak.\nWhile extensive research explores the impact of modality-specific input edits\non text-based LLMs and Large Vision-Language Models in jailbreak, the effects\nof audio-specific edits on Large Audio-Language Models (LALMs) remain\nunderexplored. Hence, this paper addresses this gap by investigating how\naudio-specific edits influence LALMs inference regarding jailbreak. We\nintroduce the Audio Editing Toolbox (AET), which enables audio-modality edits\nsuch as tone adjustment, word emphasis, and noise injection, and the Edited\nAudio Datasets (EADs), a comprehensive audio jailbreak benchmark. We also\nconduct extensive evaluations of state-of-the-art LALMs to assess their\nrobustness under different audio edits. This work lays the groundwork for\nfuture explorations on audio-modality interactions in LALMs security."
  },
  {
    "arxiv_id": "2501.13545",
    "title": "LLMs Can Plan Only If We Tell Them",
    "url": "http://arxiv.org/abs/2501.13545v1",
    "abstract": "Large language models (LLMs) have demonstrated significant capabilities in\nnatural language processing and reasoning, yet their effectiveness in\nautonomous planning has been under debate. While existing studies have utilized\nLLMs with external feedback mechanisms or in controlled environments for\nplanning, these approaches often involve substantial computational and\ndevelopment resources due to the requirement for careful design and iterative\nbackprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to\nmatch human performance on standard planning benchmarks, such as the\nBlocksworld, without additional support. This paper investigates whether LLMs\ncan independently generate long-horizon plans that rival human baselines. Our\nnovel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help\nachieve state-of-the-art results in planning benchmarks out-competing prior\nmethods and human baselines all autonomously."
  },
  {
    "arxiv_id": "2501.13479",
    "title": "Adaptive Few-Shot Learning (AFSL): Tackling Data Scarcity with Stability, Robustness, and Versatility",
    "url": "http://arxiv.org/abs/2501.13479v1",
    "abstract": "Few-shot learning (FSL) enables machine learning models to generalize\neffectively with minimal labeled data, making it crucial for data-scarce\ndomains such as healthcare, robotics, and natural language processing. Despite\nits potential, FSL faces challenges including sensitivity to initialization,\ndifficulty in adapting to diverse domains, and vulnerability to noisy datasets.\nTo address these issues, this paper introduces Adaptive Few-Shot Learning\n(AFSL), a framework that integrates advancements in meta-learning, domain\nalignment, noise resilience, and multi-modal integration. AFSL consists of four\nkey modules: a Dynamic Stability Module for performance consistency, a\nContextual Domain Alignment Module for domain adaptation, a Noise-Adaptive\nResilience Module for handling noisy data, and a Multi-Modal Fusion Module for\nintegrating diverse modalities. This work also explores strategies such as\ntask-aware data augmentation, semi-supervised learning, and explainable AI\ntechniques to enhance the applicability and robustness of FSL. AFSL provides\nscalable, reliable, and impactful solutions for real-world, high-stakes\ndomains."
  },
  {
    "arxiv_id": "2501.14717",
    "title": "Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models",
    "url": "http://arxiv.org/abs/2501.14717v1",
    "abstract": "Recent advances in natural language processing have leveraged instruction\ntuning to enhance Large Language Models (LLMs) for table-related tasks.\nHowever, previous works train different base models with different training\ndata, lacking an apples-to-apples comparison across the result table LLMs. To\naddress this, we fine-tune base models from the Mistral, OLMo, and Phi families\non existing public training datasets. Our replication achieves performance on\npar with or surpassing existing table LLMs, establishing new state-of-the-art\nperformance on Hitab, a table question-answering dataset. More importantly,\nthrough systematic out-of-domain evaluation, we decouple the contributions of\ntraining data and the base model, providing insight into their individual\nimpacts. In addition, we assess the effects of table-specific instruction\ntuning on general-purpose benchmarks, revealing trade-offs between\nspecialization and generalization."
  },
  {
    "arxiv_id": "2501.14713",
    "title": "FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing",
    "url": "http://arxiv.org/abs/2501.14713v1",
    "abstract": "The rapid proliferation of large language models (LLMs) in natural language\nprocessing (NLP) has created a critical need for techniques that enable\nefficient deployment on memory-constrained devices without compromising\nperformance. We present a method to prune LLMs that selectively prunes model\nblocks based on an importance score and replaces them with a low-parameter\nreplacement strategy. Specifically, we propose a principled metric to replace\neach pruned block using a weight-sharing mechanism that leverages unpruned\ncounterparts from the model and block-specific low-rank adapters. Furthermore,\nwe facilitate the learning of these replacement blocks with output feature\nnormalization and an adapter initialization scheme built on low-rank SVD\nreconstructions. Empirical evaluations demonstrate substantial performance\ngains over existing methods, achieving state-of-the-art performance on 5/6\nbenchmarks for a compression rate of 30% and 6/6 benchmarks for a compression\nrate of 40%. We also demonstrate that our approach can extend smaller models,\nboosting performance on 6/6 benchmarks using only ~0.3% tokens of extended\ntraining with minimal additional parameter costs."
  },
  {
    "arxiv_id": "2501.14499",
    "title": "Automated Assignment Grading with Large Language Models: Insights From a Bioinformatics Course",
    "url": "http://arxiv.org/abs/2501.14499v1",
    "abstract": "Providing students with individualized feedback through assignments is a\ncornerstone of education that supports their learning and development. Studies\nhave shown that timely, high-quality feedback plays a critical role in\nimproving learning outcomes. However, providing personalized feedback on a\nlarge scale in classes with large numbers of students is often impractical due\nto the significant time and effort required. Recent advances in natural\nlanguage processing and large language models (LLMs) offer a promising solution\nby enabling the efficient delivery of personalized feedback. These technologies\ncan reduce the workload of course staff while improving student satisfaction\nand learning outcomes. Their successful implementation, however, requires\nthorough evaluation and validation in real classrooms. We present the results\nof a practical evaluation of LLM-based graders for written assignments in the\n2024/25 iteration of the Introduction to Bioinformatics course at the\nUniversity of Ljubljana. Over the course of the semester, more than 100\nstudents answered 36 text-based questions, most of which were automatically\ngraded using LLMs. In a blind study, students received feedback from both LLMs\nand human teaching assistants without knowing the source, and later rated the\nquality of the feedback. We conducted a systematic evaluation of six commercial\nand open-source LLMs and compared their grading performance with human teaching\nassistants. Our results show that with well-designed prompts, LLMs can achieve\ngrading accuracy and feedback quality comparable to human graders. Our results\nalso suggest that open-source LLMs perform as well as commercial LLMs, allowing\nschools to implement their own grading systems while maintaining privacy."
  },
  {
    "arxiv_id": "2501.14406",
    "title": "Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models",
    "url": "http://arxiv.org/abs/2501.14406v1",
    "abstract": "Pre-trained Language Models (PLMs) have demonstrated their superiority and\nversatility in modern Natural Language Processing (NLP), effectively adapting\nto various downstream tasks through further fine-tuning. Federated\nParameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution\nto address privacy and efficiency challenges in distributed training for PLMs\non resource-constrained local devices. However, our measurements reveal two key\nlimitations of FedPEFT: heterogeneous data across devices leads to significant\nperformance degradation, and a fixed parameter configuration results in\ncommunication inefficiency. To overcome these limitations, we propose FedARA, a\nnovel Adaptive Rank Allocation framework for federated parameter-efficient\nfine-tuning of language models. Specifically, FedARA employs truncated Singular\nValue Decomposition (SVD) adaptation to enhance similar feature representation\nacross clients, significantly mitigating the adverse effects of data\nheterogeneity. Subsequently, it utilizes dynamic rank allocation to\nprogressively identify critical ranks, effectively improving communication\nefficiency. Lastly, it leverages rank-based module pruning to automatically\nremove inactive modules, steadily reducing local computational cost and memory\nusage in each federated learning round. Extensive experiments show that FedARA\nconsistently outperforms baselines by an average of 6.95% to 8.49% across\nvarious datasets and models under heterogeneous data while significantly\nimproving communication efficiency by 2.40$ \\times$. Moreover, experiments on\nvarious edge devices demonstrate substantial decreases in total training time\nand energy consumption by up to 48.90% and 46.95%, respectively."
  },
  {
    "arxiv_id": "2501.16191",
    "title": "Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs",
    "url": "http://arxiv.org/abs/2501.16191v1",
    "abstract": "Fixing Python dependency issues is a tedious and error-prone task for\ndevelopers, who must manually identify and resolve environment dependencies and\nversion constraints of third-party modules and Python interpreters. Researchers\nhave attempted to automate this process by relying on large knowledge graphs\nand database lookup tables. However, these traditional approaches face\nlimitations due to the variety of dependency error types, large sets of\npossible module versions, and conflicts among transitive dependencies. This\nstudy explores the potential of using large language models (LLMs) to\nautomatically fix dependency issues in Python programs. We introduce PLLM\n(pronounced \"plum\"), a novel technique that employs retrieval-augmented\ngeneration (RAG) to help an LLM infer Python versions and required modules for\na given Python file. PLLM builds a testing environment that iteratively (1)\nprompts the LLM for module combinations, (2) tests the suggested changes, and\n(3) provides feedback (error messages) to the LLM to refine the fix. This\nfeedback cycle leverages natural language processing (NLP) to intelligently\nparse and interpret build error messages. We benchmark PLLM on the Gistable\nHG2.9K dataset, a collection of challenging single-file Python gists. We\ncompare PLLM against two state-of-the-art automatic dependency inference\napproaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency\nissues. Our results indicate that PLLM can fix more dependency issues than the\ntwo baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)\nover PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial\nfor projects with many dependencies and for specific third-party numerical and\nmachine-learning modules. Our findings demonstrate the potential of LLM-based\napproaches to iteratively resolve Python dependency issues."
  },
  {
    "arxiv_id": "2501.15747",
    "title": "IndicMMLU-Pro: Benchmarking the Indic Large Language Models",
    "url": "http://arxiv.org/abs/2501.15747v1",
    "abstract": "Known by more than 1.5 billion people in the Indian subcontinent, Indic\nlanguages present unique challenges and opportunities for natural language\nprocessing (NLP) research due to their rich cultural heritage, linguistic\ndiversity, and complex structures. IndicMMLU-Pro is a comprehensive benchmark\ndesigned to evaluate Large Language Models (LLMs) across Indic languages,\nbuilding upon the MMLU Pro (Massive Multitask Language Understanding)\nframework. Covering major languages such as Hindi, Bengali, Gujarati, Marathi,\nKannada, Punjabi, Tamil, Telugu, and Urdu, our benchmark addresses the unique\nchallenges and opportunities presented by the linguistic diversity of the\nIndian subcontinent. This benchmark encompasses a wide range of tasks in\nlanguage comprehension, reasoning, and generation, meticulously crafted to\ncapture the intricacies of Indian languages. IndicMMLU-Pro provides a\nstandardized evaluation framework to push the research boundaries in Indic\nlanguage AI, facilitating the development of more accurate, efficient, and\nculturally sensitive models. This paper outlines the benchmarks' design\nprinciples, task taxonomy, and data collection methodology, and presents\nbaseline results from state-of-the-art multilingual models."
  },
  {
    "arxiv_id": "2501.15574",
    "title": "Instruction Tuning for Story Understanding and Generation with Weak Supervision",
    "url": "http://arxiv.org/abs/2501.15574v1",
    "abstract": "Story understanding and generation have long been a challenging task in\nnatural language processing (NLP), especially when dealing with various levels\nof instruction specificity. In this paper, we propose a novel approach called\n\"Weak to Strong Instruction Tuning\" for improving story generation by tuning\nmodels with instructions of varying clarity. We explore the potential of large\nlanguage models (LLMs) to adapt to different types of instructions, weak and\nstrong, and show that our method significantly enhances performance in story\ncomprehension and generation. By leveraging the strength of instruction tuning,\nwe train models to understand the nuances of story plots, characters, and\nthemes while generating coherent and engaging narratives. Through extensive\nexperiments on several benchmark datasets and comparison with state-of-the-art\nbaselines, we demonstrate that our method outperforms existing techniques,\nyielding substantial improvements in both automatic evaluation metrics and\nhuman evaluations. Our work shows that adaptive instruction tuning can be a\npowerful tool in refining generative models for complex narrative tasks."
  },
  {
    "arxiv_id": "2501.16673",
    "title": "LLM-AutoDiff: Auto-Differentiate Any LLM Workflow",
    "url": "http://arxiv.org/abs/2501.16673v2",
    "abstract": "Large Language Models (LLMs) have reshaped natural language processing,\npowering applications from multi-hop retrieval and question answering to\nautonomous agent workflows. Yet, prompt engineering -- the task of crafting\ntextual inputs to effectively direct LLMs -- remains difficult and\nlabor-intensive, particularly for complex pipelines that combine multiple LLM\ncalls with functional operations like retrieval and data formatting. We\nintroduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering\n(APE) that extends textual gradient-based methods (such as Text-Grad) to\nmulti-component, potentially cyclic LLM architectures. Implemented within the\nAdalFlow library, LLM-AutoDiff treats each textual input as a trainable\nparameter and uses a frozen backward engine LLM to generate feedback-akin to\ntextual gradients -- that guide iterative prompt updates. Unlike prior\nsingle-node approaches, LLM-AutoDiff inherently accommodates functional nodes,\npreserves time-sequential behavior in repeated calls (e.g., multi-hop loops),\nand combats the \"lost-in-the-middle\" problem by isolating distinct sub-prompts\n(instructions, formats, or few-shot examples). It further boosts training\nefficiency by focusing on error-prone samples through selective gradient\ncomputation. Across diverse tasks, including single-step classification,\nmulti-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff\nconsistently outperforms existing textual gradient baselines in both accuracy\nand training cost. By unifying prompt optimization through a graph-centric\nlens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating\nLLM workflows - mirroring the transformative role that automatic\ndifferentiation libraries have long played in neural network research."
  },
  {
    "arxiv_id": "2501.16616",
    "title": "Few-Shot Optimized Framework for Hallucination Detection in Resource-Limited NLP Systems",
    "url": "http://arxiv.org/abs/2501.16616v1",
    "abstract": "Hallucination detection in text generation remains an ongoing struggle for\nnatural language processing (NLP) systems, frequently resulting in unreliable\noutputs in applications such as machine translation and definition modeling.\nExisting methods struggle with data scarcity and the limitations of unlabeled\ndatasets, as highlighted by the SHROOM shared task at SemEval-2024. In this\nwork, we propose a novel framework to address these challenges, introducing\nDeepSeek Few-shot optimization to enhance weak label generation through\niterative prompt engineering. We achieved high-quality annotations that\nconsiderably enhanced the performance of downstream models by restructuring\ndata to align with instruct generative models. We further fine-tuned the\nMistral-7B-Instruct-v0.3 model on these optimized annotations, enabling it to\naccurately detect hallucinations in resource-limited settings. Combining this\nfine-tuned model with ensemble learning strategies, our approach achieved 85.5%\naccuracy on the test set, setting a new benchmark for the SHROOM task. This\nstudy demonstrates the effectiveness of data restructuring, few-shot\noptimization, and fine-tuning in building scalable and robust hallucination\ndetection frameworks for resource-constrained NLP systems."
  },
  {
    "arxiv_id": "2501.17654",
    "title": "Exploring Vision Language Models for Multimodal and Multilingual Stance Detection",
    "url": "http://arxiv.org/abs/2501.17654v1",
    "abstract": "Social media's global reach amplifies the spread of information, highlighting\nthe need for robust Natural Language Processing tasks like stance detection\nacross languages and modalities. Prior research predominantly focuses on\ntext-only inputs, leaving multimodal scenarios, such as those involving both\nimages and text, relatively underexplored. Meanwhile, the prevalence of\nmultimodal posts has increased significantly in recent years. Although\nstate-of-the-art Vision-Language Models (VLMs) show promise, their performance\non multimodal and multilingual stance detection tasks remains largely\nunexamined. This paper evaluates state-of-the-art VLMs on a newly extended\ndataset covering seven languages and multimodal inputs, investigating their use\nof visual cues, language-specific performance, and cross-modality interactions.\nOur results show that VLMs generally rely more on text than images for stance\ndetection and this trend persists across languages. Additionally, VLMs rely\nsignificantly more on text contained within the images than other visual\ncontent. Regarding multilinguality, the models studied tend to generate\nconsistent predictions across languages whether they are explicitly\nmultilingual or not, although there are outliers that are incongruous with\nmacro F1, language support, and model size."
  },
  {
    "arxiv_id": "2501.17479",
    "title": "DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance",
    "url": "http://arxiv.org/abs/2501.17479v1",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious natural language processing tasks but often struggle to excel uniformly\nin diverse or complex domains. We propose a novel ensemble method - Diverse\nFingerprint Ensemble (DFPE), which leverages the complementary strengths of\nmultiple LLMs to achieve more robust performance. Our approach involves: (1)\nclustering models based on response \"fingerprints\" patterns, (2) applying a\nquantile-based filtering mechanism to remove underperforming models at a\nper-subject level, and (3) assigning adaptive weights to remaining models based\non their subject-wise validation accuracy. In experiments on the Massive\nMultitask Language Understanding (MMLU) benchmark, DFPE outperforms the best\nsingle model by 3% overall accuracy and 5% in discipline-level accuracy. This\nmethod increases the robustness and generalization of LLMs and underscores how\nmodel selection, diversity preservation, and performance-driven weighting can\neffectively address challenging, multi-faceted language understanding tasks."
  },
  {
    "arxiv_id": "2501.17437",
    "title": "Bayesian BIM-Guided Construction Robot Navigation with NLP Safety Prompts in Dynamic Environments",
    "url": "http://arxiv.org/abs/2501.17437v1",
    "abstract": "Construction robotics increasingly relies on natural language processing for\ntask execution, creating a need for robust methods to interpret commands in\ncomplex, dynamic environments. While existing research primarily focuses on\nwhat tasks robots should perform, less attention has been paid to how these\ntasks should be executed safely and efficiently. This paper presents a novel\nprobabilistic framework that uses sentiment analysis from natural language\ncommands to dynamically adjust robot navigation policies in construction\nenvironments. The framework leverages Building Information Modeling (BIM) data\nand natural language prompts to create adaptive navigation strategies that\naccount for varying levels of environmental risk and uncertainty. We introduce\nan object-aware path planning approach that combines exponential potential\nfields with a grid-based representation of the environment, where the potential\nfields are dynamically adjusted based on the semantic analysis of user prompts.\nThe framework employs Bayesian inference to consolidate multiple information\nsources: the static data from BIM, the semantic content of natural language\ncommands, and the implied safety constraints from user prompts. We demonstrate\nour approach through experiments comparing three scenarios: baseline\nshortest-path planning, safety-oriented navigation, and risk-aware routing.\nResults show that our method successfully adapts path planning based on natural\nlanguage sentiment, achieving a 50\\% improvement in minimum distance to\nobstacles when safety is prioritized, while maintaining reasonable path\nlengths. Scenarios with contrasting prompts, such as \"dangerous\" and \"safe\",\ndemonstrate the framework's ability to modify paths. This approach provides a\nflexible foundation for integrating human knowledge and safety considerations\ninto construction robot navigation."
  },
  {
    "arxiv_id": "2501.18128",
    "title": "Unraveling the Capabilities of Language Models in News Summarization",
    "url": "http://arxiv.org/abs/2501.18128v1",
    "abstract": "Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization."
  },
  {
    "arxiv_id": "2501.19298",
    "title": "Synthetic User Behavior Sequence Generation with Large Language Models for Smart Homes",
    "url": "http://arxiv.org/abs/2501.19298v1",
    "abstract": "In recent years, as smart home systems have become more widespread, security\nconcerns within these environments have become a growing threat. Currently,\nmost smart home security solutions, such as anomaly detection and behavior\nprediction models, are trained using fixed datasets that are precollected.\nHowever, the process of dataset collection is time-consuming and lacks the\nflexibility needed to adapt to the constantly evolving smart home environment.\nAdditionally, the collection of personal data raises significant privacy\nconcerns for users. Lately, large language models (LLMs) have emerged as a\npowerful tool for a wide range of tasks across diverse application domains,\nthanks to their strong capabilities in natural language processing, reasoning,\nand problem-solving. In this paper, we propose an LLM-based synthetic dataset\ngeneration IoTGen framework to enhance the generalization of downstream smart\nhome intelligent models. By generating new synthetic datasets that reflect\nchanges in the environment, smart home intelligent models can be retrained to\novercome the limitations of fixed and outdated data, allowing them to better\nalign with the dynamic nature of real-world home environments. Specifically, we\nfirst propose a Structure Pattern Perception Compression (SPPC) method tailored\nfor IoT behavior data, which preserves the most informative content in the data\nwhile significantly reducing token consumption. Then, we propose a systematic\napproach to create prompts and implement data generation to automatically\ngenerate IoT synthetic data with normative and reasonable properties, assisting\ntask models in adaptive training to improve generalization and real-world\nperformance."
  },
  {
    "arxiv_id": "2501.19259",
    "title": "Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge",
    "url": "http://arxiv.org/abs/2501.19259v1",
    "abstract": "The integration of human-intuitive interactions into autonomous systems has\nbeen limited. Traditional Natural Language Processing (NLP) systems struggle\nwith context and intent understanding, severely restricting human-robot\ninteraction. Recent advancements in Large Language Models (LLMs) have\ntransformed this dynamic, allowing for intuitive and high-level communication\nthrough speech and text, and bridging the gap between human commands and\nrobotic actions. Additionally, autonomous navigation has emerged as a central\nfocus in robotics research, with artificial intelligence (AI) increasingly\nbeing leveraged to enhance these systems. However, existing AI-based navigation\nalgorithms face significant challenges in latency-critical tasks where rapid\ndecision-making is critical. Traditional frame-based vision systems, while\neffective for high-level decision-making, suffer from high energy consumption\nand latency, limiting their applicability in real-time scenarios. Neuromorphic\nvision systems, combining event-based cameras and spiking neural networks\n(SNNs), offer a promising alternative by enabling energy-efficient, low-latency\nnavigation. Despite their potential, real-world implementations of these\nsystems, particularly on physical platforms such as drones, remain scarce. In\nthis work, we present Neuro-LIFT, a real-time neuromorphic navigation framework\nimplemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural\nlanguage processing, Neuro-LIFT translates human speech into high-level\nplanning commands which are then autonomously executed using event-based\nneuromorphic vision and physics-driven planning. Our framework demonstrates its\ncapabilities in navigating in a dynamic environment, avoiding obstacles, and\nadapting to human instructions in real-time."
  },
  {
    "arxiv_id": "2501.19026",
    "title": "MPLinker: Multi-template Prompt-tuning with Adversarial Training for Issue-commit Link Recovery",
    "url": "http://arxiv.org/abs/2501.19026v1",
    "abstract": "In recent years, the pre-training, prompting and prediction paradigm, known\nas prompt-tuning, has achieved significant success in Natural Language\nProcessing (NLP). Issue-commit Link Recovery (ILR) in Software Traceability\n(ST) plays an important role in improving the reliability, quality, and\nsecurity of software systems. The current ILR methods convert the ILR into a\nclassification task using pre-trained language models (PLMs) and dedicated\nneural networks. these methods do not fully utilize the semantic information\nembedded in PLMs, resulting in not achieving acceptable performance. To address\nthis limitation, we introduce a novel paradigm: Multi-template Prompt-tuning\nwith adversarial training for issue-commit Link recovery (MPLinker). MPLinker\nredefines the ILR task as a cloze task via template-based prompt-tuning and\nincorporates adversarial training to enhance model generalization and reduce\noverfitting. We evaluated MPLinker on six open-source projects using a\ncomprehensive set of performance metrics. The experiment results demonstrate\nthat MPLinker achieves an average F1-score of 96.10%, Precision of 96.49%,\nRecall of 95.92%, MCC of 94.04%, AUC of 96.05%, and ACC of 98.15%,\nsignificantly outperforming existing state-of-the-art methods. Overall,\nMPLinker improves the performance and generalization of ILR models, and\nintroduces innovative concepts and methods for ILR. The replication package for\nMPLinker is available at\nhttps://github.com/WTU-intelligent-software-development/MPLinker"
  },
  {
    "arxiv_id": "2501.18793",
    "title": "OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization",
    "url": "http://arxiv.org/abs/2501.18793v1",
    "abstract": "Transformers have achieved state-of-the-art performance in numerous tasks. In\nthis paper, we propose a continuous-time formulation of transformers.\nSpecifically, we consider a dynamical system whose governing equation is\nparametrized by transformer blocks. We leverage optimal transport theory to\nregularize the training problem, which enhances stability in training and\nimproves generalization of the resulting model. Moreover, we demonstrate in\ntheory that this regularization is necessary as it promotes uniqueness and\nregularity of solutions. Our model is flexible in that almost any existing\ntransformer architectures can be adopted to construct the dynamical system with\nonly slight modifications to the existing code. We perform extensive numerical\nexperiments on tasks motivated by natural language processing, image\nclassification, and point cloud classification. Our experimental results show\nthat the proposed method improves the performance of its discrete counterpart\nand outperforms relevant comparing models."
  },
  {
    "arxiv_id": "2502.02539",
    "title": "LLMs for Generation of Architectural Components: An Exploratory Empirical Study in the Serverless World",
    "url": "http://arxiv.org/abs/2502.02539v1",
    "abstract": "Recently, the exponential growth in capability and pervasiveness of Large\nLanguage Models (LLMs) has led to significant work done in the field of code\ngeneration. However, this generation has been limited to code snippets. Going\none step further, our desideratum is to automatically generate architectural\ncomponents. This would not only speed up development time, but would also\nenable us to eventually completely skip the development phase, moving directly\nfrom design decisions to deployment. To this end, we conduct an exploratory\nstudy on the capability of LLMs to generate architectural components for\nFunctions as a Service (FaaS), commonly known as serverless functions. The\nsmall size of their architectural components make this architectural style\namenable for generation using current LLMs compared to other styles like\nmonoliths and microservices. We perform the study by systematically selecting\nopen source serverless repositories, masking a serverless function and\nutilizing state of the art LLMs provided with varying levels of context\ninformation about the overall system to generate the masked function. We\nevaluate correctness through existing tests present in the repositories and use\nmetrics from the Software Engineering (SE) and Natural Language Processing\n(NLP) domains to evaluate code quality and the degree of similarity between\nhuman and LLM generated code respectively. Along with our findings, we also\npresent a discussion on the path forward for using GenAI in architectural\ncomponent generation."
  },
  {
    "arxiv_id": "2502.02191",
    "title": "Large language models in climate and sustainability policy: limits and opportunities",
    "url": "http://arxiv.org/abs/2502.02191v1",
    "abstract": "As multiple crises threaten the sustainability of our societies and pose at\nrisk the planetary boundaries, complex challenges require timely, updated, and\nusable information. Natural-language processing (NLP) tools enhance and expand\ndata collection and processing and knowledge utilization capabilities to\nsupport the definition of an inclusive, sustainable future. In this work, we\napply different NLP techniques, tools and approaches to climate and\nsustainability documents to derive policy-relevant and actionable measures. We\nfocus on general and domain-specific large language models (LLMs) using a\ncombination of static and prompt-based methods. We find that the use of LLMs is\nsuccessful at processing, classifying and summarizing heterogeneous text-based\ndata. However, we also encounter challenges related to human intervention\nacross different workflow stages and knowledge utilization for policy\nprocesses. Our work presents a critical but empirically grounded application of\nLLMs to complex policy problems and suggests avenues to further expand\nArtificial Intelligence-powered computational social sciences."
  },
  {
    "arxiv_id": "2502.02074",
    "title": "Rethinking stance detection: A theoretically-informed research agenda for user-level inference using language models",
    "url": "http://arxiv.org/abs/2502.02074v1",
    "abstract": "Stance detection has emerged as a popular task in natural language processing\nresearch, enabled largely by the abundance of target-specific social media\ndata. While there has been considerable research on the development of stance\ndetection models, datasets, and application, we highlight important gaps\npertaining to (i) a lack of theoretical conceptualization of stance, and (ii)\nthe treatment of stance at an individual- or user-level, as opposed to\nmessage-level. In this paper, we first review the interdisciplinary origins of\nstance as an individual-level construct to highlight relevant attributes (e.g.,\npsychological features) that might be useful to incorporate in stance detection\nmodels. Further, we argue that recent pre-trained and large language models\n(LLMs) might offer a way to flexibly infer such user-level attributes and/or\nincorporate them in modelling stance. To better illustrate this, we briefly\nreview and synthesize the emerging corpus of studies on using LLMs for\ninferring stance, and specifically on incorporating user attributes in such\ntasks. We conclude by proposing a four-point agenda for pursuing stance\ndetection research that is theoretically informed, inclusive, and practically\nimpactful."
  },
  {
    "arxiv_id": "2502.03004",
    "title": "MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation",
    "url": "http://arxiv.org/abs/2502.03004v1",
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nnatural language processing tasks. However, their application to specialized\ndomains such as medicine and biology requires further optimization to ensure\nfactual accuracy, reliability, and contextual depth. We introduce MedBioLM, a\ndomain-adapted biomedical question-answering model designed to enhance both\nshort-form and long-form queries. By integrating fine-tuning and\nretrieval-augmented generation (RAG), MedBioLM dynamically incorporates\ndomain-specific knowledge, improving reasoning abilities and factual accuracy.\nTo evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA\ndatasets, covering structured multiple-choice assessments and complex clinical\nreasoning tasks. Fine-tuning significantly improves accuracy on benchmark\ndatasets, while RAG enhances factual consistency. These results highlight the\npotential of domain-optimized LLMs in advancing biomedical research, medical\neducation, and clinical decision support."
  },
  {
    "arxiv_id": "2502.02896",
    "title": "A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs",
    "url": "http://arxiv.org/abs/2502.02896v1",
    "abstract": "Evaluating large language models (LLMs) for tasks like fact extraction in\nsupport of knowledge graph construction frequently involves computing accuracy\nmetrics using a ground truth benchmark based on a knowledge graph (KG). These\nevaluations assume that errors represent factual disagreements. However, human\ndiscourse frequently features metalinguistic disagreement, where agents differ\nnot on facts but on the meaning of the language used to express them. Given the\ncomplexity of natural language processing and generation using LLMs, we ask: do\nmetalinguistic disagreements occur between LLMs and KGs? Based on an\ninvestigation using the T-REx knowledge alignment dataset, we hypothesize that\nmetalinguistic disagreement does in fact occur between LLMs and KGs, with\npotential relevance for the practice of knowledge graph engineering. We propose\na benchmark for evaluating the detection of factual and metalinguistic\ndisagreements between LLMs and KGs. An initial proof of concept of such a\nbenchmark is available on Github."
  },
  {
    "arxiv_id": "2502.03805",
    "title": "Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective",
    "url": "http://arxiv.org/abs/2502.03805v1",
    "abstract": "Large language models have revolutionized natural language processing but\nface significant challenges of high storage and runtime costs, due to the\ntransformer architecture's reliance on self-attention, particularly the large\nKey-Value (KV) cache for long-sequence inference. Recent efforts to reduce KV\ncache size by pruning less critical entries based on attention weights remain\nempirical and lack formal grounding. This paper presents a formal study on\nidentifying critical KV cache entries by analyzing attention output\nperturbation. Our analysis reveals that, beyond attention weights, the value\nstates within KV entries and pretrained parameter matrices are also crucial.\nBased on this, we propose a perturbation-constrained selection algorithm that\noptimizes the worst-case output perturbation to identify critical entries.\nEvaluations on the Needle-in-a-Haystack test and Longbench benchmark show our\nalgorithm enhances state-of-the-art cache eviction methods. Further empirical\nanalysis confirms that our algorithm achieves lower output perturbations in\nover 92% attention heads in Llama model, thereby providing a significant\nimprovement over existing methods."
  },
  {
    "arxiv_id": "2502.03671",
    "title": "Advancing Reasoning in Large Language Models: Promising Methods and Approaches",
    "url": "http://arxiv.org/abs/2502.03671v1",
    "abstract": "Large Language Models (LLMs) have succeeded remarkably in various natural\nlanguage processing (NLP) tasks, yet their reasoning capabilities remain a\nfundamental challenge. While LLMs exhibit impressive fluency and factual\nrecall, their ability to perform complex reasoning-spanning logical deduction,\nmathematical problem-solving, commonsense inference, and multi-step\nreasoning-often falls short of human expectations. This survey provides a\ncomprehensive review of emerging techniques enhancing reasoning in LLMs. We\ncategorize existing methods into key approaches, including prompting strategies\n(e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought\nreasoning), architectural innovations (e.g., retrieval-augmented models,\nmodular reasoning networks, and neuro-symbolic integration), and learning\nparadigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement\nlearning, and self-supervised reasoning objectives). Additionally, we explore\nevaluation frameworks used to assess reasoning in LLMs and highlight open\nchallenges, such as hallucinations, robustness, and reasoning generalization\nacross diverse tasks. By synthesizing recent advancements, this survey aims to\nprovide insights into promising directions for future research and practical\napplications of reasoning-augmented LLMs."
  },
  {
    "arxiv_id": "2502.06652",
    "title": "Transparent NLP: Using RAG and LLM Alignment for Privacy Q&A",
    "url": "http://arxiv.org/abs/2502.06652v1",
    "abstract": "The transparency principle of the General Data Protection Regulation (GDPR)\nrequires data processing information to be clear, precise, and accessible.\nWhile language models show promise in this context, their probabilistic nature\ncomplicates truthfulness and comprehensibility.\n  This paper examines state-of-the-art Retrieval Augmented Generation (RAG)\nsystems enhanced with alignment techniques to fulfill GDPR obligations. We\nevaluate RAG systems incorporating an alignment module like Rewindable\nAuto-regressive Inference (RAIN) and our proposed multidimensional extension,\nMultiRAIN, using a Privacy Q&A dataset. Responses are optimized for preciseness\nand comprehensibility and are assessed through 21 metrics, including\ndeterministic and large language model-based evaluations.\n  Our results show that RAG systems with an alignment module outperform\nbaseline RAG systems on most metrics, though none fully match human answers.\nPrincipal component analysis of the results reveals complex interactions\nbetween metrics, highlighting the need to refine metrics. This study provides a\nfoundation for integrating advanced natural language processing systems into\nlegal compliance frameworks."
  },
  {
    "arxiv_id": "2502.06572",
    "title": "LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM",
    "url": "http://arxiv.org/abs/2502.06572v1",
    "abstract": "Large language models (LLMs), both proprietary and open-source, have\ndemonstrated remarkable capabilities across various natural language processing\ntasks. However, they face significant limitations in legal reasoning tasks.\nProprietary models introduce data privacy risks and high inference costs, while\nopen-source models underperform due to insufficient legal domain training data.\nTo address these limitations, we study data generation for legal reasoning to\nimprove the legal reasoning performance of open-source LLMs with the help of\nproprietary LLMs. This is challenging due to the lack of legal knowledge in\nproprietary LLMs and the difficulty in verifying the generated data. We propose\nKgDG, a knowledge-guided data generation framework for legal reasoning. Our\nframework enables leveraging legal knowledge to enhance generation diversity\nand introduces a refinement and verification process to ensure the quality of\ngenerated data. Moreover, we expand the generated dataset to further enhance\nthe LLM reasoning capabilities. Using KgDG, we create a synthetic legal\nreasoning dataset containing 50K high-quality examples. Our trained model\nLawGPT outperforms existing legal-specific LLMs and achieves performance\ncomparable to proprietary LLMs, demonstrating the effectiveness of KgDG and\nLawGPT. Our code and resources is publicly available at\nhttps://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation ."
  },
  {
    "arxiv_id": "2502.06257",
    "title": "K-ON: Stacking Knowledge On the Head Layer of Large Language Model",
    "url": "http://arxiv.org/abs/2502.06257v1",
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nimproved various natural language processing (NLP) tasks. Typically, LLMs are\ntrained to predict the next token, aligning well with many NLP tasks. However,\nin knowledge graph (KG) scenarios, entities are the fundamental units and\nidentifying an entity requires at least several tokens. This leads to a\ngranularity mismatch between KGs and natural languages. To address this issue,\nwe propose K-ON, which integrates KG knowledge into the LLM by employing\nmultiple head layers for next k-step prediction. K-ON can not only generate\nentity-level results in one step, but also enables contrastive loss against\nentities, which is the most powerful tool in KG representation learning.\nExperimental results show that K-ON outperforms state-of-the-art methods that\nincorporate text and even the other modalities."
  },
  {
    "arxiv_id": "2502.06004",
    "title": "Analysis of LLM as a grammatical feature tagger for African American English",
    "url": "http://arxiv.org/abs/2502.06004v1",
    "abstract": "African American English (AAE) presents unique challenges in natural language\nprocessing (NLP). This research systematically compares the performance of\navailable NLP models--rule-based, transformer-based, and large language models\n(LLMs)--capable of identifying key grammatical features of AAE, namely Habitual\nBe and Multiple Negation. These features were selected for their distinct\ngrammatical complexity and frequency of occurrence. The evaluation involved\nsentence-level binary classification tasks, using both zero-shot and few-shot\nstrategies. The analysis reveals that while LLMs show promise compared to the\nbaseline, they are influenced by biases such as recency and unrelated features\nin the text such as formality. This study highlights the necessity for improved\nmodel training and architectural adjustments to better accommodate AAE's unique\nlinguistic characteristics. Data and code are available."
  },
  {
    "arxiv_id": "2502.05825",
    "title": "Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models",
    "url": "http://arxiv.org/abs/2502.05825v1",
    "abstract": "Large language models (LLMs) demonstrate strong capabilities in natural\nlanguage processing but remain prone to hallucinations, generating factually\nincorrect or fabricated content. This issue undermines their reliability,\nparticularly in high-stakes domains such as healthcare and legal advisory. To\naddress this challenge, we propose Delta, an inference-time method that reduces\nhallucinations without requiring model retraining or additional data. Delta\nworks by randomly masking parts of the input prompt and contrasting the output\ndistributions for the original and masked inputs, effectively suppressing\nhallucinations through inference-only computations. We evaluate Delta on\ncontext-rich question-answering benchmarks, achieving absolute improvements of\napproximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and\n7 and 2 percentage points on TriviaQA and Natural Questions under-sampling\ndecoding. Delta also improves the no-answer exact match score on SQuAD v2 by\nover ten percentage points, demonstrating its effectiveness in mitigating\nhallucinations arising from contextual ambiguity. These results highlight Delta\nas a computationally efficient and scalable approach for improving the\nreliability of LLMs in real-world applications."
  },
  {
    "arxiv_id": "2502.05670",
    "title": "Language Models Largely Exhibit Human-like Constituent Ordering Preferences",
    "url": "http://arxiv.org/abs/2502.05670v1",
    "abstract": "Though English sentences are typically inflexible vis-\\`a-vis word order,\nconstituents often show far more variability in ordering. One prominent theory\npresents the notion that constituent ordering is directly correlated with\nconstituent weight: a measure of the constituent's length or complexity. Such\ntheories are interesting in the context of natural language processing (NLP),\nbecause while recent advances in NLP have led to significant gains in the\nperformance of large language models (LLMs), much remains unclear about how\nthese models process language, and how this compares to human language\nprocessing. In particular, the question remains whether LLMs display the same\npatterns with constituent movement, and may provide insights into existing\ntheories on when and how the shift occurs in human language. We compare a\nvariety of LLMs with diverse properties to evaluate broad LLM performance on\nfour types of constituent movement: heavy NP shift, particle movement, dative\nalternation, and multiple PPs. Despite performing unexpectedly around particle\nmovement, LLMs generally align with human preferences around constituent\nordering."
  },
  {
    "arxiv_id": "2502.07542",
    "title": "Exoplanet Transit Candidate Identification in TESS Full-Frame Images via a Transformer-Based Algorithm",
    "url": "http://arxiv.org/abs/2502.07542v1",
    "abstract": "The Transiting Exoplanet Survey Satellite (TESS) is surveying a large\nfraction of the sky, generating a vast database of photometric time series data\nthat requires thorough analysis to identify exoplanetary transit signals.\nAutomated learning approaches have been successfully applied to identify\ntransit signals. However, most existing methods focus on the classification and\nvalidation of candidates, while few efforts have explored new techniques for\nthe search of candidates. To search for new exoplanet transit candidates, we\npropose an approach to identify exoplanet transit signals without the need for\nphase folding or assuming periodicity in the transit signals, such as those\nobserved in multi-transit light curves. To achieve this, we implement a new\nneural network inspired by Transformers to directly process Full Frame Image\n(FFI) light curves to detect exoplanet transits. Transformers, originally\ndeveloped for natural language processing, have recently demonstrated\nsignificant success in capturing long-range dependencies compared to previous\napproaches focused on sequential data. This ability allows us to employ\nmulti-head self-attention to identify exoplanet transit signals directly from\nthe complete light curves, combined with background and centroid time series,\nwithout requiring prior transit parameters. The network is trained to learn\ncharacteristics of the transit signal, like the dip shape, which helps\ndistinguish planetary transits from other variability sources. Our model\nsuccessfully identified 214 new planetary system candidates, including 122\nmulti-transit light curves, 88 single-transit and 4 multi-planet systems from\nTESS sectors 1-26 with a radius > 0.27 $R_{\\mathrm{Jupiter}}$, demonstrating\nits ability to detect transits regardless of their periodicity."
  },
  {
    "arxiv_id": "2502.07418",
    "title": "Entity Linking using LLMs for Automated Product Carbon Footprint Estimation",
    "url": "http://arxiv.org/abs/2502.07418v1",
    "abstract": "Growing concerns about climate change and sustainability are driving\nmanufacturers to take significant steps toward reducing their carbon\nfootprints. For these manufacturers, a first step towards this goal is to\nidentify the environmental impact of the individual components of their\nproducts. We propose a system leveraging large language models (LLMs) to\nautomatically map components from manufacturer Bills of Materials (BOMs) to\nLife Cycle Assessment (LCA) database entries by using LLMs to expand on\navailable component information. Our approach reduces the need for manual data\nprocessing, paving the way for more accessible sustainability practices."
  },
  {
    "arxiv_id": "2502.07286",
    "title": "Small Language Model Makes an Effective Long Text Extractor",
    "url": "http://arxiv.org/abs/2502.07286v1",
    "abstract": "Named Entity Recognition (NER) is a fundamental problem in natural language\nprocessing (NLP). However, the task of extracting longer entity spans (e.g.,\nawards) from extended texts (e.g., homepages) is barely explored. Current NER\nmethods predominantly fall into two categories: span-based methods and\ngeneration-based methods. Span-based methods require the enumeration of all\npossible token-pair spans, followed by classification on each span, resulting\nin substantial redundant computations and excessive GPU memory usage. In\ncontrast, generation-based methods involve prompting or fine-tuning large\nlanguage models (LLMs) to adapt to downstream NER tasks. However, these methods\nstruggle with the accurate generation of longer spans and often incur\nsignificant time costs for effective fine-tuning. To address these challenges,\nthis paper introduces a lightweight span-based NER method called SeNER, which\nincorporates a bidirectional arrow attention mechanism coupled with\nLogN-Scaling on the [CLS] token to embed long texts effectively, and comprises\na novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to\nreduce redundant candidate token-pair spans significantly and model\ninteractions between token-pair spans simultaneously. Extensive experiments\ndemonstrate that our method achieves state-of-the-art extraction accuracy on\nthree long NER datasets and is capable of extracting entities from long texts\nin a GPU-memory-friendly manner. Code:\nhttps://github.com/THUDM/scholar-profiling/tree/main/sener"
  },
  {
    "arxiv_id": "2502.07058",
    "title": "Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties",
    "url": "http://arxiv.org/abs/2502.07058v1",
    "abstract": "A language can have different varieties. These varieties can affect the\nperformance of natural language processing (NLP) models, including large\nlanguage models (LLMs), which are often trained on data from widely spoken\nvarieties. This paper introduces a novel and cost-effective approach to\nbenchmark model performance across language varieties. We argue that\ninternational online review platforms, such as Booking.com, can serve as\neffective data sources for constructing datasets that capture comments in\ndifferent language varieties from similar real-world scenarios, like reviews\nfor the same hotel with the same rating using the same language (e.g., Mandarin\nChinese) but different language varieties (e.g., Taiwan Mandarin, Mainland\nMandarin). To prove this concept, we constructed a contextually aligned dataset\ncomprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs\nin a sentiment analysis task. Our results show that LLMs consistently\nunderperform in Taiwan Mandarin."
  },
  {
    "arxiv_id": "2502.08180",
    "title": "Enhancing LLM Character-Level Manipulation via Divide and Conquer",
    "url": "http://arxiv.org/abs/2502.08180v1",
    "abstract": "Large Language Models (LLMs) have demonstrated strong generalization\ncapabilities across a wide range of natural language processing (NLP) tasks.\nHowever, they exhibit notable weaknesses in character-level string\nmanipulation, struggling with fundamental operations such as character\ndeletion, insertion, and substitution. These challenges stem primarily from\ntokenization constraints, despite the critical role of such operations in data\npreprocessing and code generation. Through systematic analysis, we derive two\nkey insights: (1) LLMs face significant difficulties in leveraging intrinsic\ntoken knowledge for character-level reasoning, and (2) atomized word structures\ncan substantially enhance LLMs' ability to process token-level structural\ninformation. Building on these insights, we propose Character-Level\nManipulation via Divide and Conquer, a novel approach designed to bridge the\ngap between token-level processing and character-level manipulation. Our method\ndecomposes complex operations into explicit character-level subtasks coupled\nwith controlled token reconstruction phases, leading to significant\nimprovements in accuracy. Without additional training, our method significantly\nimproves accuracies on the $\\texttt{Deletion}$, $\\texttt{Insertion}$, and\n$\\texttt{Substitution}$ tasks. To support further research, we open-source our\nimplementation and benchmarks."
  },
  {
    "arxiv_id": "2502.08109",
    "title": "HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses",
    "url": "http://arxiv.org/abs/2502.08109v1",
    "abstract": "Recent advances in large language models (LLMs) have shown promising\nimprovements, often surpassing existing methods across a wide range of\ndownstream tasks in natural language processing. However, these models still\nface challenges, which may hinder their practical applicability. For example,\nthe phenomenon of hallucination is known to compromise the reliability of LLMs,\nespecially in fields that demand high factual precision. Current benchmarks\nprimarily focus on hallucination detection and factuality evaluation but do not\nextend beyond identification. This paper proposes an explanation enhanced\nhallucination-detection model, coined as HuDEx, aimed at enhancing the\nreliability of LLM-generated responses by both detecting hallucinations and\nproviding detailed explanations. The proposed model provides a novel approach\nto integrate detection with explanations, and enable both users and the LLM\nitself to understand and reduce errors. Our measurement results demonstrate\nthat the proposed model surpasses larger LLMs, such as Llama3 70B and GPT-4, in\nhallucination detection accuracy, while maintaining reliable explanations.\nFurthermore, the proposed model performs well in both zero-shot and other test\nenvironments, showcasing its adaptability across diverse benchmark datasets.\nThe proposed approach further enhances the hallucination detection research by\nintroducing a novel approach to integrating interpretability with hallucination\ndetection, which further enhances the performance and reliability of evaluating\nhallucinations in language models."
  },
  {
    "arxiv_id": "2502.08092",
    "title": "GCoT: Chain-of-Thought Prompt Learning for Graphs",
    "url": "http://arxiv.org/abs/2502.08092v1",
    "abstract": "Chain-of-thought (CoT) prompting has achieved remarkable success in natural\nlanguage processing (NLP). However, its vast potential remains largely\nunexplored for graphs. This raises an interesting question: How can we design\nCoT prompting for graphs to guide graph models to learn step by step? On one\nhand, unlike natural languages, graphs are non-linear and characterized by\ncomplex topological structures. On the other hand, many graphs lack textual\ndata, making it difficult to formulate language-based CoT prompting. In this\nwork, we propose the first CoT prompt learning framework for text-free graphs,\nGCoT. Specifically, we decompose the adaptation process for each downstream\ntask into a series of inference steps, with each step consisting of\nprompt-based inference, ``thought'' generation, and thought-conditioned prompt\nlearning. While the steps mimic CoT prompting in NLP, the exact mechanism\ndiffers significantly. Specifically, at each step, an input graph, along with a\nprompt, is first fed into a pre-trained graph encoder for prompt-based\ninference. We then aggregate the hidden layers of the encoder to construct a\n``thought'', which captures the working state of each node in the current step.\nConditioned on this thought, we learn a prompt specific to each node based on\nthe current state. These prompts are fed into the next inference step,\nrepeating the cycle. To evaluate and analyze the effectiveness of GCoT, we\nconduct comprehensive experiments on eight public datasets, which demonstrate\nthe advantage of our approach."
  },
  {
    "arxiv_id": "2502.07855",
    "title": "Vision-Language Models for Edge Networks: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2502.07855v1",
    "abstract": "Vision Large Language Models (VLMs) combine visual understanding with natural\nlanguage processing, enabling tasks like image captioning, visual question\nanswering, and video analysis. While VLMs show impressive capabilities across\ndomains such as autonomous vehicles, smart surveillance, and healthcare, their\ndeployment on resource-constrained edge devices remains challenging due to\nprocessing power, memory, and energy limitations. This survey explores recent\nadvancements in optimizing VLMs for edge environments, focusing on model\ncompression techniques, including pruning, quantization, knowledge\ndistillation, and specialized hardware solutions that enhance efficiency. We\nprovide a detailed discussion of efficient training and fine-tuning methods,\nedge deployment challenges, and privacy considerations. Additionally, we\ndiscuss the diverse applications of lightweight VLMs across healthcare,\nenvironmental monitoring, and autonomous systems, illustrating their growing\nimpact. By highlighting key design strategies, current challenges, and offering\nrecommendations for future directions, this survey aims to inspire further\nresearch into the practical deployment of VLMs, ultimately making advanced AI\naccessible in resource-limited settings."
  },
  {
    "arxiv_id": "2502.09390",
    "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models",
    "url": "http://arxiv.org/abs/2502.09390v1",
    "abstract": "In the rapidly evolving field of Natural Language Processing, Large Language\nModels (LLMs) are tasked with increasingly complex reasoning challenges.\nTraditional methods like chain-of-thought prompting have shown promise but\noften fall short in fully leveraging a model's reasoning capabilities. This\npaper introduces SQuARE (Sequential Question Answering Reasoning Engine), a\nnovel prompting technique designed to improve reasoning through a\nself-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts\nmodels to generate and resolve multiple auxiliary questions before tackling the\nmain query, promoting a more thorough exploration of various aspects of a\ntopic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models\nacross multiple question-answering datasets, demonstrate that SQuARE\nsignificantly surpasses traditional CoT prompts and existing\nrephrase-and-respond methods. By systematically decomposing queries, SQuARE\nadvances LLM capabilities in reasoning tasks. The code is publicly available at\nhttps://github.com/IntelLabs/RAG-FiT/tree/square."
  },
  {
    "arxiv_id": "2502.09211",
    "title": "Visual Graph Question Answering with ASP and LLMs for Language Parsing",
    "url": "http://arxiv.org/abs/2502.09211v1",
    "abstract": "Visual Question Answering (VQA) is a challenging problem that requires to\nprocess multimodal input. Answer-Set Programming (ASP) has shown great\npotential in this regard to add interpretability and explainability to modular\nVQA architectures. In this work, we address the problem of how to integrate ASP\nwith modules for vision and natural language processing to solve a new and\ndemanding VQA variant that is concerned with images of graphs (not graphs in\nsymbolic form). Images containing graph-based structures are an ubiquitous and\npopular form of visualisation. Here, we deal with the particular problem of\ngraphs inspired by transit networks, and we introduce a novel dataset that\namends an existing one by adding images of graphs that resemble metro lines.\nOur modular neuro-symbolic approach combines optical graph recognition for\ngraph parsing, a pretrained optical character recognition neural network for\nparsing labels, Large Language Models (LLMs) for language processing, and ASP\nfor reasoning. This method serves as a first baseline and achieves an overall\naverage accuracy of 73% on the dataset. Our evaluation provides further\nevidence of the potential of modular neuro-symbolic systems, in particular with\npretrained models that do not involve any further training and logic\nprogramming for reasoning, to solve complex VQA tasks."
  },
  {
    "arxiv_id": "2502.09204",
    "title": "Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York",
    "url": "http://arxiv.org/abs/2502.09204v1",
    "abstract": "Legal cases require careful logical reasoning following the laws, whereas\ninteractions with non-technical users must be in natural language. As an\napplication combining logical reasoning using Prolog and natural language\nprocessing using large language models (LLMs), this paper presents a novel\napproach and system, LogicLease, to automate the analysis of landlord-tenant\nlegal cases in the state of New York. LogicLease determines compliance with\nrelevant legal requirements by analyzing case descriptions and citing all\nrelevant laws. It leverages LLMs for information extraction and Prolog for\nlegal reasoning. By separating information extraction from legal reasoning,\nLogicLease achieves greater transparency and control over the legal logic\napplied to each case. We evaluate the accuracy, efficiency, and robustness of\nLogicLease through a series of tests, achieving 100% accuracy and an average\nprocessing time of 2.57 seconds. LogicLease presents advantages over\nstate-of-the-art LLM-based legal analysis systems by providing clear,\nstep-by-step reasoning, citing specific laws, and distinguishing itself by its\nability to avoid hallucinations -- a common issue in LLMs."
  },
  {
    "arxiv_id": "2502.09142",
    "title": "LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation",
    "url": "http://arxiv.org/abs/2502.09142v1",
    "abstract": "The integration of robotics and augmented reality (AR) presents\ntransformative opportunities for advancing human-robot interaction (HRI) by\nimproving usability, intuitiveness, and accessibility. This work introduces a\ncontroller-free, LLM-driven voice-commanded AR puppeteering system, enabling\nusers to teleoperate a robot by manipulating its virtual counterpart in real\ntime. By leveraging natural language processing (NLP) and AR technologies, our\nsystem -- prototyped using Meta Quest 3 -- eliminates the need for physical\ncontrollers, enhancing ease of use while minimizing potential safety risks\nassociated with direct robot operation. A preliminary user demonstration\nsuccessfully validated the system's functionality, demonstrating its potential\nfor safer, more intuitive, and immersive robotic control."
  },
  {
    "arxiv_id": "2502.09135",
    "title": "Interpreting and Steering Protein Language Models through Sparse Autoencoders",
    "url": "http://arxiv.org/abs/2502.09135v1",
    "abstract": "The rapid advancements in transformer-based language models have\nrevolutionized natural language processing, yet understanding the internal\nmechanisms of these models remains a significant challenge. This paper explores\nthe application of sparse autoencoders (SAE) to interpret the internal\nrepresentations of protein language models, specifically focusing on the ESM-2\n8M parameter model. By performing a statistical analysis on each latent\ncomponent's relevance to distinct protein annotations, we identify potential\ninterpretations linked to various protein characteristics, including\ntransmembrane regions, binding sites, and specialized motifs.\n  We then leverage these insights to guide sequence generation, shortlisting\nthe relevant latent components that can steer the model towards desired targets\nsuch as zinc finger domains. This work contributes to the emerging field of\nmechanistic interpretability in biological sequence models, offering new\nperspectives on model steering for sequence design."
  },
  {
    "arxiv_id": "2502.09086",
    "title": "A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning",
    "url": "http://arxiv.org/abs/2502.09086v1",
    "abstract": "With the continuous development of natural language processing (NLP)\ntechnology, text classification tasks have been widely used in multiple\napplication fields. However, obtaining labeled data is often expensive and\ndifficult, especially in few-shot learning scenarios. To solve this problem,\nthis paper proposes a few-shot text classification model based on transfer\nlearning and meta-learning. The model uses the knowledge of the pre-trained\nmodel for transfer and optimizes the model's rapid adaptability in few-sample\ntasks through a meta-learning mechanism. Through a series of comparative\nexperiments and ablation experiments, we verified the effectiveness of the\nproposed method. The experimental results show that under the conditions of few\nsamples and medium samples, the model based on transfer learning and\nmeta-learning significantly outperforms traditional machine learning and deep\nlearning methods. In addition, ablation experiments further analyzed the\ncontribution of each component to the model performance and confirmed the key\nrole of transfer learning and meta-learning in improving model accuracy.\nFinally, this paper discusses future research directions and looks forward to\nthe potential of this method in practical applications."
  },
  {
    "arxiv_id": "2502.10140",
    "title": "Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages",
    "url": "http://arxiv.org/abs/2502.10140v1",
    "abstract": "Low-resource languages (LRLs) face significant challenges in natural language\nprocessing (NLP) due to limited data. While current state-of-the-art large\nlanguage models (LLMs) still struggle with LRLs, smaller multilingual models\n(mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of\ntheir capacity to low training data sizes. This study systematically\ninvestigates parameter-efficient adapter-based methods for adapting mLMs to\nLRLs, evaluating three architectures: Sequential Bottleneck, Invertible\nBottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and\nstructured knowledge from ConceptNet, we show that small adaptation datasets\n(e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains\nin intrinsic (masked language modeling) and extrinsic tasks (topic\nclassification, sentiment analysis, and named entity recognition). We find that\nSequential Bottleneck adapters excel in language modeling, while Invertible\nBottleneck adapters slightly outperform other methods on downstream tasks due\nto better embedding alignment and larger parameter counts. Adapter-based\nmethods match or outperform full fine-tuning while using far fewer parameters,\nand smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3,\nGPT-4, and DeepSeek-R1-based distilled models. While adaptation improves\nperformance, pre-training data size remains the dominant factor, especially for\nlanguages with extensive pre-training coverage."
  },
  {
    "arxiv_id": "2502.09723",
    "title": "Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models",
    "url": "http://arxiv.org/abs/2502.09723v1",
    "abstract": "Recent advances in large language models (LLMs) have demonstrated remarkable\npotential in the field of natural language processing. Unfortunately, LLMs face\nsignificant security and ethical risks. Although techniques such as safety\nalignment are developed for defense, prior researches reveal the possibility of\nbypassing such defenses through well-designed jailbreak attacks. In this paper,\nwe propose QueryAttack, a novel framework to examine the generalizability of\nsafety alignment. By treating LLMs as knowledge databases, we translate\nmalicious queries in natural language into structured non-natural query\nlanguage to bypass the safety alignment mechanisms of LLMs. We conduct\nextensive experiments on mainstream LLMs, and the results show that QueryAttack\nnot only can achieve high attack success rates (ASRs), but also can jailbreak\nvarious defense methods. Furthermore, we tailor a defense method against\nQueryAttack, which can reduce ASR by up to 64% on GPT-4-1106. Our code is\navailable at https://github.com/horizonsinzqs/QueryAttack."
  },
  {
    "arxiv_id": "2502.09690",
    "title": "Trust at Your Own Peril: A Mixed Methods Exploration of the Ability of Large Language Models to Generate Expert-Like Systems Engineering Artifacts and a Characterization of Failure Modes",
    "url": "http://arxiv.org/abs/2502.09690v1",
    "abstract": "Multi-purpose Large Language Models (LLMs), a subset of generative Artificial\nIntelligence (AI), have recently made significant progress. While expectations\nfor LLMs to assist systems engineering (SE) tasks are paramount; the\ninterdisciplinary and complex nature of systems, along with the need to\nsynthesize deep-domain knowledge and operational context, raise questions\nregarding the efficacy of LLMs to generate SE artifacts, particularly given\nthat they are trained using data that is broadly available on the internet. To\nthat end, we present results from an empirical exploration, where a human\nexpert-generated SE artifact was taken as a benchmark, parsed, and fed into\nvarious LLMs through prompt engineering to generate segments of typical SE\nartifacts. This procedure was applied without any fine-tuning or calibration to\ndocument baseline LLM performance. We then adopted a two-fold mixed-methods\napproach to compare AI generated artifacts against the benchmark. First, we\nquantitatively compare the artifacts using natural language processing\nalgorithms and find that when prompted carefully, the state-of-the-art\nalgorithms cannot differentiate AI-generated artifacts from the human-expert\nbenchmark. Second, we conduct a qualitative deep dive to investigate how they\ndiffer in terms of quality. We document that while the two-material appear very\nsimilar, AI generated artifacts exhibit serious failure modes that could be\ndifficult to detect. We characterize these as: premature requirements\ndefinition, unsubstantiated numerical estimates, and propensity to overspecify.\nWe contend that this study tells a cautionary tale about why the SE community\nmust be more cautious adopting AI suggested feedback, at least when generated\nby multi-purpose LLMs."
  },
  {
    "arxiv_id": "2502.11832",
    "title": "HAAN: A Holistic Approach for Accelerating Normalization Operations in Large Language Models",
    "url": "http://arxiv.org/abs/2502.11832v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) tasks by achieving state-of-the-art performance across a range of\nbenchmarks. Central to the success of these models is the integration of\nsophisticated architectural components aimed at improving training stability,\nconvergence speed, and generalization capabilities. Among these components,\nnormalization operation, such as layer normalization (LayerNorm), emerges as a\npivotal technique, offering substantial benefits to the overall model\nperformance. However, previous studies have indicated that normalization\noperations can substantially elevate processing latency and energy usage. In\nthis work, we adopt the principles of algorithm and hardware co-design,\nintroducing a holistic normalization accelerating method named HAAN. The\nevaluation results demonstrate that HAAN can achieve significantly better\nhardware performance compared to state-of-the-art solutions."
  },
  {
    "arxiv_id": "2502.11671",
    "title": "Diversity-Oriented Data Augmentation with Large Language Models",
    "url": "http://arxiv.org/abs/2502.11671v1",
    "abstract": "Data augmentation is an essential technique in natural language processing\n(NLP) for enriching training datasets by generating diverse samples. This\nprocess is crucial for improving the robustness and generalization capabilities\nof NLP models. However, a significant challenge remains: \\textit{Insufficient\nAttention to Sample Distribution Diversity}. Most existing methods focus on\nincreasing the sample numbers while neglecting the sample distribution\ndiversity, which can lead to model overfitting. In response, we explore data\naugmentation's impact on dataset diversity and propose a\n\\textbf{\\underline{D}}iversity-\\textbf{\\underline{o}}riented data\n\\textbf{\\underline{Aug}}mentation framework (\\textbf{DoAug}). %\n\\(\\mathscr{DoAug}\\) Specifically, we utilize a diversity-oriented fine-tuning\napproach to train an LLM as a diverse paraphraser, which is capable of\naugmenting textual datasets by generating diversified paraphrases. Then, we\napply the LLM paraphraser to a selected coreset of highly informative samples\nand integrate the paraphrases with the original data to create a more diverse\naugmented dataset. Finally, we conduct extensive experiments on 12 real-world\ntextual datasets. The results show that our fine-tuned LLM augmenter improves\ndiversity while preserving label consistency, thereby enhancing the robustness\nand performance of downstream tasks. Specifically, it achieves an average\nperformance gain of \\(10.52\\%\\), surpassing the runner-up baseline with more\nthan three percentage points."
  },
  {
    "arxiv_id": "2502.11603",
    "title": "DR.GAP: Mitigating Bias in Large Language Models using Gender-Aware Prompting with Demonstration and Reasoning",
    "url": "http://arxiv.org/abs/2502.11603v1",
    "abstract": "Large Language Models (LLMs) exhibit strong natural language processing\ncapabilities but also inherit and amplify societal biases, including gender\nbias, raising fairness concerns. Existing debiasing methods face significant\nlimitations: parameter tuning requires access to model weights, prompt-based\napproaches often degrade model utility, and optimization-based techniques lack\ngeneralizability. To address these challenges, we propose DR.GAP (Demonstration\nand Reasoning for Gender-Aware Prompting), an automated and model-agnostic\napproach that mitigates gender bias while preserving model performance. DR.GAP\nselects bias-revealing examples and generates structured reasoning to guide\nmodels toward more impartial responses. Extensive experiments on coreference\nresolution and QA tasks across multiple LLMs (GPT-3.5, Llama3, and\nLlama2-Alpaca) demonstrate its effectiveness, generalization ability, and\nrobustness. DR.GAP can generalize to vision-language models (VLMs), achieving\nsignificant bias reduction."
  },
  {
    "arxiv_id": "2502.11559",
    "title": "Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models",
    "url": "http://arxiv.org/abs/2502.11559v1",
    "abstract": "Pre-training large language models (LLMs) on vast text corpora enhances\nnatural language processing capabilities but risks encoding social biases,\nparticularly gender bias. While parameter-modification methods like fine-tuning\nmitigate bias, they are resource-intensive, unsuitable for closed-source\nmodels, and lack adaptability to evolving societal norms. Instruction-based\napproaches offer flexibility but often compromise task performance. To address\nthese limitations, we propose $\\textit{FaIRMaker}$, an automated and\nmodel-independent framework that employs an $\\textbf{auto-search and\nrefinement}$ paradigm to adaptively generate Fairwords, which act as\ninstructions integrated into input queries to reduce gender bias and enhance\nresponse quality. Extensive experiments demonstrate that $\\textit{FaIRMaker}$\nautomatically searches for and dynamically refines Fairwords, effectively\nmitigating gender bias while preserving task integrity and ensuring\ncompatibility with both API-based and open-source LLMs."
  },
  {
    "arxiv_id": "2502.11491",
    "title": "Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering",
    "url": "http://arxiv.org/abs/2502.11491v1",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing. However, in knowledge graph question answering tasks\n(KGQA), there remains the issue of answering questions that require multi-hop\nreasoning. Existing methods rely on entity vector matching, but the purpose of\nthe question is abstract and difficult to match with specific entities. As a\nresult, it is difficult to establish reasoning paths to the purpose, which\nleads to information loss and redundancy. To address this issue, inspired by\nhuman reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a\nnovel framework that constructs reasoning paths from purposes back to\nconditions. ORT operates in three key phases: (1) using LLM to extract purpose\nlabels and condition labels, (2) constructing label reasoning paths based on\nthe KG ontology, and (3) using the label reasoning paths to guide knowledge\nretrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves\nstate-of-the-art performance and significantly enhances the capability of LLMs\nfor KGQA."
  },
  {
    "arxiv_id": "2502.11467",
    "title": "Approximation of Permutation Invariant Polynomials by Transformers: Efficient Construction in Column-Size",
    "url": "http://arxiv.org/abs/2502.11467v1",
    "abstract": "Transformers are a type of neural network that have demonstrated remarkable\nperformance across various domains, particularly in natural language processing\ntasks. Motivated by this success, research on the theoretical understanding of\ntransformers has garnered significant attention. A notable example is the\nmathematical analysis of their approximation power, which validates the\nempirical expressive capability of transformers. In this study, we investigate\nthe ability of transformers to approximate column-symmetric polynomials, an\nextension of symmetric polynomials that take matrices as input. Consequently,\nwe establish an explicit relationship between the size of the transformer\nnetwork and its approximation capability, leveraging the parameter efficiency\nof transformers and their compatibility with symmetry by focusing on the\nalgebraic properties of symmetric polynomials."
  },
  {
    "arxiv_id": "2502.13031",
    "title": "HPSS: Heuristic Prompting Strategy Search for LLM Evaluators",
    "url": "http://arxiv.org/abs/2502.13031v1",
    "abstract": "Since the adoption of large language models (LLMs) for text evaluation has\nbecome increasingly prevalent in the field of natural language processing\n(NLP), a series of existing works attempt to optimize the prompts for LLM\nevaluators to improve their alignment with human judgment. However, their\nefforts are limited to optimizing individual factors of evaluation prompts,\nsuch as evaluation criteria or output formats, neglecting the combinatorial\nimpact of multiple factors, which leads to insufficient optimization of the\nevaluation pipeline. Nevertheless, identifying well-behaved prompting\nstrategies for adjusting multiple factors requires extensive enumeration. To\nthis end, we comprehensively integrate 8 key factors for evaluation prompts and\npropose a novel automatic prompting strategy optimization method called\nHeuristic Prompting Strategy Search (HPSS). Inspired by the genetic algorithm,\nHPSS conducts an iterative search to find well-behaved prompting strategies for\nLLM evaluators. A heuristic function is employed to guide the search process,\nenhancing the performance of our algorithm. Extensive experiments across four\nevaluation tasks demonstrate the effectiveness of HPSS, consistently\noutperforming both human-designed evaluation prompts and existing automatic\nprompt optimization methods."
  },
  {
    "arxiv_id": "2502.12924",
    "title": "Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded in Naturally Occurring Data",
    "url": "http://arxiv.org/abs/2502.12924v1",
    "abstract": "Code-switching (CS) is still a critical challenge in Natural Language\nProcessing (NLP). Current Large Language Models (LLMs) struggle to interpret\nand generate code-switched text, primarily due to the scarcity of large-scale\nCS datasets for training. This paper presents a novel methodology to generate\nCS data using LLMs, and test it on the English-Spanish language pair. We\npropose back-translating natural CS sentences into monolingual English, and\nusing the resulting parallel corpus to fine-tune LLMs to turn monolingual\nsentences into CS. Unlike previous approaches to CS generation, our methodology\nuses natural CS data as a starting point, allowing models to learn its natural\ndistribution beyond grammatical patterns. We thoroughly analyse the models'\nperformance through a study on human preferences, a qualitative error analysis\nand an evaluation with popular automatic metrics. Results show that our\nmethodology generates fluent code-switched text, expanding research\nopportunities in CS communication, and that traditional metrics do not\ncorrelate with human judgement when assessing the quality of the generated CS\ndata. We release our code and generated dataset under a CC-BY-NC-SA license."
  },
  {
    "arxiv_id": "2502.12886",
    "title": "Are Multilingual Language Models an Off-ramp for Under-resourced Languages? Will we arrive at Digital Language Equality in Europe in 2030?",
    "url": "http://arxiv.org/abs/2502.12886v1",
    "abstract": "Large language models (LLMs) demonstrate unprecedented capabilities and\ndefine the state of the art for almost all natural language processing (NLP)\ntasks and also for essentially all Language Technology (LT) applications. LLMs\ncan only be trained for languages for which a sufficient amount of pre-training\ndata is available, effectively excluding many languages that are typically\ncharacterised as under-resourced. However, there is both circumstantial and\nempirical evidence that multilingual LLMs, which have been trained using data\nsets that cover multiple languages (including under-resourced ones), do exhibit\nstrong capabilities for some of these under-resourced languages. Eventually,\nthis approach may have the potential to be a technological off-ramp for those\nunder-resourced languages for which \"native\" LLMs, and LLM-based technologies,\ncannot be developed due to a lack of training data. This paper, which\nconcentrates on European languages, examines this idea, analyses the current\nsituation in terms of technology support and summarises related work. The\narticle concludes by focusing on the key open questions that need to be\nanswered for the approach to be put into practice in a systematic way."
  },
  {
    "arxiv_id": "2502.12838",
    "title": "Towards Equitable AI: Detecting Bias in Using Large Language Models for Marketing",
    "url": "http://arxiv.org/abs/2502.12838v1",
    "abstract": "The recent advances in large language models (LLMs) have revolutionized\nindustries such as finance, marketing, and customer service by enabling\nsophisticated natural language processing tasks. However, the broad adoption of\nLLMs brings significant challenges, particularly in the form of social biases\nthat can be embedded within their outputs. Biases related to gender, age, and\nother sensitive attributes can lead to unfair treatment, raising ethical\nconcerns and risking both company reputation and customer trust. This study\nexamined bias in finance-related marketing slogans generated by LLMs (i.e.,\nChatGPT) by prompting tailored ads targeting five demographic categories:\ngender, marital status, age, income level, and education level. A total of\n1,700 slogans were generated for 17 unique demographic groups, and key terms\nwere categorized into four thematic groups: empowerment, financial, benefits\nand features, and personalization. Bias was systematically assessed using\nrelative bias calculations and statistically tested with the Kolmogorov-Smirnov\n(KS) test against general slogans generated for any individual. Results\nrevealed that marketing slogans are not neutral; rather, they emphasize\ndifferent themes based on demographic factors. Women, younger individuals,\nlow-income earners, and those with lower education levels receive more distinct\nmessaging compared to older, higher-income, and highly educated individuals.\nThis underscores the need to consider demographic-based biases in AI-generated\nmarketing strategies and their broader societal implications. The findings of\nthis study provide a roadmap for developing more equitable AI systems,\nhighlighting the need for ongoing bias detection and mitigation efforts in\nLLMs."
  },
  {
    "arxiv_id": "2502.12829",
    "title": "KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan",
    "url": "http://arxiv.org/abs/2502.12829v1",
    "abstract": "Despite having a population of twenty million, Kazakhstan's culture and\nlanguage remain underrepresented in the field of natural language processing.\nAlthough large language models (LLMs) continue to advance worldwide, progress\nin Kazakh language has been limited, as seen in the scarcity of dedicated\nmodels and benchmark evaluations. To address this gap, we introduce KazMMLU,\nthe first MMLU-style dataset specifically designed for Kazakh language. KazMMLU\ncomprises 23,000 questions that cover various educational levels, including\nSTEM, humanities, and social sciences, sourced from authentic educational\nmaterials and manually validated by native speakers and educators. The dataset\nincludes 10,969 Kazakh questions and 12,031 Russian questions, reflecting\nKazakhstan's bilingual education system and rich local context. Our evaluation\nof several state-of-the-art multilingual models (Llama-3.1, Qwen-2.5, GPT-4,\nand DeepSeek V3) demonstrates substantial room for improvement, as even the\nbest-performing models struggle to achieve competitive performance in Kazakh\nand Russian. These findings underscore significant performance gaps compared to\nhigh-resource languages. We hope that our dataset will enable further research\nand development of Kazakh-centric LLMs. Data and code will be made available\nupon acceptance."
  },
  {
    "arxiv_id": "2502.12560",
    "title": "How does a Language-Specific Tokenizer affect LLMs?",
    "url": "http://arxiv.org/abs/2502.12560v1",
    "abstract": "The necessity of language-specific tokenizers intuitively appears crucial for\neffective natural language processing, yet empirical analyses on their\nsignificance and underlying reasons are lacking. This study explores how\nlanguage-specific tokenizers influence the behavior of Large Language Models\npredominantly trained with English text data, through the case study of Korean.\nThe research unfolds in two main stages: (1) the development of a\nKorean-specific extended tokenizer and (2) experiments to compare models with\nthe basic tokenizer and the extended tokenizer through various Next Token\nPrediction tasks. Our in-depth analysis reveals that the extended tokenizer\ndecreases confidence in incorrect predictions during generation and reduces\ncross-entropy in complex tasks, indicating a tendency to produce less\nnonsensical outputs. Consequently, the extended tokenizer provides stability\nduring generation, potentially leading to higher performance in downstream\ntasks."
  },
  {
    "arxiv_id": "2502.13908",
    "title": "Judging the Judges: A Collection of LLM-Generated Relevance Judgements",
    "url": "http://arxiv.org/abs/2502.13908v1",
    "abstract": "Using Large Language Models (LLMs) for relevance assessments offers promising\nopportunities to improve Information Retrieval (IR), Natural Language\nProcessing (NLP), and related fields. Indeed, LLMs hold the promise of allowing\nIR experimenters to build evaluation collections with a fraction of the manual\nhuman labor currently required. This could help with fresh topics on which\nthere is still limited knowledge and could mitigate the challenges of\nevaluating ranking systems in low-resource scenarios, where it is challenging\nto find human annotators. Given the fast-paced recent developments in the\ndomain, many questions concerning LLMs as assessors are yet to be answered.\nAmong the aspects that require further investigation, we can list the impact of\nvarious components in a relevance judgment generation pipeline, such as the\nprompt used or the LLM chosen.\n  This paper benchmarks and reports on the results of a large-scale automatic\nrelevance judgment evaluation, the LLMJudge challenge at SIGIR 2024, where\ndifferent relevance assessment approaches were proposed. In detail, we release\nand benchmark 42 LLM-generated labels of the TREC 2023 Deep Learning track\nrelevance judgments produced by eight international teams who participated in\nthe challenge. Given their diverse nature, these automatically generated\nrelevance judgments can help the community not only investigate systematic\nbiases caused by LLMs but also explore the effectiveness of ensemble models,\nanalyze the trade-offs between different models and human assessors, and\nadvance methodologies for improving automated evaluation techniques. The\nreleased resource is available at the following link:\nhttps://llm4eval.github.io/LLMJudge-benchmark/"
  },
  {
    "arxiv_id": "2502.13832",
    "title": "ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities",
    "url": "http://arxiv.org/abs/2502.13832v1",
    "abstract": "Can Multimodal Large Language Models (MLLMs), with capabilities in\nperception, recognition, understanding, and reasoning, function as independent\nassistants in art evaluation dialogues? Current MLLM evaluation methods, which\nrely on subjective human scoring or costly interviews, lack comprehensive\ncoverage of various scenarios. This paper proposes a process-oriented\nHuman-Computer Interaction (HCI) space design to facilitate more accurate MLLM\nassessment and development. This approach aids teachers in efficient art\nevaluation while also recording interactions for MLLM capability assessment. We\nintroduce ArtMentor, a comprehensive space that integrates a dataset and three\nsystems to optimize MLLM evaluation. The dataset consists of 380 sessions\nconducted by five art teachers across nine critical dimensions. The modular\nsystem includes agents for entity recognition, review generation, and\nsuggestion generation, enabling iterative upgrades. Machine learning and\nnatural language processing techniques ensure the reliability of evaluations.\nThe results confirm GPT-4o's effectiveness in assisting teachers in art\nevaluation dialogues. Our contributions are available at\nhttps://artmentor.github.io/."
  },
  {
    "arxiv_id": "2502.13725",
    "title": "Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method",
    "url": "http://arxiv.org/abs/2502.13725v1",
    "abstract": "Time series modeling holds significant importance in many real-world\napplications and has been extensively studied. While pre-trained foundation\nmodels have made impressive strides in the fields of natural language\nprocessing (NLP) and computer vision (CV), their development in time series\ndomains has been constrained by data sparsity. A series of recent studies have\ndemonstrated that large language models (LLMs) possess robust pattern\nrecognition and reasoning abilities over complex sequences of tokens. However,\nthe current literature have yet striked a high-quality balance between (a)\neffectively aligning the time series and natural language modalities, and (b)\nkeeping the inference efficiency. To address the above issues, we now propose\nthe Time-LlaMA framework. Time-LlaMA first converts the time series input into\ntoken embeddings through a linear tokenization mechanism. Second, the time\nseries token embeddings are aligned with the text prompts. Third, to further\nadapt the LLM backbone for time series modeling, we have developed a dynamic\nlow-rank adaptation technique (D-LoRA). D-LoRA dynamically chooses the most\nsuitable LoRA modules at each layer of the Transformer backbone for each time\nseries input, enhancing the model's predictive capabilities. Our experimental\nresults on an extensive collection of challenging real-world time series tasks\nconfirm that our proposed method achieves the state-of-the-art (SOTA)\nperformance."
  },
  {
    "arxiv_id": "2502.13533",
    "title": "Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models",
    "url": "http://arxiv.org/abs/2502.13533v1",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language\nprocessing with exceptional task generalization capabilities. Low-Rank Adaption\n(LoRA) offers a cost-effective fine-tuning solution, freezing the original\nmodel parameters and training only lightweight, low-rank adapter matrices.\nHowever, the memory footprint of LoRA is largely dominated by the original\nmodel parameters. To mitigate this, we propose LoRAM, a memory-efficient LoRA\ntraining scheme founded on the intuition that many neurons in\nover-parameterized LLMs have low training utility but are essential for\ninference. LoRAM presents a unique twist: it trains on a pruned (small) model\nto obtain pruned low-rank matrices, which are then recovered and utilized with\nthe original (large) model for inference. Additionally, minimal-cost continual\npre-training, performed by the model publishers in advance, aligns the\nknowledge discrepancy between pruned and original models. Our extensive\nexperiments demonstrate the efficacy of LoRAM across various pruning strategies\nand downstream tasks. For a model with 70 billion parameters, LoRAM enables\ntraining on a GPU with only 20G HBM, replacing an A100-80G GPU for LoRA\ntraining and 15 GPUs for full fine-tuning. Specifically, QLoRAM implemented by\nstructured pruning combined with 4-bit quantization, for LLaMA-3.1-70B\n(LLaMA-2-70B), reduces the parameter storage cost that dominates the memory\nusage in low-rank matrix training by 15.81$\\times$ (16.95$\\times$), while\nachieving dominant performance gains over both the original LLaMA-3.1-70B\n(LLaMA-2-70B) and LoRA-trained LLaMA-3.1-8B (LLaMA-2-13B). Code is available at\nhttps://github.com/junzhang-zj/LoRAM."
  },
  {
    "arxiv_id": "2502.13474",
    "title": "Towards Lightweight, Adaptive and Attribute-Aware Multi-Aspect Controllable Text Generation with Large Language Models",
    "url": "http://arxiv.org/abs/2502.13474v1",
    "abstract": "Multi-aspect controllable text generation aims to control text generation in\nattributes from multiple aspects, making it a complex but powerful task in\nnatural language processing. Supervised fine-tuning methods are often employed\nfor this task due to their simplicity and effectiveness. However, they still\nhave some limitations: low rank adaptation (LoRA) only fine-tunes a few\nparameters and has suboptimal control effects, while full fine-tuning (FFT)\nrequires significant computational resources and is susceptible to overfitting,\nparticularly when data is limited. Moreover, existing works typically train\nmulti-aspect controllable text generation models using only single-aspect\nannotated data, which results in discrepancies in data distribution; at the\nsame time, accurately generating text with specific attributes is a challenge\nthat requires strong attribute-aware capabilities. To address these\nlimitations, we propose a lightweight, adaptive and attribute-aware framework\nfor multi-aspect controllable text generation. Our framework can dynamically\nadjust model parameters according to different aspects of data to achieve\ncontrollable text generation, aiming to optimize performance across multiple\naspects. Experimental results show that our framework outperforms other strong\nbaselines, achieves state-of-the-art performance, adapts well to data\ndiscrepancies, and is more accurate in attribute perception."
  },
  {
    "arxiv_id": "2502.13358",
    "title": "Bridging the Editing Gap in LLMs: FineEdit for Precise and Targeted Text Modifications",
    "url": "http://arxiv.org/abs/2502.13358v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nyet they still struggle with direct text editing tasks that demand precise,\ncontext-aware modifications. While models like ChatGPT excel in text generation\nand analysis, their editing abilities often fall short, addressing only\nsuperficial issues rather than deeper structural or logical inconsistencies. In\nthis work, we introduce a dual approach to enhance LLMs editing performance.\nFirst, we present InstrEditBench, a high-quality benchmark dataset comprising\nover 20,000 structured editing tasks spanning Wiki articles, LaTeX documents,\ncode, and database Domain-specific Languages (DSL). InstrEditBench is generated\nusing an innovative automated workflow that accurately identifies and evaluates\ntargeted edits, ensuring that modifications adhere strictly to specified\ninstructions without altering unrelated content. Second, we propose FineEdit, a\nspecialized model trained on this curated benchmark. Experimental results\ndemonstrate that FineEdit achieves significant improvements around {10\\%}\ncompared with Gemini on direct editing tasks, convincingly validating its\neffectiveness."
  },
  {
    "arxiv_id": "2502.14538",
    "title": "LoRA-GGPO: Mitigating Double Descent in LoRA Fine-Tuning via Gradient-Guided Perturbation Optimization",
    "url": "http://arxiv.org/abs/2502.14538v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing, but their full fine-tuning remains resource-intensive.\nParameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation\n(LoRA), have emerged as a practical solution by approximating parameter updates\nwith low-rank matrices. However, LoRA often exhibits a \"double descent\"\nphenomenon during fine-tuning, where model performance degrades due to\noverfitting and limited expressiveness caused by low-rank constraints. To\naddress this issue, we propose LoRA-GGPO (Gradient-Guided Perturbation\nOptimization), a novel method that leverages gradient and weight norms to\ngenerate targeted perturbations. By optimizing the sharpness of the loss\nlandscape, LoRA-GGPO guides the model toward flatter minima, mitigating the\ndouble descent problem and improving generalization. Extensive experiments on\nnatural language understanding (NLU) and generation (NLG) tasks demonstrate\nthat LoRA-GGPO outperforms LoRA and its state-of-the-art variants. Furthermore,\nextended experiments specifically designed to analyze the double descent\nphenomenon confirm that LoRA-GGPO effectively alleviates this issue, producing\nmore robust and generalizable models. Our work provides a robust and efficient\nsolution for fine-tuning LLMs, with broad applicability in real-world\nscenarios. The code is available at https://github.com/llm172/LoRA-GGPO."
  },
  {
    "arxiv_id": "2502.14315",
    "title": "Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension",
    "url": "http://arxiv.org/abs/2502.14315v1",
    "abstract": "Despite the impressive performance of multilingual large language models\n(mLLMs) in various natural language processing tasks, their ability to\nunderstand procedural texts, particularly those with culture-specific content,\nremains largely unexplored. Texts describing cultural procedures, including\nrituals, traditional craftsmanship, and social etiquette, require an inherent\nunderstanding of cultural context, presenting a significant challenge for\nmLLMs. In this work, we introduce CAPTex, a benchmark designed to evaluate\nmLLMs' ability to process and reason about culturally diverse procedural texts\nacross multiple languages using various methodologies to assess their\nperformance. Our findings indicate that (1) mLLMs face difficulties with\nculturally contextualized procedural texts, showing notable performance\ndeclines in low-resource languages, (2) model performance fluctuates across\ncultural domains, with some areas presenting greater difficulties, and (3)\nlanguage models exhibit better performance on multiple-choice tasks within\nconversational frameworks compared to direct questioning. These results\nunderscore the current limitations of mLLMs in handling culturally nuanced\nprocedural texts and highlight the need for culturally aware benchmarks like\nCAPTex to enhance their adaptability and comprehension across diverse\nlinguistic and cultural landscapes."
  },
  {
    "arxiv_id": "2502.14189",
    "title": "QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare Text Multi-Label Classification",
    "url": "http://arxiv.org/abs/2502.14189v1",
    "abstract": "The escalating volume of collected healthcare textual data presents a unique\nchallenge for automated Multi-Label Text Classification (MLTC), which is\nprimarily due to the scarcity of annotated texts for training and their nuanced\nnature. Traditional machine learning models often fail to fully capture the\narray of expressed topics. However, Large Language Models (LLMs) have\ndemonstrated remarkable effectiveness across numerous Natural Language\nProcessing (NLP) tasks in various domains, which show impressive computational\nefficiency and suitability for unsupervised learning through prompt\nengineering. Consequently, these LLMs promise an effective MLTC of medical\nnarratives. However, when dealing with various labels, different prompts can be\nrelevant depending on the topic. To address these challenges, the proposed\napproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,\nPEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in which\nBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, and\nBART provides topics' assignment probabilities, which results in four\nclassifications, all in a 0-shot setting. The outputs are then combined using\nensemble learning and processed through a meta-classifier to produce the final\nMLTC result. The approach is evaluated using three samples of annotated texts,\nwhich contrast it with traditional and single-model methods. The results show\nsignificant improvements across the majority of the topics in the\nclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and\n80.16% with standard deviations of 0.025 and 0.011, respectively). This\nresearch advances MLTC using LLMs and provides an efficient and scalable\nsolution to rapidly categorize healthcare-related text data without further\ntraining."
  },
  {
    "arxiv_id": "2502.14122",
    "title": "Benchmarking LLMs for Political Science: A United Nations Perspective",
    "url": "http://arxiv.org/abs/2502.14122v1",
    "abstract": "Large Language Models (LLMs) have achieved significant advances in natural\nlanguage processing, yet their potential for high-stake political\ndecision-making remains largely unexplored. This paper addresses the gap by\nfocusing on the application of LLMs to the United Nations (UN) decision-making\nprocess, where the stakes are particularly high and political decisions can\nhave far-reaching consequences. We introduce a novel dataset comprising\npublicly available UN Security Council (UNSC) records from 1994 to 2024,\nincluding draft resolutions, voting records, and diplomatic speeches. Using\nthis dataset, we propose the United Nations Benchmark (UNBench), the first\ncomprehensive benchmark designed to evaluate LLMs across four interconnected\npolitical science tasks: co-penholder judgment, representative voting\nsimulation, draft adoption prediction, and representative statement generation.\nThese tasks span the three stages of the UN decision-making process--drafting,\nvoting, and discussing--and aim to assess LLMs' ability to understand and\nsimulate political dynamics. Our experimental analysis demonstrates the\npotential and challenges of applying LLMs in this domain, providing insights\ninto their strengths and limitations in political science. This work\ncontributes to the growing intersection of AI and political science, opening\nnew avenues for research and practical applications in global governance. The\nUNBench Repository can be accessed at:\nhttps://github.com/yueqingliang1/UNBench."
  },
  {
    "arxiv_id": "2502.17129",
    "title": "Thus Spake Long-Context Large Language Model",
    "url": "http://arxiv.org/abs/2502.17129v1",
    "abstract": "Long context is an important topic in Natural Language Processing (NLP),\nrunning through the development of NLP architectures, and offers immense\nopportunities for Large Language Models (LLMs) giving LLMs the lifelong\nlearning potential akin to humans. Unfortunately, the pursuit of a long context\nis accompanied by numerous obstacles. Nevertheless, long context remains a core\ncompetitive advantage for LLMs. In the past two years, the context length of\nLLMs has achieved a breakthrough extension to millions of tokens. Moreover, the\nresearch on long-context LLMs has expanded from length extrapolation to a\ncomprehensive focus on architecture, infrastructure, training, and evaluation\ntechnologies.\n  Inspired by the symphonic poem, Thus Spake Zarathustra, we draw an analogy\nbetween the journey of extending the context of LLM and the attempts of humans\nto transcend its mortality. In this survey, We will illustrate how LLM\nstruggles between the tremendous need for a longer context and its equal need\nto accept the fact that it is ultimately finite. To achieve this, we give a\nglobal picture of the lifecycle of long-context LLMs from four perspectives:\narchitecture, infrastructure, training, and evaluation, showcasing the full\nspectrum of long-context technologies. At the end of this survey, we will\npresent 10 unanswered questions currently faced by long-context LLMs. We hope\nthis survey can serve as a systematic introduction to the research on\nlong-context LLMs."
  },
  {
    "arxiv_id": "2502.17071",
    "title": "Systematic Weight Evaluation for Pruning Large Language Models: Enhancing Performance and Sustainability",
    "url": "http://arxiv.org/abs/2502.17071v1",
    "abstract": "The exponential growth of large language models (LLMs) like ChatGPT has\nrevolutionized artificial intelligence, offering unprecedented capabilities in\nnatural language processing. However, the extensive computational resources\nrequired for training these models have significant environmental implications,\nincluding high carbon emissions, energy consumption, and water usage. This\nresearch presents a novel approach to LLM pruning, focusing on the systematic\nevaluation of individual weight importance throughout the training process. By\nmonitoring parameter evolution over time, we propose a method that effectively\nreduces model size without compromising performance. Extensive experiments with\nboth a scaled-down LLM and a large multimodal model reveal that moderate\npruning enhances efficiency and reduces loss, while excessive pruning\ndrastically deteriorates model performance. These findings highlight the\ncritical need for optimized AI models to ensure sustainable development,\nbalancing technological advancement with environmental responsibility."
  },
  {
    "arxiv_id": "2502.17017",
    "title": "Quantifying Logical Consistency in Transformers via Query-Key Alignment",
    "url": "http://arxiv.org/abs/2502.17017v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance in\nvarious natural language processing tasks, yet their ability to perform\nmulti-step logical reasoning remains an open challenge. Although\nChain-of-Thought prompting has improved logical reasoning by enabling models to\ngenerate intermediate steps, it lacks mechanisms to assess the coherence of\nthese logical transitions. In this paper, we propose a novel, lightweight\nevaluation strategy for logical reasoning that uses query-key alignments inside\ntransformer attention heads. By computing a single forward pass and extracting\na \"QK-score\" from carefully chosen heads, our method reveals latent\nrepresentations that reliably separate valid from invalid inferences, offering\na scalable alternative to traditional ablation-based techniques. We also\nprovide an empirical validation on multiple logical reasoning benchmarks,\ndemonstrating improved robustness of our evaluation method against distractors\nand increased reasoning depth. The experiments were conducted on a diverse set\nof models, ranging from 1.5B to 70B parameters."
  },
  {
    "arxiv_id": "2502.16965",
    "title": "Autoregressive Image Generation Guided by Chains of Thought",
    "url": "http://arxiv.org/abs/2502.16965v1",
    "abstract": "In autoregressive (AR) image generation, models based on the 'next-token\nprediction' paradigm of LLMs have shown comparable performance to diffusion\nmodels by reducing inductive biases. However, directly applying LLMs to complex\nimage generation can struggle with reconstructing the image's structure and\ndetails, impacting the generation's accuracy and stability. Additionally, the\n'next-token prediction' paradigm in the AR model does not align with the\ncontextual scanning and logical reasoning processes involved in human visual\nperception, limiting effective image generation. Prompt engineering, as a key\ntechnique for guiding LLMs, leverages specifically designed prompts to improve\nmodel performance on complex natural language processing (NLP) tasks, enhancing\naccuracy and stability of generation while maintaining contextual coherence and\nlogical consistency, similar to human reasoning. Inspired by prompt engineering\nfrom the field of NLP, we propose Vision Full-view prompt (VF prompt) to\nenhance autoregressive image generation. Specifically, we design specialized\nimage-related VF prompts for AR image generation to simulate the process of\nhuman image creation. This enhances contextual logic ability by allowing the\nmodel to first perceive overall distribution information before generating the\nimage, and improve generation stability by increasing the inference steps.\nCompared to the AR method without VF prompts, our method shows outstanding\nperformance and achieves an approximate improvement of 20%."
  },
  {
    "arxiv_id": "2502.16923",
    "title": "A Systematic Survey of Automatic Prompt Optimization Techniques",
    "url": "http://arxiv.org/abs/2502.16923v1",
    "abstract": "Since the advent of large language models (LLMs), prompt engineering has been\na crucial step for eliciting desired responses for various Natural Language\nProcessing (NLP) tasks. However, prompt engineering remains an impediment for\nend users due to rapid advances in models, tasks, and associated best\npractices. To mitigate this, Automatic Prompt Optimization (APO) techniques\nhave recently emerged that use various automated techniques to help improve the\nperformance of LLMs on various tasks. In this paper, we present a comprehensive\nsurvey summarizing the current progress and remaining challenges in this field.\nWe provide a formal definition of APO, a 5-part unifying framework, and then\nproceed to rigorously categorize all relevant works based on their salient\nfeatures therein. We hope to spur further research guided by our framework."
  },
  {
    "arxiv_id": "2502.16919",
    "title": "Dependency Parsing with the Structuralized Prompt Template",
    "url": "http://arxiv.org/abs/2502.16919v1",
    "abstract": "Dependency parsing is a fundamental task in natural language processing\n(NLP), aiming to identify syntactic dependencies and construct a syntactic tree\nfor a given sentence. Traditional dependency parsing models typically construct\nembeddings and utilize additional layers for prediction. We propose a novel\ndependency parsing method that relies solely on an encoder model with a\ntext-to-text training approach. To facilitate this, we introduce a structured\nprompt template that effectively captures the structural information of\ndependency trees. Our experimental results demonstrate that the proposed method\nachieves outstanding performance compared to traditional models, despite\nrelying solely on a pre-trained model. Furthermore, this method is highly\nadaptable to various pre-trained models across different target languages and\ntraining environments, allowing easy integration of task-specific features."
  },
  {
    "arxiv_id": "2502.18318",
    "title": "Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology",
    "url": "http://arxiv.org/abs/2502.18318v1",
    "abstract": "Stroboscopic light stimulation (SLS) on closed eyes typically induces simple\nvisual hallucinations (VHs), characterised by vivid, geometric and colourful\npatterns. A dataset of 862 sentences, extracted from 422 open subjective\nreports, was recently compiled as part of the Dreamachine programme (Collective\nAct, 2022), an immersive multisensory experience that combines SLS and spatial\nsound in a collective setting. Although open reports extend the range of\nreportable phenomenology, their analysis presents significant challenges,\nparticularly in systematically identifying patterns. To address this challenge,\nwe implemented a data-driven approach leveraging Large Language Models and\nTopic Modelling to uncover and interpret latent experiential topics directly\nfrom the Dreamachine's text-based reports. Our analysis confirmed the presence\nof simple VHs typically documented in scientific studies of SLS, while also\nrevealing experiences of altered states of consciousness and complex\nhallucinations. Building on these findings, our computational approach expands\nthe systematic study of subjective experience by enabling data-driven analyses\nof open-ended phenomenological reports, capturing experiences not readily\nidentified through standard questionnaires. By revealing rich and multifaceted\naspects of experiences, our study broadens our understanding of\nstroboscopically-induced phenomena while highlighting the potential of Natural\nLanguage Processing and Large Language Models in the emerging field of\ncomputational (neuro)phenomenology. More generally, this approach provides a\npractically applicable methodology for uncovering subtle hidden patterns of\nsubjective experience across diverse research domains."
  },
  {
    "arxiv_id": "2502.17967",
    "title": "LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena",
    "url": "http://arxiv.org/abs/2502.17967v1",
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nimproved performance in natural language processing tasks. However, their\nability to generalize to dynamic, unseen tasks, particularly in numerical\nreasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on\nproblems with predefined optimal solutions, which may not align with real-world\nscenarios where clear answers are absent. To bridge this gap, we design the\nAgent Trading Arena, a virtual numerical game simulating complex economic\nsystems through zero-sum games, where agents invest in stock portfolios. Our\nexperiments reveal that LLMs, including GPT-4o, struggle with algebraic\nreasoning when dealing with plain-text stock data, often focusing on local\ndetails rather than global trends. In contrast, LLMs perform significantly\nbetter with geometric reasoning when presented with visual data, such as\nscatter plots or K-line charts, suggesting that visual representations enhance\nnumerical reasoning. This capability is further improved by incorporating the\nreflection module, which aids in the analysis and interpretation of complex\ndata. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate\nstronger reasoning with visual data compared to text. Our code and data are\npublicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git."
  },
  {
    "arxiv_id": "2502.17945",
    "title": "Assessing Large Language Models in Agentic Multilingual National Bias",
    "url": "http://arxiv.org/abs/2502.17945v1",
    "abstract": "Large Language Models have garnered significant attention for their\ncapabilities in multilingual natural language processing, while studies on\nrisks associated with cross biases are limited to immediate context\npreferences. Cross-language disparities in reasoning-based recommendations\nremain largely unexplored, with a lack of even descriptive analysis. This study\nis the first to address this gap. We test LLM's applicability and capability in\nproviding personalized advice across three key scenarios: university\napplications, travel, and relocation. We investigate multilingual bias in\nstate-of-the-art LLMs by analyzing their responses to decision-making tasks\nacross multiple languages. We quantify bias in model-generated scores and\nassess the impact of demographic factors and reasoning strategies (e.g.,\nChain-of-Thought prompting) on bias patterns. Our findings reveal that local\nlanguage bias is prevalent across different tasks, with GPT-4 and Sonnet\nreducing bias for English-speaking countries compared to GPT-3.5 but failing to\nachieve robust multilingual alignment, highlighting broader implications for\nmultilingual AI agents and applications such as education."
  },
  {
    "arxiv_id": "2502.17657",
    "title": "StatLLM: A Dataset for Evaluating the Performance of Large Language Models in Statistical Analysis",
    "url": "http://arxiv.org/abs/2502.17657v1",
    "abstract": "The coding capabilities of large language models (LLMs) have opened up new\nopportunities for automatic statistical analysis in machine learning and data\nscience. However, before their widespread adoption, it is crucial to assess the\naccuracy of code generated by LLMs. A major challenge in this evaluation lies\nin the absence of a benchmark dataset for statistical code (e.g., SAS and R).\nTo fill in this gap, this paper introduces StatLLM, an open-source dataset for\nevaluating the performance of LLMs in statistical analysis. The StatLLM dataset\ncomprises three key components: statistical analysis tasks, LLM-generated SAS\ncode, and human evaluation scores. The first component includes statistical\nanalysis tasks spanning a variety of analyses and datasets, providing problem\ndescriptions, dataset details, and human-verified SAS code. The second\ncomponent features SAS code generated by ChatGPT 3.5, ChatGPT 4.0, and Llama\n3.1 for those tasks. The third component contains evaluation scores from human\nexperts in assessing the correctness, effectiveness, readability,\nexecutability, and output accuracy of the LLM-generated code. We also\nillustrate the unique potential of the established benchmark dataset for (1)\nevaluating and enhancing natural language processing metrics, (2) assessing and\nimproving LLM performance in statistical coding, and (3) developing and testing\nof next-generation statistical software - advancements that are crucial for\ndata science and machine learning research."
  },
  {
    "arxiv_id": "2502.19339",
    "title": "Evaluating LLMs and Pre-trained Models for Text Summarization Across Diverse Datasets",
    "url": "http://arxiv.org/abs/2502.19339v1",
    "abstract": "Text summarization plays a crucial role in natural language processing by\ncondensing large volumes of text into concise and coherent summaries. As\ndigital content continues to grow rapidly and the demand for effective\ninformation retrieval increases, text summarization has become a focal point of\nresearch in recent years. This study offers a thorough evaluation of four\nleading pre-trained and open-source large language models: BART, FLAN-T5,\nLLaMA-3-8B, and Gemma-7B, across five diverse datasets CNN/DM, Gigaword, News\nSummary, XSum, and BBC News. The evaluation employs widely recognized automatic\nmetrics, including ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR, to assess\nthe models' capabilities in generating coherent and informative summaries. The\nresults reveal the comparative strengths and limitations of these models in\nprocessing various text types."
  },
  {
    "arxiv_id": "2502.19214",
    "title": "A Hybrid Transformer Architecture with a Quantized Self-Attention Mechanism Applied to Molecular Generation",
    "url": "http://arxiv.org/abs/2502.19214v1",
    "abstract": "The success of the self-attention mechanism in classical machine learning\nmodels has inspired the development of quantum analogs aimed at reducing\ncomputational overhead. Self-attention integrates learnable query and key\nmatrices to calculate attention scores between all pairs of tokens in a\nsequence. These scores are then multiplied by a learnable value matrix to\nobtain the output self-attention matrix, enabling the model to effectively\ncapture long-range dependencies within the input sequence. Here, we propose a\nhybrid quantum-classical self-attention mechanism as part of a transformer\ndecoder, the architecture underlying large language models (LLMs). To\ndemonstrate its utility in chemistry, we train this model on the QM9 dataset\nfor conditional generation, using SMILES strings as input, each labeled with a\nset of physicochemical properties that serve as conditions during inference.\nOur theoretical analysis shows that the time complexity of the query-key dot\nproduct is reduced from $\\mathcal{O}(n^2 d)$ in a classical model to\n$\\mathcal{O}(n^2\\log d)$ in our quantum model, where $n$ and $d$ represent the\nsequence length and embedding dimension, respectively. We perform simulations\nusing NVIDIA's CUDA-Q platform, which is designed for efficient GPU\nscalability. This work provides a promising avenue for quantum-enhanced natural\nlanguage processing (NLP)."
  },
  {
    "arxiv_id": "2502.19178",
    "title": "UQABench: Evaluating User Embedding for Prompting LLMs in Personalized Question Answering",
    "url": "http://arxiv.org/abs/2502.19178v1",
    "abstract": "Large language models (LLMs) achieve remarkable success in natural language\nprocessing (NLP). In practical scenarios like recommendations, as users\nincreasingly seek personalized experiences, it becomes crucial to incorporate\nuser interaction history into the context of LLMs to enhance personalization.\nHowever, from a practical utility perspective, user interactions' extensive\nlength and noise present challenges when used directly as text prompts. A\npromising solution is to compress and distill interactions into compact\nembeddings, serving as soft prompts to assist LLMs in generating personalized\nresponses. Although this approach brings efficiency, a critical concern\nemerges: Can user embeddings adequately capture valuable information and prompt\nLLMs? To address this concern, we propose \\name, a benchmark designed to\nevaluate the effectiveness of user embeddings in prompting LLMs for\npersonalization. We establish a fair and standardized evaluation process,\nencompassing pre-training, fine-tuning, and evaluation stages. To thoroughly\nevaluate user embeddings, we design three dimensions of tasks: sequence\nunderstanding, action prediction, and interest perception. These evaluation\ntasks cover the industry's demands in traditional recommendation tasks, such as\nimproving prediction accuracy, and its aspirations for LLM-based methods, such\nas accurately understanding user interests and enhancing the user experience.\nWe conduct extensive experiments on various state-of-the-art methods for\nmodeling user embeddings. Additionally, we reveal the scaling laws of\nleveraging user embeddings to prompt LLMs. The benchmark is available online."
  },
  {
    "arxiv_id": "2502.19008",
    "title": "Binary Neural Networks for Large Language Model: A Survey",
    "url": "http://arxiv.org/abs/2502.19008v1",
    "abstract": "Large language models (LLMs) have wide applications in the field of natural\nlanguage processing(NLP), such as GPT-4 and Llama. However, with the\nexponential growth of model parameter sizes, LLMs bring significant resource\noverheads. Low-bit quantization, as a key technique, reduces memory usage and\ncomputational demands by decreasing the bit-width of model parameters,\nactivations, and gradients. Previous quantization methods for LLMs have largely\nemployed Post-Training Quantization (PTQ) and Quantization-Aware Training\n(QAT). PTQ does not require any retraining of the original model, while QAT\ninvolves optimizing precision during training to achieve the best quantization\nparameters. The BitNet team proposed a radically different approach, where\nquantization is performed from the start of model training, utilizing\nlow-precision binary weights during the training process. This approach has led\nto the emergence of many binary quantization techniques for large language\nmodels. This paper provides a comprehensive review of these binary quantization\ntechniques. Specifically, we will introduce binary quantization techniques in\ndeep neural networks and further explore their application to LLMs, reviewing\ntheir various contributions, implementations, and applications."
  },
  {
    "arxiv_id": "2502.20350",
    "title": "KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language Model",
    "url": "http://arxiv.org/abs/2502.20350v1",
    "abstract": "Drug discovery is a critical task in biomedical natural language processing\n(NLP), yet explainable drug discovery remains underexplored. Meanwhile, large\nlanguage models (LLMs) have shown remarkable abilities in natural language\nunderstanding and generation. Leveraging LLMs for explainable drug discovery\nhas the potential to improve downstream tasks and real-world applications. In\nthis study, we utilize open-source drug knowledge graphs, clinical trial data,\nand PubMed publications to construct a comprehensive dataset for the\nexplainable drug discovery task, named \\textbf{expRxRec}. Furthermore, we\nintroduce \\textbf{KEDRec-LM}, an instruction-tuned LLM which distills knowledge\nfrom rich medical knowledge corpus for drug recommendation and rationale\ngeneration. To encourage further research in this area, we will publicly\nrelease\\footnote{A copy is attached with this submission} both the dataset and\nKEDRec-LM."
  },
  {
    "arxiv_id": "2502.19726",
    "title": "Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training",
    "url": "http://arxiv.org/abs/2502.19726v1",
    "abstract": "Large language models (LLMs) have become the backbone of modern natural\nlanguage processing but pose privacy concerns about leaking sensitive training\ndata. Membership inference attacks (MIAs), which aim to infer whether a sample\nis included in a model's training dataset, can serve as a foundation for\nbroader privacy threats. Existing defenses designed for traditional\nclassification models do not account for the sequential nature of text data. As\na result, they either require significant computational resources or fail to\neffectively mitigate privacy risks in LLMs. In this work, we propose a\nlightweight yet effective empirical privacy defense for protecting training\ndata of language modeling by leveraging the token-specific characteristics. By\nanalyzing token dynamics during training, we propose a token selection strategy\nthat categorizes tokens into hard tokens for learning and memorized tokens for\nunlearning. Subsequently, our training-phase defense optimizes a novel\ndual-purpose token-level loss to achieve a Pareto-optimal balance between\nutility and privacy. Extensive experiments demonstrate that our approach not\nonly provides strong protection against MIAs but also improves language\nmodeling performance by around 10\\% across various LLM architectures and\ndatasets compared to the baselines."
  },
  {
    "arxiv_id": "2502.19574",
    "title": "Leveraging Retrieval-Augmented Generation and Large Language Models to Predict SERCA-Binding Protein Fragments from Cardiac Proteomics Data",
    "url": "http://arxiv.org/abs/2502.19574v1",
    "abstract": "Large language models (LLMs) have shown promise in various natural language\nprocessing tasks, including their application to proteomics data to classify\nprotein fragments. In this study, we curated a limited mass spectrometry\ndataset with 1000s of protein fragments, consisting of proteins that appear to\nbe attached to the endoplasmic reticulum in cardiac cells, of which a fraction\nwas cloned and characterized for their impact on SERCA, an ER calcium pump.\nWith this limited dataset, we sought to determine whether LLMs could correctly\npredict whether a new protein fragment could bind SERCA, based only on its\nsequence and a few biophysical characteristics, such as hydrophobicity,\ndetermined from that sequence. To do so, we generated random sequences based on\ncloned fragments, embedded the fragments into a retrieval augmented generation\n(RAG) database to group them by similarity, then fine-tuned large language\nmodel (LLM) prompts to predict whether a novel sequence could bind SERCA. We\nbenchmarked this approach using multiple open-source LLMs, namely the\nMeta/llama series, and embedding functions commonly available on the\nHuggingface repository. We then assessed the generalizability of this approach\nin classifying novel protein fragments from mass spectrometry that were not\ninitially cloned for functional characterization. By further tuning the prompt\nto account for motifs, such as ER retention sequences, we improved the\nclassification accuracy by and identified several proteins predicted to\nlocalize to the endoplasmic reticulum and bind SERCA, including Ribosomal\nProtein L2 and selenoprotein S. Although our results were based on proteomics\ndata from cardiac cells, our approach demonstrates the potential of LLMs in\nidentifying novel protein interactions and functions with very limited\nproteomic data."
  },
  {
    "arxiv_id": "2502.21321",
    "title": "LLM Post-Training: A Deep Dive into Reasoning Large Language Models",
    "url": "http://arxiv.org/abs/2502.21321v1",
    "abstract": "Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training."
  },
  {
    "arxiv_id": "2502.21112",
    "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
    "url": "http://arxiv.org/abs/2502.21112v1",
    "abstract": "The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques."
  },
  {
    "arxiv_id": "2502.20864",
    "title": "Do Language Models Understand Honorific Systems in Javanese?",
    "url": "http://arxiv.org/abs/2502.20864v1",
    "abstract": "The Javanese language features a complex system of honorifics that vary\naccording to the social status of the speaker, listener, and referent. Despite\nits cultural and linguistic significance, there has been limited progress in\ndeveloping a comprehensive corpus to capture these variations for natural\nlanguage processing (NLP) tasks. In this paper, we present Unggah-Ungguh, a\ncarefully curated dataset designed to encapsulate the nuances of Unggah-Ungguh\nBasa, the Javanese speech etiquette framework that dictates the choice of words\nand phrases based on social hierarchy and context. Using Unggah-Ungguh, we\nassess the ability of language models (LMs) to process various levels of\nJavanese honorifics through classification and machine translation tasks. To\nfurther evaluate cross-lingual LMs, we conduct machine translation experiments\nbetween Javanese (at specific honorific levels) and Indonesian. Additionally,\nwe explore whether LMs can generate contextually appropriate Javanese\nhonorifics in conversation tasks, where the honorific usage should align with\nthe social role and contextual cues. Our findings indicate that current LMs\nstruggle with most honorific levels, exhibitinga bias toward certain honorific\ntiers."
  },
  {
    "arxiv_id": "2502.20744",
    "title": "Comparative study of the ansätze in quantum language models",
    "url": "http://arxiv.org/abs/2502.20744v1",
    "abstract": "Quantum language models are the alternative to classical language models,\nwhich borrow concepts and methods from quantum machine learning and\ncomputational linguistics. While several quantum natural language processing\n(QNLP) methods and frameworks exist for text classification and generation,\nthere is a lack of systematic study to compare the performance across various\nans\\\"atze, in terms of their hyperparameters and classical and quantum methods\nto implement them. Here, we evaluate the performance of quantum natural\nlanguage processing models based on these ans\\\"atze at different levels in text\nclassification tasks. We perform a comparative study and optimize the QNLP\nmodels by fine-tuning several critical hyperparameters. Our results demonstrate\nhow the balance between simplification and expressivity affects model\nperformance. This study provides extensive data to improve our understanding of\nQNLP models and opens the possibility of developing better QNLP algorithms."
  },
  {
    "arxiv_id": "2502.20723",
    "title": "Variational Transformer Ansatz for the Density Operator of Steady States in Dissipative Quantum Many-Body Systems",
    "url": "http://arxiv.org/abs/2502.20723v1",
    "abstract": "The transformer architecture, known for capturing long-range dependencies and\nintricate patterns, has extended beyond natural language processing. Recently,\nit has attracted significant attention in quantum information and condensed\nmatter physics. In this work, we propose the transformer density operator\nansatz for determining the steady states of dissipative quantum many-body\nsystems. By vectorizing the density operator as a many-body state in a doubled\nHilbert space, the transformer encodes the amplitude and phase of the state's\ncoefficients, with its parameters serving as variational variables. Our design\npreserves translation invariance while leveraging attention mechanisms to\ncapture diverse long-range correlations. We demonstrate the effectiveness of\nour approach by numerically calculating the steady states of dissipative Ising\nand Heisenberg spin chain models, showing that our method achieves excellent\naccuracy in predicting steady states."
  },
  {
    "arxiv_id": "2502.20647",
    "title": "Consistency Evaluation of News Article Summaries Generated by Large (and Small) Language Models",
    "url": "http://arxiv.org/abs/2502.20647v1",
    "abstract": "Text summarizing is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation. Large\nLanguage Models (LLMs) have shown remarkable promise in generating fluent\nabstractive summaries but they can produce hallucinated details not grounded in\nthe source text. Regardless of the method of generating a summary, high quality\nautomated evaluations remain an open area of investigation. This paper embarks\non an exploration of text summarization with a diverse set of techniques,\nincluding TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The\ngenerated summaries are evaluated using traditional metrics such as the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and\nBidirectional Encoder Representations from Transformers (BERT) Score, as well\nas LLM-powered evaluation methods that directly assess a generated summary's\nconsistency with the source text. We introduce a meta evaluation score which\ndirectly assesses the performance of the LLM evaluation system (prompt +\nmodel). We find that that all summarization models produce consistent summaries\nwhen tested on the XL-Sum dataset, exceeding the consistency of the reference\nsummaries."
  },
  {
    "arxiv_id": "2503.02879",
    "title": "Wikipedia in the Era of LLMs: Evolution and Risks",
    "url": "http://arxiv.org/abs/2503.02879v1",
    "abstract": "In this paper, we present a thorough analysis of the impact of Large Language\nModels (LLMs) on Wikipedia, examining the evolution of Wikipedia through\nexisting data and using simulations to explore potential risks. We begin by\nanalyzing page views and article content to study Wikipedia's recent changes\nand assess the impact of LLMs. Subsequently, we evaluate how LLMs affect\nvarious Natural Language Processing (NLP) tasks related to Wikipedia, including\nmachine translation and retrieval-augmented generation (RAG). Our findings and\nsimulation results reveal that Wikipedia articles have been influenced by LLMs,\nwith an impact of approximately 1%-2% in certain categories. If the machine\ntranslation benchmark based on Wikipedia is influenced by LLMs, the scores of\nthe models may become inflated, and the comparative results among models might\nshift as well. Moreover, the effectiveness of RAG might decrease if the\nknowledge base becomes polluted by LLM-generated content. While LLMs have not\nyet fully changed Wikipedia's language and knowledge structures, we believe\nthat our empirical findings signal the need for careful consideration of\npotential future risks."
  },
  {
    "arxiv_id": "2503.02656",
    "title": "Adapting Decoder-Based Language Models for Diverse Encoder Downstream Tasks",
    "url": "http://arxiv.org/abs/2503.02656v1",
    "abstract": "Decoder-based transformers, while revolutionizing language modeling and\nscaling to immense sizes, have not completely overtaken encoder-heavy\narchitectures in natural language processing. Specifically, encoder-only models\nremain dominant in tasks like classification, regression, and ranking. This is\nprimarily due to the inherent structure of decoder-based models, which limits\ntheir direct applicability to these tasks. In this paper, we introduce Gemma\nEncoder, adapting the powerful Gemma decoder model to an encoder architecture,\nthereby unlocking its potential for a wider range of non-generative\napplications. To optimize the adaptation from decoder to encoder, we\nsystematically analyze various pooling strategies, attention mechanisms, and\nhyperparameters (e.g., dropout rate). Furthermore, we benchmark Gemma Encoder\nagainst established approaches on the GLUE benchmarks, and MS MARCO ranking\nbenchmark, demonstrating its effectiveness and versatility."
  },
  {
    "arxiv_id": "2503.02650",
    "title": "The Effectiveness of Large Language Models in Transforming Unstructured Text to Standardized Formats",
    "url": "http://arxiv.org/abs/2503.02650v1",
    "abstract": "The exponential growth of unstructured text data presents a fundamental\nchallenge in modern data management and information retrieval. While Large\nLanguage Models (LLMs) have shown remarkable capabilities in natural language\nprocessing, their potential to transform unstructured text into standardized,\nstructured formats remains largely unexplored - a capability that could\nrevolutionize data processing workflows across industries. This study breaks\nnew ground by systematically evaluating LLMs' ability to convert unstructured\nrecipe text into the structured Cooklang format. Through comprehensive testing\nof four models (GPT-4o, GPT-4o-mini, Llama3.1:70b, and Llama3.1:8b), an\ninnovative evaluation approach is introduced that combines traditional metrics\n(WER, ROUGE-L, TER) with specialized metrics for semantic element\nidentification. Our experiments reveal that GPT-4o with few-shot prompting\nachieves breakthrough performance (ROUGE-L: 0.9722, WER: 0.0730), demonstrating\nfor the first time that LLMs can reliably transform domain-specific\nunstructured text into structured formats without extensive training. Although\nmodel performance generally scales with size, we uncover surprising potential\nin smaller models like Llama3.1:8b for optimization through targeted\nfine-tuning. These findings open new possibilities for automated structured\ndata generation across various domains, from medical records to technical\ndocumentation, potentially transforming the way organizations process and\nutilize unstructured information."
  },
  {
    "arxiv_id": "2503.02497",
    "title": "PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset",
    "url": "http://arxiv.org/abs/2503.02497v1",
    "abstract": "Large Language Models (LLMs) offer remarkable capabilities in code\ngeneration, natural language processing, and domain-specific reasoning.\nHowever, their application in quantum software development remains\nunderexplored, particularly for PennyLane-a leading framework for hybrid\nquantum-classical computing. To address this gap, we introduce a novel,\nhigh-quality dataset comprising 3,347 PennyLane-specific quantum code samples\nand contextual descriptions, specifically curated to support LLM training and\nfine-tuning for quantum code assistance. Our contributions are threefold: (1)\nthe automatic construction and open-source release of a comprehensive PennyLane\ndataset derived from textbooks, official documentation, and open-source\nrepositories; (2) a structured methodology for data curation, annotation, and\nformatting to enhance LLM usability and relevance; and (3) a rigorous\nevaluation of code generation capabilities using both baseline\nRetrieval-Augmented Generation (RAG) and a GraphRAG-enhanced pipeline. Using\nthe PennyLang framework, we demonstrate that GraphRAG, when applied to a GPT-4o\nMini model, substantially outperforms standard prompting and baseline RAG.\nAccuracy improves from 20.5% (without RAG) to 58.2% with GraphRAG, showcasing\nits effectiveness in reducing hallucinations and improving code correctness in\nquantum programming tasks. Compared to prior efforts focused largely on Qiskit,\nour work expands LLM-based assistance to the PennyLane ecosystem, contributing\npractical tools and reproducible methodologies for advancing AI-assisted\nquantum software development."
  },
  {
    "arxiv_id": "2503.03702",
    "title": "Developing and Utilizing a Large-Scale Cantonese Dataset for Multi-Tasking in Large Language Models",
    "url": "http://arxiv.org/abs/2503.03702v1",
    "abstract": "High-quality data resources play a crucial role in learning large language\nmodels (LLMs), particularly for low-resource languages like Cantonese. Despite\nhaving more than 85 million native speakers, Cantonese is still considered a\nlow-resource language in the field of natural language processing (NLP) due to\nfactors such as the dominance of Mandarin, lack of cohesion within the\nCantonese-speaking community, diversity in character encoding and input\nmethods, and the tendency of overseas Cantonese speakers to prefer using\nEnglish. In addition, rich colloquial vocabulary of Cantonese, English\nloanwords, and code-switching characteristics add to the complexity of corpus\ncollection and processing. To address these challenges, we collect Cantonese\ntexts from a variety of sources, including open source corpora, Hong\nKong-specific forums, Wikipedia, and Common Crawl data. We conduct rigorous\ndata processing through language filtering, quality filtering, content\nfiltering, and de-duplication steps, successfully constructing a high-quality\nCantonese corpus of over 2 billion tokens for training large language models.\nWe further refined the model through supervised fine-tuning (SFT) on curated\nCantonese tasks, enhancing its ability to handle specific applications. Upon\ncompletion of the training, the model achieves state-of-the-art (SOTA)\nperformance on four Cantonese benchmarks. After training on our dataset, the\nmodel also exhibits improved performance on other mainstream language tasks."
  },
  {
    "arxiv_id": "2503.03652",
    "title": "Token-Level Privacy in Large Language Models",
    "url": "http://arxiv.org/abs/2503.03652v1",
    "abstract": "The use of language models as remote services requires transmitting private\ninformation to external providers, raising significant privacy concerns. This\nprocess not only risks exposing sensitive data to untrusted service providers\nbut also leaves it vulnerable to interception by eavesdroppers. Existing\nprivacy-preserving methods for natural language processing (NLP) interactions\nprimarily rely on semantic similarity, overlooking the role of contextual\ninformation. In this work, we introduce dchi-stencil, a novel token-level\nprivacy-preserving mechanism that integrates contextual and semantic\ninformation while ensuring strong privacy guarantees under the dchi\ndifferential privacy framework, achieving 2epsilon-dchi-privacy. By\nincorporating both semantic and contextual nuances, dchi-stencil achieves a\nrobust balance between privacy and utility. We evaluate dchi-stencil using\nstate-of-the-art language models and diverse datasets, achieving comparable and\neven better trade-off between utility and privacy compared to existing methods.\nThis work highlights the potential of dchi-stencil to set a new standard for\nprivacy-preserving NLP in modern, high-risk applications."
  },
  {
    "arxiv_id": "2503.03612",
    "title": "Large language models in finance: estimating financial sentiment for stock prediction",
    "url": "http://arxiv.org/abs/2503.03612v1",
    "abstract": "Financial sentiment has become a crucial yet complex concept in finance,\nincreasingly used in market forecasting and investment strategies. Despite its\ngrowing importance, there remains a need to define and understand what\nfinancial sentiment truly represents and how it can be effectively measured. We\nexplore the nature of financial sentiment and investigate how large language\nmodels (LLMs) contribute to its estimation. We trace the evolution of sentiment\nmeasurement in finance, from market-based and lexicon-based methods to advanced\nnatural language processing techniques. The emergence of LLMs has significantly\nenhanced sentiment analysis, providing deeper contextual understanding and\ngreater accuracy in extracting sentiment from financial text. We examine how\nBERT-based models, such as RoBERTa and FinBERT, are optimized for structured\nsentiment classification, while GPT-based models, including GPT-4, OPT, and\nLLaMA, excel in financial text generation and real-time sentiment\ninterpretation. A comparative analysis of bidirectional and autoregressive\ntransformer architectures highlights their respective roles in investor\nsentiment analysis, algorithmic trading, and financial decision-making. By\nexploring what financial sentiment is and how it is estimated within LLMs, we\nprovide insights into the growing role of AI-driven sentiment analysis in\nfinance."
  },
  {
    "arxiv_id": "2503.03261",
    "title": "Can Frontier LLMs Replace Annotators in Biomedical Text Mining? Analyzing Challenges and Exploring Solutions",
    "url": "http://arxiv.org/abs/2503.03261v1",
    "abstract": "Large language models (LLMs) can perform various natural language processing\n(NLP) tasks through in-context learning without relying on supervised data.\nHowever, multiple previous studies have reported suboptimal performance of LLMs\nin biological text mining. By analyzing failure patterns in these evaluations,\nwe identified three primary challenges for LLMs in biomedical corpora: (1) LLMs\nfail to learn implicit dataset-specific nuances from supervised data, (2) The\ncommon formatting requirements of discriminative tasks limit the reasoning\ncapabilities of LLMs particularly for LLMs that lack test-time compute, and (3)\nLLMs struggle to adhere to annotation guidelines and match exact schemas, which\nhinders their ability to understand detailed annotation requirements which is\nessential in biomedical annotation workflow. To address these challenges, we\nexperimented with prompt engineering techniques targeted to the above issues,\nand developed a pipeline that dynamically extracts instructions from annotation\nguidelines. Our findings show that frontier LLMs can approach or surpass the\nperformance of state-of-the-art (SOTA) BERT-based models with minimal reliance\non manually annotated data and without fine-tuning. Furthermore, we performed\nmodel distillation on a closed-source LLM, demonstrating that a BERT model\ntrained exclusively on synthetic data annotated by LLMs can also achieve a\npractical performance. Based on these results, we explored the feasibility of\npartially replacing manual annotation with LLMs in production scenarios for\nbiomedical text mining."
  },
  {
    "arxiv_id": "2503.02993",
    "title": "Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders Vs. Classic Encoders",
    "url": "http://arxiv.org/abs/2503.02993v1",
    "abstract": "Bangla, a language spoken by over 300 million native speakers and ranked as\nthe sixth most spoken language worldwide, presents unique challenges in natural\nlanguage processing (NLP) due to its complex morphological characteristics and\nlimited resources. While recent Large Decoder Based models (LLMs), such as GPT,\nLLaMA, and DeepSeek, have demonstrated excellent performance across many NLP\ntasks, their effectiveness in Bangla remains largely unexplored. In this paper,\nwe establish the first benchmark comparing decoder-based LLMs with classic\nencoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)\ntask in Bangla. Our evaluation of 32 state-of-the-art models reveals that,\nexisting so-called powerful encoders and decoders still struggle to achieve\nhigh accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more\nresearch and resources for Bangla NLP."
  },
  {
    "arxiv_id": "2503.04554",
    "title": "Compositional Translation: A Novel LLM-based Approach for Low-resource Machine Translation",
    "url": "http://arxiv.org/abs/2503.04554v1",
    "abstract": "The ability of generative large language models (LLMs) to perform in-context\nlearning has given rise to a large body of research into how best to prompt\nmodels for various natural language processing tasks. Machine Translation (MT)\nhas been shown to benefit from in-context examples, in particular when they are\nsemantically similar to the sentence to translate. In this paper, we propose a\nnew LLM-based translation paradigm, compositional translation, to replace naive\nfew-shot MT with similarity-based demonstrations. An LLM is used to decompose a\nsentence into simpler phrases, and then to translate each phrase with the help\nof retrieved demonstrations. Finally, the LLM is prompted to translate the\ninitial sentence with the help of the self-generated phrase-translation pairs.\nOur intuition is that this approach should improve translation because these\nshorter phrases should be intrinsically easier to translate and easier to match\nwith relevant examples. This is especially beneficial in low-resource\nscenarios, and more generally whenever the selection pool is small or out of\ndomain. We show that compositional translation boosts LLM translation\nperformance on a wide range of popular MT benchmarks, including FLORES 200,\nNTREX 128 and TICO-19. Code and outputs are available at\nhttps://github.com/ArmelRandy/compositional-translation"
  },
  {
    "arxiv_id": "2503.04405",
    "title": "Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model",
    "url": "http://arxiv.org/abs/2503.04405v1",
    "abstract": "Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical\ntasks for Natural Language Processing (NLP), yet their availability for\nlow-resource languages (LRLs) like Bodo remains limited. This article presents\na comparative empirical study investigating the effectiveness of Google's\nGemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer\nof POS and NER tagging to Bodo. We explore two distinct methodologies: (1)\ndirect translation of English sentences to Bodo followed by tag transfer, and\n(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both\nmethods leverage the machine translation and cross-lingual understanding\ncapabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and\nNER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the\ncapabilities and limitations of each approach, demonstrating that while both\nmethods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits\nsuperior performance, particularly for NER. We provide a detailed analysis of\nthe results, highlighting the impact of translation quality, grammatical\ndivergences, and the inherent challenges of zero-shot cross-lingual transfer.\nThe article concludes by discussing future research directions, emphasizing the\nneed for hybrid approaches, few-shot fine-tuning, and the development of\ndedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for\nthis low-resource language."
  },
  {
    "arxiv_id": "2503.05613",
    "title": "A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models",
    "url": "http://arxiv.org/abs/2503.05613v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models."
  },
  {
    "arxiv_id": "2503.05290",
    "title": "MatrixFlow: System-Accelerator co-design for high-performance transformer applications",
    "url": "http://arxiv.org/abs/2503.05290v1",
    "abstract": "Transformers are central to advances in artificial intelligence (AI),\nexcelling in fields ranging from computer vision to natural language\nprocessing. Despite their success, their large parameter count and\ncomputational demands challenge efficient acceleration. To address these\nlimitations, this paper proposes MatrixFlow, a novel co-designed\nsystem-accelerator architecture based on a loosely coupled systolic array\nincluding a new software mapping approach for efficient transformer code\nexecution. MatrixFlow is co-optimized via a novel dataflow-based matrix\nmultiplication technique that reduces memory overhead. These innovations\nsignificantly improve data throughput, which is critical for handling the\nextensive computations required by transformers. We validate our approach\nthrough full system simulation using gem5 across various BERT and ViT\nTransformer models featuring different data types, demonstrating significant\napplication-wide speed-ups. Our method achieves up to a 22x improvement\ncompared to a many-core CPU system, and outperforms the closest\nstate-of-the-art loosely-coupled and tightly-coupled accelerators by over 5x\nand 8x, respectively."
  },
  {
    "arxiv_id": "2503.07450",
    "title": "From Idea to Implementation: Evaluating the Influence of Large Language Models in Software Development -- An Opinion Paper",
    "url": "http://arxiv.org/abs/2503.07450v1",
    "abstract": "The introduction of transformer architecture was a turning point in Natural\nLanguage Processing (NLP). Models based on the transformer architecture such as\nBidirectional Encoder Representations from Transformers (BERT) and Generative\nPre-Trained Transformer (GPT) have gained widespread popularity in various\napplications such as software development and education. The availability of\nLarge Language Models (LLMs) such as ChatGPT and Bard to the general public has\nshowcased the tremendous potential of these models and encouraged their\nintegration into various domains such as software development for tasks such as\ncode generation, debugging, and documentation generation. In this study,\nopinions from 11 experts regarding their experience with LLMs for software\ndevelopment have been gathered and analysed to draw insights that can guide\nsuccessful and responsible integration. The overall opinion of the experts is\npositive, with the experts identifying advantages such as increase in\nproductivity and reduced coding time. Potential concerns and challenges such as\nrisk of over-dependence and ethical considerations have also been highlighted."
  },
  {
    "arxiv_id": "2503.07384",
    "title": "Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs",
    "url": "http://arxiv.org/abs/2503.07384v1",
    "abstract": "This work adapts and studies the gradient-based Membership Inference Test\n(gMINT) to the classification of text based on LLMs. MINT is a general approach\nintended to determine if given data was used for training machine learning\nmodels, and this work focuses on its application to the domain of Natural\nLanguage Processing. Using gradient-based analysis, the MINT model identifies\nwhether particular data samples were included during the language model\ntraining phase, addressing growing concerns about data privacy in machine\nlearning. The method was evaluated in seven Transformer-based models and six\ndatasets comprising over 2.5 million sentences, focusing on text classification\ntasks. Experimental results demonstrate MINTs robustness, achieving AUC scores\nbetween 85% and 99%, depending on data size and model architecture. These\nfindings highlight MINTs potential as a scalable and reliable tool for auditing\nmachine learning models, ensuring transparency, safeguarding sensitive data,\nand fostering ethical compliance in the deployment of AI/NLP technologies."
  },
  {
    "arxiv_id": "2503.07202",
    "title": "A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding",
    "url": "http://arxiv.org/abs/2503.07202v1",
    "abstract": "Zero-shot learning (ZL) is crucial for tasks involving unseen categories,\nsuch as natural language processing, image classification, and cross-lingual\ntransfer.Current applications often fail to accurately infer and handle new\nrelations orentities involving unseen categories, severely limiting their\nscalability and prac-ticality in open-domain scenarios. ZL learning faces the\nchallenge of effectivelytransferring semantic information of unseen categories\nin multi-modal knowledgegraph (MMKG) embedding representation learning. In this\npaper, we proposeZSLLM, a framework for zero-shot embedding learning of MMKGs\nusing largelanguage models (LLMs). We leverage textual modality information of\nunseencategories as prompts to fully utilize the reasoning capabilities of\nLLMs, enablingsemantic information transfer across different modalities for\nunseen categories.Through model-based learning, the embedding representation of\nunseen cate-gories in MMKG is enhanced. Extensive experiments conducted on\nmultiplereal-world datasets demonstrate the superiority of our approach\ncompared tostate-of-the-art methods."
  },
  {
    "arxiv_id": "2503.07076",
    "title": "NFIG: Autoregressive Image Generation with Next-Frequency Prediction",
    "url": "http://arxiv.org/abs/2503.07076v1",
    "abstract": "Autoregressive models have achieved promising results in natural language\nprocessing. However, for image generation tasks, they encounter substantial\nchallenges in effectively capturing long-range dependencies, managing\ncomputational costs, and most crucially, defining meaningful autoregressive\nsequences that reflect natural image hierarchies. To address these issues, we\npresent \\textbf{N}ext-\\textbf{F}requency \\textbf{I}mage \\textbf{G}eneration\n(\\textbf{NFIG}), a novel framework that decomposes the image generation process\ninto multiple frequency-guided stages. Our approach first generates\nlow-frequency components to establish global structure with fewer tokens, then\nprogressively adds higher-frequency details, following the natural spectral\nhierarchy of images. This principled autoregressive sequence not only improves\nthe quality of generated images by better capturing true causal relationships\nbetween image components, but also significantly reduces computational overhead\nduring inference. Extensive experiments demonstrate that NFIG achieves\nstate-of-the-art performance with fewer steps, offering a more efficient\nsolution for image generation, with 1.25$\\times$ speedup compared to VAR-d20\nwhile achieving better performance (FID: 2.81) on the ImageNet-256 benchmark.\nWe hope that our insight of incorporating frequency-domain knowledge to guide\nautoregressive sequence design will shed light on future research. We will make\nour code publicly available upon acceptance of the paper."
  },
  {
    "arxiv_id": "2503.06734",
    "title": "Gender Encoding Patterns in Pretrained Language Model Representations",
    "url": "http://arxiv.org/abs/2503.06734v1",
    "abstract": "Gender bias in pretrained language models (PLMs) poses significant social and\nethical challenges. Despite growing awareness, there is a lack of comprehensive\ninvestigation into how different models internally represent and propagate such\nbiases. This study adopts an information-theoretic approach to analyze how\ngender biases are encoded within various encoder-based architectures. We focus\non three key aspects: identifying how models encode gender information and\nbiases, examining the impact of bias mitigation techniques and fine-tuning on\nthe encoded biases and their effectiveness, and exploring how model design\ndifferences influence the encoding of biases. Through rigorous and systematic\ninvestigation, our findings reveal a consistent pattern of gender encoding\nacross diverse models. Surprisingly, debiasing techniques often exhibit limited\nefficacy, sometimes inadvertently increasing the encoded bias in internal\nrepresentations while reducing bias in model output distributions. This\nhighlights a disconnect between mitigating bias in output distributions and\naddressing its internal representations. This work provides valuable guidance\nfor advancing bias mitigation strategies and fostering the development of more\nequitable language models."
  },
  {
    "arxiv_id": "2503.06594",
    "title": "Beyond Decoder-only: Large Language Models Can be Good Encoders for Machine Translation",
    "url": "http://arxiv.org/abs/2503.06594v1",
    "abstract": "The field of neural machine translation (NMT) has changed with the advent of\nlarge language models (LLMs). Much of the recent emphasis in natural language\nprocessing (NLP) has been on modeling machine translation and many other\nproblems using a single pre-trained Transformer decoder, while encoder-decoder\narchitectures, which were the standard in earlier NMT models, have received\nrelatively less attention. In this paper, we explore translation models that\nare universal, efficient, and easy to optimize, by marrying the world of LLMs\nwith the world of NMT. We apply LLMs to NMT encoding and leave the NMT decoder\nunchanged. We also develop methods for adapting LLMs to work better with the\nNMT decoder. Furthermore, we construct a new dataset involving multiple tasks\nto assess how well the machine translation system generalizes across various\ntasks. Evaluations on the WMT and our datasets show that results using our\nmethod match or surpass a range of baselines in terms of translation quality,\nbut achieve $2.4 \\sim 6.5 \\times$ inference speedups and a $75\\%$ reduction in\nthe memory footprint of the KV cache. It also demonstrates strong\ngeneralization across a variety of translation-related tasks."
  },
  {
    "arxiv_id": "2503.07956",
    "title": "EFPC: Towards Efficient and Flexible Prompt Compression",
    "url": "http://arxiv.org/abs/2503.07956v1",
    "abstract": "The emergence of large language models (LLMs) like GPT-4 has revolutionized\nnatural language processing (NLP), enabling diverse, complex tasks. However,\nextensive token counts lead to high computational and financial burdens. To\naddress this, we propose Efficient and Flexible Prompt Compression (EFPC), a\nnovel method unifying task-aware and task-agnostic compression for a favorable\naccuracy-efficiency trade-off. EFPC uses GPT-4 to generate compressed prompts\nand integrates them with original prompts for training. During training and\ninference, we selectively prepend user instructions and compress prompts based\non predicted probabilities. EFPC is highly data-efficient, achieving\nsignificant performance with minimal data. Compared to the state-of-the-art\nmethod LLMLingua-2, EFPC achieves a 4.8% relative improvement in F1-score with\n1% additional data at a 4x compression rate, and an 11.4% gain with 10%\nadditional data on the LongBench single-doc QA benchmark. EFPC's unified\nframework supports broad applicability and enhances performance across various\nmodels, tasks, and domains, offering a practical advancement in NLP."
  },
  {
    "arxiv_id": "2503.07605",
    "title": "SEAP: Training-free Sparse Expert Activation Pruning Unlock the Brainpower of Large Language Models",
    "url": "http://arxiv.org/abs/2503.07605v1",
    "abstract": "Large Language Models have achieved remarkable success across various natural\nlanguage processing tasks, yet their high computational cost during inference\nremains a major bottleneck. This paper introduces Sparse Expert Activation\nPruning (SEAP), a training-free pruning method that selectively retains\ntask-relevant parameters to reduce inference overhead. Inspired by the\nclustering patterns of hidden states and activations in LLMs, SEAP identifies\ntask-specific expert activation patterns and prunes the model while preserving\ntask performance and enhancing computational efficiency. Experimental results\ndemonstrate that SEAP significantly reduces computational overhead while\nmaintaining competitive accuracy. Notably, at 50% pruning, SEAP surpasses both\nWandA and FLAP by over 20%, and at 20% pruning, it incurs only a 2.2%\nperformance drop compared to the dense model. These findings highlight SEAP's\nscalability and effectiveness, making it a promising approach for optimizing\nlarge-scale LLMs."
  },
  {
    "arxiv_id": "2503.09114",
    "title": "Sometimes Painful but Certainly Promising: Feasibility and Trade-offs of Language Model Inference at the Edge",
    "url": "http://arxiv.org/abs/2503.09114v1",
    "abstract": "The rapid rise of Language Models (LMs) has expanded the capabilities of\nnatural language processing, powering applications from text generation to\ncomplex decision-making. While state-of-the-art LMs often boast hundreds of\nbillions of parameters and are primarily deployed in data centers, recent\ntrends show a growing focus on compact models-typically under 10 billion\nparameters-enabled by techniques such as quantization and other model\ncompression techniques. This shift paves the way for LMs on edge devices,\noffering potential benefits such as enhanced privacy, reduced latency, and\nimproved data sovereignty. However, the inherent complexity of even these\nsmaller models, combined with the limited computing resources of edge hardware,\nraises critical questions about the practical trade-offs in executing LM\ninference outside the cloud. To address these challenges, we present a\ncomprehensive evaluation of generative LM inference on representative CPU-based\nand GPU-accelerated edge devices. Our study measures key performance\nindicators-including memory usage, inference speed, and energy\nconsumption-across various device configurations. Additionally, we examine\nthroughput-energy trade-offs, cost considerations, and usability, alongside an\nassessment of qualitative model performance. While quantization helps mitigate\nmemory overhead, it does not fully eliminate resource bottlenecks, especially\nfor larger models. Our findings quantify the memory and energy constraints that\nmust be considered for practical real-world deployments, offering concrete\ninsights into the trade-offs between model size, inference performance, and\nefficiency. The exploration of LMs at the edge is still in its early stages. We\nhope this study provides a foundation for future research, guiding the\nrefinement of models, the enhancement of inference efficiency, and the\nadvancement of edge-centric AI systems."
  },
  {
    "arxiv_id": "2503.10470",
    "title": "Statistical Analysis of Sentence Structures through ASCII, Lexical Alignment and PCA",
    "url": "http://arxiv.org/abs/2503.10470v1",
    "abstract": "While utilizing syntactic tools such as parts-of-speech (POS) tagging has\nhelped us understand sentence structures and their distribution across diverse\ncorpora, it is quite complex and poses a challenge in natural language\nprocessing (NLP). This study focuses on understanding sentence structure\nbalance - usages of nouns, verbs, determiners, etc - harmoniously without\nrelying on such tools. It proposes a novel statistical method that uses\nAmerican Standard Code for Information Interchange (ASCII) codes to represent\ntext of 11 text corpora from various sources and their lexical category\nalignment after using their compressed versions through PCA, and analyzes the\nresults through histograms and normality tests such as Shapiro-Wilk and\nAnderson-Darling Tests. By focusing on ASCII codes, this approach simplifies\ntext processing, although not replacing any syntactic tools but complementing\nthem by offering it as a resource-efficient tool for assessing text balance.\nThe story generated by Grok shows near normality indicating balanced sentence\nstructures in LLM outputs, whereas 4 out of the remaining 10 pass the normality\ntests. Further research could explore potential applications in text quality\nevaluation and style analysis with syntactic integration for more broader\ntasks."
  },
  {
    "arxiv_id": "2503.10251",
    "title": "Numerical Error Analysis of Large Language Models",
    "url": "http://arxiv.org/abs/2503.10251v1",
    "abstract": "Large language models based on transformer architectures have become integral\nto state-of-the-art natural language processing applications. However, their\ntraining remains computationally expensive and exhibits instabilities, some of\nwhich are expected to be caused by finite-precision computations. We provide a\ntheoretical analysis of the impact of round-off errors within the forward pass\nof a transformer architecture which yields fundamental bounds for these\neffects. In addition, we conduct a series of numerical experiments which\ndemonstrate the practical relevance of our bounds. Our results yield concrete\nguidelines for choosing hyperparameters that mitigate round-off errors, leading\nto more robust and stable inference."
  },
  {
    "arxiv_id": "2503.09956",
    "title": "Exploring Mutual Empowerment Between Wireless Networks and RL-based LLMs: A Survey",
    "url": "http://arxiv.org/abs/2503.09956v1",
    "abstract": "Reinforcement learning (RL)-based large language models (LLMs), such as\nChatGPT, DeepSeek, and Grok-3, have gained significant attention for their\nexceptional capabilities in natural language processing and multimodal data\nunderstanding. Meanwhile, the rapid expansion of information services has\ndriven the growing need for intelligence, efficient, and adaptable wireless\nnetworks. Wireless networks require the empowerment of RL-based LLMs while\nthese models also benefit from wireless networks to broaden their application\nscenarios. Specifically, RL-based LLMs can enhance wireless communication\nsystems through intelligent resource allocation, adaptive network optimization,\nand real-time decision-making. Conversely, wireless networks provide a vital\ninfrastructure for the efficient training, deployment, and distributed\ninference of RL-based LLMs, especially in decentralized and edge computing\nenvironments. This mutual empowerment highlights the need for a deeper\nexploration of the interplay between these two domains. We first review recent\nadvancements in wireless communications, highlighting the associated challenges\nand potential solutions. We then discuss the progress of RL-based LLMs,\nfocusing on key technologies for LLM training, challenges, and potential\nsolutions. Subsequently, we explore the mutual empowerment between these two\nfields, highlighting key motivations, open challenges, and potential solutions.\nFinally, we provide insights into future directions, applications, and their\nsocietal impact to further explore this intersection, paving the way for\nnext-generation intelligent communication systems. Overall, this survey\nprovides a comprehensive overview of the relationship between RL-based LLMs and\nwireless networks, offering a vision where these domains empower each other to\ndrive innovations."
  },
  {
    "arxiv_id": "2503.09791",
    "title": "Minimal Time Series Transformer",
    "url": "http://arxiv.org/abs/2503.09791v1",
    "abstract": "Transformer is the state-of-the-art model for many natural language\nprocessing, computer vision, and audio analysis problems. Transformer\neffectively combines information from the past input and output samples in\nauto-regressive manner so that each sample becomes aware of all inputs and\noutputs. In sequence-to-sequence (Seq2Seq) modeling, the transformer processed\nsamples become effective in predicting the next output. Time series forecasting\nis a Seq2Seq problem. The original architecture is defined for discrete input\nand output sequence tokens, but to adopt it for time series, the model must be\nadapted for continuous data. This work introduces minimal adaptations to make\nthe original transformer architecture suitable for continuous value time series\ndata."
  },
  {
    "arxiv_id": "2503.11232",
    "title": "PrivacyScalpel: Enhancing LLM Privacy via Interpretable Feature Intervention with Sparse Autoencoders",
    "url": "http://arxiv.org/abs/2503.11232v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing but also pose significant privacy risks by\nmemorizing and leaking Personally Identifiable Information (PII). Existing\nmitigation strategies, such as differential privacy and neuron-level\ninterventions, often degrade model utility or fail to effectively prevent\nleakage. To address this challenge, we introduce PrivacyScalpel, a novel\nprivacy-preserving framework that leverages LLM interpretability techniques to\nidentify and mitigate PII leakage while maintaining performance. PrivacyScalpel\ncomprises three key steps: (1) Feature Probing, which identifies layers in the\nmodel that encode PII-rich representations, (2) Sparse Autoencoding, where a\nk-Sparse Autoencoder (k-SAE) disentangles and isolates privacy-sensitive\nfeatures,\n  and (3) Feature-Level Interventions, which employ targeted ablation and\nvector steering to suppress PII leakage.\n  Our empirical evaluation on Gemma2-2b and Llama2-7b, fine-tuned on the Enron\ndataset, shows that PrivacyScalpel significantly reduces email leakage from\n5.15\\% to as low as 0.0\\%, while maintaining over 99.4\\% of the original\nmodel's utility. Notably, our method outperforms neuron-level interventions in\nprivacy-utility trade-offs, demonstrating that acting on sparse, monosemantic\nfeatures is more effective than manipulating polysemantic neurons. Beyond\nimproving LLM privacy, our approach offers insights into the mechanisms\nunderlying PII memorization, contributing to the broader field of model\ninterpretability and secure AI deployment."
  },
  {
    "arxiv_id": "2503.11227",
    "title": "GKG-LLM: A Unified Framework for Generalized Knowledge Graph Construction",
    "url": "http://arxiv.org/abs/2503.11227v1",
    "abstract": "The construction of Generalized Knowledge Graph (GKG), including knowledge\ngraph, event knowledge graph and commonsense knowledge graph, is fundamental\nfor various natural language processing tasks. Current studies typically\nconstruct these types of graph separately, overlooking holistic insights and\npotential unification that could be beneficial in computing resources and usage\nperspectives. However, a key challenge in developing a unified framework for\nGKG is obstacles arising from task-specific differences. In this study, we\npropose a unified framework for constructing generalized knowledge graphs to\naddress this challenge. First, we collect data from 15 sub-tasks in 29 datasets\nacross the three types of graphs, categorizing them into in-sample,\ncounter-task, and out-of-distribution (OOD) data. Then, we propose a\nthree-stage curriculum learning fine-tuning framework, by iteratively injecting\nknowledge from the three types of graphs into the Large Language Models.\nExtensive experiments show that our proposed model improves the construction of\nall three graph types across in-domain, OOD and counter-task data."
  },
  {
    "arxiv_id": "2503.10957",
    "title": "Predicting Stock Movement with BERTweet and Transformers",
    "url": "http://arxiv.org/abs/2503.10957v1",
    "abstract": "Applying deep learning and computational intelligence to finance has been a\npopular area of applied research, both within academia and industry, and\ncontinues to attract active attention. The inherently high volatility and\nnon-stationary of the data pose substantial challenges to machine learning\nmodels, especially so for today's expressive and highly-parameterized deep\nlearning models. Recent work has combined natural language processing on data\nfrom social media to augment models based purely on historic price data to\nimprove performance has received particular attention. Previous work has\nachieved state-of-the-art performance on this task by combining techniques such\nas bidirectional GRUs, variational autoencoders, word and document embeddings,\nself-attention, graph attention, and adversarial training. In this paper, we\ndemonstrated the efficacy of BERTweet, a variant of BERT pre-trained\nspecifically on a Twitter corpus, and the transformer architecture by achieving\ncompetitive performance with the existing literature and setting a new baseline\nfor Matthews Correlation Coefficient on the Stocknet dataset without auxiliary\ndata sources."
  },
  {
    "arxiv_id": "2503.10927",
    "title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses",
    "url": "http://arxiv.org/abs/2503.10927v1",
    "abstract": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available."
  },
  {
    "arxiv_id": "2503.13299",
    "title": "A Survey on Transformer Context Extension: Approaches and Evaluation",
    "url": "http://arxiv.org/abs/2503.13299v1",
    "abstract": "Large language models (LLMs) based on Transformer have been widely applied in\nthe filed of natural language processing (NLP), demonstrating strong\nperformance, particularly in handling short text tasks. However, when it comes\nto long context scenarios, the performance of LLMs degrades due to some\nchallenges. To alleviate this phenomenon, there is a number of work proposed\nrecently. In this survey, we first list the challenges of applying pre-trained\nLLMs to process long contexts. Then systematically review the approaches\nrelated to long context and propose our taxonomy categorizing them into four\nmain types: positional encoding, context compression, retrieval augmented, and\nattention pattern. In addition to the approaches, we focus on the evaluation of\nlong context, organizing relevant data, tasks, and metrics based on existing\nlong context benchmarks. Finally, we summarize unresolved issues in the long\ncontext domain and put forward our views on future developments."
  },
  {
    "arxiv_id": "2503.12440",
    "title": "HKCanto-Eval: A Benchmark for Evaluating Cantonese Language Understanding and Cultural Comprehension in LLMs",
    "url": "http://arxiv.org/abs/2503.12440v1",
    "abstract": "The ability of language models to comprehend and interact in diverse\nlinguistic and cultural landscapes is crucial. The Cantonese language used in\nHong Kong presents unique challenges for natural language processing due to its\nrich cultural nuances and lack of dedicated evaluation datasets. The\nHKCanto-Eval benchmark addresses this gap by evaluating the performance of\nlarge language models (LLMs) on Cantonese language understanding tasks,\nextending to English and Written Chinese for cross-lingual evaluation.\nHKCanto-Eval integrates cultural and linguistic nuances intrinsic to Hong Kong,\nproviding a robust framework for assessing language models in realistic\nscenarios. Additionally, the benchmark includes questions designed to tap into\nthe underlying linguistic metaknowledge of the models. Our findings indicate\nthat while proprietary models generally outperform open-weight models,\nsignificant limitations remain in handling Cantonese-specific linguistic and\ncultural knowledge, highlighting the need for more targeted training data and\nevaluation methods. The code can be accessed at\nhttps://github.com/hon9kon9ize/hkeval2025"
  },
  {
    "arxiv_id": "2503.12100",
    "title": "Large Language Models in Legislative Content Analysis: A Dataset from the Polish Parliament",
    "url": "http://arxiv.org/abs/2503.12100v1",
    "abstract": "Large language models (LLMs) are among the best methods for processing\nnatural language, partly due to their versatility. At the same time,\ndomain-specific LLMs are more practical in real-life applications. This work\nintroduces a novel natural language dataset created by acquired data from\nofficial legislative authorities' websites. The study focuses on formulating\nthree natural language processing (NLP) tasks to evaluate the effectiveness of\nLLMs on legislative content analysis within the context of the Polish legal\nsystem. Key findings highlight the potential of LLMs in automating and\nenhancing legislative content analysis while emphasizing specific challenges,\nsuch as understanding legal context. The research contributes to the\nadvancement of NLP in the legal field, particularly in the Polish language. It\nhas been demonstrated that even commonly accessible data can be practically\nutilized for legislative content analysis."
  },
  {
    "arxiv_id": "2503.11989",
    "title": "Applications of Large Language Model Reasoning in Feature Generation",
    "url": "http://arxiv.org/abs/2503.11989v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nthrough their state of art reasoning capabilities. This paper explores the\nconvergence of LLM reasoning techniques and feature generation for machine\nlearning tasks. We examine four key reasoning approaches: Chain of Thought,\nTree of Thoughts, Retrieval-Augmented Generation, and Thought Space\nExploration. Our analysis reveals how these approaches can be used to identify\neffective feature generation rules without having to manually specify search\nspaces. The paper categorizes LLM-based feature generation methods across\nvarious domains including finance, healthcare, and text analytics. LLMs can\nextract key information from clinical notes and radiology reports in\nhealthcare, by enabling more efficient data utilization. In finance, LLMs\nfacilitate text generation, summarization, and entity extraction from complex\ndocuments. We analyze evaluation methodologies for assessing feature quality\nand downstream performance, with particular attention to OCTree's decision tree\nreasoning approach that provides language-based feedback for iterative\nimprovements. Current challenges include hallucination, computational\nefficiency, and domain adaptation. As of March 2025, emerging approaches\ninclude inference-time compute scaling, reinforcement learning, and supervised\nfine-tuning with model distillation. Future directions point toward multimodal\nfeature generation, self-improving systems, and neuro-symbolic approaches. This\npaper provides a detailed overview of an emerging field that promises to\nautomate and enhance feature engineering through language model reasoning."
  },
  {
    "arxiv_id": "2503.13857",
    "title": "Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations",
    "url": "http://arxiv.org/abs/2503.13857v1",
    "abstract": "Background. Systematic reviews in comparative effectiveness research require\ntimely evidence synthesis. Preprints accelerate knowledge dissemination but\nvary in quality, posing challenges for systematic reviews.\n  Methods. We propose AutoConfidence (automated confidence assessment), an\nadvanced framework for predicting preprint publication, which reduces reliance\non manual curation and expands the range of predictors, including three key\nadvancements: (1) automated data extraction using natural language processing\ntechniques, (2) semantic embeddings of titles and abstracts, and (3) large\nlanguage model (LLM)-driven evaluation scores. Additionally, we employed two\nprediction models: a random forest classifier for binary outcome and a survival\ncure model that predicts both binary outcome and publication risk over time.\n  Results. The random forest classifier achieved AUROC 0.692 with LLM-driven\nscores, improving to 0.733 with semantic embeddings and 0.747 with article\nusage metrics. The survival cure model reached AUROC 0.716 with LLM-driven\nscores, improving to 0.731 with semantic embeddings. For publication risk\nprediction, it achieved a concordance index of 0.658, increasing to 0.667 with\nsemantic embeddings.\n  Conclusion. Our study advances the framework for preprint publication\nprediction through automated data extraction and multiple feature integration.\nBy combining semantic embeddings with LLM-driven evaluations, AutoConfidence\nenhances predictive performance while reducing manual annotation burden. The\nframework has the potential to facilitate systematic incorporation of preprint\narticles in evidence-based medicine, supporting researchers in more effective\nevaluation and utilization of preprint resources."
  },
  {
    "arxiv_id": "2503.13819",
    "title": "LLM-Empowered IoT for 6G Networks: Architecture, Challenges, and Solutions",
    "url": "http://arxiv.org/abs/2503.13819v1",
    "abstract": "The Internet of Things (IoT) in the sixth generation (6G) era is envisioned\nto evolve towards intelligence, ubiquity, and self-optimization. Large language\nmodels (LLMs) have demonstrated remarkable generalization capabilities across\ndiverse domains, including natural language processing (NLP), computer vision\n(CV), and beyond. In this article, we propose an LLM-empowered IoT architecture\nfor 6G networks to achieve intelligent autonomy while supporting advanced IoT\napplications. LLMs are pushed to the edge of the 6G network to support the\nsynergy of LLMs and IoT. LLM solutions are tailored to both IoT application\nrequirements and IoT management needs, i.e., LLM for IoT. On the other hand,\nedge inference and edge fine-tuning are discussed to support the deployment of\nLLMs, i.e., LLM on IoT. Furthermore, we propose a memory-efficient split\nfederated learning (SFL) framework for LLM fine-tuning on heterogeneous IoT\ndevices that alleviates memory pressures on both IoT devices and the edge\nserver while achieving comparable performance and convergence time. Finally, a\ncase study is presented, followed by a discussion about open issues of\nLLM-empowered IoT for 6G networks."
  },
  {
    "arxiv_id": "2503.13661",
    "title": "Pensez: Less Data, Better Reasoning -- Rethinking French LLM",
    "url": "http://arxiv.org/abs/2503.13661v1",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, achieving strong\nperformance in specialized domains like mathematical reasoning and non-English\nlanguages often requires extensive training on massive datasets. This paper\ninvestigates a contrasting approach: strategic fine-tuning on a small,\nhigh-quality, bilingual (English-French) dataset to enhance both the reasoning\ncapabilities and French language proficiency of a large language model. Rather\nthan relying on scale, we explore the hypothesis that targeted data curation\nand optimized training can achieve competitive, or even superior, performance.\nWe demonstrate, through targeted supervised fine-tuning (SFT) on only 2,000\ncarefully selected samples, significant improvements in mathematical reasoning.\nSpecifically, Pensez 7B exhibits an increase in accuracy of the base model up\nto 20% on the AIME25 and a 12% increase on a French MATH level 5 benchmark.\nThese results challenge the prevailing assumption that massive datasets are\naprerequisite for strong reasoning performance in LLMs, highlighting the\npotential of strategic data curation and optimized fine-tuning for enhancing\nboth specialized skills and multilingual capabilities. Our findings have\nimplications for the efficient development of high-performing, multilingual\nLLMs, especially in resource-constrained scenarios."
  },
  {
    "arxiv_id": "2503.15438",
    "title": "VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning",
    "url": "http://arxiv.org/abs/2503.15438v1",
    "abstract": "Natural language processing (NLP) has significantly influenced scientific\ndomains beyond human language, including protein engineering, where pre-trained\nprotein language models (PLMs) have demonstrated remarkable success. However,\ninterdisciplinary adoption remains limited due to challenges in data\ncollection, task benchmarking, and application. This work presents\nVenusFactory, a versatile engine that integrates biological data retrieval,\nstandardized task benchmarking, and modular fine-tuning of PLMs. VenusFactory\nsupports both computer science and biology communities with choices of both a\ncommand-line execution and a Gradio-based no-code interface, integrating $40+$\nprotein-related datasets and $40+$ popular PLMs. All implementations are\nopen-sourced on https://github.com/tyang816/VenusFactory."
  },
  {
    "arxiv_id": "2503.15235",
    "title": "Exploring Large Language Models for Word Games:Who is the Spy?",
    "url": "http://arxiv.org/abs/2503.15235v1",
    "abstract": "Word games hold significant research value for natural language processing\n(NLP), game theory, and related fields due to their rule-based and situational\nnature. This study explores how large language models (LLMs) can be effectively\ninvolved in word games and proposes a training-free framework. \"Shei Shi Wo Di\"\nor \"Who is the Spy\" in English, is a classic word game. Using this game as an\nexample, we introduce a Chain-of-Thought (CoT)-based scheduling framework to\nenable LLMs to achieve excellent performance in tasks such as inferring role\nwords and disguising their identities. We evaluate the framework's performance\nbased on game success rates and the accuracy of the LLM agents' analytical\nresults. Experimental results affirm the framework's effectiveness,\ndemonstrating notable improvements in LLM performance across multiple datasets.\nThis work highlights the potential of LLMs in mastering situational reasoning\nand social interactions within structured game environments. Our code is\npublicly available at https://github.com/ct-wei/Who-is-The-Spy."
  },
  {
    "arxiv_id": "2503.14932",
    "title": "Prada: Black-Box LLM Adaptation with Private Data on Resource-Constrained Devices",
    "url": "http://arxiv.org/abs/2503.14932v1",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\nabilities in various natural language processing tasks. However, adapting these\nmodels to specialized domains using private datasets stored on\nresource-constrained edge devices, such as smartphones and personal computers,\nremains challenging due to significant privacy concerns and limited\ncomputational resources. Existing model adaptation methods either compromise\ndata privacy by requiring data transmission or jeopardize model privacy by\nexposing proprietary LLM parameters. To address these challenges, we propose\nPrada, a novel privacy-preserving and efficient black-box LLM adaptation system\nusing private on-device datasets. Prada employs a lightweight proxy model\nfine-tuned with Low-Rank Adaptation (LoRA) locally on user devices. During\ninference, Prada leverages the logits offset, i.e., difference in outputs\nbetween the base and adapted proxy models, to iteratively refine outputs from a\nremote black-box LLM. This offset-based adaptation approach preserves both data\nprivacy and model privacy, as there is no need to share sensitive data or\nproprietary model parameters. Furthermore, we incorporate speculative decoding\nto further speed up the inference process of Prada, making the system\npractically deployable on bandwidth-constrained edge devices, enabling a more\npractical deployment of Prada. Extensive experiments on various downstream\ntasks demonstrate that Prada achieves performance comparable to centralized\nfine-tuning methods while significantly reducing computational overhead by up\nto 60% and communication costs by up to 80%."
  },
  {
    "arxiv_id": "2503.16304",
    "title": "Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1",
    "url": "http://arxiv.org/abs/2503.16304v2",
    "abstract": "In recent years, the development of Large Language Models (LLMs) has made\nsignificant breakthroughs in the field of natural language processing and has\ngradually been applied to the field of humanities and social sciences research.\nLLMs have a wide range of application value in the field of humanities and\nsocial sciences because of its strong text understanding, generation and\nreasoning capabilities. In humanities and social sciences research, LLMs can\nanalyze large-scale text data and make inferences.\n  This article analyzes the large language model DeepSeek-R1 from seven\naspects: low-resource language translation, educational question-answering,\nstudent writing improvement in higher education, logical reasoning, educational\nmeasurement and psychometrics, public health policy analysis, and art education\n. Then we compare the answers given by DeepSeek-R1 in the seven aspects with\nthe answers given by o1-preview. DeepSeek-R1 performs well in the humanities\nand social sciences, answering most questions correctly and logically, and can\ngive reasonable analysis processes and explanations. Compared with o1-preview,\nit can automatically generate reasoning processes and provide more detailed\nexplanations, which is suitable for beginners or people who need to have a\ndetailed understanding of this knowledge, while o1-preview is more suitable for\nquick reading.\n  Through analysis, it is found that LLM has broad application potential in the\nfield of humanities and social sciences, and shows great advantages in\nimproving text analysis efficiency, language communication and other fields.\nLLM's powerful language understanding and generation capabilities enable it to\ndeeply explore complex problems in the field of humanities and social sciences,\nand provide innovative tools for academic research and practical applications."
  },
  {
    "arxiv_id": "2503.15904",
    "title": "From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling",
    "url": "http://arxiv.org/abs/2503.15904v1",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet concerns persist regarding their tendency to reflect or amplify social\nbiases present in their training data. This study introduces a novel evaluation\nframework to uncover gender biases in LLMs, focusing on their occupational\nnarratives. Unlike previous methods relying on structured scenarios or\ncarefully crafted prompts, our approach leverages free-form storytelling to\nreveal biases embedded in the models. Systematic analyses show an\noverrepresentation of female characters across occupations in six widely used\nLLMs. Additionally, our findings reveal that LLM-generated occupational gender\nrankings align more closely with human stereotypes than actual labor\nstatistics. These insights underscore the need for balanced mitigation\nstrategies to ensure fairness while avoiding the reinforcement of new\nstereotypes."
  },
  {
    "arxiv_id": "2503.16585",
    "title": "Distributed LLMs and Multimodal Large Language Models: A Survey on Advances, Challenges, and Future Directions",
    "url": "http://arxiv.org/abs/2503.16585v1",
    "abstract": "Language models (LMs) are machine learning models designed to predict\nlinguistic patterns by estimating the probability of word sequences based on\nlarge-scale datasets, such as text. LMs have a wide range of applications in\nnatural language processing (NLP) tasks, including autocomplete and machine\ntranslation. Although larger datasets typically enhance LM performance,\nscalability remains a challenge due to constraints in computational power and\nresources. Distributed computing strategies offer essential solutions for\nimproving scalability and managing the growing computational demand. Further,\nthe use of sensitive datasets in training and deployment raises significant\nprivacy concerns. Recent research has focused on developing decentralized\ntechniques to enable distributed training and inference while utilizing diverse\ncomputational resources and enabling edge AI. This paper presents a survey on\ndistributed solutions for various LMs, including large language models (LLMs),\nvision language models (VLMs), multimodal LLMs (MLLMs), and small language\nmodels (SLMs). While LLMs focus on processing and generating text, MLLMs are\ndesigned to handle multiple modalities of data (e.g., text, images, and audio)\nand to integrate them for broader applications. To this end, this paper reviews\nkey advancements across the MLLM pipeline, including distributed training,\ninference, fine-tuning, and deployment, while also identifying the\ncontributions, limitations, and future areas of improvement. Further, it\ncategorizes the literature based on six primary focus areas of\ndecentralization. Our analysis describes gaps in current methodologies for\nenabling distributed solutions for LMs and outline future research directions,\nemphasizing the need for novel solutions to enhance the robustness and\napplicability of distributed LMs."
  },
  {
    "arxiv_id": "2503.18878",
    "title": "I Have Covered All the Bases Here: Interpreting Reasoning Features in Large Language Models via Sparse Autoencoders",
    "url": "http://arxiv.org/abs/2503.18878v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing. Recent advances have led to the developing of a new class\nof reasoning LLMs; for example, open-source DeepSeek-R1 has achieved\nstate-of-the-art performance by integrating deep thinking and complex\nreasoning. Despite these impressive capabilities, the internal reasoning\nmechanisms of such models remain unexplored. In this work, we employ Sparse\nAutoencoders (SAEs), a method to learn a sparse decomposition of latent\nrepresentations of a neural network into interpretable features, to identify\nfeatures that drive reasoning in the DeepSeek-R1 series of models. First, we\npropose an approach to extract candidate ''reasoning features'' from SAE\nrepresentations. We validate these features through empirical analysis and\ninterpretability methods, demonstrating their direct correlation with the\nmodel's reasoning abilities. Crucially, we demonstrate that steering these\nfeatures systematically enhances reasoning performance, offering the first\nmechanistic account of reasoning in LLMs. Code available at\nhttps://github.com/AIRI-Institute/SAE-Reasoning"
  },
  {
    "arxiv_id": "2503.18681",
    "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
    "url": "http://arxiv.org/abs/2503.18681v1",
    "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural\nLanguage Processing (NLP), has attracted widespread attention. Traditional\nsarcasm detection tasks have typically focused on single-modal approaches\n(e.g., text), but due to the implicit and subtle nature of sarcasm, such\nmethods often fail to yield satisfactory results. In recent years, researchers\nhave shifted the focus of sarcasm detection to multi-modal approaches. However,\neffectively leveraging multi-modal information to accurately identify sarcastic\ncontent remains a challenge that warrants further exploration. Leveraging the\npowerful integrated processing capabilities of Multi-Modal Large Language\nModels (MLLMs) for various information sources, we propose an innovative\nmulti-modal Commander-GPT framework. Inspired by military strategy, we first\ndecompose the sarcasm detection task into six distinct sub-tasks. A central\ncommander (decision-maker) then assigns the best-suited large language model to\naddress each specific sub-task. Ultimately, the detection results from each\nmodel are aggregated to identify sarcasm. We conducted extensive experiments on\nMMSD and MMSD 2.0, utilizing four multi-modal large language models and six\nprompting strategies. Our experiments demonstrate that our approach achieves\nstate-of-the-art performance, with a 19.3% improvement in F1 score, without\nnecessitating fine-tuning or ground-truth rationales."
  },
  {
    "arxiv_id": "2503.19640",
    "title": "An Efficient Data Reuse with Tile-Based Adaptive Stationary for Transformer Accelerators",
    "url": "http://arxiv.org/abs/2503.19640v1",
    "abstract": "Transformer-based models have become the \\textit{de facto} backbone across\nmany fields, such as computer vision and natural language processing. However,\nas these models scale in size, external memory access (EMA) for weight and\nactivations becomes a critical bottleneck due to its significantly higher\nenergy consumption compared to internal computations. While most prior work has\nfocused on optimizing the self-attention mechanism, little attention has been\ngiven to optimizing data transfer during linear projections, where EMA costs\nare equally important. In this paper, we propose the Tile-based Adaptive\nStationary (TAS) scheme that selects the input or weight stationary in a tile\ngranularity, based on the input sequence length. Our experimental results\ndemonstrate that TAS can significantly reduce EMA by more than 97\\% compared to\ntraditional stationary schemes, while being compatible with various attention\noptimization techniques and hardware accelerators."
  },
  {
    "arxiv_id": "2503.19265",
    "title": "PHEONA: An Evaluation Framework for Large Language Model-based Approaches to Computational Phenotyping",
    "url": "http://arxiv.org/abs/2503.19265v1",
    "abstract": "Computational phenotyping is essential for biomedical research but often\nrequires significant time and resources, especially since traditional methods\ntypically involve extensive manual data review. While machine learning and\nnatural language processing advancements have helped, further improvements are\nneeded. Few studies have explored using Large Language Models (LLMs) for these\ntasks despite known advantages of LLMs for text-based tasks. To facilitate\nfurther research in this area, we developed an evaluation framework, Evaluation\nof PHEnotyping for Observational Health Data (PHEONA), that outlines\ncontext-specific considerations. We applied and demonstrated PHEONA on concept\nclassification, a specific task within a broader phenotyping process for Acute\nRespiratory Failure (ARF) respiratory support therapies. From the sample\nconcepts tested, we achieved high classification accuracy, suggesting the\npotential for LLM-based methods to improve computational phenotyping processes."
  },
  {
    "arxiv_id": "2503.20578",
    "title": "LLPut: Investigating Large Language Models for Bug Report-Based Input Generation",
    "url": "http://arxiv.org/abs/2503.20578v3",
    "abstract": "Failure-inducing inputs play a crucial role in diagnosing and analyzing\nsoftware bugs. Bug reports typically contain these inputs, which developers\nextract to facilitate debugging. Since bug reports are written in natural\nlanguage, prior research has leveraged various Natural Language Processing\n(NLP) techniques for automated input extraction. With the advent of Large\nLanguage Models (LLMs), an important research question arises: how effectively\ncan generative LLMs extract failure-inducing inputs from bug reports? In this\npaper, we propose LLPut, a technique to empirically evaluate the performance of\nthree open-source generative LLMs -- LLaMA, Qwen, and Qwen-Coder -- in\nextracting relevant inputs from bug reports. We conduct an experimental\nevaluation on a dataset of 206 bug reports to assess the accuracy and\neffectiveness of these models. Our findings provide insights into the\ncapabilities and limitations of generative LLMs in automated bug diagnosis."
  },
  {
    "arxiv_id": "2503.20417",
    "title": "CFunModel: A \"Funny\" Language Model Capable of Chinese Humor Generation and Processing",
    "url": "http://arxiv.org/abs/2503.20417v1",
    "abstract": "Humor plays a significant role in daily language communication. With the\nrapid development of large language models (LLMs), natural language processing\nhas made significant strides in understanding and generating various genres of\ntexts. However, most LLMs exhibit poor performance in generating and processing\nChinese humor. In this study, we introduce a comprehensive Chinese\nhumor-related dataset, the Chinese Fun Set (CFunSet). This dataset aggregates\nexisting Chinese humor datasets and includes over 20,000 jokes collected from\nTieba-JokeBar, a Chinese online platform known for joke sharing. The resulting\ncorpus comprises more than 160,000 entries. Leveraging CFunSet, we developed\nthe Chinese Fun Model (CFunModel), the first large language model designed to\nhandle various Chinese humor-related tasks including Crosstalk Response\nSelection, Humor Recognition, Joke Generation, etc. Experimental results\ndemonstrate that CFunModel outperforms popular large language models in these\ntasks. Our CFunSet is available at\nhttps://huggingface.co/datasets/ZhenghanYU/CFunSet and CFunModel is available\nat https://huggingface.co/ZhenghanYU/CFunModel. A demostration video of our\nwork is available at https://youtu.be/MOsISOJ66Ms."
  },
  {
    "arxiv_id": "2503.20227",
    "title": "Advancements in Natural Language Processing: Exploring Transformer-Based Architectures for Text Understanding",
    "url": "http://arxiv.org/abs/2503.20227v1",
    "abstract": "Natural Language Processing (NLP) has witnessed a transformative leap with\nthe advent of transformer-based architectures, which have significantly\nenhanced the ability of machines to understand and generate human-like text.\nThis paper explores the advancements in transformer models, such as BERT and\nGPT, focusing on their superior performance in text understanding tasks\ncompared to traditional methods like recurrent neural networks (RNNs). By\nanalyzing statistical properties through visual representations-including\nprobability density functions of text length distributions and feature space\nclassifications-the study highlights the models' proficiency in handling\nlong-range dependencies, adapting to conditional shifts, and extracting\nfeatures for classification, even with overlapping classes. Drawing on recent\n2024 research, including enhancements in multi-hop knowledge graph reasoning\nand context-aware chat interactions, the paper outlines a methodology involving\ndata preparation, model selection, pretraining, fine-tuning, and evaluation.\nThe results demonstrate state-of-the-art performance on benchmarks like GLUE\nand SQuAD, with F1 scores exceeding 90%, though challenges such as high\ncomputational costs persist. This work underscores the pivotal role of\ntransformers in modern NLP and suggests future directions, including efficiency\noptimization and multimodal integration, to further advance language-based AI\nsystems."
  },
  {
    "arxiv_id": "2503.21683",
    "title": "LLM-Gomoku: A Large Language Model-Based System for Strategic Gomoku with Self-Play and Reinforcement Learning",
    "url": "http://arxiv.org/abs/2503.21683v1",
    "abstract": "In recent years, large language models (LLMs) have shown significant\nadvancements in natural language processing (NLP), with strong capa-bilities in\ngeneration, comprehension, and rea-soning. These models have found applications\nin education, intelligent decision-making, and gaming. However, effectively\nutilizing LLMs for strategic planning and decision-making in the game of Gomoku\nremains a challenge. This study aims to develop a Gomoku AI system based on\nLLMs, simulating the human learning process of playing chess. The system is\nde-signed to understand and apply Gomoku strat-egies and logic to make rational\ndecisions. The research methods include enabling the model to \"read the board,\"\n\"understand the rules,\" \"select strategies,\" and \"evaluate positions,\" while\nen-hancing its abilities through self-play and rein-forcement learning. The\nresults demonstrate that this approach significantly improves the se-lection of\nmove positions, resolves the issue of generating illegal positions, and reduces\npro-cess time through parallel position evaluation. After extensive self-play\ntraining, the model's Gomoku-playing capabilities have been notably enhanced."
  },
  {
    "arxiv_id": "2503.24245",
    "title": "Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation",
    "url": "http://arxiv.org/abs/2503.24245v1",
    "abstract": "Large language models (LLMs) have made significant progress in\ngeneral-purpose natural language processing tasks. However, LLMs are still\nfacing challenges when applied to domain-specific areas like\ntelecommunications, which demands specialized expertise and adaptability to\nevolving standards. This paper presents a novel framework that combines\nknowledge graph (KG) and retrieval-augmented generation (RAG) techniques to\nenhance LLM performance in the telecom domain. The framework leverages a KG to\ncapture structured, domain-specific information about network protocols,\nstandards, and other telecom-related entities, comprehensively representing\ntheir relationships. By integrating KG with RAG, LLMs can dynamically access\nand utilize the most relevant and up-to-date knowledge during response\ngeneration. This hybrid approach bridges the gap between structured knowledge\nrepresentation and the generative capabilities of LLMs, significantly enhancing\naccuracy, adaptability, and domain-specific comprehension. Our results\ndemonstrate the effectiveness of the KG-RAG framework in addressing complex\ntechnical queries with precision. The proposed KG-RAG model attained an\naccuracy of 88% for question answering tasks on a frequently used\ntelecom-specific dataset, compared to 82% for the RAG-only and 48% for the\nLLM-only approaches."
  },
  {
    "arxiv_id": "2503.24102",
    "title": "Is LLM the Silver Bullet to Low-Resource Languages Machine Translation?",
    "url": "http://arxiv.org/abs/2503.24102v1",
    "abstract": "Low-Resource Languages (LRLs) present significant challenges in natural\nlanguage processing due to their limited linguistic resources and\nunderrepresentation in standard datasets. While recent advancements in Large\nLanguage Models (LLMs) and Neural Machine Translation (NMT) have substantially\nimproved translation capabilities for high-resource languages, performance\ndisparities persist for LRLs, particularly impacting privacy-sensitive and\nresource-constrained scenarios. This paper systematically evaluates the\nlimitations of current LLMs across 200 languages using benchmarks such as\nFLORES-200. We also explore alternative data sources, including news articles\nand bilingual dictionaries, and demonstrate how knowledge distillation from\nlarge pre-trained models can significantly improve smaller LRL translations.\nAdditionally, we investigate various fine-tuning strategies, revealing that\nincremental enhancements markedly reduce performance gaps on smaller LLMs."
  },
  {
    "arxiv_id": "2503.23924",
    "title": "Model Hemorrhage and the Robustness Limits of Large Language Models",
    "url": "http://arxiv.org/abs/2503.23924v1",
    "abstract": "Large language models (LLMs) demonstrate strong performance across natural\nlanguage processing tasks, yet undergo significant performance degradation when\nmodified for deployment through quantization, pruning, or decoding strategy\nadjustments. We define this phenomenon as model hemorrhage - performance\ndecline caused by parameter alterations and architectural changes. Through\nsystematic analysis of various LLM frameworks, we identify key vulnerability\npatterns: layer expansion frequently disrupts attention mechanisms, compression\ntechniques induce information loss cascades, and decoding adjustments amplify\nprediction divergences. Our investigation reveals transformer architectures\nexhibit inherent robustness thresholds that determine hemorrhage severity\nacross modification types. We propose three mitigation strategies:\ngradient-aware pruning preserves critical weight pathways, dynamic quantization\nscaling maintains activation integrity, and decoding calibration aligns\ngeneration trajectories with original model distributions. This work\nestablishes foundational metrics for evaluating model stability during\nadaptation, providing practical guidelines for maintaining performance while\nenabling efficient LLM deployment. Our findings advance understanding of neural\nnetwork resilience under architectural transformations, particularly for\nlarge-scale language models."
  },
  {
    "arxiv_id": "2503.23395",
    "title": "Scaling Auditory Cognition via Test-Time Compute in Audio Language Models",
    "url": "http://arxiv.org/abs/2503.23395v1",
    "abstract": "Large language models (LLMs) have shown exceptional versatility in natural\nlanguage processing, prompting recent efforts to extend their multimodal\ncapabilities to speech processing through the development of audio large\nlanguage models (Audio LLMs). While Audio LLMs excel in tasks such as speech\nrecognition and synthesis, it remains unclear how they perform when faced with\nthe auditory cognitive challenges posed by real-world environments, such as\naudio comprehension and listening recall, particularly in the presence of\nbackground noise or overlapping speech. Unlike text-based LLMs, which have\naccess to vast amounts of text data for pre-training, retraining Audio LLMs\nwith diverse auditory cognitive scenes is difficult due to the limited datasets\nthat simulate real-world auditory cognitive scenarios and the challenge of\nacquiring auditory cognitive labels for training. While test-time compute (TTC)\nmethods have been shown to enhance the capabilities of text-based LLMs during\ninference, a key challenge lies in designing these TTC methods to improve the\nauditory capabilities of Audio LLMs. This study aims to address these two\nresearch gaps by: i) exploring the auditory cognitive capabilities of Audio\nLLMs, and ii) enhancing their capabilities using TTC approaches. We have\ninvestigated five different Audio LLMs for auditory cognition using a\n\\textit{self-collected} database and have proposed five TTC approaches to\nenhance auditory cognitive capabilities during inference. Our findings reveal\nthat Audio LLMs performance decreases in more challenging auditory cognitive\ntasks. The proposed TTC approaches significantly enhance cognitive auditory\ncapabilities, advancing the development of more adaptable and resilient Audio\nLLMs for practical applications such as assistive listening devices,\nvoice-based AI assistants, and communication technologies."
  },
  {
    "arxiv_id": "2504.01301",
    "title": "Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers",
    "url": "http://arxiv.org/abs/2504.01301v1",
    "abstract": "We present Bi-LAT, a novel imitation learning framework that unifies\nbilateral control with natural language processing to achieve precise force\nmodulation in robotic manipulation. Bi-LAT leverages joint position, velocity,\nand torque data from leader-follower teleoperation while also integrating\nvisual and linguistic cues to dynamically adjust applied force. By encoding\nhuman instructions such as \"softly grasp the cup\" or \"strongly twist the\nsponge\" through a multimodal Transformer-based model, Bi-LAT learns to\ndistinguish nuanced force requirements in real-world tasks. We demonstrate\nBi-LAT's performance in (1) unimanual cup-stacking scenario where the robot\naccurately modulates grasp force based on language commands, and (2) bimanual\nsponge-twisting task that requires coordinated force control. Experimental\nresults show that Bi-LAT effectively reproduces the instructed force levels,\nparticularly when incorporating SigLIP among tested language encoders. Our\nfindings demonstrate the potential of integrating natural language cues into\nimitation learning, paving the way for more intuitive and adaptive human-robot\ninteraction. For additional material, please visit:\nhttps://mertcookimg.github.io/bi-lat/"
  },
  {
    "arxiv_id": "2504.01241",
    "title": "Catastrophic Forgetting in LLMs: A Comparative Analysis Across Language Tasks",
    "url": "http://arxiv.org/abs/2504.01241v1",
    "abstract": "Large Language Models (LLMs) have significantly advanced Natural Language\nProcessing (NLP), particularly in Natural Language Understanding (NLU) tasks.\nAs we progress toward an agentic world where LLM-based agents autonomously\nhandle specialized tasks, it becomes crucial for these models to adapt to new\ntasks without forgetting previously learned information - a challenge known as\ncatastrophic forgetting. This study evaluates the continual fine-tuning of\nvarious open-source LLMs with different parameter sizes (specifically models\nunder 10 billion parameters) on key NLU tasks from the GLUE benchmark,\nincluding SST-2, MRPC, CoLA, and MNLI. By employing prompt engineering and\ntask-specific adjustments, we assess and compare the models' abilities to\nretain prior knowledge while learning new tasks. Our results indicate that\nmodels such as Phi-3.5-mini exhibit minimal forgetting while maintaining strong\nlearning capabilities, making them well-suited for continual learning\nenvironments. Additionally, models like Orca-2-7b and Qwen2.5-7B demonstrate\nimpressive learning abilities and overall performance after fine-tuning. This\nwork contributes to understanding catastrophic forgetting in LLMs and\nhighlights prompting engineering to optimize model performance for continual\nlearning scenarios."
  },
  {
    "arxiv_id": "2504.01216",
    "title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models",
    "url": "http://arxiv.org/abs/2504.01216v1",
    "abstract": "Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical\nsettings, presenting opportunities for automated detection to identify\npatients. This study evaluates natural language processing approaches for\ndetecting PTSD from clinical interview transcripts. We compared general and\nmental health-specific transformer models (BERT/RoBERTa), embedding-based\nmethods (SentenceBERT/LLaMA), and large language model prompting strategies\n(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.\nDomain-specific models significantly outperformed general models\n(Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485). LLaMA embeddings with neural\nnetworks achieved the highest performance (F1=0.700). Zero-shot prompting using\nDSM-5 criteria yielded competitive results without training data (F1=0.657).\nPerformance varied significantly across symptom severity and comorbidity\nstatus, with higher accuracy for severe PTSD cases and patients with comorbid\ndepression. Our findings highlight the potential of domain-adapted embeddings\nand LLMs for scalable screening while underscoring the need for improved\ndetection of nuanced presentations and offering insights for developing\nclinically viable AI tools for PTSD assessment."
  },
  {
    "arxiv_id": "2504.02349",
    "title": "Large (Vision) Language Models are Unsupervised In-Context Learners",
    "url": "http://arxiv.org/abs/2504.02349v1",
    "abstract": "Recent advances in large language and vision-language models have enabled\nzero-shot inference, allowing models to solve new tasks without task-specific\ntraining. Various adaptation techniques such as prompt engineering, In-Context\nLearning (ICL), and supervised fine-tuning can further enhance the model's\nperformance on a downstream task, but they require substantial manual effort to\nconstruct effective prompts or labeled examples. In this work, we introduce a\njoint inference framework for fully unsupervised adaptation, eliminating the\nneed for manual prompt engineering and labeled examples. Unlike zero-shot\ninference, which makes independent predictions, the joint inference makes\npredictions simultaneously for all inputs in a given task. Since direct joint\ninference involves computationally expensive optimization, we develop efficient\napproximation techniques, leading to two unsupervised adaptation methods:\nunsupervised fine-tuning and unsupervised ICL. We demonstrate the effectiveness\nof our methods across diverse tasks and models, including language-only\nLlama-3.1 on natural language processing tasks, reasoning-oriented Qwen2.5-Math\non grade school math problems, vision-language OpenFlamingo on vision tasks,\nand the API-only access GPT-4o model on massive multi-discipline tasks. Our\nexperiments demonstrate substantial improvements over the standard zero-shot\napproach, including 39% absolute improvement on the challenging GSM8K math\nreasoning dataset. Remarkably, despite being fully unsupervised, our framework\noften performs on par with supervised approaches that rely on ground truth\nlabels."
  },
  {
    "arxiv_id": "2504.03312",
    "title": "Evaluating Compact LLMs for Zero-Shot Iberian Language Tasks on End-User Devices",
    "url": "http://arxiv.org/abs/2504.03312v1",
    "abstract": "Large Language Models have significantly advanced natural language\nprocessing, achieving remarkable performance in tasks such as language\ngeneration, translation, and reasoning. However, their substantial\ncomputational requirements restrict deployment to high-end systems, limiting\naccessibility on consumer-grade devices. This challenge is especially\npronounced for under-resourced languages like those spoken in the Iberian\nPeninsula, where relatively limited linguistic resources and benchmarks hinder\neffective evaluation. This work presents a comprehensive evaluation of compact\nstate-of-the-art LLMs across several essential NLP tasks tailored for Iberian\nlanguages. The results reveal that while some models consistently excel in\ncertain tasks, significant performance gaps remain, particularly for languages\nsuch as Basque. These findings highlight the need for further research on\nbalancing model compactness with robust multilingual performance"
  },
  {
    "arxiv_id": "2504.03219",
    "title": "From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models",
    "url": "http://arxiv.org/abs/2504.03219v1",
    "abstract": "The rapid advancement of artificial intelligence (AI) has reshaped the field\nof natural language processing (NLP), with models like OpenAI ChatGPT and\nDeepSeek AI. Although ChatGPT established a strong foundation for\nconversational AI, DeepSeek AI introduces significant improvements in\narchitecture, performance, and ethical considerations. This paper presents a\ndetailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting\ntheir technical differences, practical applications, and broader implications\nfor AI development. To assess their capabilities, we conducted a case study\nusing a predefined set of multiple choice questions in various domains,\nevaluating the strengths and limitations of each model. By examining these\naspects, we provide valuable insight into the future trajectory of AI, its\npotential to transform industries, and key research directions for improving\nAI-driven language models."
  },
  {
    "arxiv_id": "2504.04976",
    "title": "A Domain-Based Taxonomy of Jailbreak Vulnerabilities in Large Language Models",
    "url": "http://arxiv.org/abs/2504.04976v1",
    "abstract": "The study of large language models (LLMs) is a key area in open-world machine\nlearning. Although LLMs demonstrate remarkable natural language processing\ncapabilities, they also face several challenges, including consistency issues,\nhallucinations, and jailbreak vulnerabilities. Jailbreaking refers to the\ncrafting of prompts that bypass alignment safeguards, leading to unsafe outputs\nthat compromise the integrity of LLMs. This work specifically focuses on the\nchallenge of jailbreak vulnerabilities and introduces a novel taxonomy of\njailbreak attacks grounded in the training domains of LLMs. It characterizes\nalignment failures through generalization, objectives, and robustness gaps. Our\nprimary contribution is a perspective on jailbreak, framed through the\ndifferent linguistic domains that emerge during LLM training and alignment.\nThis viewpoint highlights the limitations of existing approaches and enables us\nto classify jailbreak attacks on the basis of the underlying model deficiencies\nthey exploit. Unlike conventional classifications that categorize attacks based\non prompt construction methods (e.g., prompt templating), our approach provides\na deeper understanding of LLM behavior. We introduce a taxonomy with four\ncategories -- mismatched generalization, competing objectives, adversarial\nrobustness, and mixed attacks -- offering insights into the fundamental nature\nof jailbreak vulnerabilities. Finally, we present key lessons derived from this\ntaxonomic study."
  },
  {
    "arxiv_id": "2504.04702",
    "title": "Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent",
    "url": "http://arxiv.org/abs/2504.04702v1",
    "abstract": "Recent advancements in Transformer-based architectures have led to impressive\nbreakthroughs in natural language processing tasks, with models such as GPT-4,\nClaude, and Gemini demonstrating human-level reasoning abilities. However,\ndespite their high performance, concerns remain about the inherent limitations\nof these models, especially when it comes to learning basic logical functions.\nWhile complexity-theoretic analyses indicate that Transformers can represent\nsimple logic functions (e.g., $\\mathsf{AND}$, $\\mathsf{OR}$, and majority\ngates) by its nature of belonging to the $\\mathsf{TC}^0$ class, these results\nassume ideal parameter settings and do not account for the constraints imposed\nby gradient descent-based training methods. In this work, we investigate\nwhether Transformers can truly learn simple majority functions when trained\nusing gradient-based methods. We focus on a simplified variant of the\nTransformer architecture and consider both $n=\\mathrm{poly}(d)$ and\n$n=\\exp(\\Omega(d))$ number of training samples, where each sample is a $d$-size\nbinary string paired with the output of a basic majority function. Our analysis\ndemonstrates that even after $\\mathrm{poly}(d)$ gradient queries, the\ngeneralization error of the Transformer model still remains substantially\nlarge, growing exponentially with $d$. This work highlights fundamental\noptimization challenges in training Transformers for the simplest logical\nreasoning tasks and provides new insights into their theoretical limitations."
  },
  {
    "arxiv_id": "2504.04453",
    "title": "Prot42: a Novel Family of Protein Language Models for Target-aware Protein Binder Generation",
    "url": "http://arxiv.org/abs/2504.04453v1",
    "abstract": "Unlocking the next generation of biotechnology and therapeutic innovation\ndemands overcoming the inherent complexity and resource-intensity of\nconventional protein engineering methods. Recent GenAI-powered computational\ntechniques often rely on the availability of the target protein's 3D structures\nand specific binding sites to generate high-affinity binders, constraints\nexhibited by models such as AlphaProteo and RFdiffusion. In this work, we\nexplore the use of Protein Language Models (pLMs) for high-affinity binder\ngeneration. We introduce Prot42, a novel family of Protein Language Models\n(pLMs) pretrained on vast amounts of unlabeled protein sequences. By capturing\ndeep evolutionary, structural, and functional insights through an advanced\nauto-regressive, decoder-only architecture inspired by breakthroughs in natural\nlanguage processing, Prot42 dramatically expands the capabilities of\ncomputational protein design based on language only. Remarkably, our models\nhandle sequences up to 8,192 amino acids, significantly surpassing standard\nlimitations and enabling precise modeling of large proteins and complex\nmulti-domain sequences. Demonstrating powerful practical applications, Prot42\nexcels in generating high-affinity protein binders and sequence-specific\nDNA-binding proteins. Our innovative models are publicly available, offering\nthe scientific community an efficient and precise computational toolkit for\nrapid protein engineering."
  },
  {
    "arxiv_id": "2504.04385",
    "title": "Pre-trained Language Models and Few-shot Learning for Medical Entity Extraction",
    "url": "http://arxiv.org/abs/2504.04385v1",
    "abstract": "This study proposes a medical entity extraction method based on Transformer\nto enhance the information extraction capability of medical literature.\nConsidering the professionalism and complexity of medical texts, we compare the\nperformance of different pre-trained language models (BERT, BioBERT,\nPubMedBERT, ClinicalBERT) in medical entity extraction tasks. Experimental\nresults show that PubMedBERT achieves the best performance (F1-score = 88.8%),\nindicating that a language model pre-trained on biomedical literature is more\neffective in the medical domain. In addition, we analyze the impact of\ndifferent entity extraction methods (CRF, Span-based, Seq2Seq) and find that\nthe Span-based approach performs best in medical entity extraction tasks\n(F1-score = 88.6%). It demonstrates superior accuracy in identifying entity\nboundaries. In low-resource scenarios, we further explore the application of\nFew-shot Learning in medical entity extraction. Experimental results show that\neven with only 10-shot training samples, the model achieves an F1-score of\n79.1%, verifying the effectiveness of Few-shot Learning under limited data\nconditions. This study confirms that the combination of pre-trained language\nmodels and Few-shot Learning can enhance the accuracy of medical entity\nextraction. Future research can integrate knowledge graphs and active learning\nstrategies to improve the model's generalization and stability, providing a\nmore effective solution for medical NLP research. Keywords- Natural Language\nProcessing, medical named entity recognition, pre-trained language model,\nFew-shot Learning, information extraction, deep learning"
  },
  {
    "arxiv_id": "2504.05855",
    "title": "Enhancing Coreference Resolution with Pretrained Language Models: Bridging the Gap Between Syntax and Semantics",
    "url": "http://arxiv.org/abs/2504.05855v1",
    "abstract": "Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding."
  },
  {
    "arxiv_id": "2504.07053",
    "title": "TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling",
    "url": "http://arxiv.org/abs/2504.07053v1",
    "abstract": "Large Language Models (LLMs) excel in text-based natural language processing\ntasks but remain constrained by their reliance on textual inputs and outputs.\nTo enable more natural human-LLM interaction, recent progress have focused on\nderiving a spoken language model (SLM) that can not only listen but also\ngenerate speech. To achieve this, a promising direction is to conduct\nspeech-text joint modeling. However, recent SLM still lag behind text LLM due\nto the modality mismatch. One significant mismatch can be the sequence lengths\nbetween speech and text tokens. To address this, we introduce Text-Aligned\nSpeech Tokenization and Embedding (TASTE), a method that directly addresses the\nmodality gap by aligning speech token with the corresponding text transcription\nduring the tokenization stage. We propose a method that can achieve this\nthrough the special aggregation mechanism and with speech reconstruction as the\ntraining objective. We conduct extensive experiments and show that TASTE can\npreserve essential paralinguistic information while dramatically reducing the\ntoken sequence length. Furthermore, by leveraging TASTE, we can adapt\ntext-based LLMs into effective SLMs with parameter-efficient fine-tuning\ntechniques such as Low-Rank Adaptation (LoRA). Experimental results on\nbenchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based\nSLMs perform similarly to previous full-finetuning methods. To our knowledge,\nTASTE is the first end-to-end approach that utilizes a reconstruction objective\nto automatically learn a text-aligned speech tokenization and embedding\nsuitable for spoken language modeling. Our demo, code, and models are publicly\navailable at https://github.com/mtkresearch/TASTE-SpokenLM."
  },
  {
    "arxiv_id": "2504.06843",
    "title": "Integrating Cognitive Processing Signals into Language Models: A Review of Advances, Applications and Future Directions",
    "url": "http://arxiv.org/abs/2504.06843v1",
    "abstract": "Recently, the integration of cognitive neuroscience in Natural Language\nProcessing (NLP) has gained significant attention. This article provides a\ncritical and timely overview of recent advancements in leveraging cognitive\nsignals, particularly Eye-tracking (ET) signals, to enhance Language Models\n(LMs) and Multimodal Large Language Models (MLLMs). By incorporating\nuser-centric cognitive signals, these approaches address key challenges,\nincluding data scarcity and the environmental costs of training large-scale\nmodels. Cognitive signals enable efficient data augmentation, faster\nconvergence, and improved human alignment. The review emphasises the potential\nof ET data in tasks like Visual Question Answering (VQA) and mitigating\nhallucinations in MLLMs, and concludes by discussing emerging challenges and\nresearch trends."
  },
  {
    "arxiv_id": "2504.06704",
    "title": "CAT: Circular-Convolutional Attention for Sub-Quadratic Transformers",
    "url": "http://arxiv.org/abs/2504.06704v1",
    "abstract": "Transformers have driven remarkable breakthroughs in natural language\nprocessing and computer vision, yet their standard attention mechanism still\nimposes O(N^2) complexity, hindering scalability to longer sequences. We\nintroduce Circular-convolutional ATtention (CAT), a Fourier-based approach that\nefficiently applies circular convolutions to reduce complexity without\nsacrificing representational power. CAT achieves O(NlogN) computations,\nrequires fewer learnable parameters by streamlining fully-connected layers, and\nintroduces no heavier operations, resulting in consistent accuracy improvements\nand about a 10% speedup in naive PyTorch implementations on large-scale\nbenchmarks such as ImageNet-1k and WikiText-103. Grounded in an\nengineering-isomorphism framework, CAT's design not only offers practical\nefficiency and ease of implementation but also provides insights to guide the\ndevelopment of next-generation, high-performance Transformer architectures.\nFinally, our ablation studies highlight the key conditions underlying CAT's\nsuccess, shedding light on broader principles for scalable attention\nmechanisms."
  },
  {
    "arxiv_id": "2504.07640",
    "title": "Enhancing Large Language Models through Neuro-Symbolic Integration and Ontological Reasoning",
    "url": "http://arxiv.org/abs/2504.07640v1",
    "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in natural\nlanguage processing but suffer from inaccuracies and logical inconsistencies\nknown as hallucinations. This compromises their reliability, especially in\ndomains requiring factual accuracy. We propose a neuro-symbolic approach\nintegrating symbolic ontological reasoning and machine learning methods to\nenhance the consistency and reliability of LLM outputs. Our workflow utilizes\nOWL ontologies, a symbolic reasoner (e.g., HermiT) for consistency checking,\nand a lightweight machine learning model (logistic regression) for mapping\nnatural language statements into logical forms compatible with the ontology.\nWhen inconsistencies between LLM outputs and the ontology are detected, the\nsystem generates explanatory feedback to guide the LLM towards a corrected,\nlogically coherent response in an iterative refinement loop. We present a\nworking Python prototype demonstrating this pipeline. Experimental results in a\ndefined domain suggest significant improvements in semantic coherence and\nfactual accuracy of LLM outputs, showcasing the potential of combining LLM\nfluency with the rigor of formal semantics."
  },
  {
    "arxiv_id": "2504.07479",
    "title": "UniCAIM: A Unified CAM/CIM Architecture with Static-Dynamic KV Cache Pruning for Efficient Long-Context LLM Inference",
    "url": "http://arxiv.org/abs/2504.07479v1",
    "abstract": "Transformer-based large language models (LLMs) have achieved impressive\nperformance in various natural language processing (NLP) applications. However,\nthe high memory and computation cost induced by the KV cache limits the\ninference efficiency, especially for long input sequences. Compute-in-memory\n(CIM)-based accelerators have been proposed for LLM acceleration with KV cache\npruning. However, as existing accelerators only support static pruning with a\nfixed pattern or dynamic pruning with primitive implementations, they suffer\nfrom either high accuracy degradation or low efficiency. In this paper, we\npropose a ferroelectric FET (FeFET)-based unified content addressable memory\n(CAM) and CIM architecture, dubbed as UniCAIM. UniCAIM features simultaneous\nsupport for static and dynamic pruning with 3 computation modes: 1) in the CAM\nmode, UniCAIM enables approximate similarity measurement in O(1) time for\ndynamic KV cache pruning with high energy efficiency; 2) in the charge-domain\nCIM mode, static pruning can be supported based on accumulative similarity\nscore, which is much more flexible compared to fixed patterns; 3) in the\ncurrent-domain mode, exact attention computation can be conducted with a subset\nof selected KV cache. We further propose a novel CAM/CIM cell design that\nleverages the multi-level characteristics of FeFETs for signed multibit storage\nof the KV cache and in-place attention computation. With extensive experimental\nresults, we demonstrate UniCAIM can reduce the area-energy-delay product (AEDP)\nby 8.2-831x over the state-ofthe-art CIM-based LLM accelerators at the circuit\nlevel, along with high accuracy comparable with dense attention at the\napplication level, showing its great potential for efficient long-context LLM\ninference."
  },
  {
    "arxiv_id": "2504.07470",
    "title": "Transformer-Based Temporal Information Extraction and Application: A Review",
    "url": "http://arxiv.org/abs/2504.07470v1",
    "abstract": "Temporal information extraction (IE) aims to extract structured temporal\ninformation from unstructured text, thereby uncovering the implicit timelines\nwithin. This technique is applied across domains such as healthcare, newswire,\nand intelligence analysis, aiding models in these areas to perform temporal\nreasoning and enabling human users to grasp the temporal structure of text.\nTransformer-based pre-trained language models have produced revolutionary\nadvancements in natural language processing, demonstrating exceptional\nperformance across a multitude of tasks. Despite the achievements garnered by\nTransformer-based approaches in temporal IE, there is a lack of comprehensive\nreviews on these endeavors. In this paper, we aim to bridge this gap by\nsystematically summarizing and analyzing the body of work on temporal IE using\nTransformers while highlighting potential future research directions."
  },
  {
    "arxiv_id": "2504.07360",
    "title": "Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs",
    "url": "http://arxiv.org/abs/2504.07360v1",
    "abstract": "The adaptation of large language models (LLMs) to time series forecasting\nposes unique challenges, as time series data is continuous in nature, while\nLLMs operate on discrete tokens. Despite the success of LLMs in natural\nlanguage processing (NLP) and other structured domains, aligning time series\ndata with language-based representations while maintaining both predictive\naccuracy and interpretability remains a significant hurdle. Existing methods\nhave attempted to reprogram time series data into text-based forms, but these\noften fall short in delivering meaningful, interpretable results. In this\npaper, we propose a multi-level text alignment framework for time series\nforecasting using LLMs that not only improves prediction accuracy but also\nenhances the interpretability of time series representations. Our method\ndecomposes time series into trend, seasonal, and residual components, which are\nthen reprogrammed into component-specific text representations. We introduce a\nmulti-level alignment mechanism, where component-specific embeddings are\naligned with pre-trained word tokens, enabling more interpretable forecasts.\nExperiments on multiple datasets demonstrate that our method outperforms\nstate-of-the-art models in accuracy while providing good interpretability."
  },
  {
    "arxiv_id": "2504.07274",
    "title": "Language Modeling for the Future of Finance: A Quantitative Survey into Metrics, Tasks, and Data Opportunities",
    "url": "http://arxiv.org/abs/2504.07274v1",
    "abstract": "Recent advances in language modeling have led to growing interest in applying\nNatural Language Processing (NLP) techniques to financial problems, enabling\nnew approaches to analysis and decision-making. To systematically examine this\ntrend, we review 374 NLP research papers published between 2017 and 2024 across\n38 conferences and workshops, with a focused analysis of 221 papers that\ndirectly address finance-related tasks. We evaluate these papers across 11\nqualitative and quantitative dimensions, identifying key trends such as the\nincreasing use of general-purpose language models, steady progress in sentiment\nanalysis and information extraction, and emerging efforts around explainability\nand privacy-preserving methods. We also discuss the use of evaluation metrics,\nhighlighting the importance of domain-specific ones to complement standard\nmachine learning metrics. Our findings emphasize the need for more accessible,\nadaptive datasets and highlight the significance of incorporating financial\ncrisis periods to strengthen model robustness under real-world conditions. This\nsurvey provides a structured overview of NLP research applied to finance and\noffers practical insights for researchers and practitioners working at this\nintersection."
  },
  {
    "arxiv_id": "2504.08712",
    "title": "Beyond Black-Box Predictions: Identifying Marginal Feature Effects in Tabular Transformer Networks",
    "url": "http://arxiv.org/abs/2504.08712v1",
    "abstract": "In recent years, deep neural networks have showcased their predictive power\nacross a variety of tasks. Beyond natural language processing, the transformer\narchitecture has proven efficient in addressing tabular data problems and\nchallenges the previously dominant gradient-based decision trees in these\nareas. However, this predictive power comes at the cost of intelligibility:\nMarginal feature effects are almost completely lost in the black-box nature of\ndeep tabular transformer networks. Alternative architectures that use the\nadditivity constraints of classical statistical regression models can maintain\nintelligible marginal feature effects, but often fall short in predictive power\ncompared to their more complex counterparts. To bridge the gap between\nintelligibility and performance, we propose an adaptation of tabular\ntransformer networks designed to identify marginal feature effects. We provide\ntheoretical justifications that marginal feature effects can be accurately\nidentified, and our ablation study demonstrates that the proposed model\nefficiently detects these effects, even amidst complex feature interactions. To\ndemonstrate the model's predictive capabilities, we compare it to several\ninterpretable as well as black-box models and find that it can match black-box\nperformances while maintaining intelligibility. The source code is available at\nhttps://github.com/OpenTabular/NAMpy."
  },
  {
    "arxiv_id": "2504.08528",
    "title": "On The Landscape of Spoken Language Models: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2504.08528v1",
    "abstract": "The field of spoken language processing is undergoing a shift from training\ncustom-built, task-specific models toward using and optimizing spoken language\nmodels (SLMs) which act as universal speech processing systems. This trend is\nsimilar to the progression toward universal language models that has taken\nplace in the field of (text) natural language processing. SLMs include both\n\"pure\" language models of speech -- models of the distribution of tokenized\nspeech sequences -- and models that combine speech encoders with text language\nmodels, often including both spoken and written input or output. Work in this\narea is very diverse, with a range of terminology and evaluation settings. This\npaper aims to contribute an improved understanding of SLMs via a unifying\nliterature survey of recent work in the context of the evolution of the field.\nOur survey categorizes the work in this area by model architecture, training,\nand evaluation choices, and describes some key challenges and directions for\nfuture work."
  },
  {
    "arxiv_id": "2504.08217",
    "title": "DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset",
    "url": "http://arxiv.org/abs/2504.08217v1",
    "abstract": "At the current stage, deep learning-based methods have demonstrated excellent\ncapabilities in evaluating aerodynamic performance, significantly reducing the\ntime and cost required for traditional computational fluid dynamics (CFD)\nsimulations. However, when faced with the task of processing extremely complex\nthree-dimensional (3D) vehicle models, the lack of large-scale datasets and\ntraining resources, coupled with the inherent diversity and complexity of the\ngeometry of different vehicle models, means that the prediction accuracy and\nversatility of these networks are still not up to the level required for\ncurrent production. In view of the remarkable success of Transformer models in\nthe field of natural language processing and their strong potential in the\nfield of image processing, this study innovatively proposes a point cloud\nlearning framework called DrivAer Transformer (DAT). The DAT structure uses the\nDrivAerNet++ dataset, which contains high-fidelity CFD data of\nindustrial-standard 3D vehicle shapes. enabling accurate estimation of air drag\ndirectly from 3D meshes, thus avoiding the limitations of traditional methods\nsuch as 2D image rendering or signed distance fields (SDF). DAT enables fast\nand accurate drag prediction, driving the evolution of the aerodynamic\nevaluation process and laying the critical foundation for introducing a\ndata-driven approach to automotive design. The framework is expected to\naccelerate the vehicle design process and improve development efficiency."
  },
  {
    "arxiv_id": "2504.08208",
    "title": "How Good Are Large Language Models for Course Recommendation in MOOCs?",
    "url": "http://arxiv.org/abs/2504.08208v1",
    "abstract": "Large Language Models (LLMs) have made significant strides in natural\nlanguage processing and are increasingly being integrated into recommendation\nsystems. However, their potential in educational recommendation systems has yet\nto be fully explored. This paper investigates the use of LLMs as a\ngeneral-purpose recommendation model, leveraging their vast knowledge derived\nfrom large-scale corpora for course recommendation tasks. We explore a variety\nof approaches, ranging from prompt-based methods to more advanced fine-tuning\ntechniques, and compare their performance against traditional recommendation\nmodels. Extensive experiments were conducted on a real-world MOOC dataset,\nevaluating using LLMs as course recommendation systems across key dimensions\nsuch as accuracy, diversity, and novelty. Our results demonstrate that LLMs can\nachieve good performance comparable to traditional models, highlighting their\npotential to enhance educational recommendation systems. These findings pave\nthe way for further exploration and development of LLM-based approaches in the\ncontext of educational recommendations."
  },
  {
    "arxiv_id": "2504.09896",
    "title": "TWSSenti: A Novel Hybrid Framework for Topic-Wise Sentiment Analysis on Social Media Using Transformer Models",
    "url": "http://arxiv.org/abs/2504.09896v1",
    "abstract": "Sentiment analysis is a crucial task in natural language processing (NLP)\nthat enables the extraction of meaningful insights from textual data,\nparticularly from dynamic platforms like Twitter and IMDB. This study explores\na hybrid framework combining transformer-based models, specifically BERT,\nGPT-2, RoBERTa, XLNet, and DistilBERT, to improve sentiment classification\naccuracy and robustness. The framework addresses challenges such as noisy data,\ncontextual ambiguity, and generalization across diverse datasets by leveraging\nthe unique strengths of these models. BERT captures bidirectional context,\nGPT-2 enhances generative capabilities, RoBERTa optimizes contextual\nunderstanding with larger corpora and dynamic masking, XLNet models dependency\nthrough permutation-based learning, and DistilBERT offers efficiency with\nreduced computational overhead while maintaining high accuracy. We demonstrate\ntext cleaning, tokenization, and feature extraction using Term Frequency\nInverse Document Frequency (TF-IDF) and Bag of Words (BoW), ensure high-quality\ninput data for the models. The hybrid approach was evaluated on benchmark\ndatasets Sentiment140 and IMDB, achieving superior accuracy rates of 94\\% and\n95\\%, respectively, outperforming standalone models. The results validate the\neffectiveness of combining multiple transformer models in ensemble-like setups\nto address the limitations of individual architectures. This research\nhighlights its applicability to real-world tasks such as social media\nmonitoring, customer sentiment analysis, and public opinion tracking which\noffers a pathway for future advancements in hybrid NLP frameworks."
  },
  {
    "arxiv_id": "2504.09170",
    "title": "Langformers: Unified NLP Pipelines for Language Models",
    "url": "http://arxiv.org/abs/2504.09170v1",
    "abstract": "Transformer-based language models have revolutionized the field of natural\nlanguage processing (NLP). However, using these models often involves\nnavigating multiple frameworks and tools, as well as writing repetitive\nboilerplate code. This complexity can discourage non-programmers and beginners,\nand even slow down prototyping for experienced developers. To address these\nchallenges, we introduce Langformers, an open-source Python library designed to\nstreamline NLP pipelines through a unified, factory-based interface for large\nlanguage model (LLM) and masked language model (MLM) tasks. Langformers\nintegrates conversational AI, MLM pretraining, text classification, sentence\nembedding/reranking, data labelling, semantic search, and knowledge\ndistillation into a cohesive API, supporting popular platforms such as Hugging\nFace and Ollama. Key innovations include: (1) task-specific factories that\nabstract training, inference, and deployment complexities; (2) built-in memory\nand streaming for conversational agents; and (3) lightweight, modular design\nthat prioritizes ease of use. Documentation: https://langformers.com"
  },
  {
    "arxiv_id": "2504.11277",
    "title": "From Misleading Queries to Accurate Answers: A Three-Stage Fine-Tuning Method for LLMs",
    "url": "http://arxiv.org/abs/2504.11277v1",
    "abstract": "Large language models (LLMs) exhibit excellent performance in natural\nlanguage processing (NLP), but remain highly sensitive to the quality of input\nqueries, especially when these queries contain misleading or inaccurate\ninformation. Existing methods focus on correcting the output, but they often\noverlook the potential of improving the ability of LLMs to detect and correct\nmisleading content in the input itself. In this paper, we propose a novel\nthree-stage fine-tuning method that enhances the ability of LLMs to detect and\ncorrect misleading information in the input, further improving response\naccuracy and reducing hallucinations. Specifically, the three stages include\n(1) training LLMs to identify misleading information, (2) training LLMs to\ncorrect the misleading information using built-in or external knowledge, and\n(3) training LLMs to generate accurate answers based on the corrected queries.\nTo evaluate our method, we conducted experiments on three datasets for the\nhallucination detection task and the question answering (QA) task, as well as\ntwo datasets containing misleading information that we constructed. The\nexperimental results demonstrate that our method significantly improves the\naccuracy and factuality of LLM responses, while also enhancing the ability to\ndetect hallucinations and reducing the generation of hallucinations in the\noutput, particularly when the query contains misleading information. We will\npublicly release our code upon acceptance."
  },
  {
    "arxiv_id": "2504.10551",
    "title": "MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers",
    "url": "http://arxiv.org/abs/2504.10551v1",
    "abstract": "Empirical Risk Minimization (ERM) models often rely on spurious correlations\nbetween features and labels during the learning process, leading to shortcut\nlearning behavior that undermines robustness generalization performance.\nCurrent research mainly targets identifying or mitigating a single shortcut;\nhowever, in real-world scenarios, cues within the data are diverse and unknown.\nIn empirical studies, we reveal that the models rely to varying extents on\ndifferent shortcuts. Compared to weak shortcuts, models depend more heavily on\nstrong shortcuts, resulting in their poor generalization ability. To address\nthese challenges, we propose MiMu, a novel method integrated with\nTransformer-based ERMs designed to Mitigate Multiple shortcut learning\nbehavior, which incorporates self-calibration strategy and self-improvement\nstrategy. In the source model, we preliminarily propose the self-calibration\nstrategy to prevent the model from relying on shortcuts and make overconfident\npredictions. Then, we further design self-improvement strategy in target model\nto reduce the reliance on multiple shortcuts. The random mask strategy involves\nrandomly masking partial attention positions to diversify the focus of target\nmodel other than concentrating on a fixed region. Meanwhile, the adaptive\nattention alignment module facilitates the alignment of attention weights to\nthe calibrated source model, without the need for post-hoc attention maps or\nsupervision. Finally, extensive experiments conducted on Natural Language\nProcessing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu\nin improving robustness generalization abilities."
  },
  {
    "arxiv_id": "2504.10536",
    "title": "Federated Learning with Layer Skipping: Efficient Training of Large Language Models for Healthcare NLP",
    "url": "http://arxiv.org/abs/2504.10536v1",
    "abstract": "Federated learning (FL) enables collaborative model training across\norganizations without sharing raw data, addressing crucial privacy concerns in\nhealthcare natural language processing (NLP). However, training large language\nmodels (LLMs) in federated settings faces significant challenges, including\ncommunication overhead and data heterogeneity. We propose Layer-Skipping\nFederated Learning, where only selected layers of a pre-trained LLM are\nfine-tuned across clients while others remain frozen. Applied to LLaMA 3.2-1B,\nour approach reduces communication costs by approximately 70% while maintaining\nperformance within 2% of centralized training. We evaluate our method on\nclinical NER and classification tasks using i2b2 and MIMIC-III datasets. Our\nexperiments demonstrate that Layer-Skipping FL outperforms competitive\nbaselines, handles non-IID clinical data distributions effectively, and shows\nrobustness when combined with differential privacy. This approach represents a\npractical solution for privacy-preserving collaborative learning in healthcare\nNLP."
  },
  {
    "arxiv_id": "2504.12185",
    "title": "SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data",
    "url": "http://arxiv.org/abs/2504.12185v1",
    "abstract": "In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios."
  },
  {
    "arxiv_id": "2504.12088",
    "title": "AttentionDrop: A Novel Regularization Method for Transformer Models",
    "url": "http://arxiv.org/abs/2504.12088v1",
    "abstract": "Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss."
  },
  {
    "arxiv_id": "2504.11942",
    "title": "ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign Language Translation",
    "url": "http://arxiv.org/abs/2504.11942v1",
    "abstract": "Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure."
  },
  {
    "arxiv_id": "2504.13801",
    "title": "Transformer Encoder and Multi-features Time2Vec for Financial Prediction",
    "url": "http://arxiv.org/abs/2504.13801v1",
    "abstract": "Financial prediction is a complex and challenging task of time series\nanalysis and signal processing, expected to model both short-term fluctuations\nand long-term temporal dependencies. Transformers have remarkable success\nmostly in natural language processing using attention mechanism, which also\ninfluenced the time series community. The ability to capture both short and\nlong-range dependencies helps to understand the financial market and to\nrecognize price patterns, leading to successful applications of Transformers in\nstock prediction. Although, the previous research predominantly focuses on\nindividual features and singular predictions, that limits the model's ability\nto understand broader market trends. In reality, within sectors such as finance\nand technology, companies belonging to the same industry often exhibit\ncorrelated stock price movements.\n  In this paper, we develop a novel neural network architecture by integrating\nTime2Vec with the Encoder of the Transformer model. Based on the study of\ndifferent markets, we propose a novel correlation feature selection method.\nThrough a comprehensive fine-tuning of multiple hyperparameters, we conduct a\ncomparative analysis of our results against benchmark models. We conclude that\nour method outperforms other state-of-the-art encoding methods such as\npositional encoding, and we also conclude that selecting correlation features\nenhance the accuracy of predicting multiple stock prices."
  },
  {
    "arxiv_id": "2504.13558",
    "title": "Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective",
    "url": "http://arxiv.org/abs/2504.13558v1",
    "abstract": "The Transformer model is widely used in various application areas of machine\nlearning, such as natural language processing. This paper investigates the\napproximation of the H\\\"older continuous function class\n$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$\nby Transformers and constructs several Transformers that can overcome the curse\nof dimensionality. These Transformers consist of one self-attention layer with\none head and the softmax function as the activation function, along with\nseveral feedforward layers. For example, to achieve an approximation accuracy\nof $\\epsilon$, if the activation functions of the feedforward layers in the\nTransformer are ReLU and floor, only\n$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers\nare needed, with widths of these layers not exceeding\n$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$.\nIf other activation functions are allowed in the feedforward layers, the width\nof the feedforward layers can be further reduced to a constant. These results\ndemonstrate that Transformers have a strong expressive capability. The\nconstruction in this paper is based on the Kolmogorov-Arnold Representation\nTheorem and does not require the concept of contextual mapping, hence our proof\nis more intuitively clear compared to previous Transformer approximation works.\nAdditionally, the translation technique proposed in this paper helps to apply\nthe previous approximation results of feedforward neural networks to\nTransformer research."
  },
  {
    "arxiv_id": "2504.13531",
    "title": "Can Local Representation Alignment RNNs Solve Temporal Tasks?",
    "url": "http://arxiv.org/abs/2504.13531v1",
    "abstract": "Recurrent Neural Networks (RNNs) are commonly used for real-time processing,\nstreaming data, and cases where the amount of training samples is limited.\nBackpropagation Through Time (BPTT) is the predominant algorithm for training\nRNNs; however, it is frequently criticized for being prone to exploding and\nvanishing gradients and being biologically implausible. In this paper, we\npresent and evaluate a target propagation-based method for RNNs, which uses\nlocal updates and seeks to reduce the said instabilities. Having stable RNN\nmodels increases their practical use in a wide range of fields such as natural\nlanguage processing, time-series forecasting, anomaly detection, control\nsystems, and robotics.\n  The proposed solution uses local representation alignment (LRA). We\nthoroughly analyze the performance of this method, experiment with\nnormalization and different local error functions, and invalidate certain\nassumptions about the behavior of this type of learning. Namely, we demonstrate\nthat despite the decomposition of the network into sub-graphs, the model still\nsuffers from vanishing gradients. We also show that gradient clipping as\nproposed in LRA has little to no effect on network performance. This results in\nan LRA RNN model that is very difficult to train due to vanishing gradients. We\naddress this by introducing gradient regularization in the direction of the\nupdate and demonstrate that this modification promotes gradient flow and\nmeaningfully impacts convergence. We compare and discuss the performance of the\nalgorithm, and we show that the regularized LRA RNN considerably outperforms\nthe unregularized version on three landmark tasks: temporal order, 3-bit\ntemporal order, and random permutation."
  },
  {
    "arxiv_id": "2504.13471",
    "title": "From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs",
    "url": "http://arxiv.org/abs/2504.13471v1",
    "abstract": "In recent years, Large Language Models (LLMs) have significantly advanced\nartificial intelligence by optimizing traditional Natural Language Processing\n(NLP) pipelines, improving performance and generalization. This has spurred\ntheir integration into various systems. Many NLP systems, including ours,\nemploy a \"one-stage\" pipeline directly incorporating LLMs. While effective,\nthis approach incurs substantial costs and latency due to the need for large\nmodel parameters to achieve satisfactory outcomes. This paper introduces a\nthree-stage cost-efficient end-to-end LLM deployment pipeline-including\nprototyping, knowledge transfer, and model compression-to tackle the\ncost-performance dilemma in LLM-based frameworks. Our approach yields a super\ntiny model optimized for cost and performance in online systems, simplifying\nthe system architecture. Initially, by transforming complex tasks into a\nfunction call-based LLM-driven pipeline, an optimal performance prototype\nsystem is constructed to produce high-quality data as a teacher model. The\nsecond stage combines techniques like rejection fine-tuning, reinforcement\nlearning, and knowledge distillation to transfer knowledge to a smaller 0.5B\nstudent model, delivering effective performance at minimal cost. The final\nstage applies quantization and pruning to extremely compress models to 0.4B,\nachieving ultra-low latency and cost. The framework's modular design and\ncross-domain capabilities suggest potential applicability in other NLP areas."
  },
  {
    "arxiv_id": "2504.14891",
    "title": "Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2504.14891v1",
    "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have\nrevolutionized natural language processing by integrating Large Language Models\n(LLMs) with external information retrieval, enabling accurate, up-to-date, and\nverifiable text generation across diverse applications. However, evaluating RAG\nsystems presents unique challenges due to their hybrid architecture that\ncombines retrieval and generation components, as well as their dependence on\ndynamic knowledge sources in the LLM era. In response, this paper provides a\ncomprehensive survey of RAG evaluation methods and frameworks, systematically\nreviewing traditional and emerging evaluation approaches, for system\nperformance, factual accuracy, safety, and computational efficiency in the LLM\nera. We also compile and categorize the RAG-specific datasets and evaluation\nframeworks, conducting a meta-analysis of evaluation practices in high-impact\nRAG research. To the best of our knowledge, this work represents the most\ncomprehensive survey for RAG evaluation, bridging traditional and LLM-driven\nmethods, and serves as a critical resource for advancing RAG development."
  },
  {
    "arxiv_id": "2504.14849",
    "title": "Language Models for Materials Discovery and Sustainability: Progress, Challenges, and Opportunities",
    "url": "http://arxiv.org/abs/2504.14849v1",
    "abstract": "Significant advancements have been made in one of the most critical branches\nof artificial intelligence: natural language processing (NLP). These\nadvancements are exemplified by the remarkable success of OpenAI's GPT-3.5/4\nand the recent release of GPT-4.5, which have sparked a global surge of\ninterest akin to an NLP gold rush. In this article, we offer our perspective on\nthe development and application of NLP and large language models (LLMs) in\nmaterials science. We begin by presenting an overview of recent advancements in\nNLP within the broader scientific landscape, with a particular focus on their\nrelevance to materials science. Next, we examine how NLP can facilitate the\nunderstanding and design of novel materials and its potential integration with\nother methodologies. To highlight key challenges and opportunities, we delve\ninto three specific topics: (i) the limitations of LLMs and their implications\nfor materials science applications, (ii) the creation of a fully automated\nmaterials discovery pipeline, and (iii) the potential of GPT-like tools to\nsynthesize existing knowledge and aid in the design of sustainable materials."
  },
  {
    "arxiv_id": "2504.14706",
    "title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models",
    "url": "http://arxiv.org/abs/2504.14706v2",
    "abstract": "The human-level performance of Large Language Models (LLMs) across various\ntasks has raised expectations for the potential of Artificial Intelligence (AI)\nto possess emotions someday. To explore the capability of current LLMs to\nexpress emotions in their outputs, we conducted an experiment using several\nLLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to\nrole-play as agents answering questions with specified emotional states. We\ndefined the emotional states using Russell's Circumplex model, a\nwell-established framework that characterizes emotions along the\nsleepy-activated (arousal) and pleasure-displeasure (valence) axes. We chose\nthis model for its simplicity, utilizing two continuous parameters, which\nallows for better controllability in applications involving continuous changes\nin emotional states. The responses generated were evaluated using a sentiment\nanalysis model, independent of the LLMs, trained on the GoEmotions dataset. The\nevaluation showed that the emotional states of the generated answers were\nconsistent with the specifications, demonstrating the LLMs' capability for\nemotional expression. This indicates the potential for LLM-based AI agents to\nsimulate emotions, opening up a wide range of applications for emotion-based\ninteractions, such as advisors or consultants who can provide advice or\nopinions with a personal touch."
  },
  {
    "arxiv_id": "2504.14569",
    "title": "NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models",
    "url": "http://arxiv.org/abs/2504.14569v1",
    "abstract": "Large language models (LLMs) exhibit remarkable performance across various\nnatural language processing tasks but suffer from immense computational and\nmemory demands, limiting their deployment in resource-constrained environments.\nTo address this challenge, we propose NoWag: (Normalized Weight and Activation\nGuided Compression), a unified framework for zero-shot shape preserving\ncompression algorithms. We compressed Llama-2 7B/13B/70B and Llama-3 8/70BB\nmodels, using two popular forms of shape-preserving compression, vector\nquantization NoWag-VQ (NoWag for Vector Quantization), and\nunstructured/semi-structured pruning NoWag-P (NoWag for Pruning). We found that\nNoWag-VQ significantly outperforms state-of-the-art zero shot VQ, and that\nNoWag-P performs competitively against state-of-the-art methods. These results\nsuggest commonalities between these compression paradigms that could inspire\nfuture work. Our code is available at https://github.com/LawrenceRLiu/NoWag"
  },
  {
    "arxiv_id": "2504.14429",
    "title": "ResNetVLLM-2: Addressing ResNetVLLM's Multi-Modal Hallucinations",
    "url": "http://arxiv.org/abs/2504.14429v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing\n(NLP) tasks, but they suffer from hallucination, generating plausible yet\nfactually incorrect content. This issue extends to Video-Language Models\n(VideoLLMs), where textual descriptions may inaccurately represent visual\ncontent, resulting in multi-modal hallucinations. In this paper, we address\nhallucination in ResNetVLLM, a video-language model combining ResNet visual\nencoders with LLMs. We introduce a two-step protocol: (1) a faithfulness\ndetection strategy that uses a modified Lynx model to assess semantic alignment\nbetween generated captions and ground-truth video references, and (2) a\nhallucination mitigation strategy using Retrieval-Augmented Generation (RAG)\nwith an ad-hoc knowledge base dynamically constructed during inference. Our\nenhanced model, ResNetVLLM-2, reduces multi-modal hallucinations by\ncross-verifying generated content against external knowledge, improving factual\nconsistency. Evaluation on the ActivityNet-QA benchmark demonstrates a\nsubstantial accuracy increase from 54.8% to 65.3%, highlighting the\neffectiveness of our hallucination detection and mitigation strategies in\nenhancing video-language model reliability."
  },
  {
    "arxiv_id": "2504.14287",
    "title": "Probing the Subtle Ideological Manipulation of Large Language Models",
    "url": "http://arxiv.org/abs/2504.14287v1",
    "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nbut concerns have emerged about their susceptibility to ideological\nmanipulation, particularly in politically sensitive areas. Prior work has\nfocused on binary Left-Right LLM biases, using explicit prompts and fine-tuning\non political QA datasets. In this work, we move beyond this binary approach to\nexplore the extent to which LLMs can be influenced across a spectrum of\npolitical ideologies, from Progressive-Left to Conservative-Right. We introduce\na novel multi-task dataset designed to reflect diverse ideological positions\nthrough tasks such as ideological QA, statement ranking, manifesto cloze\ncompletion, and Congress bill comprehension. By fine-tuning three LLMs-Phi-2,\nMistral, and Llama-3-on this dataset, we evaluate their capacity to adopt and\nexpress these nuanced ideologies. Our findings indicate that fine-tuning\nsignificantly enhances nuanced ideological alignment, while explicit prompts\nprovide only minor refinements. This highlights the models' susceptibility to\nsubtle ideological manipulation, suggesting a need for more robust safeguards\nto mitigate these risks."
  },
  {
    "arxiv_id": "2504.14165",
    "title": "Self-Correction Makes LLMs Better Parsers",
    "url": "http://arxiv.org/abs/2504.14165v1",
    "abstract": "Large language models (LLMs) have achieved remarkable success across various\nnatural language processing (NLP) tasks. However, recent studies suggest that\nthey still face challenges in performing fundamental NLP tasks essential for\ndeep language understanding, particularly syntactic parsing. In this paper, we\nconduct an in-depth analysis of LLM parsing capabilities, delving into the\nspecific shortcomings of their parsing results. We find that LLMs may stem from\nlimitations to fully leverage grammar rules in existing treebanks, which\nrestricts their capability to generate valid syntactic structures. To help LLMs\nacquire knowledge without additional training, we propose a self-correction\nmethod that leverages grammar rules from existing treebanks to guide LLMs in\ncorrecting previous errors. Specifically, we automatically detect potential\nerrors and dynamically search for relevant rules, offering hints and examples\nto guide LLMs in making corrections themselves. Experimental results on three\ndatasets with various LLMs, demonstrate that our method significantly improves\nperformance in both in-domain and cross-domain settings on the English and\nChinese datasets."
  },
  {
    "arxiv_id": "2504.16005",
    "title": "CAPO: Cost-Aware Prompt Optimization",
    "url": "http://arxiv.org/abs/2504.16005v1",
    "abstract": "Large language models (LLMs) have revolutionized natural language processing\nby solving a wide range of tasks simply guided by a prompt. Yet their\nperformance is highly sensitive to prompt formulation. While automated prompt\noptimization addresses this challenge by finding optimal prompts, current\nmethods require a substantial number of LLM calls and input tokens, making\nprompt optimization expensive. We introduce CAPO (Cost-Aware Prompt\nOptimization), an algorithm that enhances prompt optimization efficiency by\nintegrating AutoML techniques. CAPO is an evolutionary approach with LLMs as\noperators, incorporating racing to save evaluations and multi-objective\noptimization to balance performance with prompt length. It jointly optimizes\ninstructions and few-shot examples while leveraging task descriptions for\nimproved robustness. Our extensive experiments across diverse datasets and LLMs\ndemonstrate that CAPO outperforms state-of-the-art discrete prompt optimization\nmethods in 11/15 cases with improvements up to 21%p. Our algorithm achieves\nbetter performances already with smaller budgets, saves evaluations through\nracing, and decreases average prompt length via a length penalty, making it\nboth cost-efficient and cost-aware. Even without few-shot examples, CAPO\noutperforms its competitors and generally remains robust to initial prompts.\nCAPO represents an important step toward making prompt optimization more\npowerful and accessible by improving cost-efficiency."
  },
  {
    "arxiv_id": "2504.15983",
    "title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models",
    "url": "http://arxiv.org/abs/2504.15983v1",
    "abstract": "The demand for efficient natural language processing (NLP) systems has led to\nthe development of lightweight language models. Previous work in this area has\nprimarily focused on manual design or training-based neural architecture search\n(NAS) methods. Recently, zero-shot NAS methods have been proposed for\nevaluating language models without the need for training. However, prevailing\napproaches to zero-shot NAS often face challenges such as biased evaluation\nmetrics and computational inefficiencies. In this paper, we introduce\nweight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored\nfor lightweight language models. Our approach utilizes two evaluation proxies:\nthe parameter count and the number of principal components with cumulative\ncontribution exceeding $\\eta$ in the feed-forward neural (FFN) layer.\nAdditionally, by eliminating the need for gradient computations, we optimize\nthe evaluation time, thus enhancing the efficiency of designing and evaluating\nlightweight language models. We conduct a comparative analysis on the GLUE and\nSQuAD datasets to evaluate our approach. The results demonstrate that our\nmethod significantly reduces training time compared to one-shot NAS methods and\nachieves higher scores in the testing phase compared to previous\nstate-of-the-art training-based methods. Furthermore, we perform ranking\nevaluations on a dataset sampled from the FlexiBERT search space. Our approach\nexhibits superior ranking correlation and further reduces solving time compared\nto other zero-shot NAS methods that require gradient computation."
  },
  {
    "arxiv_id": "2504.16921",
    "title": "IberBench: LLM Evaluation on Iberian Languages",
    "url": "http://arxiv.org/abs/2504.16921v1",
    "abstract": "Large Language Models (LLMs) remain difficult to evaluate comprehensively,\nparticularly for languages other than English, where high-quality data is often\nlimited. Existing benchmarks and leaderboards are predominantly\nEnglish-centric, with only a few addressing other languages. These benchmarks\nfall short in several key areas: they overlook the diversity of language\nvarieties, prioritize fundamental Natural Language Processing (NLP)\ncapabilities over tasks of industrial relevance, and are static. With these\naspects in mind, we present IberBench, a comprehensive and extensible benchmark\ndesigned to assess LLM performance on both fundamental and industry-relevant\nNLP tasks, in languages spoken across the Iberian Peninsula and Ibero-America.\nIberBench integrates 101 datasets from evaluation campaigns and recent\nbenchmarks, covering 22 task categories such as sentiment and emotion analysis,\ntoxicity detection, and summarization. The benchmark addresses key limitations\nin current evaluation practices, such as the lack of linguistic diversity and\nstatic evaluation setups by enabling continual updates and community-driven\nmodel and dataset submissions moderated by a committee of experts. We evaluate\n23 LLMs ranging from 100 million to 14 billion parameters and provide empirical\ninsights into their strengths and limitations. Our findings indicate that (i)\nLLMs perform worse on industry-relevant tasks than in fundamental ones, (ii)\nperformance is on average lower for Galician and Basque, (iii) some tasks show\nresults close to random, and (iv) in other tasks LLMs perform above random but\nbelow shared task systems. IberBench offers open-source implementations for the\nentire evaluation pipeline, including dataset normalization and hosting,\nincremental evaluation of LLMs, and a publicly accessible leaderboard."
  },
  {
    "arxiv_id": "2504.16768",
    "title": "How Effective are Generative Large Language Models in Performing Requirements Classification?",
    "url": "http://arxiv.org/abs/2504.16768v1",
    "abstract": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance."
  },
  {
    "arxiv_id": "2504.16761",
    "title": "Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism",
    "url": "http://arxiv.org/abs/2504.16761v1",
    "abstract": "Image description generation is essential for accessibility and AI\nunderstanding of visual content. Recent advancements in deep learning have\nsignificantly improved natural language processing and computer vision. In this\nwork, we propose Tri-FusionNet, a novel image description generation model that\nintegrates transformer modules: a Vision Transformer (ViT) encoder module with\ndual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decoder\nmodule, and a Contrastive Language-Image Pre-Training (CLIP) integrating\nmodule. The ViT encoder, enhanced with dual attention, focuses on relevant\nspatial regions and linguistic context, improving image feature extraction. The\nRoBERTa decoder is employed to generate precise textual descriptions. CLIP's\nintegrating module aligns visual and textual data through contrastive learning,\nensuring effective combination of both modalities. This fusion of ViT, RoBERTa,\nand CLIP, along with dual attention, enables the model to produce more\naccurate, contextually rich, and flexible descriptions. The proposed framework\ndemonstrated competitive performance on the Flickr30k and Flickr8k datasets,\nwith BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scores\nof 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of\n0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scores\nof 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The results\ndemonstrate the effectiveness of Tri-FusionNet in generating high-quality image\ndescriptions."
  },
  {
    "arxiv_id": "2504.16574",
    "title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression",
    "url": "http://arxiv.org/abs/2504.16574v1",
    "abstract": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs."
  },
  {
    "arxiv_id": "2504.16448",
    "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
    "url": "http://arxiv.org/abs/2504.16448v1",
    "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks."
  },
  {
    "arxiv_id": "2504.16269",
    "title": "COBRA: Algorithm-Architecture Co-optimized Binary Transformer Accelerator for Edge Inference",
    "url": "http://arxiv.org/abs/2504.16269v1",
    "abstract": "Transformer-based models have demonstrated superior performance in various\nfields, including natural language processing and computer vision. However,\ntheir enormous model size and high demands in computation, memory, and\ncommunication limit their deployment to edge platforms for local, secure\ninference. Binary transformers offer a compact, low-complexity solution for\nedge deployment with reduced bandwidth needs and acceptable accuracy. However,\nexisting binary transformers perform inefficiently on current hardware due to\nthe lack of binary specific optimizations. To address this, we introduce COBRA,\nan algorithm-architecture co-optimized binary Transformer accelerator for edge\ncomputing. COBRA features a real 1-bit binary multiplication unit, enabling\nmatrix operations with -1, 0, and +1 values, surpassing ternary methods. With\nfurther hardware-friendly optimizations in the attention block, COBRA achieves\nup to 3,894.7 GOPS throughput and 448.7 GOPS/Watt energy efficiency on edge\nFPGAs, delivering a 311x energy efficiency improvement over GPUs and a 3.5x\nthroughput improvement over the state-of-the-art binary accelerator, with only\nnegligible inference accuracy degradation."
  },
  {
    "arxiv_id": "2504.17674",
    "title": "Energy Considerations of Large Language Model Inference and Efficiency Optimizations",
    "url": "http://arxiv.org/abs/2504.17674v1",
    "abstract": "As large language models (LLMs) scale in size and adoption, their\ncomputational and environmental costs continue to rise. Prior benchmarking\nefforts have primarily focused on latency reduction in idealized settings,\noften overlooking the diverse real-world inference workloads that shape energy\nuse. In this work, we systematically analyze the energy implications of common\ninference efficiency optimizations across diverse Natural Language Processing\n(NLP) and generative Artificial Intelligence (AI) workloads, including\nconversational AI and code generation. We introduce a modeling approach that\napproximates real-world LLM workflows through a binning strategy for\ninput-output token distributions and batch size variations. Our empirical\nanalysis spans software frameworks, decoding strategies, GPU architectures,\nonline and offline serving settings, and model parallelism configurations. We\nshow that the effectiveness of inference optimizations is highly sensitive to\nworkload geometry, software stack, and hardware accelerators, demonstrating\nthat naive energy estimates based on FLOPs or theoretical GPU utilization\nsignificantly underestimate real-world energy consumption. Our findings reveal\nthat the proper application of relevant inference efficiency optimizations can\nreduce total energy use by up to 73% from unoptimized baselines. These insights\nprovide a foundation for sustainable LLM deployment and inform energy-efficient\ndesign strategies for future AI infrastructure."
  },
  {
    "arxiv_id": "2504.17018",
    "title": "LLM impact on BLV programming",
    "url": "http://arxiv.org/abs/2504.17018v1",
    "abstract": "Large Language Models (LLMs) are rapidly becoming integral to a wide range of\ntools, tasks, and problem-solving processes, especially in software\ndevelopment. Originally designed for natural language processing tasks such as\ntext generation, LLMs are increasingly being used to assist both professionals\nand students in writing code. This growing reliance on LLM-based tools is\nreshaping programming workflows and task execution. In this study, we explore\nthe impact of these technologies on blind and low-vision (BLV) developers. Our\nreview of existing literature indicates that while LLMs help mitigate some of\nthe challenges faced by BLV programmers, they also introduce new forms of\ninaccessibility. We conducted an evaluation of five popular LLM-powered\nintegrated development environments (IDEs), assessing their performance across\na comprehensive set of programming tasks. Our findings highlight several\nunsupported scenarios, instances of incorrect model output, and notable\nlimitations in interaction support for specific tasks. Through observing BLV\ndevelopers as they engaged in coding activities, we uncovered key interaction\nbarriers that go beyond model accuracy or code generation quality. This paper\noutlines the challenges and corresponding opportunities for improving\naccessibility in the context of generative AI-assisted programming. Addressing\nthese issues can meaningfully enhance the programming experience for BLV\ndevelopers. As the generative AI revolution continues to unfold, it must also\naddress the unique burdens faced by this community."
  },
  {
    "arxiv_id": "2504.16977",
    "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages",
    "url": "http://arxiv.org/abs/2504.16977v1",
    "abstract": "Tokenization is a critical component of Natural Language Processing (NLP),\nespecially for low resource languages, where subword segmentation influences\nvocabulary structure and downstream task accuracy. Although Byte Pair Encoding\n(BPE) is a standard tokenization method in multilingual language models, its\nsuitability for Named Entity Recognition (NER) in low resource Indic languages\nremains underexplored due to its limitations in handling morphological\ncomplexity. In this work, we systematically compare BPE, SentencePiece, and\nCharacter Level tokenization strategies using IndicBERT for NER tasks in low\nresource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as\nextremely low resource Indic languages like Santali, Manipuri, and Sindhi. We\nassess both intrinsic linguistic properties tokenization efficiency, out of\nvocabulary (OOV) rates, and morphological preservation as well as extrinsic\ndownstream performance, including fine tuning and zero shot cross lingual\ntransfer.\n  Our experiments show that SentencePiece is a consistently better performing\napproach than BPE for NER in low resource Indic Languages, particularly in zero\nshot cross lingual settings, as it better preserves entity consistency. While\nBPE provides the most compact tokenization form, it is not capable of\ngeneralization because it misclassifies or even fails to recognize entity\nlabels when tested on unseen languages. In contrast, SentencePiece constitutes\na better linguistic structural preservation model, benefiting extremely low\nresource and morphologically rich Indic languages, such as Santali and\nManipuri, for superior entity recognition, as well as high generalization\nacross scripts, such as Sindhi, written in Arabic. The results point to\nSentencePiece as the more effective tokenization strategy for NER within\nmultilingual and low resource Indic NLP applications."
  },
  {
    "arxiv_id": "2504.18158",
    "title": "E-InMeMo: Enhanced Prompting for Visual In-Context Learning",
    "url": "http://arxiv.org/abs/2504.18158v1",
    "abstract": "Large-scale models trained on extensive datasets have become the standard due\nto their strong generalizability across diverse tasks. In-context learning\n(ICL), widely used in natural language processing, leverages these models by\nproviding task-specific prompts without modifying their parameters. This\nparadigm is increasingly being adapted for computer vision, where models\nreceive an input-output image pair, known as an in-context pair, alongside a\nquery image to illustrate the desired output. However, the success of visual\nICL largely hinges on the quality of these prompts. To address this, we propose\nEnhanced Instruct Me More (E-InMeMo), a novel approach that incorporates\nlearnable perturbations into in-context pairs to optimize prompting. Through\nextensive experiments on standard vision tasks, E-InMeMo demonstrates superior\nperformance over existing state-of-the-art methods. Notably, it improves mIoU\nscores by 7.99 for foreground segmentation and by 17.04 for single object\ndetection when compared to the baseline without learnable prompts. These\nresults highlight E-InMeMo as a lightweight yet effective strategy for\nenhancing visual ICL. Code is publicly available at:\nhttps://github.com/Jackieam/E-InMeMo"
  },
  {
    "arxiv_id": "2504.20020",
    "title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models",
    "url": "http://arxiv.org/abs/2504.20020v1",
    "abstract": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications."
  },
  {
    "arxiv_id": "2504.19746",
    "title": "FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs",
    "url": "http://arxiv.org/abs/2504.19746v1",
    "abstract": "Large language models (LLMs) have significantly advanced the natural language\nprocessing paradigm but impose substantial demands on memory and computational\nresources. Quantization is one of the most effective ways to reduce memory\nconsumption of LLMs. However, advanced single-precision quantization methods\nexperience significant accuracy degradation when quantizing to ultra-low bits.\nExisting mixed-precision quantization methods are quantized by groups with\ncoarse granularity. Employing high precision for group data leads to\nsubstantial memory overhead, whereas low precision severely impacts model\naccuracy. To address this issue, we propose FineQ, software-hardware co-design\nfor low-bit fine-grained mixed-precision quantization of LLMs. First, FineQ\npartitions the weights into finer-grained clusters and considers the\ndistribution of outliers within these clusters, thus achieving a balance\nbetween model accuracy and memory overhead. Then, we propose an outlier\nprotection mechanism within clusters that uses 3 bits to represent outliers and\nintroduce an encoding scheme for index and data concatenation to enable aligned\nmemory access. Finally, we introduce an accelerator utilizing temporal coding\nthat effectively supports the quantization algorithm while simplifying the\nmultipliers in the systolic array. FineQ achieves higher model accuracy\ncompared to the SOTA mixed-precision quantization algorithm at a close average\nbit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency\nand reduces the area of the systolic array by 61.2%."
  },
  {
    "arxiv_id": "2504.19675",
    "title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs",
    "url": "http://arxiv.org/abs/2504.19675v1",
    "abstract": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts."
  },
  {
    "arxiv_id": "2504.19467",
    "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text",
    "url": "http://arxiv.org/abs/2504.19467v1",
    "abstract": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard"
  },
  {
    "arxiv_id": "2504.19267",
    "title": "VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?",
    "url": "http://arxiv.org/abs/2504.19267v1",
    "abstract": "Visual storytelling is an interdisciplinary field combining computer vision\nand natural language processing to generate cohesive narratives from sequences\nof images. This paper presents a novel approach that leverages recent\nadvancements in multimodal models, specifically adapting transformer-based\narchitectures and large multimodal models, for the visual storytelling task.\nLeveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT\nmodel produces visually grounded, contextually appropriate narratives. We\naddress the limitations of traditional evaluation metrics, such as BLEU,\nMETEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we\nutilize RoViST and GROOVIST, novel reference-free metrics designed to assess\nvisual storytelling, focusing on visual grounding, coherence, and\nnon-redundancy. These metrics provide a more nuanced evaluation of narrative\nquality, aligning closely with human judgment."
  },
  {
    "arxiv_id": "2504.20842",
    "title": "Language Model for Large-Text Transmission in Noisy Quantum Communications",
    "url": "http://arxiv.org/abs/2504.20842v1",
    "abstract": "Quantum communication has the potential to revolutionize information\nprocessing, providing unparalleled security and increased capacity compared to\nits classical counterpart by using the principles of quantum mechanics.\nHowever, the presence of noise remains a major barrier to realizing these\nadvantages. While strategies like quantum error correction and mitigation have\nbeen developed to address this challenge, they often come with substantial\noverhead in physical qubits or sample complexity, limiting their practicality\nfor large-scale information transfer. Here, we present an alternative approach:\napplying machine learning frameworks from natural language processing to\nenhance the performance of noisy quantum communications, focusing on superdense\ncoding. By employing bidirectional encoder representations from transformers\n(BERT), a model known for its capabilities in natural language processing, we\ndemonstrate improvements in information transfer efficiency without resorting\nto conventional error correction or mitigation techniques. These results mark a\nstep toward the practical realization of a scalable and resilient quantum\ninternet."
  },
  {
    "arxiv_id": "2504.20609",
    "title": "WenyanGPT: A Large Language Model for Classical Chinese Tasks",
    "url": "http://arxiv.org/abs/2504.20609v1",
    "abstract": "Classical Chinese, as the core carrier of Chinese culture, plays a crucial\nrole in the inheritance and study of ancient literature. However, existing\nnatural language processing models primarily optimize for Modern Chinese,\nresulting in inadequate performance on Classical Chinese. This paper presents a\ncomprehensive solution for Classical Chinese language processing. By continuing\npre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we\nconstruct a large language model, WenyanGPT, which is specifically designed for\nClassical Chinese tasks. Additionally, we develop an evaluation benchmark\ndataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that\nWenyanGPT significantly outperforms current advanced LLMs in various Classical\nChinese tasks. We make the model's training data, instruction fine-tuning\ndata\\footnote, and evaluation benchmark dataset publicly available to promote\nfurther research and development in the field of Classical Chinese processing."
  },
  {
    "arxiv_id": "2504.20472",
    "title": "Robustness via Referencing: Defending against Prompt Injection Attacks by Referencing the Executed Instruction",
    "url": "http://arxiv.org/abs/2504.20472v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance and\nhave come to dominate the field of natural language processing (NLP) across\nvarious tasks. However, due to their strong instruction-following capabilities\nand inability to distinguish between instructions and data content, LLMs are\nvulnerable to prompt injection attacks. These attacks manipulate LLMs into\ndeviating from the original input instructions and executing maliciously\ninjected instructions within data content, such as web documents retrieved from\nsearch engines. Existing defense methods, including prompt-engineering and\nfine-tuning approaches, typically instruct models to follow the original input\ninstructions while suppressing their tendencies to execute injected\ninstructions. However, our experiments reveal that suppressing\ninstruction-following tendencies is challenging. Through analyzing failure\ncases, we observe that although LLMs tend to respond to any recognized\ninstructions, they are aware of which specific instructions they are executing\nand can correctly reference them within the original prompt. Motivated by these\nfindings, we propose a novel defense method that leverages, rather than\nsuppresses, the instruction-following abilities of LLMs. Our approach prompts\nLLMs to generate responses that include both answers and their corresponding\ninstruction references. Based on these references, we filter out answers not\nassociated with the original input instructions. Comprehensive experiments\ndemonstrate that our method outperforms prompt-engineering baselines and\nachieves performance comparable to fine-tuning methods, reducing the attack\nsuccess rate (ASR) to 0 percent in some scenarios. Moreover, our approach has\nminimal impact on overall utility."
  },
  {
    "arxiv_id": "2504.20356",
    "title": "What Causes Knowledge Loss in Multilingual Language Models?",
    "url": "http://arxiv.org/abs/2504.20356v1",
    "abstract": "Cross-lingual transfer in natural language processing (NLP) models enhances\nmultilingual performance by leveraging shared linguistic knowledge. However,\ntraditional methods that process all data simultaneously often fail to mimic\nreal-world scenarios, leading to challenges like catastrophic forgetting, where\nfine-tuning on new tasks degrades performance on previously learned ones. Our\nstudy explores this issue in multilingual contexts, focusing on linguistic\ndifferences affecting representational learning rather than just model\nparameters. We experiment with 52 languages using LoRA adapters of varying\nranks to evaluate non-shared, partially shared, and fully shared parameters.\nOur aim is to see if parameter sharing through adapters can mitigate forgetting\nwhile preserving prior knowledge. We find that languages using non-Latin\nscripts are more susceptible to catastrophic forgetting, whereas those written\nin Latin script facilitate more effective cross-lingual transfer."
  },
  {
    "arxiv_id": "2504.21706",
    "title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey",
    "url": "http://arxiv.org/abs/2504.21706v1",
    "abstract": "Detecting plant diseases is a crucial aspect of modern agriculture - it plays\na key role in maintaining crop health and increasing overall yield. Traditional\napproaches, though still valuable, often rely on manual inspection or\nconventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering benefits such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This survey\nexplores the application of ViTs in precision agriculture, covering tasks from\nclassification to detection and segmentation. We begin by introducing the\nfoundational architecture of ViTs and discuss their transition from Natural\nLanguage Processing (NLP) to computer vision. The discussion includes the\nconcept of inductive bias in traditional models like Convolutional Neural\nNetworks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive\nreview of recent literature, focusing on key methodologies, datasets, and\nperformance metrics. The survey also includes a comparative analysis of CNNs\nand ViTs, with a look at hybrid models and performance enhancements. Technical\nchallenges - such as data requirements, computational demands, and model\ninterpretability - are addressed alongside potential solutions. Finally, we\noutline potential research directions and technological advancements that could\nfurther support the integration of ViTs in real-world agricultural settings.\nOur goal with this study is to offer practitioners and researchers a deeper\nunderstanding of how ViTs are poised to transform smart and precision\nagriculture."
  },
  {
    "arxiv_id": "2504.21635",
    "title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model",
    "url": "http://arxiv.org/abs/2504.21635v1",
    "abstract": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools."
  },
  {
    "arxiv_id": "2504.21553",
    "title": "Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models",
    "url": "http://arxiv.org/abs/2504.21553v1",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes."
  },
  {
    "arxiv_id": "2504.21475",
    "title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines",
    "url": "http://arxiv.org/abs/2504.21475v1",
    "abstract": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic."
  },
  {
    "arxiv_id": "2504.21372",
    "title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction",
    "url": "http://arxiv.org/abs/2504.21372v1",
    "abstract": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features."
  },
  {
    "arxiv_id": "2505.00649",
    "title": "Investigating Task Arithmetic for Zero-Shot Information Retrieval",
    "url": "http://arxiv.org/abs/2505.00649v1",
    "abstract": "Large Language Models (LLMs) have shown impressive zero-shot performance\nacross a variety of Natural Language Processing tasks, including document\nre-ranking. However, their effectiveness degrades on unseen tasks and domains,\nlargely due to shifts in vocabulary and word distributions. In this paper, we\ninvestigate Task Arithmetic, a technique that combines the weights of LLMs\npre-trained on different tasks or domains via simple mathematical operations,\nsuch as addition or subtraction, to adapt retrieval models without requiring\nadditional fine-tuning. Our method is able to synthesize diverse tasks and\ndomain knowledge into a single model, enabling effective zero-shot adaptation\nin different retrieval contexts. Extensive experiments on publicly available\nscientific, biomedical, and multilingual datasets show that our method improves\nstate-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in\nP@10. In addition to these empirical gains, our analysis provides insights into\nthe strengths and limitations of Task Arithmetic as a practical strategy for\nzero-shot learning and model adaptation. We make our code publicly available at\nhttps://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR."
  },
  {
    "arxiv_id": "2505.00057",
    "title": "A Report on the llms evaluating the high school questions",
    "url": "http://arxiv.org/abs/2505.00057v1",
    "abstract": "This report aims to evaluate the performance of large language models (LLMs)\nin solving high school science questions and to explore their potential\napplications in the educational field. With the rapid development of LLMs in\nthe field of natural language processing, their application in education has\nattracted widespread attention. This study selected mathematics exam questions\nfrom the college entrance examinations (2019-2023) as evaluation data and\nutilized at least eight LLM APIs to provide answers. A comprehensive assessment\nwas conducted based on metrics such as accuracy, response time, logical\nreasoning, and creativity. Through an in-depth analysis of the evaluation\nresults, this report reveals the strengths and weaknesses of LLMs in handling\nhigh school science questions and discusses their implications for educational\npractice. The findings indicate that although LLMs perform excellently in\ncertain aspects, there is still room for improvement in logical reasoning and\ncreative problem-solving. This report provides an empirical foundation for\nfurther research and application of LLMs in the educational field and offers\nsuggestions for improvement."
  },
  {
    "arxiv_id": "2505.01315",
    "title": "Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System",
    "url": "http://arxiv.org/abs/2505.01315v1",
    "abstract": "The recent growth in the use of Large Language Models has made them\nvulnerable to sophisticated adversarial assaults, manipulative prompts, and\nencoded malicious inputs. Existing countermeasures frequently necessitate\nretraining models, which is computationally costly and impracticable for\ndeployment. Without the need for retraining or fine-tuning, this study presents\na unique defense paradigm that allows LLMs to recognize, filter, and defend\nagainst adversarial or malicious inputs on their own. There are two main parts\nto the suggested framework: (1) A prompt filtering module that uses\nsophisticated Natural Language Processing (NLP) techniques, including zero-shot\nclassification, keyword analysis, and encoded content detection (e.g. base64,\nhexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and\n(2) A summarization module that processes and summarizes adversarial research\nliterature to give the LLM context-aware defense knowledge. This approach\nstrengthens LLMs' resistance to adversarial exploitation by fusing text\nextraction, summarization, and harmful prompt analysis. According to\nexperimental results, this integrated technique has a 98.71% success rate in\nidentifying harmful patterns, manipulative language structures, and encoded\nprompts. By employing a modest amount of adversarial research literature as\ncontext, the methodology also allows the model to react correctly to harmful\ninputs with a larger percentage of jailbreak resistance and refusal rate. While\nmaintaining the quality of LLM responses, the framework dramatically increases\nLLM's resistance to hostile misuse, demonstrating its efficacy as a quick and\neasy substitute for time-consuming, retraining-based defenses."
  },
  {
    "arxiv_id": "2505.00976",
    "title": "Attack and defense techniques in large language models: A survey and new perspectives",
    "url": "http://arxiv.org/abs/2505.00976v1",
    "abstract": "Large Language Models (LLMs) have become central to numerous natural language\nprocessing tasks, but their vulnerabilities present significant security and\nethical challenges. This systematic survey explores the evolving landscape of\nattack and defense techniques in LLMs. We classify attacks into adversarial\nprompt attack, optimized attacks, model theft, as well as attacks on\napplication of LLMs, detailing their mechanisms and implications. Consequently,\nwe analyze defense strategies, including prevention-based and detection-based\ndefense methods. Although advances have been made, challenges remain to adapt\nto the dynamic threat landscape, balance usability with robustness, and address\nresource constraints in defense implementation. We highlight open problems,\nincluding the need for adaptive scalable defenses, explainable security\ntechniques, and standardized evaluation frameworks. This survey provides\nactionable insights and directions for developing secure and resilient LLMs,\nemphasizing the importance of interdisciplinary collaboration and ethical\nconsiderations to mitigate risks in real-world applications."
  },
  {
    "arxiv_id": "2505.00926",
    "title": "How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias",
    "url": "http://arxiv.org/abs/2505.00926v1",
    "abstract": "Language recognition tasks are fundamental in natural language processing\n(NLP) and have been widely used to benchmark the performance of large language\nmodels (LLMs). These tasks also play a crucial role in explaining the working\nmechanisms of transformers. In this work, we focus on two representative tasks\nin the category of regular language recognition, known as `even pairs' and\n`parity check', the aim of which is to determine whether the occurrences of\ncertain subsequences in a given sequence are even. Our goal is to explore how a\none-layer transformer, consisting of an attention layer followed by a linear\nlayer, learns to solve these tasks by theoretically analyzing its training\ndynamics under gradient descent. While even pairs can be solved directly by a\none-layer transformer, parity check need to be solved by integrating\nChain-of-Thought (CoT), either into the inference stage of a transformer\nwell-trained for the even pairs task, or into the training of a one-layer\ntransformer. For both problems, our analysis shows that the joint training of\nattention and linear layers exhibits two distinct phases. In the first phase,\nthe attention layer grows rapidly, mapping data sequences into separable\nvectors. In the second phase, the attention layer becomes stable, while the\nlinear layer grows logarithmically and approaches in direction to a max-margin\nhyperplane that correctly separates the attention layer outputs into positive\nand negative samples, and the loss decreases at a rate of $O(1/t)$. Our\nexperiments validate those theoretical results."
  },
  {
    "arxiv_id": "2505.02795",
    "title": "HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models",
    "url": "http://arxiv.org/abs/2505.02795v1",
    "abstract": "Recently, large language models (LLMs) have achieved remarkable\nbreakthroughs, revolutionizing the natural language processing domain and\nbeyond. Due to immense parameter sizes, fine-tuning these models with private\ndata for diverse downstream tasks has become mainstream. Though federated\nlearning (FL) offers a promising solution for fine-tuning LLMs without sharing\nraw data, substantial computing costs hinder its democratization. Moreover, in\nreal-world scenarios, private client devices often possess heterogeneous\ncomputing resources, further complicating LLM fine-tuning. To combat these\nchallenges, we propose HSplitLoRA, a heterogeneous parameter-efficient\nfine-tuning (PEFT) framework built on split learning (SL) and low-rank\nadaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on\nheterogeneous client devices. HSplitLoRA first identifies important weights\nbased on their contributions to LLM training. It then dynamically configures\nthe decomposition ranks of LoRA adapters for selected weights and determines\nthe model split point according to varying computing budgets of client devices.\nFinally, a noise-free adapter aggregation mechanism is devised to support\nheterogeneous adapter aggregation without introducing noise. Extensive\nexperiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks\nin training accuracy and convergence speed."
  },
  {
    "arxiv_id": "2505.02737",
    "title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation",
    "url": "http://arxiv.org/abs/2505.02737v2",
    "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance."
  },
  {
    "arxiv_id": "2505.02362",
    "title": "Advancing Email Spam Detection: Leveraging Zero-Shot Learning and Large Language Models",
    "url": "http://arxiv.org/abs/2505.02362v1",
    "abstract": "Email spam detection is a critical task in modern communication systems,\nessential for maintaining productivity, security, and user experience.\nTraditional machine learning and deep learning approaches, while effective in\nstatic settings, face significant limitations in adapting to evolving spam\ntactics, addressing class imbalance, and managing data scarcity. These\nchallenges necessitate innovative approaches that reduce dependency on\nextensive labeled datasets and frequent retraining. This study investigates the\neffectiveness of Zero-Shot Learning using FLAN-T5, combined with advanced\nNatural Language Processing (NLP) techniques such as BERT for email spam\ndetection. By employing BERT to preprocess and extract critical information\nfrom email content, and FLAN-T5 to classify emails in a Zero-Shot framework,\nthe proposed approach aims to address the limitations of traditional spam\ndetection systems. The integration of FLAN-T5 and BERT enables robust spam\ndetection without relying on extensive labeled datasets or frequent retraining,\nmaking it highly adaptable to unseen spam patterns and adversarial\nenvironments. This research highlights the potential of leveraging zero-shot\nlearning and NLPs for scalable and efficient spam detection, providing insights\ninto their capability to address the dynamic and challenging nature of spam\ndetection tasks."
  },
  {
    "arxiv_id": "2505.01855",
    "title": "Intra-Layer Recurrence in Transformers for Language Modeling",
    "url": "http://arxiv.org/abs/2505.01855v1",
    "abstract": "Transformer models have established new benchmarks in natural language\nprocessing; however, their increasing depth results in substantial growth in\nparameter counts. While existing recurrent transformer methods address this\nissue by reprocessing layers multiple times, they often apply recurrence\nindiscriminately across entire blocks of layers. In this work, we investigate\nIntra-Layer Recurrence (ILR), a more targeted approach that applies recurrence\nselectively to individual layers within a single forward pass. Our experiments\nshow that allocating more iterations to earlier layers yields optimal results.\nThese findings suggest that ILR offers a promising direction for optimizing\nrecurrent structures in transformer architectures."
  },
  {
    "arxiv_id": "2505.03473",
    "title": "Evaluation of LLMs on Long-tail Entity Linking in Historical Documents",
    "url": "http://arxiv.org/abs/2505.03473v1",
    "abstract": "Entity Linking (EL) plays a crucial role in Natural Language Processing (NLP)\napplications, enabling the disambiguation of entity mentions by linking them to\ntheir corresponding entries in a reference knowledge base (KB). Thanks to their\ndeep contextual understanding capabilities, LLMs offer a new perspective to\ntackle EL, promising better results than traditional methods. Despite the\nimpressive generalization capabilities of LLMs, linking less popular, long-tail\nentities remains challenging as these entities are often underrepresented in\ntraining data and knowledge bases. Furthermore, the long-tail EL task is an\nunderstudied problem, and limited studies address it with LLMs. In the present\nwork, we assess the performance of two popular LLMs, GPT and LLama3, in a\nlong-tail entity linking scenario. Using MHERCL v0.1, a manually annotated\nbenchmark of sentences from domain-specific historical texts, we quantitatively\ncompare the performance of LLMs in identifying and linking entities to their\ncorresponding Wikidata entries against that of ReLiK, a state-of-the-art Entity\nLinking and Relation Extraction framework. Our preliminary experiments reveal\nthat LLMs perform encouragingly well in long-tail EL, indicating that this\ntechnology can be a valuable adjunct in filling the gap between head and\nlong-tail EL."
  },
  {
    "arxiv_id": "2505.03368",
    "title": "Geospatial Mechanistic Interpretability of Large Language Models",
    "url": "http://arxiv.org/abs/2505.03368v1",
    "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capabilities\nacross various natural language processing tasks. Their ability to process and\ngenerate viable text and code has made them ubiquitous in many fields, while\ntheir deployment as knowledge bases and \"reasoning\" tools remains an area of\nongoing research. In geography, a growing body of literature has been focusing\non evaluating LLMs' geographical knowledge and their ability to perform spatial\nreasoning. However, very little is still known about the internal functioning\nof these models, especially about how they process geographical information.\n  In this chapter, we establish a novel framework for the study of geospatial\nmechanistic interpretability - using spatial analysis to reverse engineer how\nLLMs handle geographical information. Our aim is to advance our understanding\nof the internal representations that these complex models generate while\nprocessing geographical information - what one might call \"how LLMs think about\ngeographic information\" if such phrasing was not an undue anthropomorphism.\n  We first outline the use of probing in revealing internal structures within\nLLMs. We then introduce the field of mechanistic interpretability, discussing\nthe superposition hypothesis and the role of sparse autoencoders in\ndisentangling polysemantic internal representations of LLMs into more\ninterpretable, monosemantic features. In our experiments, we use spatial\nautocorrelation to show how features obtained for placenames display spatial\npatterns related to their geographic location and can thus be interpreted\ngeospatially, providing insights into how these models process geographical\ninformation. We conclude by discussing how our framework can help shape the\nstudy and use of foundation models in geography."
  },
  {
    "arxiv_id": "2505.03345",
    "title": "Elevating Cyber Threat Intelligence against Disinformation Campaigns with LLM-based Concept Extraction and the FakeCTI Dataset",
    "url": "http://arxiv.org/abs/2505.03345v1",
    "abstract": "The swift spread of fake news and disinformation campaigns poses a\nsignificant threat to public trust, political stability, and cybersecurity.\nTraditional Cyber Threat Intelligence (CTI) approaches, which rely on low-level\nindicators such as domain names and social media handles, are easily evaded by\nadversaries who frequently modify their online infrastructure. To address these\nlimitations, we introduce a novel CTI framework that focuses on high-level,\nsemantic indicators derived from recurrent narratives and relationships of\ndisinformation campaigns. Our approach extracts structured CTI indicators from\nunstructured disinformation content, capturing key entities and their\ncontextual dependencies within fake news using Large Language Models (LLMs). We\nfurther introduce FakeCTI, the first dataset that systematically links fake\nnews to disinformation campaigns and threat actors. To evaluate the\neffectiveness of our CTI framework, we analyze multiple fake news attribution\ntechniques, spanning from traditional Natural Language Processing (NLP) to\nfine-tuned LLMs. This work shifts the focus from low-level artifacts to\npersistent conceptual structures, establishing a scalable and adaptive approach\nto tracking and countering disinformation campaigns."
  },
  {
    "arxiv_id": "2505.03265",
    "title": "Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models",
    "url": "http://arxiv.org/abs/2505.03265v1",
    "abstract": "While modern Requirements Engineering (RE) heavily relies on natural language\nprocessing and Machine Learning (ML) techniques, their effectiveness is limited\nby the scarcity of high-quality datasets. This paper introduces Synthline, a\nProduct Line (PL) approach that leverages Large Language Models to\nsystematically generate synthetic RE data for classification-based use cases.\nThrough an empirical evaluation conducted in the context of using ML for the\nidentification of requirements specification defects, we investigated both the\ndiversity of the generated data and its utility for training downstream models.\nOur analysis reveals that while synthetic datasets exhibit less diversity than\nreal data, they are good enough to serve as viable training resources.\nMoreover, our evaluation shows that combining synthetic and real data leads to\nsubstantial performance improvements. Specifically, hybrid approaches achieve\nup to 85% improvement in precision and a 2x increase in recall compared to\nmodels trained exclusively on real data. These findings demonstrate the\npotential of PL-based synthetic data generation to address data scarcity in RE.\nWe make both our implementation and generated datasets publicly available to\nsupport reproducibility and advancement in the field."
  },
  {
    "arxiv_id": "2505.03174",
    "title": "Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets",
    "url": "http://arxiv.org/abs/2505.03174v1",
    "abstract": "Instruction-Action (IA) data pairs are valuable for training robotic systems,\nespecially autonomous vehicles (AVs), but having humans manually annotate this\ndata is costly and time-inefficient. This paper explores the potential of using\nmobile application Global Positioning System (GPS) references and Natural\nLanguage Processing (NLP) to automatically generate large volumes of IA\ncommands and responses without having a human generate or retroactively tag the\ndata. In our pilot data collection, by driving to various destinations and\ncollecting voice instructions from GPS applications, we demonstrate a means to\ncollect and categorize the diverse sets of instructions, further accompanied by\nvideo data to form complete vision-language-action triads. We provide details\non our completely automated data collection prototype system, ADVLAT-Engine. We\ncharacterize collected GPS voice instructions into eight different\nclassifications, highlighting the breadth of commands and referentialities\navailable for curation from freely available mobile applications. Through\nresearch and exploration into the automation of IA data pairs using GPS\nreferences, the potential to increase the speed and volume at which\nhigh-quality IA datasets are created, while minimizing cost, can pave the way\nfor robust vision-language-action (VLA) models to serve tasks in\nvision-language navigation (VLN) and human-interactive autonomous systems."
  },
  {
    "arxiv_id": "2505.03113",
    "title": "Image Recognition with Online Lightweight Vision Transformer: A Survey",
    "url": "http://arxiv.org/abs/2505.03113v1",
    "abstract": "The Transformer architecture has achieved significant success in natural\nlanguage processing, motivating its adaptation to computer vision tasks. Unlike\nconvolutional neural networks, vision transformers inherently capture\nlong-range dependencies and enable parallel processing, yet lack inductive\nbiases and efficiency benefits, facing significant computational and memory\nchallenges that limit its real-world applicability. This paper surveys various\nonline strategies for generating lightweight vision transformers for image\nrecognition, focusing on three key areas: Efficient Component Design, Dynamic\nNetwork, and Knowledge Distillation. We evaluate the relevant exploration for\neach topic on the ImageNet-1K benchmark, analyzing trade-offs among precision,\nparameters, throughput, and more to highlight their respective advantages,\ndisadvantages, and flexibility. Finally, we propose future research directions\nand potential challenges in the lightweighting of vision transformers with the\naim of inspiring further exploration and providing practical guidance for the\ncommunity. Project Page: https://github.com/ajxklo/Lightweight-VIT"
  },
  {
    "arxiv_id": "2505.04531",
    "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review",
    "url": "http://arxiv.org/abs/2505.04531v1",
    "abstract": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies."
  },
  {
    "arxiv_id": "2505.04175",
    "title": "DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation",
    "url": "http://arxiv.org/abs/2505.04175v1",
    "abstract": "Text recognition in natural images remains a challenging yet essential task,\nwith broad applications spanning computer vision and natural language\nprocessing. This paper introduces a novel end-to-end framework that combines\nResNet and Vision Transformer backbones with advanced methodologies, including\nDeformable Convolutions, Retrieval-Augmented Generation, and Conditional Random\nFields (CRF). These innovations collectively enhance feature representation and\nimprove Optical Character Recognition (OCR) performance. Specifically, the\nframework substitutes standard convolution layers in the third and fourth\nblocks with Deformable Convolutions, leverages adaptive dropout for\nregularization, and incorporates CRF for more refined sequence modeling.\nExtensive experiments conducted on six benchmark datasets IC13, IC15, SVT,\nIIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving\nnotable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on\nIIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy\nof 77.77%. These results establish a new state-of-the-art for text recognition,\ndemonstrating the robustness of the approach across diverse and challenging\ndatasets."
  },
  {
    "arxiv_id": "2505.04084",
    "title": "An Empirical Study of OpenAI API Discussions on Stack Overflow",
    "url": "http://arxiv.org/abs/2505.04084v1",
    "abstract": "The rapid advancement of large language models (LLMs), represented by\nOpenAI's GPT series, has significantly impacted various domains such as natural\nlanguage processing, software development, education, healthcare, finance, and\nscientific research. However, OpenAI APIs introduce unique challenges that\ndiffer from traditional APIs, such as the complexities of prompt engineering,\ntoken-based cost management, non-deterministic outputs, and operation as black\nboxes. To the best of our knowledge, the challenges developers encounter when\nusing OpenAI APIs have not been explored in previous empirical studies. To fill\nthis gap, we conduct the first comprehensive empirical study by analyzing 2,874\nOpenAI API-related discussions from the popular Q&A forum Stack Overflow. We\nfirst examine the popularity and difficulty of these posts. After manually\ncategorizing them into nine OpenAI API-related categories, we identify specific\nchallenges associated with each category through topic modeling analysis. Based\non our empirical findings, we finally propose actionable implications for\ndevelopers, LLM vendors, and researchers."
  },
  {
    "arxiv_id": "2505.04654",
    "title": "A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient",
    "url": "http://arxiv.org/abs/2505.04654v1",
    "abstract": "Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly\nevolved in recent years, showcasing remarkable capabilities in natural language\nunderstanding and generation. However, these advancements also raise critical\nethical questions regarding safety, potential misuse, discrimination and\noverall societal impact. This article provides a comparative analysis of the\nethical performance of various AI models, including the brand new\nDeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5\nTurbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp)\nand highlights the need for robust human oversight, especially in situations\nwith high stakes. Furthermore, we present a new metric for calculating harm in\nLLMs called Relative Danger Coefficient (RDC)."
  }
]