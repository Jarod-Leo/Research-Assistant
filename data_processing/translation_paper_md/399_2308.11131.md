# ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation

链接: http://arxiv.org/abs/2308.11131v1

原文摘要:
With large language models (LLMs) achieving remarkable breakthroughs in
natural language processing (NLP) domains, LLM-enhanced recommender systems
have received much attention and have been actively explored currently. In this
paper, we focus on adapting and empowering a pure large language model for
zero-shot and few-shot recommendation tasks. First and foremost, we identify
and formulate the lifelong sequential behavior incomprehension problem for LLMs
in recommendation domains, i.e., LLMs fail to extract useful information from a
textual context of long user behavior sequence, even if the length of context
is far from reaching the context limitation of LLMs. To address such an issue
and improve the recommendation performance of LLMs, we propose a novel
framework, namely Retrieval-enhanced Large Language models (ReLLa) for
recommendation tasks in both zero-shot and few-shot settings. For zero-shot
recommendation, we perform semantic user behavior retrieval (SUBR) to improve
the data quality of testing samples, which greatly reduces the difficulty for
LLMs to extract the essential knowledge from user behavior sequences. As for
few-shot recommendation, we further design retrieval-enhanced instruction
tuning (ReiT) by adopting SUBR as a data augmentation technique for training
samples. Specifically, we develop a mixed training dataset consisting of both
the original data samples and their retrieval-enhanced counterparts. We conduct
extensive experiments on three real-world public datasets to demonstrate the
superiority of ReLLa compared with existing baseline models, as well as its
capability for lifelong sequential behavior comprehension. To be highlighted,
with only less than 10% training samples, few-shot ReLLa can outperform
traditional CTR models that are trained on the entire training set (e.g.,
DCNv2, DIN, SIM). The code is available
\url{https://github.com/LaVieEnRose365/ReLLa}.

中文翻译:
随着大语言模型（LLM）在自然语言处理（NLP）领域取得显著突破，基于LLM的增强型推荐系统近期受到广泛关注并得到积极探索。本文重点研究如何改造纯大语言模型，使其适用于零样本和小样本推荐任务。首先，我们发现并系统阐述了LLM在推荐领域存在的终身序列行为理解障碍问题——即当用户行为序列的文本上下文长度远未达到LLM处理上限时，模型仍无法从中提取有效信息。  

为解决该问题并提升LLM的推荐性能，我们提出创新框架ReLLa（检索增强型大语言模型），适用于零样本和小样本推荐场景。针对零样本推荐，我们采用语义化用户行为检索（SUBR）技术提升测试样本数据质量，显著降低LLM从用户行为序列中提取核心知识的难度。对于小样本推荐，我们进一步设计检索增强式指令微调（ReiT），将SUBR作为训练样本的数据增强手段：通过构建包含原始数据样本及其检索增强版本的混合训练数据集来实现优化。  

在三个真实公开数据集上的大量实验表明，ReLLa不仅优于现有基线模型，更展现出卓越的终身序列行为理解能力。值得强调的是，仅需不足10%的训练样本，小样本ReLLa即可超越传统点击率模型（如DCNv2、DIN、SIM）在全量训练集上的表现。代码已开源：\url{https://github.com/LaVieEnRose365/ReLLa}  

（注：译文严格遵循学术规范，通过以下技术处理实现专业性与可读性平衡：  
1. 术语统一："zero-shot/few-shot"译为"零样本/小样本"；"click-through rate"采用通用译法"点击率"  
2. 长句拆分：将原文复合句按中文表达习惯分解为短句群  
3. 被动语态转化："have been actively explored"转为主动式"得到积极探索"  
4. 概念显化："lifelong sequential behavior incomprehension"译为"终身序列行为理解障碍"，通过添加破折号解释提升可读性  
5. 技术表述精确化："data augmentation technique"译为"数据增强手段"而非字面直译）
