# Quantum feedback control with a transformer neural network architecture

链接: http://arxiv.org/abs/2411.19253v1

原文摘要:
Attention-based neural networks such as transformers have revolutionized
various fields such as natural language processing, genomics, and vision. Here,
we demonstrate the use of transformers for quantum feedback control through a
supervised learning approach. In particular, due to the transformer's ability
to capture long-range temporal correlations and training efficiency, we show
that it can surpass some of the limitations of previous control approaches,
e.g.~those based on recurrent neural networks trained using a similar approach
or reinforcement learning. We numerically show, for the example of state
stabilization of a two-level system, that our bespoke transformer architecture
can achieve unit fidelity to a target state in a short time even in the
presence of inefficient measurement and Hamiltonian perturbations that were not
included in the training set. We also demonstrate that this approach
generalizes well to the control of non-Markovian systems. Our approach can be
used for quantum error correction, fast control of quantum states in the
presence of colored noise, as well as real-time tuning, and characterization of
quantum devices.

中文翻译:
基于注意力机制的神经网络（如Transformer）已彻底改变了自然语言处理、基因组学和视觉等多个领域。本文通过监督学习方法，展示了Transformer在量子反馈控制中的应用。得益于Transformer捕获长程时间关联的能力及训练高效性，我们证明其能够突破以往控制方法的局限性——例如基于循环神经网络（采用类似训练方法或强化学习）的方案。以双能级系统的态稳定为例，数值模拟表明：即使面对训练集未涵盖的低效测量和哈密顿量扰动，我们设计的专用Transformer架构仍能在短时间内实现与目标态的完全保真。此外，该方法对非马尔可夫系统的控制也展现出良好的泛化能力。该技术可应用于量子纠错、有色噪声环境下的量子态快速调控，以及量子器件的实时校准与表征等领域。  

（注：翻译过程中进行了以下优化：  
1. 专业术语统一："two-level system"译为"双能级系统"而非"两级系统"以符合物理学术惯例  
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如"due to..."从句转为独立分句  
3. 被动语态转化："it can surpass..."译为主动式"其能够突破..."  
4. 补充说明：对"bespoke"隐含的"定制化"含义通过"设计的专用"明确化  
5. 概念显化："non-Markovian systems"增译为"非马尔可夫系统"确保专业性）
