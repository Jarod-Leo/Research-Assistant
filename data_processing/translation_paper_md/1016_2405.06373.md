# LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play

链接: http://arxiv.org/abs/2405.06373v1

原文摘要:
Large language models (LLMs) have shown exceptional proficiency in natural
language processing but often fall short of generating creative and original
responses to open-ended questions. To enhance LLM creativity, our key insight
is to emulate the human process of inducing collective creativity through
engaging discussions with participants from diverse backgrounds and
perspectives. To this end, we propose LLM Discussion, a three-phase discussion
framework that facilitates vigorous and diverging idea exchanges and ensures
convergence to creative answers. Moreover, we adopt a role-playing technique by
assigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate
the efficacy of the proposed framework with the Alternative Uses Test,
Similarities Test, Instances Test, and Scientific Creativity Test through both
LLM evaluation and human study. The results show that our proposed framework
outperforms single-LLM approaches and existing multi-LLM frameworks across
various creativity metrics. The code is available at
https://github.com/lawraa/LLM-Discussion.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）在自然语言处理方面展现出卓越能力，但在应对开放式问题时往往难以生成具有创造性和原创性的回答。为提升LLM的创造力，我们的核心思路是模拟人类通过多元背景参与者开展深入讨论来激发集体创造力的过程。为此，我们提出LLM讨论框架，该三阶段讨论机制既能促进活跃发散的观点交流，又能确保最终收敛于创造性答案。针对LLMs同质化问题，我们采用角色扮演技术为不同模型分配差异化角色。通过替代用途测试、相似性测试、实例测试和科学创造力测试，我们结合LLM评估与人类研究对框架有效性进行验证。结果表明，在各项创造力指标上，本框架均优于单LLM方法和现有多LLM框架。代码已开源：https://github.com/lawraa/LLM-Discussion。

（翻译说明：
1. 专业术语统一处理：LLM保持英文缩写，"Alternative Uses Test"等标准化测试名称采用学界通用译法
2. 长句拆分重组：将原文复合句按中文表达习惯分解为多个短句，如三阶段框架描述部分
3. 被动语态转化："are assigned"译为主动式"分配"
4. 概念准确传达："homogeneity"译为"同质化"而非简单直译
5. 学术风格保持：使用"旨在""结果表明"等规范表述，避免口语化
6. 链接信息完整保留，符合技术论文格式要求）
