# Language Modeling on Tabular Data: A Survey of Foundations, Techniques and Evolution

链接: http://arxiv.org/abs/2408.10548v1

原文摘要:
Tabular data, a prevalent data type across various domains, presents unique
challenges due to its heterogeneous nature and complex structural
relationships. Achieving high predictive performance and robustness in tabular
data analysis holds significant promise for numerous applications. Influenced
by recent advancements in natural language processing, particularly transformer
architectures, new methods for tabular data modeling have emerged. Early
techniques concentrated on pre-training transformers from scratch, often
encountering scalability issues. Subsequently, methods leveraging pre-trained
language models like BERT have been developed, which require less data and
yield enhanced performance. The recent advent of large language models, such as
GPT and LLaMA, has further revolutionized the field, facilitating more advanced
and diverse applications with minimal fine-tuning. Despite the growing
interest, a comprehensive survey of language modeling techniques for tabular
data remains absent. This paper fills this gap by providing a systematic review
of the development of language modeling for tabular data, encompassing: (1) a
categorization of different tabular data structures and data types; (2) a
review of key datasets used in model training and tasks used for evaluation;
(3) a summary of modeling techniques including widely-adopted data processing
methods, popular architectures, and training objectives; (4) the evolution from
adapting traditional Pre-training/Pre-trained language models to the
utilization of large language models; (5) an identification of persistent
challenges and potential future research directions in language modeling for
tabular data analysis. GitHub page associated with this survey is available at:
https://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git.

中文翻译:
表格数据作为跨领域普遍存在的数据类型，因其异构性和复杂的结构关系而带来独特挑战。在表格数据分析中实现高预测性能和鲁棒性对众多应用具有重要意义。受自然语言处理领域（尤其是Transformer架构）近期进展的影响，表格数据建模的新方法不断涌现。早期技术主要聚焦于从头预训练Transformer模型，但常面临可扩展性问题；随后发展的方法利用BERT等预训练语言模型，在减少数据需求的同时提升了性能；而GPT、LLaMA等大语言模型的最新出现更推动领域革新，仅需微调即可实现更先进多样的应用。尽管关注度持续增长，目前仍缺乏对表格数据语言建模技术的全面综述。本文通过系统梳理表格数据语言建模的发展脉络填补这一空白，内容包括：（1）不同表格数据结构与数据类型的分类体系；（2）模型训练关键数据集与评估任务的综述；（3）主流建模技术总结，涵盖广泛采用的数据处理方法、流行架构及训练目标；（4）从传统预训练/预训练语言模型适配到大语言模型应用的演进路径；（5）表格数据分析语言建模领域持续存在的挑战与未来潜在研究方向。本综述关联的GitHub页面详见：https://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git

（注：译文采用学术论文摘要的典型结构，通过以下处理实现专业性与可读性平衡：
1. 专业术语标准化处理："heterogeneous nature"译为"异构性"，"fine-tuning"统一为"微调"
2. 长句拆分重组：将原文复合句按中文表达习惯分解为多个短句，如将"methods leveraging..."处理为独立分句
3. 逻辑连接显性化：添加"而"、"更"等连接词强化段落递进关系
4. 被动语态转化："have been developed"译为主动态"发展的方法"
5. 技术名词统一："large language models"全篇统一为"大语言模型"而非"大型语言模型"）
