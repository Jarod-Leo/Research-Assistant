# ChatAug: Leveraging ChatGPT for Text Data Augmentation

链接: http://arxiv.org/abs/2302.13007v1

原文摘要:
Text data augmentation is an effective strategy for overcoming the challenge
of limited sample sizes in many natural language processing (NLP) tasks. This
challenge is especially prominent in the few-shot learning scenario, where the
data in the target domain is generally much scarcer and of lowered quality. A
natural and widely-used strategy to mitigate such challenges is to perform data
augmentation to better capture the data invariance and increase the sample
size. However, current text data augmentation methods either can't ensure the
correct labeling of the generated data (lacking faithfulness) or can't ensure
sufficient diversity in the generated data (lacking compactness), or both.
Inspired by the recent success of large language models, especially the
development of ChatGPT, which demonstrated improved language comprehension
abilities, in this work, we propose a text data augmentation approach based on
ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples
into multiple conceptually similar but semantically different samples. The
augmented samples can then be used in downstream model training. Experiment
results on few-shot learning text classification tasks show the superior
performance of the proposed AugGPT approach over state-of-the-art text data
augmentation methods in terms of testing accuracy and distribution of the
augmented samples.

中文翻译:
文本数据增强是解决自然语言处理任务中样本量不足问题的有效策略，这一挑战在小样本学习场景中尤为突出——目标领域的数据往往数量稀缺且质量较低。通过数据增强来更好地捕捉数据不变性并扩大样本规模，是一种自然且广泛采用的解决思路。然而，现有文本数据增强方法要么无法保证生成数据的正确标注（缺乏忠实性），要么难以确保生成数据的充分多样性（缺乏紧凑性），或两者兼有之。受大型语言模型最新进展的启发，特别是ChatGPT展现出的卓越语言理解能力，本研究提出基于ChatGPT的文本数据增强方法AugGPT。该方法将训练样本中的每个句子重述为多个概念相似但语义不同的样本，生成的增强数据可用于下游模型训练。在小样本文本分类任务的实验中，AugGPT在测试准确率和增强样本分布方面均优于当前最先进的文本数据增强方法。
