# Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language

链接: http://arxiv.org/abs/2405.01682v1

原文摘要:
Automatic conversion of free-text radiology reports into structured data
using Natural Language Processing (NLP) techniques is crucial for analyzing
diseases on a large scale. While effective for tasks in widely spoken languages
like English, generative large language models (LLMs) typically underperform
with less common languages and can pose potential risks to patient privacy.
Fine-tuning local NLP models is hindered by the skewed nature of real-world
medical datasets, where rare findings represent a significant data imbalance.
We introduce SMP-BERT, a novel prompt learning method that leverages the
structured nature of reports to overcome these challenges. In our studies
involving a substantial collection of Crohn's disease radiology reports in
Hebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed
traditional fine-tuning methods in performance, notably in detecting infrequent
conditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more
accurate AI diagnostics available for low-resource languages.

中文翻译:
利用自然语言处理（NLP）技术将自由文本放射学报告自动转化为结构化数据，对于大规模疾病分析至关重要。虽然生成式大语言模型（LLM）在英语等广泛使用语言的任务中表现优异，但其对小语种的处理能力通常欠佳，并可能对患者隐私构成潜在风险。现实世界医学数据集的偏态分布（罕见病症数据占比极低）阻碍了本地NLP模型的微调效果。我们提出SMP-BERT这一新型提示学习方法，通过利用放射学报告固有的结构化特征来应对这些挑战。在针对希伯来语克罗恩病放射学报告的大规模研究中（涉及8,000余名患者的10,000余份报告），SMP-BERT在检测罕见病症方面显著超越传统微调方法（AUC：0.99 vs 0.94，F1分数：0.84 vs 0.34）。该技术为资源稀缺语言提供了更精准的人工智能诊断支持。

（翻译说明：
1. 专业术语处理："AUC/F1"等指标保留英文缩写，符合医学文献惯例
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如将generative LLMs的处理单独成句
3. 被动语态转换："is hindered by"译为主动式"阻碍了"
4. 文化适配："low-resource languages"译为"资源稀缺语言"而非字面直译
5. 数据呈现：精确转换数字格式，使用中文计数单位"余名/余份"
6. 技术概念："prompt learning"统一译为当前学界通用译法"提示学习"）
