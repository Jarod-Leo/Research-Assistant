# Personalized Large Language Models

链接: http://arxiv.org/abs/2402.09269v1

原文摘要:
Large language models (LLMs) have significantly advanced Natural Language
Processing (NLP) tasks in recent years. However, their universal nature poses
limitations in scenarios requiring personalized responses, such as
recommendation systems and chatbots. This paper investigates methods to
personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on
subjective tasks. Results demonstrate that personalized fine-tuning improves
model reasoning compared to non-personalized models. Experiments on datasets
for emotion recognition and hate speech detection show consistent performance
gains with personalized methods across different LLM architectures. These
findings underscore the importance of personalization for enhancing LLM
capabilities in subjective text perception tasks.

中文翻译:
近年来，大型语言模型（LLMs）显著推动了自然语言处理（NLP）任务的发展。然而，其通用性在需要个性化反馈的场景（如推荐系统和聊天机器人）中存在局限性。本文研究了LLMs个性化方法，通过微调与零样本推理两种路径在主观性任务上进行对比。实验结果表明，相较于非个性化模型，经过个性化微调的模型能显著提升推理能力。在情感识别和仇恨言论检测数据集上的测试显示，不同架构的LLM采用个性化方法后均能获得稳定的性能提升。这些发现印证了个性化技术对于增强LLMs在主观文本感知任务中表现的关键作用。

（翻译说明：采用学术论文摘要的简洁风格，通过以下处理实现专业表达：
1. 术语统一："zero-shot reasoning"译为"零样本推理"符合NLP领域规范
2. 句式重构：将原文复合句拆分为符合中文表达习惯的短句，如将"comparing..."独立成句
3. 被动语态转化："Results demonstrate..."转为主动式"实验结果表明..."
4. 概念显化："subjective text perception tasks"意译为"主观文本感知任务"以准确传达技术内涵
5. 逻辑连接：使用"相较于""印证了"等连接词保持论证严谨性）
