# Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension

链接: http://arxiv.org/abs/2303.08262v1

原文摘要:
Objective: To develop a natural language processing system that solves both
clinical concept extraction and relation extraction in a unified prompt-based
machine reading comprehension (MRC) architecture with good generalizability for
cross-institution applications.
  Methods: We formulate both clinical concept extraction and relation
extraction using a unified prompt-based MRC architecture and explore
state-of-the-art transformer models. We compare our MRC models with existing
deep learning models for concept extraction and end-to-end relation extraction
using two benchmark datasets developed by the 2018 National NLP Clinical
Challenges (n2c2) challenge (medications and adverse drug events) and the 2022
n2c2 challenge (relations of social determinants of health [SDoH]). We also
evaluate the transfer learning ability of the proposed MRC models in a
cross-institution setting. We perform error analyses and examine how different
prompting strategies affect the performance of MRC models.
  Results and Conclusion: The proposed MRC models achieve state-of-the-art
performance for clinical concept and relation extraction on the two benchmark
datasets, outperforming previous non-MRC transformer models. GatorTron-MRC
achieves the best strict and lenient F1-scores for concept extraction,
outperforming previous deep learning models on the two datasets by 1%~3% and
0.7%~1.3%, respectively. For end-to-end relation extraction, GatorTron-MRC and
BERT-MIMIC-MRC achieve the best F1-scores, outperforming previous deep learning
models by 0.9%~2.4% and 10%-11%, respectively. For cross-institution
evaluation, GatorTron-MRC outperforms traditional GatorTron by 6.4% and 16% for
the two datasets, respectively. The proposed method is better at handling
nested/overlapped concepts, extracting relations, and has good portability for
cross-institute applications.

中文翻译:
目的：开发一种自然语言处理系统，通过基于提示的统一机器阅读理解（MRC）架构同步解决临床概念抽取与关系抽取任务，并具备良好的跨机构应用泛化能力。
方法：采用基于提示的统一MRC架构重构临床概念抽取与关系抽取任务，并探索最先进的Transformer模型。使用2018年n2c2挑战赛（药物与药物不良反应）和2022年n2c2挑战赛（健康社会决定因素[SDoH]关系）构建的两个基准数据集，将所提MRC模型与现有深度学习模型在概念抽取和端到端关系抽取任务上进行对比。同时评估MRC模型在跨机构场景下的迁移学习能力，通过错误分析探究不同提示策略对模型性能的影响。
结果与结论：所提MRC模型在两个基准数据集上均取得当前最优的临床概念与关系抽取性能，超越既往非MRC架构的Transformer模型。GatorTron-MRC在概念抽取任务中获得最佳严格/宽松F1值，相较原有深度学习模型在两个数据集上分别提升1%~3%和0.7%~1.3%。在端到端关系抽取任务中，GatorTron-MRC与BERT-MIMIC-MRC分别以0.9%~2.4%和10%~11%的优势刷新最佳F1值。跨机构评估显示，GatorTron-MRC较传统GatorTron模型在两个数据集上分别提升6.4%和16%。该方法能更有效处理嵌套/重叠概念，提升关系抽取效果，并具有优异的跨机构移植性。
