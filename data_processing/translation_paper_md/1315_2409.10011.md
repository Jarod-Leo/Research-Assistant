# HALO: Hallucination Analysis and Learning Optimization to Empower LLMs with Retrieval-Augmented Context for Guided Clinical Decision Making

链接: http://arxiv.org/abs/2409.10011v1

原文摘要:
Large language models (LLMs) have significantly advanced natural language
processing tasks, yet they are susceptible to generating inaccurate or
unreliable responses, a phenomenon known as hallucination. In critical domains
such as health and medicine, these hallucinations can pose serious risks. This
paper introduces HALO, a novel framework designed to enhance the accuracy and
reliability of medical question-answering (QA) systems by focusing on the
detection and mitigation of hallucinations. Our approach generates multiple
variations of a given query using LLMs and retrieves relevant information from
external open knowledge bases to enrich the context. We utilize maximum
marginal relevance scoring to prioritize the retrieved context, which is then
provided to LLMs for answer generation, thereby reducing the risk of
hallucinations. The integration of LangChain further streamlines this process,
resulting in a notable and robust increase in the accuracy of both open-source
and commercial LLMs, such as Llama-3.1 (from 44% to 65%) and ChatGPT (from 56%
to 70%). This framework underscores the critical importance of addressing
hallucinations in medical QA systems, ultimately improving clinical
decision-making and patient care. The open-source HALO is available at:
https://github.com/ResponsibleAILab/HALO.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）在自然语言处理任务中取得显著进展，但其易生成不准确或不可靠的响应，这种现象被称为"幻觉"。在医疗健康等关键领域，此类幻觉可能引发严重风险。本文提出HALO框架，通过聚焦幻觉检测与缓解来提升医疗问答系统的准确性与可靠性。我们的方法利用LLMs生成给定查询的多种变体，并从外部开放知识库检索相关信息以丰富上下文。采用最大边际相关性评分对检索内容进行优先级排序，再将优化后的上下文提供给LLMs生成答案，从而降低幻觉风险。结合LangChain的集成应用，该框架使得开源与商用LLMs（如Llama-3.1从44%提升至65%，ChatGPT从56%提升至70%）的准确率获得显著且稳健的提升。本框架凸显了解决医疗问答系统中幻觉问题的关键价值，最终将改善临床决策与患者护理。开源HALO项目地址：https://github.com/ResponsibleAILab/HALO。

（翻译严格遵循以下原则：
1. 专业术语统一："hallucination"译为"幻觉"，"maximum marginal relevance"译为"最大边际相关性"
2. 被动语态转化："are susceptible to"译为"易"，"is then provided"译为"再提供给"
3. 长句拆分：将原文复合句分解为符合中文表达习惯的短句
4. 数据呈现规范：百分比数字保留原文格式
5. 学术风格：使用"聚焦"、"凸显"等正式学术用语
6. 链接保留：完整保留GitHub项目地址）
