# Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models

链接: http://arxiv.org/abs/2311.00287v1

原文摘要:
Clinical natural language processing requires methods that can address
domain-specific challenges, such as complex medical terminology and clinical
contexts. Recently, large language models (LLMs) have shown promise in this
domain. Yet, their direct deployment can lead to privacy issues and are
constrained by resources. To address this challenge, we delve into synthetic
clinical text generation using LLMs for clinical NLP tasks. We propose an
innovative, resource-efficient approach, ClinGen, which infuses knowledge into
the process. Our model involves clinical knowledge extraction and
context-informed LLM prompting. Both clinical topics and writing styles are
drawn from external domain-specific knowledge graphs and LLMs to guide data
generation. Our extensive empirical study across 7 clinical NLP tasks and 16
datasets reveals that ClinGen consistently enhances performance across various
tasks, effectively aligning the distribution of real datasets and significantly
enriching the diversity of generated training instances. Our code is available
at \url{https://github.com/ritaranx/ClinGen}.

中文翻译:
临床自然语言处理需要能够应对领域特有挑战的方法，例如复杂的医学术语和临床情境。近年来，大型语言模型（LLMs）在该领域展现出应用潜力，但直接部署可能引发隐私问题并受资源限制。为应对这一挑战，我们深入研究了利用LLMs生成合成临床文本以支持临床NLP任务的方法。本文提出一种创新且资源高效的知识融合方案ClinGen，其核心流程包括临床知识抽取和情境感知的LLM提示工程。通过整合来自外部领域知识图谱和LLMs的临床主题与写作风格，系统化指导数据生成。我们在7项临床NLP任务和16个数据集上的大规模实验表明：ClinGen能持续提升各类任务性能，有效对齐真实数据集的分布特征，并显著增强生成训练实例的多样性。代码已开源于\url{https://github.com/ritaranx/ClinGen}。

（注：根据学术摘要的文体特征，翻译时进行了以下处理：
1. 将英文被动语态转换为中文主动表述
2. 专业术语如"NLP/LLMs"保留英文缩写但首次出现标注全称
3. 长难句拆解为符合中文表达习惯的短句结构
4. 技术概念如"context-informed prompting"译为"情境感知提示工程"以保持专业性
5. 统一了"数据集/实例"等计算机领域术语的表述
6. 最后补充"注"说明翻译策略，实际交付时可删除此部分）
