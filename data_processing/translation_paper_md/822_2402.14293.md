# Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education

链接: http://arxiv.org/abs/2402.14293v1

原文摘要:
In the domain of Natural Language Processing (NLP), Large Language Models
(LLMs) have demonstrated promise in text-generation tasks. However, their
educational applications, particularly for domain-specific queries, remain
underexplored. This study investigates LLMs' capabilities in educational
scenarios, focusing on concept graph recovery and question-answering (QA). We
assess LLMs' zero-shot performance in creating domain-specific concept graphs
and introduce TutorQA, a new expert-verified NLP-focused benchmark for
scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA
pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating
concept graphs with LLMs for answering diverse questions. Our results indicate
that LLMs' zero-shot concept graph recovery is competitive with supervised
methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs
achieve up to 26% F1 score enhancement. Moreover, human evaluation and analysis
show that CGLLM generates answers with more fine-grained concepts.

中文翻译:
在自然语言处理（NLP）领域，大语言模型（LLMs）已在文本生成任务中展现出潜力。然而，其在教育领域的应用——特别是针对特定领域问题的处理——仍未得到充分探索。本研究聚焦教育场景中的概念图谱重建与问答（QA）任务，系统评估了LLMs的零样本能力。我们构建了TutorQA基准测试集，这是一个经专家验证、专注于科学图谱推理与QA的NLP评估体系，包含5类任务共计500组问答对。为应对TutorQA的复杂查询，本文提出CGLLM框架——通过整合概念图谱与大语言模型的协同管道来实现多样化问题解答。实验结果表明：在零样本概念图谱重建任务中，LLMs的表现与监督学习方法相当，F1分数平均提升3%；在TutorQA任务中，LLMs最高可获得26%的F1分数提升。进一步的人类评估与分析证实，CGLLM生成的答案具有更细粒度的概念呈现。

（注：译文严格遵循学术规范，采用术语统一原则处理专业词汇如"zero-shot"译为"零样本"、"F1 score"保留专业指标名称。通过拆分英文长句为中文短句结构（如将原文"introduce TutorQA..."处理为独立分句），并运用"协同管道""评估体系"等符合中文科技论文表达的措辞。关键创新点"CGLLM"首次出现时标注为"框架"以明确其系统属性，后续统一使用简称保持连贯性。）
