# VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model

链接: http://arxiv.org/abs/2309.08474v1

原文摘要:
This paper presents VulnSense framework, a comprehensive approach to
efficiently detect vulnerabilities in Ethereum smart contracts using a
multimodal learning approach on graph-based and natural language processing
(NLP) models. Our proposed framework combines three types of features from
smart contracts comprising source code, opcode sequences, and control flow
graph (CFG) extracted from bytecode. We employ Bidirectional Encoder
Representations from Transformers (BERT), Bidirectional Long Short-Term Memory
(BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these
features. The final layer of our multimodal approach consists of a fully
connected layer used to predict vulnerabilities in Ethereum smart contracts.
Addressing limitations of existing vulnerability detection methods relying on
single-feature or single-model deep learning techniques, our method surpasses
accuracy and effectiveness constraints. We assess VulnSense using a collection
of 1.769 smart contracts derived from the combination of three datasets:
Curated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with
various unimodal and multimodal learning techniques contributed by GNN, BiLSTM
and BERT architectures. The experimental outcomes demonstrate the superior
performance of our proposed approach, achieving an average accuracy of 77.96\%
across all three categories of vulnerable smart contracts.

中文翻译:
本文提出VulnSense框架，这是一种基于多模态学习的综合性方案，通过结合图神经网络与自然语言处理技术，实现对以太坊智能合约漏洞的高效检测。该框架融合智能合约的三类特征：源代码、操作码序列以及从字节码中提取的控制流图（CFG），并采用基于Transformer的双向编码器（BERT）、双向长短期记忆网络（BiLSTM）和图神经网络（GNN）进行特征提取与分析。多模态架构的最终层通过全连接网络实现以太坊智能合约漏洞的预测。相较于现有依赖单一特征或单一模型的深度学习检测方法，本方案突破了准确性与有效性的局限。我们在整合Curated、SolidiFI-Benchmark和Smartbugs Wild三个数据集形成的1,769份智能合约集合上评估VulnSense，并与GNN、BiLSTM和BERT架构构建的各种单模态及多模态学习技术进行对比。实验结果表明，所提方法在三类漏洞合约检测中平均准确率达77.96%，显著优于现有技术。
