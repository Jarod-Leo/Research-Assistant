# AttentionDrop: A Novel Regularization Method for Transformer Models

链接: http://arxiv.org/abs/2504.12088v1

原文摘要:
Transformer-based architectures achieve state-of-the-art performance across a
wide range of tasks in natural language processing, computer vision, and
speech. However, their immense capacity often leads to overfitting, especially
when training data is limited or noisy. We propose AttentionDrop, a unified
family of stochastic regularization techniques that operate directly on the
self-attention distributions. We introduces three variants: 1. Hard Attention
Masking: randomly zeroes out top-k attention logits per query to encourage
diverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic
Gaussian convolution over attention logits to diffuse overly peaked
distributions. 3. Consistency-Regularized AttentionDrop: enforces output
stability under multiple independent AttentionDrop perturbations via a KL-based
consistency loss.

中文翻译:
基于Transformer的架构在自然语言处理、计算机视觉和语音领域广泛任务中实现了最先进的性能表现。然而，其庞大的模型容量常导致过拟合问题，在训练数据有限或存在噪声时尤为显著。我们提出AttentionDrop——一个直接在自注意力分布上操作的随机正则化方法家族，包含三种变体：1. 硬注意力掩码：对每个查询随机置零top-k注意力逻辑值，以促进多样化的上下文利用；2. 模糊注意力平滑：在注意力逻辑值上动态应用高斯卷积，以扩散过度集中的分布；3. 一致性正则化AttentionDrop：通过基于KL散度的一致性损失，强制模型在多重独立AttentionDrop扰动下保持输出稳定性。
