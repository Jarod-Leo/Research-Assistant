# Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks

链接: http://arxiv.org/abs/2403.09832v1

原文摘要:
Large Language Models (LLMs) are increasingly becoming the preferred
foundation platforms for many Natural Language Processing tasks such as Machine
Translation, owing to their quality often comparable to or better than
task-specific models, and the simplicity of specifying the task through natural
language instructions or in-context examples. Their generality, however, opens
them up to subversion by end users who may embed into their requests
instructions that cause the model to behave in unauthorized and possibly unsafe
ways. In this work we study these Prompt Injection Attacks (PIAs) on multiple
families of LLMs on a Machine Translation task, focusing on the effects of
model size on the attack success rates. We introduce a new benchmark data set
and we discover that on multiple language pairs and injected prompts written in
English, larger models under certain conditions may become more susceptible to
successful attacks, an instance of the Inverse Scaling phenomenon (McKenzie et
al., 2023). To our knowledge, this is the first work to study non-trivial LLM
scaling behaviour in a multi-lingual setting.

中文翻译:
大型语言模型（LLMs）正日益成为机器翻译等自然语言处理任务的首选基础平台，这既得益于其质量往往媲美甚至超越专用模型，也因其能通过自然语言指令或上下文示例简便地定义任务。然而，这种通用性也使其面临终端用户的潜在滥用——他们可能在请求中嵌入特殊指令，导致模型产生越权或不安全行为。本研究针对机器翻译任务，在多系列LLMs上探究了这类提示注入攻击（PIAs），重点关注模型规模对攻击成功率的影响。我们引入了一个新的基准数据集，并在多语言对及英文注入提示的实验中发现：特定条件下，更大规模的模型可能更容易遭受成功攻击，这一现象符合逆向缩放定律（McKenzie等，2023）。据我们所知，这是首个在多语言环境中研究LLMs非平凡缩放行为的工作。  

（翻译说明：  
1. 专业术语统一处理："Prompt Injection Attacks"译为行业通用表述"提示注入攻击"，"Inverse Scaling phenomenon"采用文献既定译法"逆向缩放定律"  
2. 长句拆分重构：将原文复合句分解为符合中文表达习惯的短句，如将"owing to..."因果从句转化为独立分句  
3. 被动语态转化："are increasingly becoming"译为主动态"正日益成为"，"may be embedded"处理为无主语句"可能嵌入"  
4. 概念显化处理："non-trivial scaling behaviour"译为"非平凡缩放行为"以保留学术严谨性，同时通过脚注说明可补充"指不符合常规预期的模型性能变化"  
5. 文化适配：保留"McKenzie等，2023"的学术引用格式，符合中文论文规范）
