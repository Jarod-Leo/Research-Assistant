# Challenges in Pre-Training Graph Neural Networks for Context-Based Fake News Detection: An Evaluation of Current Strategies and Resource Limitations

链接: http://arxiv.org/abs/2402.18179v1

原文摘要:
Pre-training of neural networks has recently revolutionized the field of
Natural Language Processing (NLP) and has before demonstrated its effectiveness
in computer vision. At the same time, advances around the detection of fake
news were mainly driven by the context-based paradigm, where different types of
signals (e.g. from social media) form graph-like structures that hold
contextual information apart from the news article to classify. We propose to
merge these two developments by applying pre-training of Graph Neural Networks
(GNNs) in the domain of context-based fake news detection. Our experiments
provide an evaluation of different pre-training strategies for graph-based
misinformation detection and demonstrate that transfer learning does currently
not lead to significant improvements over training a model from scratch in the
domain. We argue that a major current issue is the lack of suitable large-scale
resources that can be used for pre-training.

中文翻译:
神经网络预训练技术近期在自然语言处理（NLP）领域引发革命性变革，此前该技术已在计算机视觉领域展现卓越成效。与此同时，虚假新闻检测领域的进展主要依托于基于上下文的范式——通过整合社交媒体等多源信号构建图结构数据，这些数据除待分类新闻文本外还蕴含丰富的上下文信息。本研究旨在融合这两大发展趋势，将图神经网络（GNN）预训练应用于基于上下文的虚假新闻检测领域。我们通过实验评估了多种图结构虚假信息检测的预训练策略，结果表明：在当前领域内，迁移学习相比从头训练模型尚未能带来显著性能提升。本文指出，当前面临的主要困境在于缺乏适用于预训练的大规模数据集资源。
