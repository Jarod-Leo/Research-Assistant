# An Introduction to Transformers

链接: http://arxiv.org/abs/2304.10557v1

原文摘要:
The transformer is a neural network component that can be used to learn
useful representations of sequences or sets of data-points. The transformer has
driven recent advances in natural language processing, computer vision, and
spatio-temporal modelling. There are many introductions to transformers, but
most do not contain precise mathematical descriptions of the architecture and
the intuitions behind the design choices are often also missing. Moreover, as
research takes a winding path, the explanations for the components of the
transformer can be idiosyncratic. In this note we aim for a mathematically
precise, intuitive, and clean description of the transformer architecture. We
will not discuss training as this is rather standard. We assume that the reader
is familiar with fundamental topics in machine learning including multi-layer
perceptrons, linear transformations, softmax functions and basic probability.

中文翻译:
以下是您提供的英文摘要的中文翻译：

变压器（Transformer）是一种可用于学习序列或数据点集合有效表征的神经网络组件。近年来，该架构在自然语言处理、计算机视觉以及时空建模领域推动了重大进展。虽然已有许多关于变压器的介绍性资料，但多数未能提供架构的精确数学描述，且往往缺失设计选择背后的原理阐释。此外，由于研究路径的曲折性，现有对变压器组件的解释可能存在特异性。本文旨在以数学严谨、直观清晰的方式阐述变压器架构，其中不涉及常规的训练过程讨论。我们默认读者已掌握机器学习基础知识，包括多层感知机、线性变换、Softmax函数及基础概率论。

（说明：根据学术文献翻译规范，对关键术语进行了统一处理：
1. "transformer"译为"变压器"并保留英文原名首现标注
2. "data-points"译为"数据点"而非逐字翻译
3. "spatio-temporal modelling"采用专业译法"时空建模"
4. 将英语长句合理切分为符合中文表达习惯的短句
5. 专业术语如"multi-layer perceptrons"等使用学界通用译名）
