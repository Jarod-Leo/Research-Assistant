# Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models

链接: http://arxiv.org/abs/2310.20081v1

原文摘要:
Personalization, the ability to tailor a system to individual users, is an
essential factor in user experience with natural language processing (NLP)
systems. With the emergence of Large Language Models (LLMs), a key question is
how to leverage these models to better personalize user experiences. To
personalize a language model's output, a straightforward approach is to
incorporate past user data into the language model prompt, but this approach
can result in lengthy inputs exceeding limitations on input length and
incurring latency and cost issues. Existing approaches tackle such challenges
by selectively extracting relevant user data (i.e. selective retrieval) to
construct a prompt for downstream tasks. However, retrieval-based methods are
limited by potential information loss, lack of more profound user
understanding, and cold-start challenges. To overcome these limitations, we
propose a novel summary-augmented approach by extending retrieval-augmented
personalization with task-aware user summaries generated by LLMs. The summaries
can be generated and stored offline, enabling real-world systems with runtime
constraints like voice assistants to leverage the power of LLMs. Experiments
show our method with 75% less of retrieved user data is on-par or outperforms
retrieval augmentation on most tasks in the LaMP personalization benchmark. We
demonstrate that offline summarization via LLMs and runtime retrieval enables
better performance for personalization on a range of tasks under practical
constraints.

中文翻译:
个性化（即根据个体用户需求定制系统的能力）是影响自然语言处理（NLP）系统用户体验的关键因素。随着大语言模型（LLMs）的兴起，如何利用这些模型优化个性化体验成为核心议题。为实现语言模型输出的个性化，传统方法直接将用户历史数据嵌入模型提示词，但会导致输入内容过长——既可能突破输入长度限制，又会引发延迟和成本问题。现有解决方案通过选择性提取相关用户数据（即选择性检索）来构建下游任务提示词，但检索式方法存在固有缺陷：潜在信息丢失、缺乏深层用户理解以及冷启动挑战。

为突破这些限制，我们创新性地提出"摘要增强"方法，通过大语言模型生成的任务感知型用户摘要来扩展检索增强的个性化方案。这些摘要可离线生成并存储，使语音助手等具有实时性约束的实际系统也能充分利用大语言模型的能力。实验表明：在LaMP个性化基准测试中，我们的方法仅需25%的检索数据量，就能在多数任务上达到或超越检索增强的效果。我们证实，通过大语言模型离线摘要与运行时检索的协同，可在实际约束条件下为各类任务提供更优的个性化性能。

（翻译说明：
1. 专业术语统一："retrieval-augmented"译为"检索增强"，"cold-start"译为"冷启动"
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句结构
3. 被动语态转化："can be generated"译为主动式"可离线生成"
4. 概念显化："task-aware"译为"任务感知型"以突出技术特性
5. 数据量化处理："75% less"转化为"仅需25%"更符合中文表述逻辑
6. 技术场景适配："voice assistants"译为"语音助手"符合行业通用译法
7. 学术风格保持：使用"基准测试""协同"等学术规范用语）
