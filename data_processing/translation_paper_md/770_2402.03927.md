# Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs

链接: http://arxiv.org/abs/2402.03927v1

原文摘要:
Natural Language Processing (NLP) research is increasingly focusing on the
use of Large Language Models (LLMs), with some of the most popular ones being
either fully or partially closed-source. The lack of access to model details,
especially regarding training data, has repeatedly raised concerns about data
contamination among researchers. Several attempts have been made to address
this issue, but they are limited to anecdotal evidence and trial and error.
Additionally, they overlook the problem of \emph{indirect} data leaking, where
models are iteratively improved by using data coming from users. In this work,
we conduct the first systematic analysis of work using OpenAI's GPT-3.5 and
GPT-4, the most prominently used LLMs today, in the context of data
contamination. By analysing 255 papers and considering OpenAI's data usage
policy, we extensively document the amount of data leaked to these models
during the first year after the model's release. We report that these models
have been globally exposed to $\sim$4.7M samples from 263 benchmarks. At the
same time, we document a number of evaluation malpractices emerging in the
reviewed papers, such as unfair or missing baseline comparisons and
reproducibility issues. We release our results as a collaborative project on
https://leak-llm.github.io/, where other researchers can contribute to our
efforts.

中文翻译:
自然语言处理（NLP）研究日益聚焦于大语言模型（LLMs）的应用，而当前最流行的模型多为完全或部分闭源。由于无法获取模型细节（尤其是训练数据相关细节），数据污染问题屡屡引发研究者担忧。尽管已有若干尝试解决该问题，但这些探索仅停留在个案经验与试错层面，且忽视了"间接"数据泄露问题——即模型通过用户输入数据实现迭代优化。本研究首次针对当前最主流的GPT-3.5和GPT-4模型，在数据污染背景下展开系统性分析。通过审查255篇论文并结合OpenAI的数据使用政策，我们全面记录了模型发布首年内泄露至这些模型的数据规模。分析表明，这些模型已全局性接触过来自263个基准测试的约470万样本数据。同时，我们在审阅论文中发现了一系列评估失范现象，包括不公平或缺失的基线对比、可复现性缺陷等问题。研究结果已发布于https://leak-llm.github.io/协作平台，诚邀学界同仁共同推进此项工作。

（翻译说明：采用学术论文摘要的严谨表述风格，通过以下处理实现专业性与可读性平衡：
1. 专业术语统一："data contamination"译为"数据污染"、"benchmarks"译为"基准测试"
2. 被动语态转化：将英文被动结构转换为中文主动表述（如"has been exposed to"译为"已接触"）
3. 长句拆分：将原文复合长句分解为符合中文表达习惯的短句
4. 概念显化："indirect data leaking"增译为"间接数据泄露问题"并补充解释性括号
5. 数字规范：保留原文$\sim$4.7M的精确表述，转换为中文常用"约470万"
6. 文化适配："anecdotal evidence"译为"个案经验"更符合中文社科研究表述习惯
7. 补充逻辑连接词："同时"等词增强段落连贯性）
