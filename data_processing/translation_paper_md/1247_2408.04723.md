# Survey: Transformer-based Models in Data Modality Conversion

链接: http://arxiv.org/abs/2408.04723v1

原文摘要:
Transformers have made significant strides across various artificial
intelligence domains, including natural language processing, computer vision,
and audio processing. This success has naturally garnered considerable interest
from both academic and industry researchers. Consequently, numerous Transformer
variants (often referred to as X-formers) have been developed for these fields.
However, a thorough and systematic review of these modality-specific
conversions remains lacking. Modality Conversion involves the transformation of
data from one form of representation to another, mimicking the way humans
integrate and interpret sensory information. This paper provides a
comprehensive review of transformer-based models applied to the primary
modalities of text, vision, and speech, discussing their architectures,
conversion methodologies, and applications. By synthesizing the literature on
modality conversion, this survey aims to underline the versatility and
scalability of transformers in advancing AI-driven content generation and
understanding.

中文翻译:
Transformer模型在人工智能多个领域取得了重大突破，包括自然语言处理、计算机视觉和音频处理。这一成功自然引起了学术界和工业界研究者的广泛关注。因此，针对这些领域已衍生出大量Transformer变体（通常称为X-former）。然而，目前仍缺乏对这些跨模态转换方法全面系统的梳理。模态转换是指将数据从一种表征形式转化为另一种形式，其机制模拟了人类整合与解析多感官信息的过程。本文针对文本、视觉和语音三大主要模态，系统综述了基于Transformer的模型架构、转换方法及应用场景。通过整合模态转换领域的文献，本综述旨在强调Transformer模型在推动AI驱动的内容生成与理解方面所展现的多功能性和可扩展性。

（译文说明：
1. 专业术语处理："X-formers"保留技术社区惯用的"X-former"译法；"modality conversion"统一译为"模态转换"以保持学术严谨性
2. 句式重构：将英文长句拆解为符合中文表达习惯的短句，如将原文第三句重组为因果关系的表达
3. 概念显化："mimicking the way..."译为"其机制模拟了..."，通过增译使学术概念更明晰
4. 学术风格：使用"系统综述""旨在强调"等符合中文论文摘要的规范表达
5. 术语一致性：全文统一"transformer"为"Transformer模型"，"modality"为"模态"）
