# Large Language Model Evaluation via Matrix Entropy

链接: http://arxiv.org/abs/2401.17139v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing and
extended their powerful capabilities to multi-modal domains. As LLMs continue
to advance, it is crucial to develop diverse and appropriate metrics for their
evaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank,
grounded in information theory and geometry principles. Diff-eRank assesses
LLMs by analyzing their hidden representations, providing a quantitative
measure of how efficiently they eliminate redundant information during
training. We demonstrate the applicability of Diff-eRank in both single-modal
(e.g., language) and multi-modal settings. For language models, our results
show that Diff-eRank increases with model size and correlates well with
conventional metrics such as loss and accuracy. In the multi-modal context, we
propose an alignment evaluation method based on the eRank, and verify that
contemporary multi-modal LLMs exhibit strong alignment performance based on our
method. Our code is publicly available at
https://github.com/waltonfuture/Diff-eRank.

中文翻译:
以下是符合要求的学术摘要中文翻译：

【大型语言模型（LLMs）革新了自然语言处理领域，并将其强大能力扩展至多模态领域。随着LLMs的持续发展，建立多样化且适配的评估指标体系显得尤为重要。本文提出了一种基于信息论与几何学原理的新型排序度量方法——Diff-eRank，该方法通过分析模型的隐层表示来评估LLMs，量化表征其在训练过程中消除冗余信息的效率。我们验证了Diff-eRank在单模态（如语言）和多模态场景中的适用性：对于语言模型，实验表明该指标随模型规模增大而提升，且与传统评估指标（如损失值和准确率）具有显著相关性；在多模态场景中，我们基于eRank提出了对齐度评估方法，验证了当前主流多模态LLMs基于本方法均表现出优异的对齐性能。相关代码已开源：https://github.com/waltonfuture/Diff-eRank。】

翻译说明：
1. 专业术语处理：LLMs统一译为"大型语言模型"，"multi-modal"译为"多模态"，"hidden representations"译为"隐层表示"等
2. 学术句式重构：将英文被动语态转换为中文主动表述（如"are evaluated"译为"来评估"），长难句拆分为符合中文表达习惯的短句
3. 概念准确传达："rank-based metric"译为"排序度量方法"，"alignment evaluation"译为"对齐度评估"
4. 数据呈现规范：保留专业术语首字母缩写（LLMs），URL链接完整呈现
5. 学术风格统一：使用"验证了""表明""表现出"等学术动词，保持客观严谨的论述风格
