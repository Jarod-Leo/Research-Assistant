# BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text

链接: http://arxiv.org/abs/2504.19467v1

原文摘要:
Large language models (LLMs) hold great promise for medical applications and
are evolving rapidly, with new models being released at an accelerated pace.
However, current evaluations of LLMs in clinical contexts remain limited. Most
existing benchmarks rely on medical exam-style questions or PubMed-derived
text, failing to capture the complexity of real-world electronic health record
(EHR) data. Others focus narrowly on specific application scenarios, limiting
their generalizability across broader clinical use. To address this gap, we
present BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks
sourced from real-world clinical data sources across nine languages. We
systematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,
GPT-4o, Gemini, and Llama 4) under various inference strategies. With a total
of 13,572 experiments, our results reveal substantial performance variation
across model sizes, languages, natural language processing tasks, and clinical
specialties. Notably, we demonstrate that open-source LLMs can achieve
performance comparable to proprietary models, while medically fine-tuned LLMs
based on older architectures often underperform versus updated general-purpose
models. The BRIDGE and its corresponding leaderboard serve as a foundational
resource and a unique reference for the development and evaluation of new LLMs
in real-world clinical text understanding.
  The BRIDGE leaderboard:
https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）在医疗领域展现出巨大潜力且发展迅猛，新模型正以加速态势持续涌现。然而当前针对临床场景的LLM评估仍存在局限：多数现有基准测试依赖于医学考试式题目或PubMed衍生的文本，未能捕捉真实世界电子健康记录（EHR）数据的复杂性；另一些则过度聚焦特定应用场景，限制了其在更广泛临床用途中的普适性。为弥补这一空白，我们推出BRIDGE——一个包含87项任务的多语言综合基准测试集，其任务源自九种语言的真实临床数据源。我们系统评估了52个前沿LLM（包括DeepSeek-R1、GPT-4o、Gemini和Llama 4）在不同推理策略下的表现。通过13,572次实验，我们发现模型性能在参数量级、语言类型、自然语言处理任务及临床专科领域均存在显著差异。值得注意的是，研究表明开源LLM能达到与专有模型相当的性能，而基于旧架构的医学微调模型往往逊色于更新的通用模型。BRIDGE及其对应排行榜为临床文本理解领域的新LLM开发与评估提供了基础性资源和独特参照标准。

BRIDGE排行榜：
https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard

（翻译严格遵循以下原则：
1. 专业术语准确统一："electronic health record"译为"电子健康记录"，"fine-tuned"译为"微调"
2. 长句拆分重组：将原文复合句按中文表达习惯分解为多个短句
3. 被动语态转化："are released"译为主动态"持续涌现"
4. 学术用语规范："benchmark"译为"基准测试"，"generalizability"译为"普适性"
5. 重要概念保留原名称：LLM、EHR等缩写首次出现时标注全称
6. 数据精确传达：87项任务、52个模型等数字信息完整保留
7. 超链接位置与格式严格对应原文）
