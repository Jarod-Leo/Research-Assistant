# Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot

链接: http://arxiv.org/abs/2404.17216v1

原文摘要:
Many multilingual communities, including numerous in Africa, frequently
engage in code-switching during conversations. This behaviour stresses the need
for natural language processing technologies adept at processing code-switched
text. However, data scarcity, particularly in African languages, poses a
significant challenge, as many are low-resourced and under-represented. In this
study, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English
code-switched sentences, enhancing diversity using topic-keyword pairs,
linguistic guidelines, and few-shot examples. Our findings indicate that the
quality of generated sentences for languages using non-Latin scripts, like
Yoruba, is considerably lower when compared with the high Afrikaans-English
success rate. There is therefore a notable opportunity to refine prompting
guidelines to yield sentences suitable for the fine-tuning of language models.
We propose a framework for augmenting the diversity of synthetically generated
code-switched data using GPT and propose leveraging this technology to mitigate
data scarcity in low-resourced languages, underscoring the essential role of
native speakers in this process.

中文翻译:
许多多语言社区（包括非洲众多地区）在对话中频繁出现语码转换现象。这种行为凸显了对能够熟练处理语码混合文本的自然语言处理技术的需求。然而，数据稀缺问题——尤其是非洲语言领域——构成了重大挑战，因为这些语言大多属于资源匮乏型且代表性不足。本研究通过提示GPT-3.5生成南非荷兰语-英语和约鲁巴语-英语的语码混合句，并采用主题关键词组合、语言学指导原则和少量示例来增强多样性。研究发现：与南非荷兰语-英语的高成功率相比，使用非拉丁文字的语言（如约鲁巴语）所生成句子的质量显著偏低。这为优化提示模板以生成适用于语言模型微调的句子提供了重要改进空间。我们提出一个利用GPT增强合成语码混合数据多样性的框架，建议运用该技术缓解资源匮乏语言的数据短缺问题，同时强调以母语者为核心参与者的关键作用。
