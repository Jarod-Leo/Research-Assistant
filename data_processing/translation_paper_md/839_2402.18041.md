# Datasets for Large Language Models: A Comprehensive Survey

链接: http://arxiv.org/abs/2402.18041v1

原文摘要:
This paper embarks on an exploration into the Large Language Model (LLM)
datasets, which play a crucial role in the remarkable advancements of LLMs. The
datasets serve as the foundational infrastructure analogous to a root system
that sustains and nurtures the development of LLMs. Consequently, examination
of these datasets emerges as a critical topic in research. In order to address
the current lack of a comprehensive overview and thorough analysis of LLM
datasets, and to gain insights into their current status and future trends,
this survey consolidates and categorizes the fundamental aspects of LLM
datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction
Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5)
Traditional Natural Language Processing (NLP) Datasets. The survey sheds light
on the prevailing challenges and points out potential avenues for future
investigation. Additionally, a comprehensive review of the existing available
dataset resources is also provided, including statistics from 444 datasets,
covering 8 language categories and spanning 32 domains. Information from 20
dimensions is incorporated into the dataset statistics. The total data size
surveyed surpasses 774.5 TB for pre-training corpora and 700M instances for
other datasets. We aim to present the entire landscape of LLM text datasets,
serving as a comprehensive reference for researchers in this field and
contributing to future studies. Related resources are available at:
https://github.com/lmmlzn/Awesome-LLMs-Datasets.

中文翻译:
本文深入探究了大型语言模型（LLM）数据集这一推动LLM取得显著进展的核心要素。这些数据集如同支撑LLM发展的根系基础设施，对其研究已成为关键课题。针对当前学界缺乏对LLM数据集的系统性梳理与深度分析，为全面把握其发展现状与未来趋势，本综述从五个维度对LLM数据集的基础要素进行整合归类：（1）预训练语料库；（2）指令微调数据集；（3）偏好数据集；（4）评估数据集；（5）传统自然语言处理（NLP）数据集。研究揭示了当前面临的突出挑战，并指明了未来探索的潜在路径。

此外，本文对现有可用数据集资源进行了全景式梳理：涵盖444个数据集的统计信息，涉及8种语言类型与32个应用领域，数据集统计维度达20项。经统计，预训练语料总规模超过774.5TB，其他类型数据集总量突破7亿条实例。我们力图完整呈现LLM文本数据集的全景图，为领域研究者提供权威参考，助力未来研究。相关资源详见：https://github.com/lmmlzn/Awesome-LLMs-Datasets。

（注：根据学术论文摘要的文体特征，译文在保持专业性的同时注重逻辑连贯性，采用"探究""要素""维度""全景式"等学术用语；将英语长句合理切分为符合中文表达习惯的短句；专业术语如"fine-tuning"统一译为"微调"；通过"根系基础设施"等比喻保持原文形象化表达；数据单位按中文习惯转换为"TB/亿条"；补充"注"字实现自然衔接；最后保留原始URL确保信息完整。）
