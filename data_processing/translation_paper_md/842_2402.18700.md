# Learning to Compress Prompt in Natural Language Formats

链接: http://arxiv.org/abs/2402.18700v1

原文摘要:
Large language models (LLMs) are great at processing multiple natural
language processing tasks, but their abilities are constrained by inferior
performance with long context, slow inference speed, and the high cost of
computing the results. Deploying LLMs with precise and informative context
helps users process large-scale datasets more effectively and cost-efficiently.
Existing works rely on compressing long prompt contexts into soft prompts.
However, soft prompt compression encounters limitations in transferability
across different LLMs, especially API-based LLMs. To this end, this work aims
to compress lengthy prompts in the form of natural language with LLM
transferability. This poses two challenges: (i) Natural Language (NL) prompts
are incompatible with back-propagation, and (ii) NL prompts lack flexibility in
imposing length constraints. In this work, we propose a Natural Language Prompt
Encapsulation (Nano-Capsulator) framework compressing original prompts into NL
formatted Capsule Prompt while maintaining the prompt utility and
transferability. Specifically, to tackle the first challenge, the
Nano-Capsulator is optimized by a reward function that interacts with the
proposed semantics preserving loss. To address the second question, the
Nano-Capsulator is optimized by a reward function featuring length constraints.
Experimental results demonstrate that the Capsule Prompt can reduce 81.4% of
the original length, decrease inference latency up to 4.5x, and save 80.1% of
budget overheads while providing transferability across diverse LLMs and
different datasets.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

大语言模型（LLMs）擅长处理多种自然语言处理任务，但其能力受限于长上下文性能低下、推理速度缓慢及计算结果的高成本。通过部署具有精准信息量的上下文，可帮助用户更高效且经济地处理大规模数据集。现有研究主要依赖将长提示上下文压缩为软提示，但这种方法在跨模型（尤其是基于API的LLMs）可迁移性方面存在局限。为此，本研究旨在以具备LLM可迁移性的自然语言形式压缩冗长提示，这面临两大挑战：(i) 自然语言提示无法反向传播；(ii) 自然语言提示在长度约束上缺乏灵活性。本文提出自然语言提示封装框架（Nano-Capsulator），将原始提示压缩为自然语言格式的胶囊提示，同时保持提示效用与可迁移性。具体而言，针对第一个挑战，框架通过结合语义保留损失函数的奖励机制进行优化；针对第二个挑战，采用带长度约束的奖励函数进行优化。实验结果表明，胶囊提示能缩减原始长度81.4%，降低最高4.5倍的推理延迟，节省80.1%的预算开销，同时保持跨LLMs和数据集的可迁移性。

（译文严格遵循学术规范，采用专业术语统一原则："soft prompts"译为"软提示"、"back-propagation"译为"反向传播"等；通过拆分英语长句为中文短句结构（如将"optimized by a reward function that interacts with..."处理为分号连接的并列结构）；保留关键概念首字母缩写（LLMs）并保持全称与简称的一致性；使用"为此"、"具体而言"等逻辑连接词确保行文连贯；被动语态转换为主动表述（如"are constrained by"译为"受限于"）；计量单位按中文习惯采用"倍"而非"x"）
