# Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats

链接: http://arxiv.org/abs/2410.22293v1

原文摘要:
Recent advancements in Large Language Models (LLMs) have significantly
improved their capabilities in natural language processing and code synthesis,
enabling more complex applications across different fields. This paper explores
the application of LLMs in the context of code mutation, a process where the
structure of program code is altered without changing its functionality.
Traditionally, code mutation has been employed to increase software robustness
in mission-critical applications. Additionally, mutation engines have been
exploited by malware developers to evade the signature-based detection methods
employed by malware detection systems. Existing code mutation engines, often
used by such threat actors, typically result in only limited variations in the
malware, which can still be identified through static code analysis. However,
the agility demonstrated by an LLM-based code synthesizer could significantly
change this threat landscape by allowing for more complex code mutations that
are not easily detected using static analysis. One can increase variations of
codes synthesized by a pre-trained LLM through fine-tuning and retraining. This
process is what we refer to as code mutation training. In this paper, we
propose a novel definition of code mutation training tailored for pre-trained
LLM-based code synthesizers and demonstrate this training on a lightweight
pre-trained model. Our approach involves restructuring (i.e., mutating) code at
the subroutine level, which allows for more manageable mutations while
maintaining the semantic integrity verified through unit testing. Our
experimental results illustrate the effectiveness of our approach in improving
code mutation capabilities of LLM-based program synthesizers in producing
varied and functionally correct code solutions, showcasing their potential to
transform the landscape of code mutation and the threats associated with it.

中文翻译:
近年来，大型语言模型（LLMs）在自然语言处理和代码合成领域取得显著进展，使其能够支持跨领域的复杂应用。本文探讨了LLMs在代码变异中的应用——该技术通过改变程序代码结构而不影响其功能。传统上，代码变异技术被用于提升关键任务应用中的软件鲁棒性，同时也被恶意软件开发人员用来规避基于特征签名的恶意软件检测系统。现有威胁行为者常用的代码变异引擎通常只能产生有限变体，仍可通过静态代码分析识别。然而，基于LLM的代码合成器所展现的敏捷性可能彻底改变这一威胁格局，其生成的复杂代码变异体能够有效规避静态分析检测。

通过微调和再训练，可以显著增加预训练LLM合成代码的变异多样性，这一过程我们称之为"代码变异训练"。本文首次针对基于预训练LLM的代码合成器提出了定制化的代码变异训练定义，并在轻量级预训练模型上进行了实证研究。我们的方法在子程序级别进行代码重构（即变异），既能保持经单元测试验证的语义完整性，又能实现更可控的变异操作。实验结果表明，该方法有效提升了LLM程序合成器生成多样化且功能正确的代码解决方案的能力，展现了其重塑代码变异技术格局及相关威胁生态的潜力。

（译文特点说明：
1. 专业术语准确统一："code mutation"译为"代码变异"，"static analysis"译为"静态分析"
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句
3. 逻辑显化处理：通过破折号、括号等标点明确技术概念的解释关系
4. 动态对等翻译："agility"译为"敏捷性"而非字面直译，更符合技术语境
5. 学术风格保持：使用"实证研究""展现...潜力"等符合论文摘要的规范表达）
