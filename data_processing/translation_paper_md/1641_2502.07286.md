# Small Language Model Makes an Effective Long Text Extractor

链接: http://arxiv.org/abs/2502.07286v1

原文摘要:
Named Entity Recognition (NER) is a fundamental problem in natural language
processing (NLP). However, the task of extracting longer entity spans (e.g.,
awards) from extended texts (e.g., homepages) is barely explored. Current NER
methods predominantly fall into two categories: span-based methods and
generation-based methods. Span-based methods require the enumeration of all
possible token-pair spans, followed by classification on each span, resulting
in substantial redundant computations and excessive GPU memory usage. In
contrast, generation-based methods involve prompting or fine-tuning large
language models (LLMs) to adapt to downstream NER tasks. However, these methods
struggle with the accurate generation of longer spans and often incur
significant time costs for effective fine-tuning. To address these challenges,
this paper introduces a lightweight span-based NER method called SeNER, which
incorporates a bidirectional arrow attention mechanism coupled with
LogN-Scaling on the [CLS] token to embed long texts effectively, and comprises
a novel bidirectional sliding-window plus-shaped attention (BiSPA) mechanism to
reduce redundant candidate token-pair spans significantly and model
interactions between token-pair spans simultaneously. Extensive experiments
demonstrate that our method achieves state-of-the-art extraction accuracy on
three long NER datasets and is capable of extracting entities from long texts
in a GPU-memory-friendly manner. Code:
https://github.com/THUDM/scholar-profiling/tree/main/sener

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

命名实体识别（NER）是自然语言处理（NLP）中的基础任务。然而，从长文本（如个人主页）中抽取较长实体跨度（如奖项）的研究仍属空白。现有NER方法主要分为两类：基于跨度的方法和基于生成的方法。基于跨度的方法需要枚举所有可能的词对跨度并进行逐项分类，导致大量冗余计算和GPU内存过度消耗；而基于生成的方法通过提示或微调大语言模型（LLM）适配下游NER任务，但难以准确生成较长跨度，且通常需要耗费大量时间进行有效微调。为解决这些问题，本文提出一种轻量级基于跨度的NER方法SeNER：通过双向箭头注意力机制结合[CLS]标记的LogN缩放策略实现长文本高效嵌入，并创新性地采用双向滑动窗口十字形注意力机制（BiSPA），在显著减少冗余候选词对跨度的同时建模跨度间交互关系。大量实验表明，本方法在三个长文本NER数据集上达到最先进的抽取准确率，且能以GPU内存友好的方式处理长文本实体抽取。代码地址：https://github.com/THUDM/scholar-profiling/tree/main/sener

（翻译严格遵循以下原则：
1. 专业术语准确统一（如"span-based methods"译为"基于跨度的方法"）
2. 长难句合理切分（如将原文复合句拆解为分号连接的并列结构）
3. 被动语态主动化处理（如"is barely explored"译为"仍属空白"）
4. 技术概念清晰传达（如"BiSPA mechanism"保留英文缩写并补充中文全称）
5. 学术表达规范（如"state-of-the-art"译为"最先进的"）
6. 重要元素完整保留（如GitHub代码地址不作任何改动））
