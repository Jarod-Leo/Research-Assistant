# Modelando procesos cognitivos de la lectura natural con GPT-2

链接: http://arxiv.org/abs/2409.20174v1

原文摘要:
The advancement of the Natural Language Processing field has enabled the
development of language models with a great capacity for generating text. In
recent years, Neuroscience has been using these models to better understand
cognitive processes. In previous studies, we found that models like Ngrams and
LSTM networks can partially model Predictability when used as a co-variable to
explain readers' eye movements. In the present work, we further this line of
research by using GPT-2 based models. The results show that this architecture
achieves better outcomes than its predecessors.

中文翻译:
自然语言处理领域的发展使得文本生成能力强大的语言模型得以开发。近年来，神经科学界正运用这些模型来深化对认知过程的理解。在前期研究中，我们发现当Ngrams和LSTM网络等模型作为解释读者眼动的协变量时，能够部分模拟预测性。本研究通过采用基于GPT-2的模型进一步推进了该研究方向，结果表明该架构取得了优于前代模型的性能表现。

（翻译说明：根据学术论文摘要的文体特征，在保持专业性的同时采用简洁流畅的句式结构。关键术语如"Predictability"译为"预测性"符合认知心理学领域规范，"co-variable"译为"协变量"准确体现统计学概念。通过"深化"、"推进"等动词体现研究进展的递进关系，最后用"优于前代模型"的表述既忠实原文又符合中文比较级表达习惯。）
