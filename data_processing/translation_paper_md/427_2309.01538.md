# ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning

链接: http://arxiv.org/abs/2309.01538v1

原文摘要:
Logical rules are essential for uncovering the logical connections between
relations, which could improve reasoning performance and provide interpretable
results on knowledge graphs (KGs). Although there have been many efforts to
mine meaningful logical rules over KGs, existing methods suffer from
computationally intensive searches over the rule space and a lack of
scalability for large-scale KGs. Besides, they often ignore the semantics of
relations which is crucial for uncovering logical connections. Recently, large
language models (LLMs) have shown impressive performance in the field of
natural language processing and various applications, owing to their emergent
ability and generalizability. In this paper, we propose a novel framework,
ChatRule, unleashing the power of large language models for mining logical
rules over knowledge graphs. Specifically, the framework is initiated with an
LLM-based rule generator, leveraging both the semantic and structural
information of KGs to prompt LLMs to generate logical rules. To refine the
generated rules, a rule ranking module estimates the rule quality by
incorporating facts from existing KGs. Last, the ranked rules can be used to
conduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,
w.r.t. different rule quality metrics and downstream tasks, showing the
effectiveness and scalability of our method.

中文翻译:
逻辑规则对于揭示关系间的逻辑关联至关重要，它不仅能提升知识图谱（KGs）上的推理性能，还能提供可解释的结果。尽管已有诸多研究致力于挖掘知识图谱中有意义的逻辑规则，现有方法仍存在规则空间搜索计算密集、难以适应大规模知识图谱的扩展需求等局限性。此外，这些方法往往忽视了对揭示逻辑连接至关重要的关系语义。近年来，大型语言模型（LLMs）凭借其涌现能力和泛化性，在自然语言处理领域及各类应用中展现出卓越性能。本文提出创新框架ChatRule，通过释放大型语言模型的潜力来实现知识图谱上的逻辑规则挖掘。具体而言，该框架首先采用基于LLM的规则生成器，结合知识图谱的语义与结构信息来激发LLM生成逻辑规则；随后通过规则排序模块，利用现有知识图谱中的事实评估规则质量以进行精炼；最终，经过排序的规则可用于知识图谱推理。ChatRule在四个大规模知识图谱上针对不同规则质量指标和下游任务进行评估，结果验证了该方法的有效性和可扩展性。
