# Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization

链接: http://arxiv.org/abs/2311.01544v1

原文摘要:
Large Language Models (LLMs) have reshaped natural language processing with
their impressive capabilities. However, their ever-increasing size has raised
concerns about their effective deployment and the need for LLM compression.
This study introduces the Divergent Token Metrics (DTMs), a novel approach to
assessing compressed LLMs, addressing the limitations of traditional perplexity
or accuracy measures that fail to accurately reflect text generation quality.
DTMs measure token divergences that allow deeper insights into the subtleties
of model compression, in particular, when evaluating components' impacts
individually. Utilizing the First Divergent Token Metric (FDTM) in model
sparsification reveals that 25% of all attention components can be pruned
beyond 90% on the Llama-2 model family, still keeping SOTA performance. For
quantization, FDTM suggests that more than 80% of parameters can be naively
transformed to int8 without special outlier management. These evaluations
indicate the necessity of choosing appropriate compressions for parameters
individually -- and that FDTM can identify those -- while standard metrics
result in deteriorated outcomes.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）凭借其卓越性能重塑了自然语言处理领域。然而，模型规模的持续增长引发了对其有效部署的担忧，也凸显了模型压缩的必要性。本研究提出发散标记度量（DTMs）这一创新评估方法，解决了传统困惑度或准确率指标无法准确反映文本生成质量的局限性。该度量通过分析标记级发散特征，能够深入揭示模型压缩的微观影响，特别是在单独评估组件作用时表现突出。应用首标记发散度量（FDTM）对Llama-2系列模型进行稀疏化实验表明：25%的注意力组件可修剪90%以上仍保持前沿性能；在量化方面，FDTM显示超过80%参数可直接转为int8格式而无需特殊异常值处理。这些评估证实：不同参数需要个性化选择压缩方案（FDTM可有效识别），而传统度量标准会导致性能劣化。

（翻译严格遵循以下原则：
1. 专业术语统一（如"quantization"译为"量化"）
2. 被动语态转换（英文被动→中文主动）
3. 长句拆分重组（如原文最后复合句分解为因果句式）
4. 学术用语规范（"SOTA performance"译为"前沿性能"而非口语化表达）
5. 保留技术细节准确性（如"int8"保持原格式）
6. 逻辑连接显化（添加"而"等转折词明确对比关系））
