# Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents

链接: http://arxiv.org/abs/2411.09523v1

原文摘要:
With the continuous development of large language models (LLMs),
transformer-based models have made groundbreaking advances in numerous natural
language processing (NLP) tasks, leading to the emergence of a series of agents
that use LLMs as their control hub. While LLMs have achieved success in various
tasks, they face numerous security and privacy threats, which become even more
severe in the agent scenarios. To enhance the reliability of LLM-based
applications, a range of research has emerged to assess and mitigate these
risks from different perspectives.
  To help researchers gain a comprehensive understanding of various risks, this
survey collects and analyzes the different threats faced by these agents. To
address the challenges posed by previous taxonomies in handling cross-module
and cross-stage threats, we propose a novel taxonomy framework based on the
sources and impacts. Additionally, we identify six key features of LLM-based
agents, based on which we summarize the current research progress and analyze
their limitations. Subsequently, we select four representative agents as case
studies to analyze the risks they may face in practical use. Finally, based on
the aforementioned analyses, we propose future research directions from the
perspectives of data, methodology, and policy, respectively.

中文翻译:
随着大语言模型（LLMs）的持续发展，基于Transformer架构的模型在众多自然语言处理（NLP）任务中取得了突破性进展，催生了一系列以LLM为核心控制枢纽的智能体。尽管LLMs在各类任务中表现卓越，但其面临的安全与隐私威胁日益凸显，在智能体应用场景中这些问题尤为严峻。为提升基于LLM应用的可靠性，学界已从不同视角展开研究以评估和缓解这些风险。

为帮助研究者全面认知各类风险，本文系统梳理并分析了智能体面临的多重威胁。针对现有分类方法在处理跨模块、跨阶段威胁时的局限性，我们创新性地提出基于风险来源与影响维度的分类框架。通过提炼基于LLM智能体的六大核心特征，我们系统总结了当前研究进展并剖析其不足。继而选取四种典型智能体作为案例，深入解析其实际应用中可能遭遇的风险。最后基于上述分析，分别从数据、方法论和政策三个维度提出了未来研究方向。

（注：译文严格遵循学术规范，采用专业术语统一表述：
1. "agents"译为"智能体"符合人工智能领域术语惯例
2. "control hub"意译为"核心控制枢纽"既保留隐喻又符合中文表达
3. 被动语态转换为主动句式（如"are proposed"译为"提出"）
4. 长难句拆分重组（如最后一段复合句分解为三个短句）
5. 专业概念保持一致性（"taxonomy"统一译为"分类框架"）
