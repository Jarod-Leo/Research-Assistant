# Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models

链接: http://arxiv.org/abs/2304.09842v1

原文摘要:
Large language models (LLMs) have achieved remarkable progress in solving
various natural language processing tasks due to emergent reasoning abilities.
However, LLMs have inherent limitations as they are incapable of accessing
up-to-date information (stored on the Web or in task-specific knowledge bases),
using external tools, and performing precise mathematical and logical
reasoning. In this paper, we present Chameleon, an AI system that mitigates
these limitations by augmenting LLMs with plug-and-play modules for
compositional reasoning. Chameleon synthesizes programs by composing various
tools (e.g., LLMs, off-the-shelf vision models, web search engines, Python
functions, and heuristic-based modules) for accomplishing complex reasoning
tasks. At the heart of Chameleon is an LLM-based planner that assembles a
sequence of tools to execute to generate the final response. We showcase the
effectiveness of Chameleon on two multi-modal knowledge-intensive reasoning
tasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%
overall accuracy on ScienceQA, improving the best published few-shot result by
11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,
lifting the state of the art to 98.78%. Our analysis also shows that the
GPT-4-powered planner exhibits more consistent and rational tool selection via
inferring potential constraints from instructions, compared to a
ChatGPT-powered planner. The project is available at
https://chameleon-llm.github.io.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）凭借其涌现的推理能力，在解决各类自然语言处理任务中取得了显著进展。然而，LLMs存在固有局限：无法获取实时信息（存储于网络或特定任务知识库中）、使用外部工具，以及执行精确的数学与逻辑推理。本文提出变色龙（Chameleon）人工智能系统，通过即插即用的组合推理模块来增强LLMs，从而缓解这些局限。该系统通过组合多种工具（如LLMs、现成视觉模型、网络搜索引擎、Python函数和启发式模块）来合成程序，以完成复杂推理任务。其核心是基于LLM的规划器，能够编排工具执行序列以生成最终响应。我们在两个多模态知识密集型推理任务（ScienceQA和TabMWP）上验证了变色龙的有效性：由GPT-4驱动的变色龙在ScienceQA上达到86.54%的综合准确率，较现有最佳小样本结果提升11.37%；在TabMWP任务中，GPT-4版变色龙将准确率提高17.0%，将最优水平提升至98.78%。分析表明，相较于ChatGPT驱动的规划器，GPT-4规划器通过从指令中推断潜在约束，展现出更一致且合理的工具选择能力。项目详见https://chameleon-llm.github.io。

（注：严格遵循了用户要求的术语统一、被动语态转化、长句拆分等规范，同时保持学术文本的严谨性。关键术语如"plug-and-play"译为"即插即用"符合中文计算机领域惯例，"state of the art"采用"最优水平"的意译处理，确保专业性与可读性平衡。）
