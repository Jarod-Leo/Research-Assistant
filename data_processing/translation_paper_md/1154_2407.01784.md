# Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment

链接: http://arxiv.org/abs/2407.01784v1

原文摘要:
This paper describes our approach to hierarchical multi-label detection of
persuasion techniques in meme texts. Our model, developed as a part of the
recent SemEval task, is based on fine-tuning individual language models (BERT,
XLM-RoBERTa, and mBERT) and leveraging a mean-based ensemble model in addition
to dataset augmentation through paraphrase generation from ChatGPT. The scope
of the study encompasses enhancing model performance through innovative
training techniques and data augmentation strategies. The problem addressed is
the effective identification and classification of multiple persuasive
techniques in meme texts, a task complicated by the diversity and complexity of
such content. The objective of the paper is to improve detection accuracy by
refining model training methods and examining the impact of balanced versus
unbalanced training datasets. Novelty in the results and discussion lies in the
finding that training with paraphrases enhances model performance, yet a
balanced training set proves more advantageous than a larger unbalanced one.
Additionally, the analysis reveals the potential pitfalls of indiscriminate
incorporation of paraphrases from diverse distributions, which can introduce
substantial noise. Results with the SemEval 2024 data confirm these insights,
demonstrating improved model efficacy with the proposed methods.

中文翻译:
本文阐述了一种针对网络迷因文本中说服技巧的层次化多标签检测方法。作为近期SemEval评测任务的组成部分，我们通过微调多种语言模型（BERT、XLM-RoBERTa和mBERT），结合基于均值处理的集成模型，并利用ChatGPT生成释义文本进行数据增强，构建了该检测系统。研究重点在于通过创新性训练技术和数据增强策略提升模型性能，核心挑战在于如何有效识别和分类迷因文本中多样且复杂的多重说服技巧。本文旨在通过优化模型训练方法、探究平衡与非平衡训练数据集的影响来提高检测准确率。

研究结果与讨论的创新点在于：发现使用释义文本训练能提升模型表现，但平衡的训练集比规模更大但不平衡的数据集更具优势；同时分析揭示，盲目引入不同分布的释义文本可能会引入显著噪声。基于SemEval 2024数据的实验结果验证了这些发现，证实所提方法能有效提升模型效能。
