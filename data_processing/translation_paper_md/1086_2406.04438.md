# TexIm FAST: Text-to-Image Representation for Semantic Similarity Evaluation using Transformers

链接: http://arxiv.org/abs/2406.04438v1

原文摘要:
One of the principal objectives of Natural Language Processing (NLP) is to
generate meaningful representations from text. Improving the informativeness of
the representations has led to a tremendous rise in the dimensionality and the
memory footprint. It leads to a cascading effect amplifying the complexity of
the downstream model by increasing its parameters. The available techniques
cannot be applied to cross-modal applications such as text-to-image. To
ameliorate these issues, a novel Text-to-Image methodology for generating
fixed-length representations through a self-supervised Variational Auto-Encoder
(VAE) for semantic evaluation applying transformers (TexIm FAST) has been
proposed in this paper. The pictorial representations allow oblivious inference
while retaining the linguistic intricacies, and are potent in cross-modal
applications. TexIm FAST deals with variable-length sequences and generates
fixed-length representations with over 75% reduced memory footprint. It
enhances the efficiency of the models for downstream tasks by reducing its
parameters. The efficacy of TexIm FAST has been extensively analyzed for the
task of Semantic Textual Similarity (STS) upon the MSRPC, CNN/ Daily Mail, and
XSum data-sets. The results demonstrate 6% improvement in accuracy compared to
the baseline and showcase its exceptional ability to compare disparate length
sequences such as a text with its summary.

中文翻译:
自然语言处理（NLP）的核心目标之一是从文本生成具有意义的表征。随着表征信息量的提升，其维度与内存占用呈指数级增长，这种增长会通过增加下游模型参数产生级联效应，进而放大模型复杂度。现有技术无法应用于文本到图像等跨模态场景。为缓解这些问题，本文提出了一种创新的文本到图像方法——通过自监督变分自编码器（VAE）生成固定长度表征的语义评估框架TexIm FAST（基于Transformer的文本图像固定表征生成）。该方法生成的图像表征能在保留语言复杂性的同时实现无感知推理，并具备强大的跨模态应用能力。TexIm FAST可处理变长序列，生成的固定长度表征内存占用减少75%以上，通过精简参数显著提升下游任务模型效率。研究在MSRPC、CNN/Daily Mail和XSum数据集上对TexIm FAST的语义文本相似度（STS）任务表现进行了全面评估，结果显示其准确率较基线方法提升6%，特别在原文与摘要等长度差异文本的对比任务中展现出卓越性能。
