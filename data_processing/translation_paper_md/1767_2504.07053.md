# TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling

链接: http://arxiv.org/abs/2504.07053v1

原文摘要:
Large Language Models (LLMs) excel in text-based natural language processing
tasks but remain constrained by their reliance on textual inputs and outputs.
To enable more natural human-LLM interaction, recent progress have focused on
deriving a spoken language model (SLM) that can not only listen but also
generate speech. To achieve this, a promising direction is to conduct
speech-text joint modeling. However, recent SLM still lag behind text LLM due
to the modality mismatch. One significant mismatch can be the sequence lengths
between speech and text tokens. To address this, we introduce Text-Aligned
Speech Tokenization and Embedding (TASTE), a method that directly addresses the
modality gap by aligning speech token with the corresponding text transcription
during the tokenization stage. We propose a method that can achieve this
through the special aggregation mechanism and with speech reconstruction as the
training objective. We conduct extensive experiments and show that TASTE can
preserve essential paralinguistic information while dramatically reducing the
token sequence length. Furthermore, by leveraging TASTE, we can adapt
text-based LLMs into effective SLMs with parameter-efficient fine-tuning
techniques such as Low-Rank Adaptation (LoRA). Experimental results on
benchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based
SLMs perform similarly to previous full-finetuning methods. To our knowledge,
TASTE is the first end-to-end approach that utilizes a reconstruction objective
to automatically learn a text-aligned speech tokenization and embedding
suitable for spoken language modeling. Our demo, code, and models are publicly
available at https://github.com/mtkresearch/TASTE-SpokenLM.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）在基于文本的自然语言处理任务中表现卓越，但其依赖文本输入输出的特性仍构成限制。为实现更自然的人机交互，近期研究致力于开发不仅能听取还能生成语音的口语语言模型（SLM）。实现这一目标的有效途径是建立语音-文本联合建模，然而当前SLM由于模态失配问题仍落后于文本LLM。其中关键失配因素在于语音与文本标记的序列长度差异。为此，我们提出文本对齐语音标记化与嵌入方法（TASTE），该方法通过在标记化阶段将语音标记与对应文本转录对齐，直接解决模态差异问题。我们设计了一种通过特殊聚合机制实现该目标的方法，并以语音重构作为训练目标。大量实验表明，TASTE能在显著缩短标记序列长度的同时保留关键副语言信息。进一步地，通过结合参数高效微调技术（如低秩适应LoRA），我们可利用TASTE将基于文本的LLM适配为高效SLM。在SALMON和StoryCloze等基准任务上的实验证明，基于TASTE的SLM能达到与完整微调方法相当的性能。据我们所知，TASTE是首个采用重构目标来自动学习适用于口语建模的文本对齐语音标记化与嵌入的端到端方法。我们的演示、代码及模型已开源：https://github.com/mtkresearch/TASTE-SpokenLM。

（注：严格遵循了用户要求的术语统一、被动语态转化、长句拆分等规范，同时保持了学术文本的严谨性，专业术语如"paralinguistic information"译为"副语言信息"符合语言学领域惯例）
