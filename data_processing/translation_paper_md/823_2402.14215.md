# Swin3D++: Effective Multi-Source Pretraining for 3D Indoor Scene Understanding

链接: http://arxiv.org/abs/2402.14215v1

原文摘要:
Data diversity and abundance are essential for improving the performance and
generalization of models in natural language processing and 2D vision. However,
3D vision domain suffers from the lack of 3D data, and simply combining
multiple 3D datasets for pretraining a 3D backbone does not yield significant
improvement, due to the domain discrepancies among different 3D datasets that
impede effective feature learning. In this work, we identify the main sources
of the domain discrepancies between 3D indoor scene datasets, and propose
Swin3D++, an enhanced architecture based on Swin3D for efficient pretraining on
multi-source 3D point clouds. Swin3D++ introduces domain-specific mechanisms to
Swin3D's modules to address domain discrepancies and enhance the network
capability on multi-source pretraining. Moreover, we devise a simple
source-augmentation strategy to increase the pretraining data scale and
facilitate supervised pretraining. We validate the effectiveness of our design,
and demonstrate that Swin3D++ surpasses the state-of-the-art 3D pretraining
methods on typical indoor scene understanding tasks. Our code and models will
be released at https://github.com/microsoft/Swin3D

中文翻译:
以下是符合学术规范的中文翻译：

【摘要】数据多样性与丰富性对于提升自然语言处理与二维视觉领域模型的性能及泛化能力至关重要。然而，三维视觉领域长期面临数据匮乏的困境，且由于不同三维数据集间存在的领域差异会阻碍有效特征学习，简单地组合多个三维数据集进行骨干网络预训练难以获得显著性能提升。本研究系统分析了三维室内场景数据集间领域差异的主要成因，并提出Swin3D++——一种基于Swin3D架构的增强型三维点云多源预训练框架。该框架通过在Swin3D模块中引入领域自适应机制来消除领域差异，同时增强网络在多源预训练中的表征能力。此外，我们设计了一种简洁的数据源增强策略，通过扩展预训练数据规模来提升监督式预训练效果。实验验证表明，Swin3D++在典型室内场景理解任务上显著优于当前最先进的三维预训练方法。相关代码与模型将在https://github.com/microsoft/Swin3D开源。

（翻译说明：1. 采用学术摘要惯用的第三人称客观表述；2. 专业术语如"domain discrepancies"译为"领域差异"、"supervised pretraining"译为"监督式预训练"等保持一致性；3. 长句按中文习惯切分为短句，如将原文第二句拆分为因果关系的两个分句；4. 被动语态转换为主动表述，如"are essential for"译为"对于...至关重要"；5. 保留技术术语"Swin3D++"等专有名词不翻译；6. 网址信息完整保留）
