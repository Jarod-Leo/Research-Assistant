# Machine Learning for Brain Disorders: Transformers and Visual Transformers

链接: http://arxiv.org/abs/2303.12068v1

原文摘要:
Transformers were initially introduced for natural language processing (NLP)
tasks, but fast they were adopted by most deep learning fields, including
computer vision. They measure the relationships between pairs of input tokens
(words in the case of text strings, parts of images for visual Transformers),
termed attention. The cost is exponential with the number of tokens. For image
classification, the most common Transformer Architecture uses only the
Transformer Encoder in order to transform the various input tokens. However,
there are also numerous other applications in which the decoder part of the
traditional Transformer Architecture is also used. Here, we first introduce the
Attention mechanism (Section 1), and then the Basic Transformer Block including
the Vision Transformer (Section 2). Next, we discuss some improvements of
visual Transformers to account for small datasets or less computation(Section
3). Finally, we introduce Visual Transformers applied to tasks other than image
classification, such as detection, segmentation, generation and training
without labels (Section 4) and other domains, such as video or multimodality
using text or audio data (Section 5).

中文翻译:
Transformer架构最初是为自然语言处理（NLP）任务提出的，但很快被大多数深度学习领域采用，包括计算机视觉领域。该架构通过注意力机制衡量输入标记对之间的关系（文本数据中的单词对应文本标记，视觉Transformer中的图像区域对应视觉标记），其计算成本随标记数量呈指数级增长。在图像分类任务中，最常见的Transformer架构仅使用编码器部分来处理多样化的输入标记。然而，在众多其他应用场景中，传统Transformer架构的解码器部分同样发挥着重要作用。
本文首先系统阐述注意力机制（第1节），进而解析包含视觉Transformer在内的基础Transformer模块（第2节）；随后探讨针对小规模数据集或有限计算资源的视觉Transformer改进方案（第3节）；最后介绍图像分类之外的应用场景，包括检测、分割、生成及无标签训练等任务（第4节），以及视频处理、结合文本或音频数据的多模态应用等其他领域（第5节）。
