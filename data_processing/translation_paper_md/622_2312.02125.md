# TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and Advanced Decoding Techniques

链接: http://arxiv.org/abs/2312.02125v1

原文摘要:
Recent advances in language models (LMs), have demonstrated significant
efficacy in tasks related to the arts and humanities. While LMs have exhibited
exceptional performance across a wide range of natural language processing
tasks, there are notable challenges associated with their utilization on small
datasets and their ability to replicate more creative human capacities. In this
study, we aim to address these challenges by training a Persian classical
poetry generation model using a transformer architecture on a specialized
dataset with no pretraining. Additionally, we propose a novel decoding method
to enhance coherence and meaningfulness in the generated poetry, effectively
managing the tradeoff between diversity and quality. Furthermore, the results
of our training approach and the proposed decoding method are evaluated through
comprehensive set of automatic and human evaluations and showed its superior
capability to generate coherent and meaningful poetry in compare to other
decoding methods and an existing Persian large language model (LLM).

中文翻译:
近年来，语言模型（LMs）在艺术与人文学科相关任务中展现出显著成效。尽管语言模型在各类自然语言处理任务中表现卓越，但其在小规模数据集上的应用能力及对人类创造性思维的复现仍存在明显挑战。本研究通过基于专业数据集（无预训练）采用Transformer架构训练波斯古典诗歌生成模型，旨在解决这些问题。我们同时提出一种新型解码方法，通过有效平衡多样性与质量的关系，显著提升生成诗歌的连贯性与意义表达。通过自动化评估与人工评估相结合的全面测试，我们的训练方案及所提解码方法相较于其他解码方式及现有波斯语大语言模型（LLM），展现出更优异的诗歌生成连贯性与语义表达能力。

（翻译说明：采用学术论文摘要的标准表述方式，通过以下处理实现专业性与可读性平衡：
1. 专业术语保留英文缩写（LMs/LLM）并首次出现标注全称
2. 将英语长句拆分为符合中文表达习惯的短句结构
3. "tradeoff"译为"平衡关系"符合计算机领域术语规范
4. "coherence and meaningfulness"统一处理为"连贯性与意义表达"保持概念对应
5. 被动语态转换为主动表述（如"are evaluated"译为"通过...测试"）
6. 补充"近年来"时间状语使中文语境更完整）
