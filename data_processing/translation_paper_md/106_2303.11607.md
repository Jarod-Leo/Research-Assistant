# Transformers in Speech Processing: A Survey

链接: http://arxiv.org/abs/2303.11607v1

原文摘要:
The remarkable success of transformers in the field of natural language
processing has sparked the interest of the speech-processing community, leading
to an exploration of their potential for modeling long-range dependencies
within speech sequences. Recently, transformers have gained prominence across
various speech-related domains, including automatic speech recognition, speech
synthesis, speech translation, speech para-linguistics, speech enhancement,
spoken dialogue systems, and numerous multimodal applications. In this paper,
we present a comprehensive survey that aims to bridge research studies from
diverse subfields within speech technology. By consolidating findings from
across the speech technology landscape, we provide a valuable resource for
researchers interested in harnessing the power of transformers to advance the
field. We identify the challenges encountered by transformers in speech
processing while also offering insights into potential solutions to address
these issues.

中文翻译:
自然语言处理领域中Transformer模型的显著成功引发了语音处理学界的研究兴趣，促使学者们探索其在建模语音序列长程依赖性方面的潜力。近年来，Transformer模型已在多个语音相关领域崭露头角，包括自动语音识别、语音合成、语音翻译、语音副语言学、语音增强、口语对话系统以及众多多模态应用。本文通过系统性综述，旨在整合语音技术各子领域的研究成果，为希望利用Transformer推动学科发展的研究者提供重要参考资源。我们在剖析Transformer应用于语音处理时所面临挑战的同时，也针对这些问题提出了潜在的解决方案。
