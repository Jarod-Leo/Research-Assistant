# Visual Prompting in LLMs for Enhancing Emotion Recognition

链接: http://arxiv.org/abs/2410.02244v1

原文摘要:
Vision Large Language Models (VLLMs) are transforming the intersection of
computer vision and natural language processing. Nonetheless, the potential of
using visual prompts for emotion recognition in these models remains largely
unexplored and untapped. Traditional methods in VLLMs struggle with spatial
localization and often discard valuable global context. To address this
problem, we propose a Set-of-Vision prompting (SoV) approach that enhances
zero-shot emotion recognition by using spatial information, such as bounding
boxes and facial landmarks, to mark targets precisely. SoV improves accuracy in
face count and emotion categorization while preserving the enriched image
context. Through a battery of experimentation and analysis of recent commercial
or open-source VLLMs, we evaluate the SoV model's ability to comprehend facial
expressions in natural environments. Our findings demonstrate the effectiveness
of integrating spatial visual prompts into VLLMs for improving emotion
recognition performance.

中文翻译:
视觉大语言模型（VLLMs）正在重塑计算机视觉与自然语言处理的交叉领域。然而，在这类模型中利用视觉提示进行情绪识别的潜力仍处于尚未充分探索和开发的状态。传统VLLM方法在空间定位方面存在局限，且常常丢失宝贵的全局上下文信息。为解决这一问题，我们提出了一种视觉集合提示（SoV）方法，该方法通过边界框、面部关键点等空间信息精确标记目标，从而增强零样本情绪识别能力。SoV在提升人脸计数和情绪分类准确率的同时，保留了丰富的图像上下文信息。通过对最新商用或开源VLLMs进行系统实验与分析，我们评估了SoV模型在自然场景下面部表情理解的能力。研究结果表明，将空间视觉提示整合到VLLMs中能有效提升情绪识别性能。

（翻译说明：采用学术论文摘要的规范表达，处理长句时进行合理切分，如将"spatial information, such as..."译为"通过...等空间信息"的符合中文前置修饰习惯的句式。专业术语如"zero-shot"保留技术概念译为"零样本"，"bounding boxes"采用行业通用译法"边界框"。通过"重塑""尚未充分探索""存在局限"等措辞保持学术文本的严谨性，同时使用"提升""保留""评估"等动词确保表述的准确性。）
