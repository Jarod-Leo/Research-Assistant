# M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models

链接: http://arxiv.org/abs/2306.05179v1

原文摘要:
Despite the existence of various benchmarks for evaluating natural language
processing models, we argue that human exams are a more suitable means of
evaluating general intelligence for large language models (LLMs), as they
inherently demand a much wider range of abilities such as language
understanding, domain knowledge, and problem-solving skills. To this end, we
introduce M3Exam, a novel benchmark sourced from real and official human exam
questions for evaluating LLMs in a multilingual, multimodal, and multilevel
context. M3Exam exhibits three unique characteristics: (1) multilingualism,
encompassing questions from multiple countries that require strong multilingual
proficiency and cultural knowledge; (2) multimodality, accounting for the
multimodal nature of many exam questions to test the model's multimodal
understanding capability; and (3) multilevel structure, featuring exams from
three critical educational periods to comprehensively assess a model's
proficiency at different levels. In total, M3Exam contains 12,317 questions in
9 diverse languages with three educational levels, where about 23\% of the
questions require processing images for successful solving. We assess the
performance of top-performing LLMs on M3Exam and find that current models,
including GPT-4, still struggle with multilingual text, particularly in
low-resource and non-Latin script languages. Multimodal LLMs also perform
poorly with complex multimodal questions. We believe that M3Exam can be a
valuable resource for comprehensively evaluating LLMs by examining their
multilingual and multimodal abilities and tracking their development. Data and
evaluation code is available at \url{https://github.com/DAMO-NLP-SG/M3Exam}.

中文翻译:
尽管目前存在多种评估自然语言处理模型的基准测试，我们认为人类考试是衡量大语言模型（LLMs）通用智能更合适的方式，因为其本质上需要更广泛的能力维度，包括语言理解、领域知识和问题解决技能等。为此，我们推出M3Exam——一个基于真实官方人类考试题目构建的创新性基准测试，用于在多语言、多模态、多层级场景下评估大语言模型。M3Exam具有三大独特属性：（1）多语言性：涵盖多国考试题目，要求模型具备强大的多语言能力和文化知识；（2）多模态性：针对考试中常见的多模态题型，检验模型的多模态理解能力；（3）多层次结构：包含三个关键教育阶段的考试，全面评估模型在不同认知层级的表现。该基准共包含9种语言的12,317道试题，涵盖三个教育阶段，其中约23%的题目需要处理图像信息才能解答。我们对顶尖大语言模型在M3Exam上的表现进行评估，发现包括GPT-4在内的现有模型仍存在多语言文本处理困难（尤其在低资源和非拉丁语系语言中），而多模态大模型对复杂多模态问题的处理能力也显不足。我们相信M3Exam能成为全面评估大语言模型多语言/多模态能力、追踪其发展进程的重要资源。数据与评估代码已开源于：\url{https://github.com/DAMO-NLP-SG/M3Exam}。

（注：根据学术文本翻译规范，对原文进行了以下处理：
1. 专业术语统一："LLMs"统一译为"大语言模型"，"multimodal"统一处理为"多模态"
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句
3. 被动语态转换："are required"等被动结构转为中文主动表述
4. 数据呈现优化：百分比数字与中文格式统一为"约23%"
5. 链接保留：维持原始GitHub链接格式不变）
