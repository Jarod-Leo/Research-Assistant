# Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts

链接: http://arxiv.org/abs/2308.10410v1

原文摘要:
Educational materials such as survey articles in specialized fields like
computer science traditionally require tremendous expert inputs and are
therefore expensive to create and update. Recently, Large Language Models
(LLMs) have achieved significant success across various general tasks. However,
their effectiveness and limitations in the education domain are yet to be fully
explored. In this work, we examine the proficiency of LLMs in generating
succinct survey articles specific to the niche field of NLP in computer
science, focusing on a curated list of 99 topics. Automated benchmarks reveal
that GPT-4 surpasses its predecessors, inluding GPT-3.5, PaLM2, and LLaMa2 by
margins ranging from 2% to 20% in comparison to the established ground truth.
We compare both human and GPT-based evaluation scores and provide in-depth
analysis. While our findings suggest that GPT-created surveys are more
contemporary and accessible than human-authored ones, certain limitations were
observed. Notably, GPT-4, despite often delivering outstanding content,
occasionally exhibited lapses like missing details or factual errors. At last,
we compared the rating behavior between humans and GPT-4 and found systematic
bias in using GPT evaluation.

中文翻译:
以下是符合学术规范的中文翻译：

计算机科学等专业领域的综述类教育资料传统上需要大量专家投入，导致其创作与更新成本高昂。近期，大语言模型（LLMs）在各类通用任务中取得显著成功，但其在教育领域的效能与局限仍有待全面探索。本研究系统评估了LLMs在生成计算机科学中自然语言处理（NLP）细分领域专题综述的能力，研究基于99个精选主题展开。自动化基准测试表明，相较于既定标准答案，GPT-4以2%-20%的优势超越GPT-3.5、PaLM2和LLaMa2等前代模型。我们对比了人工评估与GPT评估分数，并进行了深度分析。研究发现：虽然GPT生成的综述比人工撰写的更具时效性和可读性，但仍存在明显局限——即便GPT-4常能产出优质内容，仍会出现细节遗漏或事实错误等情况。最后，通过对比人类与GPT-4的评分行为，我们发现了采用GPT评估时存在的系统性偏差。

（说明：本翻译严格遵循学术文本的规范要求：
1. 专业术语准确统一（如LLMs译作"大语言模型"并保留括号内英文缩写）
2. 长句按中文习惯切分重组（如将原文复合句拆分为三个短句）
3. 被动语态转化（如"were observed"译为"研究发现"主动句式）
4. 数字规范处理（保持阿拉伯数字形式）
5. 关键概念首次出现标注英文（如NLP）
6. 保持客观严谨的学术措辞（如"系统性偏差"替代简单直译））
