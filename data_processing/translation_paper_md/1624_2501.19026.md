# MPLinker: Multi-template Prompt-tuning with Adversarial Training for Issue-commit Link Recovery

链接: http://arxiv.org/abs/2501.19026v1

原文摘要:
In recent years, the pre-training, prompting and prediction paradigm, known
as prompt-tuning, has achieved significant success in Natural Language
Processing (NLP). Issue-commit Link Recovery (ILR) in Software Traceability
(ST) plays an important role in improving the reliability, quality, and
security of software systems. The current ILR methods convert the ILR into a
classification task using pre-trained language models (PLMs) and dedicated
neural networks. these methods do not fully utilize the semantic information
embedded in PLMs, resulting in not achieving acceptable performance. To address
this limitation, we introduce a novel paradigm: Multi-template Prompt-tuning
with adversarial training for issue-commit Link recovery (MPLinker). MPLinker
redefines the ILR task as a cloze task via template-based prompt-tuning and
incorporates adversarial training to enhance model generalization and reduce
overfitting. We evaluated MPLinker on six open-source projects using a
comprehensive set of performance metrics. The experiment results demonstrate
that MPLinker achieves an average F1-score of 96.10%, Precision of 96.49%,
Recall of 95.92%, MCC of 94.04%, AUC of 96.05%, and ACC of 98.15%,
significantly outperforming existing state-of-the-art methods. Overall,
MPLinker improves the performance and generalization of ILR models, and
introduces innovative concepts and methods for ILR. The replication package for
MPLinker is available at
https://github.com/WTU-intelligent-software-development/MPLinker

中文翻译:
近年来，预训练-提示-预测范式（即提示调优）在自然语言处理（NLP）领域取得显著成功。软件追踪性（ST）中的问题-提交链接恢复（ILR）对提升软件系统的可靠性、质量与安全性具有重要作用。现有ILR方法虽利用预训练语言模型（PLM）和专用神经网络将其转化为分类任务，但未能充分挖掘PLM中蕴含的语义信息，导致性能表现欠佳。为此，我们提出创新范式：基于多模板提示调优与对抗训练的问题-提交链接恢复方法（MPLinker）。该方法通过模板化提示调优将ILR任务重构为完形填空任务，并引入对抗训练以增强模型泛化能力、抑制过拟合现象。我们在六个开源项目上采用多维度性能指标进行评估，实验结果表明MPLinker平均达到F1值96.10%、精确率96.49%、召回率95.92%、马修斯相关系数94.04%、AUC值96.05%及准确率98.15%，显著优于现有最优方法。总体而言，MPLinker不仅提升了ILR模型的性能与泛化能力，更为该领域引入了创新性理念与方法。项目复现材料详见：https://github.com/WTU-intelligent-software-development/MPLinker

（译文特点说明：
1. 专业术语规范处理："prompt-tuning"译为行业认可译法"提示调优"，"adversarial training"译为"对抗训练"
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将方法描述部分拆分为"现有...虽...但..."的转折结构
3. 被动语态转化："is converted"等被动式转为"将其转化为"等主动表达
4. 数据呈现优化：性能指标采用中文标准计量表述（精确率/召回率等），百分数格式统一
5. 学术风格保持：使用"范式""泛化能力""过拟合现象"等学术规范用语
6. 链接信息完整保留：GitHub地址原样呈现确保可追溯性）
