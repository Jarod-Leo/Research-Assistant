# Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective

链接: http://arxiv.org/abs/2411.14258v1

原文摘要:
Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）彻底改变了自然语言处理（NLP）应用生态，包括自动文本生成、问答系统和聊天机器人等。然而其面临关键挑战：幻觉现象——模型会生成看似合理但事实错误的回答。这一问题损害了用户信任，限制了LLMs在多领域的适用性。相比之下，知识图谱（KGs）通过实体（节点）和关系（边）构成的结构化事实网络，能够弥补LLMs在特定主题理解上的知识缺口。最新研究表明，利用KGs提供上下文信息可有效缓解LLMs的幻觉问题，在保持模型广泛适用性的同时提升其可靠性与准确性。该领域仍存在诸多待解难题，是当前研究热点。本文系统探讨了以下开放挑战：最前沿的数据集与基准测试、知识整合方法以及幻觉评估技术。通过分析KGs在LLM系统中的现有应用，我们针对各项挑战提出了未来研究方向。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如hallucinations译为"幻觉现象"）
2. 长句合理切分，符合中文表达习惯
3. 被动语态转化（如"have been leveraged"译为"能够"）
4. 学术用语规范（如"state-of-the-art"译为"最前沿"）
5. 逻辑连接词显化（如"however"译为"然而"）
6. 保留原文严谨性，无主观添加）
