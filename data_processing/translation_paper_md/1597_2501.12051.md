# MedS$^3$: Towards Medical Small Language Models with Self-Evolved Slow Thinking

链接: http://arxiv.org/abs/2501.12051v1

原文摘要:
Medical language models (MLMs) have become pivotal in advancing medical
natural language processing. However, prior models that rely on pre-training or
supervised fine-tuning often exhibit low data efficiency and limited
practicality in real-world clinical applications. While OpenAI's o1 highlights
test-time scaling in mathematics, attempts to replicate this approach in
medicine typically distill responses from GPT-series models to open-source
models, focusing primarily on multiple-choice tasks. This strategy, though
straightforward, neglects critical concerns like data privacy and realistic
deployment in clinical settings. In this work, we present a deployable,
small-scale medical reasoning system, MedS3, designed for long-chain reasoning
in clinical tasks using a self-evolution paradigm. Starting with a seed dataset
of around 8,000 instances spanning five domains and 16 datasets, we prompt a
base policy model to perform Monte Carlo Tree Search (MCTS) to construct
rule-verifiable reasoning chains. Each reasoning step is assigned an evolution
rollout value, allowing verified trajectories to train the policy model and the
process reward model (PRM). During inference, the policy model generates
multiple responses, and the reward model selects the one with a newly proposed
PRM-guided Vote-Sum (P-VS) strategy. Experiments on eleven evaluation datasets
demonstrate that MedS3 outperforms not only the prior strongest medical model
by 6.59, but also 32B-level general reasoning models by 8.71 points. Code and
data are available at https://github.com/pixas/MedSSS.

中文翻译:
以下是符合学术规范的中文翻译：

医学语言模型（MLMs）已成为推动医学自然语言处理发展的关键工具。然而，先前依赖预训练或有监督微调的模型在真实临床应用中往往表现出数据效率低下和实用性受限的问题。尽管OpenAI的o1模型在数学领域展示了测试时扩展的潜力，但医学领域试图复现该方法的研究通常仅将GPT系列模型的响应蒸馏至开源模型，且主要聚焦于多项选择题任务。这种策略虽然简便，却忽视了数据隐私和临床实际部署等关键问题。本研究提出一个可部署的小规模医学推理系统MedS3，采用自我进化范式设计，专为临床任务中的长链推理而构建。我们以涵盖5个领域16个数据集的约8,000条种子数据为起点，驱动基础策略模型执行蒙特卡洛树搜索（MCTS）来构建可验证规则的推理链。每个推理步骤均被赋予进化推演值，经验证的轨迹将用于训练策略模型和过程奖励模型（PRM）。在推理阶段，策略模型生成多个响应，而奖励模型则通过新提出的PRM引导投票求和（P-VS）策略进行优选。在11个评估数据集上的实验表明，MedS3不仅以6.59分的优势超越先前最强的医学模型，更以8.71分的差距领先于32B级别的通用推理模型。代码与数据详见https://github.com/pixas/MedSSS。

（说明：本翻译严格遵循以下学术规范：
1. 专业术语标准化处理（如MCTS、PRM等首现全称标注）
2. 被动语态转换为中文主动表述（如"are assigned"译为"被赋予"）
3. 长难句拆分重组（如将原文复合从句分解为符合中文表达习惯的短句）
4. 数字单位规范处理（32B级→32B级别）
5. 保留所有技术概念和机构名称的原始表述
6. 学术用语准确对应（如"self-evolution paradigm"译为"自我进化范式"））
