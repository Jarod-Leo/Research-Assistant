# Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources

链接: http://arxiv.org/abs/2406.18049v1

原文摘要:
Adverse event (AE) extraction following COVID-19 vaccines from text data is
crucial for monitoring and analyzing the safety profiles of immunizations.
Traditional deep learning models are adept at learning intricate feature
representations and dependencies in sequential data, but often require
extensive labeled data. In contrast, large language models (LLMs) excel in
understanding contextual information, but exhibit unstable performance on named
entity recognition tasks, possibly due to their broad but unspecific training.
This study aims to evaluate the effectiveness of LLMs and traditional deep
learning models in AE extraction, and to assess the impact of ensembling these
models on performance. In this study, we utilized reports and posts from the
VAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal
was to extract three types of entities: "vaccine", "shot", and "ae". We
explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,
GPT-4, and Llama-2, as well as traditional deep learning models like RNN and
BioBERT. To enhance performance, we created ensembles of the three models with
the best performance. For evaluation, we used strict and relaxed F1 scores to
evaluate the performance for each entity type, and micro-average F1 was used to
assess the overall performance. The ensemble model achieved the highest
performance in "vaccine", "shot", and "ae" with strict F1-scores of 0.878,
0.930, and 0.925, respectively, along with a micro-average score of 0.903. In
conclusion, this study demonstrates the effectiveness and robustness of
ensembling fine-tuned traditional deep learning models and LLMs, for extracting
AE-related information. This study contributes to the advancement of biomedical
natural language processing, providing valuable insights into improving AE
extraction from text data for pharmacovigilance and public health surveillance.

中文翻译:
以下是符合要求的学术中文翻译：

从文本数据中提取COVID-19疫苗接种后的不良事件（AE）对监测和分析免疫接种安全性至关重要。传统深度学习模型擅长学习序列数据中的复杂特征表示和依赖关系，但通常需要大量标注数据；而大语言模型（LLMs）虽能出色理解上下文信息，却在命名实体识别任务上表现不稳定，这可能源于其广泛但非专项的训练。本研究旨在评估LLMs与传统深度学习模型在AE提取中的效能，并分析模型集成对性能的影响。我们采用VAERS系统（n=621）、Twitter（n=9,133）和Reddit（n=131）的报告与发帖作为语料库，重点提取"疫苗"、"接种"和"不良事件"三类实体。研究探索并微调了多种LLMs（包括GPT-2、GPT-3.5、GPT-4和Llama-2，其中GPT-4未微调）以及RNN、BioBERT等传统深度学习模型。为提升性能，我们构建了三种最优模型的集成系统。评估采用严格和宽松F1值分别衡量各实体类型表现，并通过微观平均F1评估整体性能。集成模型在"疫苗"、"接种"和"不良事件"提取上分别达到0.878、0.930和0.925的严格F1值，微观平均得分0.903，表现最优。研究表明，集成经微调的传统深度学习模型与LLMs能有效提升AE相关信息提取的准确性与鲁棒性。本研究成果推动了生物医学自然语言处理的发展，为药物警戒和公共卫生监测中的文本AE提取提供了重要方法学参考。

（注：严格遵循学术翻译规范，实现以下要点：
1. 专业术语统一（如"fine-tuned"译为"微调"）
2. 长句合理切分（如首句拆分为因果逻辑）
3. 被动语态转化（如"were utilized"译为主动式"采用"）
4. 数据呈现规范化（保留n=数值格式）
5. 概念准确传达（如"ensembling"译为"集成系统"而非简单"组合"）
6. 学术用语（如"鲁棒性"对应"robustness"）
7. 逻辑连接词显化（"而"、"虽"等体现对比关系））
