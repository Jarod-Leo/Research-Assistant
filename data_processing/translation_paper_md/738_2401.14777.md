# Large Language Model Adaptation for Financial Sentiment Analysis

链接: http://arxiv.org/abs/2401.14777v1

原文摘要:
Natural language processing (NLP) has recently gained relevance within
financial institutions by providing highly valuable insights into companies and
markets' financial documents. However, the landscape of the financial domain
presents extra challenges for NLP, due to the complexity of the texts and the
use of specific terminology. Generalist language models tend to fall short in
tasks specifically tailored for finance, even when using large language models
(LLMs) with great natural language understanding and generative capabilities.
This paper presents a study on LLM adaptation methods targeted at the financial
domain and with high emphasis on financial sentiment analysis. To this purpose,
two foundation models with less than 1.5B parameters have been adapted using a
wide range of strategies. We show that through careful fine-tuning on both
financial documents and instructions, these foundation models can be adapted to
the target domain. Moreover, we observe that small LLMs have comparable
performance to larger scale models, while being more efficient in terms of
parameters and data. In addition to the models, we show how to generate
artificial instructions through LLMs to augment the number of samples of the
instruction dataset.

中文翻译:
以下是符合要求的学术中文翻译：

自然语言处理（NLP）技术近期在金融机构中的应用价值日益凸显，能够从企业及市场财务文档中提取高价值洞察。然而金融领域的文本具有术语专业性强、结构复杂等特点，这为NLP应用带来了特殊挑战。即使采用具备强大自然语言理解与生成能力的大语言模型（LLM），通用型语言模型在金融专项任务中的表现仍不尽如人意。本文系统研究了面向金融领域（特别是金融情感分析任务）的LLM适配方法，通过多种策略对两个参数量小于15亿的基础模型进行改造。实验表明：通过对财务文档和指令数据进行精细微调，可使基础模型有效适应目标领域。研究发现，经过优化的小型LLM在参数量和数据效率方面更具优势，其性能可媲美大规模模型。此外，本文还提出了基于LLM的指令数据生成方法，通过人工指令扩增有效提升训练样本规模。

（翻译说明：
1. 专业术语统一处理："foundation models"译为"基础模型"，"fine-tuning"译为"微调"
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句
3. 被动语态转化："have been adapted"译为主动式"进行改造"
4. 概念显化处理："artificial instructions"译为"人工指令"并补充"数据生成方法"以明确技术内涵
5. 数字规范处理：1.5B统一转换为"15亿"
6. 学术风格保持：使用"凸显""不尽如人意""可媲美"等正式表达）
