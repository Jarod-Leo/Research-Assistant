# Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models

链接: http://arxiv.org/abs/2405.15122v1

原文摘要:
Background: Biomedical entity normalization is critical to biomedical
research because the richness of free-text clinical data, such as progress
notes, can often be fully leveraged only after translating words and phrases
into structured and coded representations suitable for analysis. Large Language
Models (LLMs), in turn, have shown great potential and high performance in a
variety of natural language processing (NLP) tasks, but their application for
normalization remains understudied.
  Methods: We applied both proprietary and open-source LLMs in combination with
several rule-based normalization systems commonly used in biomedical research.
We used a two-step LLM integration approach, (1) using an LLM to generate
alternative phrasings of a source utterance, and (2) to prune candidate UMLS
concepts, using a variety of prompting methods. We measure results by
$F_{\beta}$, where we favor recall over precision, and F1.
  Results: We evaluated a total of 5,523 concept terms and text contexts from a
publicly available dataset of human-annotated biomedical abstracts.
Incorporating GPT-3.5-turbo increased overall $F_{\beta}$ and F1 in
normalization systems +9.5 and +7.3 (MetaMapLite), +13.9 and +10.9 (QuickUMLS),
and +10.5 and +10.3 (BM25), while the open-source Vicuna model achieved +10.8
and +12.2 (MetaMapLite), +14.7 and +15 (QuickUMLS), and +15.6 and +18.7 (BM25).
  Conclusions: Existing general-purpose LLMs, both propriety and open-source,
can be leveraged at scale to greatly improve normalization performance using
existing tools, with no fine-tuning.

中文翻译:
背景：生物医学实体标准化对生物医学研究至关重要，因为只有将自由文本临床数据（如病程记录）中的词汇和短语转化为适合分析的结构化编码表示，才能充分释放这类丰富文本数据的价值。尽管大语言模型（LLM）在各类自然语言处理（NLP）任务中展现出巨大潜力与卓越性能，但其在标准化任务中的应用仍待深入探索。

方法：我们联合使用专有和开源LLM与生物医学研究中常用的多种基于规则的标准化系统。采用两步式LLM整合策略：（1）利用LLM生成源文本的替代表述；（2）通过多样化提示方法筛选UMLS概念候选集。采用侧重召回率的$F_{\beta}$指标和F1值进行评估。

结果：基于公开的生物医学摘要人工标注数据集，我们对5,523个概念术语及文本上下文进行了评估。整合GPT-3.5-turbo使标准化系统的综合性能显著提升：$F_{\beta}$与F1值在MetaMapLite系统中分别提升9.5和7.3，QuickUMLS系统提升13.9和10.9，BM25系统提升10.5和10.3；而开源Vicuna模型在相应系统中分别实现10.8/12.2、14.7/15和15.6/18.7的增益。

结论：现有通用LLM（包括专有和开源模型）无需微调即可规模化应用，通过现有工具大幅提升标准化性能。
