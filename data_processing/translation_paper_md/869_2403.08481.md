# SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks

链接: http://arxiv.org/abs/2403.08481v1

原文摘要:
Natural language processing models have experienced a significant upsurge in
recent years, with numerous applications being built upon them. Many of these
applications require fine-tuning generic base models on customized, proprietary
datasets. This fine-tuning data is especially likely to contain personal or
sensitive information about individuals, resulting in increased privacy risk.
Membership inference attacks are the most commonly employed attack to assess
the privacy leakage of a machine learning model. However, limited research is
available on the factors that affect the vulnerability of language models to
this kind of attack, or on the applicability of different defense strategies in
the language domain. We provide the first systematic review of the
vulnerability of fine-tuned large language models to membership inference
attacks, the various factors that come into play, and the effectiveness of
different defense strategies. We find that some training methods provide
significantly reduced privacy risk, with the combination of differential
privacy and low-rank adaptors achieving the best privacy protection against
these attacks.

中文翻译:
近年来，自然语言处理模型呈现显著增长态势，基于这些模型构建的应用层出不穷。其中许多应用需要在定制化专有数据集上对通用基础模型进行微调。这类微调数据尤其可能包含个人敏感信息，从而导致隐私风险加剧。成员推理攻击作为评估机器学习模型隐私泄露程度最常用的攻击手段，目前关于语言模型对此类攻击脆弱性的影响因素研究仍显不足，针对语言领域的防御策略适用性探讨也较为有限。本文首次系统性地综述了微调后大语言模型对成员推理攻击的脆弱性、相关影响因素以及不同防御策略的有效性。研究发现，某些训练方法能显著降低隐私风险，其中差分隐私与低秩适配器的组合方案在抵御此类攻击时展现出最优的隐私保护效果。

（翻译说明：采用学术论文摘要的规范表述方式，通过以下处理实现专业性与可读性的平衡：
1. 专业术语准确对应："membership inference attacks"译为"成员推理攻击"，"differential privacy"译为"差分隐私"
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将"However"引导的转折长句拆分为两个独立句
3. 被动语态转化："are built upon them"译为主动态"基于...构建"
4. 概念显化处理："low-rank adaptors"增译为"低秩适配器方案"以明确技术内涵
5. 逻辑连接优化：使用"其中""研究发现"等连接词保持论证连贯性）
