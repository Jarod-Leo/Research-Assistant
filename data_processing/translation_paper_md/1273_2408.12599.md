# Controllable Text Generation for Large Language Models: A Survey

链接: http://arxiv.org/abs/2408.12599v1

原文摘要:
In Natural Language Processing (NLP), Large Language Models (LLMs) have
demonstrated high text generation quality. However, in real-world applications,
LLMs must meet increasingly complex requirements. Beyond avoiding misleading or
inappropriate content, LLMs are also expected to cater to specific user needs,
such as imitating particular writing styles or generating text with poetic
richness. These varied demands have driven the development of Controllable Text
Generation (CTG) techniques, which ensure that outputs adhere to predefined
control conditions--such as safety, sentiment, thematic consistency, and
linguistic style--while maintaining high standards of helpfulness, fluency, and
diversity.
  This paper systematically reviews the latest advancements in CTG for LLMs,
offering a comprehensive definition of its core concepts and clarifying the
requirements for control conditions and text quality. We categorize CTG tasks
into two primary types: content control and attribute control. The key methods
are discussed, including model retraining, fine-tuning, reinforcement learning,
prompt engineering, latent space manipulation, and decoding-time intervention.
We analyze each method's characteristics, advantages, and limitations,
providing nuanced insights for achieving generation control. Additionally, we
review CTG evaluation methods, summarize its applications across domains, and
address key challenges in current research, including reduced fluency and
practicality. We also propose several appeals, such as placing greater emphasis
on real-world applications in future research. This paper aims to offer
valuable guidance to researchers and developers in the field. Our reference
list and Chinese version are open-sourced at
https://github.com/IAAR-Shanghai/CTGSurvey.

中文翻译:
在自然语言处理（NLP）领域，大语言模型（LLMs）已展现出卓越的文本生成能力。然而在实际应用中，LLMs需要满足日益复杂的需求：除了避免误导性或不当内容外，还需适配特定用户需求——例如模仿特定写作风格，或生成富有诗意的文本。这些多样化诉求推动了可控文本生成（CTG）技术的发展，该技术通过预设控制条件（如安全性、情感倾向、主题一致性和语言风格），在确保文本具备高实用性、流畅性和多样性的前提下，使输出内容符合既定约束。

本文系统梳理了LLMs可控文本生成的最新进展，明确定义了核心概念，阐释了控制条件与文本质量的要求。我们将CTG任务划分为内容控制与属性控制两大类型，重点探讨了模型重训练、微调、强化学习、提示工程、潜空间操控和解码时干预等关键技术，分析各类方法的特性、优势与局限，为生成控制提供细致的方法论指导。此外，我们综述了CTG评估体系，总结了跨领域应用场景，并指出当前研究面临的关键挑战（如流畅性下降与实用性不足等问题）。针对未来研究方向，本文提出若干倡议，包括应更注重实际应用价值等。期望本综述能为领域研究者和开发者提供有益参考。参考文献列表及中文版开源地址：https://github.com/IAAR-Shanghai/CTGSurvey。  

（注：译文采用学术论文摘要的典型结构，通过以下处理实现专业性与可读性平衡：
1. 技术术语统一："latent space manipulation"译为"潜空间操控"符合NLP领域惯例
2. 长句拆分：将原文复合句重组为符合中文表达习惯的短句群
3. 逻辑显化：添加"例如""等"等衔接词强化论证脉络
4. 被动语态转化："are expected to cater to"译为"需适配"更符合中文主动表达
5. 概念对应："poetic richness"意译为"富有诗意"而非字面直译，保留文学性）
