# MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning

链接: http://arxiv.org/abs/2212.10773v1

原文摘要:
Instruction tuning, a new learning paradigm that fine-tunes pre-trained
language models on tasks specified through instructions, has shown promising
zero-shot performance on various natural language processing tasks. However, it
has yet to be explored for vision and multimodal tasks. In this work, we
introduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark
dataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq
format covering 10 broad categories. The tasks are derived from 21 existing
open-source datasets and each task is equipped with 5 expert-written
instructions. We take OFA as the base pre-trained model for multimodal
instruction tuning, and to further improve its zero-shot performance, we
explore multiple transfer learning strategies to leverage the large-scale
NATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot
performance on various unseen multimodal tasks and the benefit of transfer
learning from a text-only instruction dataset. We also design a new evaluation
metric - Sensitivity, to evaluate how sensitive the model is to the variety of
instructions. Our results indicate that fine-tuning the model on a diverse set
of tasks and instructions leads to a reduced sensitivity to variations in
instructions for each task.

中文翻译:
指令微调（Instruction Tuning）是一种通过指令指定任务来微调预训练语言模型的新范式，已在多种自然语言处理任务中展现出优异的零样本性能。然而，该范式在视觉和多模态任务领域的应用尚未得到充分探索。本研究首次提出MUL-TIINSTRUCT——一个统一采用序列到序列格式的多模态指令微调基准数据集，涵盖10个大类的62项多样化多模态任务。这些任务源自21个现有开源数据集，每个任务均配备5条专家撰写的指令文本。我们选择OFA作为多模态指令微调的基础预训练模型，并通过探索多种迁移学习策略（利用大规模纯文本指令数据集NATURAL INSTRUCTIONS）进一步提升其零样本性能。实验结果表明，模型在多种未见过的多模态任务上表现出强大的零样本能力，并验证了从纯文本指令数据集迁移学习的有效性。此外，我们设计了一种新型评估指标——敏感度（Sensitivity），用于量化模型对指令多样性的敏感程度。研究结果显示，在多样化任务和指令集上进行微调的模型，对单任务内指令变化的敏感度显著降低。

