# InstructProtein: Aligning Human and Protein Language via Knowledge Instruction

链接: http://arxiv.org/abs/2310.03269v1

原文摘要:
Large Language Models (LLMs) have revolutionized the field of natural
language processing, but they fall short in comprehending biological sequences
such as proteins. To address this challenge, we propose InstructProtein, an
innovative LLM that possesses bidirectional generation capabilities in both
human and protein languages: (i) taking a protein sequence as input to predict
its textual function description and (ii) using natural language to prompt
protein sequence generation. To achieve this, we first pre-train an LLM on both
protein and natural language corpora, enabling it to comprehend individual
languages. Then supervised instruction tuning is employed to facilitate the
alignment of these two distinct languages. Herein, we introduce a knowledge
graph-based instruction generation framework to construct a high-quality
instruction dataset, addressing annotation imbalance and instruction deficits
in existing protein-text corpus. In particular, the instructions inherit the
structural relations between proteins and function annotations in knowledge
graphs, which empowers our model to engage in the causal modeling of protein
functions, akin to the chain-of-thought processes in natural languages.
Extensive experiments on bidirectional protein-text generation tasks show that
InstructProtein outperforms state-of-the-art LLMs by large margins. Moreover,
InstructProtein serves as a pioneering step towards text-based protein function
prediction and sequence design, effectively bridging the gap between protein
and human language understanding.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）虽已革新自然语言处理领域，但在理解蛋白质等生物序列方面仍存在不足。为应对这一挑战，我们提出创新型LLM框架InstructProtein，该模型具备人类语言与蛋白质语言的双向生成能力：（1）以蛋白质序列为输入预测其文本功能描述；（2）通过自然语言提示生成蛋白质序列。实现路径分为两步：首先在蛋白质语料库和自然语言语料库上进行预训练，使模型掌握单语言理解能力；随后采用监督式指令微调实现跨语言对齐。我们创新性地引入基于知识图谱的指令生成框架，通过继承知识图谱中蛋白质与功能注释的结构化关联关系，构建高质量指令数据集，有效解决现有蛋白质-文本语料中标注不平衡与指令缺失问题。这种设计使模型能像自然语言中的思维链推理那样，建立蛋白质功能的因果建模机制。双向蛋白质-文本生成任务的实验表明，InstructProtein显著超越现有最先进LLMs。该模型为基于文本的蛋白质功能预测与序列设计开创了新范式，成功弥合了蛋白质语言与人类语言理解之间的鸿沟。

翻译特色说明：
1. 专业术语处理：采用"LLMs"缩写与全称交替使用，保持"知识图谱"等专业表述
2. 句式重构：将原文复合句拆分为符合中文表达习惯的短句（如实现路径分步说明）
3. 概念转化："chain-of-thought processes"译为"思维链推理"符合NLP领域共识
4. 逻辑显化：通过"分为两步"等过渡词明确技术路线层次
5. 学术风格：使用"范式""鸿沟"等学术用语，保持摘要严谨性
6. 被动语态转化："are employed"等转换为中文主动表述
7. 文化适配："pioneering step"译为"开创了新范式"更符合中文科技文献表达
