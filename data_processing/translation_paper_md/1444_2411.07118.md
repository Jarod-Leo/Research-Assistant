# ConvMixFormer- A Resource-efficient Convolution Mixer for Transformer-based Dynamic Hand Gesture Recognition

链接: http://arxiv.org/abs/2411.07118v1

原文摘要:
Transformer models have demonstrated remarkable success in many domains such
as natural language processing (NLP) and computer vision. With the growing
interest in transformer-based architectures, they are now utilized for gesture
recognition. So, we also explore and devise a novel ConvMixFormer architecture
for dynamic hand gestures. The transformers use quadratic scaling of the
attention features with the sequential data, due to which these models are
computationally complex and heavy. We have considered this drawback of the
transformer and designed a resource-efficient model that replaces the
self-attention in the transformer with the simple convolutional layer-based
token mixer. The computational cost and the parameters used for the
convolution-based mixer are comparatively less than the quadratic
self-attention. Convolution-mixer helps the model capture the local spatial
features that self-attention struggles to capture due to their sequential
processing nature. Further, an efficient gate mechanism is employed instead of
a conventional feed-forward network in the transformer to help the model
control the flow of features within different stages of the proposed model.
This design uses fewer learnable parameters which is nearly half the vanilla
transformer that helps in fast and efficient training. The proposed method is
evaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has
achieved state-of-the-art results on single and multimodal inputs. We have also
shown the parameter efficiency of the proposed ConvMixFormer model compared to
other methods. The source code is available at
https://github.com/mallikagarg/ConvMixFormer.

中文翻译:
Transformer模型在自然语言处理（NLP）和计算机视觉等诸多领域展现出卓越性能。随着基于Transformer架构的研究热潮兴起，该技术现已被应用于手势识别领域。为此，我们探索并设计了一种面向动态手势识别的新型ConvMixFormer架构。传统Transformer模型在处理序列数据时，其注意力特征存在二次方级计算复杂度，导致模型计算负担沉重。针对这一缺陷，我们设计了一种资源高效模型——用基于简单卷积层的令牌混合器替代Transformer中的自注意力机制。相较于二次方复杂度的自注意力机制，这种卷积混合器在计算成本和参数量上具有显著优势。卷积混合器能有效捕捉局部空间特征，而这正是基于序列处理的自注意力机制所欠缺的能力。此外，我们在模型中采用高效门控机制替代传统前馈网络，以优化特征流在不同层级间的传递控制。该设计将可训练参数量缩减至标准Transformer的近一半，从而实现快速高效的模型训练。我们在NVidia动态手势数据集和Briareo数据集上评估了所提方法，实验表明该模型在单模态和多模态输入条件下均达到最先进性能。同时，我们通过对比实验验证了ConvMixFormer模型在参数量效率上的优势。源代码已开源：https://github.com/mallikagarg/ConvMixFormer。

（注：根据学术摘要翻译规范，在保持专业术语准确性的同时，对原文进行了以下优化处理：
1. 将长句拆分为符合中文表达习惯的短句结构
2. "quadratic scaling"译为"二次方级计算复杂度"以明确技术含义
3. "state-of-the-art"采用国内学界通用译法"最先进性能"
4. 被动语态转换为主动语态（如"are now utilized"→"现已被应用于"）
5. 补充"通过对比实验验证了"等逻辑连接词以增强中文可读性
