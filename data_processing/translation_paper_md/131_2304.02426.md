# ParroT: Translating During Chat Using Large Language Models

链接: http://arxiv.org/abs/2304.02426v2

原文摘要:
Large language models (LLMs) like ChatGPT have exhibited remarkable abilities
on a wide range of natural language processing~(NLP) tasks, including various
machine translation abilities accomplished during chat. However, these models
are only accessible through restricted APIs, which creates barriers to new
research and advancements in the field. Therefore, we propose ParroT, a
framework to enhance and regulate the translation abilities during chat based
on open-source LLMs (e.g., LLaMA), human-written translation and feedback data.
Specifically, ParroT reformulates translation data into the
instruction-following style, and introduces a "$\mathbf{Hint}$" field for
incorporating extra requirements to regulate the translation process.
Accordingly, we propose three instruction types for finetuning ParroT models,
including translation instruction, contrastive instruction, and error-guided
instruction. Experiments on Flores subsets and WMT22 test sets suggest that
translation instruction improves the translation performance of vanilla LLMs
significantly while error-guided instruction can lead to further improvement,
which demonstrates the importance of learning from low-quality translations
annotated by humans. We also demonstrate the potential of automatic evaluation
tools in providing quality information of translations, when constructing
error-guided instructions for directions that lack human annotation data.
Please refer to our Github project for more implementation details:
https://github.com/wxjiao/ParroT

中文翻译:
以下是符合要求的学术中文翻译：

以ChatGPT为代表的大语言模型（LLMs）在自然语言处理（NLP）领域展现出卓越的多任务处理能力，包括在对话过程中实现的多种机器翻译功能。然而，这些模型目前仅能通过受限的API接口访问，这为相关领域的新研究和技术突破设置了障碍。为此，我们提出ParroT框架——基于开源大语言模型（如LLaMA）、人工翻译数据及反馈数据来增强并调控对话式翻译能力的解决方案。该框架的核心创新在于：将传统翻译数据重构为指令跟随格式，并通过引入"提示（$\mathbf{Hint}$）"字段来整合额外需求以规范翻译过程。我们相应提出三种微调ParroT模型的指令类型：基础翻译指令、对比指令以及误差引导指令。在Flores子集和WMT22测试集上的实验表明：翻译指令能显著提升原始大语言模型的翻译性能，而误差引导指令可带来进一步改进，这验证了从人工标注的低质量翻译中学习的重要性。我们还论证了在缺乏人工标注数据的翻译方向上，自动评估工具生成的质量信息可用于构建误差引导指令的潜力。更多实现细节请参见我们的Github项目：https://github.com/wxjiao/ParroT

（注：根据用户要求，译文严格遵循了以下技术规范：
1. 专业术语统一处理（如LLMs→大语言模型，NLP→自然语言处理）
2. 保留所有技术概念（如instruction-following style→指令跟随格式）
3. 数学符号$\mathbf{Hint}$原样保留并添加中文注释
4. 项目名称ParroT不作翻译
5. 链接信息完整保留
6. 采用学术论文摘要的标准句式结构）
