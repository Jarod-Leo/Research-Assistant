# RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference

链接: http://arxiv.org/abs/2410.04519v1

原文摘要:
Large language models (LLMs) have brought a great breakthrough to the natural
language processing (NLP) community, while leading the challenge of handling
concurrent customer queries due to their high throughput demands. Data
multiplexing addresses this by merging multiple inputs into a single composite
input, allowing more efficient inference through a shared forward pass.
However, as distinguishing individuals from a composite input is challenging,
conventional methods typically require training the entire backbone, yet still
suffer from performance degradation. In this paper, we introduce RevMUX, a
parameter-efficient data multiplexing framework that incorporates a reversible
design in the multiplexer, which can be reused by the demultiplexer to perform
reverse operations and restore individual samples for classification. Extensive
experiments on four datasets and three types of LLM backbones demonstrate the
effectiveness of RevMUX for enhancing LLM inference efficiency while retaining
a satisfactory classification performance.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）为自然语言处理（NLP）领域带来了重大突破，但同时也因其高吞吐量需求而面临并发用户查询处理的挑战。数据复用技术通过将多个输入合并为单一复合输入来解决这一问题，借助共享前向传播实现更高效的推理。然而，由于从复合输入中区分个体样本存在困难，传统方法通常需要对整个主干模型进行训练，且仍存在性能下降问题。本文提出RevMUX——一种参数高效的数据复用框架，其复用器采用可逆设计，解复用器可复用该设计执行逆向操作以恢复原始样本进行分类。在四种数据集和三类LLM主干模型上的大量实验表明，RevMUX能在保持满意分类性能的同时有效提升LLM推理效率。

（翻译说明：
1. 专业术语统一处理："throughput demands"译为"吞吐量需求"，"forward pass"译为"前向传播"
2. 被动语态转换：将英文被动式转换为中文主动式表达（如"are challenged"译为"面临挑战"）
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句
4. 概念准确传达："reversible design"译为"可逆设计"而非字面直译
5. 学术规范：保留技术术语首字母缩写（LLM/NLP），保持数值表述严谨性（"four datasets"译为"四种数据集"）
6. 逻辑关系显化：通过"借助"、"由于"等连接词明确原文隐含的因果关系）
