# Third-Party Language Model Performance Prediction from Instruction

链接: http://arxiv.org/abs/2403.12413v1

原文摘要:
Language model-based instruction-following systems have lately shown
increasing performance on many benchmark tasks, demonstrating the capability of
adapting to a broad variety of instructions. However, such systems are often
not designed to be transparent about their limitations; a user may easily
prompt a model with an instruction without any idea of whether the responses
should be expected to be accurate, or if the system is even capable of
performing the task. We propose a third party performance prediction framework,
where a separate model is trained to predict the metric resulting from
evaluating an instruction-following system on a task while assuming access only
to its inputs and outputs at inference time. We perform this analysis with a
variety of both open and closed instruction-following models as well as
multiple performance predictors, and examine the effect of various factors such
as model size, number of training tasks, and prompt format. Our findings
indicate that third-party performance prediction is very challenging, and much
work remains in developing predictors that can automatically reveal the
limitations of modern instruction-following natural language processing
systems.

中文翻译:
基于语言模型的指令跟随系统近年来在多项基准任务中展现出日益提升的性能，彰显出适应多样化指令的能力。然而，这类系统通常缺乏透明度设计来揭示其局限性——用户可能轻易地向模型输入指令，却无从判断响应是否应当预期为准确，甚至不确定系统是否具备执行该任务的能力。我们提出一种第三方性能预测框架：通过训练独立模型来预测指令跟随系统在任务中的评估指标，该预测模型仅需在推理时访问目标系统的输入输出。我们针对多种开源与闭源指令跟随模型及不同性能预测器展开分析，探究模型规模、训练任务数量、提示格式等因素的影响。研究结果表明，第三方性能预测极具挑战性，要开发能自动揭示现代指令跟随式自然语言处理系统局限性的预测器，仍需大量探索工作。
