# Large Language Models Understand Layouts

链接: http://arxiv.org/abs/2407.05750v1

原文摘要:
Large language models (LLMs) demonstrate extraordinary abilities in a wide
range of natural language processing (NLP) tasks. In this paper, we show that,
beyond text understanding capability, LLMs are capable of processing text
layouts that are denoted by spatial markers. They are able to answer questions
that require explicit spatial perceiving and reasoning, while a drastic
performance drop is observed when the spatial markers from the original data
are excluded. We perform a series of experiments with the GPT-3.5, Baichuan2,
Llama2 and ChatGLM3 models on various types of layout-sensitive datasets for
further analysis. The experimental results reveal that the layout understanding
ability of LLMs is mainly introduced by the coding data for pretraining, which
is further enhanced at the instruction-tuning stage. In addition, layout
understanding can be enhanced by integrating low-cost, auto-generated data
approached by a novel text game. Finally, we show that layout understanding
ability is beneficial for building efficient visual question-answering (VQA)
systems.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出卓越能力。本文研究表明，LLMs不仅具备文本理解能力，还能处理通过空间标记表示的文本布局结构。实验证明，当问题需要显式空间感知与推理时，模型能有效作答；但若从原始数据中移除空间标记，其性能会出现显著下降。我们基于GPT-3.5、Baichuan2、Llama2和ChatGLM3模型，在多种布局敏感数据集上展开系列实验分析。结果表明：LLMs的布局理解能力主要源自预训练阶段的编程数据，并在指令微调阶段得到强化；此外，通过新型文本游戏方法生成的低成本自动标注数据可进一步提升该能力；最后，我们论证了布局理解能力对构建高效视觉问答（VQA）系统具有积极意义。

（翻译说明：
1. 专业术语统一处理："spatial markers"译为"空间标记"，"instruction-tuning"译为"指令微调"
2. 被动语态转化："are observed"转为主动句式"实验证明"
3. 长句拆分：将原文复合句分解为符合中文表达习惯的短句
4. 学术表达规范："demonstrate"译为"展现"而非"展示"，"reveal"译为"表明"而非"显示"
5. 概念准确传达："auto-generated data approached by..."译为"通过...方法生成的自动标注数据"）
