# Evaluating LLM Prompts for Data Augmentation in Multi-label Classification of Ecological Texts

链接: http://arxiv.org/abs/2411.14896v1

原文摘要:
Large language models (LLMs) play a crucial role in natural language
processing (NLP) tasks, improving the understanding, generation, and
manipulation of human language across domains such as translating, summarizing,
and classifying text. Previous studies have demonstrated that instruction-based
LLMs can be effectively utilized for data augmentation to generate diverse and
realistic text samples. This study applied prompt-based data augmentation to
detect mentions of green practices in Russian social media. Detecting green
practices in social media aids in understanding their prevalence and helps
formulate recommendations for scaling eco-friendly actions to mitigate
environmental issues. We evaluated several prompts for augmenting texts in a
multi-label classification task, either by rewriting existing datasets using
LLMs, generating new data, or combining both approaches. Our results revealed
that all strategies improved classification performance compared to the models
fine-tuned only on the original dataset, outperforming baselines in most cases.
The best results were obtained with the prompt that paraphrased the original
text while clearly indicating the relevant categories.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）在自然语言处理（NLP）任务中发挥着关键作用，通过提升对人类语言的理解、生成与操控能力，显著改善了跨领域文本的翻译、摘要和分类等任务。现有研究表明，基于指令调校的LLMs能有效用于数据增强，以生成多样化且真实的文本样本。本研究采用基于提示词的数据增强技术，检测俄罗斯社交媒体中绿色实践的提及情况。识别社交媒体中的绿色实践不仅有助于理解其普及程度，更能为制定推广环保行动的建议提供依据，从而缓解环境问题。我们评估了多标签分类任务中的多种文本增强策略：包括使用LLMs重写现有数据集、生成新数据以及结合两种方法。实验结果表明，相较于仅在原始数据集上微调的模型，所有增强策略均能提升分类性能，且在多数情况下优于基线模型。其中表现最佳的是采用明确标注相关类别的文本复述提示词方案。

（翻译严格遵循以下原则：
1. 专业术语准确统一："prompt"译为"提示词"，"multi-label classification"译为"多标签分类"
2. 被动语态转化："were evaluated"译为"评估了"
3. 长句拆分：将原文复合句按中文习惯分解为多个短句
4. 逻辑显化：通过"不仅...更能..."等连接词强化论证关系
5. 学术风格：使用"本研究""结果表明"等规范表达
6. 文化适配："Russian social media"译为"俄罗斯社交媒体"而非音译）
