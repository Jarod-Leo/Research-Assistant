# LabelPrompt: Effective Prompt-based Learning for Relation Classification

链接: http://arxiv.org/abs/2302.08068v1

原文摘要:
Recently, prompt-based learning has gained popularity across many natural
language processing (NLP) tasks by reformulating them into a cloze-style format
to better align pre-trained language models (PLMs) with downstream tasks.
However, applying this approach to relation classification poses unique
challenges. Specifically, associating natural language words that fill the
masked token with semantic relation labels (\textit{e.g.}
\textit{``org:founded\_by}'') is difficult. To address this challenge, this
paper presents a novel prompt-based learning method, namely LabelPrompt, for
the relation classification task. Motivated by the intuition to ``GIVE MODEL
CHOICES!'', we first define additional tokens to represent relation labels,
which regard these tokens as the verbaliser with semantic initialisation and
explicitly construct them with a prompt template method. Then, to mitigate
inconsistency between predicted relations and given entities, we implement an
entity-aware module with contrastive learning. Last, we conduct an attention
query strategy within the self-attention layer to differentiates prompt tokens
and sequence tokens. Together, these strategies enhance the adaptability of
prompt-based learning, especially when only small labelled datasets is
available. Comprehensive experiments on benchmark datasets demonstrate the
superiority of our method, particularly in the few-shot scenario.

中文翻译:
近年来，基于提示的学习通过将自然语言处理（NLP）任务重构为填空形式，使预训练语言模型（PLMs）与下游任务更好对齐，已在多项任务中广受欢迎。然而，将该方法应用于关系分类任务时存在特殊挑战：如何将填充掩码标记的自然语言词汇与语义关系标签（如"org:founded_by"）有效关联。针对这一挑战，本文提出了一种新颖的基于提示的关系分类方法LabelPrompt。基于"为模型提供选择！"的直觉，我们首先定义额外标记来表示关系标签，将其视为具有语义初始化的词表生成器，并通过提示模板方法显式构建。其次，为缓解预测关系与给定实体间的不一致性，我们采用对比学习实现实体感知模块。最后，在自注意力层中实施注意力查询策略以区分提示标记与序列标记。这些策略共同增强了基于提示的学习方法的适应性，尤其在仅有少量标注数据时表现突出。在基准数据集上的综合实验表明，本方法具有显著优势，在少样本场景下表现尤为突出。
