# Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset

链接: http://arxiv.org/abs/2405.10542v1

原文摘要:
In light of recent breakthroughs in large language models (LLMs) that have
revolutionized natural language processing (NLP), there is an urgent need for
new benchmarks to keep pace with the fast development of LLMs. In this paper,
we propose CFLUE, the Chinese Financial Language Understanding Evaluation
benchmark, designed to assess the capability of LLMs across various dimensions.
Specifically, CFLUE provides datasets tailored for both knowledge assessment
and application assessment. In knowledge assessment, it consists of 38K+
multiple-choice questions with associated solution explanations. These
questions serve dual purposes: answer prediction and question reasoning. In
application assessment, CFLUE features 16K+ test instances across distinct
groups of NLP tasks such as text classification, machine translation, relation
extraction, reading comprehension, and text generation. Upon CFLUE, we conduct
a thorough evaluation of representative LLMs. The results reveal that only
GPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\% in answer prediction
for knowledge assessment, suggesting that there is still substantial room for
improvement in current LLMs. In application assessment, although GPT-4 and
GPT-4-turbo are the top two performers, their considerable advantage over
lightweight LLMs is noticeably diminished. The datasets and scripts associated
with CFLUE are openly accessible at https://github.com/aliyun/cflue.

中文翻译:
鉴于大语言模型（LLM）近期取得的突破性进展已彻底改变自然语言处理（NLP）领域，当前亟需建立新的基准测试以适应LLM的快速发展。本文提出中文金融语言理解评估基准CFLUE，旨在多维度评估LLM的能力。具体而言，CFLUE提供面向知识评估与应用评估的定制数据集：在知识评估方面，包含38,000余道附带解析说明的单选题，这些题目兼具答案预测与问题推理双重功能；在应用评估方面，涵盖文本分类、机器翻译、关系抽取、阅读理解及文本生成等NLP任务组的16,000余个测试实例。基于CFLUE，我们对代表性LLM进行全面评估。结果显示：在知识评估的答案预测任务中，仅GPT-4与GPT-4-turbo准确率超过60%，表明当前LLM仍有显著提升空间；在应用评估中，尽管GPT-4系列表现最优，但其相对轻量级LLM的优势明显缩小。CFLUE相关数据集与脚本已开源发布于https://github.com/aliyun/cflue。

（翻译说明：
1. 专业术语处理："large language models"统一译为"大语言模型"，"multiple-choice questions"译为"单选题"以符合中文教育测评语境
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句，如将"These questions serve dual purposes..."独立成短句
3. 被动语态转换："are openly accessible"主动化为"已开源发布"
4. 数字表达：38K+/16K+译为"38,000余/16,000余"符合中文计量规范
5. 概念显化："distinct groups of NLP tasks"译为"任务组"体现分类层级
6. 逻辑显化："considerable advantage...diminished"转译为"优势明显缩小"突出对比关系）
