# Can Large Language Models Be an Alternative to Human Evaluations?

链接: http://arxiv.org/abs/2305.01937v1

原文摘要:
Human evaluation is indispensable and inevitable for assessing the quality of
texts generated by machine learning models or written by humans. However, human
evaluation is very difficult to reproduce and its quality is notoriously
unstable, hindering fair comparisons among different natural language
processing (NLP) models and algorithms. Recently, large language models (LLMs)
have demonstrated exceptional performance on unseen tasks when only the task
instructions are provided. In this paper, we explore if such an ability of the
LLMs can be used as an alternative to human evaluation. We present the LLMs
with the exact same instructions, samples to be evaluated, and questions used
to conduct human evaluation, and then ask the LLMs to generate responses to
those questions; we dub this LLM evaluation. We use human evaluation and LLM
evaluation to evaluate the texts in two NLP tasks: open-ended story generation
and adversarial attacks. We show that the result of LLM evaluation is
consistent with the results obtained by expert human evaluation: the texts
rated higher by human experts are also rated higher by the LLMs. We also find
that the results of LLM evaluation are stable over different formatting of the
task instructions and the sampling algorithm used to generate the answer. We
are the first to show the potential of using LLMs to assess the quality of
texts and discuss the limitations and ethical considerations of LLM evaluation.

中文翻译:
人工评估对于衡量机器学习模型生成文本或人类撰写文本的质量而言不可或缺且无法替代。然而人工评估的复现难度极高，且质量 notoriously 难以保持稳定，这阻碍了不同自然语言处理（NLP）模型与算法之间的公平比较。近期研究表明，大语言模型（LLMs）仅需任务指令即可在未见任务中展现卓越性能。本文探究是否可利用LLMs的这种能力替代人工评估：我们将人类评估时使用的完整指令、待评估样本及问题集直接输入LLMs，要求其生成对应回答——这种范式被称为"LLM评估"。我们在开放域故事生成和对抗攻击两个NLP任务中，同步采用人工评估与LLM评估进行文本质量判定。实验证明LLM评估结果与专家人工评估具有一致性：人类专家评分较高的文本同样获得LLMs更高评价。我们还发现LLM评估结果不受任务指令格式差异及答案生成采样算法的影响。本研究首次揭示了LLMs在文本质量评估领域的应用潜力，并探讨了LLM评估的局限性及伦理考量。

（翻译说明：
1. 专业术语处理："notoriously unstable"译为" notoriously 难以保持稳定"保留原文强调语气
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句
3. 被动语态转换："are rated higher"等被动结构转换为主动语态
4. 概念显化："dub"译为"范式"体现方法论属性
5. 学术规范："we"统一处理为"本文/本研究"保持客观性
6. 文化适配："ethical considerations"译为"伦理考量"符合中文社科表述惯例）
