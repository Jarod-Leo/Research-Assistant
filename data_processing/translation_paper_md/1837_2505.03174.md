# Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets

链接: http://arxiv.org/abs/2505.03174v1

原文摘要:
Instruction-Action (IA) data pairs are valuable for training robotic systems,
especially autonomous vehicles (AVs), but having humans manually annotate this
data is costly and time-inefficient. This paper explores the potential of using
mobile application Global Positioning System (GPS) references and Natural
Language Processing (NLP) to automatically generate large volumes of IA
commands and responses without having a human generate or retroactively tag the
data. In our pilot data collection, by driving to various destinations and
collecting voice instructions from GPS applications, we demonstrate a means to
collect and categorize the diverse sets of instructions, further accompanied by
video data to form complete vision-language-action triads. We provide details
on our completely automated data collection prototype system, ADVLAT-Engine. We
characterize collected GPS voice instructions into eight different
classifications, highlighting the breadth of commands and referentialities
available for curation from freely available mobile applications. Through
research and exploration into the automation of IA data pairs using GPS
references, the potential to increase the speed and volume at which
high-quality IA datasets are created, while minimizing cost, can pave the way
for robust vision-language-action (VLA) models to serve tasks in
vision-language navigation (VLN) and human-interactive autonomous systems.

中文翻译:
以下是符合要求的学术中文翻译：

指令-动作（Instruction-Action，IA）数据对对于机器人系统（尤其是自动驾驶车辆AVs）的训练具有重要价值，但人工标注这类数据成本高昂且效率低下。本文探索了利用移动应用程序全球定位系统（GPS）参考数据与自然语言处理（NLP）技术自动生成海量IA指令-响应的可行性，该方法无需人工生成或事后标注数据。在我们的试点数据收集中，通过驾驶至不同目的地并采集GPS应用的语音指令，我们展示了一种收集和分类多样化指令集的方法，这些指令进一步与视频数据结合构成完整的视觉-语言-动作三元组。我们详细介绍了全自动数据采集原型系统ADVLAT-Engine，并将采集的GPS语音指令归纳为八种不同分类，凸显了从免费移动应用中可获取的指令广度与指称多样性。通过利用GPS参考实现IA数据对自动化的研究探索，在保证质量的同时提升数据集构建速度与规模并控制成本，有望为构建强大的视觉-语言-动作（VLA）模型铺平道路，进而服务于视觉-语言导航（VLN）和人机交互自动驾驶系统任务。

（译文严格遵循以下原则：
1. 专业术语统一处理（如IA/VLA/VLN保持首字母缩写下标格式）
2. 被动语态转换为中文主动表述（如"are valuable for"译为"具有重要价值"）
3. 长难句拆分重组（如最后复合句分解为因果逻辑链）
4. 学术用语规范化（"characterize"译为"归纳分类"而非简单直译）
5. 保持技术细节准确性（"vision-language-action triads"译为专业术语"三元组"））
