# Generative Judge for Evaluating Alignment

链接: http://arxiv.org/abs/2310.05470v1

原文摘要:
The rapid development of Large Language Models (LLMs) has substantially
expanded the range of tasks they can address. In the field of Natural Language
Processing (NLP), researchers have shifted their focus from conventional NLP
tasks (e.g., sequence tagging and parsing) towards tasks that revolve around
aligning with human needs (e.g., brainstorming and email writing). This shift
in task distribution imposes new requirements on evaluating these aligned
models regarding generality (i.e., assessing performance across diverse
scenarios), flexibility (i.e., examining under different protocols), and
interpretability (i.e., scrutinizing models with explanations). In this paper,
we propose a generative judge with 13B parameters, Auto-J, designed to address
these challenges. Our model is trained on user queries and LLM-generated
responses under massive real-world scenarios and accommodates diverse
evaluation protocols (e.g., pairwise response comparison and single-response
evaluation) with well-structured natural language critiques. To demonstrate the
efficacy of our approach, we construct a new testbed covering 58 different
scenarios. Experimentally, Auto-J outperforms a series of strong competitors,
including both open-source and closed-source models, by a large margin. We also
provide detailed analysis and case studies to further reveal the potential of
our method and make a variety of resources public at
https://github.com/GAIR-NLP/auto-j.

中文翻译:
大型语言模型（LLMs）的快速发展极大地拓展了其任务处理范围。在自然语言处理（NLP）领域，研究者的关注焦点已从传统NLP任务（如序列标注和句法解析）转向以人类需求为核心的任务（如头脑风暴和邮件撰写）。这种任务范式的转变对模型评估提出了新要求：需要评估体系具备通用性（即跨场景性能评估）、灵活性（即支持不同评估协议）和可解释性（即提供解释性分析）。本文提出一个130亿参数生成式评估模型Auto-J以应对这些挑战。该模型基于海量真实场景中的用户查询与LLM生成响应进行训练，能适配多样化评估协议（如双响应对比评估和单响应质量评估），并输出结构清晰的自然语言评析。为验证方法有效性，我们构建了覆盖58个场景的新测试平台。实验表明，Auto-J显著优于包括开源和闭源模型在内的一系列强基线系统。我们还通过详细分析与案例研究进一步揭示该方法的潜力，相关资源已开源发布于https://github.com/GAIR-NLP/auto-j。

（翻译说明：
1. 专业术语处理："sequence tagging"译为"序列标注"，"parsing"译为"句法解析"，保持NLP领域术语一致性
2. 概念显化："aligning with human needs"意译为"以人类需求为核心"，避免直译生硬
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如将三个评估要求处理为冒号列举式
4. 被动转主动："is trained on"译为"基于...进行训练"，符合中文主动语态偏好
5. 数字规范：13B统一译为"130亿"而非"13B"，符合中文计量习惯
6. 技术表述："well-structured natural language critiques"译为"结构清晰的自然语言评析"，准确传达技术内涵
7. 链接保留：完整保留原始GitHub链接，确保资源可追溯性）
