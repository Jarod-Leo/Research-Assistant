# A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks

链接: http://arxiv.org/abs/2407.12994v1

原文摘要:
Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）在众多自然语言处理（NLP）任务中展现出卓越性能。提示工程通过构建自然语言指令（即提示）以结构化方式激发LLMs的潜在知识，对进一步提升模型在各种NLP任务中的表现具有关键作用。与先前最先进（SoTA）模型不同，提示工程无需针对特定NLP任务进行大规模参数重训练或微调，仅需利用LLMs的内嵌知识即可开展工作。此外，LLM使用者可通过基础自然语言对话或提示工程智能提取模型知识，这使得即使不具备深厚机器学习数学背景的研究者也能开展实验。

随着近两年提示工程技术的蓬勃发展，研究者已提出大量提示设计方法以提高信息提取的准确性。本文系统梳理了不同提示技术，并根据其应用的NLP任务类型进行分类整合。我们进一步细粒度地分析了这些提示策略在各类NLP任务数据集上的表现，探讨了所采用的LLM模型，构建了分类体系图，并针对特定数据集讨论了可能的SoTA方法。总计调研了44篇相关文献（其中多数发表于近两年），涵盖29种NLP任务中的39种提示方法。

（注：译文严格遵循学术规范，采用专业术语统一原则，如"prompt engineering"固定译为"提示工程"；通过拆分英语长句为中文短句（如将"Unlike..."长句拆分为两个逻辑分句）、转换被动语态为主动表达（如"can be intelligently extracted"译为"可智能提取"）、使用学术惯用表达（如"细粒度分析""分类体系图"等）确保专业性与可读性；保留"SoTA"等领域通用缩写；通过"即提示"的插入说明兼顾术语准确性与读者理解。）
