# Do Large Language Models Know What They Don't Know?

链接: http://arxiv.org/abs/2305.18153v2

原文摘要:
Large language models (LLMs) have a wealth of knowledge that allows them to
excel in various Natural Language Processing (NLP) tasks. Current research
focuses on enhancing their performance within their existing knowledge. Despite
their vast knowledge, LLMs are still limited by the amount of information they
can accommodate and comprehend. Therefore, the ability to understand their own
limitations on the unknows, referred to as self-knowledge, is of paramount
importance. This study aims to evaluate LLMs' self-knowledge by assessing their
ability to identify unanswerable or unknowable questions. We introduce an
automated methodology to detect uncertainty in the responses of these models,
providing a novel measure of their self-knowledge. We further introduce a
unique dataset, SelfAware, consisting of unanswerable questions from five
diverse categories and their answerable counterparts. Our extensive analysis,
involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an
intrinsic capacity for self-knowledge within these models. Moreover, we
demonstrate that in-context learning and instruction tuning can further enhance
this self-knowledge. Despite this promising insight, our findings also
highlight a considerable gap between the capabilities of these models and human
proficiency in recognizing the limits of their knowledge.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）具备丰富的知识储备，使其在各类自然语言处理（NLP）任务中表现卓越。当前研究主要聚焦于提升模型在已知知识范围内的性能表现。尽管LLMs拥有海量知识，其容纳和理解的信息总量仍存在固有局限。因此，模型对自身认知边界的觉察能力（即自我认知能力）具有关键意义。本研究通过评估LLMs识别不可回答或不可知问题的能力，系统考察其自我认知水平。我们提出了一种自动化检测模型响应不确定性的创新方法，为衡量自我认知能力提供了新型量化指标。此外，本研究构建了一个独特的数据集SelfAware，涵盖五个不同领域的不可回答问题及其可回答对照问题。通过对GPT-3、InstructGPT和LLaMA等20个LLMs的广泛测试，我们发现这些模型确实具备内在的自我认知能力。实验进一步证明，情境学习（in-context learning）和指令微调（instruction tuning）能有效增强这种能力。尽管获得这些积极发现，但研究结果同时揭示：当前模型在认知边界识别能力方面，与人类水平仍存在显著差距。

（翻译说明：
1. 专业术语统一处理：如"self-knowledge"译为"自我认知能力"保持全文一致
2. 被动语态转化："are limited by"译为主动式"存在固有局限"
3. 长句拆分：将原文复合句按中文习惯分解为多个短句
4. 学术表达规范："demonstrate"译为"证明"而非"展示"
5. 概念准确传达："unknowable questions"译为"不可知问题"而非字面直译
6. 文化适应性调整："in-context learning"采用学界通用译法"情境学习"）
