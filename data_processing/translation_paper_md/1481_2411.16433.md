# Finding Structure in Language Models

链接: http://arxiv.org/abs/2411.16433v1

原文摘要:
When we speak, write or listen, we continuously make predictions based on our
knowledge of a language's grammar. Remarkably, children acquire this
grammatical knowledge within just a few years, enabling them to understand and
generalise to novel constructions that have never been uttered before. Language
models are powerful tools that create representations of language by
incrementally predicting the next word in a sentence, and they have had a
tremendous societal impact in recent years. The central research question of
this thesis is whether these models possess a deep understanding of grammatical
structure similar to that of humans. This question lies at the intersection of
natural language processing, linguistics, and interpretability. To address it,
we will develop novel interpretability techniques that enhance our
understanding of the complex nature of large-scale language models. We approach
our research question from three directions. First, we explore the presence of
abstract linguistic information through structural priming, a key paradigm in
psycholinguistics for uncovering grammatical structure in human language
processing. Next, we examine various linguistic phenomena, such as adjective
order and negative polarity items, and connect a model's comprehension of these
phenomena to the data distribution on which it was trained. Finally, we
introduce a controlled testbed for studying hierarchical structure in language
models using various synthetic languages of increasing complexity and examine
the role of feature interactions in modelling this structure. Our findings
offer a detailed account of the grammatical knowledge embedded in language
model representations and provide several directions for investigating
fundamental linguistic questions using computational methods.

中文翻译:
当我们说话、书写或聆听时，会持续基于对语法规则的认知进行预测。令人惊叹的是，儿童仅需数年便能掌握这种语法知识，使其不仅能理解语言，还能对从未听过的新颖句式进行泛化处理。语言模型作为通过逐词预测构建语言表征的强大工具，近年来已产生深远的社会影响。本论文的核心研究问题是：这些模型是否具备与人类相似的深层语法结构理解能力？该问题处于自然语言处理、语言学和模型可解释性研究的交叉领域。为此，我们将开发新型可解释性技术，以深化对大规模语言模型复杂本质的理解。研究从三个维度展开：首先通过心理语言学揭示人类语法处理机制的关键范式——结构启动效应，探究模型中抽象语言信息的存在性；其次系统考察形容词排序、否定极性项等语言现象，将模型对这些现象的理解与其训练数据分布建立关联；最后通过构建复杂度递增的合成语言测试环境，研究语言模型对层次结构的建模机制，特别关注特征交互的作用。本研究不仅详尽阐释了语言模型表征中蕴含的语法知识，更为运用计算方法探索基础语言学问题提供了多元路径。
