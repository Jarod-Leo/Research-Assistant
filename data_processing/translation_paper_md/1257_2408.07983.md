# ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models

链接: http://arxiv.org/abs/2408.07983v1

原文摘要:
The rapid advancements in Large Language Models (LLMs) have led to
significant improvements in various natural language processing tasks. However,
the evaluation of LLMs' legal knowledge, particularly in non-English languages
such as Arabic, remains under-explored. To address this gap, we introduce
ArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal
knowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval
consists of multiple tasks sourced from Saudi legal documents and synthesized
questions. In this work, we aim to analyze the capabilities required to solve
legal problems in Arabic and benchmark the performance of state-of-the-art
LLMs. We explore the impact of in-context learning and investigate various
evaluation methods. Additionally, we explore workflows for generating questions
with automatic validation to enhance the dataset's quality. We benchmark
multilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We
also share our methodology for creating the dataset and validation, which can
be generalized to other domains. We hope to accelerate AI research in the
Arabic Legal domain by releasing the ArabLegalEval dataset and code:
https://github.com/Thiqah/ArabLegalEval

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）的快速发展显著提升了各类自然语言处理任务的性能。然而，针对LLMs法律知识评估的研究——特别是在阿拉伯语等非英语语言中的表现——仍存在探索不足的问题。为填补这一空白，我们推出ArabLegalEval多任务基准数据集，用于系统评估LLMs的阿拉伯语法律知识。受MMLU和LegalBench数据集启发，ArabLegalEval包含源自沙特法律文书的人工构建问题与合成问题。本研究旨在：（1）解析阿拉伯语法律问题解决所需的核心能力；（2）对前沿LLMs进行性能基准测试；（3）探究上下文学习的影响效应；（4）验证不同评估方法的有效性。我们进一步开发了具有自动验证功能的问题生成工作流以提升数据集质量。实验对多语言模型（如GPT-4）与阿拉伯语专用模型（如Jais）进行了系统评测。本文同时公开了可迁移至其他领域的数据集构建与验证方法论。通过开源ArabLegalEval数据集及代码（https://github.com/Thiqah/ArabLegalEval），我们期望加速阿拉伯语法律领域的人工智能研究。

翻译说明：
1. 专业术语处理：采用"大型语言模型（LLMs）"、"上下文学习"等学界通用译法
2. 句式重构：将原文复合句拆分为符合中文表达习惯的短句结构（如将"we aim to..."转换为三个分号列举的研究目标）
3. 被动语态转换："remain under-explored"译为主动式"仍存在探索不足"
4. 概念显化："synthesized questions"译为"人工构建问题与合成问题"以明确区分
5. 学术规范：保留所有技术术语首字母缩写（MMLU/Jais）及原始URL格式
6. 逻辑衔接：使用"（1）...；（2）..."等标号保持论证层次清晰
7. 文化适配："Saudi legal documents"译为"沙特法律文书"符合中文法律文献表述习惯
