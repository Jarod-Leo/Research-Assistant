# Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: A Preliminary Empirical Study

链接: http://arxiv.org/abs/2304.00723v1

原文摘要:
Evaluating the quality of generated text is a challenging task in NLP, due to
the inherent complexity and diversity of text. Recently, large language models
(LLMs) have garnered significant attention due to their impressive performance
in various tasks. Therefore, we present this paper to investigate the
effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their
use in assessing text quality. We compared three kinds of reference-free
evaluation methods. The experimental results prove that ChatGPT is capable of
evaluating text quality effectively from various perspectives without reference
and demonstrates superior performance than most existing automatic metrics. In
particular, the Explicit Score, which utilizes ChatGPT to generate a numeric
score measuring text quality, is the most effective and reliable method among
the three exploited approaches. However, directly comparing the quality of two
texts may lead to suboptimal results. We believe this paper will provide
valuable insights for evaluating text quality with LLMs and have released the
used data.

中文翻译:
由于文本固有的复杂性和多样性，评估生成文本的质量一直是自然语言处理领域的一项挑战性任务。近年来，大语言模型（LLMs）凭借其在各类任务中的卓越表现而备受关注。为此，本研究系统考察了以ChatGPT为代表的LLMs在文本质量评估中的有效性，并探索了优化其使用的方法。我们对比了三种无参考评估方法，实验结果表明：ChatGPT能够从多维度有效评估文本质量（无需参考文本），其表现优于现有大多数自动评估指标。其中"显式评分法"（通过ChatGPT生成量化文本质量的数值分数）在三种方法中最为有效可靠。但需注意的是，直接比较两段文本质量的方法可能产生次优结果。本研究为大语言模型在文本质量评估中的应用提供了重要见解，相关实验数据已开源。  

（注：译文在保持学术严谨性的基础上进行了以下优化：  
1. 将英文被动语态转换为中文主动表述（如"are compared"→"对比了"）  
2. 专业术语准确对应（如"reference-free"→"无参考"）  
3. 长句拆分重组（如原文最后两句合并为逻辑连贯的复合句）  
4. 补充说明性内容（如括号内"无需参考文本"的补充）  
5. 关键概念保留英文缩写（LLMs）同时首次出现标注全称）
