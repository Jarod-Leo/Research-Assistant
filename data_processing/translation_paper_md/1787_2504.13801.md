# Transformer Encoder and Multi-features Time2Vec for Financial Prediction

链接: http://arxiv.org/abs/2504.13801v1

原文摘要:
Financial prediction is a complex and challenging task of time series
analysis and signal processing, expected to model both short-term fluctuations
and long-term temporal dependencies. Transformers have remarkable success
mostly in natural language processing using attention mechanism, which also
influenced the time series community. The ability to capture both short and
long-range dependencies helps to understand the financial market and to
recognize price patterns, leading to successful applications of Transformers in
stock prediction. Although, the previous research predominantly focuses on
individual features and singular predictions, that limits the model's ability
to understand broader market trends. In reality, within sectors such as finance
and technology, companies belonging to the same industry often exhibit
correlated stock price movements.
  In this paper, we develop a novel neural network architecture by integrating
Time2Vec with the Encoder of the Transformer model. Based on the study of
different markets, we propose a novel correlation feature selection method.
Through a comprehensive fine-tuning of multiple hyperparameters, we conduct a
comparative analysis of our results against benchmark models. We conclude that
our method outperforms other state-of-the-art encoding methods such as
positional encoding, and we also conclude that selecting correlation features
enhance the accuracy of predicting multiple stock prices.

中文翻译:
以下是符合要求的学术中文翻译：

金融预测是时间序列分析与信号处理领域中一项复杂且具有挑战性的任务，其核心在于同时建模短期波动与长期时序依赖关系。Transformer模型凭借注意力机制在自然语言处理领域取得显著成功，这一突破也深刻影响了时序分析研究领域。该模型捕获短期与长程依赖关系的双重能力，有助于理解金融市场并识别价格模式，从而成功应用于股票预测领域。然而现有研究主要集中于单一特征和独立预测，这限制了模型理解更广泛市场趋势的能力。事实上，在金融、科技等行业中，同领域企业的股价往往呈现联动效应。

本文提出一种创新神经网络架构，通过将Time2Vec与Transformer编码器进行集成。基于对不同市场的研究，我们设计了一种新颖的关联特征选择方法。通过对多重超参数的系统调优，我们将实验结果与基准模型进行了对比分析。研究结果表明：1）本方法性能优于位置编码等现有最先进的编码方法；2）关联特征选择能有效提升多股价格预测的准确性。

（注：根据学术翻译规范，对原文进行了以下处理：
1. 将长句拆分为符合中文表达习惯的短句结构
2. 专业术语保持统一（如Transformer/注意力机制等）
3. 被动语态转换为主动语态（如"are expected to"译为"其核心在于"）
4. 逻辑连接词显化（如"Although"译为"然而"）
5. 列表式结论呈现增强可读性
6. 保持客观严谨的学术语气）
