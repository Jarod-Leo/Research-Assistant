# Large Language Models Can Be Easily Distracted by Irrelevant Context

链接: http://arxiv.org/abs/2302.00093v1

原文摘要:
Large language models have achieved impressive performance on various natural
language processing tasks. However, so far they have been evaluated primarily
on benchmarks where all information in the input context is relevant for
solving the task. In this work, we investigate the distractibility of large
language models, i.e., how the model problem-solving accuracy can be influenced
by irrelevant context. In particular, we introduce Grade-School Math with
Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant
information in the problem description. We use this benchmark to measure the
distractibility of cutting-edge prompting techniques for large language models,
and find that the model performance is dramatically decreased when irrelevant
information is included. We also identify several approaches for mitigating
this deficiency, such as decoding with self-consistency and adding to the
prompt an instruction that tells the language model to ignore the irrelevant
information.

中文翻译:
大型语言模型在各种自然语言处理任务中展现出卓越性能。然而迄今为止，其评估主要集中于输入上下文中所有信息都与任务解决相关的基准测试。本研究探讨了大语言模型的注意力分散问题——即无关上下文如何影响模型解决问题的准确性。我们特别构建了"含无关信息的小学数学题集"（GSM-IC），这是一个在题目描述中包含无关信息的算术推理数据集。通过该基准测试，我们评估了前沿提示技术对大语言模型抗干扰能力的影响，发现当存在无关信息时，模型性能会显著下降。同时，我们提出了若干改进方案：包括采用自洽性解码技术，以及在提示语中添加"忽略无关信息"的指令等缓解措施。

