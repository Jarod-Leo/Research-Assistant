# A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models

链接: http://arxiv.org/abs/2212.09873v1

原文摘要:
There is growing interest in incorporating eye-tracking data and other
implicit measures of human language processing into natural language processing
(NLP) pipelines. The data from human language processing contain unique insight
into human linguistic understanding that could be exploited by language models.
However, many unanswered questions remain about the nature of this data and how
it can best be utilized in downstream NLP tasks. In this paper, we present
eyeStyliency, an eye-tracking dataset for human processing of stylistic text
(e.g., politeness). We develop a variety of methods to derive style saliency
scores over text using the collected eye dataset. We further investigate how
this saliency data compares to both human annotation methods and model-based
interpretability metrics. We find that while eye-tracking data is unique, it
also intersects with both human annotations and model-based importance scores,
providing a possible bridge between human- and machine-based perspectives. We
propose utilizing this type of data to evaluate the cognitive plausibility of
models that interpret style. Our eye-tracking data and processing code are
publicly available.

中文翻译:
近年来，将眼动追踪数据及其他人类语言处理的隐性测量指标纳入自然语言处理（NLP）流程的研究兴趣日益增长。这类人类语言加工数据蕴含着对人类语言理解的独特洞见，可为语言模型所利用。然而，关于此类数据的本质特征及其在下游NLP任务中的最佳应用方式，仍存在诸多未解之谜。本文提出eyeStyliency——一个用于研究人类处理风格化文本（如礼貌用语）的眼动追踪数据集。我们开发了多种方法，利用所收集的眼动数据计算文本风格显著性分数，并进一步探究该显著性数据与人工标注方法及基于模型的解释性指标之间的关联。研究发现：眼动数据虽具有独特性，但与人工标注和模型重要性评分均存在交集，这为连接人类视角与机器视角提供了可能桥梁。我们建议利用此类数据来评估风格解释模型的认知合理性。本研究公开了所有眼动数据及处理代码。  
