# Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism

链接: http://arxiv.org/abs/2504.16761v1

原文摘要:
Image description generation is essential for accessibility and AI
understanding of visual content. Recent advancements in deep learning have
significantly improved natural language processing and computer vision. In this
work, we propose Tri-FusionNet, a novel image description generation model that
integrates transformer modules: a Vision Transformer (ViT) encoder module with
dual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decoder
module, and a Contrastive Language-Image Pre-Training (CLIP) integrating
module. The ViT encoder, enhanced with dual attention, focuses on relevant
spatial regions and linguistic context, improving image feature extraction. The
RoBERTa decoder is employed to generate precise textual descriptions. CLIP's
integrating module aligns visual and textual data through contrastive learning,
ensuring effective combination of both modalities. This fusion of ViT, RoBERTa,
and CLIP, along with dual attention, enables the model to produce more
accurate, contextually rich, and flexible descriptions. The proposed framework
demonstrated competitive performance on the Flickr30k and Flickr8k datasets,
with BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scores
of 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of
0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scores
of 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The results
demonstrate the effectiveness of Tri-FusionNet in generating high-quality image
descriptions.

中文翻译:
图像描述生成对于提升视觉内容的可访问性及人工智能理解至关重要。深度学习的最新进展显著推动了自然语言处理与计算机视觉领域的发展。本研究提出Tri-FusionNet模型——一种集成Transformer模块的创新图像描述生成框架，包含采用双注意力机制的视觉Transformer（ViT）编码模块、鲁棒优化BERT（RoBERTa）解码模块以及对比语言-图像预训练（CLIP）融合模块。经双注意力强化的ViT编码器能聚焦相关空间区域与语义上下文，优化图像特征提取；RoBERTa解码器负责生成精准文本描述；CLIP融合模块通过对比学习实现视觉-文本模态对齐，确保双模态有效结合。这种ViT、RoBERTa与CLIP的协同融合机制，配合双注意力设计，使模型能生成更准确、语境丰富且灵活的图文描述。在Flickr30k和Flickr8k数据集上的实验表明，该框架BLEU分数分别达0.767-0.456与0.784-0.479，CIDEr分数为1.679和1.483，METEOR分数0.478和0.358，ROUGE-L分数0.567和0.789。在MS-COCO数据集上更获得0.893（B-1）、0.821（B-2）、0.794（B-3）和0.725（B-4）的BLEU分数。实验结果验证了Tri-FusionNet在生成高质量图像描述方面的卓越性能。

（注：根据学术翻译规范，专业术语保留英文缩写并首次出现时标注全称；指标数据采用国际通用格式；通过拆分英文长句为中文短句结构，保持专业性与可读性平衡）
