# Leveraging the power of transformers for guilt detection in text

链接: http://arxiv.org/abs/2401.07414v1

原文摘要:
In recent years, language models and deep learning techniques have
revolutionized natural language processing tasks, including emotion detection.
However, the specific emotion of guilt has received limited attention in this
field. In this research, we explore the applicability of three
transformer-based language models for detecting guilt in text and compare their
performance for general emotion detection and guilt detection. Our proposed
model outformed BERT and RoBERTa models by two and one points respectively.
Additionally, we analyze the challenges in developing accurate guilt-detection
models and evaluate our model's effectiveness in detecting related emotions
like "shame" through qualitative analysis of results.

中文翻译:
近年来，语言模型与深度学习技术彻底改变了自然语言处理领域，包括情感检测任务。然而在现有研究中，"内疚"这一特定情绪的探讨仍显不足。本研究探索了三种基于Transformer架构的语言模型在文本内疚情绪检测中的适用性，并对比了它们在通用情感检测与内疚专项检测中的表现。我们提出的模型以2分和1分的优势分别超越了BERT与RoBERTa基准模型。此外，研究还分析了构建精准内疚检测模型面临的挑战，通过对检测结果的定性分析，评估了模型在"羞愧"等关联情绪识别中的有效性。

（翻译说明：
1. 专业术语处理："transformer-based"译为技术圈通用译法"基于Transformer架构"，"qualitative analysis"保留学术惯用译法"定性分析"
2. 句式重构：将英文长句拆分为符合中文阅读习惯的短句，如将performance比较部分转化为"以...优势超越"的主动句式
3. 概念显化："received limited attention"译为"探讨仍显不足"而非字面直译，更符合学术表达
4. 术语统一：全文保持"检测"与"识别"的用词一致性，避免"分析""判断"等干扰术语
5. 文化适配："guilt"和"shame"根据心理学文献区分为"内疚"与"羞愧"，体现情绪层次差异）
