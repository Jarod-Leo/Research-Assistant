# From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling

链接: http://arxiv.org/abs/2503.15904v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing,
yet concerns persist regarding their tendency to reflect or amplify social
biases present in their training data. This study introduces a novel evaluation
framework to uncover gender biases in LLMs, focusing on their occupational
narratives. Unlike previous methods relying on structured scenarios or
carefully crafted prompts, our approach leverages free-form storytelling to
reveal biases embedded in the models. Systematic analyses show an
overrepresentation of female characters across occupations in six widely used
LLMs. Additionally, our findings reveal that LLM-generated occupational gender
rankings align more closely with human stereotypes than actual labor
statistics. These insights underscore the need for balanced mitigation
strategies to ensure fairness while avoiding the reinforcement of new
stereotypes.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）彻底改变了自然语言处理领域，但学界持续关注其反映或放大训练数据中社会偏见的倾向。本研究提出了一种新颖的评估框架，通过聚焦职业叙事来揭示LLMs中的性别偏见。与以往依赖结构化情境或精心设计提示词的方法不同，我们的方法利用自由叙事形式来挖掘模型内嵌的偏见。系统分析表明，在六个广泛使用的LLMs中，女性角色在所有职业类别中都存在过度表征现象。此外，研究发现LLMs生成的职业性别排名更接近人类刻板印象而非实际劳动力统计数据。这些发现强调需要制定平衡的缓解策略，在确保公平性的同时避免强化新的刻板印象。

翻译说明：
1. 专业术语处理：LLMs采用"大型语言模型"标准译法并保留英文缩写，符合中文计算机领域术语规范
2. 学术风格保持：使用"聚焦""揭示""内嵌""表征"等学术用语，保持原文严谨性
3. 长句拆分重组：将原文复合句分解为符合中文表达习惯的短句结构（如最后一句的拆分处理）
4. 被动语态转换："it is revealed that"转化为主动式"研究发现"，符合中文表达习惯
5. 概念准确传达："overrepresentation"译为"过度表征"准确传达社会学概念
6. 文化适应性调整："stereotypes"统一译为"刻板印象"，采用心理学领域标准译法
