# Rethinking with Retrieval: Faithful Large Language Model Inference

链接: http://arxiv.org/abs/2301.00303v1

原文摘要:
Despite the success of large language models (LLMs) in various natural
language processing (NLP) tasks, the stored knowledge in these models may
inevitably be incomplete, out-of-date, or incorrect. This motivates the need to
utilize external knowledge to assist LLMs. Unfortunately, current methods for
incorporating external knowledge often require additional training or
fine-tuning, which can be costly and may not be feasible for LLMs. To address
this issue, we propose a novel post-processing approach, rethinking with
retrieval (RR), which retrieves relevant external knowledge based on the
decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting.
This lightweight approach does not require additional training or fine-tuning
and is not limited by the input length of LLMs. We evaluate the effectiveness
of RR through extensive experiments with GPT-3 on three complex reasoning
tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our
results show that RR can produce more faithful explanations and improve the
performance of LLMs.

中文翻译:
尽管大语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了成功，但这些模型中存储的知识难免存在不完整、过时或错误的情况。这促使我们需要利用外部知识来辅助大语言模型。然而，当前整合外部知识的方法通常需要额外的训练或微调，这不仅成本高昂，而且对于大语言模型而言可能难以实现。为解决这一问题，我们提出了一种新颖的后处理方法——检索式反思（Rethinking with Retrieval, RR），该方法基于链式思维提示（CoT）所分解的推理步骤来检索相关外部知识。这种轻量级方法无需额外训练或微调，也不受大语言模型输入长度的限制。我们通过在GPT-3上对三类复杂推理任务（常识推理、时序推理和表格推理）进行大量实验，验证了RR的有效性。结果表明，RR能够生成更可信的解释，并提升大语言模型的性能。

