# DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning

链接: http://arxiv.org/abs/2309.05173v1

原文摘要:
Prompt tuning (PT), where a small amount of trainable soft (continuous)
prompt vectors is affixed to the input of language models (LM), has shown
promising results across various tasks and models for parameter-efficient
fine-tuning (PEFT). PT stands out from other PEFT approaches because it
maintains competitive performance with fewer trainable parameters and does not
drastically scale up its parameters as the model size expands. However, PT
introduces additional soft prompt tokens, leading to longer input sequences,
which significantly impacts training and inference time and memory usage due to
the Transformer's quadratic complexity. Particularly concerning for Large
Language Models (LLMs) that face heavy daily querying. To address this issue,
we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt
into a shorter soft prompt and a pair of low-rank matrices that are then
optimised with two different learning rates. This allows DePT to achieve better
performance while saving substantial memory and time costs compared to vanilla
PT and its variants, without changing trainable parameter sizes. Through
extensive experiments on 23 natural language processing (NLP) and
vision-language (VL) tasks, we demonstrate that DePT outperforms
state-of-the-art PEFT approaches, including the full fine-tuning baseline, in
some scenarios. Additionally, we empirically show that DEPT grows more
efficient as the model size increases. Our further study reveals that DePT
integrates seamlessly with parameter-efficient transfer learning in the
few-shot learning setting and highlights its adaptability to various model
architectures and sizes.

中文翻译:
以下是符合学术规范的中文翻译：

提示调优（Prompt Tuning, PT）通过向语言模型（LM）的输入添加少量可训练的软（连续）提示向量，在参数高效微调（PEFT）的各类任务和模型中展现出优异性能。相较于其他PEFT方法，PT的显著优势在于：使用更少的可训练参数即可保持竞争力，且不会因模型规模扩大而急剧增加参数量。然而，PT引入的额外软提示标记会延长输入序列，由于Transformer的二次计算复杂度，这将显著影响训练/推理时间和内存消耗——这对面临每日海量查询的大语言模型（LLMs）尤为关键。

为解决该问题，我们提出分解式提示调优（DePT），将软提示分解为更短的软提示和一对低秩矩阵，并以不同学习率分别优化。在保持可训练参数量不变的前提下，DePT相比原始PT及其变体能节省大量内存和时间成本，同时获得更优性能。通过在23项自然语言处理（NLP）和视觉语言（VL）任务上的广泛实验，我们证明DePT在某些场景下优于包括全参数微调基线在内的最先进PEFT方法。实验还表明：随着模型规模增大，DePT的效率提升更为显著。进一步研究发现，DePT能无缝融入小样本学习环境下的参数高效迁移学习框架，并展现出对不同模型架构和规模的强适应性。

（翻译严格遵循以下原则：
1. 专业术语统一（如soft prompt统一译为"软提示"）
2. 被动语态转换为中文主动句式
3. 长难句合理切分，符合中文表达习惯
4. 保留学术论文的客观严谨性
5. 关键概念首次出现标注英文原名
6. 复杂逻辑关系通过破折号、括号等清晰呈现）
