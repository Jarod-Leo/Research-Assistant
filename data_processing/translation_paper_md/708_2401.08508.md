# EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis

链接: http://arxiv.org/abs/2401.08508v1

原文摘要:
Sentiment analysis and emotion detection are important research topics in
natural language processing (NLP) and benefit many downstream tasks. With the
widespread application of LLMs, researchers have started exploring the
application of LLMs based on instruction-tuning in the field of sentiment
analysis. However, these models only focus on single aspects of affective
classification tasks (e.g. sentimental polarity or categorical emotions), and
overlook the regression tasks (e.g. sentiment strength or emotion intensity),
which leads to poor performance in downstream tasks. The main reason is the
lack of comprehensive affective instruction tuning datasets and evaluation
benchmarks, which cover various affective classification and regression tasks.
Moreover, although emotional information is useful for downstream tasks,
existing downstream datasets lack high-quality and comprehensive affective
annotations. In this paper, we propose EmoLLMs, the first series of
open-sourced instruction-following LLMs for comprehensive affective analysis
based on fine-tuning various LLMs with instruction data, the first multi-task
affective analysis instruction dataset (AAID) with 234K data samples based on
various classification and regression tasks to support LLM instruction tuning,
and a comprehensive affective evaluation benchmark (AEB) with 14 tasks from
various sources and domains to test the generalization ability of LLMs. We
propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various
affective instruction tasks. We compare our model with a variety of LLMs on
AEB, where our models outperform all other open-sourced LLMs, and surpass
ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve
the ChatGPT-level and GPT-4-level generalization capabilities on affective
analysis tasks, and demonstrates our models can be used as affective annotation
tools.

中文翻译:
情感分析与情绪检测是自然语言处理（NLP）领域的重要研究课题，对诸多下游任务具有重要价值。随着大语言模型（LLM）的广泛应用，研究者开始探索基于指令微调的LLM在情感分析领域的应用。然而现有模型仅关注情感分类任务的单一维度（如情感极性或离散情绪类别），而忽视了回归任务（如情感强度或情绪程度），导致其在下游任务中表现欠佳。究其原因，主要是缺乏覆盖多维度情感分类与回归任务的综合性指令微调数据集及评估基准。此外，尽管情感信息对下游任务具有增益作用，现有下游数据集普遍缺乏高质量、多维度的情感标注。

本文提出三大创新成果：1）EmoLLMs——首个开源的综合性情感分析指令跟随大模型系列，基于多样化的LLM进行指令数据微调；2）首个多任务情感分析指令数据集（AAID），包含23.4万条样本，涵盖分类与回归任务，支持LLM指令微调；3）综合性情感评估基准（AEB），包含跨领域、多来源的14项任务，用于测试LLM的泛化能力。我们通过AAID微调LLM构建了EmoLLMs系列模型，可处理多样化情感指令任务。在AEB基准测试中，EmoLLMs不仅优于所有开源LLM，更在多数任务中超越ChatGPT和GPT-4。这表明该系列模型在情感分析任务上达到了ChatGPT和GPT-4级别的泛化能力，验证了其作为情感标注工具的应用价值。

（注：根据学术翻译规范，对原文进行了以下优化处理：
1. 专业术语统一："sentiment strength"译为"情感强度"，"emotion intensity"译为"情绪程度"
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句
3. 逻辑显化：添加"究其原因"等连接词强化论证逻辑
4. 数据呈现：将"234K"转换为中文习惯的"23.4万条"
5. 被动语态转换："are proposed"译为主动态的"提出"
6. 学术用语："demonstrates"译为"验证了"更符合中文论文表述）
