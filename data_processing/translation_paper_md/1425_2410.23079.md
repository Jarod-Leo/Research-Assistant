# BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference

链接: http://arxiv.org/abs/2410.23079v1

原文摘要:
Large language models (LLMs) are essential in natural language processing but
often struggle with inference speed and computational efficiency, limiting
real-time deployment. The key-value (KV) cache mechanism reduces computational
overhead in transformer models, but challenges in maintaining contextual
understanding remain. In this paper, we propose BUZZ, a novel KV caching
algorithm that leverages structured contextual information to minimize cache
memory usage while enhancing inference speed. BUZZ employs a beehive-structured
sparse cache, incorporating a sliding window to capture recent information and
dynamically segmenting historical tokens into chunks to prioritize important
tokens in local neighborhoods. We evaluate BUZZ on four real-world datasets:
CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ
(1) reduces cache memory usage by $\textbf{2.5}\times$ in LLM inference while
maintaining over 99% accuracy in long-text summarization, and (2) surpasses
state-of-the-art performance in multi-document question answering by
$\textbf{7.69%}$ under the same memory limit, where full cache methods
encounter out-of-memory issues. Additionally, BUZZ achieves significant
inference speedup with a $\log{n}$ time complexity. The code is available at
https://github.com/JunqiZhao888/buzz-llm.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）在自然语言处理中具有核心地位，但其推理速度与计算效率的瓶颈制约了实时部署应用。基于键值缓存（KV Cache）的机制虽能降低Transformer模型计算开销，却难以保持上下文连贯性。本文提出BUZZ——一种创新的键值缓存算法，通过结构化上下文信息实现缓存内存占用的优化与推理加速。该算法采用蜂巢状稀疏缓存架构，结合滑动窗口捕获近期信息，并动态分割历史标记为区块以突出局部邻域的重要标记。我们在四个真实数据集（CNN/Daily Mail、XSUM、Wikitext和10-QA）上的实验表明：BUZZ算法（1）在长文本摘要任务中保持99%以上准确率的同时，将LLM推理缓存内存占用降低$\textbf{2.5}$倍；（2）同等内存限制下（完整缓存方法出现内存溢出时），多文档问答任务性能超越现有最优方法$\textbf{7.69\%}$。此外，BUZZ凭借$\log{n}$时间复杂度实现了显著的推理加速。代码已开源：https://github.com/JunqiZhao888/buzz-llm。

（翻译说明：1. 专业术语保留英文缩写并标注中文全称；2. 技术概念如"sliding window"采用业界通用译法"滑动窗口"；3. 数学表达式与百分数严格保留原文格式；4. 长句按中文习惯拆分为短句；5. 被动语态转换为主动表述；6. 项目名称BUZZ保留不译以符合计算机领域惯例）
