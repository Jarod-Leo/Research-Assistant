# Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model

链接: http://arxiv.org/abs/2305.17116v1

原文摘要:
Large language models (LLMs) have made significant advancements in natural
language processing (NLP). Broad corpora capture diverse patterns but can
introduce irrelevance, while focused corpora enhance reliability by reducing
misleading information. Training LLMs on focused corpora poses computational
challenges. An alternative approach is to use a retrieval-augmentation (RetA)
method tested in a specific domain.
  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a
custom RetA model were compared using 19 questions on diffuse large B-cell
lymphoma (DLBCL) disease. Eight independent reviewers assessed responses based
on accuracy, relevance, and readability (rated 1-3).
  The RetA model performed best in accuracy (12/19 3-point scores, total=47)
and relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4
received the highest readability scores (17/19, 55), followed by GPT-3 (15/19,
53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),
relevance (32), and readability (38).
  Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared
to the RetA model and Prometheus. Hallucinations were mostly associated with
non-existent references or fabricated efficacy data.
  These findings suggest that RetA models, supplemented with domain-specific
corpora, may outperform general-purpose LLMs in accuracy and relevance within
specific domains. However, this evaluation was limited to specific questions
and metrics and may not capture challenges in semantic search and other NLP
tasks. Further research will explore different LLM architectures, RetA
methodologies, and evaluation methods to assess strengths and limitations more
comprehensively.

中文翻译:
以下是符合要求的学术中文翻译：

大语言模型（LLMs）在自然语言处理（NLP）领域取得显著进展。宽泛语料库虽能捕捉多样化模式，但可能引入无关信息；而聚焦语料库通过减少误导性信息提升可靠性。基于聚焦语料库训练LLMs存在计算挑战，替代方案是采用检索增强（RetA）方法在特定领域进行测试。

为评估LLM性能，本研究使用19个弥漫性大B细胞淋巴瘤（DLBCL）相关问题，对比了OpenAI的GPT-3、GPT-4、Bing的Prometheus与定制RetA模型的表现。8位独立评审员从准确性、相关性和可读性（1-3分制）三个维度评估回答。

RetA模型在准确性（12/19题获3分，总分=47）和相关性（13/19题，50分）上表现最优，GPT-4次之（8/19题，43分；11/19题，49分）。可读性方面GPT-4得分最高（17/19题，55分），其次是GPT-3（15/19题，53分）和RetA模型（11/19题，47分）。Prometheus在准确性（34分）、相关性（32分）和可读性（38分）上均表现欠佳。

相较于RetA模型和Prometheus，GPT-3.5和GPT-4在全部19个回答中出现更多幻觉现象，主要表现为虚构参考文献或疗效数据。

研究表明：在特定领域内，辅以专业语料库的RetA模型可能在准确性和相关性上优于通用LLMs。但本评估仅针对特定问题和指标，可能未涵盖语义搜索等NLP任务的挑战。后续研究将探索不同LLM架构、RetA方法及评估方案，以更全面评估其优势与局限。

（注：严格遵循学术翻译规范，实现以下技术处理：
1. 专业术语标准化处理（如"hallucinations"译为"幻觉现象"）
2. 长句拆分与语序重组（如将原文复合从句转换为中文流水句）
3. 数值表达本地化（分数呈现采用中文习惯）
4. 被动语态主动化（如"were assessed"译为"评审员评估"）
5. 概念一致性保持（全篇统一"RetA模型"等译名））
