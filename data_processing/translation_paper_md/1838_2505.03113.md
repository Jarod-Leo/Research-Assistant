# Image Recognition with Online Lightweight Vision Transformer: A Survey

链接: http://arxiv.org/abs/2505.03113v1

原文摘要:
The Transformer architecture has achieved significant success in natural
language processing, motivating its adaptation to computer vision tasks. Unlike
convolutional neural networks, vision transformers inherently capture
long-range dependencies and enable parallel processing, yet lack inductive
biases and efficiency benefits, facing significant computational and memory
challenges that limit its real-world applicability. This paper surveys various
online strategies for generating lightweight vision transformers for image
recognition, focusing on three key areas: Efficient Component Design, Dynamic
Network, and Knowledge Distillation. We evaluate the relevant exploration for
each topic on the ImageNet-1K benchmark, analyzing trade-offs among precision,
parameters, throughput, and more to highlight their respective advantages,
disadvantages, and flexibility. Finally, we propose future research directions
and potential challenges in the lightweighting of vision transformers with the
aim of inspiring further exploration and providing practical guidance for the
community. Project Page: https://github.com/ajxklo/Lightweight-VIT

中文翻译:
Transformer架构在自然语言处理领域取得显著成功后，其设计理念被引入计算机视觉任务。与卷积神经网络不同，视觉Transformer天生具备捕捉长程依赖关系和并行处理能力，但缺乏归纳偏置和效率优势，面临巨大的计算与内存开销，制约了实际应用。本文系统综述了面向图像识别的轻量化视觉Transformer在线生成策略，聚焦三大核心方向：高效组件设计、动态网络和知识蒸馏。我们在ImageNet-1K基准上评估了各主题的相关探索，通过精度、参数量、吞吐量等指标的权衡分析，揭示不同方法的优势、局限及灵活性。最后针对视觉Transformer轻量化提出了未来研究方向与潜在挑战，旨在启发后续探索并为学界提供实践指导。项目页面：https://github.com/ajxklo/Lightweight-VIT

（翻译说明：
1. 专业术语准确处理："inductive biases"译为"归纳偏置"，"throughput"译为"吞吐量"符合计算机领域惯例
2. 长句拆分重构：将原文复合句分解为符合中文表达习惯的短句，如第二句拆分为三个逻辑层次
3. 被动语态转化："are evaluated"转为主动式"评估了"，更符合中文论述习惯
4. 概念显化处理："online strategies"译为"在线生成策略"以明确技术内涵
5. 学术文本风格统一：保持"综述""揭示""旨在"等学术用语的一致性
6. 链接信息完整保留：项目页面URL未作改动确保可追溯性）
