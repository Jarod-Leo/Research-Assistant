# The Accuracy of Domain Specific and Descriptive Analysis Generated by Large Language Models

链接: http://arxiv.org/abs/2405.19578v1

原文摘要:
Large language models (LLMs) have attracted considerable attention as they
are capable of showcasing impressive capabilities generating comparable
high-quality responses to human inputs. LLMs, can not only compose textual
scripts such as emails and essays but also executable programming code.
Contrary, the automated reasoning capability of these LLMs in performing
statistically-driven descriptive analysis, particularly on user-specific data
and as personal assistants to users with limited background knowledge in an
application domain who would like to carry out basic, as well as advanced
statistical and domain-specific analysis is not yet fully explored. More
importantly, the performance of these LLMs has not been compared and discussed
in detail when domain-specific data analysis tasks are needed. This study,
consequently, explores whether LLMs can be used as generative AI-based personal
assistants to users with minimal background knowledge in an application domain
infer key data insights. To demonstrate the performance of the LLMs, the study
reports a case study through which descriptive statistical analysis, as well as
Natural Language Processing (NLP) based investigations, are performed on a
number of phishing emails with the objective of comparing the accuracy of the
results generated by LLMs to the ones produced by analysts. The experimental
results show that LangChain and the Generative Pre-trained Transformer (GPT-4)
excel in numerical reasoning tasks i.e., temporal statistical analysis, achieve
competitive correlation with human judgments on feature engineering tasks while
struggle to some extent on domain specific knowledge reasoning, where
domain-specific knowledge is required.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）因其能够针对人类输入生成可比拟的高质量响应而受到广泛关注。这类模型不仅能撰写电子邮件、论文等文本脚本，还可生成可执行程序代码。然而，这些模型在统计驱动的描述性分析中的自动推理能力——特别是针对用户特定数据，以及作为个人助手为应用领域背景知识有限的用户提供基础/高级统计及领域分析的功能——尚未得到充分探索。更重要的是，当涉及领域特定的数据分析任务时，这些模型的性能尚未被系统性地比较与讨论。

为此，本研究探讨了LLMs能否作为基于生成式AI的个人助手，帮助应用领域知识基础薄弱的用户推断关键数据洞见。为验证模型性能，研究通过案例分析了钓鱼邮件的描述性统计与自然语言处理（NLP）检测任务，旨在对比LLMs生成结果与分析人员所得结果的准确性。实验表明：LangChain和生成式预训练变换器（GPT-4）在数值推理任务（如时序统计分析）中表现优异，在特征工程任务上达到与人类判断相当的关联性，但在需要领域专业知识的推理任务中仍存在一定局限。

（译文严格遵循学术规范，采用专业术语统一原则："LLMs"统一译为"大型语言模型"并保留括号标注；"Generative Pre-trained Transformer"规范译为"生成式预训练变换器"；通过拆分英文长句为中文短句结构（如将"capable of..."处理为因果句式），确保逻辑清晰；被动语态转换为主动表述（如"is not yet fully explored"译为"尚未得到充分探索"）；关键概念如"domain-specific knowledge reasoning"准确译为"领域专业知识推理"以保持专业性。）
