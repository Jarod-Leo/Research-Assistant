# HKCanto-Eval: A Benchmark for Evaluating Cantonese Language Understanding and Cultural Comprehension in LLMs

链接: http://arxiv.org/abs/2503.12440v1

原文摘要:
The ability of language models to comprehend and interact in diverse
linguistic and cultural landscapes is crucial. The Cantonese language used in
Hong Kong presents unique challenges for natural language processing due to its
rich cultural nuances and lack of dedicated evaluation datasets. The
HKCanto-Eval benchmark addresses this gap by evaluating the performance of
large language models (LLMs) on Cantonese language understanding tasks,
extending to English and Written Chinese for cross-lingual evaluation.
HKCanto-Eval integrates cultural and linguistic nuances intrinsic to Hong Kong,
providing a robust framework for assessing language models in realistic
scenarios. Additionally, the benchmark includes questions designed to tap into
the underlying linguistic metaknowledge of the models. Our findings indicate
that while proprietary models generally outperform open-weight models,
significant limitations remain in handling Cantonese-specific linguistic and
cultural knowledge, highlighting the need for more targeted training data and
evaluation methods. The code can be accessed at
https://github.com/hon9kon9ize/hkeval2025

中文翻译:
语言模型在多元语言文化环境中理解和交互的能力至关重要。香港地区使用的粤语因其丰富的文化意蕴及专用评估数据集的匮乏，为自然语言处理带来了独特挑战。HKCanto-Eval基准通过评估大语言模型（LLMs）在粤语理解任务上的表现填补了这一空白，并延伸至英语和书面中文以实现跨语言评估。该基准整合了香港特有的文化与语言细微差异，为现实场景中的语言模型评估提供了稳健框架。此外，基准测试还包含专门设计用于探测模型底层语言元知识的问题。研究结果表明，虽然专有模型总体优于开源权重模型，但在处理粤语特有语言文化知识方面仍存在显著局限，这凸显了针对性的训练数据和评估方法的必要性。代码可通过https://github.com/hon9kon9ize/hkeval2025获取。

（注：根据学术文本翻译规范，对以下要点进行了优化处理：
1. "linguistic metaknowledge"译为"语言元知识"符合认知语言学专业术语
2. "open-weight models"采用"开源权重模型"的译法，既保留技术准确性又符合中文表达
3. 长句拆分符合中文多用短句的表述习惯，如将原文最后复合句拆分为两个独立语义单元
4. 专业术语如"benchmark"统一译为"基准"保持全文一致性
5. 被动语态转换为主动句式，如"can be accessed"译为"可通过"）
