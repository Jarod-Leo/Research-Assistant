# GEIC: Universal and Multilingual Named Entity Recognition with Large Language Models

链接: http://arxiv.org/abs/2409.11022v2

原文摘要:
With the advancement of Large Language Models (LLMs), more and more
researchers apply LLMs for Named Entity Recognition (NER) methods, bringing
vitality to this classical Natural Language Processing task. However, existing
datasets are designed for traditional machine learning methods, inadequate for
LLM-based methods in terms of corpus selection, entity categorization, and
design logic. This limitation leads to less effective evaluation and model
fine-tuning. To address this issue, we propose DynamicNER, the first NER
dataset specifically designed for LLMs and with dynamic categorization,
transcending the limitations of fixed categorization in existing datasets. It
is also multi-lingual and multi-granular, covering 8 languages and 155 entity
types, with corpus spanning multiple specialized domains. Furthermore, in
response to the limitations demonstrated by existing LLM-based methods during
DynamicNER testing, we develop CascadeNER, a novel NER method based on a
two-stage strategy and lightweight LLMs, addressing the problems in current
methods. Experiments show that DynamicNER is an effective benchmark for
LLM-based NER methods, and CascadeNER outperforms existing methods with fewer
computational resources. Our work is opened at
https://github.com/CascadeNER/CascadeNER.

中文翻译:
随着大语言模型（LLMs）的发展，越来越多的研究者将其应用于命名实体识别（NER）任务，为这一经典自然语言处理课题注入了新活力。然而，现有数据集专为传统机器学习方法设计，在语料选择、实体分类和逻辑架构方面难以适配基于LLM的方法，导致评估与模型微调效果受限。为此，我们提出DynamicNER——首个专为LLM设计且具备动态分类特性的NER数据集，突破了现有数据集固定分类体系的局限。该数据集具备多语言、多粒度特性，涵盖8种语言和155种实体类型，语料覆盖多个专业领域。

针对现有基于LLM的方法在DynamicNER测试中暴露的不足，我们进一步提出CascadeNER：一种基于两阶段策略和轻量化LLM的新型NER方法，有效解决了当前方法存在的问题。实验表明，DynamicNER可作为评估基于LLM的NER方法的有效基准，而CascadeNER在消耗更少计算资源的情况下性能优于现有方法。我们的工作已开源：https://github.com/CascadeNER/CascadeNER。

（注：根据学术翻译规范，对原文进行了以下优化处理：
1. 将"methods"根据语境分别译为"方法/任务/课题"
2. "dynamic categorization"译为"动态分类特性"以突出数据集特性
3. 调整英文长句为中文短句结构，如将"transcending..."处理为独立分句
4. 专业术语保持统一："LLMs"始终译为"大语言模型"
5. 补充"该数据集"等连接词增强中文连贯性
6. 技术描述采用"两阶段策略"等符合中文论文表达的措辞）
