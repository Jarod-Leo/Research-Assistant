# LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation

链接: http://arxiv.org/abs/2407.13744v1

原文摘要:
Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like "artificial general intelligences"
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as "prompt injection" and
"jailbreaking").

中文翻译:
自然语言处理技术的发展轨迹相当迅速：从针对特定任务构建模型，到采用通用预训练模型进行微调以适应具体任务，直至今日出现了看似具有内在通用性的模型。本文指出，这种发展导致我们逐渐无法清晰界定这些模型究竟在建模什么，由此产生的"人工通用智能"等隐喻无助于准确评估其优势与局限。我们主张从"基于自然语言规范来逼近专业功能"的视角，重新理解这类模型的通用性及其潜在价值。这一理论框架不仅凸显了功能逼近的质量问题，更引申出关于这些功能的可发现性、稳定性与可保护性等深层议题。如本文所述，该框架能够将实践与理论双重视角下的各类评估维度（包括常被边缘化的"提示注入"和"越狱"等问题）统一纳入同一个概念体系。
