# CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation

链接: http://arxiv.org/abs/2310.15638v1

原文摘要:
Annotated data plays a critical role in Natural Language Processing (NLP) in
training models and evaluating their performance. Given recent developments in
Large Language Models (LLMs), models such as ChatGPT demonstrate zero-shot
capability on many text-annotation tasks, comparable with or even exceeding
human annotators. Such LLMs can serve as alternatives for manual annotation,
due to lower costs and higher scalability. However, limited work has leveraged
LLMs as complementary annotators, nor explored how annotation work is best
allocated among humans and LLMs to achieve both quality and cost objectives. We
propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of
unstructured texts at scale. Under this framework, we utilize uncertainty to
estimate LLMs' annotation capability. Our empirical study shows CoAnnotating to
be an effective means to allocate work from results on different datasets, with
up to 21% performance improvement over random baseline. For code
implementation, see https://github.com/SALT-NLP/CoAnnotating.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

标注数据在自然语言处理（NLP）领域对模型训练和性能评估具有关键作用。随着大语言模型（LLMs）的最新发展，ChatGPT等模型在众多文本标注任务中展现出与人类标注者相当甚至更优的零样本能力。这类LLMs凭借更低成本与更高扩展性，可作为人工标注的替代方案。然而，现有研究较少探索如何将LLMs作为补充性标注工具，也未系统研究如何在人类与LLMs之间优化分配标注任务以实现质量与成本的双重目标。本文提出"协同标注"（CoAnnotating）这一创新范式，用于大规模非结构化文本的人机协同标注。该框架通过不确定性度量来评估LLMs的标注能力，实证研究表明：在不同数据集上，协同标注的工作分配策略相比随机基线最高可获得21%的性能提升。代码实现详见https://github.com/SALT-NLP/CoAnnotating。

（注：根据学术翻译规范，对关键术语进行了统一处理：
1. "Large Language Models"译为"大语言模型"并保留缩写LLMs
2. "zero-shot capability"采用通用译法"零样本能力"
3. 框架名称"CoAnnotating"首次出现时译为"协同标注"并保留英文原名
4. 技术术语"uncertainty"根据上下文译为"不确定性度量"
5. 保持被动语态与原文学术风格的一致性
6. 长句按中文习惯拆分重组，如将"nor explored..."独立成句
7. 补充"本文"作为主语以符合中文表达习惯）
