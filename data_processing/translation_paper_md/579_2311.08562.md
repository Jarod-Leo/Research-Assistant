# MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration

链接: http://arxiv.org/abs/2311.08562v2

原文摘要:
Large Language Models (LLMs) have significantly advanced natural language
processing, demonstrating exceptional reasoning, tool usage, and memory
capabilities. As their applications expand into multi-agent environments, there
arises a need for a comprehensive evaluation framework that captures LLMs'
reasoning, planning, collaboration, and other social abilities. This work
introduces a novel competition-based benchmark framework specifically designed
to assess LLMs within multi-agent settings, providing quantitative metrics to
evaluate their judgment, reasoning, deception, self-awareness, cooperation,
coordination, and rationality. We utilize two social deduction games alongside
three game-theory scenarios to create diverse environments. Our frame is
fortified with the probabilistic graphic modeling (PGM) method, enhancing the
LLMs' capabilities in navigating complex social and cognitive dimensions. We
evaluate seven LLMs, quantitatively highlighting a significant capability gap
of over threefold between the strongest, GPT o1, and the weakest, Llama-2-70B.
It also confirms that our PGM enhancement boosts the abilities of all selected
models by an average of 37%. Our data and code can be found here
https://github.com/cathyxl/MAgIC.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）在自然语言处理领域取得显著突破，展现出卓越的推理能力、工具使用能力和记忆能力。随着其在多智能体环境中的应用扩展，亟需建立能够全面评估LLMs推理、规划、协作等社会性能力的框架。本研究提出了一种基于竞争的新型基准测试框架，专门用于评估多智能体环境中的LLMs，通过量化指标衡量其判断、推理、欺骗、自我意识、合作、协调及理性等能力。我们采用两款社交推理游戏和三种博弈论场景构建多样化测试环境，并引入概率图模型（PGM）方法强化框架，显著提升了LLMs在复杂社会认知维度中的表现。通过对七种LLMs的评估，定量揭示了性能最强模型GPT-4与最弱模型Llama-2-70B之间超过三倍的能力差距。实验同时证实，PGM增强策略使所有测试模型的平均能力提升达37%。相关数据与代码已开源：https://github.com/cathyxl/MAgIC。

（翻译说明：
1. 专业术语处理：LLMs保持英文缩写+中文全称的学术惯例，PGM译为"概率图模型"并标注英文原称
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"demonstrating..."独立成句译为"展现出..."
3. 被动语态转换："there arises a need"译为主动句式"亟需建立"
4. 概念对等："social deduction games"译为专业术语"社交推理游戏"
5. 数据呈现：精确转换"threefold"为"三倍"，"37%"保留数字格式
6. 学术规范：保留技术术语英文缩写及开源链接原貌）
