# Differentially Private Natural Language Models: Recent Advances and Future Directions

链接: http://arxiv.org/abs/2301.09112v1

原文摘要:
Recent developments in deep learning have led to great success in various
natural language processing (NLP) tasks. However, these applications may
involve data that contain sensitive information. Therefore, how to achieve good
performance while also protecting the privacy of sensitive data is a crucial
challenge in NLP. To preserve privacy, Differential Privacy (DP), which can
prevent reconstruction attacks and protect against potential side knowledge, is
becoming a de facto technique for private data analysis. In recent years, NLP
in DP models (DP-NLP) has been studied from different perspectives, which
deserves a comprehensive review. In this paper, we provide the first systematic
review of recent advances in DP deep learning models in NLP. In particular, we
first discuss some differences and additional challenges of DP-NLP compared
with the standard DP deep learning. Then, we investigate some existing work on
DP-NLP and present its recent developments from three aspects: gradient
perturbation based methods, embedding vector perturbation based methods, and
ensemble model based methods. We also discuss some challenges and future
directions.

中文翻译:
深度学习领域的最新进展使得各类自然语言处理（NLP）任务取得了显著成功。然而，这些应用可能涉及包含敏感信息的数据。因此，如何在保证良好性能的同时保护敏感数据的隐私，成为NLP领域的关键挑战。为保护隐私，能够防止重构攻击并抵御潜在旁路知识的差分隐私（DP）技术，已成为隐私数据分析的事实标准方法。近年来，差分隐私模型在NLP领域（DP-NLP）的研究已从多角度展开，亟需系统性梳理。本文首次对NLP中差分隐私深度学习模型的最新进展进行了系统综述：首先阐述DP-NLP相较于标准DP深度学习的差异性与附加挑战；继而从梯度扰动法、嵌入向量扰动法和集成模型法三个维度剖析现有研究成果；最后探讨当前面临的挑战与未来发展方向。

