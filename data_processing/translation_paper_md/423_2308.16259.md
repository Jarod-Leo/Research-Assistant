# Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction

链接: http://arxiv.org/abs/2308.16259v1

原文摘要:
Recently, the remarkable capabilities of large language models (LLMs) have
been illustrated across a variety of research domains such as natural language
processing, computer vision, and molecular modeling. We extend this paradigm by
utilizing LLMs for material property prediction by introducing our model
Materials Informatics Transformer (MatInFormer). Specifically, we introduce a
novel approach that involves learning the grammar of crystallography through
the tokenization of pertinent space group information. We further illustrate
the adaptability of MatInFormer by incorporating task-specific data pertaining
to Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover
the key features that the model prioritizes during property prediction. The
effectiveness of our proposed model is empirically validated across 14 distinct
datasets, hereby underscoring its potential for high throughput screening
through accurate material property prediction.

中文翻译:
近期，大型语言模型（LLM）在自然语言处理、计算机视觉和分子建模等多个研究领域展现出卓越能力。我们通过引入"材料信息学Transformer"（MatInFormer）模型，将这一范式拓展至材料性能预测领域。具体而言，我们提出了一种创新方法——通过对相关空间群信息进行标记化处理，实现晶体学语法规则的机器学习。研究进一步通过整合金属有机框架（MOFs）的任务特异性数据，验证了MatInFormer的强适配性。借助注意力可视化技术，我们揭示了模型在性能预测过程中关注的关键特征。通过在14个不同数据集上的实证验证，本模型凭借精准的材料性能预测能力，充分展现了其在高通量筛选应用中的巨大潜力。

（翻译说明：
1. 专业术语处理："tokenization"译为"标记化"符合NLP领域惯例，"space group"译为"空间群"符合晶体学术语
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"illustrated across..."处理为"在...领域展现出"的主动句式
3. 概念显化："this paradigm"具体化为"这一范式"，"throughput screening"扩充为"高通量筛选"以明确专业内涵
4. 逻辑连接：添加"具体而言"、"借助"等连接词增强行文连贯性
5. 被动语态转换：将"are illustrated"等被动式转为"展现出"等主动表达
6. 术语统一性：全篇保持"模型/性能预测/标记化"等核心术语的一致性）
