# Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers

链接: http://arxiv.org/abs/2304.09948v1

原文摘要:
The proliferation of fake reviews of doctors has potentially detrimental
consequences for patient well-being and has prompted concern among consumer
protection groups and regulatory bodies. Yet despite significant advancements
in the fields of machine learning and natural language processing, there
remains limited comprehension of the characteristics differentiating fraudulent
from authentic reviews. This study utilizes a novel pre-labeled dataset of
38048 physician reviews to establish the effectiveness of large language models
in classifying reviews. Specifically, we compare the performance of traditional
ML models, such as logistic regression and support vector machines, to
generative pre-trained transformer models. Furthermore, we use GPT4, the newest
model in the GPT family, to uncover the key dimensions along which fake and
genuine physician reviews differ. Our findings reveal significantly superior
performance of GPT-3 over traditional ML models in this context. Additionally,
our analysis suggests that GPT3 requires a smaller training sample than
traditional models, suggesting its appropriateness for tasks with scarce
training data. Moreover, the superiority of GPT3 performance increases in the
cold start context i.e., when there are no prior reviews of a doctor. Finally,
we employ GPT4 to reveal the crucial dimensions that distinguish fake physician
reviews. In sharp contrast to previous findings in the literature that were
obtained using simulated data, our findings from a real-world dataset show that
fake reviews are generally more clinically detailed, more reserved in
sentiment, and have better structure and grammar than authentic ones.

中文翻译:
以下是符合您要求的中文翻译：

医生虚假评论的泛滥可能对患者健康造成潜在危害，已引发消费者保护团体和监管机构的担忧。尽管机器学习和自然语言处理领域已取得重大进展，学界对虚假评论与真实评论的区分特征仍缺乏深入理解。本研究采用包含38048条预标注医生评论的新型数据集，验证大语言模型在评论分类中的有效性。具体而言，我们比较了逻辑回归和支持向量机等传统机器学习模型与生成式预训练变换模型的性能差异。此外，我们运用GPT家族最新模型GPT4，揭示了虚假与真实医生评论的关键区分维度。

研究结果表明：在此分类任务中，GPT3的表现显著优于传统机器学习模型；与传统模型相比，GPT3所需训练样本量更少，表明其特别适合训练数据稀缺的场景；当面临"冷启动"情境（即医生尚无历史评论）时，GPT3的性能优势更为突出。最后，通过GPT4的分析我们发现：与既往基于模拟数据的研究结论截然不同，真实世界数据集显示虚假评论通常具有更详尽的临床细节、更克制的情感表达，以及比真实评论更严谨的结构和语法规范。

（注：根据学术摘要的文体特点，译文在保持专业性的同时：
1. 将英语长句合理切分为符合中文表达习惯的短句
2. 专业术语如"cold start"采用行业通用译法"冷启动"
3. 关键量化数据38048保留原貌
4. 通过"研究表明"等措辞保持学术客观性
5. 对比性结论使用分号衔接以体现逻辑关系
6. 最后一句通过"与...截然不同"的转折结构突出研究创新点）
