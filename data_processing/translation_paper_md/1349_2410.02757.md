# Loong: Generating Minute-level Long Videos with Autoregressive Language Models

链接: http://arxiv.org/abs/2410.02757v1

原文摘要:
It is desirable but challenging to generate content-rich long videos in the
scale of minutes. Autoregressive large language models (LLMs) have achieved
great success in generating coherent and long sequences of tokens in the domain
of natural language processing, while the exploration of autoregressive LLMs
for video generation is limited to generating short videos of several seconds.
In this work, we conduct a deep analysis of the challenges that prevent
autoregressive LLM-based video generators from generating long videos. Based on
the observations and analysis, we propose Loong, a new autoregressive LLM-based
video generator that can generate minute-long videos. Specifically, we model
the text tokens and video tokens as a unified sequence for autoregressive LLMs
and train the model from scratch. We propose progressive short-to-long training
with a loss re-weighting scheme to mitigate the loss imbalance problem for long
video training. We further investigate inference strategies, including video
token re-encoding and sampling strategies, to diminish error accumulation
during inference. Our proposed Loong can be trained on 10-second videos and be
extended to generate minute-level long videos conditioned on text prompts, as
demonstrated by the results. More samples are available at:
https://yuqingwang1029.github.io/Loong-video.

中文翻译:
生成内容丰富、时长数分钟的长视频是一个理想但极具挑战性的目标。自回归大语言模型（LLMs）在自然语言处理领域已成功生成长序列的连贯文本，但将其应用于视频生成时，目前仅能生成数秒的短视频。本研究深入分析了阻碍基于自回归LLM的视频生成模型生成长视频的关键问题，并基于观察与分析提出了Loong——一种新型的自回归LLM视频生成框架，能够生成分钟级的长视频。具体而言，我们将文本标记与视频标记统一建模为自回归LLM的序列并从头训练模型。通过提出渐进式"由短至长"训练策略与损失重加权方案，有效缓解了长视频训练中的损失失衡问题。此外，我们研究了包括视频标记重编码与采样策略在内的推理优化方法，以减少推理过程中的误差累积。实验结果表明，所提出的Loong框架在10秒短视频上训练后，能够根据文本提示生成分钟级的长视频。更多生成样本请访问：https://yuqingwang1029.github.io/Loong-video。

（翻译说明：
1. 专业术语处理："autoregressive LLMs"统一译为"自回归大语言模型"并首次出现标注英文缩写
2. 长句拆分：将原文复合长句按中文表达习惯拆分为多个短句，如将"Based on..."独立为分句
3. 被动语态转换："it is desirable but challenging"转化为主动句式"是理想但极具挑战性的目标"
4. 概念显化："progressive short-to-long training"译为"渐进式'由短至长'训练策略"以增强可读性
5. 技术表述准确性："video token re-encoding"严格对应"视频标记重编码"
6. 衔接处理：添加"具体而言""此外"等逻辑连接词保持行文连贯
7. 文化适配：保留技术链接但采用中文引导语"更多生成样本请访问"）
