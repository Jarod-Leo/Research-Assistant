# A Survey on Large Language Models for Recommendation

链接: http://arxiv.org/abs/2305.19860v2

原文摘要:
Large Language Models (LLMs) have emerged as powerful tools in the field of
Natural Language Processing (NLP) and have recently gained significant
attention in the domain of Recommendation Systems (RS). These models, trained
on massive amounts of data using self-supervised learning, have demonstrated
remarkable success in learning universal representations and have the potential
to enhance various aspects of recommendation systems by some effective transfer
techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect
of harnessing the power of language models in enhancing recommendation quality
is the utilization of their high-quality representations of textual features
and their extensive coverage of external knowledge to establish correlations
between items and users. To provide a comprehensive understanding of the
existing LLM-based recommendation systems, this survey presents a taxonomy that
categorizes these models into two major paradigms, respectively Discriminative
LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation
(GLLM4Rec), with the latter being systematically sorted out for the first time.
Furthermore, we systematically review and analyze existing LLM-based
recommendation systems within each paradigm, providing insights into their
methodologies, techniques, and performance. Additionally, we identify key
challenges and several valuable findings to provide researchers and
practitioners with inspiration. We have also created a GitHub repository to
index relevant papers on LLMs for recommendation,
https://github.com/WLiK/LLM4Rec.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）已成为自然语言处理（NLP）领域的重要工具，近年来在推荐系统（RS）领域获得显著关注。这类通过自监督学习在海量数据上训练的模型，在学习通用表征方面展现出卓越能力，并能通过微调、提示调优等迁移技术有效提升推荐系统的多个维度。其核心价值在于利用高质量的文本特征表征和广覆盖的外部知识，建立物品与用户间的关联网络。

为系统梳理现有基于LLM的推荐系统研究，本文首次提出二元分类框架：判别式推荐大模型（DLLM4Rec）与生成式推荐大模型（GLLM4Rec），其中后者系首次被系统归纳。我们分别对两类范式下的推荐模型进行方法论、技术实现与性能表现的全面分析，同时提炼出关键挑战与重要发现以启发展未来研究。相关论文资源已建立GitHub仓库索引：https://github.com/WLiK/LLM4Rec。

（注：根据学术翻译规范，对原文进行了以下处理：
1. 将长句拆分为符合中文表达习惯的短句结构
2. "self-supervised learning"统一译为"自监督学习"（领域标准译法）
3. "fine-tuning/prompt tuning"采用"微调/提示调优"的通用译法
4. 专业术语如"representations"译为"表征"（NLP领域标准译法）
5. 补充"系首次被系统归纳"等逻辑连接词增强行文连贯性
6. 保留技术缩写（LLM/RS等）及GitHub链接的原始格式
