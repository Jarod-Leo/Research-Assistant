# ClipFormer: Key-Value Clipping of Transformers on Memristive Crossbars for Write Noise Mitigation

链接: http://arxiv.org/abs/2402.02586v1

原文摘要:
Transformers have revolutionized various real-world applications from natural
language processing to computer vision. However, traditional von-Neumann
computing paradigm faces memory and bandwidth limitations in accelerating
transformers owing to their massive model sizes. To this end, In-memory
Computing (IMC) crossbars based on Non-volatile Memories (NVMs), due to their
ability to perform highly parallelized Matrix-Vector-Multiplications (MVMs)
with high energy-efficiencies, have emerged as a promising solution for
accelerating transformers. However, analog MVM operations in crossbars
introduce non-idealities, such as stochastic read & write noise, which affect
the inference accuracy of the deployed transformers. Specifically, we find
pre-trained Vision Transformers (ViTs) to be vulnerable on crossbars due to the
impact of write noise on the dynamically-generated Key (K) and Value (V)
matrices in the attention layers, an effect not accounted for in prior studies.
We, thus, propose ClipFormer, a transformation on the K and V matrices during
inference, to boost the non-ideal accuracies of pre-trained ViT models.
ClipFormer requires no additional hardware and training overhead and is
amenable to transformers deployed on any memristive crossbar platform. Our
experiments on Imagenet-1k dataset using pre-trained DeiT-S transformers,
subjected to standard training and variation-aware-training, show >10-40%
higher non-ideal accuracies at the high write noise regime by applying
ClipFormer.

中文翻译:
Transformer模型已彻底革新了从自然语言处理到计算机视觉的多种实际应用。然而，传统冯·诺依曼计算架构在加速Transformer时面临内存与带宽限制，这源于其庞大的模型规模。为此，基于非易失性存储器（NVM）的内存计算（IMC）交叉阵列凭借其高效并行执行矩阵-向量乘法（MVM）的能力及卓越能效，成为加速Transformer的理想解决方案。但交叉阵列中的模拟MVM操作会引入非理想因素（如随机读写噪声），影响部署模型的推理精度。研究发现，预训练视觉Transformer（ViT）在交叉阵列上尤为脆弱，这主要源于写入噪声对注意力层动态生成的键（K）和值（V）矩阵的影响——该效应在先前研究中未被充分考虑。因此，我们提出ClipFormer方案，通过在推理阶段对K、V矩阵进行变换，有效提升预训练ViT模型在非理想条件下的准确率。该方案无需额外硬件投入和训练开销，可适配任何忆阻器交叉阵列平台。在ImageNet-1k数据集上对预训练DeiT-S模型的实验表明：采用标准训练和抗变异训练时，ClipFormer在高写入噪声环境下可使非理想准确率提升10-40%以上。
