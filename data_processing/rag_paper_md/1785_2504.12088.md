# AttentionDrop: A Novel Regularization Method for Transformer Models

链接: http://arxiv.org/abs/2504.12088v1

原文摘要:
Transformer-based architectures achieve state-of-the-art performance across a
wide range of tasks in natural language processing, computer vision, and
speech. However, their immense capacity often leads to overfitting, especially
when training data is limited or noisy. We propose AttentionDrop, a unified
family of stochastic regularization techniques that operate directly on the
self-attention distributions. We introduces three variants: 1. Hard Attention
Masking: randomly zeroes out top-k attention logits per query to encourage
diverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic
Gaussian convolution over attention logits to diffuse overly peaked
distributions. 3. Consistency-Regularized AttentionDrop: enforces output
stability under multiple independent AttentionDrop perturbations via a KL-based
consistency loss.

中文翻译:
基于Transformer的架构在自然语言处理、计算机视觉和语音领域广泛任务中实现了最先进的性能。然而，其巨大容量常导致过拟合问题，尤其在训练数据有限或存在噪声时。我们提出AttentionDrop——一个直接作用于自注意力分布的统一随机正则化技术家族，包含三种变体：1. 硬注意力掩码：随机清零每个查询的前k个注意力对数，以促进多样化上下文利用；2. 模糊注意力平滑：对注意力对数施加动态高斯卷积，扩散过度集中的分布；3. 一致性正则化AttentionDrop：通过基于KL散度的一致性损失，强制模型在多次独立AttentionDrop扰动下保持输出稳定性。
