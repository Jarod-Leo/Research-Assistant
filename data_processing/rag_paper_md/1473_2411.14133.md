# GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs

链接: http://arxiv.org/abs/2411.14133v1

原文摘要:
Large Language Models (LLMs) have shown impressive proficiency across a range
of natural language processing tasks yet remain vulnerable to adversarial
prompts, known as jailbreak attacks, carefully designed to elicit harmful
responses from LLMs. Traditional methods rely on manual heuristics, which
suffer from limited generalizability. While being automatic, optimization-based
attacks often produce unnatural jailbreak prompts that are easy to detect by
safety filters or require high computational overhead due to discrete token
optimization. Witnessing the limitations of existing jailbreak methods, we
introduce Generative Adversarial Suffix Prompter (GASP), a novel framework that
combines human-readable prompt generation with Latent Bayesian Optimization
(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP
leverages LBO to craft adversarial suffixes by efficiently exploring continuous
embedding spaces, gradually optimizing the model to improve attack efficacy
while balancing prompt coherence through a targeted iterative refinement
procedure. Our experiments show that GASP can generate natural jailbreak
prompts, significantly improving attack success rates, reducing training times,
and accelerating inference speed, thus making it an efficient and scalable
solution for red-teaming LLMs.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越能力，但仍易受经过精心设计、旨在诱发有害回复的对抗性提示（即越狱攻击）的影响。传统方法依赖人工启发式规则，其泛化能力有限。而基于优化的自动化攻击虽无需人工干预，却常生成不自然的越狱提示——这些提示易被安全过滤器识别，或由于离散令牌优化导致计算开销过高。针对现有越狱方法的局限性，我们提出生成对抗后缀提示器（GASP），该创新框架将人类可读提示生成与潜在贝叶斯优化（LBO）相结合，在完全黑盒环境下提升对抗后缀的创建效果。GASP利用LBO通过高效探索连续嵌入空间来构建对抗后缀，逐步优化模型以提升攻击效能，同时通过定向迭代精炼流程平衡提示的连贯性。实验表明，GASP能生成自然的越狱提示，显著提高攻击成功率，缩短训练时间并加速推理速度，从而为LLM红队测试提供了高效可扩展的解决方案。
