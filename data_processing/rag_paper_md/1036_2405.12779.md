# Transformer in Touch: A Survey

链接: http://arxiv.org/abs/2405.12779v1

原文摘要:
The Transformer model, initially achieving significant success in the field
of natural language processing, has recently shown great potential in the
application of tactile perception. This review aims to comprehensively outline
the application and development of Transformers in tactile technology. We first
introduce the two fundamental concepts behind the success of the Transformer:
the self-attention mechanism and large-scale pre-training. Then, we delve into
the application of Transformers in various tactile tasks, including but not
limited to object recognition, cross-modal generation, and object manipulation,
offering a concise summary of the core methodologies, performance benchmarks,
and design highlights. Finally, we suggest potential areas for further research
and future work, aiming to generate more interest within the community, tackle
existing challenges, and encourage the use of Transformer models in the tactile
field.

中文翻译:
Transformer模型最初在自然语言处理领域取得重大成功后，近年来在触觉感知应用中展现出巨大潜力。本文旨在全面概述Transformer在触觉技术中的应用与发展。我们首先阐释Transformer成功的两大核心基础：自注意力机制与大规模预训练策略。随后深入探讨Transformer在各类触觉任务中的应用，涵盖但不限于物体识别、跨模态生成与物体操控等领域，对其核心方法、性能基准与设计亮点进行凝练总结。最后，我们提出未来研究的潜在方向，以期激发学界更多关注，应对现存挑战，并推动Transformer模型在触觉领域的更广泛应用。

（翻译说明：采用学术论文摘要的规范表述方式，通过以下处理实现专业性与可读性的平衡：
1. 专业术语统一："self-attention mechanism"译为行业通用术语"自注意力机制"
2. 长句拆分：将原文复合句分解为符合中文表达习惯的短句结构
3. 概念显化："large-scale pre-training"增译为"大规模预训练策略"以明确技术属性
4. 动态对等："performance benchmarks"译为"性能基准"而非字面直译，保持专业语境
5. 逻辑衔接：使用"随后"、"最后"等连接词保持论证脉络清晰
6. 学术风格：采用"凝练总结"、"潜在方向"等符合学术文本特征的表述）
