# Progressive Document-level Text Simplification via Large Language Models

链接: http://arxiv.org/abs/2501.03857v1

原文摘要:
Research on text simplification has primarily focused on lexical and
sentence-level changes. Long document-level simplification (DS) is still
relatively unexplored. Large Language Models (LLMs), like ChatGPT, have
excelled in many natural language processing tasks. However, their performance
on DS tasks is unsatisfactory, as they often treat DS as merely document
summarization. For the DS task, the generated long sequences not only must
maintain consistency with the original document throughout, but complete
moderate simplification operations encompassing discourses, sentences, and
word-level simplifications. Human editors employ a hierarchical complexity
simplification strategy to simplify documents. This study delves into
simulating this strategy through the utilization of a multi-stage collaboration
using LLMs. We propose a progressive simplification method (ProgDS) by
hierarchically decomposing the task, including the discourse-level,
topic-level, and lexical-level simplification. Experimental results demonstrate
that ProgDS significantly outperforms existing smaller models or direct
prompting with LLMs, advancing the state-of-the-art in the document
simplification task.

中文翻译:
文本简化研究主要集中于词汇和句子层面的改写，长文档级简化（DS）仍是一个相对未被充分探索的领域。以ChatGPT为代表的大语言模型（LLMs）虽在众多自然语言处理任务中表现卓越，但其在DS任务中的表现却不尽如人意——这些模型往往将文档简化简单等同于文档摘要。DS任务要求生成的文本序列不仅需全程保持与原文的一致性，还需完成涵盖语篇、句子及词汇层面的适度简化操作。人类编辑通常采用层级式复杂度简化策略来处理文档，本研究通过大语言模型的多阶段协同机制模拟这一策略，提出渐进式简化方法（ProgDS）：通过任务分解实现语篇结构级、主题级和词汇级的层级简化。实验结果表明，ProgDS显著优于现有小规模模型或直接提示大语言模型的方法，将文档简化任务的性能提升至新高度。

（译文特点说明：
1. 专业术语准确处理："discourse-level"译为"语篇结构级"符合语言学规范
2. 长句拆分重构：将原文60词长段落合理切分为符合中文阅读习惯的短句群
3. 被动语态转化："is still relatively unexplored"译为主动式"仍是...未被充分探索的领域"
4. 概念显化处理："hierarchical complexity simplification strategy"增译为"层级式复杂度简化策略"
5. 技术表述统一："progressive simplification method"与"渐进式简化方法"形成术语闭环
6. 学术风格保持：使用"其""需""涵盖"等书面化表达，符合论文摘要文体特征）
