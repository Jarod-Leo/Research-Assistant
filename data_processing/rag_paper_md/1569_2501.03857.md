# Progressive Document-level Text Simplification via Large Language Models

链接: http://arxiv.org/abs/2501.03857v1

原文摘要:
Research on text simplification has primarily focused on lexical and
sentence-level changes. Long document-level simplification (DS) is still
relatively unexplored. Large Language Models (LLMs), like ChatGPT, have
excelled in many natural language processing tasks. However, their performance
on DS tasks is unsatisfactory, as they often treat DS as merely document
summarization. For the DS task, the generated long sequences not only must
maintain consistency with the original document throughout, but complete
moderate simplification operations encompassing discourses, sentences, and
word-level simplifications. Human editors employ a hierarchical complexity
simplification strategy to simplify documents. This study delves into
simulating this strategy through the utilization of a multi-stage collaboration
using LLMs. We propose a progressive simplification method (ProgDS) by
hierarchically decomposing the task, including the discourse-level,
topic-level, and lexical-level simplification. Experimental results demonstrate
that ProgDS significantly outperforms existing smaller models or direct
prompting with LLMs, advancing the state-of-the-art in the document
simplification task.

中文翻译:
文本简化研究主要集中于词汇和句子层面的改写，而长文档级简化（DS）仍是一个相对未被充分探索的领域。以ChatGPT为代表的大语言模型（LLMs）虽在众多自然语言处理任务中表现卓越，但在DS任务中的表现却不尽如人意——这些模型往往将文档简化简单等同于文档摘要。DS任务要求生成的文本不仅需全程保持与原文语义一致性，还需完成涵盖篇章结构、句子重组和词汇替换的多层次适度简化。人类编辑通常采用分层复杂度简化策略来处理文档，本研究通过大语言模型的多阶段协同机制模拟这一策略，提出渐进式简化方法（ProgDS）：将任务分解为篇章结构简化、主题级简化和词汇级简化三个层次逐步实施。实验结果表明，ProgDS显著优于现有小规模模型或直接使用LLMs提示的方法，推动了文档简化任务技术水平的进步。
