# ALPS: Improved Optimization for Highly Sparse One-Shot Pruning for Large Language Models

链接: http://arxiv.org/abs/2406.07831v1

原文摘要:
The impressive performance of Large Language Models (LLMs) across various
natural language processing tasks comes at the cost of vast computational
resources and storage requirements. One-shot pruning techniques offer a way to
alleviate these burdens by removing redundant weights without the need for
retraining. Yet, the massive scale of LLMs often forces current pruning
approaches to rely on heuristics instead of optimization-based techniques,
potentially resulting in suboptimal compression. In this paper, we introduce
ALPS, an optimization-based framework that tackles the pruning problem using
the operator splitting technique and a preconditioned conjugate gradient-based
post-processing step. Our approach incorporates novel techniques to accelerate
and theoretically guarantee convergence while leveraging vectorization and GPU
parallelism for efficiency. ALPS substantially outperforms state-of-the-art
methods in terms of the pruning objective and perplexity reduction,
particularly for highly sparse models. On the OPT-30B model with 70% sparsity,
ALPS achieves a 13% reduction in test perplexity on the WikiText dataset and a
19% improvement in zero-shot benchmark performance compared to existing
methods.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越性能，但其代价是巨大的计算资源消耗与存储需求。一次性剪枝技术通过移除冗余权重且无需重新训练，为缓解这一负担提供了解决方案。然而，LLMs的海量规模往往迫使现有剪枝方法依赖启发式策略而非基于优化的技术，这可能导致次优的压缩效果。本文提出ALPS框架——一种基于优化的解决方案，其运用算子分裂技术并结合基于预条件共轭梯度的后处理步骤来处理剪枝问题。我们的方法整合了创新技术以加速收敛并在理论上保证收敛性，同时利用向量化与GPU并行技术提升效率。在剪枝目标与困惑度降低方面，ALPS显著优于现有最优方法，尤其在高稀疏度模型中表现突出。对于稀疏度为70%的OPT-30B模型，ALPS在WikiText数据集上实现了测试困惑度降低13%，在零样本基准任务中相比现有方法性能提升19%。

（翻译说明：
1. 专业术语处理："one-shot pruning"译为"一次性剪枝"，"operator splitting"保留专业表述"算子分裂"，"preconditioned conjugate gradient"译为"预条件共轭梯度"
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如第一句拆分为性能表现与代价两个层次
3. 被动语态转换："are forced to"译为主动式"迫使...依赖"
4. 数据呈现：精确保留"70% sparsity"等关键数值及"13%/19%"性能提升数据
5. 技术概念显化："vectorization and GPU parallelism"译为"向量化与GPU并行技术"以明确技术内涵
6. 学术风格保持：使用"次优""整合""稀疏度"等符合学术论文表达的词汇）
