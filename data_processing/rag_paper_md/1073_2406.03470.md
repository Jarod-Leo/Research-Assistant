# SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN

链接: http://arxiv.org/abs/2406.03470v1

原文摘要:
Spiking neural network (SNN) has attracted great attention due to its
characteristic of high efficiency and accuracy. Currently, the ANN-to-SNN
conversion methods can obtain ANN on-par accuracy SNN with ultra-low latency (8
time-steps) in CNN structure on computer vision (CV) tasks. However, as
Transformer-based networks have achieved prevailing precision on both CV and
natural language processing (NLP), the Transformer-based SNNs are still
encounting the lower accuracy w.r.t the ANN counterparts. In this work, we
introduce a novel ANN-to-SNN conversion method called SpikeZIP-TF, where ANN
and SNN are exactly equivalent, thus incurring no accuracy degradation.
SpikeZIP-TF achieves 83.82% accuracy on CV dataset (ImageNet) and 93.79%
accuracy on NLP dataset (SST-2), which are higher than SOTA Transformer-based
SNNs. The code is available in GitHub:
https://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer

中文翻译:
脉冲神经网络（SNN）因其高效精准的特性备受关注。当前基于人工神经网络（ANN）到SNN的转换方法在计算机视觉任务中，已能通过CNN架构实现与ANN精度相当、且仅需超低延迟（8个时间步长）的SNN模型。然而，尽管基于Transformer的网络在计算机视觉和自然语言处理领域均展现出卓越精度，基于Transformer的SNN模型仍面临精度低于对应ANN的问题。本研究提出创新性转换方法SpikeZIP-TF，通过建立ANN与SNN的严格等效性实现零精度损失。该方法在计算机视觉数据集（ImageNet）上达到83.82%准确率，在自然语言处理数据集（SST-2）上获得93.79%准确率，性能超越当前最先进的基于Transformer的SNN模型。代码已开源：https://github.com/Intelligent-Computing-Research-Group/SpikeZIP_transformer

（注：根据学术翻译规范，对原文进行了以下处理：
1. 专业术语统一："ANN-to-SNN conversion"统一译为"ANN到SNN转换"
2. 技术表述优化："ultra-low latency (8 time-steps)"译为"超低延迟（8个时间步长）"
3. 被动语态转换："are still encountering"译为"仍面临"
4. 机构名称保留："GitHub"不翻译
5. 长句拆分：将原文复合句拆分为符合中文表达习惯的短句
6. 数据呈现标准化：准确率数值保留两位小数）
