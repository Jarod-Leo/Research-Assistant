# Few-Shot Optimized Framework for Hallucination Detection in Resource-Limited NLP Systems

链接: http://arxiv.org/abs/2501.16616v1

原文摘要:
Hallucination detection in text generation remains an ongoing struggle for
natural language processing (NLP) systems, frequently resulting in unreliable
outputs in applications such as machine translation and definition modeling.
Existing methods struggle with data scarcity and the limitations of unlabeled
datasets, as highlighted by the SHROOM shared task at SemEval-2024. In this
work, we propose a novel framework to address these challenges, introducing
DeepSeek Few-shot optimization to enhance weak label generation through
iterative prompt engineering. We achieved high-quality annotations that
considerably enhanced the performance of downstream models by restructuring
data to align with instruct generative models. We further fine-tuned the
Mistral-7B-Instruct-v0.3 model on these optimized annotations, enabling it to
accurately detect hallucinations in resource-limited settings. Combining this
fine-tuned model with ensemble learning strategies, our approach achieved 85.5%
accuracy on the test set, setting a new benchmark for the SHROOM task. This
study demonstrates the effectiveness of data restructuring, few-shot
optimization, and fine-tuning in building scalable and robust hallucination
detection frameworks for resource-constrained NLP systems.

中文翻译:
文本生成中的幻觉检测始终是自然语言处理（NLP）系统面临的挑战，常导致机器翻译和定义建模等应用输出不可靠结果。如SemEval-2024的SHROOM共享任务所示，现有方法受限于数据稀缺和未标注数据集的局限性。本研究提出创新框架应对这些挑战，通过引入DeepSeek少样本优化技术，借助迭代式提示工程增强弱标签生成。通过重构数据以适配指令生成模型，我们获得了显著提升下游模型性能的高质量标注。进一步基于这些优化标注微调Mistral-7B-Instruct-v0.3模型，使其能在资源受限环境下精准检测幻觉。结合集成学习策略，该方法在测试集上达到85.5%准确率，创下SHROOM任务新标杆。本研究表明数据重构、少样本优化与微调技术能有效构建适用于资源受限NLP系统的可扩展、鲁棒性幻觉检测框架。
