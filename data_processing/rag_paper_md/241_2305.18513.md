# SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using Training Dynamics

链接: http://arxiv.org/abs/2305.18513v1

原文摘要:
Transformer-based models, such as BERT and ViT, have achieved
state-of-the-art results across different natural language processing (NLP) and
computer vision (CV) tasks. However, these models are extremely memory
intensive during their fine-tuning process, making them difficult to deploy on
GPUs with limited memory resources. To address this issue, we introduce a new
tool called SlimFit that reduces the memory requirements of these models by
dynamically analyzing their training dynamics and freezing less-contributory
layers during fine-tuning. The layers to freeze are chosen using a runtime
inter-layer scheduling algorithm. SlimFit adopts quantization and pruning for
particular layers to balance the load of dynamic activations and to minimize
the memory footprint of static activations, where static activations refer to
those that cannot be discarded regardless of freezing. This allows SlimFit to
freeze up to 95% of layers and reduce the overall on-device GPU memory usage of
transformer-based models such as ViT and BERT by an average of 2.2x, across
different NLP and CV benchmarks/datasets such as GLUE, SQuAD 2.0, CIFAR-10,
CIFAR-100 and ImageNet with an average degradation of 0.2% in accuracy. For
such NLP and CV tasks, SlimFit can reduce up to 3.1x the total on-device memory
usage with an accuracy degradation of only up to 0.4%. As a result, while
fine-tuning of ViT on ImageNet and BERT on SQuAD 2.0 with a batch size of 128
requires 3 and 2 32GB GPUs respectively, SlimFit enables their fine-tuning on a
single 32GB GPU without any significant accuracy degradation.

中文翻译:
基于Transformer的模型（如BERT和ViT）在不同自然语言处理（NLP）和计算机视觉（CV）任务中已取得最先进的性能表现。然而这些模型在微调过程中存在极高的内存消耗，导致其难以在显存资源有限的GPU上部署。为解决这一问题，我们推出名为SlimFit的新型工具，通过动态分析模型训练状态并在微调时冻结贡献度较低的层，显著降低内存需求。该工具采用运行时层间调度算法选择待冻结层，同时对特定层实施量化和剪枝处理，以平衡动态激活的负载并最小化静态激活（指无论是否冻结都必须保留的激活值）的内存占用。实验表明，在GLUE、SQuAD 2.0、CIFAR-10、CIFAR-100及ImageNet等NLP与CV基准数据集上，SlimFit可冻结高达95%的模型层，使ViT和BERT等Transformer模型的设备端GPU显存占用平均降低2.2倍，且平均精度损失仅0.2%。对于部分NLP和CV任务，该工具最多可减少3.1倍设备端总内存使用，而精度损失不超过0.4%。最终，当ImageNet上的ViT微调和SQuAD 2.0上的BERT微调（批处理规模128）原本分别需要3块和2块32GB GPU时，SlimFit能使其在单块32GB GPU上完成微调，且不会造成显著精度下降。
