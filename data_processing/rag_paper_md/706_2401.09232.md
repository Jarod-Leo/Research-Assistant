# Dynamic Relation Transformer for Contextual Text Block Detection

链接: http://arxiv.org/abs/2401.09232v1

原文摘要:
Contextual Text Block Detection (CTBD) is the task of identifying coherent
text blocks within the complexity of natural scenes. Previous methodologies
have treated CTBD as either a visual relation extraction challenge within
computer vision or as a sequence modeling problem from the perspective of
natural language processing. We introduce a new framework that frames CTBD as a
graph generation problem. This methodology consists of two essential
procedures: identifying individual text units as graph nodes and discerning the
sequential reading order relationships among these units as graph edges.
Leveraging the cutting-edge capabilities of DQ-DETR for node detection, our
framework innovates further by integrating a novel mechanism, a Dynamic
Relation Transformer (DRFormer), dedicated to edge generation. DRFormer
incorporates a dual interactive transformer decoder that deftly manages a
dynamic graph structure refinement process. Through this iterative process, the
model systematically enhances the graph's fidelity, ultimately resulting in
improved precision in detecting contextual text blocks. Comprehensive
experimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Context
datasets substantiate that our method achieves state-of-the-art results,
underscoring the effectiveness and potential of our graph generation framework
in advancing the field of CTBD.

中文翻译:
上下文文本块检测（CTBD）旨在自然场景的复杂环境中识别具有连贯语义的文本区域。现有方法或将CTBD视为计算机视觉领域的视觉关系抽取任务，或从自然语言处理角度将其建模为序列预测问题。我们提出了一种创新框架，将CTBD重新定义为图结构生成任务。该框架包含两个核心环节：首先将独立文本单元识别为图节点，继而判定这些单元间的阅读顺序关系作为图边。基于DQ-DETR先进的节点检测能力，我们进一步设计了动态关系变换器（DRFormer）这一专门用于边生成的创新机制。DRFormer采用双交互式变换器解码器架构，通过动态图结构优化过程实现迭代式精度提升。在SCUT-CTW-Context和ReCTS-Context数据集上的全面实验表明，本方法取得了最先进的性能表现，验证了图生成框架在推动CTBD领域发展方面的有效性和潜力。
