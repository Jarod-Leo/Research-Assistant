# Black-Box Analysis: GPTs Across Time in Legal Textual Entailment Task

链接: http://arxiv.org/abs/2309.05501v1

原文摘要:
The evolution of Generative Pre-trained Transformer (GPT) models has led to
significant advancements in various natural language processing applications,
particularly in legal textual entailment. We present an analysis of GPT-3.5
(ChatGPT) and GPT-4 performances on COLIEE Task 4 dataset, a prominent
benchmark in this domain. The study encompasses data from Heisei 18 (2006) to
Reiwa 3 (2021), exploring the models' abilities to discern entailment
relationships within Japanese statute law across different periods. Our
preliminary experimental results unveil intriguing insights into the models'
strengths and weaknesses in handling legal textual entailment tasks, as well as
the patterns observed in model performance. In the context of proprietary
models with undisclosed architectures and weights, black-box analysis becomes
crucial for evaluating their capabilities. We discuss the influence of training
data distribution and the implications on the models' generalizability. This
analysis serves as a foundation for future research, aiming to optimize
GPT-based models and enable their successful adoption in legal information
extraction and entailment applications.

中文翻译:
生成式预训练变换器（GPT）模型的演进推动了各类自然语言处理应用的显著进步，尤其在法律文本蕴含任务领域。本文针对该领域权威基准COLIEE任务4数据集，分析了GPT-3.5（ChatGPT）与GPT-4的表现。研究涵盖平成18年（2006）至令和3年（2021）期间数据，探究模型在不同时期日本成文法中识别蕴含关系的能力。初步实验结果揭示了模型处理法律文本蕴含任务的优势与局限，以及性能表现中呈现的规律模式。鉴于专有模型的架构与权重未公开，黑箱分析成为评估其能力的关键方法。我们探讨了训练数据分布的影响及其对模型泛化能力的启示，该分析为未来研究奠定基础，旨在优化基于GPT的模型并推动其在法律信息抽取与蕴含应用中的成功落地。
