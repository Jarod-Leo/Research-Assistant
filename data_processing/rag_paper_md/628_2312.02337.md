# Measuring Distributional Shifts in Text: The Advantage of Language Model-Based Embeddings

链接: http://arxiv.org/abs/2312.02337v1

原文摘要:
An essential part of monitoring machine learning models in production is
measuring input and output data drift. In this paper, we present a system for
measuring distributional shifts in natural language data and highlight and
investigate the potential advantage of using large language models (LLMs) for
this problem. Recent advancements in LLMs and their successful adoption in
different domains indicate their effectiveness in capturing semantic
relationships for solving various natural language processing problems. The
power of LLMs comes largely from the encodings (embeddings) generated in the
hidden layers of the corresponding neural network. First we propose a
clustering-based algorithm for measuring distributional shifts in text data by
exploiting such embeddings. Then we study the effectiveness of our approach
when applied to text embeddings generated by both LLMs and classical embedding
algorithms. Our experiments show that general-purpose LLM-based embeddings
provide a high sensitivity to data drift compared to other embedding methods.
We propose drift sensitivity as an important evaluation metric to consider when
comparing language models. Finally, we present insights and lessons learned
from deploying our framework as part of the Fiddler ML Monitoring platform over
a period of 18 months.

中文翻译:
监测生产环境中机器学习模型的关键环节之一，是测量输入与输出数据的漂移情况。本文提出一种用于检测自然语言数据分布偏移的系统，重点探讨并验证了利用大语言模型（LLM）解决该问题的潜在优势。LLM技术的最新进展及其在多领域的成功应用，表明其在捕捉语义关系以解决各类自然语言处理任务方面具有卓越效能。LLM的核心能力主要源自神经网络隐藏层生成的编码（嵌入向量）。我们首先提出一种基于聚类的算法，通过利用此类嵌入向量来量化文本数据的分布偏移；随后系统比较了LLM生成嵌入与传统嵌入算法在方法有效性上的差异。实验结果表明，相较于其他嵌入方法，基于通用LLM的嵌入对数据漂移具有更高的敏感度。我们提出将漂移敏感度作为语言模型比较的重要评估指标。最后，本文分享了将本框架集成至Fiddler机器学习监测平台18个月以来所获得的实践洞见和经验总结。
