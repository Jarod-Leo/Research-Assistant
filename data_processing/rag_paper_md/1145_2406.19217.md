# Think Step by Step: Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos

链接: http://arxiv.org/abs/2406.19217v1

原文摘要:
Despite significant advancements in robotic systems and surgical data
science, ensuring safe and optimal execution in robot-assisted minimally
invasive surgery (RMIS) remains a complex challenge. Current surgical error
detection methods involve two parts: identifying surgical gestures and then
detecting errors within each gesture clip. These methods seldom consider the
rich contextual and semantic information inherent in surgical videos, limiting
their performance due to reliance on accurate gesture identification. Motivated
by the chain-of-thought prompting in natural language processing, this letter
presents a novel and real-time end-to-end error detection framework,
Chain-of-Thought (COG) prompting, leveraging contextual information from
surgical videos. This encompasses two reasoning modules designed to mimic the
decision-making processes of expert surgeons. Concretely, we first design a
Gestural-Visual Reasoning module, which utilizes transformer and attention
architectures for gesture prompting, while the second, a Multi-Scale Temporal
Reasoning module, employs a multi-stage temporal convolutional network with
both slow and fast paths for temporal information extraction. We extensively
validate our method on the public benchmark RMIS dataset JIGSAWS. Our method
encapsulates the reasoning processes inherent to surgical activities enabling
it to outperform the state-of-the-art by 4.6% in F1 score, 4.6% in Accuracy,
and 5.9% in Jaccard index while processing each frame in 6.69 milliseconds on
average, demonstrating the great potential of our approach in enhancing the
safety and efficacy of RMIS procedures and surgical education. The code will be
available.

中文翻译:
尽管机器人系统和外科数据科学取得了显著进展，但在机器人辅助微创手术（RMIS）中确保安全且最优的执行仍是一项复杂挑战。现有手术错误检测方法包含两个环节：先识别手术动作，再检测每个动作片段中的错误。这些方法很少考虑手术视频中丰富的上下文与语义信息，因依赖精确的动作识别而限制了性能。受自然语言处理中思维链提示的启发，本文提出了一种新颖的实时端到端错误检测框架——思维链（COG）提示，充分利用手术视频的上下文信息。该框架包含两个模拟外科专家决策过程的推理模块：首先设计基于Transformer和注意力架构的"动作-视觉推理模块"实现动作提示；其次构建"多尺度时序推理模块"，采用包含快慢路径的多阶段时序卷积网络提取时序信息。我们在公开基准数据集JIGSAWS上进行了全面验证，该方法通过封装手术活动固有的推理过程，在F1分数、准确率和Jaccard指数上分别以4.6%、4.6%和5.9%的优势超越现有最优方法，同时单帧处理仅需6.69毫秒，展现了提升RMIS手术安全性和教学效能的巨大潜力。相关代码将公开。
