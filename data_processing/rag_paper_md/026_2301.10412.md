# BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing

链接: http://arxiv.org/abs/2301.10412v1

原文摘要:
Deep neural networks (DNNs) and natural language processing (NLP) systems
have developed rapidly and have been widely used in various real-world fields.
However, they have been shown to be vulnerable to backdoor attacks.
Specifically, the adversary injects a backdoor into the model during the
training phase, so that input samples with backdoor triggers are classified as
the target class. Some attacks have achieved high attack success rates on the
pre-trained language models (LMs), but there have yet to be effective defense
methods. In this work, we propose a defense method based on deep model mutation
testing. Our main justification is that backdoor samples are much more robust
than clean samples if we impose random mutations on the LMs and that backdoors
are generalizable. We first confirm the effectiveness of model mutation testing
in detecting backdoor samples and select the most appropriate mutation
operators. We then systematically defend against three extensively studied
backdoor attack levels (i.e., char-level, word-level, and sentence-level) by
detecting backdoor samples. We also make the first attempt to defend against
the latest style-level backdoor attacks. We evaluate our approach on three
benchmark datasets (i.e., IMDB, Yelp, and AG news) and three style transfer
datasets (i.e., SST-2, Hate-speech, and AG news). The extensive experimental
results demonstrate that our approach can detect backdoor samples more
efficiently and accurately than the three state-of-the-art defense approaches.

中文翻译:
深度神经网络（DNNs）与自然语言处理（NLP）系统发展迅猛，已广泛应用于现实世界的各个领域。然而研究表明，这类系统易受后门攻击威胁。具体而言，攻击者在模型训练阶段植入后门，使得含有触发器的输入样本被误分类为目标类别。尽管部分攻击方法在预训练语言模型（LMs）上已实现高攻击成功率，但迄今仍缺乏有效的防御手段。本研究提出一种基于深度模型变异测试的防御方法，其核心依据是：当对语言模型施加随机变异时，后门样本相比干净样本表现出更强的鲁棒性，且后门具有泛化特性。我们首先验证了模型变异测试在检测后门样本方面的有效性，并筛选出最优变异算子；随后通过后门样本检测，系统防御了三种广泛研究的攻击层级（字符级、词级和句子级）；同时首次尝试防御最新出现的风格级后门攻击。我们在三个基准数据集（IMDB、Yelp和AG新闻）及三个风格迁移数据集（SST-2、仇恨言论和AG新闻）上评估本方法。大量实验结果表明，相较于三种最先进的防御方案，我们的方法能以更高效率和准确率检测后门样本。

（翻译说明：
1. 专业术语处理：采用"深度神经网络/自然语言处理/预训练语言模型"等学界通用译法
2. 长句拆分：将英文复合句按中文表达习惯分解为多个短句，如将"specifically..."从句独立成句
3. 被动语态转换："have been shown"等被动结构转为主动式"研究表明"
4. 概念显化："generalizable"译为"泛化特性"以突出其技术内涵
5. 数据名称保留：数据集名称保持英文缩写形式（如SST-2）符合学术惯例
6. 逻辑连接优化：通过"其核心依据是/随后/同时"等衔接词保持论证连贯性
7. 程度副词强化："extensively studied"译为"广泛研究"以准确传达原文强调意味）
