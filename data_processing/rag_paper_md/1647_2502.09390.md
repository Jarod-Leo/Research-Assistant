# SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models

链接: http://arxiv.org/abs/2502.09390v1

原文摘要:
In the rapidly evolving field of Natural Language Processing, Large Language
Models (LLMs) are tasked with increasingly complex reasoning challenges.
Traditional methods like chain-of-thought prompting have shown promise but
often fall short in fully leveraging a model's reasoning capabilities. This
paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a
novel prompting technique designed to improve reasoning through a
self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts
models to generate and resolve multiple auxiliary questions before tackling the
main query, promoting a more thorough exploration of various aspects of a
topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models
across multiple question-answering datasets, demonstrate that SQuARE
significantly surpasses traditional CoT prompts and existing
rephrase-and-respond methods. By systematically decomposing queries, SQuARE
advances LLM capabilities in reasoning tasks. The code is publicly available at
https://github.com/IntelLabs/RAG-FiT/tree/square.

中文翻译:
在自然语言处理这一快速发展的领域中，大型语言模型（LLMs）正面临日益复杂的推理挑战。传统方法如思维链提示（chain-of-thought prompting）虽展现出潜力，但往往难以充分发挥模型的推理能力。本文提出SQuARE（序列问答推理引擎），这是一种基于自我审问范式的新型提示技术，旨在提升推理性能。该技术在思维链框架基础上，引导模型在处理主问题前先生成并解决多个辅助性问题，从而推动对主题各维度的深入探索。我们基于Llama 3和GPT-4o模型在多个问答数据集上开展的广泛评估表明，SQuARE显著优于传统思维链提示及现有重述应答方法。通过系统化的问题分解，SQuARE有效提升了大型语言模型在推理任务中的表现。相关代码已开源：https://github.com/IntelLabs/RAG-FiT/tree/square。

（注：根据学术论文摘要的文体特征，翻译时采取了以下处理：
1. 专业术语采用学界通用译法（如"prompting technique"译为"提示技术"）
2. 机构名称保留英文缩写（LLMs）以符合中文文献惯例
3. 长句拆分重组，如将"promoting a more thorough..."独立译为结果状语
4. 被动语态转换为主动表述（如"are tasked with"译为"正面临"）
5. 技术名称SQuARE保留英文并补充中文全称，符合计算机领域术语处理规范）
