# $\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models

链接: http://arxiv.org/abs/2403.16432v1

原文摘要:
Prompt-based learning is a new language model training paradigm that adapts
the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes
the performance benchmarks across various natural language processing (NLP)
tasks. Instead of using a fixed prompt template to fine-tune the model, some
research demonstrates the effectiveness of searching for the prompt via
optimization. Such prompt optimization process of prompt-based learning on PLMs
also gives insight into generating adversarial prompts to mislead the model,
raising concerns about the adversarial vulnerability of this paradigm. Recent
studies have shown that universal adversarial triggers (UATs) can be generated
to alter not only the predictions of the target PLMs but also the prediction of
corresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based
learning paradigm. However, UATs found in previous works are often unreadable
tokens or characters and can be easily distinguished from natural texts with
adaptive defenses. In this work, we consider the naturalness of the UATs and
develop $\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs
by a gradient-based beam search algorithm that not only effectively attacks the
target PLMs and PFMs but also maintains the naturalness among the trigger
tokens. Extensive results demonstrate the effectiveness of
$\textit{LinkPrompt}$, as well as the transferability of UATs generated by
$\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and
API-accessed LLM GPT-3.5-turbo. The resource is available at
$\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$.

中文翻译:
基于提示的学习是一种新型语言模型训练范式，它通过将预训练语言模型（PLMs）适配至下游任务，显著提升了各类自然语言处理（NLP）任务的性能基准。不同于使用固定提示模板进行模型微调，研究表明通过优化搜索提示能有效提升模型表现。然而，这种在PLMs上进行提示优化的过程也揭示了生成对抗性提示以误导模型的可能性，引发了学界对该范式对抗脆弱性的关注。最新研究表明，通用对抗触发器（UATs）不仅能改变目标PLMs的预测结果，还能在基于提示的学习范式下影响相应提示微调模型（PFMs）的预测。但现有工作中发现的UATs往往由不可读的符号或字符构成，容易被自适应防御机制从自然文本中识别。本研究聚焦UATs的自然性，提出梯度引导束搜索算法$\textit{LinkPrompt}$来生成对抗触发器——该算法在有效攻击目标PLMs和PFMs的同时，能保持触发标记的自然语言特性。大量实验证实了$\textit{LinkPrompt}$的有效性，其生成的UATs对开源大语言模型Llama2和API访问型模型GPT-3.5-turbo均展现出强迁移性。相关资源已发布于$\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$。  

（注：根据学术规范要求，技术术语保持英文缩写形式；超链接采用学术论文常用的\href格式；算法名称保留原文斜体格式；长句按中文表达习惯拆分为符合逻辑的短句；被动语态转换为主动表述；专业表述如"adversarial vulnerability"译为"对抗脆弱性"以符合领域术语）
