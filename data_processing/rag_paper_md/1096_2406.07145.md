# Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models

链接: http://arxiv.org/abs/2406.07145v1

原文摘要:
In large deep neural networks that seem to perform surprisingly well on many
tasks, we also observe a few failures related to accuracy, social biases, and
alignment with human values, among others. Therefore, before deploying these
models, it is crucial to characterize this failure landscape for engineers to
debug and legislative bodies to audit models. Nevertheless, it is infeasible to
exhaustively test for all possible combinations of factors that could lead to a
model's failure. In this paper, we introduce a post-hoc method that utilizes
\emph{deep reinforcement learning} to explore and construct the landscape of
failure modes in pre-trained discriminative and generative models. With the aid
of limited human feedback, we then demonstrate how to restructure the failure
landscape to be more desirable by moving away from the discovered failure
modes. We empirically show the effectiveness of the proposed method across
common Computer Vision, Natural Language Processing, and Vision-Language tasks.

中文翻译:
在那些看似在众多任务中表现卓越的大型深度神经网络中，我们也观察到一些与准确性、社会偏见及人类价值观对齐相关的失败案例。因此，在部署这些模型之前，对故障模式进行全面刻画至关重要，这既有助于工程师调试，也为立法机构审核模型提供依据。然而，穷尽所有可能导致模型失效的因素组合进行测试是不现实的。本文提出一种事后分析方法，利用**深度强化学习**技术探索并构建预训练判别式与生成式模型的故障模式图谱。通过结合有限的人工反馈，我们进一步展示了如何通过远离已发现的故障模式来重构更理想的故障图谱。实验部分验证了该方法在计算机视觉、自然语言处理及视觉-语言跨模态任务中的有效性。
