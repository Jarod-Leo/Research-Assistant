# Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese

链接: http://arxiv.org/abs/2309.04175v1

原文摘要:
Large Language Models (LLMs) have demonstrated remarkable success in diverse
natural language processing (NLP) tasks in general domains. However, LLMs
sometimes generate responses with the hallucination about medical facts due to
limited domain knowledge. Such shortcomings pose potential risks in the
utilization of LLMs within medical contexts. To address this challenge, we
propose knowledge-tuning, which leverages structured medical knowledge bases
for the LLMs to grasp domain knowledge efficiently and facilitate reliable
response generation. We also release cMedKnowQA, a Chinese medical knowledge
question-answering dataset constructed from medical knowledge bases to assess
the medical knowledge proficiency of LLMs. Experimental results show that the
LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of
accuracy in response generation compared with vanilla instruction-tuning and
offer a new reliable way for the domain adaptation of LLMs.

中文翻译:
大型语言模型（LLMs）在通用领域的多样化自然语言处理（NLP）任务中已展现出卓越成效。然而，由于领域知识储备有限，LLMs在医疗场景下可能生成包含事实性幻觉的回应，这类缺陷为其在医学领域的应用埋下了潜在风险。为应对这一挑战，本研究提出知识微调方法——通过结构化医学知识库赋能LLMs高效掌握领域知识，从而促进可靠回答的生成。我们同步发布中文医疗知识问答数据集cMedKnowQA，该数据集基于医学知识库构建，专门用于评估LLMs的医学知识掌握程度。实验结果表明：相较于基础指令微调，采用cMedKnowQA进行知识微调的LLMs能显著提升回答准确率，为LLMs的领域适配提供了新的可靠路径。
