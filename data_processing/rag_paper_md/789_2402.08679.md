# COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability

链接: http://arxiv.org/abs/2402.08679v1

原文摘要:
Jailbreaks on large language models (LLMs) have recently received increasing
attention. For a comprehensive assessment of LLM safety, it is essential to
consider jailbreaks with diverse attributes, such as contextual coherence and
sentiment/stylistic variations, and hence it is beneficial to study
controllable jailbreaking, i.e. how to enforce control on LLM attacks. In this
paper, we formally formulate the controllable attack generation problem, and
build a novel connection between this problem and controllable text generation,
a well-explored topic of natural language processing. Based on this connection,
we adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a
state-of-the-art, highly efficient algorithm in controllable text generation,
and introduce the COLD-Attack framework which unifies and automates the search
of adversarial LLM attacks under a variety of control requirements such as
fluency, stealthiness, sentiment, and left-right-coherence. The controllability
enabled by COLD-Attack leads to diverse new jailbreak scenarios which not only
cover the standard setting of generating fluent (suffix) attack with
continuation constraint, but also allow us to address new controllable attack
settings such as revising a user query adversarially with paraphrasing
constraint, and inserting stealthy attacks in context with position constraint.
Our extensive experiments on various LLMs (Llama-2, Mistral, Vicuna, Guanaco,
GPT-3.5, and GPT-4) show COLD-Attack's broad applicability, strong
controllability, high success rate, and attack transferability. Our code is
available at https://github.com/Yu-Fangxu/COLD-Attack.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）的越狱攻击近期受到日益关注。为全面评估LLM安全性，需考虑具有多样化属性的越狱攻击，例如上下文连贯性和情感/风格变异，因此研究可控越狱（即如何对LLM攻击实施控制）具有重要意义。本文首次形式化定义了可控攻击生成问题，并建立了该问题与自然语言处理中深入研究过的可控文本生成领域的新联系。基于此联系，我们改进了基于能量的朗之万动力学约束解码（COLD）这一当前最先进的高效可控文本生成算法，提出COLD-Attack框架——该框架能统一自动化地搜索满足多种控制要求（如流畅性、隐蔽性、情感倾向和左右连贯性）的对抗性LLM攻击。COLD-Attack提供的可控性催生了多样化的新型越狱场景：不仅涵盖生成具有延续性约束的流畅（后缀）攻击的标准设定，还能处理新的可控攻击场景，例如通过改写约束对用户查询进行对抗性修订，以及通过位置约束在上下文中插入隐蔽攻击。我们在多种LLM（Llama-2、Mistral、Vicuna、Guanaco、GPT-3.5和GPT-4）上的大量实验表明，COLD-Attack具有广泛适用性、强可控性、高成功率及优秀的攻击可迁移性。代码已开源：https://github.com/Yu-Fangxu/COLD-Attack。

（翻译严格遵循以下原则：
1. 专业术语准确统一："jailbreaks"译为"越狱攻击"，"Energy-based Constrained Decoding"保留专业缩写并补充全称
2. 被动语态转化："have recently received"转为主动态"受到"
3. 长句拆分：将原文复合句按中文习惯分解为多个短句
4. 逻辑显化：通过破折号和冒号明确技术方案的层次关系
5. 学术规范：保留所有技术术语、模型名称和算法名称的英文原名
6. 流畅性：使用"催生"、"涵盖"等学术动词保持专业语体）
