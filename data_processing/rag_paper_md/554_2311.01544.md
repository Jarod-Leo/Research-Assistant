# Divergent Token Metrics: Measuring degradation to prune away LLM components -- and optimize quantization

链接: http://arxiv.org/abs/2311.01544v1

原文摘要:
Large Language Models (LLMs) have reshaped natural language processing with
their impressive capabilities. However, their ever-increasing size has raised
concerns about their effective deployment and the need for LLM compression.
This study introduces the Divergent Token Metrics (DTMs), a novel approach to
assessing compressed LLMs, addressing the limitations of traditional perplexity
or accuracy measures that fail to accurately reflect text generation quality.
DTMs measure token divergences that allow deeper insights into the subtleties
of model compression, in particular, when evaluating components' impacts
individually. Utilizing the First Divergent Token Metric (FDTM) in model
sparsification reveals that 25% of all attention components can be pruned
beyond 90% on the Llama-2 model family, still keeping SOTA performance. For
quantization, FDTM suggests that more than 80% of parameters can be naively
transformed to int8 without special outlier management. These evaluations
indicate the necessity of choosing appropriate compressions for parameters
individually -- and that FDTM can identify those -- while standard metrics
result in deteriorated outcomes.

中文翻译:
大型语言模型（LLMs）凭借其卓越能力重塑了自然语言处理领域。然而，其不断膨胀的规模引发了关于有效部署及模型压缩需求的担忧。本研究提出发散词元度量（DTMs）这一创新评估方法，解决了传统困惑度或准确率指标无法真实反映文本生成质量的局限。DTMs通过测量词元发散程度，能深入洞察模型压缩的微妙影响，尤其在单独评估组件作用时表现突出。

应用首词元发散度量（FDTM）对Llama-2系列模型进行稀疏化实验表明：25%的注意力组件可修剪超过90%仍保持顶尖性能。在量化方面，FDTM显示超过80%参数无需特殊异常值处理即可直接转为int8格式。这些评估证实了针对不同参数选择特定压缩方式的必要性——而FDTM能精准识别这些参数——传统度量标准则会导致性能劣化。

（注：根据学术规范，采用"词元"对应"token"的术语翻译；"SOTA"保留英文缩写形式；技术术语如"int8"保持原格式；复杂长句按中文习惯拆分为短句；被动语态转换为主动表述；专业表述如"稀疏化/量化"等确保准确性）
