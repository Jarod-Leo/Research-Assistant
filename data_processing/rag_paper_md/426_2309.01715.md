# Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction

链接: http://arxiv.org/abs/2309.01715v1

原文摘要:
Taxonomies represent hierarchical relations between entities, frequently
applied in various software modeling and natural language processing (NLP)
activities. They are typically subject to a set of structural constraints
restricting their content. However, manual taxonomy construction can be
time-consuming, incomplete, and costly to maintain. Recent studies of large
language models (LLMs) have demonstrated that appropriate user inputs (called
prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks
without explicit (re-)training. However, existing approaches for automated
taxonomy construction typically involve fine-tuning a language model by
adjusting model parameters. In this paper, we present a general framework for
taxonomy construction that takes into account structural constraints. We
subsequently conduct a systematic comparison between the prompting and
fine-tuning approaches performed on a hypernym taxonomy and a novel computer
science taxonomy dataset. Our result reveals the following: (1) Even without
explicit training on the dataset, the prompting approach outperforms
fine-tuning-based approaches. Moreover, the performance gap between prompting
and fine-tuning widens when the training dataset is small. However, (2)
taxonomies generated by the fine-tuning approach can be easily post-processed
to satisfy all the constraints, whereas handling violations of the taxonomies
produced by the prompting approach can be challenging. These evaluation
findings provide guidance on selecting the appropriate method for taxonomy
construction and highlight potential enhancements for both approaches.

中文翻译:
分类体系展现了实体间的层级关系，广泛应用于各类软件建模与自然语言处理任务中。这类体系通常受限于一系列约束其内容的结构化规则。然而人工构建分类体系往往耗时费力、难以完备且维护成本高昂。近期针对大语言模型（如GPT-3）的研究表明，通过适当的用户输入（即提示工程）即可有效引导模型完成多种自然语言处理任务，而无需显式的（重新）训练。但现有自动化分类体系构建方法多依赖于调整模型参数的微调技术。本文提出一个兼顾结构化约束的通用分类体系构建框架，并基于上位词分类体系与新颖的计算机科学分类数据集，对提示工程与微调方法进行了系统性对比研究。实验结果表明：（1）即便未对目标数据集进行显式训练，提示工程方法的性能仍优于基于微调的方法，且当训练数据规模较小时，二者性能差距更为显著；（2）微调方法生成的分类体系易于通过后处理满足所有约束条件，而提示工程产生的体系若违反约束规则则较难修正。这些评估结论为分类体系构建方法的选择提供了指导依据，同时揭示了两种方法潜在的改进方向。
