# Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study

链接: http://arxiv.org/abs/2405.02937v1

原文摘要:
Natural Language Inference (NLI) is a cornerstone of Natural Language
Processing (NLP), providing insights into the entailment relationships between
text pairings. It is a critical component of Natural Language Understanding
(NLU), demonstrating the ability to extract information from spoken or written
interactions. NLI is mainly concerned with determining the entailment
relationship between two statements, known as the premise and hypothesis. When
the premise logically implies the hypothesis, the pair is labeled "entailment".
If the hypothesis contradicts the premise, the pair receives the
"contradiction" label. When there is insufficient evidence to establish a
connection, the pair is described as "neutral". Despite the success of Large
Language Models (LLMs) in various tasks, their effectiveness in NLI remains
constrained by issues like low-resource domain accuracy, model overconfidence,
and difficulty in capturing human judgment disagreements. This study addresses
the underexplored area of evaluating LLMs in low-resourced languages such as
Bengali. Through a comprehensive evaluation, we assess the performance of
prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,
focusing on natural language inference. Utilizing the XNLI dataset, we conduct
zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and
Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,
mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve
comparable or superior performance to fine-tuned SOTA models in few-shot
scenarios, further research is necessary to enhance our understanding of LLMs
in languages with modest resources like Bengali. This study underscores the
importance of continued efforts in exploring LLM capabilities across diverse
linguistic contexts.

中文翻译:
自然语言推理（NLI）作为自然语言处理（NLP）的基石，通过揭示文本对之间的蕴涵关系，为自然语言理解（NLU）提供了关键支撑，展现了从口语或书面交互中提取信息的能力。该任务主要判定前提与假设两个陈述间的逻辑关系：若前提能推导出假设则标记为"蕴涵"；若二者矛盾则标注为"矛盾"；当缺乏充分关联证据时定义为"中性"。尽管大语言模型（LLMs）在多领域表现卓越，但其在NLI任务中的效能仍受限于低资源领域准确率、模型过度自信及难以捕捉人类判断分歧等问题。本研究聚焦孟加拉语等低资源语言环境下LLMs评估这一探索不足的领域，通过系统评测对比了GPT-3.5 Turbo、Gemini 1.5 Pro等LLMs与BanglaBERT、Bangla BERT Base、DistilBERT、mBERT、sahajBERT等前沿模型在XNLI数据集上的零样本与小样本表现。实验表明，在小样本场景下LLMs可达到甚至超越精调SOTA模型的性能，但针对孟加拉语等中等资源语言，仍需进一步研究以深化对LLMs的理解。本成果强调了持续探索LLMs跨语言能力的重要性。
