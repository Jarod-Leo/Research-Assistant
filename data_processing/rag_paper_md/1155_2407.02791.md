# Model-Enhanced LLM-Driven VUI Testing of VPA Apps

链接: http://arxiv.org/abs/2407.02791v1

原文摘要:
The flourishing ecosystem centered around voice personal assistants (VPA),
such as Amazon Alexa, has led to the booming of VPA apps. The largest app
market Amazon skills store, for example, hosts over 200,000 apps. Despite their
popularity, the open nature of app release and the easy accessibility of apps
also raise significant concerns regarding security, privacy and quality.
Consequently, various testing approaches have been proposed to systematically
examine VPA app behaviors. To tackle the inherent lack of a visible user
interface in the VPA app, two strategies are employed during testing, i.e.,
chatbot-style testing and model-based testing. The former often lacks effective
guidance for expanding its search space, while the latter falls short in
interpreting the semantics of conversations to construct precise and
comprehensive behavior models for apps. In this work, we introduce Elevate, a
model-enhanced large language model (LLM)-driven VUI testing framework. Elevate
leverages LLMs' strong capability in natural language processing to compensate
for semantic information loss during model-based VUI testing. It operates by
prompting LLMs to extract states from VPA apps' outputs and generate
context-related inputs. During the automatic interactions with the app, it
incrementally constructs the behavior model, which facilitates the LLM in
generating inputs that are highly likely to discover new states. Elevate
bridges the LLM and the behavior model with innovative techniques such as
encoding behavior model into prompts and selecting LLM-generated inputs based
on the context relevance. Elevate is benchmarked on 4,000 real-world Alexa
skills, against the state-of-the-art tester Vitas. It achieves 15% higher state
space coverage compared to Vitas on all types of apps, and exhibits significant
advancement in efficiency.

中文翻译:
以亚马逊Alexa为代表的语音个人助手（VPA）生态系统的蓬勃发展，推动了VPA应用程序的爆发式增长。全球最大的应用市场Amazon技能商店目前已托管超过20万个应用程序。尽管这些应用广受欢迎，但其开放式的发布模式和便捷的访问特性也引发了人们对安全性、隐私性和质量的重大担忧。为此，研究者们提出了多种测试方法来系统化检测VPA应用行为。

针对VPA应用缺乏可视化用户界面的固有特性，当前测试主要采用两种策略：聊天机器人式测试和基于模型的测试。前者往往缺乏有效的搜索空间扩展指导，后者则难以解析对话语义以构建精确全面的应用程序行为模型。本研究提出Elevate框架——一种基于大语言模型（LLM）增强的VUI测试系统，通过利用LLM强大的自然语言处理能力来弥补基于模型的VUI测试中的语义信息缺失。该框架通过提示LLM从VPA应用输出中提取状态并生成上下文相关输入，在自动化交互过程中逐步构建行为模型，从而帮助LLM生成更可能发现新状态的输入。

Elevate采用创新技术实现LLM与行为模型的协同：将行为模型编码为提示词，基于上下文相关性筛选LLM生成的输入。在4,000个真实Alexa技能应用上的测试表明，相较于当前最先进的测试工具Vitas，Elevate在所有类型应用上实现了15%的状态空间覆盖率提升，并展现出显著的效率优势。
