# Democratizing Reasoning Ability: Tailored Learning from Large Language Model

链接: http://arxiv.org/abs/2310.13332v1

原文摘要:
Large language models (LLMs) exhibit impressive emergent abilities in natural
language processing, but their democratization is hindered due to huge
computation requirements and closed-source nature. Recent research on advancing
open-source smaller LMs by distilling knowledge from black-box LLMs has
obtained promising results in the instruction-following ability. However, the
reasoning ability which is more challenging to foster, is relatively rarely
explored. In this paper, we propose a tailored learning approach to distill
such reasoning ability to smaller LMs to facilitate the democratization of the
exclusive reasoning ability. In contrast to merely employing LLM as a data
annotator, we exploit the potential of LLM as a reasoning teacher by building
an interactive multi-round learning paradigm. This paradigm enables the student
to expose its deficiencies to the black-box teacher who then can provide
customized training data in return. Further, to exploit the reasoning potential
of the smaller LM, we propose self-reflection learning to motivate the student
to learn from self-made mistakes. The learning from self-reflection and LLM are
all tailored to the student's learning status, thanks to the seamless
integration with the multi-round learning paradigm. Comprehensive experiments
and analysis on mathematical and commonsense reasoning tasks demonstrate the
effectiveness of our method. The code will be available at
https://github.com/Raibows/Learn-to-Reason.

中文翻译:
大型语言模型（LLM）在自然语言处理领域展现出令人瞩目的涌现能力，但其普及却受限于庞大的计算需求与闭源特性。近期研究通过从黑盒LLM中蒸馏知识来提升开源小型语言模型，在指令跟随能力上取得了显著成果。然而更具挑战性的推理能力培养却鲜少被探索。本文提出一种定制化学习方法，将这种推理能力蒸馏至小型模型，以促进这一独家能力的民主化进程。与仅将LLM作为数据标注工具不同，我们通过构建交互式多轮学习范式，充分挖掘其作为推理教师的潜力。该范式使学生模型能向黑盒教师暴露自身缺陷，从而获得定制化的训练数据反馈。更进一步，为激发小型模型的推理潜能，我们提出自反思学习机制，激励学生模型从自身错误中学习。得益于与多轮学习范式的无缝整合，自反思与LLM的教学都能根据学生的学习状态进行动态调整。在数学与常识推理任务上的全面实验与分析验证了本方法的有效性。代码将在https://github.com/Raibows/Learn-to-Reason公开。
