# Enhancing LLM Problem Solving with REAP: Reflection, Explicit Problem Deconstruction, and Advanced Prompting

链接: http://arxiv.org/abs/2409.09415v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing,
yet improving their problem-solving capabilities, particularly for complex,
reasoning-intensive tasks, remains a persistent challenge. This paper
introduces the REAP (Reflection, Explicit Problem Deconstruction, and Advanced
Prompting) method, an innovative approach within the dynamic context generation
framework. REAP guides LLMs through reflection on the query, deconstructing it
into manageable components, and generating relevant context to enhance the
solution process. We evaluated REAP using a dataset designed to expose LLM
limitations, comparing zero-shot prompting with REAP-enhanced prompts across
six state-of-the-art models: OpenAI's o1-preview, o1-mini, GPT-4o, GPT-4o-mini,
Google's Gemini 1.5 Pro, and Claude 3.5 Sonnet. The results demonstrate notable
performance gains, with o1-mini improving by 40.97%, GPT-4o by 66.26%, and
GPT-4o-mini by 112.93%. Despite the already strong baseline performance of
OpenAI's o1-preview, modest gains were observed. Beyond performance
improvements, REAP offers a cost-effective solution; for example, GPT-4o-mini,
which is approximately 100 times cheaper than o1-preview, delivered competitive
results. REAP also improves the clarity of model outputs, making it easier for
humans to understand the reasoning behind the results and simplifying the
process of identifying and addressing any issues. These findings demonstrate
REAP's potential to greatly improve the capabilities of LLMs, providing both
better performance and increased cost-efficiency across a wide range of
applications.

中文翻译:
大型语言模型（LLMs）已彻底改变了自然语言处理领域，但提升其解决复杂推理密集型任务的能力仍是持续存在的挑战。本文提出REAP（反思、显式问题解构与高级提示）方法——一种动态上下文生成框架下的创新方案。该方法通过引导模型对问题进行反思，将其拆解为可处理的子模块，并生成相关上下文以优化求解过程。我们在专为暴露LLM局限性设计的数据集上评估REAP，对比了零样本提示与REAP增强提示在六种前沿模型的表现：OpenAI的o1-preview、o1-mini、GPT-4o、GPT-4o-mini，Google的Gemini 1.5 Pro以及Claude 3.5 Sonnet。结果显示显著性能提升：o1-mini提高40.97%，GPT-4o提升66.26%，GPT-4o-mini增幅达112.93%。尽管o1-preview基线性能已很强劲，仍观察到适度提升。除性能改进外，REAP更具成本效益：例如价格仅为o1-preview约1%的GPT-4o-mini取得了可比结果。该方法还增强了输出清晰度，使人更易理解模型推理过程，并简化问题诊断流程。这些发现证明REAP能显著增强LLMs能力，在广泛应用中实现性能与成本效益的双重提升。
