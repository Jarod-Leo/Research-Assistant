# Enhancing LLM Problem Solving with REAP: Reflection, Explicit Problem Deconstruction, and Advanced Prompting

链接: http://arxiv.org/abs/2409.09415v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing,
yet improving their problem-solving capabilities, particularly for complex,
reasoning-intensive tasks, remains a persistent challenge. This paper
introduces the REAP (Reflection, Explicit Problem Deconstruction, and Advanced
Prompting) method, an innovative approach within the dynamic context generation
framework. REAP guides LLMs through reflection on the query, deconstructing it
into manageable components, and generating relevant context to enhance the
solution process. We evaluated REAP using a dataset designed to expose LLM
limitations, comparing zero-shot prompting with REAP-enhanced prompts across
six state-of-the-art models: OpenAI's o1-preview, o1-mini, GPT-4o, GPT-4o-mini,
Google's Gemini 1.5 Pro, and Claude 3.5 Sonnet. The results demonstrate notable
performance gains, with o1-mini improving by 40.97%, GPT-4o by 66.26%, and
GPT-4o-mini by 112.93%. Despite the already strong baseline performance of
OpenAI's o1-preview, modest gains were observed. Beyond performance
improvements, REAP offers a cost-effective solution; for example, GPT-4o-mini,
which is approximately 100 times cheaper than o1-preview, delivered competitive
results. REAP also improves the clarity of model outputs, making it easier for
humans to understand the reasoning behind the results and simplifying the
process of identifying and addressing any issues. These findings demonstrate
REAP's potential to greatly improve the capabilities of LLMs, providing both
better performance and increased cost-efficiency across a wide range of
applications.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）已彻底改变了自然语言处理领域，但提升其解决复杂推理密集型任务的能力仍是持续存在的挑战。本文提出REAP（反思、显式问题解构与高级提示）方法——一种动态上下文生成框架内的创新方案。该技术通过引导模型进行问题反思、将查询分解为可处理组件并生成相关上下文来优化求解过程。我们在专为暴露LLM局限性设计的数据集上评估REAP，对比了零样本提示与REAP增强提示在六大前沿模型的表现：OpenAI的o1-preview、o1-mini、GPT-4o、GPT-4o-mini，Google的Gemini 1.5 Pro以及Claude 3.5 Sonnet。结果显示显著性能提升：o1-mini提高40.97%，GPT-4o提升66.26%，GPT-4o-mini增幅达112.93%。尽管OpenAI o1-preview基线性能已很强劲，仍观察到适度提升。除性能改进外，REAP更具成本效益：例如价格仅为o1-preview约1%的GPT-4o-mini取得了具有竞争力的结果。该方法还增强了输出清晰度，使人更易理解结果背后的推理逻辑，并简化问题识别与修正流程。这些发现证明REAP能显著增强LLM能力，在广泛应用中实现性能与成本效益的双重提升。

翻译说明：
1. 专业术语处理：LLMs统一译为"大型语言模型"，REAP全称采用中文释义加英文缩写括号标注
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如第一段拆分为技术背景与论文贡献两部分
3. 被动语态转换："were observed"等被动结构转为中文主动表达
4. 数据呈现优化：百分比数据保留原始精度，模型名称维持英文代号+中文说明格式
5. 逻辑显化：补充"该方法"等连接词确保行文连贯性
6. 技术概念准确传达："dynamic context generation framework"译为"动态上下文生成框架"保持专业度
7. 文化适配：保留"零样本提示"等NLP领域通用译法，确保学术共同体认可度
