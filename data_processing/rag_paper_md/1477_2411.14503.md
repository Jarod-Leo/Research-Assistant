# Planning-Driven Programming: A Large Language Model Programming Workflow

链接: http://arxiv.org/abs/2411.14503v1

原文摘要:
The strong performance of large language models (LLMs) raises extensive
discussion on their application to code generation. Recent research suggests
continuous program refinements through visible tests to improve code generation
accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and
limited reasoning capacity. In this work, we propose an LLM programming
workflow (LPW) designed to improve both initial code generation and subsequent
refinements within a structured two-phase workflow. Specifically, the solution
generation phase formulates a solution plan, which is then verified through
visible tests to specify the intended natural language solution. Subsequently,
the code implementation phase drafts an initial code according to the solution
plan and its verification. If the generated code fails the visible tests, the
plan verification serves as the intended solution to consistently inform the
refinement process for correcting bugs. Compared to state-of-the-art methods
across various existing LLMs, LPW significantly improves the Pass@1 accuracy by
up to 16.4% on well-established text-to-code generation benchmarks. LPW also
sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%
on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using
GPT-4o as the backbone.

中文翻译:
大型语言模型（LLM）的卓越表现引发了对其在代码生成领域应用的广泛讨论。近期研究表明，通过可见测试进行持续程序优化能提升LLM的代码生成准确率。然而，这些方法受限于LLM的低效性和有限推理能力。本研究提出一种LLM编程工作流（LPW），通过结构化双阶段流程同时提升初始代码生成与后续优化效果。具体而言，方案生成阶段首先制定解决方案计划，随后通过可见测试验证以明确自然语言解决方案的预期目标；代码实现阶段则依据验证后的方案计划起草初始代码。若生成代码未通过可见测试，计划验证结果将作为预期解决方案持续指导修复过程的错误修正。相较于现有各类LLM的最先进方法，LPW在成熟文本到代码生成基准测试中显著提升Pass@1准确率最高达16.4%。以GPT-4o为核心时，LPW创下多项新纪录：HumanEval（98.2%）、MBPP（84.8%）、LiveCode（59.3%）、APPS（62.6%）和CodeContest（34.7%）的Pass@1准确率均达到当前最优水平。
