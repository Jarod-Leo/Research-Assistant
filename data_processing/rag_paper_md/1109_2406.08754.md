# StructuralSleight: Automated Jailbreak Attacks on Large Language Models Utilizing Uncommon Text-Encoded Structure

链接: http://arxiv.org/abs/2406.08754v1

原文摘要:
Large Language Models (LLMs) are widely used in natural language processing
but face the risk of jailbreak attacks that maliciously induce them to generate
harmful content. Existing jailbreak attacks, including character-level and
context-level attacks, mainly focus on the prompt of plain text without
specifically exploring the significant influence of its structure. In this
paper, we focus on studying how the prompt structure contributes to the
jailbreak attack. We introduce a novel structure-level attack method based on
long-tailed structures, which we refer to as Uncommon Text-Organization
Structures (UTOS). We extensively study 12 UTOS templates and 6 obfuscation
methods to build an effective automated jailbreak tool named StructuralSleight
that contains three escalating attack strategies: Structural Attack, Structural
and Character/Context Obfuscation Attack, and Fully Obfuscated Structural
Attack. Extensive experiments on existing LLMs show that StructuralSleight
significantly outperforms the baseline methods. In particular, the attack
success rate reaches 94.62\% on GPT-4o, which has not been addressed by
state-of-the-art techniques.

中文翻译:
大型语言模型（LLMs）在自然语言处理领域应用广泛，但面临恶意诱导生成有害内容的越狱攻击风险。现有攻击方法（包括字符级与上下文级攻击）主要针对纯文本提示，未深入探究其结构的重要影响。本文聚焦于提示结构对越狱攻击的贡献机制，提出基于长尾结构的新型结构级攻击方法——非常规文本组织结构（UTOS）。我们系统研究了12种UTOS模板与6种混淆方法，构建了包含三级递进攻击策略（结构攻击、结构与字符/上下文混淆攻击、完全混淆结构攻击）的自动化越狱工具StructuralSleight。在多款主流LLMs上的实验表明，该工具显著优于基线方法，尤其在GPT-4o上的攻击成功率高达94.62%，突破了现有技术的防御瓶颈。
