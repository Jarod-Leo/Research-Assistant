# Automatic Prompt Selection for Large Language Models

链接: http://arxiv.org/abs/2404.02717v1

原文摘要:
Large Language Models (LLMs) can perform various natural language processing
tasks with suitable instruction prompts. However, designing effective prompts
manually is challenging and time-consuming. Existing methods for automatic
prompt optimization either lack flexibility or efficiency. In this paper, we
propose an effective approach to automatically select the optimal prompt for a
given input from a finite set of synthetic candidate prompts. Our approach
consists of three steps: (1) clustering the training data and generating
candidate prompts for each cluster using an LLM-based prompt generator; (2)
synthesizing a dataset of input-prompt-output tuples for training a prompt
evaluator to rank the prompts based on their relevance to the input; (3) using
the prompt evaluator to select the best prompt for a new input at test time.
Our approach balances prompt generality-specificity and eliminates the need for
resource-intensive training and inference. It demonstrates competitive
performance on zero-shot question-answering datasets: GSM8K, MultiArith, and
AQuA.

中文翻译:
大型语言模型（LLMs）能够通过适当的指令提示完成多种自然语言处理任务。然而，手动设计有效的提示既具挑战性又耗时。现有的自动提示优化方法往往缺乏灵活性或效率。本文提出一种创新方法，能够从有限的合成候选提示集中自动选择最适合给定输入的最优提示。该方法包含三个关键步骤：（1）对训练数据进行聚类，并基于LLM的提示生成器为每个聚类生成候选提示；（2）合成输入-提示-输出三元组数据集，用于训练提示评估器，根据提示与输入的相关性进行排序；（3）在测试阶段使用该评估器为新输入选择最佳提示。本方法在保持提示通用性与特异性平衡的同时，避免了资源密集型的训练和推理过程。在零样本问答数据集GSM8K、MultiArith和AQuA上的实验表明，其性能达到竞争水平。
