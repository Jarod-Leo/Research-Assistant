# Consistency Evaluation of News Article Summaries Generated by Large (and Small) Language Models

链接: http://arxiv.org/abs/2502.20647v1

原文摘要:
Text summarizing is a critical Natural Language Processing (NLP) task with
applications ranging from information retrieval to content generation. Large
Language Models (LLMs) have shown remarkable promise in generating fluent
abstractive summaries but they can produce hallucinated details not grounded in
the source text. Regardless of the method of generating a summary, high quality
automated evaluations remain an open area of investigation. This paper embarks
on an exploration of text summarization with a diverse set of techniques,
including TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The
generated summaries are evaluated using traditional metrics such as the
Recall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and
Bidirectional Encoder Representations from Transformers (BERT) Score, as well
as LLM-powered evaluation methods that directly assess a generated summary's
consistency with the source text. We introduce a meta evaluation score which
directly assesses the performance of the LLM evaluation system (prompt +
model). We find that that all summarization models produce consistent summaries
when tested on the XL-Sum dataset, exceeding the consistency of the reference
summaries.

中文翻译:
文本摘要作为自然语言处理（NLP）的核心任务，其应用涵盖信息检索至内容生成等多个领域。大型语言模型（LLMs）在生成流畅的抽象摘要方面展现出显著潜力，但也可能产生与源文本不符的虚构细节。无论采用何种摘要生成方法，高质量的自动化评估仍是待探索的研究方向。本文通过TextRank、BART、Mistral-7B-Instruct和OpenAI GPT-3.5-Turbo等多种技术对文本摘要进行系统性研究。所生成摘要采用传统指标（如ROUGE评分和BERTScore）及基于LLM的评估方法进行评测，后者直接衡量生成摘要与源文本的一致性。我们提出了一种元评估分数，用于直接评估LLM评价系统（提示词+模型）的性能。实验发现，所有摘要模型在XL-Sum数据集上生成的摘要均具有较高一致性，其表现甚至优于参考摘要的一致性水平。
