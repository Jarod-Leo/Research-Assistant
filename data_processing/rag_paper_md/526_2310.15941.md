# This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models

链接: http://arxiv.org/abs/2310.15941v1

原文摘要:
Although large language models (LLMs) have apparently acquired a certain
level of grammatical knowledge and the ability to make generalizations, they
fail to interpret negation, a crucial step in Natural Language Processing. We
try to clarify the reasons for the sub-optimal performance of LLMs
understanding negation. We introduce a large semi-automatically generated
dataset of circa 400,000 descriptive sentences about commonsense knowledge that
can be true or false in which negation is present in about 2/3 of the corpus in
different forms. We have used our dataset with the largest available open LLMs
in a zero-shot approach to grasp their generalization and inference capability
and we have also fine-tuned some of the models to assess whether the
understanding of negation can be trained. Our findings show that, while LLMs
are proficient at classifying affirmative sentences, they struggle with
negative sentences and lack a deep understanding of negation, often relying on
superficial cues. Although fine-tuning the models on negative sentences
improves their performance, the lack of generalization in handling negation is
persistent, highlighting the ongoing challenges of LLMs regarding negation
understanding and generalization. The dataset and code are publicly available.

中文翻译:
尽管大型语言模型（LLMs）已展现出一定程度的语法知识与泛化能力，但其在自然语言处理的关键环节——否定理解上仍存在明显不足。本研究旨在揭示LLMs在否定理解上表现欠佳的根本原因。我们构建了一个包含约40万条常识性描述语句的半自动生成数据集，其中约三分之二的语料以不同形式包含否定结构，这些语句可判定真伪。通过零样本测试方法，我们在当前最大规模的开源LLMs上验证了其泛化与推理能力，并对部分模型进行微调以评估否定理解是否可通过训练获得。研究结果表明：LLMs能准确分类肯定句，却难以处理否定句且缺乏深层次否定理解，往往依赖表面特征。虽然针对否定句的微调能提升模型表现，但处理否定时的泛化能力缺失问题持续存在，凸显出LLMs在否定理解与泛化方面仍面临严峻挑战。本研究的完整数据集与代码已公开。
