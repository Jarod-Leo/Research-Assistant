# This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models

链接: http://arxiv.org/abs/2310.15941v1

原文摘要:
Although large language models (LLMs) have apparently acquired a certain
level of grammatical knowledge and the ability to make generalizations, they
fail to interpret negation, a crucial step in Natural Language Processing. We
try to clarify the reasons for the sub-optimal performance of LLMs
understanding negation. We introduce a large semi-automatically generated
dataset of circa 400,000 descriptive sentences about commonsense knowledge that
can be true or false in which negation is present in about 2/3 of the corpus in
different forms. We have used our dataset with the largest available open LLMs
in a zero-shot approach to grasp their generalization and inference capability
and we have also fine-tuned some of the models to assess whether the
understanding of negation can be trained. Our findings show that, while LLMs
are proficient at classifying affirmative sentences, they struggle with
negative sentences and lack a deep understanding of negation, often relying on
superficial cues. Although fine-tuning the models on negative sentences
improves their performance, the lack of generalization in handling negation is
persistent, highlighting the ongoing challenges of LLMs regarding negation
understanding and generalization. The dataset and code are publicly available.

中文翻译:
尽管大型语言模型（LLMs）已初步掌握语法规则并具备一定泛化能力，但其在自然语言处理的关键环节——否定理解上仍存在明显缺陷。本研究旨在揭示LLMs在否定理解上表现欠佳的内在原因。我们构建了一个包含约40万条常识性描述语句的半自动生成数据集，其中三分之二语料以不同形式包含否定结构，这些语句可判定真伪。通过零样本测试方法，我们在当前最大规模的开源LLMs上验证了其泛化与推理能力，并对部分模型进行微调以探究否定理解能力是否可通过训练获得。实验结果表明：LLMs能准确分类肯定句，却难以处理否定句，其理解往往停留在表层线索而缺乏深度语义把握。虽然针对否定句的微调能提升模型表现，但处理否定时的泛化能力缺失问题持续存在，这凸显了LLMs在否定理解与泛化方面仍面临根本性挑战。本研究的数据集与代码已开源。
