# How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks

链接: http://arxiv.org/abs/2303.00293v1

原文摘要:
The GPT-3.5 models have demonstrated impressive performance in various
Natural Language Processing (NLP) tasks, showcasing their strong understanding
and reasoning capabilities. However, their robustness and abilities to handle
various complexities of the open world have yet to be explored, which is
especially crucial in assessing the stability of models and is a key aspect of
trustworthy AI. In this study, we perform a comprehensive experimental analysis
of GPT-3.5, exploring its robustness using 21 datasets (about 116K test
samples) with 66 text transformations from TextFlint that cover 9 popular
Natural Language Understanding (NLU) tasks. Our findings indicate that while
GPT-3.5 outperforms existing fine-tuned models on some tasks, it still
encounters significant robustness degradation, such as its average performance
dropping by up to 35.74\% and 43.59\% in natural language inference and
sentiment analysis tasks, respectively. We also show that GPT-3.5 faces some
specific robustness challenges, including robustness instability, prompt
sensitivity, and number sensitivity. These insights are valuable for
understanding its limitations and guiding future research in addressing these
challenges to enhance GPT-3.5's overall performance and generalization
abilities.

中文翻译:
GPT-3.5模型在各类自然语言处理任务中展现出卓越性能，其强大的理解与推理能力已得到验证。然而，该模型在开放环境中应对复杂场景的鲁棒性仍有待探究——这一特性既是评估模型稳定性的关键指标，也是可信人工智能的核心维度。本研究通过21个数据集（约11.6万测试样本）和TextFlint提供的涵盖9大主流自然语言理解任务的66种文本转换策略，对GPT-3.5进行了系统性实验分析。研究发现：尽管GPT-3.5在部分任务上超越现有微调模型，但其鲁棒性仍存在显著缺陷，例如在自然语言推理和情感分析任务中平均性能分别下降达35.74%和43.59%。实验同时揭示了GPT-3.5特有的鲁棒性挑战，包括稳定性波动、提示敏感性和数字敏感性等问题。这些发现不仅有助于深入理解模型局限，更为未来研究指明了提升GPT-3.5综合性能与泛化能力的关键方向。
