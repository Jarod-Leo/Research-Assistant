# How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks

链接: http://arxiv.org/abs/2303.00293v1

原文摘要:
The GPT-3.5 models have demonstrated impressive performance in various
Natural Language Processing (NLP) tasks, showcasing their strong understanding
and reasoning capabilities. However, their robustness and abilities to handle
various complexities of the open world have yet to be explored, which is
especially crucial in assessing the stability of models and is a key aspect of
trustworthy AI. In this study, we perform a comprehensive experimental analysis
of GPT-3.5, exploring its robustness using 21 datasets (about 116K test
samples) with 66 text transformations from TextFlint that cover 9 popular
Natural Language Understanding (NLU) tasks. Our findings indicate that while
GPT-3.5 outperforms existing fine-tuned models on some tasks, it still
encounters significant robustness degradation, such as its average performance
dropping by up to 35.74\% and 43.59\% in natural language inference and
sentiment analysis tasks, respectively. We also show that GPT-3.5 faces some
specific robustness challenges, including robustness instability, prompt
sensitivity, and number sensitivity. These insights are valuable for
understanding its limitations and guiding future research in addressing these
challenges to enhance GPT-3.5's overall performance and generalization
abilities.

中文翻译:
GPT-3.5模型在各类自然语言处理（NLP）任务中展现出卓越性能，体现了其强大的理解与推理能力。然而，该模型在开放世界中应对复杂场景的鲁棒性及能力仍有待探索——这对评估模型稳定性至关重要，也是可信人工智能的关键维度。本研究通过系统性实验分析，采用TextFlint提供的涵盖9类主流自然语言理解（NLU）任务的66种文本变换方法（涉及21个数据集约11.6万测试样本），全面考察GPT-3.5的鲁棒性。研究发现：尽管GPT-3.5在部分任务上优于现有微调模型，但其鲁棒性仍存在显著缺陷——在自然语言推理和情感分析任务中，平均性能分别下降达35.74%和43.59%。研究还揭示了GPT-3.5面临的特定鲁棒性挑战，包括：鲁棒性不稳定、提示敏感性和数字敏感性。这些发现不仅有助于理解模型局限，更为未来研究指明方向——通过解决这些挑战来提升GPT-3.5的整体性能与泛化能力。
