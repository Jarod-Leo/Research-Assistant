# Introduction to Transformers: an NLP Perspective

链接: http://arxiv.org/abs/2311.17633v1

原文摘要:
Transformers have dominated empirical machine learning models of natural
language processing. In this paper, we introduce basic concepts of Transformers
and present key techniques that form the recent advances of these models. This
includes a description of the standard Transformer architecture, a series of
model refinements, and common applications. Given that Transformers and related
deep learning techniques might be evolving in ways we have never seen, we
cannot dive into all the model details or cover all the technical areas.
Instead, we focus on just those concepts that are helpful for gaining a good
understanding of Transformers and their variants. We also summarize the key
ideas that impact this field, thereby yielding some insights into the strengths
and limitations of these models.

中文翻译:
Transformer模型已成为自然语言处理领域占据主导地位的机器学习实证模型。本文系统介绍了Transformer的基本概念，并阐述了构成这些模型最新进展的核心技术。内容涵盖标准Transformer架构解析、一系列模型优化方法以及典型应用场景。鉴于Transformer及相关深度学习技术可能正以我们前所未见的方式演进，本文无法穷尽所有模型细节或覆盖全部技术领域，而是聚焦于那些有助于深入理解Transformer及其变体的关键概念。同时，我们提炼了影响该领域发展的核心思想，从而揭示这些模型的优势与局限性。
