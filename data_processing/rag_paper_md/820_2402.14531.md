# Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance

链接: http://arxiv.org/abs/2402.14531v1

原文摘要:
We investigate the impact of politeness levels in prompts on the performance
of large language models (LLMs). Polite language in human communications often
garners more compliance and effectiveness, while rudeness can cause aversion,
impacting response quality. We consider that LLMs mirror human communication
traits, suggesting they align with human cultural norms. We assess the impact
of politeness in prompts on LLMs across English, Chinese, and Japanese tasks.
We observed that impolite prompts often result in poor performance, but overly
polite language does not guarantee better outcomes. The best politeness level
is different according to the language. This phenomenon suggests that LLMs not
only reflect human behavior but are also influenced by language, particularly
in different cultural contexts. Our findings highlight the need to factor in
politeness for cross-cultural natural language processing and LLM usage.

中文翻译:
本研究探讨了提示语句中的礼貌程度对大型语言模型（LLMs）表现的影响。在人类交流中，礼貌用语通常能获得更高的配合度与沟通成效，而粗鲁表达则易引发抵触心理，从而影响应答质量。鉴于LLMs能够反映人类交流特征，我们推测其行为模式会遵循人类文化规范。我们通过英语、汉语和日语三类任务，系统评估了提示语礼貌程度对LLMs的影响。研究发现：非礼貌提示往往导致模型表现欠佳，但过度礼貌的表达也未必能提升效果；最佳礼貌等级因语言而异。这种现象表明LLMs不仅能够映射人类行为模式，还会受到语言特性的影响——特别是在不同文化语境中。本研究成果强调，在跨文化自然语言处理及LLMs应用场景中，必须将礼貌策略纳入考量因素。

（翻译说明：采用学术论文摘要的规范表述，通过以下处理实现专业性与可读性平衡：
1. 将被动语态转换为中文主动句式（如"are influenced by"译为"受到...影响"）
2. 专业术语统一处理（如"prompts"统一译为"提示语/提示句"）
3. 长难句拆分重组（如原文最后两句合并为符合中文阅读习惯的递进结构）
4. 文化负载词处理（如"aversion"译为"抵触心理"而非字面直译）
5. 保持关键量化表述（如"often/overly"准确传达原文程度限定））
