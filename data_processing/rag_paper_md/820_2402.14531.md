# Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance

链接: http://arxiv.org/abs/2402.14531v1

原文摘要:
We investigate the impact of politeness levels in prompts on the performance
of large language models (LLMs). Polite language in human communications often
garners more compliance and effectiveness, while rudeness can cause aversion,
impacting response quality. We consider that LLMs mirror human communication
traits, suggesting they align with human cultural norms. We assess the impact
of politeness in prompts on LLMs across English, Chinese, and Japanese tasks.
We observed that impolite prompts often result in poor performance, but overly
polite language does not guarantee better outcomes. The best politeness level
is different according to the language. This phenomenon suggests that LLMs not
only reflect human behavior but are also influenced by language, particularly
in different cultural contexts. Our findings highlight the need to factor in
politeness for cross-cultural natural language processing and LLM usage.

中文翻译:
本研究探讨了提示语中礼貌程度对大语言模型（LLM）性能的影响。在人类交流中，礼貌用语通常能获得更高的配合度与沟通效率，而粗鲁表达易引发抵触情绪，从而影响回应质量。鉴于大语言模型模拟人类交流特性，我们假设其会遵循人类文化规范。我们通过英语、汉语和日语三类任务，系统评估了提示语礼貌程度对LLM表现的影响。研究发现：非礼貌提示往往导致性能下降，但过度礼貌表达亦不能确保效果提升；最佳礼貌等级因语言而异。这种现象表明大语言模型不仅映射人类行为特征，还受到语言（尤其是不同文化语境）的显著影响。我们的发现强调了在跨文化自然语言处理及大语言模型应用中纳入礼貌考量因素的必要性。
