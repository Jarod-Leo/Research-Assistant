# Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education

链接: http://arxiv.org/abs/2402.14293v1

原文摘要:
In the domain of Natural Language Processing (NLP), Large Language Models
(LLMs) have demonstrated promise in text-generation tasks. However, their
educational applications, particularly for domain-specific queries, remain
underexplored. This study investigates LLMs' capabilities in educational
scenarios, focusing on concept graph recovery and question-answering (QA). We
assess LLMs' zero-shot performance in creating domain-specific concept graphs
and introduce TutorQA, a new expert-verified NLP-focused benchmark for
scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA
pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating
concept graphs with LLMs for answering diverse questions. Our results indicate
that LLMs' zero-shot concept graph recovery is competitive with supervised
methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs
achieve up to 26% F1 score enhancement. Moreover, human evaluation and analysis
show that CGLLM generates answers with more fine-grained concepts.

中文翻译:
在自然语言处理（NLP）领域，大语言模型（LLMs）已在文本生成任务中展现出潜力。然而，其在教育领域的应用，尤其是针对特定领域查询的场景，仍缺乏深入探索。本研究聚焦教育场景中的概念图谱重建与问答（QA）任务，系统评估了LLMs的零样本能力。我们提出了TutorQA——一个经专家验证、以NLP为核心的科学图谱推理与问答新基准，包含五项任务共计500组问答对。为应对TutorQA的查询需求，我们开发了CGLLM框架，该框架通过整合概念图谱与LLMs来解答多样化问题。实验结果表明：在零样本概念图谱重建任务中，LLMs的表现与监督学习方法相当，F1分数平均提升3%；在TutorQA任务中，LLMs最高可获得26%的F1分数提升。进一步的人类评估与分析显示，CGLLM生成的答案包含更细粒度的概念表述。
