# EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning

链接: http://arxiv.org/abs/2404.16670v1

原文摘要:
Visual Instruction Tuning represents a novel learning paradigm involving the
fine-tuning of pre-trained language models using task-specific instructions.
This paradigm shows promising zero-shot results in various natural language
processing tasks but is still unexplored in vision emotion understanding. In
this work, we focus on enhancing the model's proficiency in understanding and
adhering to instructions related to emotional contexts. Initially, we identify
key visual clues critical to visual emotion recognition. Subsequently, we
introduce a novel GPT-assisted pipeline for generating emotion visual
instruction data, effectively addressing the scarcity of annotated instruction
data in this domain. Expanding on the groundwork established by InstructBLIP,
our proposed EmoVIT architecture incorporates emotion-specific instruction
data, leveraging the powerful capabilities of Large Language Models to enhance
performance. Through extensive experiments, our model showcases its proficiency
in emotion classification, adeptness in affective reasoning, and competence in
comprehending humor. The comparative analysis provides a robust benchmark for
Emotion Visual Instruction Tuning in the era of LLMs, providing valuable
insights and opening avenues for future exploration in this domain. Our code is
available at \url{https://github.com/aimmemotion/EmoVIT}.

中文翻译:
视觉指令微调是一种新兴的学习范式，它通过对预训练语言模型进行任务特定指令的精细调整来实现。该范式在多种自然语言处理任务中展现出优异的零样本性能，但在视觉情感理解领域仍属空白。本研究致力于提升模型在情感相关语境下的指令理解与执行能力。我们首先识别了视觉情感识别的关键视觉线索，随后开发了一种基于GPT辅助的情感视觉指令数据生成流程，有效解决了该领域标注指令数据稀缺的问题。基于InstructBLIP框架，我们提出的EmoVIT架构整合了情感专属指令数据，充分发挥大语言模型的强大能力以提升性能。大量实验表明，我们的模型在情感分类、情感推理和幽默理解等方面均表现出色。对比分析为LLM时代的情感视觉指令微调建立了可靠基准，为该领域的未来探索提供了宝贵见解与发展路径。代码已开源于\url{https://github.com/aimmemotion/EmoVIT}。
