# FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking

链接: http://arxiv.org/abs/2309.00240v1

原文摘要:
Automatic fact-checking plays a crucial role in combating the spread of
misinformation. Large Language Models (LLMs) and Instruction-Following
variants, such as InstructGPT and Alpaca, have shown remarkable performance in
various natural language processing tasks. However, their knowledge may not
always be up-to-date or sufficient, potentially leading to inaccuracies in
fact-checking. To address this limitation, we propose combining the power of
instruction-following language models with external evidence retrieval to
enhance fact-checking performance. Our approach involves leveraging search
engines to retrieve relevant evidence for a given input claim. This external
evidence serves as valuable supplementary information to augment the knowledge
of the pretrained language model. Then, we instruct-tune an open-sourced
language model, called LLaMA, using this evidence, enabling it to predict the
veracity of the input claim more accurately. To evaluate our method, we
conducted experiments on two widely used fact-checking datasets: RAWFC and
LIAR. The results demonstrate that our approach achieves state-of-the-art
performance in fact-checking tasks. By integrating external evidence, we bridge
the gap between the model's knowledge and the most up-to-date and sufficient
context available, leading to improved fact-checking outcomes. Our findings
have implications for combating misinformation and promoting the dissemination
of accurate information on online platforms. Our released materials are
accessible at: https://thcheung.github.io/factllama.

中文翻译:
自动事实核查在遏制虚假信息传播中发挥着关键作用。大型语言模型（LLMs）及其指令跟随变体（如InstructGPT和Alpaca）已在多种自然语言处理任务中展现出卓越性能。然而，这些模型的知识可能不够及时或充分，容易导致事实核查的误差。为突破这一局限，我们提出将指令跟随语言模型与外部证据检索相结合以提升核查效能。该方法通过搜索引擎获取输入主张的相关证据，这些外部证据作为有价值的补充信息，可增强预训练语言模型的知识储备。随后，我们基于开源模型LLaMA进行指令微调，使其能更准确地预测输入主张的真实性。我们在RAWFC和LIAR两个广泛使用的事实核查数据集上开展实验，结果表明该方法达到了当前最优的核查性能。通过整合外部证据，我们弥合了模型知识与最新充分语境之间的鸿沟，从而优化了核查效果。本研究对打击虚假信息、促进网络平台准确信息传播具有重要启示。相关资源已发布于：https://thcheung.github.io/factllama。
