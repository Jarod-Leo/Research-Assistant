# ByteScience: Bridging Unstructured Scientific Literature and Structured Data with Auto Fine-tuned Large Language Model in Token Granularity

链接: http://arxiv.org/abs/2411.12000v1

原文摘要:
Natural Language Processing (NLP) is widely used to supply summarization
ability from long context to structured information. However, extracting
structured knowledge from scientific text by NLP models remains a challenge
because of its domain-specific nature to complex data preprocessing and the
granularity of multi-layered device-level information. To address this, we
introduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language
Model (LLM) platform, which is designed to extract structured scientific data
and synthesize new scientific knowledge from vast scientific corpora. The
platform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to
natural science. The platform was built on Amazon Web Services (AWS) and
provides an automated, user-friendly workflow for custom model development and
data extraction. The platform achieves remarkable accuracy with only a small
amount of well-annotated articles. This innovative tool streamlines the
transition from the science literature to structured knowledge and data and
benefits the advancements in natural informatics.

中文翻译:
自然语言处理（NLP）技术被广泛用于从长篇文本中提取结构化信息的摘要功能。然而，由于科学文本具有领域特殊性、数据预处理复杂以及多层设备级信息的细粒度特征，利用NLP模型从中提取结构化知识仍面临挑战。为此，我们推出了ByteScience——一个非营利性云端自动微调大语言模型（LLM）平台，专为从海量科学文献中提取结构化数据并合成新科学知识而设计。该平台基于DARWIN（一个专注于自然科学领域的开源微调LLM）构建，依托亚马逊云服务（AWS）基础设施，提供自动化、用户友好的定制化模型开发与数据提取工作流。实验表明，该平台仅需少量精准标注的文献即可实现卓越的准确率。这一创新工具显著简化了从科学文献到结构化知识与数据的转化流程，有力推动了自然信息学领域的发展。
