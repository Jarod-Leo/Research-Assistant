# Fine-Tuning LLMs for Code Mutation: A New Era of Cyber Threats

链接: http://arxiv.org/abs/2410.22293v1

原文摘要:
Recent advancements in Large Language Models (LLMs) have significantly
improved their capabilities in natural language processing and code synthesis,
enabling more complex applications across different fields. This paper explores
the application of LLMs in the context of code mutation, a process where the
structure of program code is altered without changing its functionality.
Traditionally, code mutation has been employed to increase software robustness
in mission-critical applications. Additionally, mutation engines have been
exploited by malware developers to evade the signature-based detection methods
employed by malware detection systems. Existing code mutation engines, often
used by such threat actors, typically result in only limited variations in the
malware, which can still be identified through static code analysis. However,
the agility demonstrated by an LLM-based code synthesizer could significantly
change this threat landscape by allowing for more complex code mutations that
are not easily detected using static analysis. One can increase variations of
codes synthesized by a pre-trained LLM through fine-tuning and retraining. This
process is what we refer to as code mutation training. In this paper, we
propose a novel definition of code mutation training tailored for pre-trained
LLM-based code synthesizers and demonstrate this training on a lightweight
pre-trained model. Our approach involves restructuring (i.e., mutating) code at
the subroutine level, which allows for more manageable mutations while
maintaining the semantic integrity verified through unit testing. Our
experimental results illustrate the effectiveness of our approach in improving
code mutation capabilities of LLM-based program synthesizers in producing
varied and functionally correct code solutions, showcasing their potential to
transform the landscape of code mutation and the threats associated with it.

中文翻译:
近年来，大型语言模型（LLMs）在自然语言处理和代码合成领域的能力显著提升，推动了跨领域更复杂应用的发展。本文探讨了LLMs在代码变异中的应用——这一过程通过改变程序代码结构而不影响其功能实现。传统上，代码变异技术被用于增强关键任务应用中的软件鲁棒性，同时也被恶意软件开发者利用以规避基于特征签名的检测机制。现有由威胁行为体常用的代码变异引擎通常仅能产生有限变体，仍可通过静态代码分析识别。然而，基于LLM的代码合成器所展现的灵活性可能彻底改变这一威胁格局，其生成的复杂代码变异体将难以通过静态分析检测。

通过微调和再训练，可以显著增加预训练LLM合成代码的变异多样性，这一过程我们称之为代码变异训练。本文提出了一种专门针对预训练LLM代码合成器的代码变异训练新定义，并在轻量级预训练模型上进行了实证研究。我们的方法在子程序级别进行代码重构（即变异），在保持通过单元测试验证的语义完整性前提下，实现了更可控的变异操作。实验结果表明，该方法能有效提升基于LLM的程序合成器生成多样化且功能正确代码解决方案的能力，展现了其在重塑代码变异技术格局及相关威胁态势方面的潜力。
