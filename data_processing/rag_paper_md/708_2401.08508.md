# EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis

链接: http://arxiv.org/abs/2401.08508v1

原文摘要:
Sentiment analysis and emotion detection are important research topics in
natural language processing (NLP) and benefit many downstream tasks. With the
widespread application of LLMs, researchers have started exploring the
application of LLMs based on instruction-tuning in the field of sentiment
analysis. However, these models only focus on single aspects of affective
classification tasks (e.g. sentimental polarity or categorical emotions), and
overlook the regression tasks (e.g. sentiment strength or emotion intensity),
which leads to poor performance in downstream tasks. The main reason is the
lack of comprehensive affective instruction tuning datasets and evaluation
benchmarks, which cover various affective classification and regression tasks.
Moreover, although emotional information is useful for downstream tasks,
existing downstream datasets lack high-quality and comprehensive affective
annotations. In this paper, we propose EmoLLMs, the first series of
open-sourced instruction-following LLMs for comprehensive affective analysis
based on fine-tuning various LLMs with instruction data, the first multi-task
affective analysis instruction dataset (AAID) with 234K data samples based on
various classification and regression tasks to support LLM instruction tuning,
and a comprehensive affective evaluation benchmark (AEB) with 14 tasks from
various sources and domains to test the generalization ability of LLMs. We
propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various
affective instruction tasks. We compare our model with a variety of LLMs on
AEB, where our models outperform all other open-sourced LLMs, and surpass
ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve
the ChatGPT-level and GPT-4-level generalization capabilities on affective
analysis tasks, and demonstrates our models can be used as affective annotation
tools.

中文翻译:
情感分析与情绪检测是自然语言处理（NLP）领域的重要研究方向，对诸多下游任务具有显著价值。随着大语言模型（LLM）的广泛应用，研究者开始探索基于指令微调的LLM在情感分析领域的应用。然而现有模型仅关注情感分类任务的单一维度（如情感极性或离散情绪类别），而忽视了回归任务（如情感强度或情绪程度），导致其在下游任务中表现欠佳。究其原因，主要是缺乏覆盖多维度情感分类与回归任务的综合性指令微调数据集及评估基准。此外，尽管情感信息对下游任务具有重要价值，现有下游数据集普遍缺乏高质量、多维度的情感标注。

本文提出EmoLLMs系列开源模型，首次基于多类型LLM通过指令数据微调实现了综合性情感分析。我们构建了首个多任务情感分析指令数据集（AAID），涵盖23.4万条分类与回归任务样本以支持LLM指令微调；并创建了综合性情感评估基准（AEB），包含跨领域14项任务以测试模型泛化能力。通过AAID微调LLM得到的EmoLLMs系列模型，在AEB基准测试中全面超越其他开源模型，且在多数任务上优于ChatGPT和GPT-4。这表明EmoLLMs系列在情感分析任务上达到了ChatGPT和GPT-4级别的泛化能力，验证了其作为情感标注工具的有效性。
