# OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking

链接: http://arxiv.org/abs/2311.09758v1

原文摘要:
Large language models (LLMs) have revolutionized the landscape of Natural
Language Processing systems, but are computationally expensive. To reduce the
cost without sacrificing performance, previous studies have explored various
approaches to harness the potential of Small Language Models (SLMs) as
cost-effective alternatives to their larger counterparts. Driven by findings
that SLMs and LLMs exhibit complementary strengths in a structured knowledge
extraction task, this work presents a novel SLM/LLM routing framework designed
to improve computational efficiency and enhance task performance. First,
exemplar pools are created to represent the types of contexts where each LM
provides a more reliable answer, leveraging a sentence embedding fine-tuned so
that context similarity is close to dialogue state similarity. Then, during
inference, the k-nearest exemplars to the testing instance are retrieved, and
the instance is routed according to majority vote. In dialogue state tracking
tasks, the proposed routing framework enhances performance substantially
compared to relying solely on LLMs, while reducing the computational costs by
over 50%.

中文翻译:
大型语言模型（LLMs）彻底改变了自然语言处理系统的格局，但其计算成本高昂。为在不牺牲性能的前提下降低成本，先前研究探索了多种方法，试图挖掘小型语言模型（SLMs）作为高效替代方案的潜力。本研究基于SLMs与LLMs在结构化知识抽取任务中表现出互补优势的发现，提出了一种创新的SLM/LLM路由框架，旨在提升计算效率并增强任务表现。该框架首先构建示例池来表征每种语言模型能提供更可靠答案的上下文类型，通过微调句子嵌入使上下文相似度逼近对话状态相似度；随后在推理阶段检索测试实例的k近邻示例，根据多数表决机制进行路由决策。在对话状态跟踪任务中，该路由框架相比单纯依赖LLMs显著提升了性能，同时将计算成本降低了50%以上。
