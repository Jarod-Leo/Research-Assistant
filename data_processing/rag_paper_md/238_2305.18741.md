# Grokking of Hierarchical Structure in Vanilla Transformers

链接: http://arxiv.org/abs/2305.18741v1

原文摘要:
For humans, language production and comprehension is sensitive to the
hierarchical structure of sentences. In natural language processing, past work
has questioned how effectively neural sequence models like transformers capture
this hierarchical structure when generalizing to structurally novel inputs. We
show that transformer language models can learn to generalize hierarchically
after training for extremely long periods -- far beyond the point when
in-domain accuracy has saturated. We call this phenomenon \emph{structural
grokking}. On multiple datasets, structural grokking exhibits inverted U-shaped
scaling in model depth: intermediate-depth models generalize better than both
very deep and very shallow transformers. When analyzing the relationship
between model-internal properties and grokking, we find that optimal depth for
grokking can be identified using the tree-structuredness metric of
\citet{murty2023projections}. Overall, our work provides strong evidence that,
with extended training, vanilla transformers discover and use hierarchical
structure.

中文翻译:
对人类而言，语言生成与理解对句子的层次结构具有敏感性。在自然语言处理领域，先前研究曾质疑神经网络序列模型（如Transformer）在面对结构新颖的输入时，能否有效捕捉这种层次结构。本研究表明，经过极长时间训练后——远超过领域内准确率饱和的时间点——Transformer语言模型能够学会按层次结构进行泛化。我们将这种现象称为\emph{结构顿悟}。在多个数据集上，结构顿悟现象呈现倒U型深度缩放规律：中等深度的模型比极深或极浅的Transformer表现出更好的泛化能力。通过分析模型内部特性与顿悟现象的关系，我们发现\citet{murty2023projections}提出的树形结构化度量指标可识别出最优顿悟深度。总体而言，本研究提供了有力证据，表明经过延长训练后，标准Transformer模型能够发现并利用层次结构。
