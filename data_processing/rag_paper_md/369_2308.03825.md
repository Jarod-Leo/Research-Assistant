# "Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models

链接: http://arxiv.org/abs/2308.03825v1

原文摘要:
The misuse of large language models (LLMs) has drawn significant attention
from the general public and LLM vendors. One particular type of adversarial
prompt, known as jailbreak prompt, has emerged as the main attack vector to
bypass the safeguards and elicit harmful content from LLMs. In this paper,
employing our new framework JailbreakHub, we conduct a comprehensive analysis
of 1,405 jailbreak prompts spanning from December 2022 to December 2023. We
identify 131 jailbreak communities and discover unique characteristics of
jailbreak prompts and their major attack strategies, such as prompt injection
and privilege escalation. We also observe that jailbreak prompts increasingly
shift from online Web communities to prompt-aggregation websites and 28 user
accounts have consistently optimized jailbreak prompts over 100 days. To assess
the potential harm caused by jailbreak prompts, we create a question set
comprising 107,250 samples across 13 forbidden scenarios. Leveraging this
dataset, our experiments on six popular LLMs show that their safeguards cannot
adequately defend jailbreak prompts in all scenarios. Particularly, we identify
five highly effective jailbreak prompts that achieve 0.95 attack success rates
on ChatGPT (GPT-3.5) and GPT-4, and the earliest one has persisted online for
over 240 days. We hope that our study can facilitate the research community and
LLM vendors in promoting safer and regulated LLMs.

中文翻译:
大型语言模型（LLMs）的滥用问题已引发公众和厂商的高度关注。其中一类被称为"越狱提示"（jailbreak prompt）的对抗性提示，正成为绕过安全防护、诱导模型生成有害内容的主要攻击手段。本文通过自建的JailbreakHub分析框架，对2022年12月至2023年12月期间的1,405个越狱提示进行了系统性研究，识别出131个越狱社区，揭示了此类提示的独特特征及提示注入（prompt injection）、权限提升（privilege escalation）等核心攻击策略。研究发现，越狱提示的传播阵地正从网络社区向提示聚合网站转移，28个用户账号持续优化越狱提示超过100天。为评估潜在危害，我们构建了涵盖13类禁忌场景的107,250个测试样本集，在六大主流LLM上的实验表明：现有防护机制无法全面抵御越狱攻击，其中五个高效提示在ChatGPT（GPT-3.5）和GPT-4上的攻击成功率高达95%，最早出现的样本已存活240余天。本研究旨在助力学术界和厂商共同推进LLM的安全合规发展。  

（翻译说明：  
1. 专业术语处理："jailbreak prompt"译为行业通用表述"越狱提示"，"prompt injection"等术语保留英文原词并附加中文注释  
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如将实验方法部分重组为"通过...对...进行了..."的典型中文论文句式  
3. 数据呈现优化：将"1,405 jailbreak prompts"等数字转换为中文惯用的"1,405个"格式  
4. 被动语态转换："has been observed"等英文被动结构转为中文主动表述"研究发现"  
5. 学术风格保持：使用"揭示""构建""涵盖"等符合学术摘要特征的动词，结尾"旨在助力"体现研究目的）
