# A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient

链接: http://arxiv.org/abs/2505.04654v1

原文摘要:
Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly
evolved in recent years, showcasing remarkable capabilities in natural language
understanding and generation. However, these advancements also raise critical
ethical questions regarding safety, potential misuse, discrimination and
overall societal impact. This article provides a comparative analysis of the
ethical performance of various AI models, including the brand new
DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5
Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp)
and highlights the need for robust human oversight, especially in situations
with high stakes. Furthermore, we present a new metric for calculating harm in
LLMs called Relative Danger Coefficient (RDC).

中文翻译:
近年来，人工智能（AI）与大语言模型（LLM）快速发展，在自然语言理解与生成方面展现出卓越能力。然而这些技术进步也引发了关于安全性、潜在滥用、歧视及整体社会影响的关键伦理问题。本文对多个AI模型的伦理表现进行了对比分析，包括全新发布的DeepSeek-V3（含推理模块版与无推理模块版）、不同GPT变体（4o、3.5 Turbo、4 Turbo、o1/o3 mini）以及Gemini系列（1.5 flash、2.0 flash和2.0 flash exp），并强调在高风险场景中加强人工监督的必要性。此外，我们提出了一种名为"相对危险系数"（RDC）的新指标，用于量化大语言模型可能造成的危害程度。
