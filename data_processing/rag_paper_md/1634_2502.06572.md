# LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM

链接: http://arxiv.org/abs/2502.06572v1

原文摘要:
Large language models (LLMs), both proprietary and open-source, have
demonstrated remarkable capabilities across various natural language processing
tasks. However, they face significant limitations in legal reasoning tasks.
Proprietary models introduce data privacy risks and high inference costs, while
open-source models underperform due to insufficient legal domain training data.
To address these limitations, we study data generation for legal reasoning to
improve the legal reasoning performance of open-source LLMs with the help of
proprietary LLMs. This is challenging due to the lack of legal knowledge in
proprietary LLMs and the difficulty in verifying the generated data. We propose
KgDG, a knowledge-guided data generation framework for legal reasoning. Our
framework enables leveraging legal knowledge to enhance generation diversity
and introduces a refinement and verification process to ensure the quality of
generated data. Moreover, we expand the generated dataset to further enhance
the LLM reasoning capabilities. Using KgDG, we create a synthetic legal
reasoning dataset containing 50K high-quality examples. Our trained model
LawGPT outperforms existing legal-specific LLMs and achieves performance
comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and
LawGPT. Our code and resources is publicly available at
https://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation .

中文翻译:
大型语言模型（LLMs），无论是专有还是开源版本，已在各类自然语言处理任务中展现出卓越能力。然而它们在法律推理任务中存在显著局限：专有模型存在数据隐私风险和高昂推理成本，开源模型则因法律领域训练数据不足而表现欠佳。为解决这些问题，我们研究如何借助专有LLMs生成法律推理数据以提升开源模型的性能。这一研究面临双重挑战——专有LLMs缺乏法律专业知识，且生成数据的验证难度较高。为此，我们提出知识引导的法律推理数据生成框架KgDG，该框架通过注入法律知识增强生成多样性，并引入数据精炼与验证流程确保质量。此外，我们还扩展生成数据集以进一步提升LLMs的推理能力。基于KgDG构建的合成法律推理数据集包含5万条高质量样本，由此训练的法律专用模型LawGPT不仅超越现有同类模型，更达到与专有LLMs相媲美的性能，充分验证了KgDG框架与LawGPT模型的有效性。相关代码与资源已开源发布于https://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation。
