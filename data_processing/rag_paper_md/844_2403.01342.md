# LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems

链接: http://arxiv.org/abs/2403.01342v1

原文摘要:
In the rapidly evolving field of natural language processing, the translation
of linguistic descriptions into mathematical formulation of optimization
problems presents a formidable challenge, demanding intricate understanding and
processing capabilities from Large Language Models (LLMs). This study compares
prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and
one-shot settings for this task. Our findings show GPT-4's superior
performance, particularly in the one-shot scenario. A central part of this
research is the introduction of `LM4OPT,' a progressive fine-tuning framework
for Llama-2-7b that utilizes noisy embeddings and specialized datasets.
However, this research highlights a notable gap in the contextual understanding
capabilities of smaller models such as Llama-2-7b compared to larger
counterparts, especially in processing lengthy and complex input contexts. Our
empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4
surpasses the baseline performance established by previous research, achieving
an F1-score of 0.63, solely based on the problem description in natural
language, and without relying on any additional named entity information.
GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These
findings not only benchmark the current capabilities of LLMs in a novel
application area but also lay the groundwork for future improvements in
mathematical formulation of optimization problems from natural language input.

中文翻译:
在自然语言处理技术飞速发展的背景下，将语言描述转化为优化问题的数学表达是一项极具挑战性的任务，要求大型语言模型（LLMs）具备复杂的理解与处理能力。本研究对比了GPT-3.5、GPT-4和Llama-2-7b等主流LLM模型在零样本和单样本设置下的表现。结果显示GPT-4表现最优，尤其在单样本场景中。研究核心是提出"LM4OPT"框架——一个基于噪声嵌入和专用数据集对Llama-2-7b进行渐进式微调的系统。然而，研究发现Llama-2-7b等较小模型在处理长而复杂的输入上下文时，其语境理解能力与大型模型存在显著差距。通过NL4Opt数据集的实证研究表明，仅依靠自然语言问题描述（不借助任何额外命名实体信息），GPT-4以0.63的F1分数超越了既有研究的基线性能，GPT-3.5紧随其后，两者均优于经过微调的Llama-2-7b。这些发现不仅为LLMs在新应用领域的当前能力提供了基准，更为未来从自然语言输入生成优化问题数学表达的研究奠定了基础。
