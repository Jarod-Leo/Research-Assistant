# AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks

链接: http://arxiv.org/abs/2411.13757v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing
(NLP), excelling in tasks like text generation and summarization. However,
their increasing adoption in mission-critical applications raises concerns
about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,
enabled by fault injection methods such as Rowhammer, target model parameters
in memory, compromising both integrity and performance. Identifying critical
parameters for BFAs in the vast parameter space of LLMs poses significant
challenges. While prior research suggests transformer-based architectures are
inherently more robust to BFAs compared to traditional deep neural networks, we
challenge this assumption. For the first time, we demonstrate that as few as
three bit-flips can cause catastrophic performance degradation in an LLM with
billions of parameters. Current BFA techniques are inadequate for exploiting
this vulnerability due to the difficulty of efficiently identifying critical
parameters within the immense parameter space. To address this, we propose
AttentionBreaker, a novel framework tailored for LLMs that enables efficient
traversal of the parameter space to identify critical parameters. Additionally,
we introduce GenBFA, an evolutionary optimization strategy designed to refine
the search further, isolating the most critical bits for an efficient and
effective attack. Empirical results reveal the profound vulnerability of LLMs
to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of
total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result
in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to
0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings
underscore the effectiveness of AttentionBreaker in uncovering and exploiting
critical vulnerabilities within LLM architectures.

中文翻译:
大型语言模型（LLMs）彻底改变了自然语言处理（NLP）领域，在文本生成和摘要等任务中表现卓越。然而，随着其在关键任务应用中的广泛采用，基于硬件的威胁（尤其是比特翻转攻击/BFAs）引发了新的安全担忧。这类通过Rowhammer等故障注入方法实施的攻击会篡改内存中的模型参数，同时破坏模型完整性和性能。在LLMs庞大的参数空间中定位关键攻击目标存在巨大挑战。尽管现有研究认为基于Transformer的架构相比传统深度神经网络对BFAs具有固有鲁棒性，但我们质疑这一假设。我们首次证明：仅需翻转3个比特位（在具有数十亿参数的LLM中）即可导致性能灾难性下降。由于现有BFA技术难以在巨大参数空间中高效定位关键参数，当前尚无法有效利用这一漏洞。为此，我们提出专为LLMs设计的AttentionBreaker框架，能高效遍历参数空间以识别关键参数；同时开发GenBFA进化优化策略，通过精细化搜索定位最具破坏力的关键比特位。实验结果表明LLMs对AttentionBreaker存在严重脆弱性：例如在LLaMA3-8B-Instruct的8位量化（W8）模型中，仅翻转3个比特位（占总参数的4.129×10^-9%）就会导致性能全面崩溃——MMLU任务准确率从67.3%骤降至0%，Wikitext困惑度从12.6飙升至4.72×10^5。这些发现证实了AttentionBreaker在发掘和利用LLM架构关键漏洞方面的卓越效能。  

（翻译说明：  
1. 专业术语统一处理："bit-flip attacks"译为"比特翻转攻击"并首次出现标注英文缩写（BFAs）  
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如Rowhammer说明部分转为括号补充  
3. 数字规范转换：科学计数法保留原格式（4.129×10^-9%），百分数统一使用中文符号  
4. 被动语态转化："are inadequate"译为"尚无法"更符合中文主动表达  
5. 技术概念显化："evolutionary optimization strategy"译为"进化优化策略"并补充说明其功能  
6. 数据呈现优化：实验数据采用中文标点，保持与原文一致的精确性同时增强可读性）
