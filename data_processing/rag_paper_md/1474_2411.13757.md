# AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks

链接: http://arxiv.org/abs/2411.13757v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing
(NLP), excelling in tasks like text generation and summarization. However,
their increasing adoption in mission-critical applications raises concerns
about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,
enabled by fault injection methods such as Rowhammer, target model parameters
in memory, compromising both integrity and performance. Identifying critical
parameters for BFAs in the vast parameter space of LLMs poses significant
challenges. While prior research suggests transformer-based architectures are
inherently more robust to BFAs compared to traditional deep neural networks, we
challenge this assumption. For the first time, we demonstrate that as few as
three bit-flips can cause catastrophic performance degradation in an LLM with
billions of parameters. Current BFA techniques are inadequate for exploiting
this vulnerability due to the difficulty of efficiently identifying critical
parameters within the immense parameter space. To address this, we propose
AttentionBreaker, a novel framework tailored for LLMs that enables efficient
traversal of the parameter space to identify critical parameters. Additionally,
we introduce GenBFA, an evolutionary optimization strategy designed to refine
the search further, isolating the most critical bits for an efficient and
effective attack. Empirical results reveal the profound vulnerability of LLMs
to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of
total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result
in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to
0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings
underscore the effectiveness of AttentionBreaker in uncovering and exploiting
critical vulnerabilities within LLM architectures.

中文翻译:
大型语言模型（LLM）彻底改变了自然语言处理（NLP）领域，在文本生成和摘要等任务中表现卓越。然而，随着其在关键任务应用中的广泛部署，基于硬件的威胁——尤其是比特翻转攻击（BFA）——引发了新的安全担忧。这类通过Rowhammer等故障注入手段实施的攻击会篡改内存中的模型参数，同时破坏模型完整性和性能。面对LLM庞大的参数空间，如何精准定位关键攻击目标成为重大挑战。尽管现有研究认为基于Transformer的架构相比传统深度神经网络对BFA具有天然鲁棒性，但我们质疑这一假设。研究首次证实：仅需翻转3个比特位就能导致具有数十亿参数的LLM出现灾难性性能崩溃。当前BFA技术因难以在庞大参数空间中高效定位关键参数，尚无法有效利用这一漏洞。

为此，我们提出专为LLM设计的AttentionBreaker框架，通过创新方法高效遍历参数空间以识别关键参数。进一步开发了GenBFA进化优化策略，可精确定位最具破坏力的关键比特位，实现高效攻击。实证研究揭示了LLM面对AttentionBreaker的极端脆弱性：在LLaMA3-8B-Instruct的8位量化（W8）模型中，仅翻转3个比特位（占总参数的4.129×10^-9%）就导致MMLU任务准确率从67.3%暴跌至0%，Wikitext困惑度从12.6激增至4.72×10^5。这些发现证实了AttentionBreaker在挖掘和利用LLM架构关键漏洞方面的卓越效能。
