# Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations

链接: http://arxiv.org/abs/2404.05415v1

原文摘要:
In acupuncture therapy, the accurate location of acupoints is essential for
its effectiveness. The advanced language understanding capabilities of large
language models (LLMs) like Generative Pre-trained Transformers (GPT) present a
significant opportunity for extracting relations related to acupoint locations
from textual knowledge sources. This study aims to compare the performance of
GPT with traditional deep learning models (Long Short-Term Memory (LSTM) and
Bidirectional Encoder Representations from Transformers for Biomedical Text
Mining (BioBERT)) in extracting acupoint-related location relations and assess
the impact of pretraining and fine-tuning on GPT's performance. We utilized the
World Health Organization Standard Acupuncture Point Locations in the Western
Pacific Region (WHO Standard) as our corpus, which consists of descriptions of
361 acupoints. Five types of relations ('direction_of,' 'distance_of,'
'part_of,' 'near_acupoint,' and 'located_near') (n= 3,174) between acupoints
were annotated. Five models were compared: BioBERT, LSTM, pre-trained GPT-3.5,
fine-tuned GPT-3.5, as well as pre-trained GPT-4. Performance metrics included
micro-average exact match precision, recall, and F1 scores. Our results
demonstrate that fine-tuned GPT-3.5 consistently outperformed other models in
F1 scores across all relation types. Overall, it achieved the highest
micro-average F1 score of 0.92. This study underscores the effectiveness of
LLMs like GPT in extracting relations related to acupoint locations, with
implications for accurately modeling acupuncture knowledge and promoting
standard implementation in acupuncture training and practice. The findings also
contribute to advancing informatics applications in traditional and
complementary medicine, showcasing the potential of LLMs in natural language
processing.

中文翻译:
在针灸治疗中，准确定位腧穴是确保疗效的关键。以生成式预训练转换器（GPT）为代表的大语言模型（LLM）凭借其卓越的语言理解能力，为从文本知识源中提取腧穴定位相关关系提供了重要机遇。本研究旨在比较GPT与传统深度学习模型（长短期记忆网络LSTM和生物医学文本挖掘双向编码器表征模型BioBERT）在提取腧穴定位关系中的表现，并评估预训练与微调对GPT性能的影响。我们以《世界卫生组织西太平洋地区标准针灸经穴定位》为语料库，该文献包含361个腧穴的描述文本。研究标注了腧穴间五种关系类型（"方向"、"距离"、"所属部位"、"邻近腧穴"和"毗邻结构"）（n=3,174），对比了BioBERT、LSTM、预训练GPT-3.5、微调GPT-3.5及预训练GPT-4五种模型的表现，采用微观平均精确匹配的精确率、召回率和F1值作为评价指标。结果显示，经过微调的GPT-3.5在所有关系类型的F1值上均优于其他模型，总体微观平均F1值最高达0.92。本研究证实了GPT等大语言模型在提取腧穴定位关系方面的有效性，对准确构建针灸知识模型、促进针灸教学与临床实践规范化具有重要意义。研究结果同时推动了传统医学与补充医学信息学应用的发展，展现了大语言模型在自然语言处理领域的潜力。
