# Extractive Summarization via ChatGPT for Faithful Summary Generation

链接: http://arxiv.org/abs/2304.04193v1

原文摘要:
Extractive summarization is a crucial task in natural language processing
that aims to condense long documents into shorter versions by directly
extracting sentences. The recent introduction of large language models has
attracted significant interest in the NLP community due to its remarkable
performance on a wide range of downstream tasks. This paper first presents a
thorough evaluation of ChatGPT's performance on extractive summarization and
compares it with traditional fine-tuning methods on various benchmark datasets.
Our experimental analysis reveals that ChatGPT exhibits inferior extractive
summarization performance in terms of ROUGE scores compared to existing
supervised systems, while achieving higher performance based on LLM-based
evaluation metrics. In addition, we explore the effectiveness of in-context
learning and chain-of-thought reasoning for enhancing its performance.
Furthermore, we find that applying an extract-then-generate pipeline with
ChatGPT yields significant performance improvements over abstractive baselines
in terms of summary faithfulness. These observations highlight potential
directions for enhancing ChatGPT's capabilities in faithful summarization using
two-stage approaches.

中文翻译:
抽取式摘要作为自然语言处理中的核心任务，旨在通过直接选取原文句子将长文档压缩为简洁版本。随着大语言模型的兴起，其在下游任务中的卓越表现引发了自然语言处理领域的广泛关注。本文首次系统评估了ChatGPT在抽取式摘要任务上的表现，并在多个基准数据集上与传统的微调方法进行对比。实验分析表明，基于ROUGE指标，ChatGPT的抽取摘要性能逊于现有监督式系统，但采用基于大语言模型的评估指标时则展现出优势。此外，我们探究了情境学习与思维链推理对提升其性能的有效性。研究发现，采用"先抽取后生成"的流程策略，ChatGPT在摘要忠实度方面较生成式基线模型取得显著提升。这些发现为通过两阶段方法增强ChatGPT忠实摘要能力指明了潜在优化方向。
