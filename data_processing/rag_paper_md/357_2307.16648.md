# LLMs4OL: Large Language Models for Ontology Learning

链接: http://arxiv.org/abs/2307.16648v2

原文摘要:
We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)
for Ontology Learning (OL). LLMs have shown significant advancements in natural
language processing, demonstrating their ability to capture complex language
patterns in different knowledge domains. Our LLMs4OL paradigm investigates the
following hypothesis: \textit{Can LLMs effectively apply their language pattern
capturing capability to OL, which involves automatically extracting and
structuring knowledge from natural language text?} To test this hypothesis, we
conduct a comprehensive evaluation using the zero-shot prompting method. We
evaluate nine different LLM model families for three main OL tasks: term
typing, taxonomy discovery, and extraction of non-taxonomic relations.
Additionally, the evaluations encompass diverse genres of ontological
knowledge, including lexicosemantic knowledge in WordNet, geographical
knowledge in GeoNames, and medical knowledge in UMLS.

中文翻译:
我们提出LLMs4OL方法，利用大语言模型（LLMs）进行本体学习（OL）。大语言模型在自然语言处理领域展现出显著进步，其捕获不同知识领域复杂语言模式的能力已得到验证。我们的LLMs4OL范式旨在探究以下假设：\textit{大语言模型能否将其语言模式捕获能力有效应用于本体学习？该任务涉及从自然语言文本中自动提取并结构化知识。}为验证这一假设，我们采用零样本提示方法进行全面评估，针对三类核心本体学习任务（术语类型识别、分类体系发现、非分类关系抽取）测试了九个不同的大语言模型家族。评估还涵盖多领域本体知识，包括WordNet中的词汇语义知识、GeoNames中的地理知识以及UMLS中的医学知识。

（翻译说明：
1. 专业术语处理：采用"大语言模型"统一LLMs的译法，保持全文一致性；OL译为"本体学习"符合计算机领域术语规范
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"demonstrating..."独立译为验证性短句
3. 被动语态转换："are evaluated"等被动式转为中文主动态"测试了..."
4. 斜体强调处理：保留原文\textit{}的强调格式，使用中文引号「」标注假设内容
5. 列表信息整合：将三个OL tasks用中文顿号连接，保持专业性与可读性平衡
6. 知识库名称保留：WordNet/GeoNames/UMLS等专有名词不翻译，符合学术惯例）
