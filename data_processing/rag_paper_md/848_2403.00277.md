# Gender Bias in Large Language Models across Multiple Languages

链接: http://arxiv.org/abs/2403.00277v1

原文摘要:
With the growing deployment of large language models (LLMs) across various
applications, assessing the influence of gender biases embedded in LLMs becomes
crucial. The topic of gender bias within the realm of natural language
processing (NLP) has gained considerable focus, particularly in the context of
English. Nonetheless, the investigation of gender bias in languages other than
English is still relatively under-explored and insufficiently analyzed. In this
work, We examine gender bias in LLMs-generated outputs for different languages.
We use three measurements: 1) gender bias in selecting descriptive words given
the gender-related context. 2) gender bias in selecting gender-related pronouns
(she/he) given the descriptive words. 3) gender bias in the topics of
LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs
in various languages using our three measurement methods. Our findings revealed
significant gender biases across all the languages we examined.

中文翻译:
随着大型语言模型（LLMs）在各领域的广泛应用，评估其内嵌性别偏见的影响变得至关重要。自然语言处理（NLP）领域中的性别偏见议题已受到广泛关注，尤其在英语语境下。然而，针对非英语语言的性别偏见研究仍相对匮乏且分析不足。本研究通过三种测量方法系统考察了多语言LLMs生成文本中的性别偏见：1）在性别相关语境下选择描述性词汇时的偏见；2）根据描述性词汇选择性别关联代词（她/他）时的偏见；3）LLM生成对话主题中隐含的偏见。基于对GPT系列模型多语言输出的实验分析，我们发现所有被检测语言均存在显著的性别偏见现象。
