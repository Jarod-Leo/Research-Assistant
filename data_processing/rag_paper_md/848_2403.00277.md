# Gender Bias in Large Language Models across Multiple Languages

链接: http://arxiv.org/abs/2403.00277v1

原文摘要:
With the growing deployment of large language models (LLMs) across various
applications, assessing the influence of gender biases embedded in LLMs becomes
crucial. The topic of gender bias within the realm of natural language
processing (NLP) has gained considerable focus, particularly in the context of
English. Nonetheless, the investigation of gender bias in languages other than
English is still relatively under-explored and insufficiently analyzed. In this
work, We examine gender bias in LLMs-generated outputs for different languages.
We use three measurements: 1) gender bias in selecting descriptive words given
the gender-related context. 2) gender bias in selecting gender-related pronouns
(she/he) given the descriptive words. 3) gender bias in the topics of
LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs
in various languages using our three measurement methods. Our findings revealed
significant gender biases across all the languages we examined.

中文翻译:
随着大语言模型（LLM）在各领域的广泛应用，评估其内隐性别偏见的影响变得至关重要。自然语言处理（NLP）领域的性别偏见研究已获得广泛关注，但现有成果主要集中在英语语境。相比之下，非英语语言的性别偏见研究仍存在探索不足、分析欠缺的问题。本研究通过三种测量方法系统考察了多语言环境下LLM生成文本的性别偏见：1）在性别相关语境中选择描述性词语时表现的偏见；2）根据描述性词语选择性别相关代词（她/他）时呈现的偏见；3）LLM生成对话主题中存在的偏见。基于对GPT系列模型多语言输出的实验分析，我们发现所有被检测语言均存在显著的性别偏见现象。
