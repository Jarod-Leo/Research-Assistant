# FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models

链接: http://arxiv.org/abs/2308.09975v1

原文摘要:
Large language models have demonstrated outstanding performance in various
natural language processing tasks, but their security capabilities in the
financial domain have not been explored, and their performance on complex tasks
like financial agent remains unknown. This paper presents FinEval, a benchmark
designed to evaluate LLMs' financial domain knowledge and practical abilities.
The dataset contains 8,351 questions categorized into four different key areas:
Financial Academic Knowledge, Financial Industry Knowledge, Financial Security
Knowledge, and Financial Agent. Financial Academic Knowledge comprises 4,661
multiple-choice questions spanning 34 subjects such as finance and economics.
Financial Industry Knowledge contains 1,434 questions covering practical
scenarios like investment research. Financial Security Knowledge assesses
models through 1,640 questions on topics like application security and
cryptography. Financial Agent evaluates tool usage and complex reasoning with
616 questions. FinEval has multiple evaluation settings, including zero-shot,
five-shot with chain-of-thought, and assesses model performance using objective
and subjective criteria. Our results show that Claude 3.5-Sonnet achieves the
highest weighted average score of 72.9 across all financial domain categories
under zero-shot setting. Our work provides a comprehensive benchmark closely
aligned with Chinese financial domain.

中文翻译:
大语言模型在各类自然语言处理任务中展现出卓越性能，但其在金融领域的安全能力尚未得到充分探索，对于金融智能体等复杂任务的适用性仍不明确。本研究提出FinEval评估基准，旨在系统检验大模型在金融领域的知识储备与实践能力。该数据集包含8,351道题目，划分为四大核心维度：金融学术知识（含4,661道涵盖金融经济等34门学科的选择题）、金融实务知识（含1,434道投资研究等实际场景题）、金融安全知识（含1,640道应用安全与密码学等题型）以及金融智能体（含616道工具调用与复杂推理题）。FinEval设置零样本、五样本思维链等多种评测模式，采用客观题准确率与主观题专家评分相结合的评价体系。实验结果表明，Claude 3.5-Sonnet在零样本设定下以72.9%的加权平均分位居金融全领域榜首。本工作构建了与中国金融领域深度契合的综合性评测基准。
