# Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges

链接: http://arxiv.org/abs/2403.02990v1

原文摘要:
In the rapidly evolving field of large language models (LLMs), data
augmentation (DA) has emerged as a pivotal technique for enhancing model
performance by diversifying training examples without the need for additional
data collection. This survey explores the transformative impact of LLMs on DA,
particularly addressing the unique challenges and opportunities they present in
the context of natural language processing (NLP) and beyond. From both data and
learning perspectives, we examine various strategies that utilize LLMs for data
augmentation, including a novel exploration of learning paradigms where
LLM-generated data is used for diverse forms of further training. Additionally,
this paper highlights the primary open challenges faced in this domain, ranging
from controllable data augmentation to multi-modal data augmentation. This
survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve
as a comprehensive guide for researchers and practitioners.

中文翻译:
在快速演进的大语言模型（LLM）领域，数据增强（DA）已成为提升模型性能的关键技术——它通过多样化训练样本而无需额外数据收集。本综述探讨了LLM对数据增强的变革性影响，特别关注其在自然语言处理（NLP）及其他领域带来的独特挑战与机遇。从数据和学习的双重视角，我们系统分析了利用LLM进行数据增强的多种策略，包括创新性地探索以LLM生成数据支持多样化进阶训练的学习范式。此外，本文还揭示了该领域当前面临的核心开放挑战，涵盖可控数据增强到多模态数据增强等方向。本综述不仅阐明了LLM引发的数据增强范式转变，更致力于为研究者和实践者提供一份全面指南。
