# Adapting Sentence Transformers for the Aviation Domain

链接: http://arxiv.org/abs/2305.09556v1

原文摘要:
Learning effective sentence representations is crucial for many Natural
Language Processing (NLP) tasks, including semantic search, semantic textual
similarity (STS), and clustering. While multiple transformer models have been
developed for sentence embedding learning, these models may not perform
optimally when dealing with specialized domains like aviation, which has unique
characteristics such as technical jargon, abbreviations, and unconventional
grammar. Furthermore, the absence of labeled datasets makes it difficult to
train models specifically for the aviation domain. To address these challenges,
we propose a novel approach for adapting sentence transformers for the aviation
domain. Our method is a two-stage process consisting of pre-training followed
by fine-tuning. During pre-training, we use Transformers and Sequential
Denoising AutoEncoder (TSDAE) with aviation text data as input to improve the
initial model performance. Subsequently, we fine-tune our models using a
Natural Language Inference (NLI) dataset in the Sentence Bidirectional Encoder
Representations from Transformers (SBERT) architecture to mitigate overfitting
issues. Experimental results on several downstream tasks show that our adapted
sentence transformers significantly outperform general-purpose transformers,
demonstrating the effectiveness of our approach in capturing the nuances of the
aviation domain. Overall, our work highlights the importance of domain-specific
adaptation in developing high-quality NLP solutions for specialized industries
like aviation.

中文翻译:
学习有效的句子表征对于语义搜索、语义文本相似度（STS）和聚类等众多自然语言处理（NLP）任务至关重要。尽管目前已开发出多种用于句子嵌入学习的Transformer模型，但这些模型在处理航空等专业领域时可能表现欠佳，因为该领域具有技术术语、缩略语和非传统语法等独特特征。此外，标注数据集的缺失使得专门针对航空领域训练模型变得尤为困难。为解决这些挑战，我们提出了一种新颖的句子Transformer航空领域适配方法。该方法采用预训练与微调相结合的两阶段流程：在预训练阶段，我们以航空文本数据作为输入，采用Transformer与序列去噪自编码器（TSDAE）技术提升初始模型性能；随后在基于Transformer的双向编码器句子表征（SBERT）架构中，利用自然语言推理（NLI）数据集进行微调以缓解过拟合问题。多个下游任务的实验结果表明，经我们适配的句子Transformer模型显著优于通用Transformer模型，有效验证了该方法在捕捉航空领域语言特性方面的优越性。本研究揭示了领域适配对于航空等专业行业开发高质量NLP解决方案的重要性。
