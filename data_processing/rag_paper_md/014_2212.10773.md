# MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning

链接: http://arxiv.org/abs/2212.10773v1

原文摘要:
Instruction tuning, a new learning paradigm that fine-tunes pre-trained
language models on tasks specified through instructions, has shown promising
zero-shot performance on various natural language processing tasks. However, it
has yet to be explored for vision and multimodal tasks. In this work, we
introduce MUL-TIINSTRUCT, the first multimodal instruction tuning benchmark
dataset that consists of 62 diverse multimodal tasks in a unified seq-to-seq
format covering 10 broad categories. The tasks are derived from 21 existing
open-source datasets and each task is equipped with 5 expert-written
instructions. We take OFA as the base pre-trained model for multimodal
instruction tuning, and to further improve its zero-shot performance, we
explore multiple transfer learning strategies to leverage the large-scale
NATURAL INSTRUCTIONS dataset. Experimental results demonstrate strong zero-shot
performance on various unseen multimodal tasks and the benefit of transfer
learning from a text-only instruction dataset. We also design a new evaluation
metric - Sensitivity, to evaluate how sensitive the model is to the variety of
instructions. Our results indicate that fine-tuning the model on a diverse set
of tasks and instructions leads to a reduced sensitivity to variations in
instructions for each task.

中文翻译:
指令调优作为一种新兴学习范式，通过在任务指令指导下微调预训练语言模型，已在各类自然语言处理任务中展现出优异的零样本性能。然而，该范式在视觉与多模态任务领域的应用尚未得到充分探索。本研究提出首个多模态指令调优基准数据集MUL-TIINSTRUCT，涵盖10大类别共62项多样化多模态任务，所有任务均以统一的序列到序列格式呈现。这些任务源自21个开源数据集，每条任务配备5条专家撰写的指令文本。我们选用OFA作为多模态指令调优的基础预训练模型，并探索多种迁移学习策略以利用大规模纯文本指令数据集NATURAL INSTRUCTIONS来提升零样本性能。实验结果表明，模型在未见过的多模态任务上表现出强大的零样本能力，且文本指令数据的迁移学习带来显著增益。我们创新性地提出"敏感度"评估指标，用于衡量模型对指令多样性的适应能力。研究发现，在多样化任务和指令集上进行微调，能有效降低模型对单任务指令变化的敏感性。
