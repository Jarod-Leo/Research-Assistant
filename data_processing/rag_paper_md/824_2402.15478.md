# Transformers are Expressive, But Are They Expressive Enough for Regression?

链接: http://arxiv.org/abs/2402.15478v1

原文摘要:
Transformers have become pivotal in Natural Language Processing,
demonstrating remarkable success in applications like Machine Translation and
Summarization. Given their widespread adoption, several works have attempted to
analyze the expressivity of Transformers. Expressivity of a neural network is
the class of functions it can approximate. A neural network is fully expressive
if it can act as a universal function approximator. We attempt to analyze the
same for Transformers. Contrary to existing claims, our findings reveal that
Transformers struggle to reliably approximate smooth functions, relying on
piecewise constant approximations with sizable intervals. The central question
emerges as: ''Are Transformers truly Universal Function Approximators?'' To
address this, we conduct a thorough investigation, providing theoretical
insights and supporting evidence through experiments. Theoretically, we prove
that Transformer Encoders cannot approximate smooth functions. Experimentally,
we complement our theory and show that the full Transformer architecture cannot
approximate smooth functions. By shedding light on these challenges, we
advocate a refined understanding of Transformers' capabilities. Code Link:
https://github.com/swaroop-nath/transformer-expressivity.

中文翻译:
Transformer模型已成为自然语言处理领域的核心支柱，在机器翻译与文本摘要等任务中展现出卓越性能。鉴于其广泛应用，已有诸多研究尝试分析Transformer的表达能力。神经网络表达能力指的是其能够逼近的函数类别——若一个神经网络可作为通用函数逼近器，则称其具备完全表达能力。本文针对Transformer模型展开了相同维度的分析。与现有论断相反，我们的研究发现：Transformer难以可靠地逼近光滑函数，只能依赖具有较大间隔的分段常数近似。这引出了核心问题："Transformer是否确为通用函数逼近器？"为此，我们通过理论论证与实验验证展开了系统研究。理论上，我们证明了Transformer编码器无法逼近光滑函数；实验方面则进一步验证完整Transformer架构同样存在此局限。通过揭示这些挑战，我们主张学界应重新审视Transformer的能力边界。代码仓库：https://github.com/swaroop-nath/transformer-expressivity。
