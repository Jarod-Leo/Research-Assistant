# SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction

链接: http://arxiv.org/abs/2410.08669v1

原文摘要:
Predicting the future motion of surrounding agents is essential for
autonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed
environments. However, the scarcity of large-scale driving datasets has
hindered the development of robust and generalizable motion prediction models,
limiting their ability to capture complex interactions and road geometries.
Inspired by recent advances in natural language processing (NLP) and computer
vision (CV), self-supervised learning (SSL) has gained significant attention in
the motion prediction community for learning rich and transferable scene
representations. Nonetheless, existing pre-training methods for motion
prediction have largely focused on specific model architectures and single
dataset, limiting their scalability and generalizability. To address these
challenges, we propose SmartPretrain, a general and scalable SSL framework for
motion prediction that is both model-agnostic and dataset-agnostic. Our
approach integrates contrastive and reconstructive SSL, leveraging the
strengths of both generative and discriminative paradigms to effectively
represent spatiotemporal evolution and interactions without imposing
architectural constraints. Additionally, SmartPretrain employs a
dataset-agnostic scenario sampling strategy that integrates multiple datasets,
enhancing data volume, diversity, and robustness. Extensive experiments on
multiple datasets demonstrate that SmartPretrain consistently improves the
performance of state-of-the-art prediction models across datasets, data splits
and main metrics. For instance, SmartPretrain significantly reduces the
MissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's
effectiveness as a unified, scalable solution for motion prediction, breaking
free from the limitations of the small-data regime. Codes are available at
https://github.com/youngzhou1999/SmartPretrain

中文翻译:
预测周围智能体的未来运动轨迹对于自动驾驶车辆（AVs）在动态人机混合环境中安全运行至关重要。然而，大规模驾驶数据集的稀缺性阻碍了鲁棒且泛化性强的运动预测模型的发展，限制了其捕捉复杂交互与道路几何特征的能力。受自然语言处理（NLP）和计算机视觉（CV）领域最新进展的启发，自监督学习（SSL）在运动预测领域获得了广泛关注，因其能学习丰富且可迁移的场景表征。但现有运动预测预训练方法多局限于特定模型架构和单一数据集，制约了其扩展性与泛化能力。

为此，我们提出SmartPretrain——一个模型无关且数据集无关的通用可扩展SSL框架。该方法融合对比式与重构式自监督学习，结合生成式与判别式范式的优势，在不强加架构约束的前提下有效表征时空演化与交互特征。此外，SmartPretrain采用数据集无关的场景采样策略，通过整合多源数据集提升数据规模、多样性与鲁棒性。在多数据集上的大量实验表明，SmartPretrain能持续提升前沿预测模型在不同数据集、数据划分和核心指标上的性能。例如，该方法使Forecast-MAE的MissRate显著降低10.6%。这些结果验证了SmartPretrain作为突破小数据局限的统一可扩展解决方案的有效性。代码已开源于https://github.com/youngzhou1999/SmartPretrain。
