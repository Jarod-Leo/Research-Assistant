# Transformers versus LSTMs for electronic trading

链接: http://arxiv.org/abs/2309.11400v1

原文摘要:
With the rapid development of artificial intelligence, long short term memory
(LSTM), one kind of recurrent neural network (RNN), has been widely applied in
time series prediction.
  Like RNN, Transformer is designed to handle the sequential data. As
Transformer achieved great success in Natural Language Processing (NLP),
researchers got interested in Transformer's performance on time series
prediction, and plenty of Transformer-based solutions on long time series
forecasting have come out recently. However, when it comes to financial time
series prediction, LSTM is still a dominant architecture. Therefore, the
question this study wants to answer is: whether the Transformer-based model can
be applied in financial time series prediction and beat LSTM.
  To answer this question, various LSTM-based and Transformer-based models are
compared on multiple financial prediction tasks based on high-frequency limit
order book data. A new LSTM-based model called DLSTM is built and new
architecture for the Transformer-based model is designed to adapt for financial
prediction. The experiment result reflects that the Transformer-based model
only has the limited advantage in absolute price sequence prediction. The
LSTM-based models show better and more robust performance on difference
sequence prediction, such as price difference and price movement.

中文翻译:
随着人工智能技术的快速发展，长短期记忆网络（LSTM）作为循环神经网络（RNN）的一种，已在时间序列预测领域获得广泛应用。

与RNN类似，Transformer架构同样专为处理序列数据而设计。当Transformer在自然语言处理（NLP）领域取得巨大成功后，研究者们开始关注其在时间序列预测中的表现，近期涌现出大量基于Transformer的长序列预测方案。然而在金融时间序列预测领域，LSTM仍占据主导地位。因此，本研究旨在探讨：基于Transformer的模型能否应用于金融时间序列预测并超越LSTM？

为解答这一问题，我们基于高频限价订单簿数据，在多种金融预测任务中对各类LSTM模型与Transformer模型进行了系统比较。研究不仅构建了新型LSTM模型DLSTM，还针对金融预测特点设计了Transformer模型的新架构。实验结果表明：Transformer模型仅在绝对价格序列预测中具有有限优势，而在价格差值、价格变动等差分序列预测任务中，基于LSTM的模型展现出更优且更稳健的性能。
