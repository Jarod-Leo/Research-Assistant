# Transformers versus LSTMs for electronic trading

链接: http://arxiv.org/abs/2309.11400v1

原文摘要:
With the rapid development of artificial intelligence, long short term memory
(LSTM), one kind of recurrent neural network (RNN), has been widely applied in
time series prediction.
  Like RNN, Transformer is designed to handle the sequential data. As
Transformer achieved great success in Natural Language Processing (NLP),
researchers got interested in Transformer's performance on time series
prediction, and plenty of Transformer-based solutions on long time series
forecasting have come out recently. However, when it comes to financial time
series prediction, LSTM is still a dominant architecture. Therefore, the
question this study wants to answer is: whether the Transformer-based model can
be applied in financial time series prediction and beat LSTM.
  To answer this question, various LSTM-based and Transformer-based models are
compared on multiple financial prediction tasks based on high-frequency limit
order book data. A new LSTM-based model called DLSTM is built and new
architecture for the Transformer-based model is designed to adapt for financial
prediction. The experiment result reflects that the Transformer-based model
only has the limited advantage in absolute price sequence prediction. The
LSTM-based models show better and more robust performance on difference
sequence prediction, such as price difference and price movement.

中文翻译:
随着人工智能的飞速发展，作为循环神经网络（RNN）变体的长短期记忆网络（LSTM）在时间序列预测领域得到广泛应用。与RNN类似，Transformer架构同样为处理序列数据而设计。当Transformer在自然语言处理（NLP）领域取得巨大成功后，研究者们开始关注其在时间序列预测中的表现，近期涌现出大量基于Transformer的长序列预测方案。然而在金融时间序列预测领域，LSTM仍占据主导地位。因此，本研究旨在探讨：基于Transformer的模型能否应用于金融时间序列预测并超越LSTM？

为解答这一问题，本研究基于高频限价订单簿数据，在多种金融预测任务中对不同LSTM模型和Transformer模型进行对比。我们构建了新型LSTM模型DLSTM，并为Transformer模型设计了适配金融预测任务的新架构。实验结果表明，Transformer模型仅在绝对价格序列预测中具有有限优势；而在价格差值、价格变动等差分序列预测任务中，基于LSTM的模型展现出更优且更稳健的性能。
