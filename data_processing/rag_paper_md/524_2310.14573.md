# Exploring the Boundaries of GPT-4 in Radiology

链接: http://arxiv.org/abs/2310.14573v1

原文摘要:
The recent success of general-domain large language models (LLMs) has
significantly changed the natural language processing paradigm towards a
unified foundation model across domains and applications. In this paper, we
focus on assessing the performance of GPT-4, the most capable LLM so far, on
the text-based applications for radiology reports, comparing against
state-of-the-art (SOTA) radiology-specific models. Exploring various prompting
strategies, we evaluated GPT-4 on a diverse range of common radiology tasks and
we found GPT-4 either outperforms or is on par with current SOTA radiology
models. With zero-shot prompting, GPT-4 already obtains substantial gains
($\approx$ 10% absolute improvement) over radiology models in temporal sentence
similarity classification (accuracy) and natural language inference ($F_1$).
For tasks that require learning dataset-specific style or schema (e.g. findings
summarisation), GPT-4 improves with example-based prompting and matches
supervised SOTA. Our extensive error analysis with a board-certified
radiologist shows GPT-4 has a sufficient level of radiology knowledge with only
occasional errors in complex context that require nuanced domain knowledge. For
findings summarisation, GPT-4 outputs are found to be overall comparable with
existing manually-written impressions.

中文翻译:
通用领域大语言模型（LLMs）近期的突破性进展，显著改变了自然语言处理范式，推动其向跨领域、跨应用的统一基础模型方向发展。本文聚焦于评估当前最先进的GPT-4在基于文本的放射学报告应用中的表现，并与该领域专用模型进行对比研究。通过探索多种提示策略，我们在多项常见放射学任务上测试GPT-4后发现：其性能要么超越现有最佳放射学模型，要么与之持平。在零样本提示条件下，GPT-4在时序句子相似性分类（准确率）和自然语言推理（F1值）任务上已显著领先放射学专用模型（绝对提升约10%）。对于需要学习数据集特定风格或架构的任务（如检查结果摘要生成），采用示例提示后GPT-4可达到监督学习最佳模型的水平。我们与执业放射科医师联合开展的误差分析表明，GPT-4具备充分的放射学知识储备，仅在需要微妙领域知识的复杂情境下偶现错误。在检查结果摘要任务中，GPT-4生成内容与人工撰写的印象报告总体具有可比性。
