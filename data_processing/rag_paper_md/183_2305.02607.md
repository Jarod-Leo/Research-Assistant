# DN at SemEval-2023 Task 12: Low-Resource Language Text Classification via Multilingual Pretrained Language Model Fine-tuning

链接: http://arxiv.org/abs/2305.02607v1

原文摘要:
In recent years, sentiment analysis has gained significant importance in
natural language processing. However, most existing models and datasets for
sentiment analysis are developed for high-resource languages, such as English
and Chinese, leaving low-resource languages, particularly African languages,
largely unexplored. The AfriSenti-SemEval 2023 Shared Task 12 aims to fill this
gap by evaluating sentiment analysis models on low-resource African languages.
In this paper, we present our solution to the shared task, where we employed
different multilingual XLM-R models with classification head trained on various
data, including those retrained in African dialects and fine-tuned on target
languages. Our team achieved the third-best results in Subtask B, Track 16:
Multilingual, demonstrating the effectiveness of our approach. While our model
showed relatively good results on multilingual data, it performed poorly in
some languages. Our findings highlight the importance of developing more
comprehensive datasets and models for low-resource African languages to advance
sentiment analysis research. We also provided the solution on the github
repository.

中文翻译:
近年来，情感分析在自然语言处理领域的重要性日益凸显。然而现有大多数情感分析模型和数据集均针对英语、汉语等高资源语言开发，致使低资源语言（尤其是非洲语言）的研究长期处于空白状态。AfriSenti-SemEval 2023共享任务12通过评估非洲低资源语言的情感分析模型，致力于填补这一研究缺口。本文阐述了我们在该任务中的解决方案：我们采用多种经过非洲方言重训练和目标语言微调的多语言XLM-R分类模型进行实验。研究团队在子任务B（赛道16：多语言）中取得了第三名的成绩，验证了该方法的有效性。尽管模型在多语言数据上表现良好，但在部分语言中仍存在性能不足的问题。这一发现凸显了构建更全面的非洲低资源语言数据集和模型对推进情感分析研究的关键意义。相关解决方案已发布于GitHub代码库。
