# Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers

链接: http://arxiv.org/abs/2411.01645v1

原文摘要:
Feature engineering is crucial for optimizing machine learning model
performance, particularly in tabular data classification tasks. Leveraging
advancements in natural language processing, this study presents a systematic
approach to enrich tabular datasets with features derived from large language
model embeddings. Through a comprehensive ablation study on diverse datasets,
we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,
including Random Forest, XGBoost, and CatBoost. Results indicate that
integrating embeddings with traditional numerical and categorical features
often enhances predictive performance, especially on datasets with class
imbalance or limited features and samples, such as UCI Adult, Heart Disease,
Titanic, and Pima Indian Diabetes, with improvements particularly notable in
XGBoost and CatBoost classifiers. Additionally, feature importance analysis
reveals that LLM-derived features frequently rank among the most impactful for
the predictions. This study provides a structured approach to embedding-based
feature enrichment and illustrates its benefits in ensemble learning for
tabular data.

中文翻译:
特征工程对于优化机器学习模型性能至关重要，尤其在表格数据分类任务中。本研究基于自然语言处理领域的最新进展，提出了一种利用大语言模型嵌入特征来增强表格数据集的系统方法。通过对多个数据集（包括UCI Adult、心脏病、泰坦尼克号和皮马印第安人糖尿病数据集）开展全面的消融实验，我们评估了RoBERTa和GPT-2嵌入特征对随机森林、XGBoost和CatBoost等集成分类器的影响。研究结果表明：将嵌入特征与传统数值型、类别型特征相结合，通常能提升预测性能——在特征/样本有限或存在类别不平衡的数据集上效果尤为显著，其中XGBoost和CatBoost分类器的改进幅度最为突出。特征重要性分析进一步显示，大语言模型衍生的特征往往位列最具预测影响力的特征之中。本研究不仅提供了基于嵌入的特征增强结构化方案，更通过实证阐明了该方法在表格数据集成学习中的优势。

（翻译说明：
1. 专业术语处理：保持"Random Forest/XGBoost/CatBoost"等技术术语原貌，符合中文机器学习领域惯例
2. 长句拆分：将原文复合长句拆分为符合中文表达习惯的短句，如将"with improvements..."独立成句并添加破折号衔接
3. 被动语态转换："Results indicate"译为主动式"研究结果表明"，更符合中文论述习惯
4. 数据呈现优化：将括号内的数据集枚举改为中文更常用的顿号分隔列举式
5. 概念显化："structured approach"译为"结构化方案"而非字面直译，突出方法论价值
6. 学术风格保持：使用"消融实验""衍生的""实证阐明"等符合论文摘要语体的表述）
