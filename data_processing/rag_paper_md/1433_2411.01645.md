# Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers

链接: http://arxiv.org/abs/2411.01645v1

原文摘要:
Feature engineering is crucial for optimizing machine learning model
performance, particularly in tabular data classification tasks. Leveraging
advancements in natural language processing, this study presents a systematic
approach to enrich tabular datasets with features derived from large language
model embeddings. Through a comprehensive ablation study on diverse datasets,
we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers,
including Random Forest, XGBoost, and CatBoost. Results indicate that
integrating embeddings with traditional numerical and categorical features
often enhances predictive performance, especially on datasets with class
imbalance or limited features and samples, such as UCI Adult, Heart Disease,
Titanic, and Pima Indian Diabetes, with improvements particularly notable in
XGBoost and CatBoost classifiers. Additionally, feature importance analysis
reveals that LLM-derived features frequently rank among the most impactful for
the predictions. This study provides a structured approach to embedding-based
feature enrichment and illustrates its benefits in ensemble learning for
tabular data.

中文翻译:
特征工程对于优化机器学习模型性能至关重要，尤其在表格数据分类任务中。本研究基于自然语言处理领域的最新进展，提出了一种利用大语言模型嵌入特征系统化增强表格数据的方法。通过对多个数据集的全面消融实验，我们评估了RoBERTa和GPT-2嵌入特征对随机森林、XGBoost和CatBoost等集成分类器的影响。结果表明，在UCI Adult、心脏病、泰坦尼克号和皮马印第安人糖尿病等存在类别不平衡或特征样本有限的场景下，将嵌入特征与传统数值/分类特征结合能显著提升预测性能，其中XGBoost和CatBoost分类器的改进尤为突出。特征重要性分析进一步揭示，语言模型衍生的特征往往位列最具预测影响力的特征之中。本研究不仅提供了基于嵌入的特征增强结构化方法，更实证了其在表格数据集成学习中的优势。
