# Vision Language Transformers: A Survey

链接: http://arxiv.org/abs/2307.03254v1

原文摘要:
Vision language tasks, such as answering questions about or generating
captions that describe an image, are difficult tasks for computers to perform.
A relatively recent body of research has adapted the pretrained transformer
architecture introduced in \citet{vaswani2017attention} to vision language
modeling. Transformer models have greatly improved performance and versatility
over previous vision language models. They do so by pretraining models on a
large generic datasets and transferring their learning to new tasks with minor
changes in architecture and parameter values. This type of transfer learning
has become the standard modeling practice in both natural language processing
and computer vision. Vision language transformers offer the promise of
producing similar advancements in tasks which require both vision and language.
In this paper, we provide a broad synthesis of the currently available research
on vision language transformer models and offer some analysis of their
strengths, limitations and some open questions that remain.

中文翻译:
以下是您提供的英文论文摘要的中文翻译：

视觉语言任务（例如回答关于图像的问题或生成描述图像的标题）对计算机而言是极具挑战性的任务。近期一系列研究采用\citet{vaswani2017attention}提出的预训练Transformer架构进行视觉语言建模。相比早期的视觉语言模型，Transformer模型在性能与多功能性上实现了显著提升。其核心方法是通过海量通用数据集进行模型预训练，随后仅需微调架构和参数即可将学习成果迁移至新任务。这种迁移学习模式已成为自然语言处理和计算机视觉领域的标准建模实践。视觉语言Transformer模型有望在需要视觉与语言协同处理的任务中带来同等突破。本文系统综述了当前视觉语言Transformer模型的研究进展，并对其优势、局限性及待解问题进行了分析性探讨。

翻译说明：
1. 专业术语处理：保持"Transformer"等专业名词不变，"pretraining"译为"预训练"，"transfer learning"译为"迁移学习"
2. 学术风格保持：使用"系统综述"对应"synthesis"，"分析性探讨"对应"analysis"
3. 长句拆分：将原文复合句按中文习惯拆分为多个短句，如将"they do so by..."独立成句
4. 被动语态转换："has been adapted"转为主动态"采用"
5. 文献引用保留：\citet格式予以保留以符合学术规范
6. 概念显化："promise"译为"有望"更符合中文科技论文表达习惯
