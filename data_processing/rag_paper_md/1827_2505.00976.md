# Attack and defense techniques in large language models: A survey and new perspectives

链接: http://arxiv.org/abs/2505.00976v1

原文摘要:
Large Language Models (LLMs) have become central to numerous natural language
processing tasks, but their vulnerabilities present significant security and
ethical challenges. This systematic survey explores the evolving landscape of
attack and defense techniques in LLMs. We classify attacks into adversarial
prompt attack, optimized attacks, model theft, as well as attacks on
application of LLMs, detailing their mechanisms and implications. Consequently,
we analyze defense strategies, including prevention-based and detection-based
defense methods. Although advances have been made, challenges remain to adapt
to the dynamic threat landscape, balance usability with robustness, and address
resource constraints in defense implementation. We highlight open problems,
including the need for adaptive scalable defenses, explainable security
techniques, and standardized evaluation frameworks. This survey provides
actionable insights and directions for developing secure and resilient LLMs,
emphasizing the importance of interdisciplinary collaboration and ethical
considerations to mitigate risks in real-world applications.

中文翻译:
大型语言模型（LLMs）已成为众多自然语言处理任务的核心，但其存在的漏洞带来了重大的安全与伦理挑战。本系统性综述探讨了LLMs攻防技术的动态发展格局。我们将攻击类型归纳为对抗性提示攻击、优化攻击、模型窃取以及针对LLM应用的攻击，详细剖析其机制与影响；进而分析防御策略，涵盖基于预防和基于检测的防御方法。尽管已取得进展，但在适应动态威胁环境、平衡可用性与鲁棒性、解决防御实施中的资源限制等方面仍存在挑战。我们着重指出若干开放性问题，包括需要发展自适应可扩展防御、可解释安全技术以及标准化评估框架。本综述为开发安全稳健的LLMs提供了可操作的见解与方向，强调跨学科协作与伦理考量的重要性，以降低实际应用中的风险。
