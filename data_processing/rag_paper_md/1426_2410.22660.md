# Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models

链接: http://arxiv.org/abs/2410.22660v1

原文摘要:
Code-switching, the phenomenon of alternating between two or more languages
in a single conversation, presents unique challenges for Natural Language
Processing (NLP). Most existing research focuses on either syntactic
constraints or neural generation, with few efforts to integrate linguistic
theory with large language models (LLMs) for generating natural code-switched
text. In this paper, we introduce EZSwitch, a novel framework that combines
Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid
and fluent code-switched text. We evaluate our method using both human
judgments and automatic metrics, demonstrating a significant improvement in the
quality of generated code-switching sentences compared to baseline LLMs. To
address the lack of suitable evaluation metrics, we conduct a comprehensive
correlation study of various automatic metrics against human scores, revealing
that current metrics often fail to capture the nuanced fluency of code-switched
text. Additionally, we create CSPref, a human preference dataset based on human
ratings and analyze model performance across ``hard`` and ``easy`` examples.
Our findings indicate that incorporating linguistic constraints into LLMs leads
to more robust and human-aligned generation, paving the way for scalable
code-switching text generation across diverse language pairs.

中文翻译:
代码转换（Code-switching），即在单一对话中交替使用两种或多种语言的现象，为自然语言处理（NLP）带来了独特挑战。现有研究多集中于句法约束或神经生成领域，鲜有尝试将语言学理论与大语言模型（LLMs）相结合以生成自然的代码转换文本。本文提出EZSwitch框架，通过融合等价约束理论（ECT）与大语言模型，生成兼具语言学有效性和流畅性的代码转换文本。基于人工评估与自动化指标的双重验证，本方法相较基线大语言模型在生成质量上实现显著提升。针对当前缺乏合适评估标准的问题，我们开展了自动化指标与人工评分的相关性研究，发现现有指标往往难以捕捉代码转换文本的细微流畅度差异。此外，我们构建了基于人类评分的偏好数据集CSPref，并通过分析模型在"困难"与"简单"样本上的表现，证实融入语言学约束能使大语言模型生成更稳健且符合人类预期的文本，为跨语言对的规模化代码转换文本生成开辟了新路径。
