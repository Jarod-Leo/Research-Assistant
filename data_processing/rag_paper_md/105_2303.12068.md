# Machine Learning for Brain Disorders: Transformers and Visual Transformers

链接: http://arxiv.org/abs/2303.12068v1

原文摘要:
Transformers were initially introduced for natural language processing (NLP)
tasks, but fast they were adopted by most deep learning fields, including
computer vision. They measure the relationships between pairs of input tokens
(words in the case of text strings, parts of images for visual Transformers),
termed attention. The cost is exponential with the number of tokens. For image
classification, the most common Transformer Architecture uses only the
Transformer Encoder in order to transform the various input tokens. However,
there are also numerous other applications in which the decoder part of the
traditional Transformer Architecture is also used. Here, we first introduce the
Attention mechanism (Section 1), and then the Basic Transformer Block including
the Vision Transformer (Section 2). Next, we discuss some improvements of
visual Transformers to account for small datasets or less computation(Section
3). Finally, we introduce Visual Transformers applied to tasks other than image
classification, such as detection, segmentation, generation and training
without labels (Section 4) and other domains, such as video or multimodality
using text or audio data (Section 5).

中文翻译:
Transformer最初是为自然语言处理（NLP）任务提出的，但很快被包括计算机视觉在内的大多数深度学习领域所采用。它通过衡量输入标记对（文本字符串中的单词或视觉Transformer中的图像局部区域）之间的关系来工作，这种机制被称为注意力机制。其计算成本随标记数量呈指数级增长。在图像分类任务中，最常见的Transformer架构仅使用编码器部分来处理多样化的输入标记。然而，在众多其他应用中也会用到传统Transformer架构中的解码器部分。本文首先介绍注意力机制（第1节），随后阐述包含视觉Transformer在内的基础Transformer模块（第2节）。接着探讨针对小规模数据集或有限计算资源的视觉Transformer改进方案（第3节）。最后，我们展示视觉Transformer在图像分类之外的应用，如检测、分割、生成及无标签训练（第4节），以及视频、结合文本或音频数据的多模态等其他领域（第5节）。
