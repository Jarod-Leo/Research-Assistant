# Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models

链接: http://arxiv.org/abs/2407.08967v1

原文摘要:
Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE)
that utilizes limited training instances, appeals to more researchers in
Natural Language Processing (NLP) due to its capability to extract textual
information in extremely low-resource scenarios. The primary methodologies
employed for FSRE have been fine-tuning or prompt tuning techniques based on
Pre-trained Language Models (PLMs). Recently, the emergence of Large Language
Models (LLMs) has prompted numerous researchers to explore FSRE through
In-Context Learning (ICL). However, there are substantial limitations
associated with methods based on either traditional RE models or LLMs.
Traditional RE models are hampered by a lack of necessary prior knowledge,
while LLMs fall short in their task-specific capabilities for RE. To address
these shortcomings, we propose a Dual-System Augmented Relation Extractor
(DSARE), which synergistically combines traditional RE models with LLMs.
Specifically, DSARE innovatively injects the prior knowledge of LLMs into
traditional RE models, and conversely enhances LLMs' task-specific aptitude for
RE through relation extraction augmentation. Moreover, an Integrated Prediction
module is employed to jointly consider these two respective predictions and
derive the final results. Extensive experiments demonstrate the efficacy of our
proposed method.

中文翻译:
小样本关系抽取（FSRE）作为关系抽取（RE）的子任务，利用有限训练实例在极低资源场景下提取文本信息的能力，正吸引越来越多自然语言处理（NLP）研究者的关注。该领域主要采用基于预训练语言模型（PLMs）的微调或提示调优技术。近期，大语言模型（LLMs）的兴起促使众多研究者通过上下文学习（ICL）探索FSRE。然而，无论是传统RE模型还是LLMs方法都存在显著局限：传统RE模型受限于先验知识匮乏，而LLMs则缺乏针对RE任务的专项能力。为此，我们提出双系统增强关系抽取器（DSARE），通过协同整合传统RE模型与LLMs来弥补这些缺陷。具体而言，DSARE创新性地将LLMs的先验知识注入传统RE模型，同时通过关系抽取增强提升LLMs的RE任务专项能力，并采用集成预测模块综合双方预测结果生成最终判定。大量实验验证了该方法的有效性。
