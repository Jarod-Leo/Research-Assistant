# Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies

链接: http://arxiv.org/abs/2407.19816v1

原文摘要:
The labor market is undergoing rapid changes, with increasing demands on job
seekers and a surge in job openings. Identifying essential skills and
competencies from job descriptions is challenging due to varying employer
requirements and the omission of key skills. This study addresses these
challenges by comparing traditional Named Entity Recognition (NER) methods
based on encoders with Large Language Models (LLMs) for extracting skills from
Russian job vacancies. Using a labeled dataset of 4,000 job vacancies for
training and 1,472 for testing, the performance of both approaches is
evaluated. Results indicate that traditional NER models, especially DeepPavlov
RuBERT NER tuned, outperform LLMs across various metrics including accuracy,
precision, recall, and inference time. The findings suggest that traditional
NER models provide more effective and efficient solutions for skill extraction,
enhancing job requirement clarity and aiding job seekers in aligning their
qualifications with employer expectations. This research contributes to the
field of natural language processing (NLP) and its application in the labor
market, particularly in non-English contexts.

中文翻译:
劳动力市场正经历快速变革，对求职者的要求日益提高，职位空缺数量激增。由于雇主需求差异和关键技能的表述缺失，从职位描述中识别核心技能与胜任力面临挑战。本研究通过比较基于编码器的传统命名实体识别（NER）方法与大型语言模型（LLMs）在俄语职位空缺中的技能提取效果，针对这些问题提出了解决方案。实验采用包含4,000条标注职位空缺的训练集和1,472条的测试集，对两种方法的性能进行评估。结果表明，传统NER模型（特别是经过调优的DeepPavlov RuBERT NER）在准确率、精确率、召回率和推理时间等各项指标上均优于LLMs。研究发现传统NER模型能为技能提取提供更高效、更精准的解决方案，既可提升职位要求的清晰度，又能帮助求职者根据雇主期望调整自身资质。这项研究为自然语言处理（NLP）技术及其在劳动力市场（尤其是非英语语境）的应用领域作出了贡献。
