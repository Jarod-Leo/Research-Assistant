# Trustformer: A Trusted Federated Transformer

链接: http://arxiv.org/abs/2501.11706v1

原文摘要:
Transformers, a cornerstone of deep-learning architectures for sequential
data, have achieved state-of-the-art results in tasks like Natural Language
Processing (NLP). Models such as BERT and GPT-3 exemplify their success and
have driven the rise of large language models (LLMs). However, a critical
challenge persists: safeguarding the privacy of data used in LLM training.
Privacy-preserving techniques like Federated Learning (FL) offer potential
solutions, but practical limitations hinder their effectiveness for Transformer
training. Two primary issues are (I) the risk of sensitive information leakage
due to aggregation methods like FedAvg or FedSGD, and (II) the high
communication overhead caused by the large size of Transformer models.
  This paper introduces a novel FL method that reduces communication overhead
while maintaining competitive utility. Our approach avoids sharing full model
weights by simulating a global model locally. We apply k-means clustering to
each Transformer layer, compute centroids locally, and transmit only these
centroids to the server instead of full weights or gradients. To enhance
security, we leverage Intel SGX for secure transmission of centroids. Evaluated
on a translation task, our method achieves utility comparable to
state-of-the-art baselines while significantly reducing communication costs.
This provides a more efficient and privacy-preserving FL solution for
Transformer models.

中文翻译:
Transformer作为处理序列数据的深度学习架构基石，已在自然语言处理（NLP）等任务中取得最先进成果。BERT和GPT-3等模型的成功实践推动了大规模语言模型（LLM）的兴起，但其训练数据隐私保护始终面临严峻挑战。联邦学习（FL）等隐私保护技术虽提供潜在解决方案，但在Transformer训练中存在实际局限性：其一，FedAvg或FedSGD等聚合方法可能导致敏感信息泄露；其二，Transformer模型参数量庞大导致通信开销过高。

本文提出一种新型联邦学习方法，在保持模型性能的同时显著降低通信成本。该方法通过本地模拟全局模型，避免共享完整模型参数：对每个Transformer层进行k-means聚类，本地计算聚类中心后仅向服务器传输中心点而非完整权重或梯度。为增强安全性，采用Intel SGX技术保障中心点传输安全。在翻译任务上的评估表明，本方法在保持与前沿基线相当性能的前提下，通信开销大幅降低，为Transformer模型提供了更高效且隐私保护的联邦学习解决方案。
