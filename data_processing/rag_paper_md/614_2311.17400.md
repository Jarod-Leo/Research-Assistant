# Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention

链接: http://arxiv.org/abs/2311.17400v1

原文摘要:
Transformer-based models, such as BERT and GPT, have been widely adopted in
natural language processing (NLP) due to their exceptional performance.
However, recent studies show their vulnerability to textual adversarial attacks
where the model's output can be misled by intentionally manipulating the text
inputs. Despite various methods that have been proposed to enhance the model's
robustness and mitigate this vulnerability, many require heavy consumption
resources (e.g., adversarial training) or only provide limited protection
(e.g., defensive dropout). In this paper, we propose a novel method called
dynamic attention, tailored for the transformer architecture, to enhance the
inherent robustness of the model itself against various adversarial attacks.
Our method requires no downstream task knowledge and does not incur additional
costs. The proposed dynamic attention consists of two modules: (I) attention
rectification, which masks or weakens the attention value of the chosen tokens,
and (ii) dynamic modeling, which dynamically builds the set of candidate
tokens. Extensive experiments demonstrate that dynamic attention significantly
mitigates the impact of adversarial attacks, improving up to 33\% better
performance than previous methods against widely-used adversarial attacks. The
model-level design of dynamic attention enables it to be easily combined with
other defense methods (e.g., adversarial training) to further enhance the
model's robustness. Furthermore, we demonstrate that dynamic attention
preserves the state-of-the-art robustness space of the original model compared
to other dynamic modeling methods.

中文翻译:
基于Transformer的模型（如BERT和GPT）因其卓越性能在自然语言处理（NLP）领域得到广泛应用。然而，近期研究表明这类模型易受文本对抗攻击的影响——通过刻意操纵输入文本，模型的输出可能被误导。尽管已有多种方法被提出以增强模型鲁棒性并缓解这一脆弱性，但许多方法要么需要消耗大量资源（如对抗训练），要么仅提供有限保护（如防御性丢弃）。本文提出一种专为Transformer架构设计的新方法——动态注意力机制，旨在从模型层面提升其内在鲁棒性以抵御各类对抗攻击。该方法无需下游任务知识且不产生额外成本，由两个核心模块构成：（1）注意力校正模块，通过掩码或弱化选定标记的注意力值；（2）动态建模模块，动态构建候选标记集合。大量实验表明，动态注意力机制能显著削弱对抗攻击的影响，在应对广泛使用的对抗攻击时，性能较现有方法提升最高达33%。该模型级设计使其能轻松与其他防御方法（如对抗训练）结合以进一步增强鲁棒性。此外，研究证实相比其他动态建模方法，动态注意力机制能更好地保持原始模型的前沿鲁棒性空间。
