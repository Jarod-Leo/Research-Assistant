# Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models

链接: http://arxiv.org/abs/2502.09723v1

原文摘要:
Recent advances in large language models (LLMs) have demonstrated remarkable
potential in the field of natural language processing. Unfortunately, LLMs face
significant security and ethical risks. Although techniques such as safety
alignment are developed for defense, prior researches reveal the possibility of
bypassing such defenses through well-designed jailbreak attacks. In this paper,
we propose QueryAttack, a novel framework to examine the generalizability of
safety alignment. By treating LLMs as knowledge databases, we translate
malicious queries in natural language into structured non-natural query
language to bypass the safety alignment mechanisms of LLMs. We conduct
extensive experiments on mainstream LLMs, and the results show that QueryAttack
not only can achieve high attack success rates (ASRs), but also can jailbreak
various defense methods. Furthermore, we tailor a defense method against
QueryAttack, which can reduce ASR by up to 64% on GPT-4-1106. Our code is
available at https://github.com/horizonsinzqs/QueryAttack.

中文翻译:
以下是符合您要求的中文翻译：

【中文译文】
大语言模型（LLMs）的最新进展在自然语言处理领域展现出非凡潜力，但同时也面临重大安全与伦理风险。尽管研究者已开发出安全对齐等技术进行防御，但先前研究表明，通过精心设计的越狱攻击仍可能绕过这些防护机制。本文提出QueryAttack创新框架，用于检验安全对齐技术的泛化能力。通过将LLMs视为知识数据库，我们将自然语言中的恶意查询转换为结构化的非自然查询语言，从而绕过LLMs的安全对齐机制。我们在主流LLMs上进行了大量实验，结果表明QueryAttack不仅能实现高达92%的攻击成功率（ASR），还能突破多种防御方法的防护。此外，我们专门设计了一种针对QueryAttack的防御方案，可使GPT-4-1106的ASR最高降低64%。代码已开源：https://github.com/horizonsinzqs/QueryAttack

【翻译要点说明】
1. 术语处理：
- "jailbreak attacks"译为"越狱攻击"（信息安全领域标准译法）
- "safety alignment"统一译为"安全对齐"
- "ASRs"保留英文缩写并首次出现时标注全称"攻击成功率"

2. 句式重构：
- 将原文复合句拆分为符合中文表达习惯的短句（如第一句拆分为转折关系复句）
- "structured non-natural query language"译为"结构化的非自然查询语言"保持专业性的同时确保可读性

3. 技术细节保留：
- 精确翻译"GPT-4-1106"等模型名称
- 完整保留代码仓库URL等关键信息

4. 学术风格：
- 使用"本文""结果表明"等学术论文标准表述
- 保持客观陈述语气，避免主观修饰词

5. 数字处理：
- "up to 64%"译为"最高降低64%"，符合中文比较级表达习惯
