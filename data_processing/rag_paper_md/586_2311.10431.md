# Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human Narrative Processing

链接: http://arxiv.org/abs/2311.10431v1

原文摘要:
Understanding how humans process natural language has long been a vital
research direction. The field of natural language processing (NLP) has recently
experienced a surge in the development of powerful language models. These
models have proven to be invaluable tools for studying another complex system
known to process human language: the brain. Previous studies have demonstrated
that the features of language models can be mapped to fMRI brain activity. This
raises the question: is there a commonality between information processing in
language models and the human brain? To estimate information flow patterns in a
language model, we examined the causal relationships between different layers.
Drawing inspiration from the workspace framework for consciousness, we
hypothesized that features integrating more information would more accurately
predict higher hierarchical brain activity. To validate this hypothesis, we
classified language model features into two categories based on causal network
measures: 'low in-degree' and 'high in-degree'. We subsequently compared the
brain prediction accuracy maps for these two groups. Our results reveal that
the difference in prediction accuracy follows a hierarchical pattern,
consistent with the cortical hierarchy map revealed by activity time constants.
This finding suggests a parallel between how language models and the human
brain process linguistic information.

中文翻译:
理解人类如何处理自然语言一直是一个至关重要的研究方向。近年来，自然语言处理（NLP）领域涌现出众多强大的语言模型。这些模型已被证明是研究另一个已知能处理人类语言的复杂系统——大脑——的宝贵工具。先前研究表明，语言模型的特征可以映射到功能性磁共振成像（fMRI）记录的大脑活动上。这引发了一个问题：语言模型与人类大脑在信息处理方面是否存在共性？为评估语言模型中的信息流动模式，我们研究了不同层级之间的因果关系。受意识工作空间框架的启发，我们假设整合更多信息的特征能更准确地预测更高层级的大脑活动。为验证这一假设，我们根据因果网络测量指标将语言模型特征分为"低入度"和"高入度"两类，随后比较了两组特征的大脑预测准确度图谱。研究结果显示，预测准确度的差异遵循层级化模式，与活动时间常数揭示的皮层层级图谱一致。这一发现表明，语言模型与人类大脑在语言信息处理方面存在相似性。
