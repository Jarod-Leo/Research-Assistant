# Causal Graph in Language Model Rediscovers Cortical Hierarchy in Human Narrative Processing

链接: http://arxiv.org/abs/2311.10431v1

原文摘要:
Understanding how humans process natural language has long been a vital
research direction. The field of natural language processing (NLP) has recently
experienced a surge in the development of powerful language models. These
models have proven to be invaluable tools for studying another complex system
known to process human language: the brain. Previous studies have demonstrated
that the features of language models can be mapped to fMRI brain activity. This
raises the question: is there a commonality between information processing in
language models and the human brain? To estimate information flow patterns in a
language model, we examined the causal relationships between different layers.
Drawing inspiration from the workspace framework for consciousness, we
hypothesized that features integrating more information would more accurately
predict higher hierarchical brain activity. To validate this hypothesis, we
classified language model features into two categories based on causal network
measures: 'low in-degree' and 'high in-degree'. We subsequently compared the
brain prediction accuracy maps for these two groups. Our results reveal that
the difference in prediction accuracy follows a hierarchical pattern,
consistent with the cortical hierarchy map revealed by activity time constants.
This finding suggests a parallel between how language models and the human
brain process linguistic information.

中文翻译:
理解人类如何处理自然语言长期以来都是一个至关重要的研究方向。近年来，自然语言处理（NLP）领域涌现出大量强大语言模型。这些模型已被证明是研究另一个已知能处理人类语言的复杂系统——大脑——的宝贵工具。既往研究表明，语言模型的特征能够与功能性磁共振成像（fMRI）记录的脑活动建立映射关系。这引发了一个关键问题：语言模型与人类大脑的信息处理是否存在共性？为评估语言模型中的信息流动模式，我们分析了不同层级间的因果关系。受意识工作空间理论框架启发，我们提出假设：整合更多信息的特征能更精准预测大脑高级别层次的活动。为验证该假设，我们根据因果网络度量指标将语言模型特征分为"低入度"与"高入度"两类，随后比较两组特征对应的大脑预测精度图谱。研究结果显示，预测精度的差异呈现层级化分布模式，与通过活动时间常数揭示的皮层层级图谱高度一致。这一发现表明，语言模型与人类大脑在语言信息处理方面存在潜在相似性。
