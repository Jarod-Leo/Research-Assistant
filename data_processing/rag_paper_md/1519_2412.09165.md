# When Text Embedding Meets Large Language Model: A Comprehensive Survey

链接: http://arxiv.org/abs/2412.09165v1

原文摘要:
Text embedding has become a foundational technology in natural language
processing (NLP) during the deep learning era, driving advancements across a
wide array of downstream tasks. While many natural language understanding
challenges can now be modeled using generative paradigms and leverage the
robust generative and comprehension capabilities of large language models
(LLMs), numerous practical applications - such as semantic matching,
clustering, and information retrieval - continue to rely on text embeddings for
their efficiency and effectiveness. Therefore, integrating LLMs with text
embeddings has become a major research focus in recent years. In this survey,
we categorize the interplay between LLMs and text embeddings into three
overarching themes: (1) LLM-augmented text embedding, enhancing traditional
embedding methods with LLMs; (2) LLMs as text embedders, adapting their innate
capabilities for high-quality embedding; and (3) Text embedding understanding
with LLMs, leveraging LLMs to analyze and interpret embeddings. By organizing
recent works based on interaction patterns rather than specific downstream
applications, we offer a novel and systematic overview of contributions from
various research and application domains in the era of LLMs. Furthermore, we
highlight the unresolved challenges that persisted in the pre-LLM era with
pre-trained language models (PLMs) and explore the emerging obstacles brought
forth by LLMs. Building on this analysis, we outline prospective directions for
the evolution of text embedding, addressing both theoretical and practical
opportunities in the rapidly advancing landscape of NLP.

中文翻译:
文本嵌入已成为深度学习时代自然语言处理（NLP）的基础技术，推动着众多下游任务的进步。尽管当前许多自然语言理解挑战可通过生成范式建模，并利用大语言模型（LLMs）强大的生成与理解能力，但语义匹配、聚类、信息检索等实际应用仍依赖文本嵌入的高效性与实用性。因此，LLMs与文本嵌入的融合成为近年研究热点。本文从交互模式出发，将二者关系系统梳理为三大主题：（1）LLM增强型文本嵌入——利用LLMs优化传统嵌入方法；（2）LLMs作为文本嵌入器——适配其原生能力生成高质量嵌入；（3）基于LLMs的嵌入理解——运用LLMs分析与解释嵌入表征。不同于按应用领域分类的常规方法，这种架构创新性地整合了LLM时代多领域研究成果。我们同时指出预训练语言模型（PLMs）时代遗留的未解难题，剖析LLMs带来的新挑战，并据此勾勒文本嵌入技术的未来发展方向，为NLP快速演进中的理论突破与实践创新提供前瞻视角。
