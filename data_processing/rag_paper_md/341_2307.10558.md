# Instruction-following Evaluation through Verbalizer Manipulation

链接: http://arxiv.org/abs/2307.10558v1

原文摘要:
While instruction-tuned models have shown remarkable success in various
natural language processing tasks, accurately evaluating their ability to
follow instructions remains challenging. Existing benchmarks primarily focus on
common instructions that align well with what the model learned during
training. However, proficiency in responding to these instructions does not
necessarily imply strong ability in instruction following. In this paper, we
propose a novel instruction-following evaluation protocol called verbalizer
manipulation. It instructs the model to verbalize the task label with words
aligning with model priors to different extents, adopting verbalizers from
highly aligned (e.g., outputting ``postive'' for positive sentiment), to
minimally aligned (e.g., outputting ``negative'' for positive sentiment).
Verbalizer manipulation can be seamlessly integrated with any classification
benchmark to examine the model's reliance on priors and its ability to override
them to accurately follow the instructions. We conduct a comprehensive
evaluation of four major model families across nine datasets, employing twelve
sets of verbalizers for each of them. We observe that the instruction-following
abilities of models, across different families and scales, are significantly
distinguished by their performance on less natural verbalizers. Even the
strongest GPT-4 model struggles to perform better than random guessing on the
most challenging verbalizer, emphasizing the need for continued advancements to
improve their instruction-following abilities.

中文翻译:
虽然指令微调模型在各种自然语言处理任务中取得了显著成功，但如何准确评估其遵循指令的能力仍具挑战性。现有基准测试主要关注与模型训练期间所学高度契合的常见指令，然而对这些指令的熟练响应并不必然意味着强大的指令遵循能力。本文提出了一种新颖的指令遵循评估方法——表达器调控技术。该方法通过采用与模型先验知识契合度不同的标签表达器（从高度契合（如对积极情感输出"正向"）到最低限度契合（如对积极情感输出"负向"）），指导模型用不同契合度的词汇表述任务标签。该技术可无缝集成到任何分类基准测试中，用以检验模型对先验知识的依赖程度及突破先验准确遵循指令的能力。我们对四大模型家族的九个数据集进行了全面评估，每个数据集采用十二组表达器。研究发现：不同家族和规模的模型在非自然表达器上的表现，能显著区分其指令遵循能力的差异。即使在最具挑战性的表达器上，最强的GPT-4模型也难以超越随机猜测水平，这凸显了持续提升指令遵循能力的必要性。
