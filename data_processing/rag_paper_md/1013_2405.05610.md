# Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM

链接: http://arxiv.org/abs/2405.05610v1

原文摘要:
Large language models (LLMs) have achieved remarkable performance in various
natural language processing tasks, especially in dialogue systems. However, LLM
may also pose security and moral threats, especially in multi round
conversations where large models are more easily guided by contextual content,
resulting in harmful or biased responses. In this paper, we present a novel
method to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack).
CoA is a semantic-driven contextual multi-turn attack method that adaptively
adjusts the attack policy through contextual feedback and semantic relevance
during multi-turn of dialogue with a large model, resulting in the model
producing unreasonable or harmful content. We evaluate CoA on different LLMs
and datasets, and show that it can effectively expose the vulnerabilities of
LLMs, and outperform existing attack methods. Our work provides a new
perspective and tool for attacking and defending LLMs, and contributes to the
security and ethical assessment of dialogue systems.

中文翻译:
大语言模型（LLMs）在各类自然语言处理任务中展现出卓越性能，尤其在对话系统领域表现突出。然而，LLM也可能引发安全与道德风险，特别是在多轮对话场景中，大模型更容易受上下文内容引导，产生有害或带有偏见的回应。本文提出了一种新颖的多轮对话攻击方法——攻击链（CoA）。该方法作为语义驱动的上下文多轮攻击策略，通过与大模型对话过程中的上下文反馈和语义关联性进行自适应攻击策略调整，最终诱导模型生成不合理或有害内容。我们在不同LLM模型和数据集上评估了CoA的效果，结果表明该方法能有效暴露大语言模型的脆弱性，其攻击效果优于现有攻击方法。本研究为LLM攻防提供了新视角和工具，对对话系统的安全性与伦理评估具有重要贡献。
