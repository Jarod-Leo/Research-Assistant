# ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities

链接: http://arxiv.org/abs/2502.13832v1

原文摘要:
Can Multimodal Large Language Models (MLLMs), with capabilities in
perception, recognition, understanding, and reasoning, function as independent
assistants in art evaluation dialogues? Current MLLM evaluation methods, which
rely on subjective human scoring or costly interviews, lack comprehensive
coverage of various scenarios. This paper proposes a process-oriented
Human-Computer Interaction (HCI) space design to facilitate more accurate MLLM
assessment and development. This approach aids teachers in efficient art
evaluation while also recording interactions for MLLM capability assessment. We
introduce ArtMentor, a comprehensive space that integrates a dataset and three
systems to optimize MLLM evaluation. The dataset consists of 380 sessions
conducted by five art teachers across nine critical dimensions. The modular
system includes agents for entity recognition, review generation, and
suggestion generation, enabling iterative upgrades. Machine learning and
natural language processing techniques ensure the reliability of evaluations.
The results confirm GPT-4o's effectiveness in assisting teachers in art
evaluation dialogues. Our contributions are available at
https://artmentor.github.io/.

中文翻译:
具备感知、识别、理解与推理能力的多模态大语言模型（MLLMs）能否作为独立助手参与艺术评价对话？当前依赖主观人工评分或高成本访谈的MLLM评估方法，难以全面覆盖多样化场景。本文提出面向过程的人机交互空间设计，以实现更精准的MLLM评估与开发。该方法既能辅助教师高效开展艺术评价，又可记录交互过程用于MLLM能力评估。我们推出ArtMentor综合空间，通过集成数据集与三大系统优化MLLM评估：数据集包含五位艺术教师开展的380次对话会话，涵盖九大核心维度；模块化系统配备实体识别、评语生成与建议生成智能体，支持迭代升级；机器学习与自然语言处理技术保障评估可靠性。实验结果验证了GPT-4o在辅助教师艺术评价对话中的有效性。相关成果已发布于https://artmentor.github.io/。
