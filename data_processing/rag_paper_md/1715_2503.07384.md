# Is My Text in Your AI Model? Gradient-based Membership Inference Test applied to LLMs

链接: http://arxiv.org/abs/2503.07384v1

原文摘要:
This work adapts and studies the gradient-based Membership Inference Test
(gMINT) to the classification of text based on LLMs. MINT is a general approach
intended to determine if given data was used for training machine learning
models, and this work focuses on its application to the domain of Natural
Language Processing. Using gradient-based analysis, the MINT model identifies
whether particular data samples were included during the language model
training phase, addressing growing concerns about data privacy in machine
learning. The method was evaluated in seven Transformer-based models and six
datasets comprising over 2.5 million sentences, focusing on text classification
tasks. Experimental results demonstrate MINTs robustness, achieving AUC scores
between 85% and 99%, depending on data size and model architecture. These
findings highlight MINTs potential as a scalable and reliable tool for auditing
machine learning models, ensuring transparency, safeguarding sensitive data,
and fostering ethical compliance in the deployment of AI/NLP technologies.

中文翻译:
本研究将基于梯度的成员推断测试（gMINT）方法适配并应用于基于大语言模型的文本分类任务。MINT作为一种通用技术，旨在判定特定数据是否被用于机器学习模型训练，本工作重点探索其在自然语言处理领域的应用。该方法通过梯度分析识别语言模型训练阶段是否包含特定数据样本，以应对机器学习中日益增长的数据隐私关切。我们在7个基于Transformer的模型和包含超250万语句的6个数据集上进行了文本分类任务的评估，实验结果表明MINT具有强鲁棒性，其AUC得分介于85%至99%之间，具体表现取决于数据规模和模型架构。这些发现凸显了MINT作为可扩展审计工具的潜力，能有效确保机器学习模型的透明度，保护敏感数据，并促进AI/NLP技术应用中的伦理合规。
