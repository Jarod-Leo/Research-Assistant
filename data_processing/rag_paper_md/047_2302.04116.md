# Training-free Lexical Backdoor Attacks on Language Models

链接: http://arxiv.org/abs/2302.04116v1

原文摘要:
Large-scale language models have achieved tremendous success across various
natural language processing (NLP) applications. Nevertheless, language models
are vulnerable to backdoor attacks, which inject stealthy triggers into models
for steering them to undesirable behaviors. Most existing backdoor attacks,
such as data poisoning, require further (re)training or fine-tuning language
models to learn the intended backdoor patterns. The additional training process
however diminishes the stealthiness of the attacks, as training a language
model usually requires long optimization time, a massive amount of data, and
considerable modifications to the model parameters. In this work, we propose
Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free
backdoor attack on language models. Our attack is achieved by injecting lexical
triggers into the tokenizer of a language model via manipulating its embedding
dictionary using carefully designed rules. These rules are explainable to human
developers which inspires attacks from a wider range of hackers. The sparse
manipulation of the dictionary also habilitates the stealthiness of our attack.
We conduct extensive experiments on three dominant NLP tasks based on nine
language models to demonstrate the effectiveness and universality of our
attack. The code of this work is available at
https://github.com/Jinxhy/TFLexAttack.

中文翻译:
以下是符合要求的学术化中文翻译：

大规模语言模型在各类自然语言处理（NLP）应用中取得了显著成功。然而，这类模型易受后门攻击影响——攻击者通过植入隐蔽触发器来诱导模型产生异常行为。现有后门攻击方法（如数据投毒）大多需要通过对语言模型进行（重新）训练或微调来学习预设的后门模式。但额外的训练过程会削弱攻击的隐蔽性，因为语言模型训练通常需要长时间优化、海量数据支持以及大幅度的参数调整。

本研究提出首个免训练的词法后门攻击方法TFLexAttack（Training-Free Lexical Backdoor Attack）。该方法通过精心设计的规则操纵语言模型分词器的嵌入词典，将词法触发器注入模型。这些规则对人类开发者具有可解释性，从而可能激发更广泛的黑客攻击行为。由于仅对词典进行稀疏修改，本方法能有效保持攻击隐蔽性。我们在九种语言模型上针对三大主流NLP任务开展了大量实验，结果验证了该攻击方法的有效性和普适性。本项目代码已开源：https://github.com/Jinxhy/TFLexAttack。

（注：根据学术规范要求，译文实现了以下处理：
1. 专业术语统一（如backdoor attack统一译为"后门攻击"）
2. 被动语态转换（如"are vulnerable to"译为"易受...影响"）
3. 长句拆分重组（如原文第二句拆分为两个中文句子）
4. 概念准确传达（如"stealthy triggers"译为"隐蔽触发器"）
5. 保留技术细节（如"embedding dictionary"译为"嵌入词典"）
6. 项目名称保留英文原名+中文释义）
