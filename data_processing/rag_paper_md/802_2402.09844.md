# Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent

链接: http://arxiv.org/abs/2402.09844v1

原文摘要:
The search for a general model that can operate seamlessly across multiple
domains remains a key goal in machine learning research. The prevailing
methodology in Reinforcement Learning (RL) typically limits models to a single
task within a unimodal framework, a limitation that contrasts with the broader
vision of a versatile, multi-domain model. In this paper, we present Jack of
All Trades (JAT), a transformer-based model with a unique design optimized for
handling sequential decision-making tasks and multi-modal data types. The JAT
model demonstrates its robust capabilities and versatility by achieving strong
performance on very different RL benchmarks, along with promising results on
Computer Vision (CV) and Natural Language Processing (NLP) tasks, all using a
single set of weights. The JAT model marks a significant step towards more
general, cross-domain AI model design, and notably, it is the first model of
its kind to be fully open-sourced at https://huggingface.co/jat-project/jat,
including a pioneering general-purpose dataset.

中文翻译:
寻找一个能够跨多个领域无缝运行的通用模型，始终是机器学习研究的核心目标。当前强化学习（RL）的主流方法通常将模型限制在单一模态框架下的特定任务中，这与构建多功能、跨领域模型的宏大愿景形成鲜明对比。本文提出的"多面手"（JAT）模型基于Transformer架构，其独特设计专为处理序列决策任务和多模态数据类型而优化。该模型在差异显著的RL基准测试中展现出卓越性能，同时在计算机视觉（CV）和自然语言处理（NLP）任务上取得突破性成果——所有功能仅通过单一权重集实现。JAT模型标志着向通用跨领域AI设计迈出重要一步，尤为值得注意的是，它成为首个在https://huggingface.co/jat-project/jat 完全开源的此类模型，并包含首创的通用数据集。
