# Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models

链接: http://arxiv.org/abs/2503.18681v1

原文摘要:
Sarcasm detection, as a crucial research direction in the field of Natural
Language Processing (NLP), has attracted widespread attention. Traditional
sarcasm detection tasks have typically focused on single-modal approaches
(e.g., text), but due to the implicit and subtle nature of sarcasm, such
methods often fail to yield satisfactory results. In recent years, researchers
have shifted the focus of sarcasm detection to multi-modal approaches. However,
effectively leveraging multi-modal information to accurately identify sarcastic
content remains a challenge that warrants further exploration. Leveraging the
powerful integrated processing capabilities of Multi-Modal Large Language
Models (MLLMs) for various information sources, we propose an innovative
multi-modal Commander-GPT framework. Inspired by military strategy, we first
decompose the sarcasm detection task into six distinct sub-tasks. A central
commander (decision-maker) then assigns the best-suited large language model to
address each specific sub-task. Ultimately, the detection results from each
model are aggregated to identify sarcasm. We conducted extensive experiments on
MMSD and MMSD 2.0, utilizing four multi-modal large language models and six
prompting strategies. Our experiments demonstrate that our approach achieves
state-of-the-art performance, with a 19.3% improvement in F1 score, without
necessitating fine-tuning or ground-truth rationales.

中文翻译:
讽刺检测作为自然语言处理领域的重要研究方向，受到了广泛关注。传统讽刺检测任务通常采用单模态方法（如文本），但由于讽刺具有隐晦微妙的特点，此类方法往往难以取得理想效果。近年来研究者将讽刺检测重心转向多模态方向，然而如何有效利用多模态信息精准识别讽刺内容，仍是值得深入探索的挑战。借助多模态大语言模型（MLLMs）对多种信息源的强大整合处理能力，我们提出创新的多模态Commander-GPT框架。受军事战略思想启发，我们首先将讽刺检测任务解构为六个独立子任务，由中央指挥官（决策者）为每个特定子任务分配最适配的大语言模型进行处理，最终汇总各模型检测结果实现讽刺识别。我们在MMSD和MMSD 2.0数据集上使用四种多模态大语言模型和六种提示策略进行了大量实验，结果表明本方法在不需微调或真实依据的情况下，F1分数提升19.3%，达到了最先进的性能水平。
