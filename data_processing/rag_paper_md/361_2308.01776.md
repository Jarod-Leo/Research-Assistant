# Does Correction Remain An Problem For Large Language Models?

链接: http://arxiv.org/abs/2308.01776v1

原文摘要:
As large language models, such as GPT, continue to advance the capabilities
of natural language processing (NLP), the question arises: does the problem of
correction still persist? This paper investigates the role of correction in the
context of large language models by conducting two experiments. The first
experiment focuses on correction as a standalone task, employing few-shot
learning techniques with GPT-like models for error correction. The second
experiment explores the notion of correction as a preparatory task for other
NLP tasks, examining whether large language models can tolerate and perform
adequately on texts containing certain levels of noise or errors. By addressing
these experiments, we aim to shed light on the significance of correction in
the era of large language models and its implications for various NLP
applications.

中文翻译:
随着GPT等大型语言模型持续推动自然语言处理（NLP）能力的发展，一个核心问题随之浮现：文本纠错问题是否依然存在？本文通过两项实验探究大型语言模型语境下纠错任务的作用机制。第一项实验将纠错作为独立任务，采用类GPT模型的少样本学习技术进行错误修正；第二项实验则探讨纠错作为其他NLP任务前置工序的可行性，检验大型语言模型对含噪文本的容忍度及处理效能。通过这两项实验，我们试图阐明大型语言模型时代纠错任务的重要意义，及其对各类NLP应用场景的潜在影响。

（翻译说明：采用学术论文摘要的标准句式结构，通过以下处理实现专业性与可读性的平衡：
1. 将"few-shot learning techniques"译为专业术语"少样本学习技术"
2. "tolerate and perform adequately"意译为"容忍度及处理效能"，符合中文表达习惯
3. 使用"前置工序"等比喻增强可读性
4. 保持"含噪文本"等专业表述的准确性
5. 通过"随之浮现""探讨...可行性"等措辞保持学术文本的严谨性
6. 最后一句"潜在影响"的译法既保留原文含义，又符合中文摘要收尾惯例）
