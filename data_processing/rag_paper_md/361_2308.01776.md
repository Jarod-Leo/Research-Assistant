# Does Correction Remain An Problem For Large Language Models?

链接: http://arxiv.org/abs/2308.01776v1

原文摘要:
As large language models, such as GPT, continue to advance the capabilities
of natural language processing (NLP), the question arises: does the problem of
correction still persist? This paper investigates the role of correction in the
context of large language models by conducting two experiments. The first
experiment focuses on correction as a standalone task, employing few-shot
learning techniques with GPT-like models for error correction. The second
experiment explores the notion of correction as a preparatory task for other
NLP tasks, examining whether large language models can tolerate and perform
adequately on texts containing certain levels of noise or errors. By addressing
these experiments, we aim to shed light on the significance of correction in
the era of large language models and its implications for various NLP
applications.

中文翻译:
随着GPT等大型语言模型持续推动自然语言处理(NLP)能力的发展，一个核心问题随之浮现：纠错任务是否仍有存在必要？本文通过两项实验探究大型语言模型语境下纠错任务的作用机制。首项实验将纠错作为独立任务，采用类GPT模型的少样本学习技术进行错误修正；次项实验则探讨纠错作为NLP任务前置环节的可行性，检验大语言模型对含噪文本的容忍度与处理效能。通过这两项实验，我们试图阐明大语言模型时代纠错任务的价值及其对各类NLP应用的启示。
