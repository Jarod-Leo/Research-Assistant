# Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models

链接: http://arxiv.org/abs/2311.01732v1

原文摘要:
Large Language Models (LLMs) have significantly advanced the field of Natural
Language Processing (NLP), but their lack of interpretability has been a major
concern. Current methods for interpreting LLMs are post hoc, applied after
inference time, and have limitations such as their focus on low-level features
and lack of explainability at higher level text units. In this work, we
introduce proto-lm, a prototypical network-based white-box framework that
allows LLMs to learn immediately interpretable embeddings during the
fine-tuning stage while maintaining competitive performance. Our method's
applicability and interpretability are demonstrated through experiments on a
wide range of NLP tasks, and our results indicate a new possibility of creating
interpretable models without sacrificing performance. This novel approach to
interpretability in LLMs can pave the way for more interpretable models without
the need to sacrifice performance.

中文翻译:
大型语言模型（LLMs）显著推动了自然语言处理（NLP）领域的发展，但其可解释性不足一直备受关注。现有解释方法多为事后分析，应用于推理阶段后，存在聚焦底层特征、缺乏高层文本单元解释力等局限。本研究提出proto-lm——一个基于原型网络的白盒框架，使LLMs在微调阶段即可学习直接可解释的嵌入表示，同时保持竞争力性能。通过多类NLP任务的实验验证，我们证明了该方法的适用性与可解释性，结果表明无需牺牲性能即可构建可解释模型的新可能。这种创新的可解释性研究路径，为开发高性能可解释模型开辟了新方向。
