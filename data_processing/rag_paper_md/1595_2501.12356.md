# Vision-Language Models for Automated Chest X-ray Interpretation: Leveraging ViT and GPT-2

链接: http://arxiv.org/abs/2501.12356v1

原文摘要:
Radiology plays a pivotal role in modern medicine due to its non-invasive
diagnostic capabilities. However, the manual generation of unstructured medical
reports is time consuming and prone to errors. It creates a significant
bottleneck in clinical workflows. Despite advancements in AI-generated
radiology reports, challenges remain in achieving detailed and accurate report
generation. In this study we have evaluated different combinations of
multimodal models that integrate Computer Vision and Natural Language
Processing to generate comprehensive radiology reports. We employed a
pretrained Vision Transformer (ViT-B16) and a SWIN Transformer as the image
encoders. The BART and GPT-2 models serve as the textual decoders. We used
Chest X-ray images and reports from the IU-Xray dataset to evaluate the
usability of the SWIN Transformer-BART, SWIN Transformer-GPT-2, ViT-B16-BART
and ViT-B16-GPT-2 models for report generation. We aimed at finding the best
combination among the models. The SWIN-BART model performs as the
best-performing model among the four models achieving remarkable results in
almost all the evaluation metrics like ROUGE, BLEU and BERTScore.

中文翻译:
放射学凭借其无创诊断能力在现代医学中占据核心地位，但人工生成非结构化医学报告耗时且易错，已成为临床工作流程中的显著瓶颈。尽管AI生成放射学报告技术有所进展，但在实现详尽准确的报告生成方面仍存在挑战。本研究评估了融合计算机视觉与自然语言处理的多模态模型组合，以生成全面的放射学报告。我们采用预训练的Vision Transformer（ViT-B16）和SWIN Transformer作为图像编码器，BART与GPT-2模型作为文本解码器。通过IU-Xray数据集中的胸部X光图像及报告，我们评估了SWIN-BART、SWIN-GPT-2、ViT-BART和ViT-GPT-2四种模型组合的报告生成性能，旨在确定最优组合。结果表明，SWIN-BART模型在ROUGE、BLEU和BERTScore等各项评估指标中表现最优，成为四组模型中性能最佳的方案。
