# AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators

链接: http://arxiv.org/abs/2303.16854v1

原文摘要:
Many natural language processing (NLP) tasks rely on labeled data to train
machine learning models with high performance. However, data annotation is
time-consuming and expensive, especially when the task involves a large amount
of data or requires specialized domains. Recently, GPT-3.5 series models have
demonstrated remarkable few-shot and zero-shot ability across various NLP
tasks. In this paper, we first claim that large language models (LLMs), such as
GPT-3.5, can serve as an excellent crowdsourced annotator when provided with
sufficient guidance and demonstrated examples. Accordingly, we propose AnnoLLM,
an annotation system powered by LLMs, which adopts a two-step approach,
explain-then-annotate. Concretely, we first prompt LLMs to provide explanations
for why the specific ground truth answer/label was assigned for a given
example. Then, we construct the few-shot chain-of-thought prompt with the
self-generated explanation and employ it to annotate the unlabeled data with
LLMs. Our experiment results on three tasks, including user input and keyword
relevance assessment, BoolQ, and WiC, demonstrate that AnnoLLM surpasses or
performs on par with crowdsourced annotators. Furthermore, we build the first
conversation-based information retrieval dataset employing AnnoLLM. This
dataset is designed to facilitate the development of retrieval models capable
of retrieving pertinent documents for conversational text. Human evaluation has
validated the dataset's high quality.

中文翻译:
众多自然语言处理（NLP）任务依赖标注数据来训练高性能的机器学习模型。然而，数据标注过程耗时且成本高昂，尤其在涉及海量数据或需要专业领域知识时更为突出。近期，GPT-3.5系列模型在各类NLP任务中展现出卓越的小样本和零样本学习能力。本文首次提出，当提供充分指导和示例时，以GPT-3.5为代表的大语言模型（LLMs）可成为优质的众包标注工具。基于此，我们开发了AnnoLLM——一个由大语言模型驱动的标注系统，采用"解释-标注"的两阶段方法：首先提示大语言模型对给定示例的标准答案/标签生成解释说明，随后构建包含自生成解释的思维链小样本提示，并用于未标注数据的自动化标注。在用户输入与关键词相关性评估、BoolQ和WiC三个任务上的实验表明，AnnoLLM的标注质量达到或超越了众包标注者水平。此外，我们运用AnnoLLM构建了首个基于对话的信息检索数据集，该数据集旨在促进能够检索会话文本相关文档的检索模型开发，人工评估证实了数据集的高质量特性。
