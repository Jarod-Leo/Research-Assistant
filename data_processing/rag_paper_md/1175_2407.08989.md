# Robustness of LLMs to Perturbations in Text

链接: http://arxiv.org/abs/2407.08989v1

原文摘要:
Having a clean dataset has been the foundational assumption of most natural
language processing (NLP) systems. However, properly written text is rarely
found in real-world scenarios and hence, oftentimes invalidates the
aforementioned foundational assumption. Recently, Large language models (LLMs)
have shown impressive performance, but can they handle the inevitable noise in
real-world data? This work tackles this critical question by investigating
LLMs' resilience against morphological variations in text. To that end, we
artificially introduce varying levels of noise into a diverse set of datasets
and systematically evaluate LLMs' robustness against the corrupt variations of
the original text. Our findings show that contrary to popular beliefs,
generative LLMs are quiet robust to noisy perturbations in text. This is a
departure from pre-trained models like BERT or RoBERTa whose performance has
been shown to be sensitive to deteriorating noisy text. Additionally, we test
LLMs' resilience on multiple real-world benchmarks that closely mimic commonly
found errors in the wild. With minimal prompting, LLMs achieve a new
state-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and
Lexical Semantic Change (LSC). To empower future research, we also release a
dataset annotated by humans stating their preference for LLM vs.
human-corrected outputs along with the code to reproduce our results.

中文翻译:
拥有干净的数据集一直是大多数自然语言处理（NLP）系统的基本假设。然而，现实场景中极少存在完全规范的文本，这一前提假设往往难以成立。近年来，大型语言模型（LLMs）展现出卓越性能，但它们能否应对真实数据中不可避免的噪声？本研究通过探究LLMs对文本形态变化的适应能力来解答这一关键问题。我们采用人工方式向多样化数据集注入不同强度的噪声，系统评估LLMs对原始文本失真版本的鲁棒性。研究发现：与普遍认知相反，生成式LLMs对文本噪声干扰表现出显著稳健性——这与BERT或RoBERTa等预训练模型形成鲜明对比，后者的性能已被证实对文本质量退化极为敏感。此外，我们在多个模拟真实场景错误的基准测试中验证了LLMs的适应性。仅需简单提示，LLMs就在语法错误修正（GEC）和词汇语义演变（LSC）基准任务上创造了新纪录。为促进后续研究，我们开源了包含人类标注偏好的数据集（对比LLM与人工修正结果）以及可复现实验的完整代码库。
