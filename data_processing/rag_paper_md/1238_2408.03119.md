# Evaluating the Translation Performance of Large Language Models Based on Euas-20

链接: http://arxiv.org/abs/2408.03119v1

原文摘要:
In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.

中文翻译:
近年来，随着深度学习技术的飞速发展，以BERT、GPT为代表的大语言模型(LLM)在自然语言处理任务中取得了突破性的成果。机器翻译(MT)作为自然语言处理的核心任务之一，同样受益于大语言模型的发展，取得了质的飞跃。尽管大语言模型在翻译性能上取得了显著的进步，但机器翻译仍然面临着诸多挑战。因此，本文构建数据集Euas-20，为研究者和开发者评估大语言模型在翻译任务上的性能、不同语言上的翻译能力以及预训练数据对大语言模型翻译能力的影响。
