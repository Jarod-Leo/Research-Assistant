# The Use of a Large Language Model for Cyberbullying Detection

链接: http://arxiv.org/abs/2402.04088v1

原文摘要:
The dominance of social media has added to the channels of bullying for
perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent
phenomenon in todays cyber world, and is a severe threat to the mental and
physical health of citizens. This opens the need to develop a robust system to
prevent bullying content from online forums, blogs, and social media platforms
to manage the impact in our society. Several machine learning (ML) algorithms
have been proposed for this purpose. However, their performances are not
consistent due to high class imbalance and generalisation issues. In recent
years, large language models (LLMs) like BERT and RoBERTa have achieved
state-of-the-art (SOTA) results in several natural language processing (NLP)
tasks. Unfortunately, the LLMs have not been applied extensively for CB
detection. In our paper, we explored the use of these models for cyberbullying
(CB) detection. We have prepared a new dataset (D2) from existing studies
(Formspring and Twitter). Our experimental results for dataset D1 and D2 showed
that RoBERTa outperformed other models.

中文翻译:
社交媒体的主导地位为施暴者增添了欺凌渠道。令人担忧的是，网络欺凌（CB）已成为当今网络世界最普遍的现象，对公民身心健康构成严重威胁。这亟需开发一个强大的系统，从在线论坛、博客和社交媒体平台中识别并阻止欺凌内容，以控制其对社会的影响。为此，已有多种机器学习（ML）算法被提出，但由于类别高度不平衡和泛化问题，其性能表现并不稳定。近年来，像BERT和RoBERTa这样的大型语言模型（LLMs）在多项自然语言处理（NLP）任务中取得了最先进的（SOTA）成果。然而，这些模型在网络欺凌检测领域的应用尚未广泛展开。本文中，我们探索了这些模型在网络欺凌（CB）检测中的应用，并基于现有研究（Formspring和Twitter）构建了一个新数据集（D2）。实验结果表明，在数据集D1和D2上，RoBERTa模型的表现优于其他模型。
