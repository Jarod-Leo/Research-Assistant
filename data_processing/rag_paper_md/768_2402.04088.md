# The Use of a Large Language Model for Cyberbullying Detection

链接: http://arxiv.org/abs/2402.04088v1

原文摘要:
The dominance of social media has added to the channels of bullying for
perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent
phenomenon in todays cyber world, and is a severe threat to the mental and
physical health of citizens. This opens the need to develop a robust system to
prevent bullying content from online forums, blogs, and social media platforms
to manage the impact in our society. Several machine learning (ML) algorithms
have been proposed for this purpose. However, their performances are not
consistent due to high class imbalance and generalisation issues. In recent
years, large language models (LLMs) like BERT and RoBERTa have achieved
state-of-the-art (SOTA) results in several natural language processing (NLP)
tasks. Unfortunately, the LLMs have not been applied extensively for CB
detection. In our paper, we explored the use of these models for cyberbullying
(CB) detection. We have prepared a new dataset (D2) from existing studies
(Formspring and Twitter). Our experimental results for dataset D1 and D2 showed
that RoBERTa outperformed other models.

中文翻译:
社交媒体主导地位的崛起为施暴者提供了新的欺凌渠道。令人担忧的是，网络欺凌（CB）已成为当今数字世界最普遍的现象，对公民身心健康构成严重威胁。这迫切需要我们开发一个强大的系统，从在线论坛、博客和社交媒体平台中识别欺凌内容，以控制其社会影响。目前已有多种机器学习（ML）算法被提出用于此目的，但由于类别高度不平衡和泛化能力不足等问题，这些算法的表现并不稳定。近年来，BERT和RoBERTa等大语言模型（LLM）在多项自然语言处理（NLP）任务中取得了最先进（SOTA）成果，然而这些模型尚未被广泛应用于网络欺凌检测领域。本研究探索了这些模型在网络欺凌检测中的应用，基于现有研究（Formspring和Twitter）构建了新数据集D2。实验结果表明，在数据集D1和D2上，RoBERTa模型的表现均优于其他模型。

（翻译说明：
1. 专业术语处理：CB/cyberbullying统一译为"网络欺凌"，SOTA译为"最先进"，LLM/NLP等专业缩写保留英文并添加中文注释
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如将"to manage the impact..."独立成句
3. 被动语态转换："have been proposed"等被动结构转为中文主动语态
4. 逻辑显化：补充"令人担忧的是"等连接词增强行文连贯性
5. 学术规范：保留数据集名称D1/D2等原始表述，技术名词首次出现标注英文原文）
