# Text2Time: Transformer-based Article Time Period Prediction

链接: http://arxiv.org/abs/2304.10859v2

原文摘要:
The task of predicting the publication period of text documents, such as news
articles, is an important but less studied problem in the field of natural
language processing. Predicting the year of a news article can be useful in
various contexts, such as historical research, sentiment analysis, and media
monitoring. In this work, we investigate the problem of predicting the
publication period of a text document, specifically a news article, based on
its textual content. In order to do so, we created our own extensive labeled
dataset of over 350,000 news articles published by The New York Times over six
decades. In our approach, we use a pretrained BERT model fine-tuned for the
task of text classification, specifically for time period prediction.This model
exceeds our expectations and provides some very impressive results in terms of
accurately classifying news articles into their respective publication decades.
The results beat the performance of the baseline model for this relatively
unexplored task of time prediction from text.

中文翻译:
预测文本文件（如新闻文章）发表时期的任务，是自然语言处理领域中一个重要但研究较少的问题。预测新闻文章的年份在历史研究、情感分析和媒体监测等多种情境下都具有实用价值。本研究基于文本内容探讨了预测新闻文章发表时期的问题。为此，我们自主构建了一个包含超过35万篇《纽约时报》新闻文章的标注数据集，这些文章横跨六十余年。在方法上，我们采用预训练的BERT模型进行微调，专门用于文本分类任务中的时期预测。该模型表现超出预期，在将新闻文章准确分类至相应发表年代方面取得了令人瞩目的成果。针对这项尚未充分探索的文本时间预测任务，该模型的性能超越了基线模型的表现。
