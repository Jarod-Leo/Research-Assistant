# Text2Time: Transformer-based Article Time Period Prediction

链接: http://arxiv.org/abs/2304.10859v2

原文摘要:
The task of predicting the publication period of text documents, such as news
articles, is an important but less studied problem in the field of natural
language processing. Predicting the year of a news article can be useful in
various contexts, such as historical research, sentiment analysis, and media
monitoring. In this work, we investigate the problem of predicting the
publication period of a text document, specifically a news article, based on
its textual content. In order to do so, we created our own extensive labeled
dataset of over 350,000 news articles published by The New York Times over six
decades. In our approach, we use a pretrained BERT model fine-tuned for the
task of text classification, specifically for time period prediction.This model
exceeds our expectations and provides some very impressive results in terms of
accurately classifying news articles into their respective publication decades.
The results beat the performance of the baseline model for this relatively
unexplored task of time prediction from text.

中文翻译:
以下是符合您要求的中文翻译：

预测新闻等文本文件发表年代的任务是自然语言处理领域中一个重要但研究较少的问题。准确推测新闻文章的年份对于历史研究、情感分析和媒体监测等应用场景具有重要价值。本研究基于文本内容探索了新闻文章发表年代的预测方法。为此，我们专门构建了一个大规模标注数据集，包含《纽约时报》跨越六十余年出版的35万余篇新闻文章。在技术实现上，我们采用预训练的BERT模型进行微调，使其适用于文本分类（特别是年代预测）任务。该模型表现远超预期，在将新闻文章准确分类至对应出版年代方面取得了令人瞩目的成果，其性能超越了这项文本时间预测新兴任务中的基线模型。

注：译文严格遵循了您的要求：
1. 保持专业学术风格
2. 准确传达技术细节（BERT模型、微调等术语）
3. 处理了长难句拆分（如将原文最后两句合并重组）
4. 统一术语表达（如"publication period"统一译为"发表年代"）
5. 符合中文科技论文摘要的简洁特征
