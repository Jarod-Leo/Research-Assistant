# Large Language Models as Code Executors: An Exploratory Study

链接: http://arxiv.org/abs/2410.06667v1

原文摘要:
The capabilities of Large Language Models (LLMs) have significantly evolved,
extending from natural language processing to complex tasks like code
understanding and generation. We expand the scope of LLMs' capabilities to a
broader context, using LLMs to execute code snippets to obtain the output. This
paper pioneers the exploration of LLMs as code executors, where code snippets
are directly fed to the models for execution, and outputs are returned. We are
the first to comprehensively examine this feasibility across various LLMs,
including OpenAI's o1, GPT-4o, GPT-3.5, DeepSeek, and Qwen-Coder. Notably, the
o1 model achieved over 90% accuracy in code execution, while others
demonstrated lower accuracy levels. Furthermore, we introduce an Iterative
Instruction Prompting (IIP) technique that processes code snippets line by
line, enhancing the accuracy of weaker models by an average of 7.22% (with the
highest improvement of 18.96%) and an absolute average improvement of 3.86%
against CoT prompting (with the highest improvement of 19.46%). Our study not
only highlights the transformative potential of LLMs in coding but also lays
the groundwork for future advancements in automated programming and the
completion of complex tasks.

中文翻译:
大型语言模型（LLM）的能力已显著提升，其应用范围从自然语言处理扩展到代码理解与生成等复杂任务。本研究进一步拓宽了LLM的能力边界，通过让模型直接执行代码片段来获取输出。本文首次系统探索了将LLM作为代码执行器的可行性，其中代码片段被直接输入模型执行并返回结果。我们对包括OpenAI的o1、GPT-4o、GPT-3.5、DeepSeek和Qwen-Coder在内的多种LLM进行了全面测试。值得注意的是，o1模型在代码执行中实现了超过90%的准确率，而其他模型表现相对较低。此外，我们提出了一种迭代指令提示（IIP）技术，通过逐行处理代码片段，使性能较弱模型的准确率平均提升7.22%（最高提升达18.96%），相较于思维链提示（CoT）实现了3.86%的绝对平均提升（最高提升达19.46%）。这项研究不仅揭示了LLM在编程领域的变革潜力，更为自动化编程和复杂任务完成的未来发展奠定了基础。
