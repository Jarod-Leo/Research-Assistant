# Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?

链接: http://arxiv.org/abs/2309.17122v1

原文摘要:
Large Language Models (LLMs) are advancing at a rapid pace, with significant
improvements at natural language processing and coding tasks. Yet, their
ability to work with formal languages representing data, specifically within
the realm of knowledge graph engineering, remains under-investigated. To
evaluate the proficiency of various LLMs, we created a set of five tasks that
probe their ability to parse, understand, analyze, and create knowledge graphs
serialized in Turtle syntax. These tasks, each embodying distinct degrees of
complexity and being able to scale with the size of the problem, have been
integrated into our automated evaluation system, the LLM-KG-Bench. The
evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4,
Claude 1.3, and Claude 2.0, as well as two freely accessible offline models,
GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth
understanding of the strengths and shortcomings of LLMs in relation to their
application within RDF knowledge graph engineering workflows utilizing Turtle
representation. While our findings show that the latest commercial models
outperform their forerunners in terms of proficiency with the Turtle language,
they also reveal an apparent weakness. These models fall short when it comes to
adhering strictly to the output formatting constraints, a crucial requirement
in this context.

中文翻译:
大型语言模型（LLMs）正以迅猛的态势发展，在自然语言处理和代码任务方面取得了显著进步。然而，它们在处理表示数据的正式语言（特别是在知识图谱工程领域）的能力仍缺乏深入研究。为评估各类LLMs的熟练程度，我们设计了一套包含五项任务的测试集，用于考察其解析、理解、分析及创建以Turtle语法序列化知识图谱的能力。这些任务各自体现不同复杂度层级，并能随问题规模扩展，已集成至我们的自动化评估系统LLM-KG-Bench中。

本次评估涵盖四款商用LLM（GPT-3.5、GPT-4、Claude 1.3和Claude 2.0）以及两款可离线免费使用的模型（GPT4All Vicuna和GPT4All Falcon 13B）。分析结果深入揭示了LLMs在采用Turtle表示的RDF知识图谱工程工作流应用中的优势与不足。研究发现，虽然最新商用模型在Turtle语言处理能力上超越了前代产品，但它们存在一个明显缺陷：无法严格遵守输出格式约束——而这正是该应用场景的关键要求。
