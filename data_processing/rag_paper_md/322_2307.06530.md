# Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study

链接: http://arxiv.org/abs/2307.06530v1

原文摘要:
This paper explores the integration of Large Language Models (LLMs) into
Automatic Speech Recognition (ASR) systems to improve transcription accuracy.
The increasing sophistication of LLMs, with their in-context learning
capabilities and instruction-following behavior, has drawn significant
attention in the field of Natural Language Processing (NLP). Our primary focus
is to investigate the potential of using an LLM's in-context learning
capabilities to enhance the performance of ASR systems, which currently face
challenges such as ambient noise, speaker accents, and complex linguistic
contexts. We designed a study using the Aishell-1 and LibriSpeech datasets,
with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.
Unfortunately, our initial experiments did not yield promising results,
indicating the complexity of leveraging LLM's in-context learning for ASR
applications. Despite further exploration with varied settings and models, the
corrected sentences from the LLMs frequently resulted in higher Word Error
Rates (WER), demonstrating the limitations of LLMs in speech applications. This
paper provides a detailed overview of these experiments, their results, and
implications, establishing that using LLMs' in-context learning capabilities to
correct potential errors in speech recognition transcriptions is still a
challenging task at the current stage.

中文翻译:
本文探讨了将大语言模型（LLMs）集成到自动语音识别（ASR）系统中以提高转录准确性的方法。随着LLMs在上下文学习能力和指令跟随行为方面的日益成熟，其在自然语言处理（NLP）领域引起了广泛关注。我们的主要研究重点是探索利用LLMs的上下文学习能力来提升ASR系统性能的潜力，当前ASR系统面临环境噪声、说话者口音和复杂语言环境等挑战。我们使用Aishell-1和LibriSpeech数据集设计了实验，并以ChatGPT和GPT-4作为LLM能力的基准。遗憾的是，初步实验并未取得预期效果，这表明利用LLM的上下文学习能力改进ASR应用具有复杂性。尽管我们尝试了多种设置和模型进行深入探索，但LLMs修正后的句子往往导致更高的词错误率（WER），这揭示了LLMs在语音应用中的局限性。本文详细概述了这些实验及其结果与启示，证实了在当前阶段利用LLMs的上下文学习能力纠正语音识别转录中的潜在错误仍是一项具有挑战性的任务。
