# Punctuation Matters! Stealthy Backdoor Attack for Language Models

链接: http://arxiv.org/abs/2312.15867v1

原文摘要:
Recent studies have pointed out that natural language processing (NLP) models
are vulnerable to backdoor attacks. A backdoored model produces normal outputs
on the clean samples while performing improperly on the texts with triggers
that the adversary injects. However, previous studies on textual backdoor
attack pay little attention to stealthiness. Moreover, some attack methods even
cause grammatical issues or change the semantic meaning of the original texts.
Therefore, they can easily be detected by humans or defense systems. In this
paper, we propose a novel stealthy backdoor attack method against textual
models, which is called \textbf{PuncAttack}. It leverages combinations of
punctuation marks as the trigger and chooses proper locations strategically to
replace them. Through extensive experiments, we demonstrate that the proposed
method can effectively compromise multiple models in various tasks. Meanwhile,
we conduct automatic evaluation and human inspection, which indicate the
proposed method possesses good performance of stealthiness without bringing
grammatical issues and altering the meaning of sentences.

中文翻译:
近期研究表明，自然语言处理（NLP）模型易受后门攻击。被植入后门的模型在处理正常样本时表现正常，但在遇到攻击者注入的特定触发文本时会产生异常输出。然而，现有文本后门攻击研究普遍忽视隐蔽性问题，部分攻击方法甚至会导致语法错误或改变原文语义，极易被人眼或防御系统察觉。本文提出一种新型隐蔽文本后门攻击方法——\textbf{标点攻击（PuncAttack）}，该方法创新性地采用组合标点符号作为触发器，并通过策略性选点进行替换。大量实验证明，该方法能有效攻陷多种任务场景下的各类模型。同时，自动化评估与人工检测结果表明，所提方法在保持高度隐蔽性的同时，既不会引发语法问题，也不会改变句子原意。
