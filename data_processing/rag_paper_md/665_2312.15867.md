# Punctuation Matters! Stealthy Backdoor Attack for Language Models

链接: http://arxiv.org/abs/2312.15867v1

原文摘要:
Recent studies have pointed out that natural language processing (NLP) models
are vulnerable to backdoor attacks. A backdoored model produces normal outputs
on the clean samples while performing improperly on the texts with triggers
that the adversary injects. However, previous studies on textual backdoor
attack pay little attention to stealthiness. Moreover, some attack methods even
cause grammatical issues or change the semantic meaning of the original texts.
Therefore, they can easily be detected by humans or defense systems. In this
paper, we propose a novel stealthy backdoor attack method against textual
models, which is called \textbf{PuncAttack}. It leverages combinations of
punctuation marks as the trigger and chooses proper locations strategically to
replace them. Through extensive experiments, we demonstrate that the proposed
method can effectively compromise multiple models in various tasks. Meanwhile,
we conduct automatic evaluation and human inspection, which indicate the
proposed method possesses good performance of stealthiness without bringing
grammatical issues and altering the meaning of sentences.

中文翻译:
近期研究指出，自然语言处理（NLP）模型易受后门攻击影响。被植入后门的模型对干净样本输出正常结果，却在面对攻击者注入的特定触发词文本时表现异常。然而，现有文本后门攻击研究普遍忽视隐蔽性，部分方法甚至引发语法错误或篡改原文本语义，导致其极易被人眼或防御系统识别。本文提出一种新型隐蔽文本后门攻击方法——**标点攻击（PuncAttack）**，通过标点符号组合作为触发机制，并策略性选择替换位置。大量实验表明，该方法能有效攻陷多种任务场景下的各类模型。同时，自动化评估与人工检测证实，该方法在保持语法正确性和语义一致性的前提下，展现出优异的隐蔽性表现。
