# Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded in Naturally Occurring Data

链接: http://arxiv.org/abs/2502.12924v1

原文摘要:
Code-switching (CS) is still a critical challenge in Natural Language
Processing (NLP). Current Large Language Models (LLMs) struggle to interpret
and generate code-switched text, primarily due to the scarcity of large-scale
CS datasets for training. This paper presents a novel methodology to generate
CS data using LLMs, and test it on the English-Spanish language pair. We
propose back-translating natural CS sentences into monolingual English, and
using the resulting parallel corpus to fine-tune LLMs to turn monolingual
sentences into CS. Unlike previous approaches to CS generation, our methodology
uses natural CS data as a starting point, allowing models to learn its natural
distribution beyond grammatical patterns. We thoroughly analyse the models'
performance through a study on human preferences, a qualitative error analysis
and an evaluation with popular automatic metrics. Results show that our
methodology generates fluent code-switched text, expanding research
opportunities in CS communication, and that traditional metrics do not
correlate with human judgement when assessing the quality of the generated CS
data. We release our code and generated dataset under a CC-BY-NC-SA license.

中文翻译:
代码转换（Code-switching, CS）在自然语言处理（NLP）领域仍是一项关键挑战。当前的大语言模型（LLMs）在理解和生成代码转换文本方面存在困难，主要源于大规模CS训练数据的稀缺。本文提出了一种利用LLMs生成CS数据的新方法，并以英语-西班牙语为对象进行验证。我们采用回译技术将自然CS语句转换为单语英语，并利用生成的平行语料库对LLMs进行微调，使其能将单语语句转化为CS文本。与以往CS生成方法不同，本方法以自然CS数据为起点，使模型能够学习超越语法规则的自然分布特征。我们通过人类偏好研究、定性错误分析及主流自动指标评估，对模型性能进行了全面分析。结果表明：该方法能生成流畅的代码转换文本，为CS交际研究开辟了新途径；同时发现传统评估指标在衡量生成CS数据质量时与人类判断存在偏差。相关代码及生成数据集以CC-BY-NC-SA协议开源发布。
