# DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation

链接: http://arxiv.org/abs/2505.04175v1

原文摘要:
Text recognition in natural images remains a challenging yet essential task,
with broad applications spanning computer vision and natural language
processing. This paper introduces a novel end-to-end framework that combines
ResNet and Vision Transformer backbones with advanced methodologies, including
Deformable Convolutions, Retrieval-Augmented Generation, and Conditional Random
Fields (CRF). These innovations collectively enhance feature representation and
improve Optical Character Recognition (OCR) performance. Specifically, the
framework substitutes standard convolution layers in the third and fourth
blocks with Deformable Convolutions, leverages adaptive dropout for
regularization, and incorporates CRF for more refined sequence modeling.
Extensive experiments conducted on six benchmark datasets IC13, IC15, SVT,
IIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving
notable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on
IIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy
of 77.77%. These results establish a new state-of-the-art for text recognition,
demonstrating the robustness of the approach across diverse and challenging
datasets.

中文翻译:
自然场景中的文本识别仍是一项极具挑战性却至关重要的任务，其应用广泛涵盖计算机视觉与自然语言处理领域。本文提出了一种新颖的端到端框架，通过将ResNet与Vision Transformer主干网络与可变形卷积、检索增强生成和条件随机场（CRF）等先进方法相结合，显著提升了特征表征能力并优化了光学字符识别（OCR）性能。具体而言，该框架在第三和第四模块中用可变形卷积替代标准卷积层，采用自适应丢弃策略进行正则化，并引入CRF实现更精细的序列建模。在IC13、IC15、SVT、IIIT5K、SVTP和CUTE80六个基准数据集上的大量实验验证了该方法的有效性，分别取得97.32%、58.26%、88.10%、74.13%、82.17%和66.67%的识别准确率，平均精度达77.77%。这些成果为文本识别领域树立了新的技术标杆，充分证明了该方法在多样化复杂数据集上的卓越鲁棒性。
