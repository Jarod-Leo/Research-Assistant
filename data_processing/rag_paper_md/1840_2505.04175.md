# DOTA: Deformable Optimized Transformer Architecture for End-to-End Text Recognition with Retrieval-Augmented Generation

链接: http://arxiv.org/abs/2505.04175v1

原文摘要:
Text recognition in natural images remains a challenging yet essential task,
with broad applications spanning computer vision and natural language
processing. This paper introduces a novel end-to-end framework that combines
ResNet and Vision Transformer backbones with advanced methodologies, including
Deformable Convolutions, Retrieval-Augmented Generation, and Conditional Random
Fields (CRF). These innovations collectively enhance feature representation and
improve Optical Character Recognition (OCR) performance. Specifically, the
framework substitutes standard convolution layers in the third and fourth
blocks with Deformable Convolutions, leverages adaptive dropout for
regularization, and incorporates CRF for more refined sequence modeling.
Extensive experiments conducted on six benchmark datasets IC13, IC15, SVT,
IIIT5K, SVTP, and CUTE80 validate the proposed method's efficacy, achieving
notable accuracies: 97.32% on IC13, 58.26% on IC15, 88.10% on SVT, 74.13% on
IIIT5K, 82.17% on SVTP, and 66.67% on CUTE80, resulting in an average accuracy
of 77.77%. These results establish a new state-of-the-art for text recognition,
demonstrating the robustness of the approach across diverse and challenging
datasets.

中文翻译:
自然场景文本识别仍是一项具有挑战性但至关重要的任务，在计算机视觉和自然语言处理领域具有广泛应用。本文提出了一种新颖的端到端框架，该框架将ResNet与Vision Transformer主干网络相结合，并整合了可变形卷积、检索增强生成和条件随机场（CRF）等先进方法。这些创新技术协同增强了特征表征能力，显著提升了光学字符识别（OCR）性能。具体而言，该框架在第三和第四模块中用可变形卷积替代标准卷积层，采用自适应丢弃策略进行正则化，并引入CRF实现更精细的序列建模。在IC13、IC15、SVT、IIIT5K、SVTP和CUTE80六个基准数据集上的大量实验验证了该方法的有效性，取得了显著准确率：IC13达97.32%、IC15达58.26%、SVT达88.10%、IIIT5K达74.13%、SVTP达82.17%、CUTE80达66.67%，平均准确率达77.77%。这些成果为文本识别树立了新的技术标杆，证明了该方法在多样化挑战性数据集上的强大鲁棒性。

（注：根据学术论文翻译规范，对专业术语如"Deformable Convolutions"采用计算机视觉领域通用译法"可变形卷积"；对"Retrieval-Augmented Generation"采用新兴技术术语"检索增强生成"；保持"ResNet"、"Vision Transformer"等专有名词原貌；通过拆分长句、调整语序等手段使中文表达符合科技论文语体特征。）
