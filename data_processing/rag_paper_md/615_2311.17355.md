# Are Large Language Models Good Fact Checkers: A Preliminary Study

链接: http://arxiv.org/abs/2311.17355v1

原文摘要:
Recently, Large Language Models (LLMs) have drawn significant attention due
to their outstanding reasoning capabilities and extensive knowledge repository,
positioning them as superior in handling various natural language processing
tasks compared to other language models. In this paper, we present a
preliminary investigation into the potential of LLMs in fact-checking. This
study aims to comprehensively evaluate various LLMs in tackling specific
fact-checking subtasks, systematically evaluating their capabilities, and
conducting a comparative analysis of their performance against pre-trained and
state-of-the-art low-parameter models. Experiments demonstrate that LLMs
achieve competitive performance compared to other small models in most
scenarios. However, they encounter challenges in effectively handling Chinese
fact verification and the entirety of the fact-checking pipeline due to
language inconsistencies and hallucinations. These findings underscore the need
for further exploration and research to enhance the proficiency of LLMs as
reliable fact-checkers, unveiling the potential capability of LLMs and the
possible challenges in fact-checking tasks.

中文翻译:
近年来，大型语言模型（LLMs）因其卓越的推理能力和庞大的知识库备受关注，相较于其他语言模型，其在处理各类自然语言处理任务中展现出显著优势。本文针对LLMs在事实核查领域的应用潜力展开初步探索，旨在全面评估不同LLMs处理特定事实核查子任务的表现，系统检验其能力边界，并与预训练模型及先进的小参数量模型进行性能对比分析。实验表明，在多数场景下LLMs能取得与其他小型模型相当的竞争力，但由于语言不一致性和幻觉问题，其在中文事实验证及完整事实核查流程中的表现仍面临挑战。这些发现揭示了LLMs作为可靠事实核查工具仍需深入探索的改进空间，同时展现了LLMs的潜在能力与事实核查任务中可能存在的障碍。
