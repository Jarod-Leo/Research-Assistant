# Are Large Language Models Good Fact Checkers: A Preliminary Study

链接: http://arxiv.org/abs/2311.17355v1

原文摘要:
Recently, Large Language Models (LLMs) have drawn significant attention due
to their outstanding reasoning capabilities and extensive knowledge repository,
positioning them as superior in handling various natural language processing
tasks compared to other language models. In this paper, we present a
preliminary investigation into the potential of LLMs in fact-checking. This
study aims to comprehensively evaluate various LLMs in tackling specific
fact-checking subtasks, systematically evaluating their capabilities, and
conducting a comparative analysis of their performance against pre-trained and
state-of-the-art low-parameter models. Experiments demonstrate that LLMs
achieve competitive performance compared to other small models in most
scenarios. However, they encounter challenges in effectively handling Chinese
fact verification and the entirety of the fact-checking pipeline due to
language inconsistencies and hallucinations. These findings underscore the need
for further exploration and research to enhance the proficiency of LLMs as
reliable fact-checkers, unveiling the potential capability of LLMs and the
possible challenges in fact-checking tasks.

中文翻译:
近年来，大型语言模型（LLMs）因其卓越的推理能力和庞大的知识库备受瞩目，在处理各类自然语言处理任务时展现出超越其他语言模型的优势。本文针对LLMs在事实核查领域的应用潜力展开初步研究，旨在通过系统评估不同LLMs处理特定事实核查子任务的能力，并与预训练模型及先进的小参数量模型进行性能对比分析。实验表明，在多数场景下LLMs能取得与其他小型模型相当的竞争力，但在中文事实验证及完整事实核查流程中，由于语言不一致性和幻觉问题仍面临挑战。这些发现揭示了LLMs作为可靠事实核查工具仍需深入探索的改进空间，同时展现了其在事实核查任务中的潜在能力与可能面临的障碍。
