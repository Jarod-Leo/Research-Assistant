# Differentially Private Natural Language Models: Recent Advances and Future Directions

链接: http://arxiv.org/abs/2301.09112v1

原文摘要:
Recent developments in deep learning have led to great success in various
natural language processing (NLP) tasks. However, these applications may
involve data that contain sensitive information. Therefore, how to achieve good
performance while also protecting the privacy of sensitive data is a crucial
challenge in NLP. To preserve privacy, Differential Privacy (DP), which can
prevent reconstruction attacks and protect against potential side knowledge, is
becoming a de facto technique for private data analysis. In recent years, NLP
in DP models (DP-NLP) has been studied from different perspectives, which
deserves a comprehensive review. In this paper, we provide the first systematic
review of recent advances in DP deep learning models in NLP. In particular, we
first discuss some differences and additional challenges of DP-NLP compared
with the standard DP deep learning. Then, we investigate some existing work on
DP-NLP and present its recent developments from three aspects: gradient
perturbation based methods, embedding vector perturbation based methods, and
ensemble model based methods. We also discuss some challenges and future
directions.

中文翻译:
深度学习的最新进展在各类自然语言处理（NLP）任务中取得了显著成效。然而，这些应用可能涉及包含敏感信息的数据。因此，如何在保证良好性能的同时保护敏感数据的隐私，成为NLP领域面临的关键挑战。为维护隐私，差分隐私（DP）技术因其能有效防范重构攻击并抵御潜在旁路知识，已成为隐私数据分析的事实标准方法。近年来，基于DP的NLP模型（DP-NLP）研究已从多角度展开，亟需系统性梳理。本文首次对NLP领域差分隐私深度学习模型的最新进展进行了全面综述：首先阐释了DP-NLP相较于标准DP深度学习的差异性特征与附加挑战；继而从梯度扰动、嵌入向量扰动和集成模型三大方法体系出发，系统考察了当前DP-NLP研究的代表性成果；最后探讨了该领域面临的挑战与未来发展方向。
