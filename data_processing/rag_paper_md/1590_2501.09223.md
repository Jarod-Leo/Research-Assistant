# Foundations of Large Language Models

链接: http://arxiv.org/abs/2501.09223v1

原文摘要:
This is a book about large language models. As indicated by the title, it
primarily focuses on foundational concepts rather than comprehensive coverage
of all cutting-edge technologies. The book is structured into four main
chapters, each exploring a key area: pre-training, generative models, prompting
techniques, and alignment methods. It is intended for college students,
professionals, and practitioners in natural language processing and related
fields, and can serve as a reference for anyone interested in large language
models.

中文翻译:
这是一本关于大语言模型的书籍。如书名所示，本书主要侧重基础概念而非前沿技术的全面覆盖。全书共分四个核心章节，分别探讨预训练、生成模型、提示工程和对齐技术四大主题。本书面向自然语言处理及相关领域的高校学生、专业技术人员和实践者，也可作为对大语言模型感兴趣人士的参考读物。
