# LLPut: Investigating Large Language Models for Bug Report-Based Input Generation

链接: http://arxiv.org/abs/2503.20578v3

原文摘要:
Failure-inducing inputs play a crucial role in diagnosing and analyzing
software bugs. Bug reports typically contain these inputs, which developers
extract to facilitate debugging. Since bug reports are written in natural
language, prior research has leveraged various Natural Language Processing
(NLP) techniques for automated input extraction. With the advent of Large
Language Models (LLMs), an important research question arises: how effectively
can generative LLMs extract failure-inducing inputs from bug reports? In this
paper, we propose LLPut, a technique to empirically evaluate the performance of
three open-source generative LLMs -- LLaMA, Qwen, and Qwen-Coder -- in
extracting relevant inputs from bug reports. We conduct an experimental
evaluation on a dataset of 206 bug reports to assess the accuracy and
effectiveness of these models. Our findings provide insights into the
capabilities and limitations of generative LLMs in automated bug diagnosis.

中文翻译:
导致失败的输入在软件缺陷诊断与分析中起着关键作用。缺陷报告通常包含这些输入，开发者会提取它们以辅助调试。由于缺陷报告采用自然语言撰写，先前研究已运用多种自然语言处理（NLP）技术实现自动化输入提取。随着大语言模型（LLM）的出现，一个重要研究问题随之产生：生成式大语言模型从缺陷报告中提取失败诱导输入的效果如何？本文提出LLPut技术，通过实证评估三种开源生成式大语言模型——LLaMA、Qwen和Qwen-Coder——从缺陷报告中提取相关输入的性能。我们在包含206份缺陷报告的数据集上开展实验评估，衡量这些模型的准确性与有效性。研究结果揭示了生成式大语言模型在自动化缺陷诊断中的能力与局限性。
