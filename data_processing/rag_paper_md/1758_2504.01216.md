# Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models

链接: http://arxiv.org/abs/2504.01216v1

原文摘要:
Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical
settings, presenting opportunities for automated detection to identify
patients. This study evaluates natural language processing approaches for
detecting PTSD from clinical interview transcripts. We compared general and
mental health-specific transformer models (BERT/RoBERTa), embedding-based
methods (SentenceBERT/LLaMA), and large language model prompting strategies
(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.
Domain-specific models significantly outperformed general models
(Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485). LLaMA embeddings with neural
networks achieved the highest performance (F1=0.700). Zero-shot prompting using
DSM-5 criteria yielded competitive results without training data (F1=0.657).
Performance varied significantly across symptom severity and comorbidity
status, with higher accuracy for severe PTSD cases and patients with comorbid
depression. Our findings highlight the potential of domain-adapted embeddings
and LLMs for scalable screening while underscoring the need for improved
detection of nuanced presentations and offering insights for developing
clinically viable AI tools for PTSD assessment.

中文翻译:
创伤后应激障碍（PTSD）在临床环境中仍存在漏诊现象，这为自动化识别患者提供了契机。本研究评估了从临床访谈记录中检测PTSD的自然语言处理方法。基于DAIC-WOZ数据集，我们对比了通用与心理健康专用Transformer模型（BERT/RoBERTa）、基于嵌入的方法（SentenceBERT/LLaMA）以及大语言模型提示策略（零样本/少样本/思维链）。领域专用模型表现显著优于通用模型（Mental-RoBERTa F1=0.643 vs RoBERTa-base 0.485）。LLaMA嵌入结合神经网络取得了最佳性能（F1=0.700），而采用DSM-5诊断标准的零样本提示策略在无训练数据情况下也展现出竞争力（F1=0.657）。模型表现随症状严重程度和共病状态存在显著差异，对重度PTSD病例和抑郁共病患者的识别准确率更高。研究结果揭示了领域适配嵌入和大语言模型在可扩展筛查中的应用潜力，同时强调需提升对复杂临床表现的检测能力，为开发临床可用的PTSD评估AI工具提供了重要启示。
