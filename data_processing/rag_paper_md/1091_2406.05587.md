# Creativity Has Left the Chat: The Price of Debiasing Language Models

链接: http://arxiv.org/abs/2406.05587v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing
but can exhibit biases and may generate toxic content. While alignment
techniques like Reinforcement Learning from Human Feedback (RLHF) reduce these
issues, their impact on creativity, defined as syntactic and semantic
diversity, remains unexplored. We investigate the unintended consequences of
RLHF on the creativity of LLMs through three experiments focusing on the
Llama-2 series. Our findings reveal that aligned models exhibit lower entropy
in token predictions, form distinct clusters in the embedding space, and
gravitate towards "attractor states", indicating limited output diversity. Our
findings have significant implications for marketers who rely on LLMs for
creative tasks such as copywriting, ad creation, and customer persona
generation. The trade-off between consistency and creativity in aligned models
should be carefully considered when selecting the appropriate model for a given
application. We also discuss the importance of prompt engineering in harnessing
the creative potential of base models.

中文翻译:
大型语言模型（LLMs）已彻底改变了自然语言处理领域，但也存在偏见并可能生成有害内容。尽管基于人类反馈的强化学习（RLHF）等对齐技术能缓解这些问题，但其对模型创造力的影响——即句法和语义多样性——仍未被充分研究。本文通过针对Llama-2系列模型的三项实验，探讨了RLHF对LLMs创造力产生的意外后果。研究发现：经过对齐的模型在词汇预测上表现出更低的熵值，在嵌入空间中形成明显聚类，并倾向于陷入"吸引态"，这表明其输出多样性受限。该结论对依赖LLMs完成创意工作的营销人员（如文案撰写、广告创作、客户画像生成等）具有重要启示。在选择适用模型时，必须审慎权衡对齐模型的一致性与创造力之间的平衡。研究还探讨了提示词工程在激发基础模型创意潜能方面的重要性。
