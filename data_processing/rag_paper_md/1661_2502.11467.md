# Approximation of Permutation Invariant Polynomials by Transformers: Efficient Construction in Column-Size

链接: http://arxiv.org/abs/2502.11467v1

原文摘要:
Transformers are a type of neural network that have demonstrated remarkable
performance across various domains, particularly in natural language processing
tasks. Motivated by this success, research on the theoretical understanding of
transformers has garnered significant attention. A notable example is the
mathematical analysis of their approximation power, which validates the
empirical expressive capability of transformers. In this study, we investigate
the ability of transformers to approximate column-symmetric polynomials, an
extension of symmetric polynomials that take matrices as input. Consequently,
we establish an explicit relationship between the size of the transformer
network and its approximation capability, leveraging the parameter efficiency
of transformers and their compatibility with symmetry by focusing on the
algebraic properties of symmetric polynomials.

中文翻译:
Transformer作为一种神经网络架构，已在多个领域展现出卓越性能，尤其在自然语言处理任务中表现突出。受此成功启发，针对Transformer理论理解的研究获得了广泛关注。其中，对其逼近能力的数学分析作为验证模型经验性表达能力的典型案例尤为突出。本研究探讨了Transformer网络逼近列对称多项式（以矩阵为输入的对称多项式扩展形式）的能力。通过聚焦对称多项式的代数特性，我们充分利用Transformer的参数效率及其与对称性的兼容优势，最终构建了网络规模与逼近能力之间的显式关系。
