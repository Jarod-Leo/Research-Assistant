# M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models

链接: http://arxiv.org/abs/2306.05179v1

原文摘要:
Despite the existence of various benchmarks for evaluating natural language
processing models, we argue that human exams are a more suitable means of
evaluating general intelligence for large language models (LLMs), as they
inherently demand a much wider range of abilities such as language
understanding, domain knowledge, and problem-solving skills. To this end, we
introduce M3Exam, a novel benchmark sourced from real and official human exam
questions for evaluating LLMs in a multilingual, multimodal, and multilevel
context. M3Exam exhibits three unique characteristics: (1) multilingualism,
encompassing questions from multiple countries that require strong multilingual
proficiency and cultural knowledge; (2) multimodality, accounting for the
multimodal nature of many exam questions to test the model's multimodal
understanding capability; and (3) multilevel structure, featuring exams from
three critical educational periods to comprehensively assess a model's
proficiency at different levels. In total, M3Exam contains 12,317 questions in
9 diverse languages with three educational levels, where about 23\% of the
questions require processing images for successful solving. We assess the
performance of top-performing LLMs on M3Exam and find that current models,
including GPT-4, still struggle with multilingual text, particularly in
low-resource and non-Latin script languages. Multimodal LLMs also perform
poorly with complex multimodal questions. We believe that M3Exam can be a
valuable resource for comprehensively evaluating LLMs by examining their
multilingual and multimodal abilities and tracking their development. Data and
evaluation code is available at \url{https://github.com/DAMO-NLP-SG/M3Exam}.

中文翻译:
尽管目前存在多种评估自然语言处理模型的基准测试，但我们认为人类考试是衡量大语言模型（LLMs）通用智能更合适的方式，因为其本质上要求更广泛的能力，如语言理解、领域知识和问题解决技能。为此，我们推出M3Exam——一个基于真实官方人类考试题目构建的创新性基准，用于在多语言、多模态、多层级场景下评估LLMs。该基准具有三大特征：（1）多语言性：涵盖多国考题，要求模型具备强大的多语言能力和文化知识；（2）多模态性：包含大量需要处理图像信息的题目，以检验模型的多模态理解能力；（3）多层次结构：选取三个关键教育阶段的考试，全面评估模型在不同认知层级的表现。M3Exam最终包含9种语言的12,317道题目，其中约23%需通过图像处理才能解答。我们对顶尖LLMs进行测试后发现，包括GPT-4在内的现有模型仍存在明显不足：在多语言文本（尤其是低资源和非拉丁语系语言）处理上表现欠佳，面对复杂多模态问题时多模态LLMs也频频失误。我们相信M3Exam能成为全面评估LLMs多语言/多模态能力、追踪其发展进程的重要资源。数据和评估代码已开源于\url{https://github.com/DAMO-NLP-SG/M3Exam}。
