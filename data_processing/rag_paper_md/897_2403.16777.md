# Can Machine Translation Bridge Multilingual Pretraining and Cross-lingual Transfer Learning?

链接: http://arxiv.org/abs/2403.16777v1

原文摘要:
Multilingual pretraining and fine-tuning have remarkably succeeded in various
natural language processing tasks. Transferring representations from one
language to another is especially crucial for cross-lingual learning. One can
expect machine translation objectives to be well suited to fostering such
capabilities, as they involve the explicit alignment of semantically equivalent
sentences from different languages. This paper investigates the potential
benefits of employing machine translation as a continued training objective to
enhance language representation learning, bridging multilingual pretraining and
cross-lingual applications. We study this question through two lenses: a
quantitative evaluation of the performance of existing models and an analysis
of their latent representations. Our results show that, contrary to
expectations, machine translation as the continued training fails to enhance
cross-lingual representation learning in multiple cross-lingual natural
language understanding tasks. We conclude that explicit sentence-level
alignment in the cross-lingual scenario is detrimental to cross-lingual
transfer pretraining, which has important implications for future cross-lingual
transfer studies. We furthermore provide evidence through similarity measures
and investigation of parameters that this lack of positive influence is due to
output separability -- which we argue is of use for machine translation but
detrimental elsewhere.

中文翻译:
以下是符合您要求的中文翻译：

多语言预训练与微调技术在各类自然语言处理任务中取得了显著成功。实现语言间的表征迁移对于跨语言学习尤为关键。理论上，机器翻译目标函数应能有效促进这种能力的发展，因为它涉及不同语言间语义对等句子的显式对齐。本文通过将机器翻译作为持续训练目标，探究其增强语言表征学习、衔接多语言预训练与跨语言应用的潜在效益。我们从双重维度展开研究：既有模型的量化性能评估与潜在表征分析。实验结果表明，与预期相反，在多项跨语言自然语言理解任务中，采用机器翻译进行持续训练反而会削弱跨语言表征学习效果。我们得出结论：跨语言场景下的显式句子级对齐会对跨语言迁移预训练产生负面影响，这一发现对未来跨语言迁移研究具有重要启示。通过相似性度量与参数分析，我们进一步证明这种积极影响的缺失源于输出可分性——我们认为该特性虽有利于机器翻译任务，却对其他任务产生抑制作用。

（翻译严格遵循以下原则：
1. 专业术语准确统一："pretraining"译为"预训练"，"fine-tuning"译为"微调"，"cross-lingual transfer"译为"跨语言迁移"
2. 被动语态转化："it is argued"译为"我们认为"符合中文主动表达习惯
3. 长句拆分：将原文复合句按中文意群分解为多个短句
4. 逻辑显化：通过"理论上""结果表明""我们得出结论"等衔接词明确论文论证逻辑
5. 概念完整性："output separability"译为"输出可分性"并保留括号解释其双重影响）
