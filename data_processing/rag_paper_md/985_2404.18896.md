# Overcoming Knowledge Barriers: Online Imitation Learning from Observation with Pretrained World Models

链接: http://arxiv.org/abs/2404.18896v1

原文摘要:
Pretraining and finetuning models has become increasingly popular in
decision-making. But there are still serious impediments in Imitation Learning
from Observation (ILfO) with pretrained models. This study identifies two
primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration
Knowledge Barrier (DKB). The EKB emerges due to the pretrained models'
limitations in handling novel observations, which leads to inaccurate action
inference. Conversely, the DKB stems from the reliance on limited demonstration
datasets, restricting the model's adaptability across diverse scenarios. We
propose separate solutions to overcome each barrier and apply them to Action
Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new
algorithm, AIME-NoB, integrates online interactions and a data-driven
regulariser to mitigate the EKB. Additionally, it uses a surrogate reward
function to broaden the policy's supported states, addressing the DKB. Our
experiments on vision-based control tasks from the DeepMind Control Suite and
MetaWorld benchmarks show that AIME-NoB significantly improves sample
efficiency and converged performance, presenting a robust framework for
overcoming the challenges in ILfO with pretrained models. Code available at
https://github.com/IcarusWizard/AIME-NoB.

中文翻译:
预训练与微调模型在决策领域的应用日益广泛，然而基于观测的模仿学习（ILfO）仍面临显著障碍。本研究揭示了两大核心挑战：具身知识壁垒（EKB）与示范知识壁垒（DKB）。EKB源于预训练模型处理新观测数据时的局限性，导致动作推断失准；DKB则因依赖有限示范数据集而制约了模型跨场景的适应能力。我们针对性地提出了解决方案，并将其应用于当前最先进的证据最大化动作推断算法（AIME），由此开发出新算法AIME-NoB。该算法通过整合在线交互机制和数据驱动正则化器来消解EKB，同时采用替代奖励函数扩展策略支持的状态空间以突破DKB。在DeepMind Control Suite和MetaWorld基准测试的视觉控制任务中，AIME-NoB显著提升了样本效率与收敛性能，为预训练模型在ILfO中的挑战提供了创新性解决框架。代码已开源：https://github.com/IcarusWizard/AIME-NoB。
