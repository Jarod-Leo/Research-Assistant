# WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct

链接: http://arxiv.org/abs/2308.09583v1

原文摘要:
Large language models (LLMs), such as GPT-4, have shown remarkable
performance in natural language processing (NLP) tasks, including challenging
mathematical reasoning. However, most existing open-source models are only
pre-trained on large-scale internet data and without math-related optimization.
In this paper, we present WizardMath, which enhances the mathematical CoT
reasoning abilities of LLMs without using external python tools, by applying
our proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method
to the domain of math. Through extensive experiments on two mathematical
reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary
capabilities of our model. Remarkably, WizardMath-Mistral 7B surpasses top-tier
open-source LLMs by a substantial margin with higher data efficiency.
Furthermore, WizardMath 70B even outperforms GPT-3.5-Turbo, Claude 2, Gemini
Pro and GPT-4-early-version. Additionally, our preliminary exploration
highlights the pivotal role of instruction evolution and process supervision in
achieving exceptional math performance. For more details refer to
https://github.com/nlpxucan/WizardLM

中文翻译:
诸如GPT-4之类的大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出卓越性能，包括具有挑战性的数学推理。然而，现有大多数开源模型仅在大规模互联网数据上进行预训练，并未针对数学相关任务进行优化。本文提出的WizardMath模型，通过将我们研发的"进化指令反馈强化学习"（RLEIF）方法应用于数学领域，在不依赖外部Python工具的情况下显著提升了LLMs的数学思维链推理能力。基于GSM8k和MATH两大数学推理基准的广泛实验表明，该模型展现出非凡性能：WizardMath-Mistral 7B以更高数据效率显著超越顶级开源LLMs；而WizardMath 70B甚至优于GPT-3.5-Turbo、Claude 2、Gemini Pro及早期版本GPT-4。初步探索还揭示了指令进化和过程监督对实现卓越数学性能的关键作用。详见https://github.com/nlpxucan/WizardLM
