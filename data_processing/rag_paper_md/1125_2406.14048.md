# Prompt Injection Attacks in Defended Systems

链接: http://arxiv.org/abs/2406.14048v1

原文摘要:
Large language models play a crucial role in modern natural language
processing technologies. However, their extensive use also introduces potential
security risks, such as the possibility of black-box attacks. These attacks can
embed hidden malicious features into the model, leading to adverse consequences
during its deployment.
  This paper investigates methods for black-box attacks on large language
models with a three-tiered defense mechanism. It analyzes the challenges and
significance of these attacks, highlighting their potential implications for
language processing system security. Existing attack and defense methods are
examined, evaluating their effectiveness and applicability across various
scenarios.
  Special attention is given to the detection algorithm for black-box attacks,
identifying hazardous vulnerabilities in language models and retrieving
sensitive information. This research presents a methodology for vulnerability
detection and the development of defensive strategies against black-box attacks
on large language models.

中文翻译:
大语言模型在现代自然语言处理技术中扮演着关键角色，但其广泛应用也带来了潜在安全隐患，例如可能遭受的黑盒攻击。这类攻击能将隐蔽的恶意特征植入模型，导致其在部署阶段产生不良后果。  
本文研究针对具有三重防御机制的大语言模型实施黑盒攻击的方法，分析此类攻击面临的挑战与重要意义，揭示其对语言处理系统安全可能产生的影响。通过考察现有攻防方法，评估其在不同场景下的有效性与适用性。  
研究重点聚焦于黑盒攻击的检测算法，旨在识别语言模型中的危险漏洞并获取敏感信息。本研究提出了一套针对大语言模型漏洞检测的方法论，以及防御黑盒攻击的策略构建方案。
