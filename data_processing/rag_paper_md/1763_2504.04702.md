# Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent

链接: http://arxiv.org/abs/2504.04702v1

原文摘要:
Recent advancements in Transformer-based architectures have led to impressive
breakthroughs in natural language processing tasks, with models such as GPT-4,
Claude, and Gemini demonstrating human-level reasoning abilities. However,
despite their high performance, concerns remain about the inherent limitations
of these models, especially when it comes to learning basic logical functions.
While complexity-theoretic analyses indicate that Transformers can represent
simple logic functions (e.g., $\mathsf{AND}$, $\mathsf{OR}$, and majority
gates) by its nature of belonging to the $\mathsf{TC}^0$ class, these results
assume ideal parameter settings and do not account for the constraints imposed
by gradient descent-based training methods. In this work, we investigate
whether Transformers can truly learn simple majority functions when trained
using gradient-based methods. We focus on a simplified variant of the
Transformer architecture and consider both $n=\mathrm{poly}(d)$ and
$n=\exp(\Omega(d))$ number of training samples, where each sample is a $d$-size
binary string paired with the output of a basic majority function. Our analysis
demonstrates that even after $\mathrm{poly}(d)$ gradient queries, the
generalization error of the Transformer model still remains substantially
large, growing exponentially with $d$. This work highlights fundamental
optimization challenges in training Transformers for the simplest logical
reasoning tasks and provides new insights into their theoretical limitations.

中文翻译:
近年来，基于Transformer架构的模型在自然语言处理任务中取得了令人瞩目的突破，GPT-4、Claude和Gemini等模型已展现出类人推理能力。然而，尽管这些模型性能卓越，其内在局限性仍引发担忧——尤其是在学习基础逻辑函数方面。虽然复杂度理论分析表明Transformer因其属于$\mathsf{TC}^0$类可天然表示简单逻辑函数（如$\mathsf{AND}$、$\mathsf{OR}$和多数表决门），但这些结论基于理想参数设定，未考虑梯度下降训练方法带来的约束。

本研究探究基于梯度方法训练的Transformer能否真正习得简单多数表决函数。我们聚焦简化版Transformer架构，分别考察$n=\mathrm{poly}(d)$和$n=\exp(\Omega(d))$数量级的训练样本（每个样本为$d$维二元字符串与基础多数函数输出的配对）。分析表明：即使经过$\mathrm{poly}(d)$次梯度查询，Transformer模型的泛化误差仍保持显著高位，且随$d$呈指数级增长。这项工作揭示了Transformer在最基本逻辑推理任务训练中的根本性优化挑战，为其理论局限性提供了新的认知视角。
