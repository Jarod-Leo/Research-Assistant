# DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection

链接: http://arxiv.org/abs/2409.06072v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.

中文翻译:
大语言模型（LLMs）在自然语言处理任务中展现出卓越能力，但其在高风险领域（如欺诈与滥用检测）的实际应用仍需深入探索。现有研究多局限于特定任务（如毒性言论或仇恨言论检测）。本文提出一套综合性基准测试集，旨在评估LLMs在多样化现实场景中识别与防范欺诈及恶意语言的表现。该基准涵盖垃圾邮件检测、仇恨言论识别、厌女语言判别等多类任务，并对Anthropic、Mistral AI及AI21系列等前沿模型进行了系统评估。研究表明：虽然LLMs在单一欺诈检测任务中展现出合格的基础性能，但其表现存在显著任务差异性，尤其对需要精细语用推理的任务（如识别多种形式的厌女语言）处理能力较弱。这些发现对LLMs在高风险应用中的负责任开发与部署具有重要启示。本基准测试集可为研究者提供系统评估LLMs多任务欺诈检测能力的工具，推动构建更稳健、可信且符合伦理规范的欺诈与滥用检测系统。
