# Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts

链接: http://arxiv.org/abs/2309.07430v1

原文摘要:
Analyzing vast textual data and summarizing key information from electronic
health records imposes a substantial burden on how clinicians allocate their
time. Although large language models (LLMs) have shown promise in natural
language processing (NLP), their effectiveness on a diverse range of clinical
summarization tasks remains unproven. In this study, we apply adaptation
methods to eight LLMs, spanning four distinct clinical summarization tasks:
radiology reports, patient questions, progress notes, and doctor-patient
dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP
metrics reveal trade-offs between models and adaptation methods. A clinical
reader study with ten physicians evaluates summary completeness, correctness,
and conciseness; in a majority of cases, summaries from our best adapted LLMs
are either equivalent (45%) or superior (36%) compared to summaries from
medical experts. The ensuing safety analysis highlights challenges faced by
both LLMs and medical experts, as we connect errors to potential medical harm
and categorize types of fabricated information. Our research provides evidence
of LLMs outperforming medical experts in clinical text summarization across
multiple tasks. This suggests that integrating LLMs into clinical workflows
could alleviate documentation burden, allowing clinicians to focus more on
patient care.

中文翻译:
分析海量文本数据并从电子健康记录中提取关键信息，给临床医生的时间分配带来了沉重负担。尽管大语言模型（LLM）在自然语言处理（NLP）领域展现出潜力，但其在多样化临床摘要任务中的有效性尚未得到验证。本研究对八种LLM模型进行了适应性改造，涵盖四大临床摘要任务：放射学报告、患者咨询、病程记录及医患对话。通过句法、语义和概念层面的NLP指标进行定量评估，揭示了不同模型与适配方法之间的权衡关系。十位医师参与的临床阅读评估从完整性、准确性和简洁性三个维度进行评价：在大多数案例中，经我们优化适配的最佳LLM生成的摘要，与医学专家摘要相比表现相当（45%）或更优（36%）。后续的安全性分析揭示了LLM和医学专家共同面临的挑战，我们将错误关联至潜在医疗风险，并对虚构信息类型进行了系统分类。本研究证实了LLM在多项临床文本摘要任务中能够超越医学专家，这表明将LLM整合到临床工作流程中有望减轻文书负担，使临床医生能更专注于患者诊疗。
