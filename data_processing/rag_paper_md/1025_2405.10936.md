# A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers

链接: http://arxiv.org/abs/2405.10936v1

原文摘要:
The rapid development of Large Language Models (LLMs) demonstrates remarkable
multilingual capabilities in natural language processing, attracting global
attention in both academia and industry. To mitigate potential discrimination
and enhance the overall usability and accessibility for diverse language user
groups, it is important for the development of language-fair technology.
Despite the breakthroughs of LLMs, the investigation into the multilingual
scenario remains insufficient, where a comprehensive survey to summarize recent
approaches, developments, limitations, and potential solutions is desirable. To
this end, we provide a survey with multiple perspectives on the utilization of
LLMs in the multilingual scenario. We first rethink the transitions between
previous and current research on pre-trained language models. Then we introduce
several perspectives on the multilingualism of LLMs, including training and
inference methods, information retrieval, model security, multi-domain with
language culture, and usage of datasets. We also discuss the major challenges
that arise in these aspects, along with possible solutions. Besides, we
highlight future research directions that aim at further enhancing LLMs with
multilingualism. The survey aims to help the research community address
multilingual problems and provide a comprehensive understanding of the core
concepts, key techniques, and latest developments in multilingual natural
language processing based on LLMs.

中文翻译:
大型语言模型（LLM）的快速发展展现了其在自然语言处理领域卓越的多语言能力，引发了全球学术界与产业界的广泛关注。为减少潜在歧视并提升技术对不同语言用户群体的整体可用性与可及性，开发语言公平技术至关重要。尽管LLM取得了突破性进展，但针对多语言场景的研究仍显不足，亟需系统性综述以归纳当前方法、进展、局限性与潜在解决方案。为此，本文从多维视角对LLM在多语言场景中的应用展开全面考察。我们首先重新审视预训练语言模型研究范式的演进路径，继而从模型训练与推理方法、信息检索、安全性、跨语言文化多领域适应以及数据集使用等维度剖析LLM的多语言特性。针对各维度涌现的核心挑战，我们同步探讨了可行的解决思路。此外，本文还指明了进一步增强LLM多语言能力的未来研究方向。本综述旨在帮助研究社群应对多语言问题，并提供基于LLM的多语言自然语言处理核心概念、关键技术与发展前沿的系统性认知。
