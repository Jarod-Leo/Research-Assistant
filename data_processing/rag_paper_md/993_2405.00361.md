# AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts

链接: http://arxiv.org/abs/2405.00361v1

原文摘要:
We introduce AdaMoLE, a novel method for fine-tuning large language models
(LLMs) through an Adaptive Mixture of Low-Rank Adaptation (LoRA) Experts.
Moving beyond conventional methods that employ a static top-k strategy for
activating experts, AdaMoLE dynamically adjusts the activation threshold using
a dedicated threshold network, adaptively responding to the varying
complexities of different tasks. By replacing a single LoRA in a layer with
multiple LoRA experts and integrating a gating function with the threshold
mechanism, AdaMoLE effectively selects and activates the most appropriate
experts based on the input context. Our extensive evaluations across a variety
of commonsense reasoning and natural language processing tasks show that
AdaMoLE exceeds baseline performance. This enhancement highlights the
advantages of AdaMoLE's adaptive selection of LoRA experts, improving model
effectiveness without a corresponding increase in the expert count. The
experimental validation not only confirms AdaMoLE as a robust approach for
enhancing LLMs but also suggests valuable directions for future research in
adaptive expert selection mechanisms, potentially broadening the scope for
optimizing model performance across diverse language processing tasks.

中文翻译:
我们提出了一种名为AdaMoLE的创新方法，通过自适应混合低秩适配专家（LoRA）来微调大型语言模型（LLM）。该方法突破了传统静态Top-K专家激活策略的局限，利用专用阈值网络动态调整激活阈值，从而灵活应对不同任务复杂度的变化。AdaMoLE通过在每层部署多个LoRA专家模块，并结合门控函数与阈值机制，实现了基于输入上下文的最优专家选择与激活。我们在常识推理和自然语言处理多任务上的系统评估表明，AdaMoLE显著超越了基线性能。这种性能提升凸显了自适应选择LoRA专家的优势——在不增加专家数量的前提下提高了模型效能。实验验证不仅证实了AdaMoLE作为增强LLM的有效途径，还为未来自适应专家选择机制的研究指明了方向，有望为多样化语言处理任务的模型性能优化开拓更广阔的空间。
