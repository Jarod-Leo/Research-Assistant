# Energy Considerations of Large Language Model Inference and Efficiency Optimizations

链接: http://arxiv.org/abs/2504.17674v1

原文摘要:
As large language models (LLMs) scale in size and adoption, their
computational and environmental costs continue to rise. Prior benchmarking
efforts have primarily focused on latency reduction in idealized settings,
often overlooking the diverse real-world inference workloads that shape energy
use. In this work, we systematically analyze the energy implications of common
inference efficiency optimizations across diverse Natural Language Processing
(NLP) and generative Artificial Intelligence (AI) workloads, including
conversational AI and code generation. We introduce a modeling approach that
approximates real-world LLM workflows through a binning strategy for
input-output token distributions and batch size variations. Our empirical
analysis spans software frameworks, decoding strategies, GPU architectures,
online and offline serving settings, and model parallelism configurations. We
show that the effectiveness of inference optimizations is highly sensitive to
workload geometry, software stack, and hardware accelerators, demonstrating
that naive energy estimates based on FLOPs or theoretical GPU utilization
significantly underestimate real-world energy consumption. Our findings reveal
that the proper application of relevant inference efficiency optimizations can
reduce total energy use by up to 73% from unoptimized baselines. These insights
provide a foundation for sustainable LLM deployment and inform energy-efficient
design strategies for future AI infrastructure.

中文翻译:
随着大语言模型（LLM）规模与应用范围的扩大，其计算成本和环境代价持续攀升。现有基准测试主要关注理想化场景下的延迟降低，往往忽视了实际多样化推理工作负载对能耗的影响。本研究系统分析了自然语言处理（NLP）和生成式人工智能（AI）任务（包括对话式AI和代码生成）中常见推理效率优化策略的能耗影响。我们提出一种建模方法，通过输入-输出令牌分布分箱策略和批量大小变化来模拟真实LLM工作流。实证分析涵盖软件框架、解码策略、GPU架构、在线/离线服务场景以及模型并行配置。研究表明：推理优化效果对工作负载几何特征、软件栈和硬件加速器高度敏感，基于浮点运算次数（FLOPs）或理论GPU利用率的简单能耗估算会显著低估实际能耗。实验发现合理应用相关推理效率优化可使总能耗较未优化基线降低最高达73%。这些发现为可持续LLM部署奠定了基础，并为未来AI基础设施的能效设计策略提供了依据。
