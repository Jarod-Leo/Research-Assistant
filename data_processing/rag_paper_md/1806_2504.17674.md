# Energy Considerations of Large Language Model Inference and Efficiency Optimizations

链接: http://arxiv.org/abs/2504.17674v1

原文摘要:
As large language models (LLMs) scale in size and adoption, their
computational and environmental costs continue to rise. Prior benchmarking
efforts have primarily focused on latency reduction in idealized settings,
often overlooking the diverse real-world inference workloads that shape energy
use. In this work, we systematically analyze the energy implications of common
inference efficiency optimizations across diverse Natural Language Processing
(NLP) and generative Artificial Intelligence (AI) workloads, including
conversational AI and code generation. We introduce a modeling approach that
approximates real-world LLM workflows through a binning strategy for
input-output token distributions and batch size variations. Our empirical
analysis spans software frameworks, decoding strategies, GPU architectures,
online and offline serving settings, and model parallelism configurations. We
show that the effectiveness of inference optimizations is highly sensitive to
workload geometry, software stack, and hardware accelerators, demonstrating
that naive energy estimates based on FLOPs or theoretical GPU utilization
significantly underestimate real-world energy consumption. Our findings reveal
that the proper application of relevant inference efficiency optimizations can
reduce total energy use by up to 73% from unoptimized baselines. These insights
provide a foundation for sustainable LLM deployment and inform energy-efficient
design strategies for future AI infrastructure.

中文翻译:
随着大语言模型（LLM）规模和应用范围的扩大，其计算成本和环境代价持续攀升。现有基准测试主要关注理想化场景下的延迟降低，往往忽视了影响能耗的多样化现实推理工作负载。本研究系统分析了自然语言处理（NLP）和生成式人工智能（AI）工作负载（包括对话式AI和代码生成）中常见推理效率优化对能耗的影响，提出通过输入-输出令牌分布分箱策略和批量大小变化来模拟真实LLM工作流的建模方法。我们的实证分析涵盖软件框架、解码策略、GPU架构、在线/离线服务场景以及模型并行配置。研究表明：推理优化的效果对工作负载几何特征、软件栈和硬件加速器高度敏感，基于浮点运算次数（FLOPs）或理论GPU利用率的原始能耗估算会显著低估实际能耗。实验发现，合理应用相关推理效率优化可使总能耗较未优化基线降低最高达73%。这些发现为可持续LLM部署奠定了基础，并为未来AI基础设施的能效设计策略提供了理论依据。

（翻译说明：采用技术文档的严谨风格，保留"FLOPs"等专业术语首现时的英文标注；将"binning strategy"译为"分箱策略"符合数据科学领域术语；"workload geometry"意译为"工作负载几何特征"以准确传达空间维度含义；通过拆分英文长句为中文短句结构（如最后一句），确保专业性与可读性平衡）
