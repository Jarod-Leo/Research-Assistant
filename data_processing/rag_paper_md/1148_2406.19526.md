# TocBERT: Medical Document Structure Extraction Using Bidirectional Transformers

链接: http://arxiv.org/abs/2406.19526v1

原文摘要:
Text segmentation holds paramount importance in the field of Natural Language
Processing (NLP). It plays an important role in several NLP downstream tasks
like information retrieval and document summarization. In this work, we propose
a new solution, namely TocBERT, for segmenting texts using bidirectional
transformers. TocBERT represents a supervised solution trained on the detection
of titles and sub-titles from their semantic representations. This task was
formulated as a named entity recognition (NER) problem. The solution has been
applied on a medical text segmentation use-case where the Bio-ClinicalBERT
model is fine-tuned to segment discharge summaries of the MIMIC-III dataset.
The performance of TocBERT has been evaluated on a human-labeled ground truth
corpus of 250 notes. It achieved an F1-score of 84.6% when evaluated on a
linear text segmentation problem and 72.8% on a hierarchical text segmentation
problem. It outperformed a carefully designed rule-based solution, particularly
in distinguishing titles from subtitles.

中文翻译:
文本分割在自然语言处理（NLP）领域具有至关重要的作用，对信息检索、文档摘要等下游任务影响显著。本研究提出了一种基于双向Transformer的新型解决方案TocBERT，通过检测标题与副标题的语义表征实现文本分割。该任务被构建为命名实体识别（NER）问题，并以医疗文本分割为应用场景：通过微调Bio-ClinicalBERT模型对MIMIC-III数据集中的出院小结进行分段。在包含250份人工标注医疗记录的测试集上，TocBERT在线性文本分割任务中取得84.6%的F1值，在层级文本分割任务中达到72.8%的F1值。相较于精心设计的基于规则的解决方案，该模型在区分主副标题方面表现尤为突出。
