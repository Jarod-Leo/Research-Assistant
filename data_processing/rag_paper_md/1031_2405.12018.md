# Continuous Sign Language Recognition with Adapted Conformer via Unsupervised Pretraining

链接: http://arxiv.org/abs/2405.12018v1

原文摘要:
Conventional Deep Learning frameworks for continuous sign language
recognition (CSLR) are comprised of a single or multi-modal feature extractor,
a sequence-learning module, and a decoder for outputting the glosses. The
sequence learning module is a crucial part wherein transformers have
demonstrated their efficacy in the sequence-to-sequence tasks. Analyzing the
research progress in the field of Natural Language Processing and Speech
Recognition, a rapid introduction of various transformer variants is observed.
However, in the realm of sign language, experimentation in the sequence
learning component is limited. In this work, the state-of-the-art Conformer
model for Speech Recognition is adapted for CSLR and the proposed model is
termed ConSignformer. This marks the first instance of employing Conformer for
a vision-based task. ConSignformer has bimodal pipeline of CNN as feature
extractor and Conformer for sequence learning. For improved context learning we
also introduce Cross-Modal Relative Attention (CMRA). By incorporating CMRA
into the model, it becomes more adept at learning and utilizing complex
relationships within the data. To further enhance the Conformer model,
unsupervised pretraining called Regressional Feature Extraction is conducted on
a curated sign language dataset. The pretrained Conformer is then fine-tuned
for the downstream recognition task. The experimental results confirm the
effectiveness of the adopted pretraining strategy and demonstrate how CMRA
contributes to the recognition process. Remarkably, leveraging a
Conformer-based backbone, our model achieves state-of-the-art performance on
the benchmark datasets: PHOENIX-2014 and PHOENIX-2014T.

中文翻译:
传统的连续手语识别（CSLR）深度学习框架通常由单模态或多模态特征提取器、序列学习模块以及输出词汇的解码器组成。其中序列学习模块作为核心组件，Transformer架构已在序列到序列任务中展现出卓越性能。通过分析自然语言处理与语音识别领域的研究进展，可观察到各类Transformer变体正被快速引入。然而在手语研究领域，针对序列学习模块的创新探索仍较为有限。本研究将语音识别领域最先进的Conformer模型适配于CSLR任务，提出名为ConSignformer的新型架构，这标志着Conformer首次被应用于基于视觉的任务。ConSignformer采用CNN作为特征提取器与Conformer序列学习的双模态架构，为增强上下文建模能力，创新性地提出跨模态相对注意力机制（CMRA）。该机制通过捕捉数据间复杂关联关系显著提升模型性能。为进一步优化Conformer，我们在精选手语数据集上采用回归特征提取方法进行无监督预训练，随后对下游识别任务进行微调。实验结果验证了所采用预训练策略的有效性，并证实CMRA对识别过程的促进作用。值得注意的是，基于Conformer的骨干网络使我们的模型在PHOENIX-2014和PHOENIX-2014T基准数据集上取得了当前最优性能。
