# IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities

链接: http://arxiv.org/abs/2408.12902v1

原文摘要:
In the field of multimodal large language models (MLLMs), common methods
typically involve unfreezing the language model during training to foster
profound visual understanding. However, the fine-tuning of such models with
vision-language data often leads to a diminution of their natural language
processing (NLP) capabilities. To avoid this performance degradation, a
straightforward solution is to freeze the language model while developing
multimodal competencies. Unfortunately, previous works have not attained
satisfactory outcomes. Building on the strategy of freezing the language model,
we conduct thorough structural exploration and introduce the Inner-Adaptor
Architecture (IAA). Specifically, the architecture incorporates multiple
multimodal adaptors at varying depths within the large language model to
facilitate direct interaction with the inherently text-oriented transformer
layers, thereby enabling the frozen language model to acquire multimodal
capabilities. Unlike previous approaches of freezing language models that
require large-scale aligned data, our proposed architecture is able to achieve
superior performance on small-scale datasets. We conduct extensive experiments
to improve the general multimodal capabilities and visual grounding abilities
of the MLLM. Our approach remarkably outperforms previous state-of-the-art
methods across various vision-language benchmarks without sacrificing
performance on NLP tasks. Code and models are available at
https://github.com/360CVGroup/Inner-Adaptor-Architecture.

中文翻译:
在多模态大语言模型（MLLMs）研究领域，现有方法通常需在训练阶段解冻语言模型以促进深层次的视觉理解。然而，这类模型通过视觉-语言数据进行微调时，常导致其自然语言处理（NLP）能力下降。为避免性能退化，直接解决方案是在开发多模态能力时冻结语言模型参数，但此前工作尚未取得理想效果。基于冻结语言模型的策略，我们通过深入结构探索提出了内部适配器架构（IAA）。该架构在大型语言模型不同深度嵌入多个多模态适配器，使其与原本面向文本的Transformer层直接交互，从而让冻结的语言模型获得多模态能力。不同于以往冻结语言模型方法需依赖大规模对齐数据，我们提出的架构能在小规模数据集上实现卓越性能。通过大量实验，我们提升了MLLM的通用多模态能力和视觉定位能力。该方法在各类视觉-语言基准测试中显著超越先前最优方案，且未牺牲NLP任务表现。代码与模型已开源：https://github.com/360CVGroup/Inner-Adaptor-Architecture。
