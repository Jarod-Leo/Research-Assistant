# Historical German Text Normalization Using Type- and Token-Based Language Modeling

链接: http://arxiv.org/abs/2409.02841v1

原文摘要:
Historic variations of spelling poses a challenge for full-text search or
natural language processing on historical digitized texts. To minimize the gap
between the historic orthography and contemporary spelling, usually an
automatic orthographic normalization of the historical source material is
pursued. This report proposes a normalization system for German literary texts
from c. 1700-1900, trained on a parallel corpus. The proposed system makes use
of a machine learning approach using Transformer language models, combining an
encoder-decoder model to normalize individual word types, and a pre-trained
causal language model to adjust these normalizations within their context. An
extensive evaluation shows that the proposed system provides state-of-the-art
accuracy, comparable with a much larger fully end-to-end sentence-based
normalization system, fine-tuning a pre-trained Transformer large language
model. However, the normalization of historical text remains a challenge due to
difficulties for models to generalize, and the lack of extensive high-quality
parallel data.

中文翻译:
历史拼写变体对数字化古籍的全文检索或自然语言处理构成挑战。为缩小历史正字法与当代拼写的差异，通常需对原始史料进行自动拼写规范化处理。本研究提出针对约1700-1900年德语文学文本的规范化系统，基于平行语料库训练完成。该系统采用Transformer语言模型的机器学习方法，结合编码器-解码器模型实现单词类型层面的规范化，并利用预训练因果语言模型进行上下文适配调整。综合评估表明，该系统准确率达到当前最优水平，其性能可与基于完整句子的端到端规范化系统（通过微调预训练大型Transformer语言模型实现）相媲美，而后者所需参数量更为庞大。然而，由于模型泛化能力不足及高质量平行语料匮乏，历史文本规范化仍面临诸多挑战。
