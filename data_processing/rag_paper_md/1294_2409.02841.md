# Historical German Text Normalization Using Type- and Token-Based Language Modeling

链接: http://arxiv.org/abs/2409.02841v1

原文摘要:
Historic variations of spelling poses a challenge for full-text search or
natural language processing on historical digitized texts. To minimize the gap
between the historic orthography and contemporary spelling, usually an
automatic orthographic normalization of the historical source material is
pursued. This report proposes a normalization system for German literary texts
from c. 1700-1900, trained on a parallel corpus. The proposed system makes use
of a machine learning approach using Transformer language models, combining an
encoder-decoder model to normalize individual word types, and a pre-trained
causal language model to adjust these normalizations within their context. An
extensive evaluation shows that the proposed system provides state-of-the-art
accuracy, comparable with a much larger fully end-to-end sentence-based
normalization system, fine-tuning a pre-trained Transformer large language
model. However, the normalization of historical text remains a challenge due to
difficulties for models to generalize, and the lack of extensive high-quality
parallel data.

中文翻译:
历史拼写变体对数字化历史文献的全文检索和自然语言处理构成挑战。为缩小历史正字法与当代拼写间的差异，学界通常会对原始史料进行自动拼写规范化处理。本报告提出一种针对约1700-1900年德语文学文本的规范化系统，该系统基于平行语料库训练完成。所提出的系统采用Transformer语言模型的机器学习方法，结合编码器-解码器模型实现单词类型的规范化，并利用预训练因果语言模型进行上下文适配。综合评估表明，该系统达到了当前最优准确率，其性能可与基于完整句子的端到端规范化系统相媲美——后者需对预训练的大型Transformer语言模型进行微调且参数量更为庞大。然而，由于模型泛化能力不足及高质量平行语料数据的匮乏，历史文本规范化仍面临诸多挑战。
