# On the application of Large Language Models for language teaching and assessment technology

链接: http://arxiv.org/abs/2307.08393v1

原文摘要:
The recent release of very large language models such as PaLM and GPT-4 has
made an unprecedented impact in the popular media and public consciousness,
giving rise to a mixture of excitement and fear as to their capabilities and
potential uses, and shining a light on natural language processing research
which had not previously received so much attention. The developments offer
great promise for education technology, and in this paper we look specifically
at the potential for incorporating large language models in AI-driven language
teaching and assessment systems. We consider several research areas and also
discuss the risks and ethical considerations surrounding generative AI in
education technology for language learners. Overall we find that larger
language models offer improvements over previous models in text generation,
opening up routes toward content generation which had not previously been
plausible. For text generation they must be prompted carefully and their
outputs may need to be reshaped before they are ready for use. For automated
grading and grammatical error correction, tasks whose progress is checked on
well-known benchmarks, early investigations indicate that large language models
on their own do not improve on state-of-the-art results according to standard
evaluation metrics. For grading it appears that linguistic features established
in the literature should still be used for best performance, and for error
correction it may be that the models can offer alternative feedback styles
which are not measured sensitively with existing methods. In all cases, there
is work to be done to experiment with the inclusion of large language models in
education technology for language learners, in order to properly understand and
report on their capacities and limitations, and to ensure that foreseeable
risks such as misinformation and harmful bias are mitigated.

中文翻译:
近期，PaLM和GPT-4等超大规模语言模型的发布在主流媒体和公众认知领域引发了前所未有的震动。这些模型展现的能力与潜在应用既令人振奋又引发忧虑，同时也让自然语言处理研究首次获得如此广泛的关注。这一发展为教育技术领域带来了巨大机遇，本文重点探讨将大语言模型整合到AI驱动的语言教学与测评系统中的可能性。我们考察了多个研究方向，并讨论了生成式AI在教育技术应用中涉及的语言学习者风险与伦理问题。

总体研究发现，大语言模型在文本生成方面较前代模型有所提升，为过去难以实现的内容生成开辟了新路径。但使用时需精心设计提示词，且生成内容往往需要二次加工才能投入使用。在自动评分和语法纠错这两个具有标准基准测试的领域，初期研究表明：依据现有评估指标，大语言模型单独使用时尚未突破最先进系统的性能上限。评分任务中，文献中确立的语言特征仍是保证最佳表现的关键要素；而纠错任务中，这些模型或许能提供现有评估方法尚未精准捕捉的新型反馈模式。

所有应用场景下，要将大语言模型有效整合至语言学习者的教育技术中，仍需开展大量实验研究，以准确理解并报告其能力边界，同时确保能有效规避错误信息和有害偏见等可预见的风险。
