# On the application of Large Language Models for language teaching and assessment technology

链接: http://arxiv.org/abs/2307.08393v1

原文摘要:
The recent release of very large language models such as PaLM and GPT-4 has
made an unprecedented impact in the popular media and public consciousness,
giving rise to a mixture of excitement and fear as to their capabilities and
potential uses, and shining a light on natural language processing research
which had not previously received so much attention. The developments offer
great promise for education technology, and in this paper we look specifically
at the potential for incorporating large language models in AI-driven language
teaching and assessment systems. We consider several research areas and also
discuss the risks and ethical considerations surrounding generative AI in
education technology for language learners. Overall we find that larger
language models offer improvements over previous models in text generation,
opening up routes toward content generation which had not previously been
plausible. For text generation they must be prompted carefully and their
outputs may need to be reshaped before they are ready for use. For automated
grading and grammatical error correction, tasks whose progress is checked on
well-known benchmarks, early investigations indicate that large language models
on their own do not improve on state-of-the-art results according to standard
evaluation metrics. For grading it appears that linguistic features established
in the literature should still be used for best performance, and for error
correction it may be that the models can offer alternative feedback styles
which are not measured sensitively with existing methods. In all cases, there
is work to be done to experiment with the inclusion of large language models in
education technology for language learners, in order to properly understand and
report on their capacities and limitations, and to ensure that foreseeable
risks such as misinformation and harmful bias are mitigated.

中文翻译:
近期，PaLM和GPT-4等超大规模语言模型的发布在公众媒体与社会认知层面引发了前所未有的震动。这些模型展现的能力与潜在用途既令人振奋又引发忧虑，同时也使自然语言处理研究首次获得如此广泛的关注。这一发展为教育技术领域带来了巨大机遇，本文重点探讨将大语言模型整合至AI驱动的语言教学与测评系统的可能性。

我们考察了多个研究方向，并针对语言学习类教育技术中生成式AI的风险与伦理问题展开讨论。总体而言，大语言模型在文本生成方面较前代模型有显著提升，为过去难以实现的内容生成开辟了新路径。实际应用中需精心设计提示词，且生成内容往往需要二次加工才能投入使用。

在自动评分和语法纠错这两个具有成熟基准测试的领域，初期研究表明：依据标准评估指标，大语言模型自身性能尚未突破当前最优水平。评分任务中，文献确立的语言特征仍是保证最佳表现的关键要素；而纠错任务中，模型或许能提供现有评估方法无法灵敏捕捉的新型反馈模式。

所有应用场景下，都需要通过系统实验来验证大语言模型在语言学习技术中的整合效果，从而准确认识并阐明其能力边界，同时防范错误信息和有害偏见等可预见的风险。这要求研究者在模型部署过程中持续优化技术方案，建立有效的风险缓释机制。
