# Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond

链接: http://arxiv.org/abs/2304.13712v2

原文摘要:
This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{https://github.com/Mooler0410/LLMsPracticalGuide}.

中文翻译:
本文为从事下游自然语言处理（NLP）任务的大语言模型（LLMs）实践者和终端用户提供了一份全面实用的指南。我们从模型、数据和下游任务三个维度，深入探讨了LLMs的应用方法与核心洞见。首先，我们对当前GPT类和BERT类大语言模型进行了系统性介绍与概要梳理；其次，重点分析了预训练数据、训练数据与测试数据对模型性能的影响；最关键的是，我们针对知识密集型任务、传统自然语言理解任务、文本生成任务、涌现能力等不同NLP场景，详细论证了LLMs的适用情形与局限边界，通过具体用例与非用例阐明其实际应用效果。研究同时揭示了数据要素的关键作用，剖析了各类NLP任务面临的特殊挑战。此外，我们还探究了LLMs中伪相关性偏差的影响机制，并深入讨论了模型效率、成本与延迟等实际部署中的关键考量。本指南旨在为研究者和实践者提供LLMs应用的宝贵经验与最佳实践，助力各类NLP任务的成功实施。相关实践资源清单持续更新于：\url{https://github.com/Mooler0410/LLMsPracticalGuide}。

（注：根据学术摘要的文体特征，翻译时着重处理了以下要点：
1. 专业术语统一："downstream tasks"译为"下游任务"、"emergent abilities"译为"涌现能力"
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句
3. 逻辑显化：通过"首先/其次/最关键的是"等连接词强化论证层次
4. 概念整合："spurious biases"译为"伪相关性偏差"以准确传达技术含义
5. 被动语态转化："can be found at"转为主动式"持续更新于"
6. 保留技术文档客观性，同时通过"助力"等动词增强指南的实践指导价值）
