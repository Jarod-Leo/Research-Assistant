# Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond

链接: http://arxiv.org/abs/2304.13712v2

原文摘要:
This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{https://github.com/Mooler0410/LLMsPracticalGuide}.

中文翻译:
本文为从业者和终端用户在处理下游自然语言处理（NLP）任务时使用大型语言模型（LLMs）提供了一份全面实用的指南。我们从模型、数据和下游任务三个维度，深入探讨了LLMs的应用策略与洞见。首先，我们对当前GPT类和BERT类LLMs进行了系统性介绍与梳理。随后，我们分析了预训练数据、训练数据和测试数据对模型性能的影响机制。最为关键的是，我们针对知识密集型任务、传统自然语言理解任务、文本生成任务、涌现能力等不同NLP任务场景，详细论证了LLMs的适用情形与局限边界。通过大量实际用例与非适用案例的对比分析，我们清晰呈现了LLMs在真实场景中的实践价值与约束条件。研究同时揭示了数据质量对各类NLP任务的关键作用，以及不同任务面临的独特挑战。此外，我们还探究了虚假偏差对LLMs的影响机制，并深入讨论了效率、成本、延迟等实际部署中必须考量的核心要素。本指南旨在为研究者和实践者提供有价值的见解与最佳实践，推动LLMs在多样化NLP任务中的成功应用。实时更新的LLMs实践资源精选列表详见：\url{https://github.com/Mooler0410/LLMsPracticalGuide}。
