# LegalLens: Leveraging LLMs for Legal Violation Identification in Unstructured Text

链接: http://arxiv.org/abs/2402.04335v1

原文摘要:
In this study, we focus on two main tasks, the first for detecting legal
violations within unstructured textual data, and the second for associating
these violations with potentially affected individuals. We constructed two
datasets using Large Language Models (LLMs) which were subsequently validated
by domain expert annotators. Both tasks were designed specifically for the
context of class-action cases. The experimental design incorporated fine-tuning
models from the BERT family and open-source LLMs, and conducting few-shot
experiments using closed-source LLMs. Our results, with an F1-score of 62.69\%
(violation identification) and 81.02\% (associating victims), show that our
datasets and setups can be used for both tasks. Finally, we publicly release
the datasets and the code used for the experiments in order to advance further
research in the area of legal natural language processing (NLP).

中文翻译:
本研究聚焦两项核心任务：一是从非结构化文本数据中识别违法行为，二是将这些违法行为与潜在受影响个体进行关联。我们利用大语言模型（LLMs）构建了两个专用数据集，并经由领域专家标注员完成验证，两项任务均专门针对集体诉讼场景设计。实验方案融合了BERT系列模型的微调、开源大语言模型的应用，以及基于闭源大语言模型的少样本学习实验。最终取得的F1值分别为62.69%（违法行为识别）和81.02%（受害者关联），证明所构建的数据集与实验框架能有效支持两项任务。为推动法律自然语言处理领域的深入研究，我们已公开实验所用数据集及完整代码库。

（翻译说明：
1. 专业术语处理："class-action cases"译为"集体诉讼"符合法律术语规范，"few-shot experiments"译为"少样本学习实验"保持NLP领域术语一致性
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"which were..."定语从句转换为独立分句
3. 数据呈现：精确保留原始数值（62.69%、81.02%）及技术指标（F1值）
4. 被动语态转换：将"were validated by"等被动结构转为主动式"完成验证"
5. 概念显化："advance further research"译为"推动深入研究"增强表达力度
6. 技术名词保留：LLMs、BERT等专业缩写首次出现时保留英文缩写并标注全称）
