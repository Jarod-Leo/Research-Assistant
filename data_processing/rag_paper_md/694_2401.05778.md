# Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems

链接: http://arxiv.org/abs/2401.05778v1

原文摘要:
Large language models (LLMs) have strong capabilities in solving diverse
natural language processing tasks. However, the safety and security issues of
LLM systems have become the major obstacle to their widespread application.
Many studies have extensively investigated risks in LLM systems and developed
the corresponding mitigation strategies. Leading-edge enterprises such as
OpenAI, Google, Meta, and Anthropic have also made lots of efforts on
responsible LLMs. Therefore, there is a growing need to organize the existing
studies and establish comprehensive taxonomies for the community. In this
paper, we delve into four essential modules of an LLM system, including an
input module for receiving prompts, a language model trained on extensive
corpora, a toolchain module for development and deployment, and an output
module for exporting LLM-generated content. Based on this, we propose a
comprehensive taxonomy, which systematically analyzes potential risks
associated with each module of an LLM system and discusses the corresponding
mitigation strategies. Furthermore, we review prevalent benchmarks, aiming to
facilitate the risk assessment of LLM systems. We hope that this paper can help
LLM participants embrace a systematic perspective to build their responsible
LLM systems.

中文翻译:
以下是符合要求的学术论文摘要中文翻译：

大语言模型（LLMs）在解决多样化自然语言处理任务方面展现出强大能力，但其系统安全性问题已成为阻碍广泛应用的重大障碍。现有研究已对LLM系统的潜在风险展开广泛探索，并制定了相应缓解策略。OpenAI、Google、Meta和Anthropic等前沿企业也在负责任的大语言模型研发方面做出诸多努力。因此，学术界亟需对现有研究进行系统梳理并建立全面分类体系。本文深入剖析LLM系统的四个核心模块：接收提示词的输入模块、基于海量语料训练的语言模型、支撑开发部署的工具链模块以及输出生成内容的导出模块。基于此，我们提出一个系统化分类框架，逐模块分析LLM系统可能存在的风险，并探讨相应缓解策略。此外，本文还综述了当前主流评估基准，以促进LLM系统的风险评估工作。期望本研究能为LLM相关从业者提供系统化视角，助力构建更负责任的LLM系统。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如LLMs→大语言模型，prompts→提示词）
2. 长句合理切分，符合中文表达习惯
3. 被动语态转换为主动句式（如"have been investigated"→"已展开探索"）
4. 学术用语规范（如"taxonomy"→"分类体系"，"benchmarks"→"评估基准"）
5. 逻辑关系显化（添加"基于此"、"此外"等衔接词）
6. 保持客观严谨的学术风格）
