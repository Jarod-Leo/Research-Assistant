# TasTe: Teaching Large Language Models to Translate through Self-Reflection

链接: http://arxiv.org/abs/2406.08434v1

原文摘要:
Large language models (LLMs) have exhibited remarkable performance in various
natural language processing tasks. Techniques like instruction tuning have
effectively enhanced the proficiency of LLMs in the downstream task of machine
translation. However, the existing approaches fail to yield satisfactory
translation outputs that match the quality of supervised neural machine
translation (NMT) systems. One plausible explanation for this discrepancy is
that the straightforward prompts employed in these methodologies are unable to
fully exploit the acquired instruction-following capabilities. To this end, we
propose the TasTe framework, which stands for translating through
self-reflection. The self-reflection process includes two stages of inference.
In the first stage, LLMs are instructed to generate preliminary translations
and conduct self-assessments on these translations simultaneously. In the
second stage, LLMs are tasked to refine these preliminary translations
according to the evaluation results. The evaluation results in four language
directions on the WMT22 benchmark reveal the effectiveness of our approach
compared to existing methods. Our work presents a promising approach to unleash
the potential of LLMs and enhance their capabilities in MT. The codes and
datasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越性能。指令微调等技术有效提升了LLMs在机器翻译下游任务中的表现，但现有方法仍无法产生与有监督神经机器翻译（NMT）系统相媲美的译文质量。这一差距的合理解释在于：当前方法采用的简单提示模板难以充分激发模型习得的指令遵循能力。为此，我们提出TasTe框架——通过自反思实现翻译提升。该自反思过程包含两阶段推理：第一阶段指导LLMs生成初始译文并同步进行自我评估，第二阶段要求LLMs根据评估结果优化初始译文。在WMT22基准测试中，四个语言方向的评估结果表明本方法显著优于现有技术。本研究为释放LLMs潜力、增强其机器翻译能力提供了可行路径。相关代码与数据集已开源于https://github.com/YutongWang1216/ReflectionLLMMT。
