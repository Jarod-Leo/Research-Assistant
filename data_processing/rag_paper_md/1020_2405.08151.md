# Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness

链接: http://arxiv.org/abs/2405.08151v1

原文摘要:
Large language models (LLM) have demonstrated remarkable capabilities in
various biomedical natural language processing (NLP) tasks, leveraging the
demonstration within the input context to adapt to new tasks. However, LLM is
sensitive to the selection of demonstrations. To address the hallucination
issue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by
retrieving pertinent information from an established database. Nonetheless,
existing research work lacks rigorous evaluation of the impact of
retrieval-augmented large language models on different biomedical NLP tasks.
This deficiency makes it challenging to ascertain the capabilities of RAL
within the biomedical domain. Moreover, the outputs from RAL are affected by
retrieving the unlabeled, counterfactual, or diverse knowledge that is not well
studied in the biomedical domain. However, such knowledge is common in the real
world. Finally, exploring the self-awareness ability is also crucial for the
RAL system. So, in this paper, we systematically investigate the impact of RALs
on 5 different biomedical tasks (triple extraction, link prediction,
classification, question answering, and natural language inference). We analyze
the performance of RALs in four fundamental abilities, including unlabeled
robustness, counterfactual robustness, diverse robustness, and negative
awareness. To this end, we proposed an evaluation framework to assess the RALs'
performance on different biomedical NLP tasks and establish four different
testbeds based on the aforementioned fundamental abilities. Then, we evaluate 3
representative LLMs with 3 different retrievers on 5 tasks over 9 datasets.

中文翻译:
大型语言模型（LLM）在各类生物医学自然语言处理（NLP）任务中展现出卓越能力，通过输入上下文中的示例适应新任务。然而，LLM对示例选择极为敏感。针对LLM固有的幻觉问题，检索增强型LLM（RAL）通过从既定数据库中检索相关信息提供了解决方案。但现有研究工作缺乏对检索增强型大语言模型在不同生物医学NLP任务中影响的系统评估，这一缺陷使得难以界定RAL在生物医学领域的能力边界。此外，RAL的输出易受未标注数据、反事实知识或多样性知识检索的影响，而这些因素在生物医学领域尚未得到充分研究——尽管此类知识在现实场景中普遍存在。最后，探索RAL系统的自我认知能力也至关重要。为此，本文系统研究了RAL在五种生物医学任务（三元组抽取、链接预测、分类、问答及自然语言推理）中的表现，重点分析了其在未标注鲁棒性、反事实鲁棒性、多样性鲁棒性和负向感知四项核心能力上的表现。我们构建了评估框架来衡量RAL在不同生物医学NLP任务中的性能，并基于上述核心能力建立了四个测试基准。最终对3种代表性LLM结合3种检索器在9个数据集的5项任务中进行了全面评估。
