# DialogueLLM: Context and Emotion Knowledge-Tuned LLaMA Models for Emotion Recognition in Conversations

链接: http://arxiv.org/abs/2310.11374v1

原文摘要:
Large language models (LLMs) and their variants have shown extraordinary
efficacy across numerous downstream natural language processing (NLP) tasks,
which has presented a new vision for the development of NLP. Despite their
remarkable performance in natural language generating (NLG), LLMs lack a
distinct focus on the emotion understanding domain. As a result, using LLMs for
emotion recognition may lead to suboptimal and inadequate precision. Another
limitation of LLMs is that they are typical trained without leveraging
multi-modal information. To overcome these limitations, we propose DialogueLLM,
a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA
models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.
The visual information is considered as the supplementary knowledge to
construct high-quality instructions. We offer a comprehensive evaluation of our
proposed model on three benchmarking emotion recognition in conversations (ERC)
datasets and compare the results against the SOTA baselines and other SOTA
LLMs. Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB
A100 GPU in 5 hours, facilitating reproducibility for other researchers.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）及其变体在众多下游自然语言处理（NLP）任务中展现出卓越效能，为NLP领域发展提供了全新视角。尽管在自然语言生成（NLG）方面表现突出，现有LLMs对情感理解领域的关注度明显不足，直接应用于情感识别任务可能导致次优结果与精度缺陷。此外，传统LLMs通常未充分利用多模态信息进行训练。为突破这些限制，我们提出DialogueLLM——一种基于上下文与情感知识调优的语言模型，该模型通过对LLaMA模型进行13,638组多模态（文本-视频）情感对话数据的微调获得。其中视觉信息作为补充知识用于构建高质量指令集。我们在三个会话情感识别（ERC）基准数据集上对所提模型进行全面评估，并与SOTA基线模型及其他先进LLMs进行对比。值得注意的是，DialogueLLM-7B仅需在40GB显存的A100 GPU上通过LoRA方法训练5小时即可完成，显著提升了模型的可复现性。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如LLMs/SOTA等保留英文缩写）
2. 被动语态转换为中文主动表述（如"are trained"→"进行训练"）
3. 长难句合理切分（如原文第二句拆分为两个中文因果句）
4. 学术用语规范化（"suboptimal and inadequate precision"→"次优结果与精度缺陷"）
5. 重要数据完整保留（13,638/7B/40GB等精确转换）
6. 技术表述清晰（LoRA/微调等专业概念准确传达））
