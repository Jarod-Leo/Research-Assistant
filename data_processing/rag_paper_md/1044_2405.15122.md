# Generalizable and Scalable Multistage Biomedical Concept Normalization Leveraging Large Language Models

链接: http://arxiv.org/abs/2405.15122v1

原文摘要:
Background: Biomedical entity normalization is critical to biomedical
research because the richness of free-text clinical data, such as progress
notes, can often be fully leveraged only after translating words and phrases
into structured and coded representations suitable for analysis. Large Language
Models (LLMs), in turn, have shown great potential and high performance in a
variety of natural language processing (NLP) tasks, but their application for
normalization remains understudied.
  Methods: We applied both proprietary and open-source LLMs in combination with
several rule-based normalization systems commonly used in biomedical research.
We used a two-step LLM integration approach, (1) using an LLM to generate
alternative phrasings of a source utterance, and (2) to prune candidate UMLS
concepts, using a variety of prompting methods. We measure results by
$F_{\beta}$, where we favor recall over precision, and F1.
  Results: We evaluated a total of 5,523 concept terms and text contexts from a
publicly available dataset of human-annotated biomedical abstracts.
Incorporating GPT-3.5-turbo increased overall $F_{\beta}$ and F1 in
normalization systems +9.5 and +7.3 (MetaMapLite), +13.9 and +10.9 (QuickUMLS),
and +10.5 and +10.3 (BM25), while the open-source Vicuna model achieved +10.8
and +12.2 (MetaMapLite), +14.7 and +15 (QuickUMLS), and +15.6 and +18.7 (BM25).
  Conclusions: Existing general-purpose LLMs, both propriety and open-source,
can be leveraged at scale to greatly improve normalization performance using
existing tools, with no fine-tuning.

中文翻译:
背景：生物医学实体规范化对生物医学研究至关重要，因为自由文本临床数据（如病程记录）的丰富性往往只有在将词汇和短语转化为适合分析的结构化编码表示后才能充分发挥。大型语言模型（LLMs）在多种自然语言处理（NLP）任务中展现出巨大潜力与高性能，但其在规范化任务中的应用仍待深入探索。

方法：我们结合生物医学研究中常用的多种基于规则的规范化系统，同时应用专有和开源LLMs。采用两步式LLM整合策略：（1）利用LLM生成源语句的替代表述，（2）通过多样化提示方法筛选UMLS候选概念。评估指标采用侧重召回率的$F_{\beta}$和平衡指标F1。

结果：基于公开的生物医学摘要人工标注数据集（含5,523个概念术语及文本上下文），集成GPT-3.5-turbo使各规范化系统的$F_{\beta}$/F1分别提升：MetaMapLite（+9.5/+7.3）、QuickUMLS（+13.9/+10.9）、BM25（+10.5/+10.3）；开源Vicuna模型则实现MetaMapLite（+10.8/+12.2）、QuickUMLS（+14.7/+15）、BM25（+15.6/+18.7）的性能增益。

结论：现有通用LLMs（包括专有和开源模型）无需微调即可规模化应用，通过现有工具显著提升规范化性能。
