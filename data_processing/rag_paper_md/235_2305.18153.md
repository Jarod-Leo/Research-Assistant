# Do Large Language Models Know What They Don't Know?

链接: http://arxiv.org/abs/2305.18153v2

原文摘要:
Large language models (LLMs) have a wealth of knowledge that allows them to
excel in various Natural Language Processing (NLP) tasks. Current research
focuses on enhancing their performance within their existing knowledge. Despite
their vast knowledge, LLMs are still limited by the amount of information they
can accommodate and comprehend. Therefore, the ability to understand their own
limitations on the unknows, referred to as self-knowledge, is of paramount
importance. This study aims to evaluate LLMs' self-knowledge by assessing their
ability to identify unanswerable or unknowable questions. We introduce an
automated methodology to detect uncertainty in the responses of these models,
providing a novel measure of their self-knowledge. We further introduce a
unique dataset, SelfAware, consisting of unanswerable questions from five
diverse categories and their answerable counterparts. Our extensive analysis,
involving 20 LLMs including GPT-3, InstructGPT, and LLaMA, discovering an
intrinsic capacity for self-knowledge within these models. Moreover, we
demonstrate that in-context learning and instruction tuning can further enhance
this self-knowledge. Despite this promising insight, our findings also
highlight a considerable gap between the capabilities of these models and human
proficiency in recognizing the limits of their knowledge.

中文翻译:
大型语言模型（LLMs）凭借其丰富的知识储备，在各类自然语言处理（NLP）任务中表现卓越。当前研究主要聚焦于提升模型在已知知识范围内的性能表现。尽管LLMs具备海量知识，其容纳与理解的信息量仍存在固有局限。因此，模型对未知领域自我认知的能力——即自我知识（self-knowledge）——具有至关重要的意义。本研究通过评估模型识别不可回答或不可知问题的能力，系统考察了LLMs的自我知识水平。我们提出了一种自动化检测模型响应不确定性的方法，为衡量其自我知识提供了创新指标。此外，我们构建了独特的数据集SelfAware，涵盖五个不同领域的不可回答问题及其可回答对照问题。通过对GPT-3、InstructGPT和LLaMA等20个LLMs的广泛测试，发现这些模型确实具备内在的自我认知能力。研究进一步证明，情境学习（in-context learning）和指令微调（instruction tuning）能有效增强这种自我知识。尽管获得这一积极发现，实验结果同时揭示：当前模型在认知知识边界方面，与人类水平仍存在显著差距。
