# Survey: Transformer-based Models in Data Modality Conversion

链接: http://arxiv.org/abs/2408.04723v1

原文摘要:
Transformers have made significant strides across various artificial
intelligence domains, including natural language processing, computer vision,
and audio processing. This success has naturally garnered considerable interest
from both academic and industry researchers. Consequently, numerous Transformer
variants (often referred to as X-formers) have been developed for these fields.
However, a thorough and systematic review of these modality-specific
conversions remains lacking. Modality Conversion involves the transformation of
data from one form of representation to another, mimicking the way humans
integrate and interpret sensory information. This paper provides a
comprehensive review of transformer-based models applied to the primary
modalities of text, vision, and speech, discussing their architectures,
conversion methodologies, and applications. By synthesizing the literature on
modality conversion, this survey aims to underline the versatility and
scalability of transformers in advancing AI-driven content generation and
understanding.

中文翻译:
Transformer模型在自然语言处理、计算机视觉及音频处理等多个AI领域取得了显著突破，这一成功自然引发了学术界与产业界的广泛关注。随之而来的是针对这些领域开发的大量Transformer变体（常被称为X-former）。然而，目前仍缺乏对这些特定模态转换方法全面而系统的梳理。模态转换是指将数据从一种表征形式转化为另一种形式，其本质是模拟人类整合与解读多感官信息的过程。本文系统综述了基于Transformer的文本、视觉和语音三大核心模态转换模型，详细探讨了其架构设计、转换方法及应用场景。通过整合模态转换领域的相关研究，本综述旨在强调Transformer模型在推动AI驱动的内容生成与理解方面所展现的多功能性和可扩展性。
