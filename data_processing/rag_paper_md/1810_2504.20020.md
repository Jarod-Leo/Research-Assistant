# Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models

链接: http://arxiv.org/abs/2504.20020v1

原文摘要:
Large language models (LLMs) have dramatically advanced machine learning
research including natural language processing, computer vision, data mining,
etc., yet they still exhibit critical limitations in reasoning, factual
consistency, and interpretability. In this paper, we introduce a novel learning
paradigm -- Modular Machine Learning (MML) -- as an essential approach toward
new-generation LLMs. MML decomposes the complex structure of LLMs into three
interdependent components: modular representation, modular model, and modular
reasoning, aiming to enhance LLMs' capability of counterfactual reasoning,
mitigating hallucinations, as well as promoting fairness, safety, and
transparency. Specifically, the proposed MML paradigm can: i) clarify the
internal working mechanism of LLMs through the disentanglement of semantic
components; ii) allow for flexible and task-adaptive model design; iii) enable
interpretable and logic-driven decision-making process. We present a feasible
implementation of MML-based LLMs via leveraging advanced techniques such as
disentangled representation learning, neural architecture search and
neuro-symbolic learning. We critically identify key challenges, such as the
integration of continuous neural and discrete symbolic processes, joint
optimization, and computational scalability, present promising future research
directions that deserve further exploration. Ultimately, the integration of the
MML paradigm with LLMs has the potential to bridge the gap between statistical
(deep) learning and formal (logical) reasoning, thereby paving the way for
robust, adaptable, and trustworthy AI systems across a wide range of real-world
applications.

中文翻译:
大型语言模型（LLMs）显著推动了机器学习在自然语言处理、计算机视觉、数据挖掘等领域的研究，但其在推理能力、事实一致性及可解释性方面仍存在明显局限。本文提出一种新型学习范式——模块化机器学习（MML），将其作为新一代LLMs的核心发展路径。MML将LLMs的复杂结构解耦为三个相互依存的组件：模块化表征、模块化模型和模块化推理，旨在增强LLMs的反事实推理能力、减少幻觉生成，同时提升公平性、安全性与透明度。

具体而言，MML范式能够：1）通过语义成分解耦阐明LLMs的内部工作机制；2）支持灵活的任务自适应模型设计；3）实现可解释的逻辑驱动决策过程。我们借助解耦表征学习、神经架构搜索和神经符号学习等前沿技术，提出了基于MML的LLMs可行实施方案。研究重点剖析了关键挑战，包括连续神经过程与离散符号过程的融合、联合优化及计算可扩展性等问题，并指明了值得深入探索的未来研究方向。最终，MML范式与LLMs的融合有望弥合统计（深度）学习与形式（逻辑）推理之间的鸿沟，从而为构建适用于广泛现实场景的鲁棒、自适应且可信赖的人工智能系统开辟道路。
