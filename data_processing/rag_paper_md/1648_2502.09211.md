# Visual Graph Question Answering with ASP and LLMs for Language Parsing

链接: http://arxiv.org/abs/2502.09211v1

原文摘要:
Visual Question Answering (VQA) is a challenging problem that requires to
process multimodal input. Answer-Set Programming (ASP) has shown great
potential in this regard to add interpretability and explainability to modular
VQA architectures. In this work, we address the problem of how to integrate ASP
with modules for vision and natural language processing to solve a new and
demanding VQA variant that is concerned with images of graphs (not graphs in
symbolic form). Images containing graph-based structures are an ubiquitous and
popular form of visualisation. Here, we deal with the particular problem of
graphs inspired by transit networks, and we introduce a novel dataset that
amends an existing one by adding images of graphs that resemble metro lines.
Our modular neuro-symbolic approach combines optical graph recognition for
graph parsing, a pretrained optical character recognition neural network for
parsing labels, Large Language Models (LLMs) for language processing, and ASP
for reasoning. This method serves as a first baseline and achieves an overall
average accuracy of 73% on the dataset. Our evaluation provides further
evidence of the potential of modular neuro-symbolic systems, in particular with
pretrained models that do not involve any further training and logic
programming for reasoning, to solve complex VQA tasks.

中文翻译:
视觉问答（VQA）是一项需要处理多模态输入的挑战性任务。答案集编程（ASP）在此领域展现出巨大潜力，能为模块化VQA架构增添可解释性。本研究针对如何将ASP与视觉及自然语言处理模块相结合，以解决一种新型且高要求的VQA变体——该任务涉及图形图像（而非符号化图形）的解析。基于图形结构的图像是普遍存在的可视化形式，本文重点研究受交通网络启发的特定图形问题，并通过在现有数据集中新增类似地铁线路的图形图像构建了新颖数据集。

我们的模块化神经符号方法整合了以下技术：采用光学图形识别进行图结构解析，利用预训练光学字符识别神经网络处理标签信息，结合大型语言模型（LLMs）完成语言理解，最后通过ASP实现推理。该方法作为首个基线方案，在数据集上取得了73%的平均准确率。评估结果进一步证实了模块化神经符号系统的潜力——特别是结合无需额外训练的预训练模型与逻辑编程推理——在解决复杂VQA任务中的有效性。
