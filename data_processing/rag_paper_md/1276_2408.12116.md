# Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning

链接: http://arxiv.org/abs/2408.12116v1

原文摘要:
In the geospatial domain, universal representation models are significantly
less prevalent than their extensive use in natural language processing and
computer vision. This discrepancy arises primarily from the high costs
associated with the input of existing representation models, which often
require street views and mobility data. To address this, we develop a novel,
training-free method that leverages large language models (LLMs) and auxiliary
map data from OpenStreetMap to derive geolocation representations (LLMGeovec).
LLMGeovec can represent the geographic semantics of city, country, and global
scales, which acts as a generic enhancer for spatio-temporal learning.
Specifically, by direct feature concatenation, we introduce a simple yet
effective paradigm for enhancing multiple spatio-temporal tasks including
geographic prediction (GP), long-term time series forecasting (LTSF), and
graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly
integrate into a wide spectrum of spatio-temporal learning models, providing
immediate enhancements. Experimental results demonstrate that LLMGeovec
achieves global coverage and significantly boosts the performance of leading
GP, LTSF, and GSTF models. Our codes are available at
\url{https://github.com/Umaruchain/LLMGeovec}.

中文翻译:
在地理空间领域，通用表征模型的应用远不如其在自然语言处理和计算机视觉中那样广泛。这种差异主要源于现有表征模型输入成本高昂，通常需要街景和移动数据作为支撑。为此，我们开发了一种无需训练的新方法，通过利用大语言模型（LLMs）和OpenStreetMap的辅助地图数据来生成地理位置表征（LLMGeovec）。LLMGeovec能够表征城市、国家和全球尺度的地理语义，作为时空学习的通用增强器。具体而言，通过直接特征拼接，我们提出了一种简单而有效的范式，用于增强包括地理预测（GP）、长期时间序列预测（LTSF）和基于图的时空预测（GSTF）在内的多种时空任务。LLMGeovec可无缝集成到各类时空学习模型中，实现即时性能提升。实验结果表明，LLMGeovec具备全球覆盖能力，并显著提升了主流GP、LTSF和GSTF模型的性能。代码已开源于\url{https://github.com/Umaruchain/LLMGeovec}。
