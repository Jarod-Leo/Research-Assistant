# On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions

链接: http://arxiv.org/abs/2306.14062v1

原文摘要:
The volume, variety, and velocity of change in vulnerabilities and exploits
have made incident threat analysis challenging with human expertise and
experience along. Tactics, Techniques, and Procedures (TTPs) are to describe
how and why attackers exploit vulnerabilities. However, a TTP description
written by one security professional can be interpreted very differently by
another, leading to confusion in cybersecurity operations or even business,
policy, and legal decisions. Meanwhile, advancements in AI have led to the
increasing use of Natural Language Processing (NLP) algorithms to assist the
various tasks in cyber operations. With the rise of Large Language Models
(LLMs), NLP tasks have significantly improved because of the LLM's semantic
understanding and scalability. This leads us to question how well LLMs can
interpret TTPs or general cyberattack descriptions to inform analysts of the
intended purposes of cyberattacks. We propose to analyze and compare the direct
use of LLMs (e.g., GPT-3.5) versus supervised fine-tuning (SFT) of
small-scale-LLMs (e.g., BERT) to study their capabilities in predicting ATT&CK
tactics. Our results reveal that the small-scale-LLMs with SFT provide a more
focused and clearer differentiation between the ATT&CK tactics (if such
differentiation exists). On the other hand, direct use of LLMs offer a broader
interpretation of cyberattack techniques. When treating more general cases,
despite the power of LLMs, inherent ambiguity exists and limits their
predictive power. We then summarize the challenges and recommend research
directions on LLMs to treat the inherent ambiguity of TTP descriptions used in
various cyber operations.

中文翻译:
漏洞与攻击手段在数量、种类及变化速度上的激增，使得仅依靠人类专业知识和经验进行事件威胁分析变得极具挑战性。战术、技术与程序（TTPs）被用于描述攻击者利用漏洞的方式和动机。然而，不同安全专家对同一TTP描述可能存在截然不同的解读，这会导致网络安全运营乃至商业决策、政策制定和法律裁决中的混乱。与此同时，人工智能的进步促使自然语言处理（NLP）算法越来越多地应用于网络攻防的各类任务中。随着大语言模型（LLMs）的崛起，得益于其语义理解能力和可扩展性，NLP任务性能得到了显著提升。这促使我们思考：LLMs在解读TTP或通用网络攻击描述时，能否准确向分析人员传达攻击意图？我们提出通过对比分析直接使用LLMs（如GPT-3.5）与对小规模LLMs（如BERT）进行监督微调（SFT）的方法，研究它们在预测ATT&CK战术方面的能力。实验结果表明：经过SFT的小规模LLMs能对ATT&CK战术（若存在差异）提供更聚焦且清晰的区分；而直接使用LLMs则能对攻击技术给出更宽泛的解读。在处理更普遍案例时，尽管LLMs能力强大，但其预测性能仍受限于描述本身固有的模糊性。基于此，我们总结了当前挑战，并就如何利用LLMs处理网络攻防中TTP描述固有模糊性问题提出了研究方向建议。
