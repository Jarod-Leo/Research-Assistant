# On the Uses of Large Language Models to Interpret Ambiguous Cyberattack Descriptions

链接: http://arxiv.org/abs/2306.14062v1

原文摘要:
The volume, variety, and velocity of change in vulnerabilities and exploits
have made incident threat analysis challenging with human expertise and
experience along. Tactics, Techniques, and Procedures (TTPs) are to describe
how and why attackers exploit vulnerabilities. However, a TTP description
written by one security professional can be interpreted very differently by
another, leading to confusion in cybersecurity operations or even business,
policy, and legal decisions. Meanwhile, advancements in AI have led to the
increasing use of Natural Language Processing (NLP) algorithms to assist the
various tasks in cyber operations. With the rise of Large Language Models
(LLMs), NLP tasks have significantly improved because of the LLM's semantic
understanding and scalability. This leads us to question how well LLMs can
interpret TTPs or general cyberattack descriptions to inform analysts of the
intended purposes of cyberattacks. We propose to analyze and compare the direct
use of LLMs (e.g., GPT-3.5) versus supervised fine-tuning (SFT) of
small-scale-LLMs (e.g., BERT) to study their capabilities in predicting ATT&CK
tactics. Our results reveal that the small-scale-LLMs with SFT provide a more
focused and clearer differentiation between the ATT&CK tactics (if such
differentiation exists). On the other hand, direct use of LLMs offer a broader
interpretation of cyberattack techniques. When treating more general cases,
despite the power of LLMs, inherent ambiguity exists and limits their
predictive power. We then summarize the challenges and recommend research
directions on LLMs to treat the inherent ambiguity of TTP descriptions used in
various cyber operations.

中文翻译:
以下是符合您要求的中文翻译：

漏洞与攻击手段在数量、种类和变化速度上的激增，使得仅依靠人类专业知识和经验进行事件威胁分析变得极具挑战性。战术、技术与程序（TTPs）本应用于描述攻击者利用漏洞的方式和动机，但不同安全专家对同一TTP描述可能存在截然不同的解读，这种认知差异可能导致网络安全运维、商业决策甚至政策法律层面的混乱。与此同时，人工智能的进步推动着自然语言处理（NLP）算法在网络安全任务中的广泛应用。随着大语言模型（LLMs）的崛起，得益于其语义理解能力和可扩展性，NLP任务性能得到显著提升。这促使我们思考：LLMs在解读TTPs或通用网络攻击描述时，能否准确向分析师传达攻击者的真实意图？本研究提出通过对比分析LLMs（如GPT-3.5）的直接使用与小规模LLMs（如BERT）的监督微调（SFT）方法，探究它们在预测ATT&CK战术方面的能力差异。实验结果表明：经SFT优化的小规模LLMs能对ATT&CK战术（若存在差异时）做出更聚焦、更清晰的区分；而直接使用LLMs则能提供更宽泛的攻击技术解释。研究发现，即便LLMs能力强大，面对通用场景时仍存在固有模糊性，这会限制其预测准确性。基于此，我们系统总结了当前挑战，并就如何利用LLMs处理网络攻防中TTP描述的固有模糊性问题提出了未来研究方向建议。

翻译说明：
1. 专业术语处理：采用"战术、技术与程序（TTPs）"、"监督微调（SFT）"等标准译法，保持术语一致性
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如将"However..."长句拆分为转折关系的两个分句
3. 逻辑显化：添加"研究发现"等过渡词，使论证逻辑更清晰
4. 被动语态转换："can be interpreted"译为主动式"可能存在...解读"
5. 概念整合："inherent ambiguity exists and limits..."合并译为"仍存在固有模糊性，这会限制..."
6. 学术风格保持：使用"探究""基于此"等学术用语，符合论文摘要规范
