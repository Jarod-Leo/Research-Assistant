# ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction

链接: http://arxiv.org/abs/2412.03075v1

原文摘要:
Automatic speech Recognition (ASR) is a fundamental and important task in the
field of speech and natural language processing. It is an inherent building
block in many applications such as voice assistant, speech translation, etc.
Despite the advancement of ASR technologies in recent years, it is still
inevitable for modern ASR systems to have a substantial number of erroneous
recognition due to environmental noise, ambiguity, etc. Therefore, the error
correction in ASR is crucial.
  Motivated by this, this paper studies ASR error correction in the Chinese
language, which is one of the most popular languages and enjoys a large number
of users in the world. We first create a benchmark dataset named \emph{ASR-EC}
that contains a wide spectrum of ASR errors generated by industry-grade ASR
systems. To the best of our knowledge, it is the first Chinese ASR error
correction benchmark. Then, inspired by the recent advances in \emph{large
language models (LLMs)}, we investigate how to harness the power of LLMs to
correct ASR errors. We apply LLMs to ASR error correction in three paradigms.
The first paradigm is prompting, which is further categorized as zero-shot,
few-shot, and multi-step. The second paradigm is finetuning, which finetunes
LLMs with ASR error correction data. The third paradigm is multi-modal
augmentation, which collectively utilizes the audio and ASR transcripts for
error correction. Extensive experiments reveal that prompting is not effective
for ASR error correction. Finetuning is effective only for a portion of LLMs.
Multi-modal augmentation is the most effective method for error correction and
achieves state-of-the-art performance.

中文翻译:
自动语音识别（ASR）作为语音与自然语言处理领域的一项基础且关键的任务，已成为语音助手、语音翻译等诸多应用的核心组件。尽管近年来ASR技术取得了显著进展，但受环境噪声、语义歧义等因素影响，现代ASR系统仍不可避免地存在大量识别错误，因此针对ASR的纠错技术至关重要。

基于此背景，本文以全球使用人数众多的汉语为研究对象，首次构建了名为\emph{ASR-EC}的基准数据集。该数据集涵盖了工业级ASR系统产生的多种典型错误，据我们所知，这是首个中文ASR纠错基准。受\emph{大语言模型（LLMs）}最新进展的启发，我们系统探索了如何利用LLMs进行ASR纠错，并提出了三种实现范式：第一类是提示学习，细分为零样本、少样本和多步推理；第二类是微调学习，通过ASR纠错数据对LLMs进行参数优化；第三类是多模态增强，联合利用音频和识别文本进行纠错。大量实验表明：提示学习在ASR纠错中效果有限；微调学习仅对部分LLMs有效；而多模态增强方法展现出最优的纠错性能，达到了当前最先进水平。
