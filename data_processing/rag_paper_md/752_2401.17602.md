# Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning

链接: http://arxiv.org/abs/2401.17602v1

原文摘要:
In this study, we aim to address the task of assertion detection when
extracting medical concepts from clinical notes, a key process in clinical
natural language processing (NLP). Assertion detection in clinical NLP usually
involves identifying assertion types for medical concepts in the clinical text,
namely certainty (whether the medical concept is positive, negated, possible,
or hypothetical), temporality (whether the medical concept is for present or
the past history), and experiencer (whether the medical concept is described
for the patient or a family member). These assertion types are essential for
healthcare professionals to quickly and clearly understand the context of
medical conditions from unstructured clinical texts, directly influencing the
quality and outcomes of patient care. Although widely used, traditional
methods, particularly rule-based NLP systems and machine learning or deep
learning models, demand intensive manual efforts to create patterns and tend to
overlook less common assertion types, leading to an incomplete understanding of
the context. To address this challenge, our research introduces a novel
methodology that utilizes Large Language Models (LLMs) pre-trained on a vast
array of medical data for assertion detection. We enhanced the current method
with advanced reasoning techniques, including Tree of Thought (ToT), Chain of
Thought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank
Adaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010
assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11
improvements over the previous works. To further assess the generalizability of
our approach, we extended our evaluation to a local dataset that focused on
sleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31
higher than the previous method.

中文翻译:
本研究旨在解决从临床记录中提取医学概念时的断言检测任务，这是临床自然语言处理（NLP）中的关键环节。临床NLP中的断言检测通常涉及识别临床文本中医学概念的断言类型，包括确定性（医学概念是肯定、否定、可能还是假设）、时间性（医学概念涉及当前状况还是既往史）以及体验者（医学概念描述的是患者还是家庭成员）。这些断言类型对于医疗专业人员快速清晰地理解非结构化临床文本中的病情背景至关重要，直接影响患者护理的质量和结果。尽管传统方法（尤其是基于规则的NLP系统及机器学习或深度学习模型）被广泛使用，但其需要大量人工制定规则模式，且容易忽略较少见的断言类型，导致对上下文理解不完整。

为应对这一挑战，本研究提出了一种创新方法：利用经过海量医学数据预训练的大语言模型（LLMs）进行断言检测。我们通过思维树（ToT）、思维链（CoT）和自我一致性（SC）等先进推理技术增强现有方法，并采用低秩自适应（LoRA）微调进行优化。首先在i2b2 2010断言数据集上评估模型，我们的方法取得了0.89的微平均F-1值，较先前研究提升0.11。为验证方法的泛化能力，我们进一步在专注于睡眠概念提取的本地数据集上进行评估，获得0.74的F-1值，较原有方法提高0.31。
