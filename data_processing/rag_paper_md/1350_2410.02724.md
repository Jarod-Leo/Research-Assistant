# Large Language Models as Markov Chains

链接: http://arxiv.org/abs/2410.02724v1

原文摘要:
Large language models (LLMs) are remarkably efficient across a wide range of
natural language processing tasks and well beyond them. However, a
comprehensive theoretical analysis of the LLMs' generalization capabilities
remains elusive. In our paper, we approach this task by drawing an equivalence
between autoregressive transformer-based language models and Markov chains
defined on a finite state space. This allows us to study the multi-step
inference mechanism of LLMs from first principles. We relate the obtained
results to the pathological behavior observed with LLMs such as repetitions and
incoherent replies with high temperature. Finally, we leverage the proposed
formalization to derive pre-training and in-context learning generalization
bounds for LLMs under realistic data and model assumptions. Experiments with
the most recent Llama and Gemma herds of models show that our theory correctly
captures their behavior in practice.

中文翻译:
大型语言模型（LLMs）在自然语言处理任务乃至更广泛领域中展现出卓越效能，然而其泛化能力的系统性理论分析仍属空白。本文通过建立自回归Transformer语言模型与有限状态空间马尔可夫链的等价关系，从第一性原理出发研究LLMs的多步推理机制。我们将理论推导结果与实践中观察到的病理现象（如高温参数下的重复输出与语义混乱回复）建立联系，并基于该形式化框架，在现实数据与模型假设下推导出LLMs预训练与上下文学习的泛化边界。对最新Llama和Gemma模型系列的实验表明，我们的理论能准确预测其实际行为特征。
