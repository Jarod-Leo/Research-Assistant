# Investigating the Efficacy of Large Language Models for Code Clone Detection

链接: http://arxiv.org/abs/2401.13802v1

原文摘要:
Large Language Models (LLMs) have demonstrated remarkable success in various
natural language processing and software engineering tasks, such as code
generation. The LLMs are mainly utilized in the prompt-based zero/few-shot
paradigm to guide the model in accomplishing the task. GPT-based models are one
of the popular ones studied for tasks such as code comment generation or test
generation. These tasks are `generative' tasks. However, there is limited
research on the usage of LLMs for `non-generative' tasks such as classification
using the prompt-based paradigm. In this preliminary exploratory study, we
investigated the applicability of LLMs for Code Clone Detection (CCD), a
non-generative task. By building a mono-lingual and cross-lingual CCD dataset
derived from CodeNet, we first investigated two different prompts using ChatGPT
to detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot
setting. We then conducted an analysis to understand the strengths and
weaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language
CCD attaining an F1-score of 0.877 and achieves comparable performance to fully
fine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the
prompt and the difficulty level of the problems has an impact on the
performance of ChatGPT. Finally we provide insights and future directions based
on our initial analysis

中文翻译:
大型语言模型（LLMs）在各类自然语言处理与软件工程任务中展现出卓越成效，例如代码生成。目前LLMs主要通过基于提示（prompt-based）的零样本/少样本范式来引导模型完成任务。以GPT为基础的模型在代码注释生成或测试生成等"生成式"任务中备受关注。然而，对于基于提示范式的"非生成式"任务（如分类任务）的应用研究仍较为有限。在本项探索性初步研究中，我们考察了LLMs在代码克隆检测（CCD）这一非生成式任务中的适用性。通过构建源自CodeNet的单语言与跨语言CCD数据集，我们首先使用ChatGPT在零样本设置下检测Java-Java和Java-Ruby的Type-4代码克隆，测试了两种不同提示策略。随后通过分析揭示了ChatGPT在CCD任务中的优势与局限。实验表明：在跨语言CCD中，ChatGPT以0.877的F1分数超越基线模型；在单语言CCD中则达到与全微调模型相当的0.878 F1分数。研究同时发现提示策略和问题难度等级会显著影响ChatGPT的表现。基于初步分析，我们提出了若干见解与未来研究方向。
