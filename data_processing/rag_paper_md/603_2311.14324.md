# Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs

链接: http://arxiv.org/abs/2311.14324v1

原文摘要:
The latest advancements in large language models (LLMs) have revolutionized
the field of natural language processing (NLP). Inspired by the success of LLMs
in NLP tasks, some recent work has begun investigating the potential of
applying LLMs in graph learning tasks. However, most of the existing work
focuses on utilizing LLMs as powerful node feature augmenters, leaving
employing LLMs to enhance graph topological structures an understudied problem.
In this work, we explore how to leverage the information retrieval and text
generation capabilities of LLMs to refine/enhance the topological structure of
text-attributed graphs (TAGs) under the node classification setting. First, we
propose using LLMs to help remove unreliable edges and add reliable ones in the
TAG. Specifically, we first let the LLM output the semantic similarity between
node attributes through delicate prompt designs, and then perform edge deletion
and edge addition based on the similarity. Second, we propose using
pseudo-labels generated by the LLM to improve graph topology, that is, we
introduce the pseudo-label propagation as a regularization to guide the graph
neural network (GNN) in learning proper edge weights. Finally, we incorporate
the two aforementioned LLM-based methods for graph topological refinement into
the process of GNN training, and perform extensive experiments on four
real-world datasets. The experimental results demonstrate the effectiveness of
LLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain
on public benchmarks).

中文翻译:
大型语言模型（LLM）的最新进展为自然语言处理（NLP）领域带来了革命性变革。受LLM在NLP任务中成功应用的启发，近期研究开始探索其在图学习任务中的潜力。然而现有工作大多聚焦于将LLM作为强大的节点特征增强工具，而利用LLM优化图拓扑结构的研究仍属空白。本文研究如何基于节点分类场景，通过LLM的信息检索与文本生成能力改进文本属性图（TAG）的拓扑结构。

首先，我们提出利用LLM删除不可靠边并添加可靠边：通过精心设计的提示模板，使LLM输出节点属性间的语义相似度，据此执行边删除与边添加操作。其次，我们提出采用LLM生成的伪标签优化图拓扑——将伪标签传播作为正则化项，指导图神经网络（GNN）学习合理的边权重。最终，我们将这两种基于LLM的图拓扑优化方法整合至GNN训练流程，并在四个真实数据集上开展实验。实验结果表明：基于LLM的图拓扑优化能有效提升性能（在公开基准上实现0.15%-2.47%的性能增益）。
