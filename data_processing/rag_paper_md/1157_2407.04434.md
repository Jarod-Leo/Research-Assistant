# From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs

链接: http://arxiv.org/abs/2407.04434v1

原文摘要:
Gender bias is not only prevalent in Large Language Models (LLMs) and their
training data, but also firmly ingrained into the structural aspects of
language itself. Therefore, adapting linguistic structures within LLM training
data to promote gender-inclusivity can make gender representations within the
model more inclusive. The focus of our work are gender-exclusive affixes in
English, such as in 'show-girl' or 'man-cave', which can perpetuate gender
stereotypes and binary conceptions of gender. We use an LLM training dataset to
compile a catalogue of 692 gender-exclusive terms along with gender-neutral
variants and from this, develop a gender-inclusive fine-tuning dataset, the
'Tiny Heap'. Fine-tuning three different LLMs with this dataset, we observe an
overall reduction in gender-stereotyping tendencies across the models. Our
approach provides a practical method for enhancing gender inclusivity in LLM
training data and contributes to incorporating queer-feminist linguistic
activism in bias mitigation research in NLP.

中文翻译:
性别偏见不仅普遍存在于大型语言模型（LLMs）及其训练数据中，更深刻根植于语言本身的结构特性。因此，通过调整LLM训练数据中的语言结构以促进性别包容性，能够使模型内部的性别表征更具包容度。本研究聚焦英语中具有性别排他性的词缀（如"show-girl"或"man-cave"），这些语言结构可能强化性别刻板印象和二元性别观念。我们利用LLM训练数据集编制了包含692个性别排他性术语及其性别中性变体的目录，并据此开发出名为"Tiny Heap"的性别包容微调数据集。通过对三种不同LLM进行该数据集的微调实验，我们观察到模型整体上性别刻板化倾向的显著降低。该方法为提升LLM训练数据的性别包容性提供了实用路径，同时将酷儿女性主义语言学行动主义纳入自然语言处理领域的偏见缓解研究做出了贡献。
