# LLM-CARD: Towards a Description and Landscape of Large Language Models

链接: http://arxiv.org/abs/2409.17011v1

原文摘要:
With the rapid growth of the Natural Language Processing (NLP) field, a vast
variety of Large Language Models (LLMs) continue to emerge for diverse NLP
tasks. As more papers are published, researchers and developers face the
challenge of information overload. Thus, developing a system that can
automatically extract and organise key information about LLMs from academic
papers is particularly important. The standard format for documenting
information about LLMs is the LLM model card (\textbf{LLM-Card}). We propose a
method for automatically generating LLM model cards from scientific
publications. We use Named Entity Recognition (\textbf{NER}) and Relation
Extraction (\textbf{RE}) methods that automatically extract key information
about LLMs from the papers, helping researchers to access information about
LLMs efficiently. These features include model \textit{licence}, model
\textit{name}, and model \textit{application}. With these features, we can form
a model card for each paper. We processed 106 academic papers by defining three
dictionaries -- LLM's name, licence, and application. 11,051 sentences were
extracted through dictionary lookup, and the dataset was constructed through
manual review of the final selection of 129 sentences with a link between the
name and the \textit{licence}, and 106 sentences with a link between the model
name and the \textit{application}. The resulting resource is relevant for LLM
card illustrations using relational knowledge graphs. Our code and findings can
contribute to automatic LLM card generation. Data and code in
\textsc{autoLLM-Card} will be shared and freely available at
\url{https://github.com/shengwei-tian/dependency-parser-visualization}

中文翻译:
随着自然语言处理（NLP）领域的快速发展，针对各类NLP任务的大语言模型（LLM）持续涌现。面对日益增长的论文数量，研究人员和开发者正面临信息过载的挑战。因此，开发能自动从学术论文中提取并组织LLM关键信息的系统显得尤为重要。记录LLM信息的标准格式是LLM模型卡片（\textbf{LLM-Card}）。本文提出了一种从科学文献自动生成LLM模型卡片的方法：通过命名实体识别（\textbf{NER}）和关系抽取（\textbf{RE}）技术，自动从论文中提取LLM的关键信息（如模型\textit{许可协议}、模型\textit{名称}和模型\textit{应用领域}），帮助研究者高效获取LLM相关信息，进而为每篇论文生成结构化模型卡片。基于定义的三个词典（LLM名称、许可协议、应用领域），我们对106篇学术论文进行处理，通过词典匹配提取出11,051个句子，经人工复核最终构建包含129组"模型名称-许可协议"关联句和106组"模型名称-应用领域"关联句的数据集。该资源可用于基于关系知识图谱的LLM卡片可视化呈现。我们的代码与研究成果将推动LLM卡片的自动化生成，相关数据和代码将通过\textsc{autoLLM-Card}项目在\url{https://github.com/shengwei-tian/dependency-parser-visualization}开源共享。

（翻译说明：
1. 专业术语采用中文领域通用译法，如"Named Entity Recognition"译为"命名实体识别"
2. 被动语态转换为中文主动表达，如"were extracted"处理为"提取出"
3. 长句拆分重组，如原文最后两句话合并为符合中文阅读习惯的流水句
4. 保留技术术语的英文缩写（NER/RE）及代码库名称等专有名词
5. 统一关键概念表述，如"model card"全文统一译为"模型卡片"
6. 处理英文复数形式为中文单数，如"methods"译为"技术"而非"多种方法"
7. 补充逻辑连接词"进而"使行文更连贯）
