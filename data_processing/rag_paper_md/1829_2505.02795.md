# HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models

链接: http://arxiv.org/abs/2505.02795v1

原文摘要:
Recently, large language models (LLMs) have achieved remarkable
breakthroughs, revolutionizing the natural language processing domain and
beyond. Due to immense parameter sizes, fine-tuning these models with private
data for diverse downstream tasks has become mainstream. Though federated
learning (FL) offers a promising solution for fine-tuning LLMs without sharing
raw data, substantial computing costs hinder its democratization. Moreover, in
real-world scenarios, private client devices often possess heterogeneous
computing resources, further complicating LLM fine-tuning. To combat these
challenges, we propose HSplitLoRA, a heterogeneous parameter-efficient
fine-tuning (PEFT) framework built on split learning (SL) and low-rank
adaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on
heterogeneous client devices. HSplitLoRA first identifies important weights
based on their contributions to LLM training. It then dynamically configures
the decomposition ranks of LoRA adapters for selected weights and determines
the model split point according to varying computing budgets of client devices.
Finally, a noise-free adapter aggregation mechanism is devised to support
heterogeneous adapter aggregation without introducing noise. Extensive
experiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks
in training accuracy and convergence speed.

中文翻译:
近年来，大型语言模型（LLMs）取得了突破性进展，彻底改变了自然语言处理领域及其他相关领域。由于参数量庞大，利用私有数据对这些模型进行微调以适应多样化下游任务已成为主流方法。虽然联邦学习（FL）为不共享原始数据的LLM微调提供了可行方案，但高昂的计算成本阻碍了其普及应用。此外在实际场景中，私有客户端设备往往具有异构计算资源，这进一步增加了LLM微调的复杂性。为应对这些挑战，我们提出HSplitLoRA——一个基于分割学习（SL）和低秩自适应（LoRA）微调的异构参数高效微调（PEFT）框架，可在异构客户端设备上高效微调LLMs。该框架首先根据权重对模型训练的贡献度识别重要参数，随后针对选定权重动态配置LoRA适配器的分解秩，并根据客户端设备不同的计算预算确定模型分割点。最后设计了一种无噪声适配器聚合机制，可在不引入噪声的情况下支持异构适配器聚合。大量实验表明，HSplitLoRA在训练准确率和收敛速度方面均优于当前最先进的基准方法。
