# Detecting and Correcting Hate Speech in Multimodal Memes with Large Visual Language Model

链接: http://arxiv.org/abs/2311.06737v1

原文摘要:
Recently, large language models (LLMs) have taken the spotlight in natural
language processing. Further, integrating LLMs with vision enables the users to
explore more emergent abilities in multimodality. Visual language models
(VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive
performance on various visio-linguistic tasks. Consequently, there are enormous
applications of large models that could be potentially used on social media
platforms. Despite that, there is a lack of related work on detecting or
correcting hateful memes with VLMs. In this work, we study the ability of VLMs
on hateful meme detection and hateful meme correction tasks with zero-shot
prompting. From our empirical experiments, we show the effectiveness of the
pretrained LLaVA model and discuss its strengths and weaknesses in these tasks.

中文翻译:
近年来，大型语言模型（LLMs）已成为自然语言处理领域的焦点。进一步将LLMs与视觉模态相结合后，用户得以探索多模态领域更多涌现能力。诸如LLaVA、Flamingo或GPT-4等视觉语言模型（VLMs）已在多种视觉-语言任务中展现出卓越性能。这预示着大型模型在社交媒体平台具有巨大的潜在应用空间。然而目前学界仍缺乏利用VLMs进行仇恨表情包检测与修正的相关研究。本研究通过零样本提示方法，系统评估了VLMs在仇恨表情包检测与修正任务中的表现。实验结果表明，预训练的LLaVA模型具有显著效果，我们同时深入探讨了该模型在此类任务中的优势与局限性。

（翻译说明：
1. 专业术语处理：采用"视觉语言模型"对应VLMs，"零样本提示"对应zero-shot prompting等学界通用译法
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"integrating...multimodality"重组为两个逻辑连贯的分句
3. 被动语态转换：将"there are enormous applications"等被动表述转化为中文常见的主动句式
4. 学术风格保持：使用"涌现能力""预训练模型"等符合计算机领域论文特征的表述
5. 文化适配："hateful memes"译为"仇恨表情包"更符合中文网络语境）
