# Detecting and Correcting Hate Speech in Multimodal Memes with Large Visual Language Model

链接: http://arxiv.org/abs/2311.06737v1

原文摘要:
Recently, large language models (LLMs) have taken the spotlight in natural
language processing. Further, integrating LLMs with vision enables the users to
explore more emergent abilities in multimodality. Visual language models
(VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive
performance on various visio-linguistic tasks. Consequently, there are enormous
applications of large models that could be potentially used on social media
platforms. Despite that, there is a lack of related work on detecting or
correcting hateful memes with VLMs. In this work, we study the ability of VLMs
on hateful meme detection and hateful meme correction tasks with zero-shot
prompting. From our empirical experiments, we show the effectiveness of the
pretrained LLaVA model and discuss its strengths and weaknesses in these tasks.

中文翻译:
近年来，大型语言模型（LLMs）在自然语言处理领域备受瞩目。进一步将LLMs与视觉模态融合后，用户得以探索多模态场景下更多涌现能力。以LLaVA、Flamingo和GPT-4为代表的视觉语言模型（VLMs）已在各类视觉-语言联合任务中展现出卓越性能。这预示着社交媒体平台存在大规模模型应用的广阔前景。然而目前鲜有研究探讨如何利用VLMs进行仇恨表情包的检测与修正。本研究通过零样本提示方法，系统评估了VLMs在仇恨表情包识别与内容修正任务中的表现。实验结果表明，预训练的LLaVA模型展现出显著效果，我们同时深入分析了其在此类任务中的优势与局限性。
