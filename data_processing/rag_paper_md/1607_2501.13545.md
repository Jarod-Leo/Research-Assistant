# LLMs Can Plan Only If We Tell Them

链接: http://arxiv.org/abs/2501.13545v1

原文摘要:
Large language models (LLMs) have demonstrated significant capabilities in
natural language processing and reasoning, yet their effectiveness in
autonomous planning has been under debate. While existing studies have utilized
LLMs with external feedback mechanisms or in controlled environments for
planning, these approaches often involve substantial computational and
development resources due to the requirement for careful design and iterative
backprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to
match human performance on standard planning benchmarks, such as the
Blocksworld, without additional support. This paper investigates whether LLMs
can independently generate long-horizon plans that rival human baselines. Our
novel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help
achieve state-of-the-art results in planning benchmarks out-competing prior
methods and human baselines all autonomously.

中文翻译:
以下是符合要求的学术化中文翻译：

大语言模型（LLMs）在自然语言处理与推理任务中展现出显著能力，但其在自主规划方面的有效性仍存争议。现有研究虽已尝试通过外部反馈机制或在受控环境中利用LLMs进行规划，但这些方法因需要精心设计的迭代反向提示（backprompting）而消耗大量计算与开发资源。值得注意的是，即便如GPT-4等最先进的LLMs，在Blocksworld等标准规划基准测试中，若无额外支持仍难以达到人类水平。本文探究LLMs能否独立生成媲美人类基准的长期规划方案。我们通过对"思维算法"（Algorithm-of-Thoughts）的创新性改进——称为AoT+，在规划基准测试中实现了超越现有方法及人类基准的突破性成果，且全程保持自主性。

翻译说明：
1. 专业术语处理：LLMs统一译为"大语言模型"，"Blocksworld"保留英文形式符合学术惯例，"Algorithm-of-Thoughts"采用意译加注原文的处理方式
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句（如第一句拆分为两个逻辑单元），同时保持学术严谨性
3. 被动语态转换："have been utilized"等被动结构转换为中文主动表达
4. 概念准确传达："backprompting"译为"反向提示"并保留英文标注，确保术语准确性
5. 学术风格保持：使用"探究"、"基准测试"、"突破性成果"等规范学术用语
6. 逻辑衔接处理：通过"虽"、"即便"等连接词保持原文论证逻辑的连贯性
