# Few shot clinical entity recognition in three languages: Masked language models outperform LLM prompting

链接: http://arxiv.org/abs/2402.12801v1

原文摘要:
Large language models (LLMs) have become the preferred solution for many
natural language processing tasks. In low-resource environments such as
specialized domains, their few-shot capabilities are expected to deliver high
performance. Named Entity Recognition (NER) is a critical task in information
extraction that is not covered in recent LLM benchmarks. There is a need for
better understanding the performance of LLMs for NER in a variety of settings
including languages other than English. This study aims to evaluate generative
LLMs, employed through prompt engineering, for few-shot clinical NER. %from the
perspective of F1 performance and environmental impact. We compare 13
auto-regressive models using prompting and 16 masked models using fine-tuning
on 14 NER datasets covering English, French and Spanish. While prompt-based
auto-regressive models achieve competitive F1 for general NER, they are
outperformed within the clinical domain by lighter biLSTM-CRF taggers based on
masked models. Additionally, masked models exhibit lower environmental impact
compared to auto-regressive models. Findings are consistent across the three
languages studied, which suggests that LLM prompting is not yet suited for NER
production in the clinical domain.

中文翻译:
大型语言模型（LLMs）已成为众多自然语言处理任务的首选解决方案。在专业领域等低资源环境中，其少样本学习能力被寄予厚望以实现高性能表现。命名实体识别（NER）作为信息抽取中的关键任务，却未纳入近期LLM基准测试范畴。当前亟需深入理解LLMs在包括非英语语种在内的多样化场景中的NER性能表现。本研究旨在通过提示工程方法，评估生成式LLMs在少样本临床NER任务中的表现。我们对比了采用提示策略的13个自回归模型与基于微调的16个掩码语言模型，测试涵盖英语、法语和西班牙语的14个NER数据集。研究发现：虽然基于提示的自回归模型在通用NER任务中能达到具有竞争力的F1值，但在临床领域内，其表现逊色于基于掩码模型的轻量级biLSTM-CRF标注器。此外，掩码模型展现出较自回归模型更低的环境影响。这一结论在所研究的三种语言中表现一致，表明LLM提示技术目前尚未适用于临床领域的NER实际应用。
