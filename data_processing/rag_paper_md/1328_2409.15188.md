# PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models

链接: http://arxiv.org/abs/2409.15188v2

原文摘要:
Effective patient-provider communication is crucial in clinical care,
directly impacting patient outcomes and quality of life. Traditional evaluation
methods, such as human ratings, patient feedback, and provider
self-assessments, are often limited by high costs and scalability issues.
Although existing natural language processing (NLP) techniques show promise,
they struggle with the nuances of clinical communication and require sensitive
clinical data for training, reducing their effectiveness in real-world
applications. Emerging large language models (LLMs) offer a new approach to
assessing complex communication metrics, with the potential to advance the
field through integration into passive sensing and just-in-time intervention
systems. This study explores LLMs as evaluators of palliative care
communication quality, leveraging their linguistic, in-context learning, and
reasoning capabilities. Specifically, using simulated scripts crafted and
labeled by healthcare professionals, we test proprietary models (e.g., GPT-4)
and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset
generated by GPT-4 to evaluate clinical conversations, to identify key metrics
such as `understanding' and `empathy'. Our findings demonstrated LLMs' superior
performance in evaluating clinical communication, providing actionable feedback
with reasoning, and demonstrating the feasibility and practical viability of
developing in-house LLMs. This research highlights LLMs' potential to enhance
patient-provider interactions and lays the groundwork for downstream steps in
developing LLM-empowered clinical health systems.

中文翻译:
有效的医患沟通在临床护理中至关重要，直接影响患者治疗效果与生活质量。传统评估方法（如人工评分、患者反馈和医护人员自评）常受限于高昂成本与可扩展性问题。尽管现有自然语言处理技术展现出潜力，但其对临床沟通的微妙差异处理不足，且需依赖敏感的临床数据进行训练，降低了实际应用效果。新兴的大语言模型为评估复杂沟通指标提供了新思路，通过整合被动感知和即时干预系统有望推动该领域发展。本研究探索大语言模型作为姑息治疗沟通质量的评估工具，充分利用其语言理解、情境学习和推理能力。具体而言，我们采用医疗专业人员编写标注的模拟对话脚本，测试了GPT-4等专有模型，并利用GPT-4生成的合成数据集对LLaMA2等开源模型进行微调，以评估临床对话中"理解"与"共情"等核心指标。研究结果表明：大语言模型在临床沟通评估中表现优异，能提供具有推理依据的可行性反馈，同时验证了开发内部专用模型的可行性与实用价值。该研究揭示了大语言模型优化医患互动的潜力，为构建基于大语言模型的临床健康系统奠定了重要基础。
