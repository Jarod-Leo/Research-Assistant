# PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models

链接: http://arxiv.org/abs/2409.15188v2

原文摘要:
Effective patient-provider communication is crucial in clinical care,
directly impacting patient outcomes and quality of life. Traditional evaluation
methods, such as human ratings, patient feedback, and provider
self-assessments, are often limited by high costs and scalability issues.
Although existing natural language processing (NLP) techniques show promise,
they struggle with the nuances of clinical communication and require sensitive
clinical data for training, reducing their effectiveness in real-world
applications. Emerging large language models (LLMs) offer a new approach to
assessing complex communication metrics, with the potential to advance the
field through integration into passive sensing and just-in-time intervention
systems. This study explores LLMs as evaluators of palliative care
communication quality, leveraging their linguistic, in-context learning, and
reasoning capabilities. Specifically, using simulated scripts crafted and
labeled by healthcare professionals, we test proprietary models (e.g., GPT-4)
and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset
generated by GPT-4 to evaluate clinical conversations, to identify key metrics
such as `understanding' and `empathy'. Our findings demonstrated LLMs' superior
performance in evaluating clinical communication, providing actionable feedback
with reasoning, and demonstrating the feasibility and practical viability of
developing in-house LLMs. This research highlights LLMs' potential to enhance
patient-provider interactions and lays the groundwork for downstream steps in
developing LLM-empowered clinical health systems.

中文翻译:
以下是符合学术规范的中文翻译：

医患沟通有效性在临床护理中至关重要，其直接影响患者治疗效果与生存质量。传统评估方法（如人工评分、患者反馈和医护人员自评）常受限于高成本与可扩展性问题。现有自然语言处理（NLP）技术虽具潜力，但难以捕捉临床沟通的细微差异，且需依赖敏感临床数据进行训练，限制了实际应用效果。新兴大语言模型（LLMs）为评估复杂沟通指标提供了新思路，通过整合被动感知和即时干预系统有望推动该领域发展。本研究探索LLMs在姑息治疗沟通质量评估中的应用，利用其语言理解、情境学习和推理能力。具体而言，我们采用医疗专业人员编写标注的模拟对话脚本，测试GPT-4等专有模型，并基于GPT-4生成的合成数据集微调LLaMA2等开源模型，用以评估临床对话中"理解"与"共情"等核心指标。研究发现：LLMs在临床沟通评估中表现优异，能提供具有推理依据的可操作反馈，证实开发内部LLM模型的可行性与实用价值。本研究揭示了LLMs优化医患互动的潜力，为开发LLM赋能的临床健康系统奠定了理论基础。

（翻译说明：1. 专业术语统一处理如"palliative care"译为"姑息治疗"；2. 长句拆分符合中文表达习惯；3. 被动语态转换为主动句式；4. 关键概念如"just-in-time intervention"采用"即时干预"等学界通用译法；5. 保留原文学术严谨性的同时提升中文可读性）
