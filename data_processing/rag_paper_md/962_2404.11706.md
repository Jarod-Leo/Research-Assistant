# Pretraining Billion-scale Geospatial Foundational Models on Frontier

链接: http://arxiv.org/abs/2404.11706v1

原文摘要:
As AI workloads increase in scope, generalization capability becomes
challenging for small task-specific models and their demand for large amounts
of labeled training samples increases. On the contrary, Foundation Models (FMs)
are trained with internet-scale unlabeled data via self-supervised learning and
have been shown to adapt to various tasks with minimal fine-tuning. Although
large FMs have demonstrated significant impact in natural language processing
and computer vision, efforts toward FMs for geospatial applications have been
restricted to smaller size models, as pretraining larger models requires very
large computing resources equipped with state-of-the-art hardware accelerators.
Current satellite constellations collect 100+TBs of data a day, resulting in
images that are billions of pixels and multimodal in nature. Such geospatial
data poses unique challenges opening up new opportunities to develop FMs. We
investigate billion scale FMs and HPC training profiles for geospatial
applications by pretraining on publicly available data. We studied from
end-to-end the performance and impact in the solution by scaling the model
size. Our larger 3B parameter size model achieves up to 30% improvement in top1
scene classification accuracy when comparing a 100M parameter model. Moreover,
we detail performance experiments on the Frontier supercomputer, America's
first exascale system, where we study different model and data parallel
approaches using PyTorch's Fully Sharded Data Parallel library. Specifically,
we study variants of the Vision Transformer architecture (ViT), conducting
performance analysis for ViT models with size up to 15B parameters. By
discussing throughput and performance bottlenecks under different parallelism
configurations, we offer insights on how to leverage such leadership-class HPC
resources when developing large models for geospatial imagery applications.

中文翻译:
随着人工智能任务范围的扩大，专用小模型的泛化能力面临严峻挑战，其对大量标注训练样本的需求也急剧增长。相比之下，基础模型（FMs）通过自监督学习利用互联网规模的无标注数据进行训练，并已证明只需微调即可适应多种任务。尽管大型基础模型在自然语言处理和计算机视觉领域展现出重大影响，但面向地理空间应用的基础模型研发仍局限于较小规模，因为预训练更大模型需要配备尖端硬件加速器的超大规模计算资源。当前卫星星座每天采集超过100TB数据，生成数十亿像素且本质多模态的图像。这类地理空间数据带来独特挑战，同时也为开发基础模型开辟了新机遇。我们通过在公开数据上进行预训练，研究了面向地理空间应用的十亿级基础模型及高性能计算训练方案。通过模型规模扩展，我们系统评估了端到端性能及其对解决方案的影响。与1亿参数模型相比，我们30亿参数的大模型在场景分类Top1准确率上实现了高达30%的提升。此外，我们在美国首个百亿亿次超级计算机"Frontier"上开展了性能实验，利用PyTorch全分片数据并行库研究了不同模型与数据并行策略。特别针对视觉Transformer架构（ViT）的变体，我们对高达150亿参数的ViT模型进行了性能分析。通过讨论不同并行配置下的吞吐量与性能瓶颈，我们为开发地理空间影像应用大模型时如何利用这类顶级高性能计算资源提供了实践洞见。
