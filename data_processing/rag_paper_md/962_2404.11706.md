# Pretraining Billion-scale Geospatial Foundational Models on Frontier

链接: http://arxiv.org/abs/2404.11706v1

原文摘要:
As AI workloads increase in scope, generalization capability becomes
challenging for small task-specific models and their demand for large amounts
of labeled training samples increases. On the contrary, Foundation Models (FMs)
are trained with internet-scale unlabeled data via self-supervised learning and
have been shown to adapt to various tasks with minimal fine-tuning. Although
large FMs have demonstrated significant impact in natural language processing
and computer vision, efforts toward FMs for geospatial applications have been
restricted to smaller size models, as pretraining larger models requires very
large computing resources equipped with state-of-the-art hardware accelerators.
Current satellite constellations collect 100+TBs of data a day, resulting in
images that are billions of pixels and multimodal in nature. Such geospatial
data poses unique challenges opening up new opportunities to develop FMs. We
investigate billion scale FMs and HPC training profiles for geospatial
applications by pretraining on publicly available data. We studied from
end-to-end the performance and impact in the solution by scaling the model
size. Our larger 3B parameter size model achieves up to 30% improvement in top1
scene classification accuracy when comparing a 100M parameter model. Moreover,
we detail performance experiments on the Frontier supercomputer, America's
first exascale system, where we study different model and data parallel
approaches using PyTorch's Fully Sharded Data Parallel library. Specifically,
we study variants of the Vision Transformer architecture (ViT), conducting
performance analysis for ViT models with size up to 15B parameters. By
discussing throughput and performance bottlenecks under different parallelism
configurations, we offer insights on how to leverage such leadership-class HPC
resources when developing large models for geospatial imagery applications.

中文翻译:
随着人工智能应用范围的扩大，专用小模型的泛化能力面临挑战，其对大量标注训练样本的需求也日益增长。相比之下，基础模型（FMs）通过自监督学习利用互联网规模的无标注数据进行训练，并已证明只需微调即可适应多种任务。尽管大型基础模型在自然语言处理和计算机视觉领域展现出重大影响，但地理空间应用的基础模型研发仍局限于较小规模，因为预训练更大模型需要配备尖端硬件加速器的超大规模计算资源。当前卫星星座每天采集超过100TB数据，生成数十亿像素的多模态图像。这类地理空间数据带来独特挑战，同时也为基础模型开发创造了新机遇。我们通过在公开数据上进行预训练，研究了十亿级规模基础模型及其高性能计算训练方案在地理空间应用中的表现。通过端到端研究模型规模扩展对解决方案的影响，发现30亿参数的大模型相较于1亿参数模型，在场景分类任务中Top1准确率最高可提升30%。此外，我们在美国首个百亿亿次超级计算机"Frontier"上开展了性能实验，使用PyTorch全分片数据并行库研究了不同模型与数据并行策略。特别针对视觉Transformer架构（ViT）的变体，我们对参数规模达150亿的ViT模型进行了性能分析。通过讨论不同并行配置下的吞吐量与性能瓶颈，为开发地理空间影像大模型如何利用这类顶级高性能计算资源提供了实践洞见。
