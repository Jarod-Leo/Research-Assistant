# Token-Level Privacy in Large Language Models

链接: http://arxiv.org/abs/2503.03652v1

原文摘要:
The use of language models as remote services requires transmitting private
information to external providers, raising significant privacy concerns. This
process not only risks exposing sensitive data to untrusted service providers
but also leaves it vulnerable to interception by eavesdroppers. Existing
privacy-preserving methods for natural language processing (NLP) interactions
primarily rely on semantic similarity, overlooking the role of contextual
information. In this work, we introduce dchi-stencil, a novel token-level
privacy-preserving mechanism that integrates contextual and semantic
information while ensuring strong privacy guarantees under the dchi
differential privacy framework, achieving 2epsilon-dchi-privacy. By
incorporating both semantic and contextual nuances, dchi-stencil achieves a
robust balance between privacy and utility. We evaluate dchi-stencil using
state-of-the-art language models and diverse datasets, achieving comparable and
even better trade-off between utility and privacy compared to existing methods.
This work highlights the potential of dchi-stencil to set a new standard for
privacy-preserving NLP in modern, high-risk applications.

中文翻译:
将语言模型作为远程服务使用时，需向外部提供商传输隐私信息，这引发了重大隐私隐患。该过程不仅可能使敏感数据暴露于不可信的服务商，还存在被窃听者截获的风险。现有自然语言处理（NLP）交互的隐私保护方法主要依赖语义相似性，忽视了上下文信息的作用。本研究提出dchi-stencil——一种创新的词元级隐私保护机制，该机制在dchi差分隐私框架下（实现2ε-dchi隐私）整合上下文与语义信息，通过兼顾语义细微差别和上下文关联，实现了隐私性与实用性的稳健平衡。我们采用前沿语言模型和多样化数据集对dchi-stencil进行评估，结果显示其相较现有方法能达成相当甚至更优的效用-隐私平衡。这项研究彰显了dchi-stencil为高风险现代应用场景树立隐私保护NLP新标准的潜力。
