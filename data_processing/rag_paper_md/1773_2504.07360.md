# Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs

链接: http://arxiv.org/abs/2504.07360v1

原文摘要:
The adaptation of large language models (LLMs) to time series forecasting
poses unique challenges, as time series data is continuous in nature, while
LLMs operate on discrete tokens. Despite the success of LLMs in natural
language processing (NLP) and other structured domains, aligning time series
data with language-based representations while maintaining both predictive
accuracy and interpretability remains a significant hurdle. Existing methods
have attempted to reprogram time series data into text-based forms, but these
often fall short in delivering meaningful, interpretable results. In this
paper, we propose a multi-level text alignment framework for time series
forecasting using LLMs that not only improves prediction accuracy but also
enhances the interpretability of time series representations. Our method
decomposes time series into trend, seasonal, and residual components, which are
then reprogrammed into component-specific text representations. We introduce a
multi-level alignment mechanism, where component-specific embeddings are
aligned with pre-trained word tokens, enabling more interpretable forecasts.
Experiments on multiple datasets demonstrate that our method outperforms
state-of-the-art models in accuracy while providing good interpretability.

中文翻译:
大型语言模型（LLMs）在时间序列预测任务中的适配面临独特挑战，因为时间序列数据本质上是连续的，而LLMs处理的是离散符号。尽管LLMs在自然语言处理（NLP）和其他结构化领域取得了成功，但如何在保持预测精度和可解释性的同时，将时间序列数据与基于语言的表征对齐仍是一个重大难题。现有方法尝试将时间序列数据重编程为文本形式，但这些方法往往难以产生有意义且可解释的结果。本文提出了一种基于LLMs的多层次文本对齐框架，该框架不仅能提升预测精度，还能增强时间序列表征的可解释性。我们的方法将时间序列分解为趋势、季节性和残差分量，并将其重编程为各分量对应的文本表征。通过引入多层次对齐机制，使分量特定的嵌入向量与预训练词汇符号对齐，从而生成更具可解释性的预测结果。多组数据集实验表明，本方法在预测精度上优于当前最先进模型，同时具有良好的可解释性。
