# TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling

链接: http://arxiv.org/abs/2504.07053v1

原文摘要:
Large Language Models (LLMs) excel in text-based natural language processing
tasks but remain constrained by their reliance on textual inputs and outputs.
To enable more natural human-LLM interaction, recent progress have focused on
deriving a spoken language model (SLM) that can not only listen but also
generate speech. To achieve this, a promising direction is to conduct
speech-text joint modeling. However, recent SLM still lag behind text LLM due
to the modality mismatch. One significant mismatch can be the sequence lengths
between speech and text tokens. To address this, we introduce Text-Aligned
Speech Tokenization and Embedding (TASTE), a method that directly addresses the
modality gap by aligning speech token with the corresponding text transcription
during the tokenization stage. We propose a method that can achieve this
through the special aggregation mechanism and with speech reconstruction as the
training objective. We conduct extensive experiments and show that TASTE can
preserve essential paralinguistic information while dramatically reducing the
token sequence length. Furthermore, by leveraging TASTE, we can adapt
text-based LLMs into effective SLMs with parameter-efficient fine-tuning
techniques such as Low-Rank Adaptation (LoRA). Experimental results on
benchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based
SLMs perform similarly to previous full-finetuning methods. To our knowledge,
TASTE is the first end-to-end approach that utilizes a reconstruction objective
to automatically learn a text-aligned speech tokenization and embedding
suitable for spoken language modeling. Our demo, code, and models are publicly
available at https://github.com/mtkresearch/TASTE-SpokenLM.

中文翻译:
大型语言模型（LLMs）在基于文本的自然语言处理任务中表现出色，但其依赖文本输入输出的特性仍存在局限。为实现更自然的人机交互，近期研究致力于开发既能聆听又能生成语音的口语模型（SLM）。实现这一目标的关键方向之一是构建语音-文本联合建模。然而，由于模态不匹配问题，现有SLM性能仍落后于文本LLM。其中显著的差异在于语音与文本标记的序列长度差异。为此，我们提出文本对齐语音标记化与嵌入方法（TASTE），该方法通过在标记化阶段将语音标记与对应文本转录对齐，直接解决模态差异问题。我们设计了一种通过特殊聚合机制实现该目标的方法，并以语音重构作为训练目标。大量实验表明，TASTE能在显著缩短标记序列长度的同时保留关键副语言信息。此外，借助TASTE，我们可以通过参数高效微调技术（如低秩适应LoRA）将基于文本的LLM适配为高效SLM。在SALMON和StoryCloze等基准任务上的实验结果显示，基于TASTE的SLM性能与先前全参数微调方法相当。据我们所知，TASTE是首个利用重构目标自动学习适用于口语建模的文本对齐语音标记化与嵌入的端到端方法。我们的演示、代码及模型已开源：https://github.com/mtkresearch/TASTE-SpokenLM。
