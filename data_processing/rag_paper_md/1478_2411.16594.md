# From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge

链接: http://arxiv.org/abs/2411.16594v1

原文摘要:
Assessment and evaluation have long been critical challenges in artificial
intelligence (AI) and natural language processing (NLP). However, traditional
methods, whether matching-based or embedding-based, often fall short of judging
subtle attributes and delivering satisfactory results. Recent advancements in
Large Language Models (LLMs) inspire the "LLM-as-a-judge" paradigm, where LLMs
are leveraged to perform scoring, ranking, or selection across various tasks
and applications. This paper provides a comprehensive survey of LLM-based
judgment and assessment, offering an in-depth overview to advance this emerging
field. We begin by giving detailed definitions from both input and output
perspectives. Then we introduce a comprehensive taxonomy to explore
LLM-as-a-judge from three dimensions: what to judge, how to judge and where to
judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and
highlight key challenges and promising directions, aiming to provide valuable
insights and inspire future research in this promising research area. Paper
list and more resources about LLM-as-a-judge can be found at
https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge and
https://llm-as-a-judge.github.io.

中文翻译:
评估与评测长期以来一直是人工智能（AI）和自然语言处理（NLP）领域的关键挑战。然而传统方法——无论是基于匹配还是基于嵌入的评估——往往难以判断细微属性并交付令人满意的结果。大型语言模型（LLM）的最新进展催生了"LLM即评委"范式，即利用LLM在各种任务和应用场景中执行评分、排序或选择操作。本文对基于LLM的评判与评估研究进行了全面综述，通过深入梳理推动这一新兴领域发展。我们首先从输入输出维度给出了详细定义，随后构建三维分类体系（评判内容、评判方式和应用场景）系统探索LLM即评委范式，最后整理评测基准并指出关键挑战与前景方向，旨在为该领域研究者提供洞见与启发。相关论文列表及更多资源详见https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge与https://llm-as-a-judge.github.io。
