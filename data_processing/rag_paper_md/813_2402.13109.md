# CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models

链接: http://arxiv.org/abs/2402.13109v1

原文摘要:
The advancement of large language models (LLMs) has enhanced the ability to
generalize across a wide range of unseen natural language processing (NLP)
tasks through instruction-following. Yet, their effectiveness often diminishes
in low-resource languages like Chinese, exacerbated by biased evaluations from
data leakage, casting doubt on their true generalizability to new linguistic
territories. In response, we introduce the Chinese Instruction-Following
Benchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of
LLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000
input-output pairs, developed by native speakers to test complex reasoning and
Chinese cultural nuances across 20 categories. To mitigate data contamination,
we release only half of the dataset publicly, with the remainder kept private,
and introduce diversified instructions to minimize score variance, totaling
45,000 data instances. Our evaluation of 28 selected LLMs reveals a noticeable
performance gap, with the best model scoring only 52.9%, highlighting the
limitations of LLMs in less familiar language and task contexts. This work not
only uncovers the current limitations of LLMs in handling Chinese language
tasks but also sets a new standard for future LLM generalizability research,
pushing towards the development of more adaptable, culturally informed, and
linguistically diverse models.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）的发展通过指令跟随机制增强了在未见自然语言处理（NLP）任务上的泛化能力。然而，这些模型在中文等低资源语言中的表现往往欠佳，加之数据泄露导致的评估偏差，使其在新语言领域的真实泛化能力备受质疑。为此，我们推出中文指令跟随基准（CIF-Bench），专门评估LLMs对中文的零样本泛化能力。该基准包含150项任务和15,000个输入-输出对，由母语者设计以测试20个类别中的复杂推理能力与中华文化语境理解。为降低数据污染风险，我们仅公开半数数据集并保留其余部分，同时引入45,000条多样化指令以减小评分方差。对28个精选LLMs的评估显示显著性能差距，最优模型仅获52.9%得分，凸显LLMs在陌生语言和任务场景中的局限性。本研究不仅揭示了LLMs处理中文任务的现存不足，更为未来LLM泛化能力研究树立新标准，推动开发更具适应性、文化包容性和语言多样性的模型。

翻译特色说明：
1. 专业术语处理："zero-shot"译为"零样本"，"data leakage"译为"数据泄露"，符合NLP领域规范
2. 文化适配："Chinese cultural nuances"译为"中华文化语境理解"，既准确又体现文化内涵
3. 长句拆分：将原文复合句按中文习惯分解为多个短句，如将"exacerbated by..."独立成句
4. 被动语态转化："are developed"译为主动式"由母语者设计"
5. 数据呈现：精确保留所有数值（150/15,000/52.9%等）和专有名词（CIF-Bench）
6. 学术风格：使用"泛化能力""基准""凸显"等符合论文摘要的正式用语
7. 逻辑衔接：通过"为此""同时""不仅...更..."等连接词保持论证连贯性
