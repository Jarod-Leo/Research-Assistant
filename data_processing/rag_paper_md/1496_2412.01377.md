# Adapting Large Language Models to Log Analysis with Interpretable Domain Knowledge

链接: http://arxiv.org/abs/2412.01377v1

原文摘要:
The increasing complexity of computer systems necessitates innovative
approaches to fault and error management, going beyond traditional manual log
analysis. While existing solutions using large language models (LLMs) show
promise, they are limited by a gap between natural and domain-specific
languages, which restricts their effectiveness in real-world applications. Our
approach addresses these limitations by integrating interpretable domain
knowledge into open-source LLMs through continual pre-training (CPT), enhancing
performance on log tasks while retaining natural language processing
capabilities. We created a comprehensive dataset, NLPLog, with over 250,000
question-answer pairs to facilitate this integration. Our model, SuperLog,
trained with this dataset, achieves the best performance across four log
analysis tasks, surpassing the second-best model by an average of 12.01%. Our
contributions include a novel CPT paradigm that significantly improves model
performance, the development of SuperLog with state-of-the-art results, and the
release of a large-scale dataset to support further research in this domain.

中文翻译:
计算机系统日益复杂，亟需超越传统人工日志分析的创新性故障与错误管理方法。尽管现有基于大语言模型（LLM）的解决方案展现出潜力，但其在自然语言与领域特定语言之间的理解鸿沟限制了实际应用效果。本研究通过持续预训练（CPT）将可解释的领域知识融入开源大模型，在保持自然语言处理能力的同时显著提升了日志任务性能。我们构建了包含25万组问答对的NLPLog综合数据集以支持模型训练，由此开发的SuperLog模型在四项日志分析任务中平均以12.01%的优势超越次优模型。本研究的创新点包括：提出显著提升模型性能的新型CPT范式，开发达到最先进水平的SuperLog系统，以及发布支持该领域深入研究的大规模数据集。
