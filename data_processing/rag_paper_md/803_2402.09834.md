# All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining

链接: http://arxiv.org/abs/2402.09834v1

原文摘要:
Large Language Models (LLMs) have revolutionized the fields of computer
vision (CV) and natural language processing (NLP). One of the most notable
advancements of LLMs is that a single model is trained on vast and diverse
datasets spanning multiple domains -- a paradigm we term `All in One'. This
methodology empowers LLMs with super generalization capabilities, facilitating
an encompassing comprehension of varied data distributions. Leveraging these
capabilities, a single LLM demonstrates remarkable versatility across a variety
of domains -- a paradigm we term `One for All'. However, applying this idea to
the graph field remains a formidable challenge, with cross-domain pretraining
often resulting in negative transfer. This issue is particularly important in
few-shot learning scenarios, where the paucity of training data necessitates
the incorporation of external knowledge sources. In response to this challenge,
we propose a novel approach called Graph COordinators for PrEtraining (GCOPE),
that harnesses the underlying commonalities across diverse graph datasets to
enhance few-shot learning. Our novel methodology involves a unification
framework that amalgamates disparate graph datasets during the pretraining
phase to distill and transfer meaningful knowledge to target tasks. Extensive
experiments across multiple graph datasets demonstrate the superior efficacy of
our approach. By successfully leveraging the synergistic potential of multiple
graph datasets for pretraining, our work stands as a pioneering contribution to
the realm of graph foundational model.

中文翻译:
大语言模型（LLMs）彻底改变了计算机视觉（CV）和自然语言处理（NLP）领域。其最显著的突破之一在于：单个模型通过跨多领域的海量多样化数据集进行训练——这一范式我们称之为"All in One"。该方法赋予LLMs超强的泛化能力，使其能够全面理解不同数据分布。凭借这些能力，单一LLM在多个领域展现出卓越的通用性——这一范式我们称为"One for All"。然而，将该理念应用于图领域仍面临巨大挑战，跨域预训练常导致负迁移现象。这一问题在少样本学习场景中尤为突出，当训练数据稀缺时，必须引入外部知识源。

针对这一挑战，我们提出创新方法GCOPE（图协调预训练框架），通过挖掘不同图数据集间的潜在共性来增强少样本学习。我们的核心创新在于设计了一个预训练阶段的统一框架，能够整合异构图数据集，从而提炼并迁移有效知识至目标任务。跨多个图数据集的广泛实验证明了该方法的卓越效能。通过成功利用多图数据集的协同效应进行预训练，本研究为图基础模型领域作出了开创性贡献。
