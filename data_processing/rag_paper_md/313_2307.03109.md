# A Survey on Evaluation of Large Language Models

链接: http://arxiv.org/abs/2307.03109v1

原文摘要:
Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.

中文翻译:
大型语言模型（LLMs）凭借其在各类应用中的卓越表现，正日益受到学术界与工业界的广泛关注。随着LLMs在科研与日常应用中扮演愈发重要的角色，对其评估的需求不仅局限于任务层面，更需延伸至社会层面以深入理解其潜在风险。近年来，研究者们从多维度对LLMs进行了系统性评估探索。本文从评估内容（评估什么）、评估框架（何处评估）及评估方法（如何评估）三个核心维度，全面梳理了当前LLMs评估的研究进展。

首先从评估任务视角，系统归纳了通用自然语言处理任务、推理能力、医疗应用、伦理合规性、教育领域、自然科学与社会科学、智能体应用及其他前沿方向的评估体系。其次通过解析评估方法论与基准测试体系，深入解答了"如何评估"与"基于什么标准评估"的关键问题。进而总结了LLMs在不同任务中的成功案例与典型失效场景。最后，前瞻性提出了LLMs评估领域亟待解决的若干挑战。

本研究旨在为LLMs评估领域的研究者提供系统性的参考框架，推动构建更强大的语言模型。我们强调应将评估视为促进LLMs发展的核心方法论，并持续维护开源资料库：https://github.com/MLGroupJLU/LLM-eval-survey。
