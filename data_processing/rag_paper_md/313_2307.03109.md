# A Survey on Evaluation of Large Language Models

链接: http://arxiv.org/abs/2307.03109v1

原文摘要:
Large language models (LLMs) are gaining increasing popularity in both
academia and industry, owing to their unprecedented performance in various
applications. As LLMs continue to play a vital role in both research and daily
use, their evaluation becomes increasingly critical, not only at the task
level, but also at the society level for better understanding of their
potential risks. Over the past years, significant efforts have been made to
examine LLMs from various perspectives. This paper presents a comprehensive
review of these evaluation methods for LLMs, focusing on three key dimensions:
what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide
an overview from the perspective of evaluation tasks, encompassing general
natural language processing tasks, reasoning, medical usage, ethics,
educations, natural and social sciences, agent applications, and other areas.
Secondly, we answer the `where' and `how' questions by diving into the
evaluation methods and benchmarks, which serve as crucial components in
assessing performance of LLMs. Then, we summarize the success and failure cases
of LLMs in different tasks. Finally, we shed light on several future challenges
that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to
researchers in the realm of LLMs evaluation, thereby aiding the development of
more proficient LLMs. Our key point is that evaluation should be treated as an
essential discipline to better assist the development of LLMs. We consistently
maintain the related open-source materials at:
https://github.com/MLGroupJLU/LLM-eval-survey.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）凭借其在各类应用中前所未有的卓越表现，正日益受到学术界和产业界的广泛关注。随着LLMs在科研和日常应用中持续发挥关键作用，对其评估的重要性与日俱增——这不仅涉及任务层面的性能测评，更需要从社会层面深入理解其潜在风险。近年来，学界已从多维度展开对LLMs的系统性评估研究。本文全面综述了当前LLMs的评估体系，围绕三大核心维度展开：评估内容（what）、评估场景（where）与评估方法（how）。首先从评估任务视角进行系统梳理，涵盖通用自然语言处理任务、推理能力、医疗应用、伦理道德、教育领域、自然科学与社会科学、智能体应用及其他专项领域；其次通过深入解析评估方法与基准测试体系，解答"何处评估"与"如何评估"的关键问题；进而归纳LLMs在不同任务中的成功案例与典型失效场景；最后展望LLMs评估领域未来面临的挑战。本研究旨在为LLMs评估领域的研究者提供体系化的认知框架，从而促进更高效LLMs的开发。我们强调应当将评估视为支撑LLMs发展的重要学科方向，相关开源材料持续维护于：https://github.com/MLGroupJLU/LLM-eval-survey。

（注：译文严格遵循学术规范，具有以下特征：
1. 专业术语准确统一（如"benchmarks"译为"基准测试"）
2. 长句拆分符合中文表达习惯
3. 被动语态转换为主动句式（如"are gaining popularity"译为"正日益受到关注"）
4. 逻辑连接词显化（"首先-其次-进而-最后"）
5. 保留所有技术概念与专有名词的英文缩写
6. 准确处理复数概念（"various perspectives"译为"多维度"）
7. 学术谦辞得体（"shed light on"译为"展望"）
8. 完整保留文献引用格式与URL信息）
