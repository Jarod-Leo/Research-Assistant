# Light-Weight Fault Tolerant Attention for Large Language Model Training

链接: http://arxiv.org/abs/2410.11720v1

原文摘要:
Large Language Models (LLMs) have demonstrated remarkable performance in
various natural language processing tasks. However, the training of these
models is computationally intensive and susceptible to faults, particularly in
the attention mechanism, which is a critical component of transformer-based
LLMs. In this paper, we investigate the impact of faults on LLM training,
focusing on INF, NaN, and near-INF values in the computation results with
systematic fault injection experiments. We observe the propagation patterns of
these errors, which can trigger non-trainable states in the model and disrupt
training, forcing the procedure to load from checkpoints. To mitigate the
impact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault
Tolerance (ABFT) technique tailored for the attention mechanism in LLMs.
ATTNChecker is designed based on fault propagation patterns of LLM and
incorporates performance optimization to adapt to both system reliability and
model vulnerability while providing lightweight protection for fast LLM
training. Evaluations on four LLMs show that ATTNChecker incurs on average 7%
overhead on training while detecting and correcting all extreme errors.
Compared with the state-of-the-art checkpoint/restore approach, ATTNChecker
reduces recovery overhead by up to 49x.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越性能。然而，这类模型的训练过程存在计算密集性高且易受故障影响的特性，尤其对于基于Transformer架构的LLMs核心组件——注意力机制而言更是如此。本文通过系统性故障注入实验，重点研究了计算过程中出现的INF（无穷大）、NaN（非数值）及近INF值对LLM训练的影响。我们观察到这些错误会引发特定的传播模式，可能导致模型陷入不可训练状态并中断训练流程，迫使系统必须从检查点重新加载。为缓解此类故障影响，我们提出了ATTNChecker——首个专为LLM注意力机制设计的算法级容错（ABFT）技术。该方案基于LLM故障传播特性进行设计，通过性能优化实现系统可靠性与模型脆弱性的双重适配，同时为快速LLM训练提供轻量级防护。在四种LLM上的评估表明，ATTNChecker能以平均7%的训练开销检测并修正所有极端错误。相较于最先进的检查点/恢复方案，本方法最高可降低49倍的恢复开销。

（译文严格遵循学术规范，采用专业术语统一原则："fault injection experiments"译为"故障注入实验"、"non-trainable states"译为"不可训练状态"等。通过拆分英语长句为中文短句结构，如将原文第二句拆分为两个逻辑分句。保留关键技术缩写（INF/NaN/ABFT）并首次出现时标注全称，符合科技论文翻译标准。被动语态转换为中文主动表述，如"is computationally intensive"处理为"存在计算密集性高"。）
