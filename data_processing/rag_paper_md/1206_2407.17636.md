# IgnitionInnovators at "Discharge Me!": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries

链接: http://arxiv.org/abs/2407.17636v1

原文摘要:
This paper presents our proposed approach to the Discharge Me! shared task,
collocated with the 23th Workshop on Biomedical Natural Language Processing
(BioNLP). In this work, we develop an LLM-based framework for solving the
Discharge Summary Documentation (DSD) task, i.e., generating the two critical
target sections `Brief Hospital Course' and `Discharge Instructions' in the
discharge summary. By streamlining the recent instruction-finetuning process on
LLMs, we explore several prompting strategies for optimally adapting LLMs to
specific generation task of DSD. Experimental results show that providing a
clear output structure, complimented by a set of comprehensive
Chain-of-Thoughts (CoT) questions, effectively improves the model's reasoning
capability, and thereby, enhancing the structural correctness and faithfulness
of clinical information in the generated text. Source code is available at:
https://github.com/antangrocket1312/Discharge_LLM

中文翻译:
本文介绍了我们针对与第23届生物医学自然语言处理研讨会（BioNLP）同期举办的"Discharge Me!"共享任务提出的解决方案。本研究开发了一个基于大语言模型（LLM）的框架，用于完成出院摘要文档（DSD）任务，即生成出院摘要中两个关键目标章节"简要住院过程"和"出院指导"。通过优化最近的大语言模型指令微调流程，我们探索了多种提示策略，以实现大语言模型在DSD特定生成任务中的最佳适配。实验结果表明，提供清晰的输出结构并辅以一组全面的思维链（CoT）问题，能有效提升模型的推理能力，从而增强生成文本的结构准确性和临床信息的可信度。源代码已发布于：https://github.com/antangrocket1312/Discharge_LLM
