# ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning

链接: http://arxiv.org/abs/2309.01538v1

原文摘要:
Logical rules are essential for uncovering the logical connections between
relations, which could improve reasoning performance and provide interpretable
results on knowledge graphs (KGs). Although there have been many efforts to
mine meaningful logical rules over KGs, existing methods suffer from
computationally intensive searches over the rule space and a lack of
scalability for large-scale KGs. Besides, they often ignore the semantics of
relations which is crucial for uncovering logical connections. Recently, large
language models (LLMs) have shown impressive performance in the field of
natural language processing and various applications, owing to their emergent
ability and generalizability. In this paper, we propose a novel framework,
ChatRule, unleashing the power of large language models for mining logical
rules over knowledge graphs. Specifically, the framework is initiated with an
LLM-based rule generator, leveraging both the semantic and structural
information of KGs to prompt LLMs to generate logical rules. To refine the
generated rules, a rule ranking module estimates the rule quality by
incorporating facts from existing KGs. Last, the ranked rules can be used to
conduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,
w.r.t. different rule quality metrics and downstream tasks, showing the
effectiveness and scalability of our method.

中文翻译:
逻辑规则对于揭示关系间的逻辑关联至关重要，不仅能提升知识图谱（KGs）的推理性能，还能提供可解释的结果。尽管已有诸多方法致力于挖掘知识图谱中有意义的逻辑规则，现有技术仍面临规则空间搜索计算密集、难以适应大规模知识图谱的扩展需求等挑战。此外，这些方法往往忽视了对揭示逻辑连接至关重要的关系语义。近年来，大型语言模型（LLMs）凭借其涌现能力和泛化性，在自然语言处理领域及各类应用中展现出卓越性能。本文提出创新框架ChatRule，通过释放大型语言模型的潜力来实现知识图谱逻辑规则挖掘。该框架首先部署基于LLM的规则生成器，结合知识图谱的语义与结构信息来激发模型生成逻辑规则；随后通过规则排序模块融合知识图谱现有事实评估规则质量；最终将排序后的规则应用于知识图谱推理。在四个大规模知识图谱上的实验表明，ChatRule在不同规则质量指标和下游任务中均展现出卓越的有效性与可扩展性。
