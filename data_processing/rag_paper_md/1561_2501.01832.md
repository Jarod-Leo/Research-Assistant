# Time Series Language Model for Descriptive Caption Generation

链接: http://arxiv.org/abs/2501.01832v1

原文摘要:
The automatic generation of representative natural language descriptions for
observable patterns in time series data enhances interpretability, simplifies
analysis and increases cross-domain utility of temporal data. While pre-trained
foundation models have made considerable progress in natural language
processing (NLP) and computer vision (CV), their application to time series
analysis has been hindered by data scarcity. Although several large language
model (LLM)-based methods have been proposed for time series forecasting, time
series captioning is under-explored in the context of LLMs. In this paper, we
introduce TSLM, a novel time series language model designed specifically for
time series captioning. TSLM operates as an encoder-decoder model, leveraging
both text prompts and time series data representations to capture subtle
temporal patterns across multiple phases and generate precise textual
descriptions of time series inputs. TSLM addresses the data scarcity problem in
time series captioning by first leveraging an in-context prompting synthetic
data generation, and second denoising the generated data via a novel
cross-modal dense retrieval scoring applied to time series-caption pairs.
Experimental findings on various time series captioning datasets demonstrate
that TSLM outperforms existing state-of-the-art approaches from multiple data
modalities by a significant margin.

中文翻译:
为时间序列数据中的可观测模式自动生成具有代表性的自然语言描述，能够增强可解释性、简化分析流程并提升跨领域应用价值。尽管预训练基础模型在自然语言处理（NLP）和计算机视觉（CV）领域已取得显著进展，但数据稀缺问题阻碍了其在时间序列分析中的应用。虽然已有若干基于大语言模型（LLM）的时间序列预测方法被提出，但在LLM框架下对时间序列描述任务的研究仍显不足。本文提出TSLM——一种专为时间序列描述设计的新型时序语言模型。该模型采用编码器-解码器架构，通过融合文本提示与时间序列数据表征，精准捕捉多阶段时序特征，并生成对输入序列的精确文本描述。针对数据稀缺问题，TSLM创新性地采用双重解决方案：首先利用上下文提示合成数据生成技术，继而通过提出的跨模态稠密检索评分机制对生成的时序-描述对进行去噪处理。在多个时间序列描述数据集上的实验表明，TSLM显著优于现有跨模态最优方法，展现出卓越性能。
