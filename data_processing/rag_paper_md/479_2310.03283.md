# A Formalism and Approach for Improving Robustness of Large Language Models Using Risk-Adjusted Confidence Scores

链接: http://arxiv.org/abs/2310.03283v1

原文摘要:
Large Language Models (LLMs), such as ChatGPT, have achieved impressive
milestones in natural language processing (NLP). Despite their impressive
performance, the models are known to pose important risks. As these models are
deployed in real-world applications, a systematic understanding of different
risks posed by these models on tasks such as natural language inference (NLI),
is much needed. In this paper, we define and formalize two distinct types of
risk: decision risk and composite risk. We also propose a risk-centric
evaluation framework, and four novel metrics, for assessing LLMs on these risks
in both in-domain and out-of-domain settings. Finally, we propose a
risk-adjusted calibration method called DwD for helping LLMs minimize these
risks in an overall NLI architecture. Detailed experiments, using four NLI
benchmarks, three baselines and two LLMs, including ChatGPT, show both the
practical utility of the evaluation framework, and the efficacy of DwD in
reducing decision and composite risk. For instance, when using DwD, an
underlying LLM is able to address an extra 20.1% of low-risk inference tasks
(but which the LLM erroneously deems high-risk without risk adjustment) and
skip a further 19.8% of high-risk tasks, which would have been answered
incorrectly.

中文翻译:
以ChatGPT为代表的大型语言模型（LLM）在自然语言处理（NLP）领域取得了令人瞩目的突破。然而这些模型在展现卓越性能的同时，也潜藏着不容忽视的风险。随着此类模型在实际场景中的广泛应用，亟需系统性地评估其在自然语言推理（NLI）等任务中可能引发的各类风险。本文明确定义并形式化了两种风险类型：决策风险与复合风险，提出以风险为核心的四项新型评估指标及对应框架，用于衡量模型在域内与域外环境下的风险表现。此外，我们创新性地提出风险自适应校准方法DwD，通过优化NLI整体架构来最小化模型风险。基于四个NLI基准数据集、三种基线模型及包括ChatGPT在内的两种LLM的详细实验表明：该评估框架具有显著实用价值，DwD方法能有效降低决策风险（20.1%原被误判为高风险的简单任务得以正确处理）与复合风险（19.8%原将导致错误回答的高风险任务被成功规避）。
