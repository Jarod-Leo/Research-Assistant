# Ethos: Rectifying Language Models in Orthogonal Parameter Space

链接: http://arxiv.org/abs/2403.08994v1

原文摘要:
Language models (LMs) have greatly propelled the research on natural language
processing. However, LMs also raise concerns regarding the generation of biased
or toxic content and the potential disclosure of private information from the
training dataset. In this work, we present a new efficient approach, Ethos,
that rectifies LMs to mitigate toxicity and bias in outputs and avoid privacy
leakage. Ethos is built on task arithmetic. However, unlike current task
arithmetic algorithms, Ethos distinguishes general beneficial and undesired
knowledge when reconstructing task vectors. Specifically, Ethos first obtains a
set of principal components from the pre-trained models using singular value
decomposition. Then, by projecting the task vector onto principal components,
Ethos identifies the principal components that encode general or undesired
knowledge. Ethos performs negating using the task vector with undesired
knowledge only, thereby minimizing collateral damage on general model utility.
We demonstrate the efficacy of our approach on three different tasks:
debiasing, detoxification, and memorization unlearning. Evaluations show Ethos
is more effective in removing undesired knowledge and maintaining the overall
model performance compared to current task arithmetic methods.

中文翻译:
语言模型（LMs）显著推动了自然语言处理领域的研究进展，然而其生成内容可能存在的偏见、毒性及训练数据隐私泄露风险也引发广泛关注。本研究提出了一种名为Ethos的新型高效方法，通过模型修正来降低输出毒性与偏见，同时防止隐私泄露。Ethos基于任务算术框架创新性地实现了知识选择性重构：区别于现有算法，该方法在重构任务向量时能区分通用有益知识与不良知识。具体而言，Ethos首先通过奇异值分解从预训练模型中提取主成分，随后将任务向量投影至主成分空间以识别编码通用知识或不良知识的关键成分。该方法仅对包含不良知识的任务向量执行否定操作，从而最大限度保留模型通用性能。我们在去偏见、毒性消除和记忆遗忘三项任务上验证了该方法的有效性。评估结果表明，相较于现有任务算术方法，Ethos在去除不良知识的同时能更好地保持模型整体性能。
