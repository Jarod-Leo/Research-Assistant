# CAPO: Cost-Aware Prompt Optimization

链接: http://arxiv.org/abs/2504.16005v1

原文摘要:
Large language models (LLMs) have revolutionized natural language processing
by solving a wide range of tasks simply guided by a prompt. Yet their
performance is highly sensitive to prompt formulation. While automated prompt
optimization addresses this challenge by finding optimal prompts, current
methods require a substantial number of LLM calls and input tokens, making
prompt optimization expensive. We introduce CAPO (Cost-Aware Prompt
Optimization), an algorithm that enhances prompt optimization efficiency by
integrating AutoML techniques. CAPO is an evolutionary approach with LLMs as
operators, incorporating racing to save evaluations and multi-objective
optimization to balance performance with prompt length. It jointly optimizes
instructions and few-shot examples while leveraging task descriptions for
improved robustness. Our extensive experiments across diverse datasets and LLMs
demonstrate that CAPO outperforms state-of-the-art discrete prompt optimization
methods in 11/15 cases with improvements up to 21%p. Our algorithm achieves
better performances already with smaller budgets, saves evaluations through
racing, and decreases average prompt length via a length penalty, making it
both cost-efficient and cost-aware. Even without few-shot examples, CAPO
outperforms its competitors and generally remains robust to initial prompts.
CAPO represents an important step toward making prompt optimization more
powerful and accessible by improving cost-efficiency.

中文翻译:
大型语言模型（LLMs）通过仅需提示引导即可解决广泛任务，彻底改变了自然语言处理领域。然而其性能对提示表述极为敏感。虽然自动提示优化技术通过寻找最优提示应对这一挑战，但现有方法需调用大量LLM并消耗海量输入标记，导致优化成本高昂。本文提出成本感知提示优化算法CAPO，通过融合自动机器学习技术显著提升提示优化效率。该算法采用以LLM为操作符的进化策略，引入评估淘汰机制以节省计算量，并运用多目标优化平衡性能与提示长度。CAPO能同步优化指令模板与少样本示例，同时利用任务描述提升鲁棒性。

我们在多样化数据集和LLM上的大量实验表明：在15个案例中有11项CAPO超越当前最先进的离散提示优化方法，最高提升达21个百分点。该算法在较小预算下即可实现更优性能，通过淘汰机制减少评估次数，并借助长度惩罚项降低平均提示长度，兼具成本效益与成本感知特性。即使不包含少样本示例，CAPO仍优于同类方法，且对初始提示普遍保持强鲁棒性。

CAPO通过显著提升成本效益，为推动提示优化技术迈向更强大、更易用的新阶段迈出了重要一步。
