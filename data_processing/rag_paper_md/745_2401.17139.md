# Large Language Model Evaluation via Matrix Entropy

链接: http://arxiv.org/abs/2401.17139v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing and
extended their powerful capabilities to multi-modal domains. As LLMs continue
to advance, it is crucial to develop diverse and appropriate metrics for their
evaluation. In this paper, we introduce a novel rank-based metric, Diff-eRank,
grounded in information theory and geometry principles. Diff-eRank assesses
LLMs by analyzing their hidden representations, providing a quantitative
measure of how efficiently they eliminate redundant information during
training. We demonstrate the applicability of Diff-eRank in both single-modal
(e.g., language) and multi-modal settings. For language models, our results
show that Diff-eRank increases with model size and correlates well with
conventional metrics such as loss and accuracy. In the multi-modal context, we
propose an alignment evaluation method based on the eRank, and verify that
contemporary multi-modal LLMs exhibit strong alignment performance based on our
method. Our code is publicly available at
https://github.com/waltonfuture/Diff-eRank.

中文翻译:
大语言模型（LLMs）已彻底改变自然语言处理领域，并将其强大能力扩展至多模态领域。随着LLMs的持续发展，建立多样化且适配的评估指标至关重要。本文提出了一种基于信息论与几何原理的新型排序指标Diff-eRank，通过分析模型的隐层表征，量化评估LLMs在训练过程中消除冗余信息的效率。我们验证了该指标在单模态（如语言）和多模态场景中的适用性：对于语言模型，Diff-eRank随模型规模增长而提升，与传统指标（如损失值、准确率）呈现显著相关性；在多模态场景中，我们基于eRank提出了对齐度评估方法，验证了当前主流多模态LLMs基于本方法均表现出良好的对齐性能。代码已开源于https://github.com/waltonfuture/Diff-eRank。
