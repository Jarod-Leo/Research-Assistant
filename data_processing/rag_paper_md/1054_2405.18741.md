# Genshin: General Shield for Natural Language Processing with Large Language Models

链接: http://arxiv.org/abs/2405.18741v1

原文摘要:
Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been
trending recently, demonstrating considerable advancement and generalizability
power in countless domains. However, LLMs create an even bigger black box
exacerbating opacity, with interpretability limited to few approaches. The
uncertainty and opacity embedded in LLMs' nature restrict their application in
high-stakes domains like financial fraud, phishing, etc. Current approaches
mainly rely on traditional textual classification with posterior interpretable
algorithms, suffering from attackers who may create versatile adversarial
samples to break the system's defense, forcing users to make trade-offs between
efficiency and robustness. To address this issue, we propose a novel cascading
framework called Genshin (General Shield for Natural Language Processing with
Large Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike
most applications of LLMs that try to transform text into something new or
structural, Genshin uses LLMs to recover text to its original state. Genshin
aims to combine the generalizability of the LLM, the discrimination of the
median model, and the interpretability of the simple model. Our experiments on
the task of sentimental analysis and spam detection have shown fatal flaws of
the current median models and exhilarating results on LLMs' recovery ability,
demonstrating that Genshin is both effective and efficient. In our ablation
study, we unearth several intriguing observations. Utilizing the LLM defender,
a tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal
mask rate results in the 3rd paradigm of NLP. Additionally, when employing the
LLM as a potential adversarial tool, attackers are capable of executing
effective attacks that are nearly semantically lossless.

中文翻译:
近期，以ChatGPT、Gemini和LLaMA为代表的大型语言模型（LLM）成为技术热点，在众多领域展现出卓越的进步与泛化能力。然而这类模型形成了更庞大的黑箱系统，其可解释性仅局限于少数方法，导致模型透明度问题进一步恶化。LLM固有的不确定性与不透明性，限制了其在金融欺诈、网络钓鱼等高风险领域的应用。现有解决方案主要依赖传统文本分类与后置可解释算法，但攻击者可能通过生成多样化对抗样本来突破系统防御，迫使使用者在效率与鲁棒性之间做出妥协。

为解决这一难题，我们提出名为"原神"（Genshin）的新型级联框架，将LLM作为一次性防御插件使用。与大多数试图将文本转化为新形式或结构化数据的LLM应用不同，该框架利用LLM将文本还原至原始状态。Genshin旨在融合LLM的泛化能力、中间模型的判别力以及简单模型的可解释性。我们在情感分析和垃圾邮件检测任务上的实验，既揭示了当前中间模型的致命缺陷，也验证了LLM文本修复能力的惊人效果，证明该框架兼具高效性与有效性。

在消融研究中，我们发现了若干有趣现象：采用第四范式衍生的LLM防御工具时，在NLP第三范式下复现了BERT模型15%最优掩码率的结果；而当将LLM作为潜在对抗工具时，攻击者能实施语义几乎无损的有效攻击。
