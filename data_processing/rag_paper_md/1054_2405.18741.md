# Genshin: General Shield for Natural Language Processing with Large Language Models

链接: http://arxiv.org/abs/2405.18741v1

原文摘要:
Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been
trending recently, demonstrating considerable advancement and generalizability
power in countless domains. However, LLMs create an even bigger black box
exacerbating opacity, with interpretability limited to few approaches. The
uncertainty and opacity embedded in LLMs' nature restrict their application in
high-stakes domains like financial fraud, phishing, etc. Current approaches
mainly rely on traditional textual classification with posterior interpretable
algorithms, suffering from attackers who may create versatile adversarial
samples to break the system's defense, forcing users to make trade-offs between
efficiency and robustness. To address this issue, we propose a novel cascading
framework called Genshin (General Shield for Natural Language Processing with
Large Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike
most applications of LLMs that try to transform text into something new or
structural, Genshin uses LLMs to recover text to its original state. Genshin
aims to combine the generalizability of the LLM, the discrimination of the
median model, and the interpretability of the simple model. Our experiments on
the task of sentimental analysis and spam detection have shown fatal flaws of
the current median models and exhilarating results on LLMs' recovery ability,
demonstrating that Genshin is both effective and efficient. In our ablation
study, we unearth several intriguing observations. Utilizing the LLM defender,
a tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal
mask rate results in the 3rd paradigm of NLP. Additionally, when employing the
LLM as a potential adversarial tool, attackers are capable of executing
effective attacks that are nearly semantically lossless.

中文翻译:
近年来，以ChatGPT、Gemini和LLaMA为代表的大语言模型（LLMs）引发广泛关注，其在众多领域展现出卓越的进步与泛化能力。然而这类模型形成了更庞大的黑箱系统，加剧了模型的不透明性，当前可解释性方法仍十分有限。LLMs与生俱来的不确定性和不透明特性，限制了其在金融欺诈、网络钓鱼等高风险领域的应用。现有解决方案主要依赖传统文本分类与后置可解释算法，但攻击者可能通过生成多样化对抗样本来突破系统防御，迫使使用者在效率与鲁棒性之间做出妥协。

针对这一挑战，我们提出名为"Genshin"（基于大语言模型的自然语言处理通用防御框架）的新型级联框架，将LLMs作为一次性防御插件使用。与大多数将文本转化为新形式或结构化数据的LLM应用不同，Genshin利用LLMs将文本还原至原始状态。该框架旨在融合LLM的泛化能力、中间模型的判别力以及简单模型的可解释性。我们在情感分析和垃圾邮件检测任务中的实验表明：当前中间模型存在致命缺陷，而LLMs的文本还原能力展现出令人振奋的效果，证明Genshin兼具高效性与有效性。

消融研究揭示了若干有趣发现：通过采用源自第四范式的LLM防御器工具，我们在第三范式NLP任务中复现了BERT模型15%最优掩码率的结果；而当将LLM作为潜在对抗工具时，攻击者能实施语义几乎无损的有效攻击。
