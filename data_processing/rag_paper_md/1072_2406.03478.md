# Convolutional Neural Networks and Vision Transformers for Fashion MNIST Classification: A Literature Review

链接: http://arxiv.org/abs/2406.03478v1

原文摘要:
Our review explores the comparative analysis between Convolutional Neural
Networks (CNNs) and Vision Transformers (ViTs) in the domain of image
classification, with a particular focus on clothing classification within the
e-commerce sector. Utilizing the Fashion MNIST dataset, we delve into the
unique attributes of CNNs and ViTs. While CNNs have long been the cornerstone
of image classification, ViTs introduce an innovative self-attention mechanism
enabling nuanced weighting of different input data components. Historically,
transformers have primarily been associated with Natural Language Processing
(NLP) tasks. Through a comprehensive examination of existing literature, our
aim is to unveil the distinctions between ViTs and CNNs in the context of image
classification. Our analysis meticulously scrutinizes state-of-the-art
methodologies employing both architectures, striving to identify the factors
influencing their performance. These factors encompass dataset characteristics,
image dimensions, the number of target classes, hardware infrastructure, and
the specific architectures along with their respective top results. Our key
goal is to determine the most appropriate architecture between ViT and CNN for
classifying images in the Fashion MNIST dataset within the e-commerce industry,
while taking into account specific conditions and needs. We highlight the
importance of combining these two architectures with different forms to enhance
overall performance. By uniting these architectures, we can take advantage of
their unique strengths, which may lead to more precise and reliable models for
e-commerce applications. CNNs are skilled at recognizing local patterns, while
ViTs are effective at grasping overall context, making their combination a
promising strategy for boosting image classification performance.

中文翻译:
本文综述针对图像分类领域中的卷积神经网络（CNN）与视觉变换器（ViT）展开对比分析，尤其聚焦电子商务场景下的服装分类任务。基于Fashion MNIST数据集，我们深入探究了两种架构的特性：CNN长期作为图像分类的基石，而ViT则通过创新的自注意力机制实现对输入数据各部分的差异化加权处理。尽管变换器架构最初主要应用于自然语言处理（NLP）领域，我们通过系统文献研究揭示了其在图像分类任务中与CNN的本质差异。

研究采用严谨的方法论对两种架构的前沿应用方案进行剖析，着力识别影响模型性能的关键因素，包括数据集特征、图像尺寸、目标类别数量、硬件基础设施以及特定架构设计与其对应最优结果。核心目标在于明确电子商务环境下Fashion MNIST数据集图像分类任务中，ViT与CNN架构的最优选择策略，同时兼顾特定应用条件与需求。我们特别强调通过异构架构融合来提升整体性能的重要性——CNN擅长局部模式识别，ViT强调整体上下文理解，二者的优势互补有望构建更精准可靠的电商图像分类模型。这种协同策略为提升分类性能提供了极具前景的研究方向。
