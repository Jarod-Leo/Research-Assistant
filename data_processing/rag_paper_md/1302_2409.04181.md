# Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering

链接: http://arxiv.org/abs/2409.04181v1

原文摘要:
Advancements in natural language processing have revolutionized the way we
can interact with digital information systems, such as databases, making them
more accessible. However, challenges persist, especially when accuracy is
critical, as in the biomedical domain. A key issue is the hallucination
problem, where models generate information unsupported by the underlying data,
potentially leading to dangerous misinformation. This paper presents a novel
approach designed to bridge this gap by combining Large Language Models (LLM)
and Knowledge Graphs (KG) to improve the accuracy and reliability of
question-answering systems, on the example of a biomedical KG. Built on the
LangChain framework, our method incorporates a query checker that ensures the
syntactical and semantic validity of LLM-generated queries, which are then used
to extract information from a Knowledge Graph, substantially reducing errors
like hallucinations. We evaluated the overall performance using a new benchmark
dataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo
and llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other
models in generating accurate queries, open-source models like llama3:70b show
promise with appropriate prompt engineering. To make this approach accessible,
a user-friendly web-based interface has been developed, allowing users to input
natural language queries, view generated and corrected Cypher queries, and
verify the resulting paths for accuracy. Overall, this hybrid approach
effectively addresses common issues such as data gaps and hallucinations,
offering a reliable and intuitive solution for question answering systems. The
source code for generating the results of this paper and for the user-interface
can be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui

中文翻译:
自然语言处理技术的进步彻底改变了我们与数据库等数字信息系统的交互方式，使其更具可访问性。然而在生物医学等对准确性要求极高的领域，挑战依然存在。核心问题在于模型可能生成缺乏底层数据支持的"幻觉信息"，这种错误可能导致危险的误导。本文提出一种创新方法，通过结合大语言模型（LLM）与知识图谱（KG）来提升问答系统的准确性与可靠性，并以生物医学知识图谱为例进行验证。

基于LangChain框架构建的该方法包含一个查询检查器，可确保LLM生成查询的语法和语义有效性。这些经过验证的查询随后用于从知识图谱中提取信息，从而显著减少幻觉等错误。我们使用包含50个生物医学问题的新基准数据集评估系统性能，测试了GPT-4 Turbo和llama3:70b等多种大语言模型。结果表明，虽然GPT-4 Turbo在生成准确查询方面表现最优，但通过适当的提示工程，llama3:70b等开源模型也展现出应用潜力。

为提升可用性，我们开发了基于网页的友好界面，用户可输入自然语言查询，查看生成及修正后的Cypher查询语句，并验证返回路径的准确性。这种混合方法有效解决了数据缺失和幻觉等常见问题，为问答系统提供了可靠且直观的解决方案。本文结果生成代码及用户界面源代码已发布于Git仓库：https://git.zib.de/lpusch/cyphergenkg-gui
