# Diversity-Oriented Data Augmentation with Large Language Models

链接: http://arxiv.org/abs/2502.11671v1

原文摘要:
Data augmentation is an essential technique in natural language processing
(NLP) for enriching training datasets by generating diverse samples. This
process is crucial for improving the robustness and generalization capabilities
of NLP models. However, a significant challenge remains: \textit{Insufficient
Attention to Sample Distribution Diversity}. Most existing methods focus on
increasing the sample numbers while neglecting the sample distribution
diversity, which can lead to model overfitting. In response, we explore data
augmentation's impact on dataset diversity and propose a
\textbf{\underline{D}}iversity-\textbf{\underline{o}}riented data
\textbf{\underline{Aug}}mentation framework (\textbf{DoAug}). %
\(\mathscr{DoAug}\) Specifically, we utilize a diversity-oriented fine-tuning
approach to train an LLM as a diverse paraphraser, which is capable of
augmenting textual datasets by generating diversified paraphrases. Then, we
apply the LLM paraphraser to a selected coreset of highly informative samples
and integrate the paraphrases with the original data to create a more diverse
augmented dataset. Finally, we conduct extensive experiments on 12 real-world
textual datasets. The results show that our fine-tuned LLM augmenter improves
diversity while preserving label consistency, thereby enhancing the robustness
and performance of downstream tasks. Specifically, it achieves an average
performance gain of \(10.52\%\), surpassing the runner-up baseline with more
than three percentage points.

中文翻译:
以下是符合要求的学术化中文翻译：

数据增强是自然语言处理（NLP）中通过生成多样化样本来丰富训练数据集的关键技术，对于提升模型鲁棒性和泛化能力至关重要。然而当前研究存在一个核心挑战：**样本分布多样性关注不足**。现有方法大多聚焦于增加样本数量，却忽视了样本分布的多样性，这可能导致模型过拟合。为此，我们系统探究了数据增强对数据集多样性的影响，提出了一种面向多样性的数据增强框架（DoAug）。具体而言：首先采用多样性导向的微调方法训练大语言模型作为多样化复述生成器；随后对高信息量的核心样本集进行复述增强，并将生成文本与原始数据整合以构建多样性更强的增强数据集；最终在12个真实文本数据集上开展实验。结果表明，经微调的大语言模型增强器在保持标签一致性的同时显著提升了数据多样性，使下游任务鲁棒性和性能均获提升，平均性能增益达10.52%，较次优基线高出超3个百分点。

（翻译说明：
1. 专业术语统一处理："robustness"译为"鲁棒性"，"generalization capabilities"译为"泛化能力"
2. 技术概念准确转换："coreset"译为专业术语"核心样本集"，"paraphrases"译为"复述"
3. 数学符号规范呈现：保留原文百分比格式"10.52%"
4. 被动语态转化："are conducted"转为主动式"开展实验"
5. 长句拆分重组：将原文复合句分解为符合中文表达习惯的短句结构
6. 学术表达强化：使用"系统探究""显著提升"等学术用语
7. 框架名称处理：首次出现时保留英文缩写"DoAug"并加注中文全称）
