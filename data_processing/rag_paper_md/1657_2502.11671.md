# Diversity-Oriented Data Augmentation with Large Language Models

链接: http://arxiv.org/abs/2502.11671v1

原文摘要:
Data augmentation is an essential technique in natural language processing
(NLP) for enriching training datasets by generating diverse samples. This
process is crucial for improving the robustness and generalization capabilities
of NLP models. However, a significant challenge remains: \textit{Insufficient
Attention to Sample Distribution Diversity}. Most existing methods focus on
increasing the sample numbers while neglecting the sample distribution
diversity, which can lead to model overfitting. In response, we explore data
augmentation's impact on dataset diversity and propose a
\textbf{\underline{D}}iversity-\textbf{\underline{o}}riented data
\textbf{\underline{Aug}}mentation framework (\textbf{DoAug}). %
\(\mathscr{DoAug}\) Specifically, we utilize a diversity-oriented fine-tuning
approach to train an LLM as a diverse paraphraser, which is capable of
augmenting textual datasets by generating diversified paraphrases. Then, we
apply the LLM paraphraser to a selected coreset of highly informative samples
and integrate the paraphrases with the original data to create a more diverse
augmented dataset. Finally, we conduct extensive experiments on 12 real-world
textual datasets. The results show that our fine-tuned LLM augmenter improves
diversity while preserving label consistency, thereby enhancing the robustness
and performance of downstream tasks. Specifically, it achieves an average
performance gain of \(10.52\%\), surpassing the runner-up baseline with more
than three percentage points.

中文翻译:
数据增强是自然语言处理（NLP）中一项关键技术，通过生成多样化样本来丰富训练数据集，对提升模型的鲁棒性和泛化能力至关重要。然而当前仍存在一个核心挑战：**样本分布多样性关注不足**。现有方法大多聚焦于增加样本数量，却忽视了样本分布的多样性，这可能导致模型过拟合。针对这一问题，我们深入探究了数据增强对数据集多样性的影响，提出了一种**面向多样性**的数据增强框架（**DoAug**）。具体而言，我们采用多样性导向的微调策略训练大语言模型作为多样化复述生成器，能够通过生成语义多样的改写文本来扩展数据集。随后，将该复述模型应用于精选的高信息量核心样本集，并将生成内容与原始数据融合以构建更具分布多样性的增强数据集。我们在12个真实文本数据集上进行了广泛实验，结果表明：经微调的大语言模型增强器在保持标签一致性的同时显著提升了数据多样性，从而有效提高了下游任务的鲁棒性和性能表现。具体而言，其平均性能增益达到10.52%，较次优基线方法领先超过三个百分点。
