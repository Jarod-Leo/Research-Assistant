# From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning

链接: http://arxiv.org/abs/2401.13229v1

原文摘要:
A major challenge in Natural Language Processing is obtaining annotated data
for supervised learning. An option is the use of crowdsourcing platforms for
data annotation. However, crowdsourcing introduces issues related to the
annotator's experience, consistency, and biases. An alternative is to use
zero-shot methods, which in turn have limitations compared to their few-shot or
fully supervised counterparts. Recent advancements driven by large language
models show potential, but struggle to adapt to specialized domains with
severely limited data. The most common approaches therefore involve the human
itself randomly annotating a set of datapoints to build initial datasets. But
randomly sampling data to be annotated is often inefficient as it ignores the
characteristics of the data and the specific needs of the model. The situation
worsens when working with imbalanced datasets, as random sampling tends to
heavily bias towards the majority classes, leading to excessive annotated data.
To address these issues, this paper contributes an automatic and informed data
selection architecture to build a small dataset for few-shot learning. Our
proposal minimizes the quantity and maximizes diversity of data selected for
human annotation, while improving model performance.

中文翻译:
自然语言处理领域的一大挑战在于获取监督学习所需的标注数据。一种解决方案是利用众包平台进行数据标注，但这种方式会引入标注者经验、一致性和偏见等问题。另一种替代方案是采用零样本学习方法，然而与少样本或全监督方法相比，其性能存在局限。尽管基于大语言模型的最新进展展现出潜力，但在数据极度匮乏的专业领域仍难以适配。目前最常见的做法是人工随机标注数据点以构建初始数据集，但这种随机采样方式往往效率低下——既忽视了数据特性，也无法满足模型的特定需求。当处理类别不平衡数据集时情况更为严峻，随机采样会严重偏向多数类，导致标注数据冗余。针对这些问题，本文提出了一种自动化智能数据选择架构，旨在构建适用于少样本学习的小型数据集。该方案通过最小化人工标注数据量并最大化所选数据的多样性，同时提升模型性能。
