# Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification

链接: http://arxiv.org/abs/2308.09308v1

原文摘要:
Retrieval augmentation, which enhances downstream models by a knowledge
retriever and an external corpus instead of by merely increasing the number of
model parameters, has been successfully applied to many natural language
processing (NLP) tasks such as text classification, question answering and so
on. However, existing methods that separately or asynchronously train the
retriever and downstream model mainly due to the non-differentiability between
the two parts, usually lead to degraded performance compared to end-to-end
joint training. In this paper, we propose Differentiable Retrieval Augmentation
via Generative lANguage modeling(Dragan), to address this problem by a novel
differentiable reformulation. We demonstrate the effectiveness of our proposed
method on a challenging NLP task in e-commerce search, namely query intent
classification. Both the experimental results and ablation study show that the
proposed method significantly and reasonably improves the state-of-the-art
baselines on both offline evaluation and online A/B test.

中文翻译:
检索增强技术通过知识检索器和外部语料库（而非单纯增加模型参数）来提升下游模型性能，已成功应用于文本分类、问答系统等众多自然语言处理（NLP）任务。然而，现有方法因检索器与下游模型之间存在不可微分性，通常采用分离或异步训练方式，这往往导致其性能逊色于端到端联合训练。本文提出基于生成语言建模的可微分检索增强方法（Dragan），通过创新的可微分重构方案解决该问题。我们在电商搜索中的高难度NLP任务——查询意图分类上验证了方法的有效性。实验与消融研究均表明，该方法在线下评估和线上A/B测试中均显著且合理地超越了当前最先进的基线模型。

（翻译说明：
1. 专业术语处理："retrieval augmentation"译为"检索增强技术"，"non-differentiability"译为"不可微分性"，保持学术准确性
2. 长句拆分：将原文复合句按中文表达习惯拆分为多个短句，如第一句拆分为技术原理与应用领域两部分
3. 被动语态转换："has been successfully applied"转为主动式"已成功应用于"
4. 概念显化："downstream models"译为"下游模型"而非直译"下游模型"，符合中文计算机领域术语习惯
5. 技术名称保留：Dragan作为专有方法名保留不译，括号标注英文原名
6. 行业术语适配："e-commerce search"译为"电商搜索"而非"电子商务搜索"，符合国内行业用语习惯
7. 测试术语处理："A/B test"采用国内互联网行业通用译法"A/B测试"）
