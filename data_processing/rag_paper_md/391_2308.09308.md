# Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification

链接: http://arxiv.org/abs/2308.09308v1

原文摘要:
Retrieval augmentation, which enhances downstream models by a knowledge
retriever and an external corpus instead of by merely increasing the number of
model parameters, has been successfully applied to many natural language
processing (NLP) tasks such as text classification, question answering and so
on. However, existing methods that separately or asynchronously train the
retriever and downstream model mainly due to the non-differentiability between
the two parts, usually lead to degraded performance compared to end-to-end
joint training. In this paper, we propose Differentiable Retrieval Augmentation
via Generative lANguage modeling(Dragan), to address this problem by a novel
differentiable reformulation. We demonstrate the effectiveness of our proposed
method on a challenging NLP task in e-commerce search, namely query intent
classification. Both the experimental results and ablation study show that the
proposed method significantly and reasonably improves the state-of-the-art
baselines on both offline evaluation and online A/B test.

中文翻译:
检索增强技术通过引入知识检索器与外部语料库来优化下游模型性能，而非单纯增加模型参数量，已在文本分类、问答系统等自然语言处理任务中取得显著成效。然而现有方法因检索模块与下游模型间存在不可微分性，通常采用分离或异步训练策略，导致其性能往往逊色于端到端联合训练模式。针对这一核心问题，本研究提出基于生成语言模型的可微分检索增强框架（Dragan），通过创新性的可微分重构实现两模块的协同优化。我们在电商搜索场景下的查询意图分类任务（这一具有挑战性的NLP问题）上验证了该方法的有效性。离线实验与在线A/B测试结果表明，所提方案不仅显著超越了当前最优基线模型，且通过消融研究证实了改进效果的合理性与稳定性。
