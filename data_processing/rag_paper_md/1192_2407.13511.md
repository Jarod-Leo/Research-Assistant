# Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks

链接: http://arxiv.org/abs/2407.13511v1

原文摘要:
Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT
and Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)
benchmarks across different domains. New competing Open-Source alternatives
like Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while
often offering higher throughput and being less costly to use. Open-Source LLMs
can also be self-hosted, which makes them interesting for enterprise and
clinical use cases where sensitive data should not be processed by third
parties. We participated in the 12th BioASQ challenge, which is a retrieval
augmented generation (RAG) setting, and explored the performance of current GPT
models Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning
(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional
relevant knowledge from Wikipedia added to the context-window of the LLM might
improve their performance. Mixtral 8x7b was competitive in the 10-shot setting,
both with and without fine-tuning, but failed to produce usable results in the
zero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to
measurable performance gains. Our results indicate that the performance gap
between commercial and open-source models in RAG setups exists mainly in the
zero-shot setting and can be closed by simply collecting few-shot examples for
domain-specific use cases. The code needed to rerun these experiments is
available through GitHub.

中文翻译:
诸如OpenAI驱动ChatGPT的GPT-4和Anthropic的Claude 3 Opus等商用大语言模型（LLM），已在跨领域的自然语言处理（NLP）基准测试中占据主导地位。新兴的开源竞争模型如Mixtral 8x7B或Llama 3正逐步缩小差距，它们通常提供更高的吞吐量且使用成本更低。开源LLM还支持自主托管，这对涉及敏感数据不宜由第三方处理的企业和临床场景尤为重要。我们参与了第十二届BioASQ挑战赛——一个检索增强生成（RAG）任务，测试了当前GPT模型Claude 3 Opus、GPT-3.5-turbo和Mixtral 8x7b在上下文学习（零样本、少样本）及QLoRa微调下的表现，并探究了将维基百科相关知识点注入LLM上下文窗口对性能的影响。Mixtral 8x7b在10样本设置中（无论是否微调）表现优异，但在零样本场景下未能生成可用结果。QLoRa微调和维基百科上下文均未带来显著性能提升。研究表明：商业与开源模型在RAG中的性能差异主要存在于零样本场景，而通过收集领域特定的少样本示例即可弥合这一差距。实验复现代码已发布于GitHub平台。
