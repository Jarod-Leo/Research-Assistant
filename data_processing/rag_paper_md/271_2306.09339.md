# From BERT to GPT-3 Codex: Harnessing the Potential of Very Large Language Models for Data Management

链接: http://arxiv.org/abs/2306.09339v1

原文摘要:
Large language models have recently advanced the state of the art on many
natural language processing benchmarks. The newest generation of models can be
applied to a variety of tasks with little to no specialized training. This
technology creates various opportunities for applications in the context of
data management.
  The tutorial will introduce participants to basic background on language
models, discuss different methods to use language models, and give an overview
and short demonstration of available libraries and APIs. Models for generating
natural language will be considered as well as models, such as GPT-3 Codex,
which complete program code or generate code from natural language
instructions. Finally, the tutorial will discuss recent research in the
database community that exploits language models in the context of traditional
database systems or proposes novel system architectures that are based on them.
  The tutorial is targeted at database researchers. No prior background on
language models is required. The goal of the tutorial is to introduce database
researchers to the latest generation of language models, and to their use cases
in the domain of data management.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型近期在多类自然语言处理基准测试中取得了突破性进展。新一代模型只需极少专项训练即可适配多种任务，这项技术为数据管理领域的应用创造了诸多可能性。

本专题教程将首先介绍语言模型的基础背景知识，继而探讨不同模型应用方法，并对现有程序库与API进行概览性说明及简短演示。内容既涵盖自然语言生成模型，也将涉及诸如GPT-3 Codex等能够补全编程代码或根据自然语言指令生成代码的专项模型。最后，教程将重点讨论数据库学界的最新研究成果：包括传统数据库系统中语言模型的创新应用，以及基于此类模型构建的新型系统架构。

本教程主要面向数据库领域研究人员，不要求参与者具备语言模型相关背景知识。其目的在于帮助数据库研究者了解最前沿的语言模型技术及其在数据管理领域的具体应用场景。

（翻译说明：
1. 专业术语处理：采用"基准测试"对应benchmarks，"程序库"对应libraries，"系统架构"对应system architectures等标准译法
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如第一段技术说明部分
3. 被动语态转换：将"can be applied"等被动结构转为"即可适配"主动句式
4. 学术风格保持：使用"探讨""涵盖""涉及"等正式学术用语，避免口语化表达
5. 逻辑衔接处理：通过"继而""既涵盖...也将涉及""包括...以及"等连接词保持论证逻辑清晰）
