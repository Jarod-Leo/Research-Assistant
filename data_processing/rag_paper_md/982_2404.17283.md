# Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM

链接: http://arxiv.org/abs/2404.17283v1

原文摘要:
Retrieval-augmented language models have exhibited promising performance
across various areas of natural language processing (NLP), including
fact-critical tasks. However, due to the black-box nature of advanced large
language models (LLMs) and the non-retrieval-oriented supervision signal of
specific tasks, the training of retrieval model faces significant challenges
under the setting of black-box LLM. We propose an approach leveraging
Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance
fact-checking on news claims by using black-box LLM. FFRR adopts a two-level
strategy to gather fine-grained feedback from the LLM, which serves as a reward
for optimizing the retrieval policy, by rating the retrieved documents based on
the non-retrieval ground truth of the task. We evaluate our model on two public
datasets for real-world news claim verification, and the results demonstrate
that FFRR achieves significant improvements over strong LLM-enabled and non-LLM
baselines.

中文翻译:
以下是符合要求的学术化中文翻译：

检索增强型语言模型在自然语言处理（NLP）多个领域（包括事实敏感性任务）中展现出卓越性能。然而，由于先进大语言模型（LLM）的黑箱特性与特定任务非检索导向的监督信号，检索模型在黑箱LLM框架下的训练面临重大挑战。本研究提出一种基于细粒度反馈强化检索（FFRR）的方法，通过利用黑箱LLM来增强新闻声明的事实核查能力。FFRR采用双层策略：首先依据任务的非检索真实标签对检索文档进行评分，进而从LLM获取细粒度反馈作为优化检索策略的奖励信号。我们在两个真实新闻声明验证的公开数据集上进行评估，实验结果表明FFRR相较基于LLM和非LLM的强基线模型均取得显著性能提升。

（翻译说明：
1. 专业术语统一处理："black-box"译为"黑箱"，"ground truth"译为"真实标签"
2. 被动语态转化："have exhibited"译为"展现出"符合中文主动表达习惯
3. 长句拆分：将原文复合句分解为符合中文阅读习惯的短句结构
4. 概念显化："two-level strategy"译为"双层策略"并补充说明性文字
5. 学术规范：保留"FFRR"等专业缩写，首次出现标注全称
6. 数据呈现："significant improvements"译为"显著性能提升"体现量化结果）
