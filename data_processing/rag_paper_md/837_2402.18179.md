# Challenges in Pre-Training Graph Neural Networks for Context-Based Fake News Detection: An Evaluation of Current Strategies and Resource Limitations

链接: http://arxiv.org/abs/2402.18179v1

原文摘要:
Pre-training of neural networks has recently revolutionized the field of
Natural Language Processing (NLP) and has before demonstrated its effectiveness
in computer vision. At the same time, advances around the detection of fake
news were mainly driven by the context-based paradigm, where different types of
signals (e.g. from social media) form graph-like structures that hold
contextual information apart from the news article to classify. We propose to
merge these two developments by applying pre-training of Graph Neural Networks
(GNNs) in the domain of context-based fake news detection. Our experiments
provide an evaluation of different pre-training strategies for graph-based
misinformation detection and demonstrate that transfer learning does currently
not lead to significant improvements over training a model from scratch in the
domain. We argue that a major current issue is the lack of suitable large-scale
resources that can be used for pre-training.

中文翻译:
神经网络预训练技术近期彻底革新了自然语言处理领域，此前在计算机视觉中也已展现显著成效。与此同时，虚假新闻检测的进展主要依托于基于上下文的范式——通过整合社交媒体等多源信号构建图结构，这些结构除待分类新闻外还蕴含丰富的上下文信息。本研究将这两种趋势相融合，首次将图神经网络预训练应用于基于上下文的虚假新闻检测领域。实验系统评估了多种图结构误导信息检测的预训练策略，结果表明当前在该领域，迁移学习相比从头训练模型尚未带来显著性能提升。我们指出，当前核心瓶颈在于缺乏适用于预训练的大规模高质量数据集。
