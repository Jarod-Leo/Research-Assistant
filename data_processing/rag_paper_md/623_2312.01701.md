# Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites

链接: http://arxiv.org/abs/2312.01701v1

原文摘要:
Large language models (LLMs) have shown remarkable performance in natural
language processing (NLP) tasks. To comprehend and execute diverse human
instructions over image data, instruction-tuned large vision-language models
(LVLMs) have been introduced. However, LVLMs may suffer from different types of
object hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained
object hallucinations only (i.e., generated objects non-existent in the input
image). The fine-grained object attributes and behaviors non-existent in the
image may still be generated but not measured by the current evaluation
methods. In this paper, we thus focus on reducing fine-grained hallucinations
of LVLMs. We propose \textit{ReCaption}, a framework that consists of two
components: rewriting captions using ChatGPT and fine-tuning the
instruction-tuned LVLMs on the rewritten captions. We also propose a
fine-grained probing-based evaluation method named \textit{Fine-Grained Object
Hallucination Evaluation} (\textit{FGHE}). Our experiment results demonstrate
that ReCaption effectively reduces fine-grained object hallucination for
different LVLM options and improves their text generation quality. The code can
be found at https://github.com/Anonymousanoy/FOHE.

中文翻译:
大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出卓越性能。为理解并执行针对图像数据的多样化人类指令，指令调优的大型视觉语言模型（LVLMs）应运而生。然而，LVLMs可能面临不同类型的物体幻觉问题。现有评估仅针对粗粒度物体幻觉（即生成输入图像中不存在的物体），而图像中未出现的细粒度物体属性与行为仍可能被生成，却未被当前评估方法检测。本文聚焦于减少LVLMs的细粒度幻觉现象，提出\textit{ReCaption}框架，该框架包含两个核心组件：利用ChatGPT重写图像描述，并在改写后的描述数据上对指令调优的LVLMs进行微调。同时，我们提出基于细粒度探测的评估方法\textit{细粒度物体幻觉评估}（\textit{FGHE}）。实验结果表明，ReCaption能有效降低不同LVLMs的细粒度物体幻觉，并提升其文本生成质量。代码详见https://github.com/Anonymousanoy/FOHE。
