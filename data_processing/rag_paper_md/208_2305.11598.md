# Introspective Tips: Large Language Model for In-Context Decision Making

链接: http://arxiv.org/abs/2305.11598v1

原文摘要:
The emergence of large language models (LLMs) has substantially influenced
natural language processing, demonstrating exceptional results across various
tasks. In this study, we employ ``Introspective Tips" to facilitate LLMs in
self-optimizing their decision-making. By introspectively examining
trajectories, LLM refines its policy by generating succinct and valuable tips.
Our method enhances the agent's performance in both few-shot and zero-shot
learning situations by considering three essential scenarios: learning from the
agent's past experiences, integrating expert demonstrations, and generalizing
across diverse games. Importantly, we accomplish these improvements without
fine-tuning the LLM parameters; rather, we adjust the prompt to generalize
insights from the three aforementioned situations. Our framework not only
supports but also emphasizes the advantage of employing LLM in in-contxt
decision-making. Experiments involving over 100 games in TextWorld illustrate
the superior performance of our approach.

中文翻译:
大型语言模型（LLMs）的出现深刻影响了自然语言处理领域，其在多项任务中展现出卓越性能。本研究采用"自省提示"方法，促使LLM通过自我优化提升决策能力。模型通过内省式轨迹分析，生成简洁高效的行动建议以优化策略。该方法在少样本与零样本学习场景中均能提升智能体表现，涵盖三大核心情境：从智能体历史经验中学习、融合专家示范数据，以及跨游戏泛化能力。值得注意的是，这些改进无需微调LLM参数，仅需通过调整提示模板来整合上述三种情境的认知。我们的框架不仅验证了LLM在上下文决策中的适用性，更突显其独特优势。在TextWorld平台超过100款游戏上的实验表明，该方法具有显著性能优势。
