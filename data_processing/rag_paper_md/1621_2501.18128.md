# Unraveling the Capabilities of Language Models in News Summarization

链接: http://arxiv.org/abs/2501.18128v1

原文摘要:
Given the recent introduction of multiple language models and the ongoing
demand for improved Natural Language Processing tasks, particularly
summarization, this work provides a comprehensive benchmarking of 20 recent
language models, focusing on smaller ones for the news summarization task. In
this work, we systematically test the capabilities and effectiveness of these
models in summarizing news article texts which are written in different styles
and presented in three distinct datasets. Specifically, we focus in this study
on zero-shot and few-shot learning settings and we apply a robust evaluation
methodology that combines different evaluation concepts including automatic
metrics, human evaluation, and LLM-as-a-judge. Interestingly, including
demonstration examples in the few-shot learning setting did not enhance models'
performance and, in some cases, even led to worse quality of the generated
summaries. This issue arises mainly due to the poor quality of the gold
summaries that have been used as reference summaries, which negatively impacts
the models' performance. Furthermore, our study's results highlight the
exceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate
due to their advanced capabilities. However, among the public models evaluated,
certain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B
and Zephyr-7B-Beta demonstrated promising results. These models showed
significant potential, positioning them as competitive alternatives to large
models for the task of news summarization.

中文翻译:
鉴于近期多款语言模型的相继推出，以及自然语言处理任务（尤其是文本摘要）持续增长的性能优化需求，本研究针对新闻摘要任务，对20个最新语言模型（侧重中小规模模型）展开了系统性基准测试。我们通过三个不同风格的新闻数据集，系统评估了这些模型在零样本和小样本学习场景下的摘要生成能力，并采用融合自动指标、人工评估和"大模型即评判者"的鲁棒性评估框架。研究发现：小样本学习中加入示例样本不仅未能提升模型表现，某些情况下甚至导致摘要质量下降——这主要源于被用作参考摘要的黄金标准本身质量欠佳，从而对模型性能产生负面影响。值得注意的是，GPT-3.5-Turbo和GPT-4凭借其先进能力展现出绝对优势，而在开源模型中，Qwen1.5-7B、SOLAR-10.7B-Instruct-v1.0、Meta-Llama-3-8B和Zephyr-7B-Beta等模型表现突出，展现出与大型模型竞争的潜力，成为新闻摘要任务的可行替代方案。
