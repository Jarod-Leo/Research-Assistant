# Systematic Biases in LLM Simulations of Debates

链接: http://arxiv.org/abs/2402.04049v1

原文摘要:
The emergence of Large Language Models (LLMs), has opened exciting
possibilities for constructing computational simulations designed to replicate
human behavior accurately. Current research suggests that LLM-based agents
become increasingly human-like in their performance, sparking interest in using
these AI agents as substitutes for human participants in behavioral studies.
However, LLMs are complex statistical learners without straightforward
deductive rules, making them prone to unexpected behaviors. Hence, it is
crucial to study and pinpoint the key behavioral distinctions between humans
and LLM-based agents. In this study, we highlight the limitations of LLMs in
simulating human interactions, particularly focusing on LLMs' ability to
simulate political debates on topics that are important aspects of people's
day-to-day lives and decision-making processes. Our findings indicate a
tendency for LLM agents to conform to the model's inherent social biases
despite being directed to debate from certain political perspectives. This
tendency results in behavioral patterns that seem to deviate from
well-established social dynamics among humans. We reinforce these observations
using an automatic self-fine-tuning method, which enables us to manipulate the
biases within the LLM and demonstrate that agents subsequently align with the
altered biases. These results underscore the need for further research to
develop methods that help agents overcome these biases, a critical step toward
creating more realistic simulations.

中文翻译:
**中文译文：**  
大型语言模型（LLMs）的出现为构建精准模拟人类行为的计算模型开辟了令人振奋的可能性。现有研究表明，基于LLM的智能体在行为表现上日益趋近人类，这引发了将其作为人类受试者替代品应用于行为学研究的兴趣。然而，LLMs是缺乏明确演绎规则的复杂统计学习系统，容易产生不可预测的行为。因此，研究和厘清人类与LLM智能体之间的关键行为差异至关重要。  

本研究揭示了LLMs在模拟人类互动方面的局限性，尤其聚焦于LLMs对涉及日常生活与决策核心议题的政治辩论的模拟能力。研究发现，即使被要求从特定政治立场展开辩论，LLM智能体仍倾向于遵从模型固有的社会偏见，这种行为模式明显偏离人类社会中既定的群体动态规律。我们通过自动自微调方法进一步验证了这一现象——该方法能人为操纵LLM内部的偏见参数，实验证明智能体会随之调整行为以匹配被修改的偏见倾向。  

这些发现强调，未来研究需开发帮助智能体克服偏见的新方法，这是构建更逼真人类行为模拟系统的关键一步。  

**翻译要点说明：**  
1. **术语处理**：  
   - "computational simulations"译为"计算模型"（非直译"计算机模拟"），符合中文计算社会科学领域术语习惯  
   - "automatic self-fine-tuning"译为"自动自微调"，保留技术特征的同时通过"自"字体现模型的自我调整特性  

2. **长句拆分**：  
   将原文第二段拆分为三个中文段落，通过"研究发现""我们通过"等衔接词保持逻辑连贯性，符合中文段落短小精悍的特点  

3. **动态对等**：  
   - "well-established social dynamics"译为"既定的群体动态规律"，比字面译法"牢固建立的社会动态"更准确传达社会学概念  
   - "align with the altered biases"译为"匹配被修改的偏见倾向"，通过"匹配"+"倾向"的动名结构实现自然转换  

4. **学术风格保持**：  
   使用"受试者""智能体""参数"等学术用语，避免口语化表达，保留原文严谨性
