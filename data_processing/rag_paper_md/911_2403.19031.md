# Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data

链接: http://arxiv.org/abs/2403.19031v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable success in NLP
tasks. However, there is a paucity of studies that attempt to evaluate their
performances on social media-based health-related natural language processing
tasks, which have traditionally been difficult to achieve high scores in. We
benchmarked one supervised classic machine learning model based on Support
Vector Machines (SVMs), three supervised pretrained language models (PLMs)
based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5
and GPT4), across 6 text classification tasks. We developed three approaches
for leveraging LLMs for text classification: employing LLMs as zero-shot
classifiers, us-ing LLMs as annotators to annotate training data for supervised
classifiers, and utilizing LLMs with few-shot examples for augmentation of
manually annotated data. Our comprehensive experiments demonstrate that
employ-ing data augmentation using LLMs (GPT-4) with relatively small
human-annotated data to train lightweight supervised classification models
achieves superior results compared to training with human-annotated data alone.
Supervised learners also outperform GPT-4 and GPT-3.5 in zero-shot settings. By
leveraging this data augmentation strategy, we can harness the power of LLMs to
develop smaller, more effective domain-specific NLP models. LLM-annotated data
without human guidance for training light-weight supervised classification
models is an ineffective strategy. However, LLM, as a zero-shot classifier,
shows promise in excluding false negatives and potentially reducing the human
effort required for data annotation. Future investigations are imperative to
explore optimal training data sizes and the optimal amounts of augmented data.

中文翻译:
大型语言模型（LLMs）在自然语言处理任务中展现出卓越成效，然而针对社交媒体健康相关文本分类任务（传统上难以取得高分）的性能评估研究仍较为匮乏。本研究系统评估了六种文本分类任务中以下模型的性能：基于支持向量机（SVM）的经典监督机器学习模型、三种基于RoBERTa/BERTweet/SocBERT的预训练语言模型（PLMs），以及GPT-3.5和GPT-4两种LLM分类器。我们开发了三种LLM应用策略：零样本分类器模式、通过LLM标注训练数据的监督模式，以及结合少量人工标注样本的数据增强模式。实验结果表明：相较于纯人工标注数据训练，采用GPT-4进行数据增强（配合少量人工标注）来训练轻量级监督模型能获得更优性能；在零样本场景下，监督学习模型表现优于GPT-4和GPT-3.5。这种数据增强策略可有效利用LLMs能力开发更精简高效的领域专用NLP模型。研究同时发现：无人工指导的LLM标注数据训练轻量模型效果欠佳，但作为零样本分类器时，LLM在排除假阴性样本方面表现突出，有望降低人工标注成本。未来研究需重点探索最优训练数据规模与增强数据量的配比关系。
