# Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models

链接: http://arxiv.org/abs/2405.14490v1

原文摘要:
The advancement of large language models has significantly improved natural
language processing. However, challenges such as jailbreaks (prompt injections
that cause an LLM to follow instructions contrary to its intended use),
hallucinations (generating incorrect or misleading information), and
comprehension errors remain prevalent. In this report, we present a comparative
analysis of the performance of fifteen distinct models, with each model
undergoing a standardized test comprising 38 queries across three key metrics:
jailbreaks, hallucinations, and comprehension errors. The models are assessed
based on the total occurrences of jailbreaks, hallucinations, and comprehension
errors. Our work exposes these models' inherent vulnerabilities and challenges
the notion of human-level language comprehension of these models. We have
empirically analysed the impact of non-standard Unicode characters on LLMs and
their safeguarding mechanisms on the best-performing LLMs, including GPT-4,
Gemini 1.5 Pro, LlaMA-3-70B, and Claude 3 Opus. By incorporating alphanumeric
symbols from Unicode outside the standard Latin block and variants of
characters in other languages, we observed a reduction in the efficacy of
guardrails implemented through Reinforcement Learning Human Feedback (RLHF).
Consequently, these models exhibit heightened vulnerability to content policy
breaches and prompt leakage. Our study also suggests a need to incorporate
non-standard Unicode text in LLM training data to enhance the capabilities of
these models.

中文翻译:
大型语言模型的进步显著提升了自然语言处理能力，然而越狱攻击（诱导模型执行违背设计初衷的指令）、幻觉（生成错误或误导性信息）和理解错误等问题依然普遍存在。本报告对15个不同模型进行了性能对比分析，每个模型均接受包含38个查询的标准化测试，评估指标聚焦越狱攻击、幻觉和理解错误三个关键维度。我们通过统计各类违规现象的总发生次数，揭示了这些模型固有的脆弱性，并对"模型已达到人类水平语言理解能力"的论断提出质疑。

针对表现最优的GPT-4、Gemini 1.5 Pro、LlaMA-3-70B和Claude 3 Opus等模型，我们实证研究了非标准Unicode字符对其安全防护机制的影响。通过引入标准拉丁字符集外的字母数字符号及其他语言的字符变体，发现基于人类反馈强化学习（RLHF）构建的防护栏效果明显减弱，导致模型更容易违反内容政策并泄露提示信息。本研究还表明，在训练数据中纳入非标准Unicode文本将有助于增强模型的能力。
