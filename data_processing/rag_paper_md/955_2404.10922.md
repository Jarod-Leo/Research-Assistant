# Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training

链接: http://arxiv.org/abs/2404.10922v1

原文摘要:
Recent advancements in language modeling have led to the emergence of Large
Language Models (LLMs) capable of various natural language processing tasks.
Despite their success in text-based tasks, applying LLMs to the speech domain
remains limited and challenging. This paper presents BLOOMZMMS, a novel model
that integrates a multilingual LLM with a multilingual speech encoder, aiming
to harness the capabilities of LLMs for speech recognition and beyond.
Utilizing a multi-instructional training approach, we demonstrate the
transferability of linguistic knowledge from the text to the speech modality.
Our experiments, conducted on 1900 hours of transcribed data from 139
languages, establish that a multilingual speech representation can be
effectively learned and aligned with a multilingual LLM. While this learned
representation initially shows limitations in task generalization, we address
this issue by generating synthetic targets in a multi-instructional style. Our
zero-shot evaluation results confirm the robustness of our approach across
multiple tasks, including speech translation and multilingual spoken language
understanding, thereby opening new avenues for applying LLMs in the speech
domain.

中文翻译:
语言建模领域的最新进展催生了能够执行多种自然语言处理任务的大型语言模型（LLMs）。尽管这些模型在文本任务中表现卓越，但其在语音领域的应用仍存在局限与挑战。本文提出BLOOMZMMS模型，通过将多语言LLM与多语言语音编码器相融合，旨在释放LLMs在语音识别等领域的潜力。采用多指令训练方法，我们验证了语言知识从文本模态到语音模态的可迁移性。基于139种语言、1900小时转录数据的实验表明，多语言语音表征能够被有效学习并与多语言LLM对齐。虽然该学习表征在任务泛化性上初显局限，我们通过生成多指令风格的合成目标成功解决了这一问题。零样本评估结果证实了该方法在语音翻译、多语言口语理解等任务中的鲁棒性，从而为LLMs在语音领域的应用开辟了新途径。
