# Large Language Models as Evaluators for Recommendation Explanations

链接: http://arxiv.org/abs/2406.03248v1

原文摘要:
The explainability of recommender systems has attracted significant attention
in academia and industry. Many efforts have been made for explainable
recommendations, yet evaluating the quality of the explanations remains a
challenging and unresolved issue. In recent years, leveraging LLMs as
evaluators presents a promising avenue in Natural Language Processing tasks
(e.g., sentiment classification, information extraction), as they perform
strong capabilities in instruction following and common-sense reasoning.
However, evaluating recommendation explanatory texts is different from these
NLG tasks, as its criteria are related to human perceptions and are usually
subjective. In this paper, we investigate whether LLMs can serve as evaluators
of recommendation explanations. To answer the question, we utilize real user
feedback on explanations given from previous work and additionally collect
third-party annotations and LLM evaluations. We design and apply a 3-level meta
evaluation strategy to measure the correlation between evaluator labels and the
ground truth provided by users. Our experiments reveal that LLMs, such as GPT4,
can provide comparable evaluations with appropriate prompts and settings. We
also provide further insights into combining human labels with the LLM
evaluation process and utilizing ensembles of multiple heterogeneous LLM
evaluators to enhance the accuracy and stability of evaluations. Our study
verifies that utilizing LLMs as evaluators can be an accurate, reproducible and
cost-effective solution for evaluating recommendation explanation texts. Our
code is available at https://github.com/Xiaoyu-SZ/LLMasEvaluator.

中文翻译:
推荐系统的可解释性在学术界和工业界引起了广泛关注。尽管已投入大量努力开发可解释推荐，但如何评估解释质量仍是一个悬而未决的难题。近年来，利用大语言模型（LLMs）作为评估工具在自然语言处理任务（如情感分类、信息抽取）中展现出巨大潜力，因其具备出色的指令遵循和常识推理能力。然而，推荐解释文本的评估与这些自然语言生成任务存在本质差异，其评判标准涉及人类主观感知且具有高度主观性。本文系统探究了LLMs能否胜任推荐解释评估工作。为此，我们整合了既有研究中用户对解释文本的真实反馈数据，并额外收集了第三方人工标注与LLM评估结果。通过设计并实施三级元评估策略，我们量化了不同评估者标签与用户真实反馈之间的相关性。实验表明，在恰当的提示词和参数设置下，GPT-4等LLMs能提供与人类相当的评估质量。我们还深入探讨了如何将人工标注融入LLM评估流程，以及通过异构LLM评估者集成来提升评估的准确性和稳定性。本研究证实，LLMs作为评估工具能够为推荐解释文本提供准确、可复现且经济高效的评估方案。代码已开源：https://github.com/Xiaoyu-SZ/LLMasEvaluator。
