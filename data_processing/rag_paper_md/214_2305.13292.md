# VideoLLM: Modeling Video Sequence with Large Language Models

链接: http://arxiv.org/abs/2305.13292v1

原文摘要:
With the exponential growth of video data, there is an urgent need for
automated technology to analyze and comprehend video content. However, existing
video understanding models are often task-specific and lack a comprehensive
capability of handling diverse tasks. The success of large language models
(LLMs) like GPT has demonstrated their impressive abilities in sequence causal
reasoning. Building upon this insight, we propose a novel framework called
VideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs
from natural language processing (NLP) for video sequence understanding.
VideoLLM incorporates a carefully designed Modality Encoder and Semantic
Translator, which convert inputs from various modalities into a unified token
sequence. This token sequence is then fed into a decoder-only LLM.
Subsequently, with the aid of a simple task head, our VideoLLM yields an
effective unified framework for different kinds of video understanding tasks.
To evaluate the efficacy of VideoLLM, we conduct extensive experiments using
multiple LLMs and fine-tuning methods. We evaluate our VideoLLM on eight tasks
sourced from four different datasets. The experimental results demonstrate that
the understanding and reasoning capabilities of LLMs can be effectively
transferred to video understanding tasks. We release the code at
https://github.com/cg1177/VideoLLM.

中文翻译:
随着视频数据的爆炸式增长，亟需自动化技术来分析与理解视频内容。然而现有视频理解模型通常仅针对特定任务，缺乏处理多样化任务的综合能力。以GPT为代表的大语言模型（LLMs）的成功，展现了其在序列因果推理方面的卓越能力。基于这一洞见，我们提出名为VideoLLM的创新框架，通过利用预训练自然语言处理（NLP）大语言模型的序列推理能力来实现视频序列理解。VideoLLM包含精心设计的模态编码器与语义转换器，将来自不同模态的输入转化为统一标记序列，随后输入至仅解码器架构的大语言模型。借助简单的任务头模块，我们的VideoLLM构建出适用于各类视频理解任务的有效统一框架。为验证VideoLLM的效能，我们采用多种大语言模型与微调方法进行了广泛实验，在源自四个不同数据集的八项任务上开展评估。实验结果表明，大语言模型的理解与推理能力可有效迁移至视频理解任务。代码已发布于https://github.com/cg1177/VideoLLM。
