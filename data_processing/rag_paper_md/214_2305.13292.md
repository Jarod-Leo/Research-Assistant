# VideoLLM: Modeling Video Sequence with Large Language Models

链接: http://arxiv.org/abs/2305.13292v1

原文摘要:
With the exponential growth of video data, there is an urgent need for
automated technology to analyze and comprehend video content. However, existing
video understanding models are often task-specific and lack a comprehensive
capability of handling diverse tasks. The success of large language models
(LLMs) like GPT has demonstrated their impressive abilities in sequence causal
reasoning. Building upon this insight, we propose a novel framework called
VideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs
from natural language processing (NLP) for video sequence understanding.
VideoLLM incorporates a carefully designed Modality Encoder and Semantic
Translator, which convert inputs from various modalities into a unified token
sequence. This token sequence is then fed into a decoder-only LLM.
Subsequently, with the aid of a simple task head, our VideoLLM yields an
effective unified framework for different kinds of video understanding tasks.
To evaluate the efficacy of VideoLLM, we conduct extensive experiments using
multiple LLMs and fine-tuning methods. We evaluate our VideoLLM on eight tasks
sourced from four different datasets. The experimental results demonstrate that
the understanding and reasoning capabilities of LLMs can be effectively
transferred to video understanding tasks. We release the code at
https://github.com/cg1177/VideoLLM.

中文翻译:
随着视频数据的指数级增长，对视频内容进行自动化分析与理解的技术需求日益迫切。然而现有视频理解模型通常仅针对特定任务，缺乏处理多样化任务的综合能力。以GPT为代表的大语言模型（LLMs）的成功实践，展现了其在序列因果推理方面的卓越能力。基于这一洞见，我们提出名为VideoLLM的创新框架，通过复用自然语言处理（NLP）领域预训练LLMs的序列推理能力来实现视频序列理解。VideoLLM包含精心设计的模态编码器（Modality Encoder）与语义转换器（Semantic Translator），可将多模态输入转化为统一的令牌序列，随后输入至仅含解码器的LLM架构。配合简单的任务头模块，我们的VideoLLM构建出适用于多种视频理解任务的统一框架。为验证有效性，我们采用多种LLMs与微调方法进行广泛实验，在来自四个不同数据集的八项任务上评估VideoLLM。实验结果表明，LLMs的理解与推理能力可有效迁移至视频理解任务。项目代码已发布于https://github.com/cg1177/VideoLLM。

（翻译说明：1. 专业术语如"Modality Encoder"保留英文并补充中文译名；2. 长句按中文习惯拆分为短句；3. "decoder-only LLM"译为技术社区通用表述"仅含解码器的LLM架构"；4. 被动语态转换为主动表述；5. 保持学术论文的严谨风格，避免口语化表达）
