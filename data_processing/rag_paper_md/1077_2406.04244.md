# Benchmark Data Contamination of Large Language Models: A Survey

链接: http://arxiv.org/abs/2406.04244v1

原文摘要:
The rapid development of Large Language Models (LLMs) like GPT-4, Claude-3,
and Gemini has transformed the field of natural language processing. However,
it has also resulted in a significant issue known as Benchmark Data
Contamination (BDC). This occurs when language models inadvertently incorporate
evaluation benchmark information from their training data, leading to
inaccurate or unreliable performance during the evaluation phase of the
process. This paper reviews the complex challenge of BDC in LLM evaluation and
explores alternative assessment methods to mitigate the risks associated with
traditional benchmarks. The paper also examines challenges and future
directions in mitigating BDC risks, highlighting the complexity of the issue
and the need for innovative solutions to ensure the reliability of LLM
evaluation in real-world applications.

中文翻译:
以GPT-4、Claude-3和Gemini为代表的大语言模型（LLM）的快速发展，正在深刻改变自然语言处理领域。然而这也带来了一个严峻问题——基准数据污染（BDC），即语言模型在训练过程中无意吸纳了评估基准信息，导致模型在评估阶段出现性能失真。本文系统梳理了LLM评估中BDC这一复杂挑战，探讨了替代传统基准的评估范式，分析了当前缓解BDC风险的应对策略与发展趋势。研究表明，该问题具有高度复杂性，需要创新性解决方案来确保LLM在实际应用中的评估可靠性。
