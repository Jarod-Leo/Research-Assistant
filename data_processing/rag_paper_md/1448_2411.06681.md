# WDMoE: Wireless Distributed Mixture of Experts for Large Language Models

链接: http://arxiv.org/abs/2411.06681v1

原文摘要:
Large Language Models (LLMs) have achieved significant success in various
natural language processing tasks, but the role of wireless networks in
supporting LLMs has not been thoroughly explored. In this paper, we propose a
wireless distributed Mixture of Experts (WDMoE) architecture to enable
collaborative deployment of LLMs across edge servers at the base station (BS)
and mobile devices in wireless networks. Specifically, we decompose the MoE
layer in LLMs by placing the gating network and the preceding neural network
layer at BS, while distributing the expert networks among the devices. This
deployment leverages the parallel inference capabilities of expert networks on
mobile devices, effectively utilizing the limited computing and caching
resources of these devices. Accordingly, we develop a performance metric for
WDMoE-based LLMs, which accounts for both model capability and latency. To
minimize the latency while maintaining accuracy, we jointly optimize expert
selection and bandwidth allocation based on the performance metric. Moreover,
we build a hardware testbed using NVIDIA Jetson kits to validate the
effectiveness of WDMoE. Both theoretical simulations and practical hardware
experiments demonstrate that the proposed method can significantly reduce the
latency without compromising LLM performance.

中文翻译:
以下是符合要求的学术中文翻译：

大型语言模型（LLMs）在各类自然语言处理任务中取得了显著成功，但无线网络在支持LLMs中的作用尚未得到充分探索。本文提出一种无线分布式专家混合（WDMoE）架构，实现LLMs在基站（BS）边缘服务器与移动设备间的协同部署。具体而言，我们通过将MoE层中的门控网络及前置神经网络层部署于基站，同时将专家网络分布式部署于终端设备，从而解构LLMs中的MoE层。该部署方案充分利用移动设备上专家网络的并行推理能力，有效整合终端有限的计算与缓存资源。据此，我们建立了基于WDMoE的LLMs性能评估指标，该指标同时考量模型能力与延迟。为在保证精度的前提下最小化延迟，我们基于该指标联合优化专家选择与带宽分配。此外，我们采用NVIDIA Jetson套件搭建硬件测试平台以验证WDMoE的有效性。理论仿真与实际硬件实验均表明，所提方法能在保持LLM性能的同时显著降低延迟。

翻译说明：
1. 专业术语处理：采用"专家混合"（MoE）、"基站"（BS）等标准译法，首次出现标注英文缩写
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"decompose the MoE layer..."译为解构性说明
3. 被动语态转换：将"are distributed"等被动式转为主动语态（"分布式部署"）
4. 学术规范：使用"所提方法""显著降低"等学术用语，保持客观严谨
5. 技术概念准确性：精确处理"gating network"（门控网络）、"parallel inference"（并行推理）等专业表述
6. 逻辑显化：通过"据此""具体而言"等连接词强化论证逻辑链条
