# SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation

链接: http://arxiv.org/abs/2401.17005v1

原文摘要:
Text generation is a compelling sub-field of natural language processing,
aiming to generate human-readable text from input words. In particular, the
decoder-only generative models, such as generative pre-trained transformer
(GPT), are widely used for text generation, with two major computational
stages: summarization and generation. Unlike the summarization stage, which can
process the input tokens in parallel, the generation stage is difficult to
accelerate due to its sequential generation of output tokens through iteration.
Moreover, each iteration requires reading a whole model with little data reuse
opportunity. Therefore, the workload of transformer-based text generation is
severely memory-bound, making the external memory bandwidth system bottleneck.
In this paper, we proposed a subarray-level processing-in-memory architecture
named SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration of
transformer-based text generation. The SAL-PIM architecture includes three
architectural features. First, the SAL-PIM architecture utilizes higher
internal bandwidth by integrating multiple subarray-level arithmetic logic
units with optimized data mapping schemes. Second, the SAL-PIM architecture
adopts LUT-based linear interpolation to perform complex non-linear functions
in PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIM
in text generation. Furthermore, to validate the SAL-PIM architecture, we built
cycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nm
CMOS technology. As a result, when the input size is from 32 to 128 and the
output size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedup
and an average of 1.83 times speedup for the text generation based on the GPT-2
medium model compared to the server-level GPU.

中文翻译:
文本生成是自然语言处理中一个引人注目的子领域，其目标是从输入词汇生成符合人类阅读习惯的文本。其中，仅含解码器的生成模型（如生成式预训练变换器GPT）被广泛应用于文本生成，主要包含两个计算阶段：摘要阶段和生成阶段。与可并行处理输入标记的摘要阶段不同，生成阶段需要通过迭代顺序生成输出标记，因此难以加速。此外，每次迭代都需要读取整个模型，数据复用机会极少。这使得基于变换器的文本生成工作负载严重受限于内存，导致外部内存带宽成为系统瓶颈。

本文提出了一种名为SAL-PIM的存内计算架构，该架构基于高带宽内存（HBM），用于端到端加速基于变换器的文本生成。SAL-PIM架构包含三大特征：首先，通过集成多个子阵列级算术逻辑单元并采用优化数据映射方案，充分利用更高的内部带宽；其次，采用基于查找表的线性插值方法在存内计算中执行复杂非线性函数；第三，实现了文本生成过程中端到端推理的存内计算加速。为验证该架构，我们构建了周期精确模拟器，并采用28纳米CMOS工艺实现了SAL-PIM的逻辑单元。实验结果表明，当输入规模为32至128、输出规模为1至256时，基于GPT-2中型模型的文本生成任务中，SAL-PIM相比服务器级GPU最高可实现4.72倍加速，平均加速比达1.83倍。

（注：根据学术论文翻译规范，对部分术语进行了标准化处理：
1. "decoder-only generative models"译为"仅含解码器的生成模型"
2. "memory-bound"译为"受限于内存"
3. "subarray-level processing-in-memory"译为"子阵列级存内计算"
4. 保持"GPT-2 medium model"等技术术语原貌
5. 将长句合理切分为符合中文表达习惯的短句
6. 专业表述如"cycle-accurate simulator"译为"周期精确模拟器"）
