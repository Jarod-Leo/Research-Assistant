# SAL-PIM: A Subarray-level Processing-in-Memory Architecture with LUT-based Linear Interpolation for Transformer-based Text Generation

链接: http://arxiv.org/abs/2401.17005v1

原文摘要:
Text generation is a compelling sub-field of natural language processing,
aiming to generate human-readable text from input words. In particular, the
decoder-only generative models, such as generative pre-trained transformer
(GPT), are widely used for text generation, with two major computational
stages: summarization and generation. Unlike the summarization stage, which can
process the input tokens in parallel, the generation stage is difficult to
accelerate due to its sequential generation of output tokens through iteration.
Moreover, each iteration requires reading a whole model with little data reuse
opportunity. Therefore, the workload of transformer-based text generation is
severely memory-bound, making the external memory bandwidth system bottleneck.
In this paper, we proposed a subarray-level processing-in-memory architecture
named SAL-PIM, HBM-based PIM architecture for the end-to-end acceleration of
transformer-based text generation. The SAL-PIM architecture includes three
architectural features. First, the SAL-PIM architecture utilizes higher
internal bandwidth by integrating multiple subarray-level arithmetic logic
units with optimized data mapping schemes. Second, the SAL-PIM architecture
adopts LUT-based linear interpolation to perform complex non-linear functions
in PIM. Third, the SAL-PIM architecture accelerates end-to-end inference on PIM
in text generation. Furthermore, to validate the SAL-PIM architecture, we built
cycle-accurate simulator and implemented the SAL-PIM's logic units in 28-nm
CMOS technology. As a result, when the input size is from 32 to 128 and the
output size is from 1 to 256, SAL-PIM achieves a maximum of 4.72 times speedup
and an average of 1.83 times speedup for the text generation based on the GPT-2
medium model compared to the server-level GPU.

中文翻译:
文本生成作为自然语言处理中极具吸引力的子领域，其目标是从输入词汇生成符合人类阅读习惯的文本。其中，仅解码器架构的生成模型（如生成式预训练变换器GPT）被广泛应用于文本生成任务，主要包含两个计算阶段：摘要阶段与生成阶段。与可并行处理输入标记的摘要阶段不同，生成阶段需通过迭代逐序列产生输出标记，难以实现加速。此外，每次迭代都需读取整个模型参数，数据复用机会极少，导致基于变换器的文本生成工作负载严重受限于内存访问，使得外部内存带宽成为系统瓶颈。

本文提出了一种名为SAL-PIM的子阵列级存内计算架构，该架构基于高带宽内存（HBM），旨在实现对基于变换器的文本生成进行端到端加速。SAL-PIM架构具有三大特征：首先，通过集成多个子阵列级算术逻辑单元并优化数据映射方案，显著提升了内部带宽利用率；其次，采用基于查找表的线性插值方法，在存内计算中高效执行复杂非线性函数；第三，实现了文本生成全流程在存内计算架构上的加速。

为验证SAL-PIM架构，我们构建了周期精确的模拟器，并采用28纳米CMOS工艺实现了其逻辑单元。实验结果表明：当输入规模为32至128、输出规模为1至256时，相较于服务器级GPU，SAL-PIM在GPT-2中等模型上的文本生成任务中最高可实现4.72倍加速，平均加速比达1.83倍。
