# A Natural Language Processing Approach to Support Biomedical Data Harmonization: Leveraging Large Language Models

链接: http://arxiv.org/abs/2411.02730v1

原文摘要:
Biomedical research requires large, diverse samples to produce unbiased
results. Automated methods for matching variables across datasets can
accelerate this process. Research in this area has been limited, primarily
focusing on lexical matching and ontology based semantic matching. We aimed to
develop new methods, leveraging large language models (LLM) and ensemble
learning, to automate variable matching. Methods: We utilized data from two
GERAS cohort (European and Japan) studies to develop variable matching methods.
We first manually created a dataset by matching 352 EU variables with 1322
candidate JP variables, where matched variable pairs were positive and
unmatched pairs were negative instances. Using this dataset, we developed and
evaluated two types of natural language processing (NLP) methods, which matched
variables based on variable labels and definitions from data dictionaries: (1)
LLM-based and (2) fuzzy matching. We then developed an ensemble-learning
method, using the Random Forest model, to integrate individual NLP methods. RF
was trained and evaluated on 50 trials. Each trial had a random split (4:1) of
training and test sets, with the model's hyperparameters optimized through
cross-validation on the training set. For each EU variable, 1322 candidate JP
variables were ranked based on NLP-derived similarity scores or RF's
probability scores, denoting their likelihood to match the EU variable. Ranking
performance was measured by top-n hit ratio (HRn) and mean reciprocal rank
(MRR). Results:E5 performed best among individual methods, achieving 0.90 HR-30
and 0.70 MRR. RF performed better than E5 on all metrics over 50 trials (P less
than 0.001) and achieved an average HR 30 of 0.98 and MRR of 0.73. LLM-derived
features contributed most to RF's performance. One major cause of errors in
automatic variable matching was ambiguous variable definitions within data
dictionaries.

中文翻译:
生物医学研究需要大规模多样化样本以产生无偏倚的结果。跨数据集变量匹配的自动化方法可加速这一进程。该领域现有研究有限，主要集中于基于词法匹配和本体论的语义匹配。本研究旨在开发结合大语言模型（LLM）与集成学习的新方法来实现变量自动匹配。

方法：我们采用欧洲与日本GERAS队列研究数据开发变量匹配方法。首先通过人工匹配352个欧盟变量与1322个日本候选变量构建数据集，其中匹配变量对作为正例，未匹配对作为负例。基于该数据集，我们开发并评估了两种自然语言处理（NLP）方法：（1）基于LLM的匹配；（2）模糊匹配，二者均利用数据字典中的变量标签与定义进行匹配。随后开发集成学习方法，采用随机森林（RF）模型整合各NLP方法。RF模型经过50次试验训练与评估，每次试验随机划分训练集与测试集（4:1比例），并通过训练集交叉验证优化超参数。对每个欧盟变量，1322个日本候选变量根据NLP相似度得分或RF匹配概率得分排序。排序性能通过top-n命中率（HRn）和平均倒数排名（MRR）评估。

结果：在单一方法中E5表现最佳（HR-30=0.90，MRR=0.70）。RF在50次试验中所有指标均显著优于E5（P<0.001），平均HR-30达0.98，MRR达0.73。LLM生成的特征对RF性能贡献最大。自动变量匹配的主要误差来源是数据字典中变量定义的模糊性。

（注：E5指代原文中未具体说明的某个体方法，保留英文代号以保持技术准确性；GERAS为研究项目名称保留不译；P值标注采用国际通用格式）
