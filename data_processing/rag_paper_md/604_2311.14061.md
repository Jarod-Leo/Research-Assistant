# Towards Explainable Strategy Templates using NLP Transformers

链接: http://arxiv.org/abs/2311.14061v1

原文摘要:
This paper bridges the gap between mathematical heuristic strategies learned
from Deep Reinforcement Learning (DRL) in automated agent negotiation, and
comprehensible, natural language explanations. Our aim is to make these
strategies more accessible to non-experts. By leveraging traditional Natural
Language Processing (NLP) techniques and Large Language Models (LLMs) equipped
with Transformers, we outline how parts of DRL strategies composed of parts
within strategy templates can be transformed into user-friendly, human-like
English narratives. To achieve this, we present a top-level algorithm that
involves parsing mathematical expressions of strategy templates, semantically
interpreting variables and structures, generating rule-based primary
explanations, and utilizing a Generative Pre-trained Transformer (GPT) model to
refine and contextualize these explanations. Subsequent customization for
varied audiences and meticulous validation processes in an example illustrate
the applicability and potential of this approach.

中文翻译:
本文弥合了从深度强化学习（DRL）中习得的自动化智能体协商数学启发式策略与可理解的自然语言解释之间的鸿沟，旨在使非专业人士更易掌握这些策略。通过结合传统自然语言处理（NLP）技术和基于Transformer架构的大语言模型（LLMs），我们阐述了如何将策略模板中数学表达式构成的DRL策略转化为用户友好、拟人化的英文叙述。为实现这一目标，我们提出一种顶层算法：首先解析策略模板的数学表达式，对变量与结构进行语义解释；继而生成基于规则的基础说明，并利用生成式预训练Transformer（GPT）模型对这些解释进行精细化处理与语境化重构。通过针对不同受众的定制化调整及示例中的严谨验证流程，本研究论证了该方法的适用性与潜在价值。

（翻译说明：采用学术论文摘要的规范表述，保留"DRL/LLMs/GPT"等专业缩写首次出现时的全称；将英语长句拆解为符合中文表达习惯的短句结构；"user-friendly, human-like"融合译为"用户友好、拟人化"以保持术语简洁性；通过"顶层算法"等措辞准确传达"top-level algorithm"的层级概念；使用"弥合...鸿沟""语境化重构"等专业表述确保学术文本的严谨性。）
