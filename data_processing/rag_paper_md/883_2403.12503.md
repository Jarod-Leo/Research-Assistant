# Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices

链接: http://arxiv.org/abs/2403.12503v1

原文摘要:
Large language models (LLMs) have significantly transformed the landscape of
Natural Language Processing (NLP). Their impact extends across a diverse
spectrum of tasks, revolutionizing how we approach language understanding and
generations. Nevertheless, alongside their remarkable utility, LLMs introduce
critical security and risk considerations. These challenges warrant careful
examination to ensure responsible deployment and safeguard against potential
vulnerabilities. This research paper thoroughly investigates security and
privacy concerns related to LLMs from five thematic perspectives: security and
privacy concerns, vulnerabilities against adversarial attacks, potential harms
caused by misuses of LLMs, mitigation strategies to address these challenges
while identifying limitations of current strategies. Lastly, the paper
recommends promising avenues for future research to enhance the security and
risk management of LLMs.

中文翻译:
大型语言模型（LLMs）已深刻改变了自然语言处理（NLP）的格局。其影响力覆盖了多样化的任务领域，彻底革新了我们处理语言理解与生成的方式。然而，在展现卓越实用性的同时，LLMs也引发了关键的安全与风险问题。这些挑战亟需审慎研究，以确保负责任地部署模型并防范潜在漏洞。本文从五大主题维度系统探究了LLMs相关的安全与隐私问题：安全与隐私隐患、对抗性攻击下的脆弱性、模型滥用可能造成的危害、现有缓解策略及其局限性，以及应对这些挑战的解决方案。最后，论文为提升LLMs安全与风险管理指明了未来研究的可行路径。
