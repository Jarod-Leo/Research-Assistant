# Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models

链接: http://arxiv.org/abs/2407.06089v1

原文摘要:
The remarkable success of Large Language Models (LLMs) has ushered natural
language processing (NLP) research into a new era. Despite their diverse
capabilities, LLMs trained on different corpora exhibit varying strengths and
weaknesses, leading to challenges in maximizing their overall efficiency and
versatility. To address these challenges, recent studies have explored
collaborative strategies for LLMs. This paper provides a comprehensive overview
of this emerging research area, highlighting the motivation behind such
collaborations. Specifically, we categorize collaborative strategies into three
primary approaches: Merging, Ensemble, and Cooperation. Merging involves
integrating multiple LLMs in the parameter space. Ensemble combines the outputs
of various LLMs. Cooperation} leverages different LLMs to allow full play to
their diverse capabilities for specific tasks. We provide in-depth
introductions to these methods from different perspectives and discuss their
potential applications. Additionally, we outline future research directions,
hoping this work will catalyze further studies on LLM collaborations and paving
the way for advanced NLP applications.

中文翻译:
大型语言模型（LLM）的显著成功将自然语言处理（NLP）研究带入了一个新时代。尽管这些模型具备多样化的能力，但基于不同语料库训练的LLM表现出各自的优势与局限，这使得如何最大化其整体效率与通用性成为关键挑战。为应对这些挑战，近期研究开始探索LLM间的协同策略。本文全面综述了这一新兴领域，阐明了此类协作背后的动机，并将协同策略归纳为三大类：**参数融合**（通过参数空间整合多个LLM）、**集成输出**（综合不同LLM的生成结果）以及**能力协作**（利用各模型的特长完成特定任务）。我们从多视角深入解析这些方法，并探讨其潜在应用场景。此外，本文还展望了未来研究方向，期望推动LLM协作机制的深入研究，为NLP前沿应用开辟新路径。
