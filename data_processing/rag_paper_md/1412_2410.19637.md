# A distributional simplicity bias in the learning dynamics of transformers

链接: http://arxiv.org/abs/2410.19637v1

原文摘要:
The remarkable capability of over-parameterised neural networks to generalise
effectively has been explained by invoking a ``simplicity bias'': neural
networks prevent overfitting by initially learning simple classifiers before
progressing to more complex, non-linear functions. While simplicity biases have
been described theoretically and experimentally in feed-forward networks for
supervised learning, the extent to which they also explain the remarkable
success of transformers trained with self-supervised techniques remains
unclear. In our study, we demonstrate that transformers, trained on natural
language data, also display a simplicity bias. Specifically, they sequentially
learn many-body interactions among input tokens, reaching a saturation point in
the prediction error for low-degree interactions while continuing to learn
high-degree interactions. To conduct this analysis, we develop a procedure to
generate \textit{clones} of a given natural language data set, which rigorously
capture the interactions between tokens up to a specified order. This approach
opens up the possibilities of studying how interactions of different orders in
the data affect learning, in natural language processing and beyond.

中文翻译:
过参数化神经网络展现出的卓越泛化能力，常被归因于一种"简约性偏好"机制：网络通过先学习简单分类器，再逐步掌握更复杂的非线性函数来避免过拟合。尽管这种偏好已在监督学习的前馈网络中得到理论与实验验证，但其能否解释自监督训练的Transformer模型取得的巨大成功仍不明确。本研究证明，在自然语言数据上训练的Transformer同样表现出简约性偏好——它们会依次学习输入标记间的多体交互作用：当低阶交互的预测误差达到饱和时，模型仍在持续学习高阶交互。为此，我们开发了一种生成文本数据克隆集的方法，可严格捕获指定阶数内的标记交互关系。这一方法为研究自然语言处理及其他领域中，不同阶数的数据交互如何影响学习过程开辟了新途径。
