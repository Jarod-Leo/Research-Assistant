# PoseWatch: A Transformer-based Architecture for Human-centric Video Anomaly Detection Using Spatio-temporal Pose Tokenization

链接: http://arxiv.org/abs/2408.15185v1

原文摘要:
Video Anomaly Detection (VAD) presents a significant challenge in computer
vision, particularly due to the unpredictable and infrequent nature of
anomalous events, coupled with the diverse and dynamic environments in which
they occur. Human-centric VAD, a specialized area within this domain, faces
additional complexities, including variations in human behavior, potential
biases in data, and substantial privacy concerns related to human subjects.
These issues complicate the development of models that are both robust and
generalizable. To address these challenges, recent advancements have focused on
pose-based VAD, which leverages human pose as a high-level feature to mitigate
privacy concerns, reduce appearance biases, and minimize background
interference. In this paper, we introduce SPARTA, a novel transformer-based
architecture designed specifically for human-centric pose-based VAD. SPARTA
introduces an innovative Spatio-Temporal Pose and Relative Pose (ST-PRP)
tokenization method that produces an enriched representation of human motion
over time. This approach ensures that the transformer's attention mechanism
captures both spatial and temporal patterns simultaneously, rather than
focusing on only one aspect. The addition of the relative pose further
emphasizes subtle deviations from normal human movements. The architecture's
core, a novel Unified Encoder Twin Decoders (UETD) transformer, significantly
improves the detection of anomalous behaviors in video data. Extensive
evaluations across multiple benchmark datasets demonstrate that SPARTA
consistently outperforms existing methods, establishing a new state-of-the-art
in pose-based VAD.

中文翻译:
视频异常检测（Video Anomaly Detection, VAD）是计算机视觉领域的一项重大挑战，这主要源于异常事件的不可预测性和罕见性，以及其所处环境的多样性与动态性。以人为中心的VAD作为该领域的专门分支，还面临着更多复杂问题，包括人类行为的多样性、数据中潜在的偏见，以及涉及人类主体时重大的隐私隐忧。这些问题使得开发既鲁棒又具泛化能力的模型变得尤为困难。

为应对这些挑战，近期研究聚焦于基于姿态的VAD方法，通过利用人体姿态作为高层特征来缓解隐私问题、降低外观偏差并减少背景干扰。本文提出SPARTA——一种专为以人为中心的姿态基VAD设计的新型Transformer架构。该架构创新性地引入了时空姿态与相对姿态（ST-PRP）标记化方法，能够生成随时间演进的人类运动增强表征。这种方法确保Transformer的注意力机制能同时捕捉空间和时间模式，而非仅关注单一维度。相对姿态的加入进一步强化了对正常人体运动细微偏差的检测能力。

该架构的核心是新型统一编码器-双解码器（UETD）Transformer结构，显著提升了视频数据中异常行为的检测性能。在多个基准数据集上的广泛实验表明，SPARTA持续超越现有方法，确立了姿态基VAD领域的最新性能标杆。
