# Modelando procesos cognitivos de la lectura natural con GPT-2

链接: http://arxiv.org/abs/2409.20174v1

原文摘要:
The advancement of the Natural Language Processing field has enabled the
development of language models with a great capacity for generating text. In
recent years, Neuroscience has been using these models to better understand
cognitive processes. In previous studies, we found that models like Ngrams and
LSTM networks can partially model Predictability when used as a co-variable to
explain readers' eye movements. In the present work, we further this line of
research by using GPT-2 based models. The results show that this architecture
achieves better outcomes than its predecessors.

中文翻译:
自然语言处理领域的进步推动了具有强大文本生成能力的语言模型的发展。近年来，神经科学领域正运用这些模型来深化对认知过程的理解。在先前研究中，我们发现当N-gram模型和长短期记忆网络作为协变量解释读者眼动行为时，能够部分模拟可预测性效应。本研究通过采用基于GPT-2的模型进一步推进了该研究方向，实验结果表明该架构较先前模型取得了更优的预测效果。
