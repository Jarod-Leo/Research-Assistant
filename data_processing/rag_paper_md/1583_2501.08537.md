# Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers

链接: http://arxiv.org/abs/2501.08537v1

原文摘要:
Transformers have demonstrated impressive capabilities across various tasks,
yet their performance on compositional problems remains a subject of debate. In
this study, we investigate the internal mechanisms underlying Transformers'
behavior in compositional tasks. We find that complexity control strategies
significantly influence whether the model learns primitive-level rules that
generalize out-of-distribution (reasoning-based solutions) or relies solely on
memorized mappings (memory-based solutions). By applying masking strategies to
the model's information circuits and employing multiple complexity metrics, we
reveal distinct internal working mechanisms associated with different solution
types. Further analysis reveals that reasoning-based solutions exhibit a lower
complexity bias, which aligns with the well-studied neuron condensation
phenomenon. This lower complexity bias is hypothesized to be the key factor
enabling these solutions to learn reasoning rules. We validate these
conclusions across multiple real-world datasets, including image generation and
natural language processing tasks, confirming the broad applicability of our
findings.

中文翻译:
Transformer模型已在多种任务中展现出卓越性能，但其在组合性问题上的表现仍存争议。本研究深入探究了Transformer处理组合任务时的内部机制，发现复杂度控制策略显著影响模型是学习具有分布外泛化能力的基元规则（基于推理的解决方案），还是仅依赖记忆映射（基于记忆的解决方案）。通过采用信息回路掩蔽策略并结合多维度复杂度度量，我们揭示了不同解决方案类型对应的差异化内部工作机制。进一步分析表明，基于推理的解决方案呈现出更低的复杂度偏好，这与学界广泛研究的神经元凝聚现象相吻合。这种低复杂度偏好被证实是模型习得推理规则的关键因素。我们在图像生成和自然语言处理等多个现实数据集中验证了这些结论，证实了研究发现具有普适性。
