# Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction

链接: http://arxiv.org/abs/2411.04588v1

原文摘要:
Natural language processing (NLP) utilizes text data augmentation to overcome
sample size constraints. Increasing the sample size is a natural and widely
used strategy for alleviating these challenges. In this study, we chose Arabic
to increase the sample size and correct grammatical errors. Arabic is
considered one of the languages with limited resources for grammatical error
correction (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used
in most Arabic grammatical error correction research, with approximately 20,500
parallel examples, which is considered low compared with other languages.
Therefore, this study aims to develop an Arabic corpus called "Tibyan" for
grammatical error correction using ChatGPT. ChatGPT is used as a data augmenter
tool based on a pair of Arabic sentences containing grammatical errors matched
with a sentence free of errors extracted from Arabic books, called guide
sentences. Multiple steps were involved in establishing our corpus, including
the collection and pre-processing of a pair of Arabic texts from various
sources, such as books and open-access corpora. We then used ChatGPT to
generate a parallel corpus based on the text collected previously, as a guide
for generating sentences with multiple types of errors. By engaging linguistic
experts to review and validate the automatically generated sentences, we
ensured that they were correct and error-free. The corpus was validated and
refined iteratively based on feedback provided by linguistic experts to improve
its accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to
analyze the types of errors in the Tibyan corpus. Our corpus contained 49 of
errors, including seven types: orthography, morphology, syntax, semantics,
punctuation, merge, and split. The Tibyan corpus contains approximately 600 K
tokens.

中文翻译:
自然语言处理（NLP）领域通过文本数据增强技术来克服样本量的限制。增加样本规模是缓解此类挑战最自然且广泛采用的策略。本研究选择阿拉伯语作为研究对象以扩充样本规模并修正语法错误。阿拉伯语被视为语法纠错（GEC）资源相对匮乏的语言之一，目前大多数阿拉伯语语法纠错研究仅使用QALB-14和QALB-15两个数据集，其包含约20,500组平行例句，相较于其他语言而言规模明显不足。为此，本研究旨在利用ChatGPT构建名为"Tibyan"的阿拉伯语语法纠错语料库。基于从阿拉伯语书籍中提取的正确参考句（称为引导句）及其对应的含语法错误句对，我们采用ChatGPT作为数据增强工具。语料库建设包含多个步骤：首先从书籍和开放语料库等多元渠道收集阿拉伯语文本对并进行预处理；随后以预处理文本为指导，利用ChatGPT生成包含多类错误的平行语料库；继而邀请语言学专家对自动生成的句子进行审校验证，确保其正确无误；根据专家反馈意见迭代优化语料库以提升准确性。最终采用阿拉伯语错误类型标注工具（ARETA）分析Tibyan语料库中的错误类型，共识别出49种错误，涵盖七大类：正字法、词法、句法、语义、标点符号、合并及拆分错误。该语料库规模达约60万词元。
