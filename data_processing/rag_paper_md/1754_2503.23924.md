# Model Hemorrhage and the Robustness Limits of Large Language Models

链接: http://arxiv.org/abs/2503.23924v1

原文摘要:
Large language models (LLMs) demonstrate strong performance across natural
language processing tasks, yet undergo significant performance degradation when
modified for deployment through quantization, pruning, or decoding strategy
adjustments. We define this phenomenon as model hemorrhage - performance
decline caused by parameter alterations and architectural changes. Through
systematic analysis of various LLM frameworks, we identify key vulnerability
patterns: layer expansion frequently disrupts attention mechanisms, compression
techniques induce information loss cascades, and decoding adjustments amplify
prediction divergences. Our investigation reveals transformer architectures
exhibit inherent robustness thresholds that determine hemorrhage severity
across modification types. We propose three mitigation strategies:
gradient-aware pruning preserves critical weight pathways, dynamic quantization
scaling maintains activation integrity, and decoding calibration aligns
generation trajectories with original model distributions. This work
establishes foundational metrics for evaluating model stability during
adaptation, providing practical guidelines for maintaining performance while
enabling efficient LLM deployment. Our findings advance understanding of neural
network resilience under architectural transformations, particularly for
large-scale language models.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）在自然语言处理任务中展现出卓越性能，但在通过量化、剪枝或解码策略调整等修改进行部署时，往往出现显著的性能退化。我们将这种现象定义为"模型失血"——由参数变更与架构改动引发的性能衰减。通过对多种LLM框架的系统分析，我们识别出关键脆弱性模式：层扩展频繁破坏注意力机制、压缩技术引发信息损失级联、解码调整放大预测分歧。研究表明，Transformer架构存在决定不同修改类型下失血严重程度的内在鲁棒性阈值。我们提出三种缓解策略：梯度感知剪枝保留关键权重路径、动态量化缩放维持激活完整性、解码校准使生成轨迹与原始模型分布对齐。本研究建立了模型适配过程中的稳定性评估基础指标，为保持性能同时实现高效部署提供实践指南。这些发现深化了对神经网络架构变换下鲁棒性的理解，特别针对大规模语言模型具有重要价值。

注：翻译过程中进行了以下专业处理：
1. "model hemorrhage"译为"模型失血"并添加引号，既保留原文隐喻又符合中文术语习惯
2. 技术术语如quantization/pruning统一译为"量化/剪枝"（计算机领域标准译法）
3. 长难句拆分重组（如原文第三句拆分为三个中文短句），符合中文表达习惯
4. 被动语态转换（如"are identified"译为主动式"识别出"）
5. 关键概念如"robustness thresholds"译为"鲁棒性阈值"保持学术准确性
6. 添加连接词（"特别针对"）增强逻辑连贯性
