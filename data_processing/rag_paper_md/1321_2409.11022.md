# GEIC: Universal and Multilingual Named Entity Recognition with Large Language Models

链接: http://arxiv.org/abs/2409.11022v2

原文摘要:
With the advancement of Large Language Models (LLMs), more and more
researchers apply LLMs for Named Entity Recognition (NER) methods, bringing
vitality to this classical Natural Language Processing task. However, existing
datasets are designed for traditional machine learning methods, inadequate for
LLM-based methods in terms of corpus selection, entity categorization, and
design logic. This limitation leads to less effective evaluation and model
fine-tuning. To address this issue, we propose DynamicNER, the first NER
dataset specifically designed for LLMs and with dynamic categorization,
transcending the limitations of fixed categorization in existing datasets. It
is also multi-lingual and multi-granular, covering 8 languages and 155 entity
types, with corpus spanning multiple specialized domains. Furthermore, in
response to the limitations demonstrated by existing LLM-based methods during
DynamicNER testing, we develop CascadeNER, a novel NER method based on a
two-stage strategy and lightweight LLMs, addressing the problems in current
methods. Experiments show that DynamicNER is an effective benchmark for
LLM-based NER methods, and CascadeNER outperforms existing methods with fewer
computational resources. Our work is opened at
https://github.com/CascadeNER/CascadeNER.

中文翻译:
随着大语言模型（LLMs）的发展，越来越多研究者将LLMs应用于命名实体识别（NER）方法，为这一经典自然语言处理任务注入了新活力。然而现有数据集均针对传统机器学习方法设计，在语料选择、实体分类和设计逻辑上难以适配基于LLM的方法，导致评估与模型调优效果不佳。为此我们提出DynamicNER——首个专为LLMs设计且具有动态分类特性的NER数据集，突破了现有数据集固定分类的局限。该数据集同时具备多语言、多粒度特性，涵盖8种语言和155种实体类型，语料横跨多个专业领域。此外，针对现有基于LLM的方法在DynamicNER测试中暴露的不足，我们开发了CascadeNER这一基于两阶段策略与轻量化LLMs的新型NER方法，解决了当前方法存在的问题。实验表明DynamicNER能有效评测基于LLM的NER方法，CascadeNER则以更少计算资源超越了现有方法。我们的工作已开源于https://github.com/CascadeNER/CascadeNER。
