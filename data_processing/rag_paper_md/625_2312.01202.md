# From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews

链接: http://arxiv.org/abs/2312.01202v1

原文摘要:
Obtaining stakeholders' diverse experiences and opinions about current policy
in a timely manner is crucial for policymakers to identify strengths and gaps
in resource allocation, thereby supporting effective policy design and
implementation. However, manually coding even moderately sized interview texts
or open-ended survey responses from stakeholders can often be labor-intensive
and time-consuming. This study explores the integration of Large Language
Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of
stakeholder interviews regarding K-12 education policy within one U.S. state.
Employing a mixed-methods approach, human experts developed a codebook and
coding processes as informed by domain knowledge and unsupervised topic
modeling results. They then designed prompts to guide GPT-4 analysis and
iteratively evaluate different prompts' performances. This combined
human-computer method enabled nuanced thematic and sentiment analysis. Results
reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at
specific themes, expanding to broader themes increased congruence to 96.02%,
surpassing traditional Natural Language Processing (NLP) methods by over 25%.
Additionally, GPT-4 is more closely matched to expert sentiment analysis than
lexicon-based methods. Findings from quantitative measures and qualitative
reviews underscore the complementary roles of human domain expertise and
automated analysis as LLMs offer new perspectives and coding consistency. The
human-computer interactive approach enhances efficiency, validity, and
interpretability of educational policy research.

中文翻译:
及时获取利益相关方对现行政策的多样化体验与观点，对政策制定者识别资源配置的优势与不足至关重要，从而为有效政策设计与实施提供支持。然而，即使是中等规模的访谈文本或开放式调查反馈，人工编码往往也需耗费大量人力与时间。本研究探索将GPT-4等大语言模型（LLMs）与人类专业知识相结合，以增强对美国某州K-12教育政策利益相关者访谈的文本分析。通过混合研究方法，领域专家基于专业知识与无监督主题建模结果开发了编码手册及流程，随后设计提示词引导GPT-4分析并迭代评估不同提示的表现。这种人机协同方法实现了精细化的主题与情感分析。结果显示：GPT-4在具体主题上的编码与人工编码一致性达77.89%，扩展至广义主题后一致性提升至96.02%，超越传统自然语言处理方法25%以上；相较于基于词典的情感分析方法，GPT-4与专家分析结果更为接近。定量测量与定性评估表明，LLMs能提供新视角并保持编码一致性，与人类领域知识形成互补。这种人机交互方法显著提升了教育政策研究的效率、效度与可解释性。
