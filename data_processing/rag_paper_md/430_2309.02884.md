# Aligning Large Language Models for Clinical Tasks

链接: http://arxiv.org/abs/2309.02884v2

原文摘要:
Large Language Models (LLMs) have demonstrated remarkable adaptability,
showcasing their capacity to excel in tasks for which they were not explicitly
trained. However, despite their impressive natural language processing (NLP)
capabilities, effective alignment of LLMs remains a crucial challenge when
deploying them for specific clinical applications. The ability to generate
responses with factually accurate content and to engage in non-trivial
reasoning steps are crucial for the LLMs to be eligible for applications in
clinical medicine. Employing a combination of techniques including
instruction-tuning and in-prompt strategies like few-shot and chain-of-thought
prompting has significantly enhanced the performance of LLMs. Our proposed
alignment strategy for medical question-answering, known as
'expand-guess-refine', offers a parameter and data-efficient solution. A
preliminary analysis of this method demonstrated outstanding performance,
achieving a score of 70.63% on a subset of questions sourced from the USMLE
dataset.

中文翻译:
大型语言模型（LLMs）展现出卓越的适应性，能够胜任未经专门训练的任务。然而，尽管其自然语言处理（NLP）能力令人瞩目，在特定临床应用场景中，如何实现LLMs的有效对齐仍是关键挑战。生成内容事实准确且具备复杂推理能力的回答，是LLMs应用于临床医学的基本要求。通过结合指令微调技术及少样本提示、思维链提示等即时策略，LLMs性能得到显著提升。我们提出的医学问答对齐策略"扩展-推测-优化"，提供了一种参数与数据高效利用的解决方案。初步分析表明，该方法在美国医师执照考试（USMLE）部分试题上取得了70.63%的优异表现。
