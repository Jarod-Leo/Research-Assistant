# PHEONA: An Evaluation Framework for Large Language Model-based Approaches to Computational Phenotyping

链接: http://arxiv.org/abs/2503.19265v1

原文摘要:
Computational phenotyping is essential for biomedical research but often
requires significant time and resources, especially since traditional methods
typically involve extensive manual data review. While machine learning and
natural language processing advancements have helped, further improvements are
needed. Few studies have explored using Large Language Models (LLMs) for these
tasks despite known advantages of LLMs for text-based tasks. To facilitate
further research in this area, we developed an evaluation framework, Evaluation
of PHEnotyping for Observational Health Data (PHEONA), that outlines
context-specific considerations. We applied and demonstrated PHEONA on concept
classification, a specific task within a broader phenotyping process for Acute
Respiratory Failure (ARF) respiratory support therapies. From the sample
concepts tested, we achieved high classification accuracy, suggesting the
potential for LLM-based methods to improve computational phenotyping processes.

中文翻译:
计算表型分析在生物医学研究中至关重要，但通常需要投入大量时间和资源，尤其是传统方法往往涉及繁重的人工数据审查。尽管机器学习和自然语言处理技术的进步已带来一定帮助，但仍需进一步优化。尽管大型语言模型（LLM）在文本处理任务中具有公认优势，但探索其应用于表型分析的研究仍属有限。为促进该领域深入研究，我们开发了"观察性健康数据表型分析评估框架"（PHEONA），其中明确了特定场景下的考量要素。我们将该框架应用于急性呼吸衰竭（ARF）呼吸支持疗法的表型分析流程中的概念分类任务进行验证。测试样本的概念分类准确率表现优异，这表明基于LLM的方法具有优化计算表型分析流程的潜力。
