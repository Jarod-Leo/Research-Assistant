# Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback

链接: http://arxiv.org/abs/2405.19686v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable proficiency in a
range of natural language processing tasks. Once deployed, LLMs encounter users
with personalized factual knowledge, and such personalized knowledge is
consistently reflected through users' interactions with the LLMs. To enhance
user experience, real-time model personalization is essential, allowing LLMs to
adapt user-specific knowledge based on user feedback during human-LLM
interactions. Existing methods mostly require back-propagation to finetune the
model parameters, which incurs high computational and memory costs. In
addition, these methods suffer from low interpretability, which will cause
unforeseen impacts on model performance during long-term use, where the user's
personalized knowledge is accumulated extensively.To address these challenges,
we propose Knowledge Graph Tuning (KGT), a novel approach that leverages
knowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual
knowledge triples from users' queries and feedback and optimizes KGs without
modifying the LLM parameters. Our method improves computational and memory
efficiency by avoiding back-propagation and ensures interpretability by making
the KG adjustments comprehensible to humans.Experiments with state-of-the-art
LLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves
personalization performance while reducing latency and GPU memory costs.
Ultimately, KGT offers a promising solution of effective, efficient, and
interpretable real-time LLM personalization during user interactions with the
LLMs.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在一系列自然语言处理任务中展现出卓越能力。实际部署后，LLMs会接触到用户个性化的知识需求，这些知识特征持续体现在用户与模型的交互过程中。为提升用户体验，实时个性化适配至关重要，这要求LLMs在人机交互过程中能根据用户反馈动态调整专属知识。现有方法大多依赖反向传播进行参数微调，导致高昂的计算与内存开销，且可解释性不足——当用户个性化知识长期累积时，可能对模型性能产生不可预知的影响。

针对这些挑战，我们提出知识图谱调优（KGT）方法，通过知识图谱（KGs）实现LLMs个性化。KGT从用户查询和反馈中提取个性化事实三元组，在不修改LLM参数的前提下优化知识图谱。该方法通过避免反向传播提升计算与内存效率，并通过人类可理解的图谱调整确保可解释性。基于GPT-2、Llama2和Llama3等前沿模型的实验表明，KGT在显著提升个性化性能的同时，有效降低了延迟和GPU内存消耗。该技术为LLMs交互过程中的实时个性化提供了高效、可解释的解决方案。

（翻译严格遵循以下技术规范：
1. 专业术语统一处理："back-propagation"译为"反向传播"，"knowledge graphs"保留"知识图谱"标准译法
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句
3. 被动语态转化："are reflected"等被动式转为主动表述
4. 概念显化处理："unforeseen impacts"译为"不可预知的影响"以明确含义
5. 技术表述精确性："factual knowledge triples"专业译为"事实三元组"
6. 保持学术严谨性：完整保留原文实验模型名称及技术指标）
