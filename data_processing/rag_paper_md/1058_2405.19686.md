# Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback

链接: http://arxiv.org/abs/2405.19686v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable proficiency in a
range of natural language processing tasks. Once deployed, LLMs encounter users
with personalized factual knowledge, and such personalized knowledge is
consistently reflected through users' interactions with the LLMs. To enhance
user experience, real-time model personalization is essential, allowing LLMs to
adapt user-specific knowledge based on user feedback during human-LLM
interactions. Existing methods mostly require back-propagation to finetune the
model parameters, which incurs high computational and memory costs. In
addition, these methods suffer from low interpretability, which will cause
unforeseen impacts on model performance during long-term use, where the user's
personalized knowledge is accumulated extensively.To address these challenges,
we propose Knowledge Graph Tuning (KGT), a novel approach that leverages
knowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual
knowledge triples from users' queries and feedback and optimizes KGs without
modifying the LLM parameters. Our method improves computational and memory
efficiency by avoiding back-propagation and ensures interpretability by making
the KG adjustments comprehensible to humans.Experiments with state-of-the-art
LLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves
personalization performance while reducing latency and GPU memory costs.
Ultimately, KGT offers a promising solution of effective, efficient, and
interpretable real-time LLM personalization during user interactions with the
LLMs.

中文翻译:
大型语言模型（LLMs）在一系列自然语言处理任务中展现出卓越的能力。模型部署后，用户会带着个性化的知识事实与之交互，这些个性化知识持续体现在用户与LLMs的互动中。为提升用户体验，实时个性化调整至关重要——需让LLMs在交互过程中根据用户反馈动态适配其专属知识。现有方法大多依赖反向传播微调模型参数，导致高昂的计算与内存开销；同时因其可解释性不足，在长期使用中随着用户个性化知识不断累积，可能对模型性能产生不可预知的影响。

针对这些挑战，我们提出知识图谱调优（KGT）这一创新方法，通过知识图谱（KGs）实现LLMs个性化。KGT从用户查询与反馈中提取个性化事实三元组，在不修改LLM参数的前提下优化知识图谱。该方法通过规避反向传播显著提升计算与内存效率，并通过人类可理解的图谱调整确保可解释性。基于GPT-2、Llama2和Llama3等前沿模型的实验表明，KGT在显著提升个性化性能的同时，有效降低了延迟与GPU内存消耗。最终，KGT为LLMs交互过程中的实时个性化提供了高效、可解释的解决方案。
