# Large Language Models: A New Approach for Privacy Policy Analysis at Scale

链接: http://arxiv.org/abs/2405.20900v1

原文摘要:
The number and dynamic nature of web and mobile applications presents
significant challenges for assessing their compliance with data protection
laws. In this context, symbolic and statistical Natural Language Processing
(NLP) techniques have been employed for the automated analysis of these
systems' privacy policies. However, these techniques typically require
labor-intensive and potentially error-prone manually annotated datasets for
training and validation. This research proposes the application of Large
Language Models (LLMs) as an alternative for effectively and efficiently
extracting privacy practices from privacy policies at scale. Particularly, we
leverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the
optimal design of prompts, parameters, and models, incorporating advanced
strategies such as few-shot learning. We further illustrate its capability to
detect detailed and varied privacy practices accurately. Using several renowned
datasets in the domain as a benchmark, our evaluation validates its exceptional
performance, achieving an F1 score exceeding 93%. Besides, it does so with
reduced costs, faster processing times, and fewer technical knowledge
requirements. Consequently, we advocate for LLM-based solutions as a sound
alternative to traditional NLP techniques for the automated analysis of privacy
policies at scale.

中文翻译:
网络和移动应用程序的数量庞大且动态变化，这给评估其是否符合数据保护法规带来了重大挑战。在此背景下，符号化和统计自然语言处理（NLP）技术已被用于自动化分析这些系统的隐私政策。然而，这些技术通常需要耗费大量人力且可能存在错误的手动标注数据集进行训练和验证。本研究提出应用大语言模型（LLMs）作为替代方案，以高效、规模化地从隐私政策中提取隐私实践。具体而言，我们利用ChatGPT和Llama 2等知名大语言模型，并提供关于提示设计、参数设置和模型选择的最佳实践指导，其中融入了小样本学习等先进策略。我们进一步展示了该方案在准确检测多样化的详细隐私实践方面的能力。以该领域多个知名数据集为基准，我们的评估验证了其卓越性能——F1分数超过93%。此外，该方案还具有成本更低、处理速度更快、技术知识要求更低的优势。因此，我们主张将基于大语言模型的解决方案作为传统NLP技术的可靠替代方案，用于大规模隐私政策的自动化分析。

（翻译说明：
1. 专业术语处理："symbolic and statistical NLP techniques"译为"符号化和统计自然语言处理技术"，"few-shot learning"采用通用译法"小样本学习"
2. 句式重构：将英语长句拆分为符合中文表达习惯的短句，如第一句通过分号连接两个分句
3. 被动语态转换："have been employed"译为主动态"已被用于"
4. 数据呈现：保留"F1分数超过93%"的技术指标原貌
5. 概念一致性：全文统一"privacy policies"为"隐私政策"，"privacy practices"为"隐私实践"
6. 补充说明：在首次出现LLMs时添加"大语言模型"的完整表述，便于读者理解）
