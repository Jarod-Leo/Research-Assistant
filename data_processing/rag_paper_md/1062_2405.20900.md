# Large Language Models: A New Approach for Privacy Policy Analysis at Scale

链接: http://arxiv.org/abs/2405.20900v1

原文摘要:
The number and dynamic nature of web and mobile applications presents
significant challenges for assessing their compliance with data protection
laws. In this context, symbolic and statistical Natural Language Processing
(NLP) techniques have been employed for the automated analysis of these
systems' privacy policies. However, these techniques typically require
labor-intensive and potentially error-prone manually annotated datasets for
training and validation. This research proposes the application of Large
Language Models (LLMs) as an alternative for effectively and efficiently
extracting privacy practices from privacy policies at scale. Particularly, we
leverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the
optimal design of prompts, parameters, and models, incorporating advanced
strategies such as few-shot learning. We further illustrate its capability to
detect detailed and varied privacy practices accurately. Using several renowned
datasets in the domain as a benchmark, our evaluation validates its exceptional
performance, achieving an F1 score exceeding 93%. Besides, it does so with
reduced costs, faster processing times, and fewer technical knowledge
requirements. Consequently, we advocate for LLM-based solutions as a sound
alternative to traditional NLP techniques for the automated analysis of privacy
policies at scale.

中文翻译:
网络与移动应用程序的数量庞大且动态变化，这对评估其是否符合数据保护法律提出了重大挑战。在此背景下，符号化与统计自然语言处理（NLP）技术已被用于自动化分析这些系统的隐私政策。然而，这些技术通常需要耗费大量人力且可能存在错误的手动标注数据集进行训练与验证。本研究提出应用大型语言模型（LLMs）作为一种替代方案，以高效且规模化地从隐私政策中提取隐私实践。具体而言，我们利用知名LLMs如ChatGPT和Llama 2，并提供关于提示设计、参数设置及模型选择的最佳实践指导，包括小样本学习等先进策略。我们进一步展示了其准确检测多样且详细隐私实践的能力。通过以该领域多个知名数据集为基准，评估验证了其卓越性能，F1分数超过93%。此外，该方法成本更低、处理速度更快且技术知识要求更少。因此，我们主张将基于LLM的解决方案作为传统NLP技术的可靠替代，用于大规模隐私政策的自动化分析。
