# One Arrow, Many Targets: Probing LLMs for Multi-Attribute Controllable Text Summarization

链接: http://arxiv.org/abs/2411.01213v1

原文摘要:
Text summarization is a well-established task within the natural language
processing (NLP) community. However, the focus on controllable summarization
tailored to user requirements is gaining traction only recently. While several
efforts explore controllability in text summarization, the investigation of
Multi-Attribute Controllable Summarization (MACS) remains limited. This work
addresses this gap by examining the MACS task through the lens of large
language models (LLMs), using various learning paradigms, particularly low-rank
adapters. We experiment with different popular adapter fine-tuning strategies
to assess the effectiveness of the resulting models in retaining cues and
patterns associated with multiple controllable attributes. Additionally, we
propose and evaluate a novel hierarchical adapter fusion technique to integrate
learnings from two distinct controllable attributes. Subsquently, we present
our findings, discuss the challenges encountered, and suggest potential avenues
for advancing the MACS task.

中文翻译:
文本摘要作为自然语言处理（NLP）领域的经典任务已发展成熟，但针对用户需求的可控摘要研究近年才逐渐兴起。尽管已有若干探索文本摘要可控性的研究，多属性可控摘要（MACS）的深入探讨仍显不足。本研究通过大语言模型（LLM）视角填补这一空白，采用多种学习范式（尤以低秩适配器为核心）展开实验。我们测试了不同主流适配器微调策略，评估所得模型在保持多可控属性关联线索与模式方面的有效性，并提出并验证了一种新颖的分层适配器融合技术，用于整合两个独立可控属性的学习成果。最后我们呈现实验发现，讨论面临的挑战，并为推进MACS任务提出潜在发展方向。
