# RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation

链接: http://arxiv.org/abs/2402.04527v1

原文摘要:
Large language models (LLM) have recently emerged as a powerful tool for a
variety of natural language processing tasks, bringing a new surge of combining
LLM with recommendation systems, termed as LLM-based RS. Current approaches
generally fall into two main paradigms, the ID direct usage paradigm and the ID
translation paradigm, noting their core weakness stems from lacking
recommendation knowledge and uniqueness. To address this limitation, we propose
a new paradigm, ID representation, which incorporates pre-trained ID embeddings
into LLMs in a complementary manner. In this work, we present RA-Rec, an
efficient ID representation alignment framework for LLM-based recommendation,
which is compatible with multiple ID-based methods and LLM architectures.
Specifically, we treat ID embeddings as soft prompts and design an innovative
alignment module and an efficient tuning method with tailored data construction
for alignment. Extensive experiments demonstrate RA-Rec substantially
outperforms current state-of-the-art methods, achieving up to 3.0% absolute
HitRate@100 improvements while utilizing less than 10x training data.

中文翻译:
大语言模型（LLM）近期已成为处理各类自然语言任务的重要工具，由此催生了将LLM与推荐系统相结合的新趋势，即基于LLM的推荐系统（LLM-based RS）。现有方法主要遵循两种范式——ID直接使用范式和ID转换范式，但其核心缺陷在于缺乏推荐领域知识及独特性。为突破这一局限，我们提出ID表征新范式，通过互补方式将预训练ID嵌入融入LLM。本研究推出RA-Rec框架，这是一个高效适配LLM推荐任务的ID表征对齐方案，兼容多种基于ID的方法与LLM架构。具体而言，我们将ID嵌入视为软提示，设计了创新的对齐模块、高效微调方法及定制化对齐数据构建策略。大量实验表明，RA-Rec显著超越当前最优方法，在训练数据量不足十倍的情况下，HitRate@100指标绝对提升最高达3.0%。
