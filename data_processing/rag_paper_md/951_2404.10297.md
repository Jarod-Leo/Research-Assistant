# Future Language Modeling from Temporal Document History

链接: http://arxiv.org/abs/2404.10297v1

原文摘要:
Predicting the future is of great interest across many aspects of human
activity. Businesses are interested in future trends, traders are interested in
future stock prices, and companies are highly interested in future
technological breakthroughs. While there are many automated systems for
predicting future numerical data, such as weather, stock prices, and demand for
products, there is relatively little work in automatically predicting textual
data. Humans are interested in textual data predictions because it is a natural
format for our consumption, and experts routinely make predictions in a textual
format (Christensen et al., 2004; Tetlock & Gardner, 2015; Frick, 2015).
However, there has been relatively little formalization of this general problem
in the machine learning or natural language processing communities. To address
this gap, we introduce the task of future language modeling: probabilistic
modeling of texts in the future based on a temporal history of texts. To our
knowledge, our work is the first work to formalize the task of predicting the
future in this way. We show that it is indeed possible to build future language
models that improve upon strong non-temporal language model baselines, opening
the door to working on this important, and widely applicable problem.

中文翻译:
预测未来在人类活动的诸多领域中具有重大意义。企业关注未来趋势，交易者聚焦股票走势，科技公司则高度重视技术突破的前景。尽管针对数值型数据（如气象预报、股价波动、产品需求等）的自动化预测系统已较为成熟，但面向文本数据的自动预测研究却相对匮乏。文本预测之所以备受关注，既因其符合人类自然认知方式，也源于专家们长期以文本形式进行预测分析的传统（Christensen等，2004；Tetlock & Gardner，2015；Frick，2015）。然而在机器学习与自然语言处理领域，这一普适性问题尚未得到系统性建模。为填补这一空白，我们提出了"未来语言建模"任务：基于文本时序历史对未来文本进行概率建模。据我们所知，这是首个以形式化方法构建未来预测框架的研究。实验证明，所构建的未来语言模型能显著超越强非时序基线模型，为这一兼具重要性与广泛适用性的课题开辟了新的研究路径。
