# Helping Big Language Models Protect Themselves: An Enhanced Filtering and Summarization System

链接: http://arxiv.org/abs/2505.01315v1

原文摘要:
The recent growth in the use of Large Language Models has made them
vulnerable to sophisticated adversarial assaults, manipulative prompts, and
encoded malicious inputs. Existing countermeasures frequently necessitate
retraining models, which is computationally costly and impracticable for
deployment. Without the need for retraining or fine-tuning, this study presents
a unique defense paradigm that allows LLMs to recognize, filter, and defend
against adversarial or malicious inputs on their own. There are two main parts
to the suggested framework: (1) A prompt filtering module that uses
sophisticated Natural Language Processing (NLP) techniques, including zero-shot
classification, keyword analysis, and encoded content detection (e.g. base64,
hexadecimal, URL encoding), to detect, decode, and classify harmful inputs; and
(2) A summarization module that processes and summarizes adversarial research
literature to give the LLM context-aware defense knowledge. This approach
strengthens LLMs' resistance to adversarial exploitation by fusing text
extraction, summarization, and harmful prompt analysis. According to
experimental results, this integrated technique has a 98.71% success rate in
identifying harmful patterns, manipulative language structures, and encoded
prompts. By employing a modest amount of adversarial research literature as
context, the methodology also allows the model to react correctly to harmful
inputs with a larger percentage of jailbreak resistance and refusal rate. While
maintaining the quality of LLM responses, the framework dramatically increases
LLM's resistance to hostile misuse, demonstrating its efficacy as a quick and
easy substitute for time-consuming, retraining-based defenses.

中文翻译:
近年来，大型语言模型（LLM）的广泛应用使其面临复杂对抗攻击、操纵性提示和编码恶意输入的威胁。现有防御方案通常需要重新训练模型，不仅计算成本高昂，且实际部署困难。本研究提出了一种无需重新训练或微调的创新防御范式，使LLM能够自主识别、过滤并抵御对抗性或恶意输入。该框架包含两大核心模块：（1）提示过滤模块：采用零样本分类、关键词分析和编码内容检测（如base64、十六进制、URL编码）等先进自然语言处理技术，实现对有害输入的检测、解码与分类；（2）文献摘要模块：通过处理对抗性研究文献并生成摘要，为LLM提供情境感知的防御知识。该方法融合文本提取、摘要生成和恶意提示分析，显著增强了LLM的抗对抗能力。实验表明，该集成技术在识别有害模式、操纵性语言结构和编码提示方面达到98.71%的成功率。通过引入少量对抗研究文献作为上下文，模型对恶意输入的拒绝率与越狱抵抗率显著提升。该框架在保持LLM响应质量的同时，极大增强了模型抗恶意滥用的能力，为耗时耗力的重新训练防御方案提供了高效便捷的替代方案。
