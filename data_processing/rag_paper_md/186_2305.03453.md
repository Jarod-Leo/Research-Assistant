# T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering

链接: http://arxiv.org/abs/2305.03453v1

原文摘要:
Large Language Models (LLMs) have recently demonstrated exceptional
performance in various Natural Language Processing (NLP) tasks. They have also
shown the ability to perform chain-of-thought (CoT) reasoning to solve complex
problems. Recent studies have explored CoT reasoning in complex multimodal
scenarios, such as the science question answering task, by fine-tuning
multimodal models with high-quality human-annotated CoT rationales. However,
collecting high-quality COT rationales is usually time-consuming and costly.
Besides, the annotated rationales are hardly accurate due to the external
essential information missed. To address these issues, we propose a novel
method termed T-SciQ that aims at teaching science question answering with LLM
signals. The T-SciQ approach generates high-quality CoT rationales as teaching
signals and is advanced to train much smaller models to perform CoT reasoning
in complex modalities. Additionally, we introduce a novel data mixing strategy
to produce more effective teaching data samples for simple and complex science
question answer problems. Extensive experimental results show that our T-SciQ
method achieves a new state-of-the-art performance on the ScienceQA benchmark,
with an accuracy of 96.18%. Moreover, our approach outperforms the most
powerful fine-tuned baseline by 4.5%. The code is publicly available at
https://github.com/T-SciQ/T-SciQ.

中文翻译:
大型语言模型（LLMs）近期在各类自然语言处理（NLP）任务中展现出卓越性能，并表现出通过思维链（CoT）推理解决复杂问题的能力。最新研究尝试将CoT推理应用于多模态复杂场景（如科学问答任务），通过微调带有高质量人工标注CoT原理的多模态模型来实现。然而，收集高质量的CoT原理通常耗时且成本高昂，且由于遗漏外部关键信息，标注的推理过程往往不够准确。针对这些问题，我们提出创新方法T-SciQ，利用LLM生成信号进行科学问答教学。该方法通过生成高质量CoT原理作为教学信号，进而训练更小规模的模型在复杂多模态场景中执行CoT推理。此外，我们引入新型数据混合策略，为简单和复杂科学问题生成更有效的教学数据样本。大量实验结果表明，T-SciQ方法在ScienceQA基准测试中以96.18%的准确率创下新纪录，较现有最优微调基线模型提升4.5%。代码已开源：https://github.com/T-SciQ/T-SciQ。
