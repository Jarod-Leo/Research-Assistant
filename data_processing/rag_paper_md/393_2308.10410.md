# Large Language Models on Wikipedia-Style Survey Generation: an Evaluation in NLP Concepts

链接: http://arxiv.org/abs/2308.10410v1

原文摘要:
Educational materials such as survey articles in specialized fields like
computer science traditionally require tremendous expert inputs and are
therefore expensive to create and update. Recently, Large Language Models
(LLMs) have achieved significant success across various general tasks. However,
their effectiveness and limitations in the education domain are yet to be fully
explored. In this work, we examine the proficiency of LLMs in generating
succinct survey articles specific to the niche field of NLP in computer
science, focusing on a curated list of 99 topics. Automated benchmarks reveal
that GPT-4 surpasses its predecessors, inluding GPT-3.5, PaLM2, and LLaMa2 by
margins ranging from 2% to 20% in comparison to the established ground truth.
We compare both human and GPT-based evaluation scores and provide in-depth
analysis. While our findings suggest that GPT-created surveys are more
contemporary and accessible than human-authored ones, certain limitations were
observed. Notably, GPT-4, despite often delivering outstanding content,
occasionally exhibited lapses like missing details or factual errors. At last,
we compared the rating behavior between humans and GPT-4 and found systematic
bias in using GPT evaluation.

中文翻译:
在计算机科学等专业领域中，诸如综述文章之类的教育材料传统上需要大量专家投入，因此创建和更新成本高昂。近期，大语言模型（LLMs）在各种通用任务中取得了显著成功，但其在教育领域的有效性与局限性仍有待全面探索。本研究评估了LLMs在生成计算机科学自然语言处理细分领域（聚焦于99个精选主题）简明综述文章的能力。自动化基准测试显示，相较于既有标准答案，GPT-4以2%至20%的优势超越GPT-3.5、PaLM2和LLaMa2等前代模型。我们对比了人工与GPT评分结果并展开深入分析。研究发现，虽然GPT生成的综述比人工撰写的更具时效性和可读性，但仍存在明显局限：GPT-4尽管常能产出优质内容，但偶尔会出现细节遗漏或事实错误等疏漏。最后，通过对比人类与GPT-4的评分行为，我们发现GPT评估存在系统性偏差。
