# HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models

链接: http://arxiv.org/abs/2412.19925v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing
by understanding and generating human-like text. However, the increasing demand
for more sophisticated LLMs presents significant computational challenges due
to their scale and complexity. This paper introduces Hardware Accelerated
Decoding (HADES), a novel approach to enhance the performance and energy
efficiency of LLMs. We address the design of an LLM accelerator with
hardware-level speculative decoding support, a concept not previously explored
in existing literature. Our work demonstrates how speculative decoding can
significantly improve the efficiency of LLM operations, paving the way for more
advanced and practical applications of these models.

中文翻译:
大型语言模型（LLMs）通过理解与生成类人文本，彻底改变了自然语言处理领域。然而，随着对更复杂LLM需求的增长，其规模与复杂性带来了巨大的计算挑战。本文提出硬件加速解码（HADES）这一创新方法，旨在提升LLM的性能与能效。我们首次在文献中探讨了具有硬件级推测解码支持的LLM加速器设计，证实该技术可显著提升模型运算效率，为LLM更先进、更实用的应用场景开辟了新路径。
