# HADES: Hardware Accelerated Decoding for Efficient Speculation in Large Language Models

链接: http://arxiv.org/abs/2412.19925v1

原文摘要:
Large Language Models (LLMs) have revolutionized natural language processing
by understanding and generating human-like text. However, the increasing demand
for more sophisticated LLMs presents significant computational challenges due
to their scale and complexity. This paper introduces Hardware Accelerated
Decoding (HADES), a novel approach to enhance the performance and energy
efficiency of LLMs. We address the design of an LLM accelerator with
hardware-level speculative decoding support, a concept not previously explored
in existing literature. Our work demonstrates how speculative decoding can
significantly improve the efficiency of LLM operations, paving the way for more
advanced and practical applications of these models.

中文翻译:
大型语言模型（LLMs）通过理解和生成类人文本，彻底改变了自然语言处理领域。然而，随着对更复杂LLMs的需求不断增长，其庞大的规模和复杂性带来了巨大的计算挑战。本文提出硬件加速解码（HADES）这一创新方法，旨在提升LLMs的性能与能效。我们设计了一种支持硬件级推测解码的LLM加速器，这一概念在现有文献中尚未被探索。研究表明，推测解码能显著提升LLM运算效率，为这些模型的更先进、更实用化应用开辟了新途径。

（翻译说明：
1. 专业术语保留英文缩写"LLMs"并首次出现时标注全称，符合学术规范
2. "human-like text"译为"类人文本"既准确又简洁，优于直译"人类似文本"
3. "speculative decoding"统一译为"推测解码"，保持术语一致性
4. 将英文长句合理切分为符合中文表达习惯的短句，如最后一句的拆分处理
5. 被动语态转换为主动表述，如"our work demonstrates"译为"研究表明"
6. 保留技术论文的严谨性，同时使用"开辟新途径"等中文惯用表达增强可读性）
