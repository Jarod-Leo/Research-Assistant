# ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for Interdisciplinary Science

链接: http://arxiv.org/abs/2311.12289v1

原文摘要:
Large language models record impressive performance on many natural language
processing tasks. However, their knowledge capacity is limited to the
pretraining corpus. Retrieval augmentation offers an effective solution by
retrieving context from external knowledge sources to complement the language
model. However, existing retrieval augmentation techniques ignore the
structural relationships between these documents. Furthermore, retrieval models
are not explored much in scientific tasks, especially in regard to the
faithfulness of retrieved documents. In this paper, we propose a novel
structure-aware retrieval augmented language model that accommodates document
structure during retrieval augmentation. We create a heterogeneous document
graph capturing multiple types of relationships (e.g., citation, co-authorship,
etc.) that connect documents from more than 15 scientific disciplines (e.g.,
Physics, Medicine, Chemistry, etc.). We train a graph neural network on the
curated document graph to act as a structural encoder for the corresponding
passages retrieved during the model pretraining. Particularly, along with text
embeddings of the retrieved passages, we obtain structural embeddings of the
documents (passages) and fuse them together before feeding them to the language
model. We evaluate our model extensively on various scientific benchmarks that
include science question-answering and scientific document classification
tasks. Experimental results demonstrate that structure-aware retrieval improves
retrieving more coherent, faithful and contextually relevant passages, while
showing a comparable performance in the overall accuracy.

中文翻译:
大型语言模型在众多自然语言处理任务中展现出卓越性能，但其知识容量受限于预训练语料库。检索增强技术通过从外部知识源获取上下文信息来补充语言模型，提供了有效解决方案。然而现有检索增强方法普遍忽视了文档间的结构关联，且检索模型在科学任务中的应用探索不足，尤其缺乏对检索文档可信度的考量。本文提出一种新型结构感知检索增强语言模型，在检索过程中整合文档结构信息。我们构建了一个涵盖15+学科领域（如物理学、医学、化学等）的异质文档图谱，捕获包括引用、合著关系等多类型关联。通过在该图谱上训练图神经网络，我们为预训练过程中检索到的文本段落生成结构编码表示。具体而言，在输入语言模型前，我们将检索段落的文本嵌入向量与其对应的文档结构嵌入向量进行融合。在科学问答和文献分类等多个科学基准测试上的广泛实验表明：结构感知检索能显著提升检索结果的连贯性、可信度与上下文相关性，同时保持整体准确率的竞争力。
