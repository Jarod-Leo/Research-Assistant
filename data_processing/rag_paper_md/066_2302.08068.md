# LabelPrompt: Effective Prompt-based Learning for Relation Classification

链接: http://arxiv.org/abs/2302.08068v1

原文摘要:
Recently, prompt-based learning has gained popularity across many natural
language processing (NLP) tasks by reformulating them into a cloze-style format
to better align pre-trained language models (PLMs) with downstream tasks.
However, applying this approach to relation classification poses unique
challenges. Specifically, associating natural language words that fill the
masked token with semantic relation labels (\textit{e.g.}
\textit{``org:founded\_by}'') is difficult. To address this challenge, this
paper presents a novel prompt-based learning method, namely LabelPrompt, for
the relation classification task. Motivated by the intuition to ``GIVE MODEL
CHOICES!'', we first define additional tokens to represent relation labels,
which regard these tokens as the verbaliser with semantic initialisation and
explicitly construct them with a prompt template method. Then, to mitigate
inconsistency between predicted relations and given entities, we implement an
entity-aware module with contrastive learning. Last, we conduct an attention
query strategy within the self-attention layer to differentiates prompt tokens
and sequence tokens. Together, these strategies enhance the adaptability of
prompt-based learning, especially when only small labelled datasets is
available. Comprehensive experiments on benchmark datasets demonstrate the
superiority of our method, particularly in the few-shot scenario.

中文翻译:
近年来，基于提示的学习方法通过将自然语言处理任务重构为填空形式，有效弥合了预训练语言模型与下游任务之间的差异，在众多NLP任务中广受青睐。然而，这一范式在关系分类任务中面临独特挑战：如何将掩码位置填充的自然语言词汇与语义关系标签（如“org:founded_by”）准确关联成为关键难题。为此，本文提出了一种创新的提示学习方法LabelPrompt。基于“赋予模型选择权”的核心思想，我们首先定义了一组附加标记来表征关系标签，通过语义初始化将其作为可学习的表述器，并采用提示模板方法进行显式构建。其次，为缓解预测关系与给定实体间的不一致性，我们设计了基于对比学习的实体感知模块。最后，在自注意力层中实施注意力查询策略，以区分提示标记与序列标记。这些策略共同增强了提示学习在标注数据稀缺场景下的适应性。在基准数据集上的全面实验表明，我们的方法尤其在少样本场景下展现出显著优势。
