# PointLLM: Empowering Large Language Models to Understand Point Clouds

链接: http://arxiv.org/abs/2308.16911v1

原文摘要:
The unprecedented advancements in Large Language Models (LLMs) have shown a
profound impact on natural language processing but are yet to fully embrace the
realm of 3D understanding. This paper introduces PointLLM, a preliminary effort
to fill this gap, enabling LLMs to understand point clouds and offering a new
avenue beyond 2D visual data. PointLLM understands colored object point clouds
with human instructions and generates contextually appropriate responses,
illustrating its grasp of point clouds and common sense. Specifically, it
leverages a point cloud encoder with a powerful LLM to effectively fuse
geometric, appearance, and linguistic information. We collect a novel dataset
comprising 660K simple and 70K complex point-text instruction pairs to enable a
two-stage training strategy: aligning latent spaces and subsequently
instruction-tuning the unified model. To rigorously evaluate the perceptual and
generalization capabilities of PointLLM, we establish two benchmarks:
Generative 3D Object Classification and 3D Object Captioning, assessed through
three different methods, including human evaluation, GPT-4/ChatGPT evaluation,
and traditional metrics. Experimental results reveal PointLLM's superior
performance over existing 2D and 3D baselines, with a notable achievement in
human-evaluated object captioning tasks where it surpasses human annotators in
over 50% of the samples. Codes, datasets, and benchmarks are available at
https://github.com/OpenRobotLab/PointLLM .

中文翻译:
大型语言模型（LLMs）的前沿发展对自然语言处理产生了深远影响，但其在三维理解领域的应用仍有待开拓。本文提出PointLLM作为填补这一空白的初步尝试，使LLMs能够理解点云数据，从而开辟了超越二维视觉信息的新路径。该系统通过人类指令理解带颜色的物体点云，并生成符合情境的响应，展现出对点云结构与常识的认知能力。具体而言，PointLLM通过结合点云编码器与高性能LLM，实现了几何特征、外观信息与语言数据的有效融合。我们构建了包含66万条简单指令与7万条复杂指令的点云-文本配对数据集，采用两阶段训练策略：先进行潜在空间对齐，再对统一模型进行指令微调。为系统评估PointLLM的感知与泛化能力，我们建立了生成式三维物体分类和三维物体描述两大基准测试，采用人工评估、GPT-4/ChatGPT评估与传统指标三种方法进行验证。实验结果表明，PointLLM在性能上显著优于现有二维与三维基线模型，其中在人工评估的物体描述任务中，超过50%的样本表现优于人类标注者。相关代码、数据集与基准测试已开源：https://github.com/OpenRobotLab/PointLLM。

（翻译说明：采用技术文献的严谨表述风格，保留专业术语如"潜在空间对齐"、"指令微调"等核心概念；将英文长句合理切分为符合中文表达习惯的短句；"66万条/7万条"等数字表述符合中文计量规范；通过"该系统"等指代保持行文流畅；最后统一处理了技术文档特有的项目地址格式要求。）
