# Fairness Definitions in Language Models Explained

链接: http://arxiv.org/abs/2407.18454v1

原文摘要:
Language Models (LMs) have demonstrated exceptional performance across
various Natural Language Processing (NLP) tasks. Despite these advancements,
LMs can inherit and amplify societal biases related to sensitive attributes
such as gender and race, limiting their adoption in real-world applications.
Therefore, fairness has been extensively explored in LMs, leading to the
proposal of various fairness notions. However, the lack of clear agreement on
which fairness definition to apply in specific contexts (\textit{e.g.,}
medium-sized LMs versus large-sized LMs) and the complexity of understanding
the distinctions between these definitions can create confusion and impede
further progress. To this end, this paper proposes a systematic survey that
clarifies the definitions of fairness as they apply to LMs. Specifically, we
begin with a brief introduction to LMs and fairness in LMs, followed by a
comprehensive, up-to-date overview of existing fairness notions in LMs and the
introduction of a novel taxonomy that categorizes these concepts based on their
foundational principles and operational distinctions. We further illustrate
each definition through experiments, showcasing their practical implications
and outcomes. Finally, we discuss current research challenges and open
questions, aiming to foster innovative ideas and advance the field. The
implementation and additional resources are publicly available at
https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.

中文翻译:
语言模型（LMs）在各类自然语言处理（NLP）任务中展现出卓越性能。然而尽管取得这些进展，语言模型仍可能继承并放大涉及性别、种族等敏感属性的社会偏见，这限制了其在实际场景中的应用。为此，学界对语言模型的公平性问题展开了广泛研究，并提出了多种公平性概念。但由于在特定情境下（如中型语言模型与大型语言模型之间）缺乏对适用公平性定义的明确共识，加之理解这些定义之间差异的复杂性，可能导致混淆并阻碍研究进展。针对这一问题，本文提出一项系统性综述，旨在厘清适用于语言模型的公平性定义框架。具体而言，我们首先简要介绍语言模型及其公平性概念，随后全面梳理当前最新的语言模型公平性定义体系，并通过构建新型分类法，依据基础原理和操作差异对这些概念进行系统归类。我们进一步通过实验演示每种定义的实际应用场景与效果表现。最后，本文探讨了当前研究面临的挑战与开放性问题，以促进创新思路并推动领域发展。相关实现代码与资源已开源：https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions。  

（注：翻译过程中进行了以下专业处理：  
1. 将"medium-sized LMs versus large-sized LMs"译为"中型语言模型与大型语言模型"，符合中文计算机领域术语习惯  
2. "systematic survey"译为"系统性综述"准确体现学术论文类型  
3. 被动语态"have been extensively explored"转化为主动句式"学界...展开了广泛研究"  
4. 长难句拆分重组，如将原文最后复合句分解为三个中文短句，保持学术严谨性的同时提升可读性  
5. 技术术语保持统一："notions"统一译为"概念"，"definitions"统一译为"定义"）
