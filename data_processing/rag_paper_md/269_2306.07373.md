# EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural Language Processing

链接: http://arxiv.org/abs/2306.07373v1

原文摘要:
The utilization of clinical reports for various secondary purposes, including
health research and treatment monitoring, is crucial for enhancing patient
care. Natural Language Processing (NLP) tools have emerged as valuable assets
for extracting and processing relevant information from these reports. However,
the availability of specialized language models for the clinical domain in
Spanish has been limited.
  In this paper, we introduce EriBERTa, a bilingual domain-specific language
model pre-trained on extensive medical and clinical corpora. We demonstrate
that EriBERTa outperforms previous Spanish language models in the clinical
domain, showcasing its superior capabilities in understanding medical texts and
extracting meaningful information. Moreover, EriBERTa exhibits promising
transfer learning abilities, allowing for knowledge transfer from one language
to another. This aspect is particularly beneficial given the scarcity of
Spanish clinical data.

中文翻译:
临床报告在健康研究与治疗监测等二次应用中的利用，对提升患者护理质量至关重要。自然语言处理技术已成为从这些报告中提取和处理关键信息的有效工具。然而，西班牙语临床领域的专用语言模型一直较为匮乏。

本文提出EriBERTa模型，这是一种基于大规模医学临床语料库训练的双语领域专用预训练模型。研究表明，该模型在西班牙语临床文本理解与信息抽取任务上显著优于现有模型，展现出卓越的医学语义理解能力。更值得注意的是，EriBERTa表现出优异的跨语言迁移学习特性，能够实现知识在不同语言间的有效迁移，这一特性在西班牙语临床数据稀缺的背景下具有特殊价值。
