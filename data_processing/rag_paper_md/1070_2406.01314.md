# Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization

链接: http://arxiv.org/abs/2406.01314v1

原文摘要:
The Transformer model has been pivotal in advancing fields such as natural
language processing, speech recognition, and computer vision. However, a
critical limitation of this model is its quadratic computational and memory
complexity relative to the sequence length, which constrains its application to
longer sequences. This is especially crucial in medical imaging where
high-resolution images can reach gigapixel scale. Efforts to address this issue
have predominantely focused on complex techniques, such as decomposing the
softmax operation integral to the Transformer's architecture. This paper
addresses this quadratic computational complexity of Transformer models and
introduces a remarkably simple and effective method that circumvents this issue
by eliminating the softmax function from the attention mechanism and adopting a
sequence normalization technique for the key, query, and value tokens. Coupled
with a reordering of matrix multiplications this approach reduces the memory-
and compute complexity to a linear scale. We evaluate this approach across
various medical imaging datasets comprising fundoscopic, dermascopic,
radiologic and histologic imaging data. Our findings highlight that these
models exhibit a comparable performance to traditional transformer models,
while efficiently handling longer sequences.

中文翻译:
Transformer模型在推动自然语言处理、语音识别和计算机视觉等领域发展方面具有关键作用。然而该模型存在一个根本性缺陷：其计算量和内存消耗会随序列长度呈二次方增长，这限制了其在长序列任务中的应用。这一局限在医学影像领域尤为突出，因为高分辨率图像可能达到十亿像素级别。现有解决方案主要集中于复杂技术，例如分解Transformer架构核心的softmax运算。本文针对Transformer模型的二次计算复杂度问题，提出了一种极其简单有效的解决方法：通过移除注意力机制中的softmax函数，并对键、查询及值向量采用序列归一化技术，配合矩阵乘法运算顺序的优化，将内存和计算复杂度降至线性水平。我们在包含眼底镜、皮肤镜、放射学和组织学等多模态医学影像数据集上进行验证。结果表明，改进后的模型在保持与传统Transformer相当性能的同时，能够高效处理更长序列数据。
