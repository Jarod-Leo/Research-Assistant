# A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs

链接: http://arxiv.org/abs/2502.02896v1

原文摘要:
Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

中文翻译:
在支持知识图谱构建的事实提取等任务中评估大型语言模型（LLMs）时，通常需要基于知识图谱（KG）的基准真值计算准确性指标。这类评估默认误差反映的是事实性分歧。然而人类话语中频繁出现元语言分歧——参与者并非对事实本身存在异议，而是对表述事实的语言含义理解不同。考虑到LLMs进行自然语言处理与生成的复杂性，我们提出疑问：LLMs与KGs之间是否也存在元语言分歧？通过对T-REx知识对齐数据集的实验研究，我们假设LLMs与KGs之间确实存在元语言分歧，这对知识图谱工程实践具有潜在意义。我们提出了一个评估LLMs与KGs间事实性与元语言分歧检测的基准框架，其概念验证版本已在Github平台发布。
