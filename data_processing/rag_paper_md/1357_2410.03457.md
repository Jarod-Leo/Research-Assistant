# CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds

链接: http://arxiv.org/abs/2410.03457v1

原文摘要:
Detecting logical fallacies in texts can help users spot argument flaws, but
automating this detection is not easy. Manually annotating fallacies in
large-scale, real-world text data to create datasets for developing and
validating detection models is costly. This paper introduces CoCoLoFa, the
largest known logical fallacy dataset, containing 7,706 comments for 648 news
articles, with each comment labeled for fallacy presence and type. We recruited
143 crowd workers to write comments embodying specific fallacy types (e.g.,
slippery slope) in response to news articles. Recognizing the complexity of
this writing task, we built an LLM-powered assistant into the workers'
interface to aid in drafting and refining their comments. Experts rated the
writing quality and labeling validity of CoCoLoFa as high and reliable.
BERT-based models fine-tuned using CoCoLoFa achieved the highest fallacy
detection (F1=0.86) and classification (F1=0.87) performance on its test set,
outperforming the state-of-the-art LLMs. Our work shows that combining
crowdsourcing and LLMs enables us to more effectively construct datasets for
complex linguistic phenomena that crowd workers find challenging to produce on
their own.

中文翻译:
检测文本中的逻辑谬误能帮助用户识别论证缺陷，但实现自动化检测并非易事。为开发和验证检测模型，在大规模真实文本数据中人工标注谬误以构建数据集成本高昂。本文介绍了目前规模最大的逻辑谬误数据集CoCoLoFa，包含针对648篇新闻文章的7,706条评论，每条评论均标注了谬误存在与否及其类型。我们招募143名众包工作者，要求他们根据新闻文章撰写体现特定谬误类型（如滑坡谬误）的评论。鉴于该写作任务的复杂性，我们在工作者界面中嵌入了基于大语言模型的辅助工具，协助他们起草和修改评论。专家评估认为CoCoLoFa的写作质量和标注有效性均达到较高可靠度。基于该数据集微调的BERT模型在测试集上取得了最优的谬误检测（F1=0.86）与分类（F1=0.87）性能，超越了当前最先进的大语言模型。研究表明，通过结合众包与大语言模型，我们能更高效地构建针对复杂语言现象的数据集，这些任务若仅靠众包工作者独立完成将极具挑战性。
