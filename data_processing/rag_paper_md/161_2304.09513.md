# NetGPT: Generative Pretrained Transformer for Network Traffic

链接: http://arxiv.org/abs/2304.09513v1

原文摘要:
All data on the Internet are transferred by network traffic, thus accurately
modeling network traffic can help improve network services quality and protect
data privacy. Pretrained models for network traffic can utilize large-scale raw
data to learn the essential characteristics of network traffic, and generate
distinguishable results for input traffic without considering specific
downstream tasks. Effective pretrained models can significantly optimize the
training efficiency and effectiveness of downstream tasks, such as application
classification, attack detection and traffic generation. Despite the great
success of pretraining in natural language processing, there is no work in the
network field. Considering the diverse demands and characteristics of network
traffic and network tasks, it is non-trivial to build a pretrained model for
network traffic and we face various challenges, especially the heterogeneous
headers and payloads in the multi-pattern network traffic and the different
dependencies for contexts of diverse downstream network tasks.
  To tackle these challenges, in this paper, we make the first attempt to
provide a generative pretrained model NetGPT for both traffic understanding and
generation tasks. We propose the multi-pattern network traffic modeling to
construct unified text inputs and support both traffic understanding and
generation tasks. We further optimize the adaptation effect of the pretrained
model to diversified tasks by shuffling header fields, segmenting packets in
flows, and incorporating diverse task labels with prompts. With diverse traffic
datasets from encrypted software, DNS, private industrial protocols and
cryptocurrency mining, expensive experiments demonstrate the effectiveness of
our NetGPT in a range of traffic understanding and generation tasks on traffic
datasets, and outperform state-of-the-art baselines by a wide margin.

中文翻译:
互联网中的所有数据均通过网络流量进行传输，因此准确建模网络流量有助于提升网络服务质量并保障数据隐私。网络流量预训练模型能够利用大规模原始数据学习流量的本质特征，在不考虑具体下游任务的情况下，为输入流量生成可区分的表征结果。高效的预训练模型可显著优化下游任务（如应用分类、攻击检测和流量生成）的训练效率与效果。尽管预训练技术在自然语言处理领域已取得巨大成功，但网络领域尚未出现相关研究。考虑到网络流量与网络任务的多样化需求及特性，构建网络流量预训练模型面临诸多挑战，尤其是多模式网络流量中异构的报文头与载荷部分，以及不同下游网络任务对上下文依赖关系的差异化需求。

为解决这些挑战，本文首次提出面向流量理解与生成任务的双功能生成式预训练模型NetGPT。我们通过多模式网络流量建模技术构建统一文本输入，同时支持流量理解与生成任务；进一步采用报文头字段重排、流内数据包分块、结合提示词的任务标签融合等方法，优化预训练模型对多样化任务的适配效果。基于加密软件、DNS、私有工业协议及加密货币挖矿等多元流量数据集的实验表明，NetGPT在各类流量理解与生成任务中均表现优异，其性能显著超越现有最优基线模型。
