# The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education

链接: http://arxiv.org/abs/2404.02444v1

原文摘要:
Assessing instruction quality is a fundamental component of any improvement
efforts in the education system. However, traditional manual assessments are
expensive, subjective, and heavily dependent on observers' expertise and
idiosyncratic factors, preventing teachers from getting timely and frequent
feedback. Different from prior research that mostly focuses on low-inference
instructional practices on a singular basis, this paper presents the first
study that leverages Natural Language Processing (NLP) techniques to assess
multiple high-inference instructional practices in two distinct educational
settings: in-person K-12 classrooms and simulated performance tasks for
pre-service teachers. This is also the first study that applies NLP to measure
a teaching practice that is widely acknowledged to be particularly effective
for students with special needs. We confront two challenges inherent in
NLP-based instructional analysis, including noisy and long input data and
highly skewed distributions of human ratings. Our results suggest that
pretrained Language Models (PLMs) demonstrate performances comparable to the
agreement level of human raters for variables that are more discrete and
require lower inference, but their efficacy diminishes with more complex
teaching practices. Interestingly, using only teachers' utterances as input
yields strong results for student-centered variables, alleviating common
concerns over the difficulty of collecting and transcribing high-quality
student speech data in in-person teaching settings. Our findings highlight both
the potential and the limitations of current NLP techniques in the education
domain, opening avenues for further exploration.

中文翻译:
评估教学质量是推动教育系统改进的基础环节。然而传统人工评估方式成本高昂、主观性强，且高度依赖观察者的专业素养和个人特质，导致教师难以及时获得高频反馈。与以往大多孤立研究低推断性教学实践不同，本研究首次运用自然语言处理技术，在K-12实体课堂与职前教师模拟教学两种场景中，实现了对多项高推断性教学实践的综合评估。这也是首个应用自然语言处理技术来测量特殊需求学生教学效能的实证研究。针对教学文本分析中固有的两大挑战——输入数据噪声大且篇幅冗长、人工评分分布极度偏态，研究发现：预训练语言模型在离散性强、推断要求低的变量上表现与人类评分者相当，但对复杂教学实践的评估效果显著下降。有趣的是，仅分析教师话语即可对"以学生为中心"的变量实现良好预测，这缓解了实体教学中学生语音数据采集与转写的现实困境。研究成果既揭示了自然语言处理技术在教育领域的应用潜力，也明确了当前技术瓶颈，为后续探索指明了方向。
