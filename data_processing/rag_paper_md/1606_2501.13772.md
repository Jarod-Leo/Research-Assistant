# Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak

链接: http://arxiv.org/abs/2501.13772v1

原文摘要:
Large Language Models (LLMs) demonstrate remarkable zero-shot performance
across various natural language processing tasks. The integration of multimodal
encoders extends their capabilities, enabling the development of Multimodal
Large Language Models that process vision, audio, and text. However, these
capabilities also raise significant security concerns, as these models can be
manipulated to generate harmful or inappropriate content through jailbreak.
While extensive research explores the impact of modality-specific input edits
on text-based LLMs and Large Vision-Language Models in jailbreak, the effects
of audio-specific edits on Large Audio-Language Models (LALMs) remain
underexplored. Hence, this paper addresses this gap by investigating how
audio-specific edits influence LALMs inference regarding jailbreak. We
introduce the Audio Editing Toolbox (AET), which enables audio-modality edits
such as tone adjustment, word emphasis, and noise injection, and the Edited
Audio Datasets (EADs), a comprehensive audio jailbreak benchmark. We also
conduct extensive evaluations of state-of-the-art LALMs to assess their
robustness under different audio edits. This work lays the groundwork for
future explorations on audio-modality interactions in LALMs security.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越的零样本性能。通过集成多模态编码器，其能力进一步扩展，催生了能够处理视觉、音频和文本的多模态大语言模型。然而，这些能力也引发了重大安全隐患——攻击者可能通过越狱手段操控模型生成有害或不恰当内容。尽管现有研究已深入探讨文本模态输入编辑对纯文本LLMs及大型视觉语言模型在越狱攻击中的影响，但音频特定编辑对大型音频语言模型（LALMs）的作用机制仍缺乏系统研究。为此，本文针对这一空白展开研究，系统分析音频编辑技术如何影响LALMs在越狱场景下的推理行为。我们提出了音频编辑工具箱（AET），支持音调调整、词语强调和噪声注入等音频模态编辑操作，并构建了综合性音频越狱基准数据集（EADs）。通过对前沿LALMs的广泛评估，本文量化了不同音频编辑策略下模型的鲁棒性表现，为后续音频模态安全研究奠定了方法论基础。
