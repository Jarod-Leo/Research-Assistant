# Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning

链接: http://arxiv.org/abs/2310.14596v1

原文摘要:
Fine-grained entity typing (FET) is an essential task in natural language
processing that aims to assign semantic types to entities in text. However, FET
poses a major challenge known as the noise labeling problem, whereby current
methods rely on estimating noise distribution to identify noisy labels but are
confused by diverse noise distribution deviation. To address this limitation,
we introduce Co-Prediction Prompt Tuning for noise correction in FET, which
leverages multiple prediction results to identify and correct noisy labels.
Specifically, we integrate prediction results to recall labeled labels and
utilize a differentiated margin to identify inaccurate labels. Moreover, we
design an optimization objective concerning divergent co-predictions during
fine-tuning, ensuring that the model captures sufficient information and
maintains robustness in noise identification. Experimental results on three
widely-used FET datasets demonstrate that our noise correction approach
significantly enhances the quality of various types of training samples,
including those annotated using distant supervision, ChatGPT, and
crowdsourcing.

中文翻译:
细粒度实体类型标注（FET）是自然语言处理中的一项核心任务，旨在为文本中的实体分配语义类型。然而该任务面临噪声标签问题的重大挑战——现有方法虽通过估计噪声分布来识别错误标签，却常因噪声分布偏差的多样性而失效。为此，我们提出协同预测提示调优的噪声校正方法，通过整合多重预测结果实现噪声标签的识别与修正。具体而言，我们融合多维度预测结果召回已标注标签，并采用差异化边界机制识别不准确标注；同时设计微调过程中针对预测分歧的优化目标，确保模型捕获充分信息的同时保持噪声识别的鲁棒性。在三个主流FET数据集上的实验表明，我们的噪声校正方法能显著提升远程监督、ChatGPT标注和众包数据等各类训练样本的质量。
