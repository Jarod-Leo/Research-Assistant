# Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning

链接: http://arxiv.org/abs/2310.14596v1

原文摘要:
Fine-grained entity typing (FET) is an essential task in natural language
processing that aims to assign semantic types to entities in text. However, FET
poses a major challenge known as the noise labeling problem, whereby current
methods rely on estimating noise distribution to identify noisy labels but are
confused by diverse noise distribution deviation. To address this limitation,
we introduce Co-Prediction Prompt Tuning for noise correction in FET, which
leverages multiple prediction results to identify and correct noisy labels.
Specifically, we integrate prediction results to recall labeled labels and
utilize a differentiated margin to identify inaccurate labels. Moreover, we
design an optimization objective concerning divergent co-predictions during
fine-tuning, ensuring that the model captures sufficient information and
maintains robustness in noise identification. Experimental results on three
widely-used FET datasets demonstrate that our noise correction approach
significantly enhances the quality of various types of training samples,
including those annotated using distant supervision, ChatGPT, and
crowdsourcing.

中文翻译:
以下是符合要求的学术中文翻译：

细粒度实体类型标注（FET）是自然语言处理中的一项核心任务，旨在为文本中的实体分配语义类型。然而，FET面临着一个关键挑战——噪声标签问题：现有方法通过估计噪声分布来识别噪声标签，但会因噪声分布的多样性偏差而失效。为突破这一局限，我们提出基于协同预测提示微调的噪声校正方法（Co-Prediction Prompt Tuning），通过整合多重预测结果实现噪声标签的识别与校正。具体而言，我们融合多维度预测结果召回已标注标签，并采用差异化边界阈值识别不准确标签。此外，在微调过程中设计了针对预测分歧的优化目标，确保模型既能捕获充分信息，又能保持噪声识别的鲁棒性。在三个主流FET数据集上的实验表明，我们的噪声校正方法能显著提升各类训练样本（包括远程监督标注、ChatGPT生成和众包标注样本）的质量。

翻译说明：
1. 专业术语处理：采用"细粒度实体类型标注"标准译法，"distant supervision"译为"远程监督"等学界通用表述
2. 被动语态转换：将英文被动结构转换为中文主动句式（如"are confused by"译为"会因...而失效"）
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句
4. 概念显化："differentiated margin"译为"差异化边界阈值"以明确技术含义
5. 学术风格保持：使用"旨在""面临""突破""确保"等规范学术用语
6. 括号使用：首次出现FET时标注全称，符合中文论文惯例
