# Learning to Prompt in the Classroom to Understand AI Limits: A pilot study

链接: http://arxiv.org/abs/2307.01540v1

原文摘要:
Artificial intelligence's (AI) progress holds great promise in tackling
pressing societal concerns such as health and climate. Large Language Models
(LLM) and the derived chatbots, like ChatGPT, have highly improved the natural
language processing capabilities of AI systems allowing them to process an
unprecedented amount of unstructured data. However, the ensuing excitement has
led to negative sentiments, even as AI methods demonstrate remarkable
contributions (e.g. in health and genetics). A key factor contributing to this
sentiment is the misleading perception that LLMs can effortlessly provide
solutions across domains, ignoring their limitations such as hallucinations and
reasoning constraints. Acknowledging AI fallibility is crucial to address the
impact of dogmatic overconfidence in possibly erroneous suggestions generated
by LLMs. At the same time, it can reduce fear and other negative attitudes
toward AI. This necessitates comprehensive AI literacy interventions that
educate the public about LLM constraints and effective usage techniques, i.e
prompting strategies. With this aim, a pilot educational intervention was
performed in a high school with 21 students. It involved presenting high-level
concepts about intelligence, AI, and LLMs, followed by practical exercises
involving ChatGPT in creating natural educational conversations and applying
established prompting strategies. Encouraging preliminary results emerged,
including high appreciation of the activity, improved interaction quality with
the LLM, reduced negative AI sentiments, and a better grasp of limitations,
specifically unreliability, limited understanding of commands leading to
unsatisfactory responses, and limited presentation flexibility. Our aim is to
explore AI acceptance factors and refine this approach for more controlled
future studies.

中文翻译:
人工智能（AI）的进步在应对健康与气候等紧迫社会问题方面展现出巨大潜力。以ChatGPT为代表的大语言模型（LLM）及其衍生的聊天机器人，显著提升了AI系统的自然语言处理能力，使其能够处理前所未有的非结构化数据。然而，随之而来的热潮也引发了负面情绪——尽管AI方法已在健康与遗传学等领域展现出卓越贡献。这种情绪的关键诱因在于人们错误地认为LLM能轻松提供跨领域解决方案，却忽视了其存在幻觉与推理局限等缺陷。

承认AI的可错性至关重要，这既能消解人们对LLM可能产生错误建议的盲目自信，也能缓解对AI的恐惧等消极态度。为此需要开展全面的AI素养教育，向公众普及LLM的局限性及有效使用技巧（即提示策略）。基于此目标，研究团队在某高中对21名学生实施了试点教育：先讲解智力、AI与LLM的高阶概念，再通过ChatGPT实操练习创建自然教育对话并应用成熟提示策略。

初步成果令人鼓舞：活动获得高度评价，学生与LLM的交互质量提升，对AI的负面情绪减少，并更清晰地认识到三大局限——答案不可靠性、指令理解偏差导致低质回复，以及呈现方式缺乏灵活性。本研究旨在探索AI接受度影响因素，为未来更严谨的实证研究优化方法论。
