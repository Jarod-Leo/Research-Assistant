# Prompt Learning for News Recommendation

链接: http://arxiv.org/abs/2304.05263v1

原文摘要:
Some recent \textit{news recommendation} (NR) methods introduce a Pre-trained
Language Model (PLM) to encode news representation by following the vanilla
pre-train and fine-tune paradigm with carefully-designed
recommendation-specific neural networks and objective functions. Due to the
inconsistent task objective with that of PLM, we argue that their modeling
paradigm has not well exploited the abundant semantic information and
linguistic knowledge embedded in the pre-training process. Recently, the
pre-train, prompt, and predict paradigm, called \textit{prompt learning}, has
achieved many successes in natural language processing domain. In this paper,
we make the first trial of this new paradigm to develop a \textit{Prompt
Learning for News Recommendation} (Prompt4NR) framework, which transforms the
task of predicting whether a user would click a candidate news as a cloze-style
mask-prediction task. Specifically, we design a series of prompt templates,
including discrete, continuous, and hybrid templates, and construct their
corresponding answer spaces to examine the proposed Prompt4NR framework.
Furthermore, we use the prompt ensembling to integrate predictions from
multiple prompt templates. Extensive experiments on the MIND dataset validate
the effectiveness of our Prompt4NR with a set of new benchmark results.

中文翻译:
近期一些\textit{新闻推荐}（NR）方法通过采用预训练语言模型（PLM）编码新闻表征，遵循传统的预训练-微调范式，并精心设计了推荐专用的神经网络结构和目标函数。然而，由于任务目标与PLM的原始目标不一致，我们认为现有建模范式未能充分利用预训练过程中蕴含的丰富语义信息和语言学知识。最近，被称为\textit{提示学习}的"预训练-提示-预测"范式在自然语言处理领域取得显著成功。本文首次尝试将该新范式应用于新闻推荐任务，提出\textit{基于提示学习的新闻推荐框架}（Prompt4NR），将预测用户是否点击候选新闻的任务转化为填空式掩码预测任务。具体而言，我们设计了一系列提示模板（包括离散型、连续型和混合型模板），构建相应的答案空间以验证Prompt4NR框架的有效性，并采用提示集成方法融合多模板的预测结果。在MIND数据集上的大量实验表明，该框架能取得一系列新的基准性能，验证了Prompt4NR的优越性。
