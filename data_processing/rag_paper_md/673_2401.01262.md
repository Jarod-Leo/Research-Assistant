# Fairness Certification for Natural Language Processing and Large Language Models

链接: http://arxiv.org/abs/2401.01262v1

原文摘要:
Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization.

中文翻译:
自然语言处理（NLP）在我们的日常生活中扮演着重要角色，尤其是随着大语言模型（LLM）的飞速发展。然而，NLP涉及诸多对公平性要求极高的应用场景，例如作为招聘领域的专家系统或教育中基于LLM的辅导工具。由于NLP基于人类语言，潜在有害的偏见可能渗入系统，导致不公正的结果、歧视少数群体或引发法律问题。因此，建立NLP方法的公平性认证体系至关重要。

本研究采用定性研究方法探索NLP公平性认证路径。通过系统梳理大量算法公平性文献，并与该领域多位专家进行半结构化访谈，我们最终构建了包含6项核心准则的NLP公平性框架，这些准则可进一步细分为18个子类别。该框架为审计方与被审计组织提供了实施公平性测试与认证的操作基础，既涵盖了认证流程的可操作性标准，也确立了系统性验证的规范依据。
