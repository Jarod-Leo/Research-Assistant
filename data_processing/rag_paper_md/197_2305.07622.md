# PALR: Personalization Aware LLMs for Recommendation

链接: http://arxiv.org/abs/2305.07622v1

原文摘要:
Large language models (LLMs) have recently received significant attention for
their exceptional capabilities. Despite extensive efforts in developing
general-purpose LLMs that can be utilized in various natural language
processing (NLP) tasks, there has been less research exploring their potential
in recommender systems. In this paper, we propose a novel framework, named
PALR, which aiming to combine user history behaviors (such as clicks,
purchases, ratings, etc.) with LLMs to generate user preferred items.
Specifically, we first use user/item interactions as guidance for candidate
retrieval. Then we adopt a LLM-based ranking model to generate recommended
items. Unlike existing approaches that typically adopt general-purpose LLMs for
zero/few-shot recommendation testing or training on small-sized language models
(with less than 1 billion parameters), which cannot fully elicit LLMs'
reasoning abilities and leverage rich item side parametric knowledge, we
fine-tune a 7 billion parameters LLM for the ranking purpose. This model takes
retrieval candidates in natural language format as input, with instruction
which explicitly asking to select results from input candidates during
inference. Our experimental results demonstrate that our solution outperforms
state-of-the-art models on various sequential recommendation tasks.

中文翻译:
大型语言模型（LLMs）近期因其卓越能力受到广泛关注。尽管已有大量研究致力于开发适用于各类自然语言处理（NLP）任务的通用LLMs，但探索其在推荐系统中潜力的研究仍较为有限。本文提出名为PALR的创新框架，旨在将用户历史行为（如点击、购买、评分等）与LLMs相结合以生成用户偏好物品。具体而言，我们首先以用户/物品交互作为候选检索的引导，随后采用基于LLM的排序模型生成推荐物品。与现有方法通常采用通用LLMs进行零样本/少样本推荐测试，或训练参数规模小于10亿的小型语言模型（这些方法无法充分激发LLMs的推理能力及利用丰富的物品侧参数知识）不同，我们针对排序任务对70亿参数的LLM进行微调。该模型以自然语言格式的检索候选作为输入，并通过指令明确要求在推理时从输入候选中选择结果。实验结果表明，我们的解决方案在多种序列推荐任务上均优于当前最先进的模型。
