# Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT

链接: http://arxiv.org/abs/2405.04053v1

原文摘要:
This research examines the effectiveness of OpenAI's GPT models as
independent evaluators of text summaries generated by six transformer-based
models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.
We evaluated these summaries based on essential properties of high-quality
summary - conciseness, relevance, coherence, and readability - using
traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,
we also employed GPT not as a summarizer but as an evaluator, allowing it to
independently assess summary quality without predefined metrics. Our analysis
revealed significant correlations between GPT evaluations and traditional
metrics, particularly in assessing relevance and coherence. The results
demonstrate GPT's potential as a robust tool for evaluating text summaries,
offering insights that complement established metrics and providing a basis for
comparative analysis of transformer-based models in natural language processing
tasks.

中文翻译:
本研究探讨了OpenAI的GPT模型作为独立评估工具的有效性，用于评价六种基于Transformer的Hugging Face模型（DistilBART、BERT、ProphetNet、T5、BART和PEGASUS）生成的文本摘要质量。我们从高质量摘要的核心特性——简洁性、相关性、连贯性和可读性——出发，采用ROUGE和潜在语义分析（LSA）等传统指标进行评估。创新性地，我们将GPT模型不作为摘要生成器，而是作为评估工具，使其能够脱离预设指标独立评判摘要质量。分析表明，GPT的评估结果与传统指标（尤其在相关性和连贯性维度）存在显著相关性。研究结果证实了GPT作为文本摘要评估工具的潜力，其提供的洞见既是对传统指标的有效补充，也为基于Transformer的自然语言处理模型比较分析提供了新范式。  

（翻译说明：  
1. 专业术语保留英文缩写（如GPT/ROUGE/LSA）并首次出现时标注全称  
2. 将"transformer-based models"译为"基于Transformer的模型"以保持技术准确性  
3. "concise, relevant, coherent, readable"四维度采用"简洁性、相关性、连贯性、可读性"的标准译法  
4. 被动语态转换为中文主动表达（如"were evaluated"译为"采用...进行评估"）  
5. 长句拆分重组（如最后两句按语义层次重新划分），符合中文段落节奏  
6. "complement established metrics"译为"对传统指标的有效补充"，通过增译强化逻辑关系）
