# Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models

链接: http://arxiv.org/abs/2404.03921v1

原文摘要:
Sentence Embedding stands as a fundamental task within the realm of Natural
Language Processing, finding extensive application in search engines, expert
systems, and question-and-answer platforms. With the continuous evolution of
large language models such as LLaMA and Mistral, research on sentence embedding
has recently achieved notable breakthroughs. However, these advancements mainly
pertain to fine-tuning scenarios, leaving explorations into computationally
efficient direct inference methods for sentence representation in a nascent
stage. This paper endeavors to bridge this research gap. Through comprehensive
experimentation, we challenge the widely held belief in the necessity of an
Explicit One-word Limitation for deriving sentence embeddings from Pre-trained
Language Models (PLMs). We demonstrate that this approach, while beneficial for
generative models under direct inference scenario, is not imperative for
discriminative models or the fine-tuning of generative PLMs. This discovery
sheds new light on the design of manual templates in future studies. Building
upon this insight, we propose two innovative prompt engineering techniques
capable of further enhancing the expressive power of PLMs' raw embeddings:
Pretended Chain of Thought and Knowledge Enhancement. We confirm their
effectiveness across various PLM types and provide a detailed exploration of
the underlying factors contributing to their success.

中文翻译:
句子嵌入（Sentence Embedding）是自然语言处理领域的一项基础性任务，在搜索引擎、专家系统和问答平台中具有广泛应用。随着LLaMA、Mistral等大语言模型的持续演进，句子嵌入研究近期取得了显著突破。然而这些进展主要集中于微调场景，对于计算高效的直接推理式句子表征方法仍处于探索初期。本文致力于填补这一研究空白。

通过系统性实验，我们挑战了"必须采用显式单字限制（Explicit One-word Limitation）才能从预训练语言模型（PLMs）获取句子嵌入"这一普遍认知。研究表明：虽然该策略在直接推理场景下对生成式模型有益，但对于判别式模型或生成式PLMs的微调场景并非必要。这一发现为未来研究中人工模板的设计提供了新思路。

基于此洞见，我们进一步提出两种能增强PLMs原始嵌入表达力的创新提示工程技术：伪思维链（Pretended Chain of Thought）与知识增强（Knowledge Enhancement）。实验证实这些方法在多种PLMs上均有效，并通过详细分析揭示了其成功背后的关键因素。
