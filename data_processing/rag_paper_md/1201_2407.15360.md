# Dissecting Multiplication in Transformers: Insights into LLMs

链接: http://arxiv.org/abs/2407.15360v1

原文摘要:
Transformer-based large language models have achieved remarkable performance
across various natural language processing tasks. However, they often struggle
with seemingly easy tasks like arithmetic despite their vast capabilities. This
stark disparity raise human's concerns about their safe and ethical use, hinder
their widespread adoption.In this paper, we focus on a typical arithmetic task,
integer multiplication, to explore and explain the imperfection of transformers
in this domain. We provide comprehensive analysis of a vanilla transformer
trained to perform n-digit integer multiplication. Our observations indicate
that the model decomposes multiplication task into multiple parallel subtasks,
sequentially optimizing each subtask for each digit to complete the final
multiplication. Based on observation and analysis, we infer the reasons of
transformers deficiencies in multiplication tasks lies in their difficulty in
calculating successive carryovers and caching intermediate results, and
confirmed this inference through experiments. Guided by these findings, we
propose improvements to enhance transformers performance on multiplication
tasks. These enhancements are validated through rigorous testing and
mathematical modeling, not only enhance transformer's interpretability, but
also improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit
integer multiplication with a tiny transformer, outperform LLMs GPT-4. Our
method contributes to the broader fields of model understanding and
interpretability, paving the way for analyzing more complex tasks and
Transformer models. This work underscores the importance of explainable AI,
helping to build trust in large language models and promoting their adoption in
critical applications.

中文翻译:
基于Transformer架构的大规模语言模型在各类自然语言处理任务中展现出卓越性能，然而面对算术运算这类看似简单的任务时却屡屡受挫。这种能力反差引发了对其安全伦理应用的担忧，也阻碍了其广泛应用。本文聚焦整数乘法这一典型算术任务，系统探究并阐释了Transformer在该领域的性能缺陷。我们通过对标准Transformer执行n位数乘法运算的全面分析，发现模型将乘法任务分解为多个并行子任务，通过逐位优化各子任务来完成最终运算。基于观测分析，我们推断其乘法缺陷源于连续进位计算与中间结果缓存的双重困境，并通过实验验证了这一推断。基于这些发现，我们提出了针对性的改进方案，经严格测试与数学建模验证，不仅增强了模型可解释性，更显著提升了计算性能——例如使用微型Transformer即可实现五位数乘法99.9%以上的准确率，超越GPT-4等大型语言模型。本方法为模型理解与可解释性研究提供了新思路，为分析更复杂任务及Transformer模型开辟了路径。这项工作凸显了可解释AI的重要性，有助于增强对大语言模型的信任，推动其在关键领域的应用落地。
