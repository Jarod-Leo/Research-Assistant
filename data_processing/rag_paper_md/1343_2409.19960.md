# TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning

链接: http://arxiv.org/abs/2409.19960v1

原文摘要:
Zero-shot inference, where pre-trained models perform tasks without specific
training data, is an exciting emergent ability of large models like CLIP.
Although there has been considerable exploration into enhancing zero-shot
abilities in image captioning (IC) for popular datasets such as MSCOCO and
Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,
UCM-Captions, and Sydney-Captions. These datasets require captions to discern
between visually and semantically similar classes, focusing on detailed object
parts and their attributes. To overcome this challenge, we introduce
TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption
with additional object-part details using object detector proposals and Natural
Language Processing techniques. It complements rather than alters the base
caption, allowing seamless integration with other captioning methods and
offering users enhanced flexibility. Our evaluations show that TROPE
consistently boosts performance across all tested zero-shot IC approaches and
achieves state-of-the-art results on fine-grained IC datasets.

中文翻译:
零样本推理，即预训练模型无需特定训练数据即可执行任务，是如CLIP等大型模型令人瞩目的新兴能力。尽管针对MSCOCO和Flickr8k等流行数据集，图像描述生成（IC）领域的零样本能力增强已得到广泛探索，但这些方法在CUB、FLO、UCM-Captions和Sydney-Captions等细粒度数据集上表现欠佳。这类数据集要求描述能区分视觉与语义相似的类别，重点关注物体局部细节及其属性特征。为应对这一挑战，我们提出无需训练的对象局部增强方法TROPE。该方法通过目标检测提案和自然语言处理技术，在基础描述中补充物体局部细节信息。TROPE并非替换而是扩展基础描述，可与其他描述生成方法无缝结合，为用户提供更高灵活性。实验表明，TROPE在所有测试的零样本IC方法中均能稳定提升性能，并在细粒度IC数据集上取得了最先进的结果。
