# Scaling Auditory Cognition via Test-Time Compute in Audio Language Models

链接: http://arxiv.org/abs/2503.23395v1

原文摘要:
Large language models (LLMs) have shown exceptional versatility in natural
language processing, prompting recent efforts to extend their multimodal
capabilities to speech processing through the development of audio large
language models (Audio LLMs). While Audio LLMs excel in tasks such as speech
recognition and synthesis, it remains unclear how they perform when faced with
the auditory cognitive challenges posed by real-world environments, such as
audio comprehension and listening recall, particularly in the presence of
background noise or overlapping speech. Unlike text-based LLMs, which have
access to vast amounts of text data for pre-training, retraining Audio LLMs
with diverse auditory cognitive scenes is difficult due to the limited datasets
that simulate real-world auditory cognitive scenarios and the challenge of
acquiring auditory cognitive labels for training. While test-time compute (TTC)
methods have been shown to enhance the capabilities of text-based LLMs during
inference, a key challenge lies in designing these TTC methods to improve the
auditory capabilities of Audio LLMs. This study aims to address these two
research gaps by: i) exploring the auditory cognitive capabilities of Audio
LLMs, and ii) enhancing their capabilities using TTC approaches. We have
investigated five different Audio LLMs for auditory cognition using a
\textit{self-collected} database and have proposed five TTC approaches to
enhance auditory cognitive capabilities during inference. Our findings reveal
that Audio LLMs performance decreases in more challenging auditory cognitive
tasks. The proposed TTC approaches significantly enhance cognitive auditory
capabilities, advancing the development of more adaptable and resilient Audio
LLMs for practical applications such as assistive listening devices,
voice-based AI assistants, and communication technologies.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）在自然语言处理领域展现出卓越的通用性，这促使研究者近期致力于通过开发音频大语言模型（Audio LLMs）将其多模态能力扩展至语音处理领域。尽管Audio LLMs在语音识别与合成等任务中表现优异，但其面对真实环境中听觉认知挑战（如音频理解与听忆任务）时的性能仍不明确，特别是在存在背景噪声或重叠语音的情况下。与基于文本的LLMs能够获取海量预训练数据不同，由于模拟真实听觉认知场景的数据集稀缺且听觉认知标签获取困难，对Audio LLMs进行多样化听觉认知场景的再训练极具挑战性。虽然测试时计算（TTC）方法已被证明能增强文本LLMs的推理能力，但如何设计适用于提升Audio LLMs听觉能力的TTC方法仍是关键难题。本研究旨在通过以下两方面解决上述研究空白：1）探究Audio LLMs的听觉认知能力；2）利用TTC方法增强其性能。我们采用自建数据库对五种Audio LLMs进行听觉认知评估，并提出五种TTC方法在推理阶段提升听觉认知能力。研究发现Audio LLMs在更具挑战性的听觉认知任务中性能显著下降，而提出的TTC方法能有效增强认知听觉能力。这一进展推动了适应性更强、鲁棒性更优的Audio LLMs发展，对助听设备、语音AI助手及通信技术等实际应用具有重要意义。

翻译说明：
1. 专业术语处理：
- "test-time compute (TTC)" 译为"测试时计算（TTC）"并保留英文缩写
- "self-collected" 译为"自建"以符合学术用语习惯
- "auditory cognitive labels" 译为"听觉认知标签"保持专业准确性

2. 句式重构：
- 将英语长句拆分为符合中文表达习惯的短句（如第一段复合句的拆分）
- 被动语态转换为主动表述（如"it remains unclear"译为"仍不明确"）
- 学术用语规范化处理（如"versatility"译为"通用性"而非字面直译）

3. 概念对应性：
- "listening recall" 译为"听忆任务"以区分于普通记忆概念
- "resilient" 译为"鲁棒性"符合计算机领域术语

4. 逻辑显化：
- 添加"这一进展"作为段落衔接词，增强行文连贯性
- 使用中文惯用的冒号引导列举项（如"以下两方面"的表述）

译文严格遵循学术摘要的客观性要求，在保持原文信息密度的同时，通过专业术语统一和句式优化确保技术内容的准确传达。
