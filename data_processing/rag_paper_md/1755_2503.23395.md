# Scaling Auditory Cognition via Test-Time Compute in Audio Language Models

链接: http://arxiv.org/abs/2503.23395v1

原文摘要:
Large language models (LLMs) have shown exceptional versatility in natural
language processing, prompting recent efforts to extend their multimodal
capabilities to speech processing through the development of audio large
language models (Audio LLMs). While Audio LLMs excel in tasks such as speech
recognition and synthesis, it remains unclear how they perform when faced with
the auditory cognitive challenges posed by real-world environments, such as
audio comprehension and listening recall, particularly in the presence of
background noise or overlapping speech. Unlike text-based LLMs, which have
access to vast amounts of text data for pre-training, retraining Audio LLMs
with diverse auditory cognitive scenes is difficult due to the limited datasets
that simulate real-world auditory cognitive scenarios and the challenge of
acquiring auditory cognitive labels for training. While test-time compute (TTC)
methods have been shown to enhance the capabilities of text-based LLMs during
inference, a key challenge lies in designing these TTC methods to improve the
auditory capabilities of Audio LLMs. This study aims to address these two
research gaps by: i) exploring the auditory cognitive capabilities of Audio
LLMs, and ii) enhancing their capabilities using TTC approaches. We have
investigated five different Audio LLMs for auditory cognition using a
\textit{self-collected} database and have proposed five TTC approaches to
enhance auditory cognitive capabilities during inference. Our findings reveal
that Audio LLMs performance decreases in more challenging auditory cognitive
tasks. The proposed TTC approaches significantly enhance cognitive auditory
capabilities, advancing the development of more adaptable and resilient Audio
LLMs for practical applications such as assistive listening devices,
voice-based AI assistants, and communication technologies.

中文翻译:
大型语言模型（LLM）在自然语言处理领域展现出卓越的通用性，这促使研究者近期致力于通过开发音频大语言模型（Audio LLM）将其多模态能力扩展至语音处理。尽管Audio LLM在语音识别与合成等任务中表现优异，但其面对真实环境中的听觉认知挑战（如音频理解与听忆任务）时的性能仍不明确，尤其是在存在背景噪声或重叠语音的情况下。与基于文本的LLM可利用海量文本数据进行预训练不同，由于模拟真实听觉认知场景的数据集稀缺且听觉认知标签获取困难，对Audio LLM进行多样化听觉认知场景的再训练极具挑战性。虽然测试时计算（TTC）方法已被证明能增强文本LLM的推理能力，但如何设计适用于提升Audio LLM听觉能力的TTC方法仍是关键难题。本研究旨在解决这两个研究空白：1）探索Audio LLM的听觉认知能力；2）利用TTC方法增强其能力。我们通过自建数据库评估了五种Audio LLM的听觉认知表现，并提出了五种TTC推理增强方法。实验表明，Audio LLM在复杂听觉认知任务中性能显著下降，而所提TTC方法能有效提升其认知听觉能力，这对开发适用于助听设备、语音AI助手及通信技术等实际场景的适应性更强、鲁棒性更好的Audio LLM具有重要推进作用。
