# Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate

链接: http://arxiv.org/abs/2305.11595v1

原文摘要:
Large Language Models (LLMs) have shown impressive capabilities in various
applications, but they still face various inconsistency issues. Existing works
primarily focus on the inconsistency issues within a single LLM, while we
complementarily explore the inter-consistency among multiple LLMs for
collaboration. To examine whether LLMs can collaborate effectively to achieve a
consensus for a shared goal, we focus on commonsense reasoning, and introduce a
formal debate framework (FORD) to conduct a three-stage debate among LLMs with
real-world scenarios alignment: fair debate, mismatched debate, and roundtable
debate. Through extensive experiments on various datasets, LLMs can effectively
collaborate to reach a consensus despite noticeable inter-inconsistencies, but
imbalances in their abilities can lead to domination by superior LLMs.
Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost
collaboration performance. Our work contributes to understanding the
inter-consistency among LLMs and lays the foundation for developing future
collaboration methods. Codes and data are available at
https://github.com/Waste-Wood/FORD

中文翻译:
大型语言模型（LLMs）在各类应用中展现出卓越能力，但仍面临诸多不一致性问题。现有研究主要关注单一模型内部的不一致，而本文创新性地探索了多LLM协作时的相互一致性。为验证LLMs能否通过有效协作达成共识目标，我们聚焦常识推理任务，提出形式化辩论框架FORD，通过三阶段辩论（公平辩论、错位辩论、圆桌辩论）实现与现实场景的对齐。大量实验表明：尽管存在显著的不一致性，LLMs仍能有效协作达成共识，但能力失衡会导致优势模型主导讨论。引入GPT-4等先进模型作为权威裁判可显著提升协作效能。本研究为理解LLM间一致性提供了新视角，为未来协作方法开发奠定基础。代码与数据详见https://github.com/Waste-Wood/FORD。
