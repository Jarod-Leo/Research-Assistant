# A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks

链接: http://arxiv.org/abs/2307.12114v1

原文摘要:
We evaluate four state-of-the-art instruction-tuned large language models
(LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13
real-world clinical and biomedical natural language processing (NLP) tasks in
English, such as named-entity recognition (NER), question-answering (QA),
relation extraction (RE), etc. Our overall results demonstrate that the
evaluated LLMs begin to approach performance of state-of-the-art models in
zero- and few-shot scenarios for most tasks, and particularly well for the QA
task, even though they have never seen examples from these tasks before.
However, we observed that the classification and RE tasks perform below what
can be achieved with a specifically trained model for the medical field, such
as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all
the studied tasks, with some models being better suited for certain tasks than
others.

中文翻译:
我们评估了四种先进的指令调优大语言模型（LLMs）——ChatGPT、Flan-T5 UL2、Tk-Instruct和Alpaca——在13个英语临床与生物医学自然语言处理（NLP）真实任务中的表现，包括命名实体识别（NER）、问答（QA）、关系抽取（RE）等。总体结果表明，尽管这些LLMs此前从未接触过相关任务示例，但在零样本和小样本场景下，其性能已开始接近大多数任务的最先进模型水平，尤其在QA任务上表现突出。然而，我们发现分类和RE任务的性能仍低于专为医学领域（如PubMedBERT）定制的训练模型。最后值得注意的是，没有任何一个LLM能在所有研究任务中全面超越其他模型，不同模型对特定任务表现出各自的优势。
