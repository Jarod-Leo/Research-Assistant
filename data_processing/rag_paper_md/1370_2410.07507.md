# Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)

链接: http://arxiv.org/abs/2410.07507v1

原文摘要:
Decoding and expressing brain activity in a comprehensible form is a
challenging frontier in AI. This paper presents Thought2Text, which uses
instruction-tuned Large Language Models (LLMs) fine-tuned with EEG data to
achieve this goal. The approach involves three stages: (1) training an EEG
encoder for visual feature extraction, (2) fine-tuning LLMs on image and text
data, enabling multimodal description generation, and (3) further fine-tuning
on EEG embeddings to generate text directly from EEG during inference.
Experiments on a public EEG dataset collected for six subjects with image
stimuli and text captions demonstrate the efficacy of multimodal LLMs
(LLaMA-v3, Mistral-v0.3, Qwen2.5), validated using traditional language
generation evaluation metrics, as well as fluency and adequacy measures. This
approach marks a significant advancement towards portable, low-cost
"thoughts-to-text" technology with potential applications in both neuroscience
and natural language processing.

中文翻译:
将大脑活动解码并以可理解的形式表达，是人工智能领域一项极具挑战性的前沿课题。本文提出的Thought2Text系统通过指令调优的大型语言模型（LLMs）结合脑电图（EEG）数据微调实现了这一目标。该方法包含三个阶段：（1）训练EEG编码器提取视觉特征；（2）在图像和文本数据上微调LLMs，使其具备多模态描述生成能力；（3）基于EEG嵌入向量进一步微调，实现推理阶段直接从EEG生成文本。在包含六名受试者观看图像刺激并配文标注的公开EEG数据集上，实验验证了多模态LLMs（LLaMA-v3、Mistral-v0.3、Qwen2.5）的有效性，评估指标涵盖传统语言生成指标以及流畅度与适切性度量。该研究标志着向便携式、低成本"思维转文本"技术迈出重要一步，在神经科学和自然语言处理领域均具有应用潜力。
