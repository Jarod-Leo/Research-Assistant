# Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance

链接: http://arxiv.org/abs/2501.11849v1

原文摘要:
Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

中文翻译:
检测有组织的政治宣传对于打击社交媒体上的虚假信息至关重要。现有识别此类协同行动的方法主要运用网络科学、图机器学习和自然语言处理技术，其核心在于分析用户间的关联互动（如转发行为）及其发布内容的文本相似性。尽管这些方法在识别"草根营销"活动上表现有效，但仍面临重大挑战——尤其是训练数据集中普遍存在的类别不平衡问题。为缓解这一局限，现有研究通常采用数据增强或增加正样本数量等策略，但这些方案在实际场景中往往难以实施或收效有限。

本文另辟蹊径，提出了一种完全基于大语言模型（LLMs）的新型检测框架，创新性地引入了平衡检索增强生成（Balanced RAG）组件。该框架首先将社交媒体帖子（本文以推文为例）的文本信息与用户交互网络共同输入语言模型，随后通过提示工程与平衡RAG方法的协同作用，有效识别X平台（原Twitter）上的协同造谣活动。该框架无需对语言模型进行任何训练或微调，而是通过策略性地结合提示工程与平衡RAG的优势，使LLMs能够克服类别不平衡的影响，精准识别协同政治宣传活动。

实验结果表明：采用本文提出的提示工程与平衡RAG方法后，新框架在准确率、召回率和F1分数上均超越传统基于图结构的基线方法2-3倍，展现出显著性能提升。
