# Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code

链接: http://arxiv.org/abs/2405.20611v1

原文摘要:
Detecting vulnerabilities within compiled binaries is challenging due to lost
high-level code structures and other factors such as architectural
dependencies, compilers, and optimization options. To address these obstacles,
this research explores vulnerability detection using natural language
processing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn
semantics from intermediate representation (LLVM IR) code. Long short-term
memory (LSTM) neural networks were trained on embeddings from encoders created
using approximately 48k LLVM functions from the Juliet dataset. This study is
pioneering in its comparison of word2vec models with multiple bidirectional
transformers (BERT, RoBERTa) embeddings built using LLVM code to train neural
networks to detect vulnerabilities in compiled binaries. Word2vec Skip-Gram
models achieved 92% validation accuracy in detecting vulnerabilities,
outperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. This
suggests that complex contextual embeddings may not provide advantages over
simpler word2vec models for this task when a limited number (e.g. 48K) of data
samples are used to train the bidirectional transformer-based models. The
comparative results provide novel insights into selecting optimal embeddings
for learning compiler-independent semantic code representations to advance
machine learning detection of vulnerabilities in compiled binaries.

中文翻译:
由于高层代码结构的丢失以及架构依赖性、编译器和优化选项等因素的影响，检测已编译二进制文件中的漏洞具有挑战性。为应对这些难题，本研究探索利用自然语言处理（NLP）嵌入技术（包括word2vec、BERT和RoBERTa）从中间表示代码（LLVM IR）中学习语义特征进行漏洞检测。基于Juliet数据集中约4.8万个LLVM函数生成的编码器嵌入，我们训练了长短期记忆（LSTM）神经网络。该研究首次系统比较了word2vec模型与多种基于LLVM代码构建的双向变换器（BERT、RoBERTa）嵌入在训练神经网络检测二进制文件漏洞方面的表现。实验表明，word2vec的Skip-Gram模型在漏洞检测中达到92%的验证准确率，优于word2vec的连续词袋模型（CBOW）、BERT和RoBERTa。这说明当用于训练基于双向变换器模型的数据样本量有限（如4.8万条）时，复杂的上下文嵌入可能不会比简单的word2vec模型更具优势。这些对比结果为选择最佳嵌入方法提供了新见解，有助于学习编译器无关的语义代码表示，从而推动机器学习在已编译二进制文件漏洞检测领域的发展。

（翻译说明：采用技术论文的标准表述方式，通过拆分长句、调整语序确保专业术语准确；保留"LLVM IR"等专业缩写；将"48k"转换为中文数字规范；使用"连续词袋模型"等学界通用译法；通过"这表明""实验表明"等衔接词保持逻辑连贯；最后一句采用"推动...发展"的主动句式强化结论表述。）
