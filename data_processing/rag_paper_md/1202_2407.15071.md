# Relational Database Augmented Large Language Model

链接: http://arxiv.org/abs/2407.15071v1

原文摘要:
Large language models (LLMs) excel in many natural language processing (NLP)
tasks. However, since LLMs can only incorporate new knowledge through training
or supervised fine-tuning processes, they are unsuitable for applications that
demand precise, up-to-date, and private information not available in the
training corpora. This precise, up-to-date, and private information is
typically stored in relational databases. Thus, a promising solution is to
augment LLMs with the inclusion of relational databases as external memory.
This can ensure the timeliness, correctness, and consistency of data, and
assist LLMs in performing complex arithmetic operations beyond their inherent
capabilities. However, bridging the gap between LLMs and relational databases
is challenging. It requires the awareness of databases and data values stored
in databases to select correct databases and issue correct SQL queries.
Besides, it is necessary for the external memory to be independent of the LLM
to meet the needs of real-world applications. We introduce a novel LLM-agnostic
memory architecture comprising a database selection memory, a data value
memory, and relational databases. And we design an elegant pipeline to retrieve
information from it. Besides, we carefully design the prompts to instruct the
LLM to maximize the framework's potential. To evaluate our method, we compose a
new dataset with various types of questions. Experimental results show that our
framework enables LLMs to effectively answer database-related questions, which
is beyond their direct ability.

中文翻译:
大型语言模型（LLMs）在众多自然语言处理（NLP）任务中表现卓越。然而，由于LLMs仅能通过训练或有监督的微调过程整合新知识，它们并不适用于需要精确、最新且训练语料库中未包含的私有信息的应用场景。这类精确、实时且私密的信息通常存储于关系型数据库中。因此，一种可行的解决方案是将关系数据库作为外部记忆模块增强LLMs的能力，从而确保数据的时效性、准确性和一致性，并辅助LLMs执行超出其固有能力的复杂算术运算。

但弥合LLMs与关系数据库之间的鸿沟面临诸多挑战：需要具备数据库感知能力及对存储数据值的认知，以正确选择数据库并生成准确的SQL查询语句；同时外部记忆模块必须独立于LLM架构，以满足实际应用需求。我们提出了一种与LLM无关的新型记忆架构，包含数据库选择记忆、数据值记忆和关系数据库三个组件，并设计了高效的信息检索流程。此外，通过精心设计的提示词（prompts）来引导LLM充分发挥该框架的潜力。

为评估该方法，我们构建了包含多类问题的新数据集。实验结果表明，该框架能有效帮助LLMs回答超出其直接能力范围的数据库相关问题。
