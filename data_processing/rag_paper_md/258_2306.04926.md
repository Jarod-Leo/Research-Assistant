# covLLM: Large Language Models for COVID-19 Biomedical Literature

链接: http://arxiv.org/abs/2306.04926v1

原文摘要:
The COVID-19 pandemic led to 1.1 million deaths in the United States, despite
the explosion of coronavirus research. These new findings are slow to translate
to clinical interventions, leading to poorer patient outcomes and unnecessary
deaths. One reason is that clinicians, overwhelmed by patients, struggle to
keep pace with the rate of new coronavirus literature. A potential solution is
developing a tool for evaluating coronavirus literature using large language
models (LLMs) -- neural networks that are deployed for natural language
processing. LLMs can be used to summarize and extract user-specified
information. The greater availability and advancement of LLMs and pre-processed
coronavirus literature databases provide the opportunity to assist clinicians
in evaluating coronavirus literature through a coronavirus literature specific
LLM (covLLM), a tool that directly takes an inputted research article and a
user query to return an answer. Using the COVID-19 Open Research Dataset
(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of
handwritten prompts and synthetic prompts generated using OpenAI, and (2) real
abstracts, which contains abstract and title pairs. covLLM was trained with
LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca
and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real
abstract datasets. These models were evaluated by two human evaluators and
ChatGPT. Results demonstrate that training covLLM on the synCovid and abstract
pairs datasets performs competitively with ChatGPT and outperforms covLLM
trained primarily using the Alpaca dataset.

中文翻译:
尽管新冠病毒研究呈爆炸式增长，但COVID-19大流行仍导致美国110万人死亡。这些新发现转化为临床干预的速度缓慢，导致患者预后较差和不必要的死亡。一个重要原因是临床医生因患者数量激增而疲于应对，难以跟上新冠文献的更新速度。潜在解决方案是开发一种利用大语言模型（LLMs）评估新冠文献的工具——这类神经网络专为自然语言处理而设计，能够总结和提取用户指定信息。随着LLMs技术的日益普及与进步，以及预处理新冠文献数据库的发展，我们有机会通过专门的新冠文献LLM工具（covLLM）协助临床医生评估文献。该工具可直接接收输入的研究论文和用户查询，返回相应答案。

基于COVID-19开放研究数据集（CORD-19），我们构建了两个数据集：（1）synCovid（结合人工编写提示与OpenAI生成的合成提示）；（2）真实摘要（包含摘要与标题配对）。以LLaMA 7B作为基线模型，我们训练出三个covLLM变体：分别基于（1）Alpaca与synCovid数据集、（2）仅synCovid数据集、（3）synCovid与真实摘要数据集。经两位人工评估员和ChatGPT测试表明，在synCovid和真实摘要组合数据集上训练的covLLM性能与ChatGPT相当，且显著优于主要基于Alpaca数据集训练的模型。
