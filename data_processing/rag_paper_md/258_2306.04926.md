# covLLM: Large Language Models for COVID-19 Biomedical Literature

链接: http://arxiv.org/abs/2306.04926v1

原文摘要:
The COVID-19 pandemic led to 1.1 million deaths in the United States, despite
the explosion of coronavirus research. These new findings are slow to translate
to clinical interventions, leading to poorer patient outcomes and unnecessary
deaths. One reason is that clinicians, overwhelmed by patients, struggle to
keep pace with the rate of new coronavirus literature. A potential solution is
developing a tool for evaluating coronavirus literature using large language
models (LLMs) -- neural networks that are deployed for natural language
processing. LLMs can be used to summarize and extract user-specified
information. The greater availability and advancement of LLMs and pre-processed
coronavirus literature databases provide the opportunity to assist clinicians
in evaluating coronavirus literature through a coronavirus literature specific
LLM (covLLM), a tool that directly takes an inputted research article and a
user query to return an answer. Using the COVID-19 Open Research Dataset
(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of
handwritten prompts and synthetic prompts generated using OpenAI, and (2) real
abstracts, which contains abstract and title pairs. covLLM was trained with
LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca
and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real
abstract datasets. These models were evaluated by two human evaluators and
ChatGPT. Results demonstrate that training covLLM on the synCovid and abstract
pairs datasets performs competitively with ChatGPT and outperforms covLLM
trained primarily using the Alpaca dataset.

中文翻译:
尽管冠状病毒研究呈爆炸式增长，但COVID-19大流行仍导致美国110万人死亡。这些新发现转化为临床干预措施的速度缓慢，导致患者预后较差和本可避免的死亡。一个重要原因是：超负荷工作的临床医生难以跟上冠状病毒新文献的产出速度。潜在解决方案是开发基于大语言模型（LLMs）的冠状病毒文献评估工具——这类神经网络专为自然语言处理而设计，能够总结和提取用户指定信息。随着LLMs技术的进步及预处理冠状病毒文献数据库的普及，我们有机会通过冠状病毒专用大语言模型（covLLM）协助临床医生评估文献。该工具可直接接收输入的研究论文和用户查询，返回相应答案。

基于COVID-19开放研究数据集（CORD-19），我们构建了两个数据集：（1）synCovid（结合人工编写提示与OpenAI生成的合成提示）；（2）真实摘要（包含摘要与标题配对）。以LLaMA 7B作为基线模型，我们训练出三个covLLM变体：（1）Alpaca+synCovid联合训练模型；（2）纯synCovid训练模型；（3）synCovid+真实摘要联合训练模型。经两位人类评估员和ChatGPT测试表明：在synCovid和真实摘要数据集上训练的covLLM性能与ChatGPT相当，且显著优于主要基于Alpaca数据集训练的模型。

（注：根据学术翻译规范，对原文进行了以下处理：
1. 将被动语态转换为中文主动表述（如"are slow to translate"译为"转化速度缓慢"）
2. 专业术语保留英文缩写并首次出现时标注全称（LLMs）
3. 长句拆分重组（如最后一句拆分为两个逻辑层次）
4. 概念性表述补充说明（如"预处理的冠状病毒文献数据库"）
5. 保持数值表述准确性（110万））
