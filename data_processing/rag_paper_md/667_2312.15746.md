# Large Language Models are Not Stable Recommender Systems

链接: http://arxiv.org/abs/2312.15746v1

原文摘要:
With the significant successes of large language models (LLMs) in many
natural language processing tasks, there is growing interest among researchers
in exploring LLMs for novel recommender systems. However, we have observed that
directly using LLMs as a recommender system is usually unstable due to its
inherent position bias. To this end, we introduce exploratory research and find
consistent patterns of positional bias in LLMs that influence the performance
of recommendation across a range of scenarios. Then, we propose a Bayesian
probabilistic framework, STELLA (Stable LLM for Recommendation), which involves
a two-stage pipeline. During the first probing stage, we identify patterns in a
transition matrix using a probing detection dataset. And in the second
recommendation stage, a Bayesian strategy is employed to adjust the biased
output of LLMs with an entropy indicator. Therefore, our framework can
capitalize on existing pattern information to calibrate instability of LLMs,
and enhance recommendation performance. Finally, extensive experiments clearly
validate the effectiveness of our framework.

中文翻译:
随着大语言模型（LLM）在众多自然语言处理任务中取得显著成功，研究者们日益关注如何利用LLM构建新型推荐系统。然而我们发现，直接采用LLM作为推荐系统往往因其固有的位置偏差而表现不稳定。为此，我们通过探索性研究发现了LLM中影响多场景推荐效果的位置偏差一致性规律，进而提出贝叶斯概率框架STELLA（稳定推荐大模型）。该框架采用两阶段处理流程：在探测阶段，我们通过探测数据集识别状态转移矩阵中的规律模式；在推荐阶段，则运用贝叶斯策略配合熵值指标对LLM的偏差输出进行校准。该框架能充分利用既有模式信息来消除LLM的不稳定性，从而提升推荐性能。最终，大量实验充分验证了我们框架的有效性。
