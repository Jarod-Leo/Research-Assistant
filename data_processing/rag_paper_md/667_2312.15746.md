# Large Language Models are Not Stable Recommender Systems

链接: http://arxiv.org/abs/2312.15746v1

原文摘要:
With the significant successes of large language models (LLMs) in many
natural language processing tasks, there is growing interest among researchers
in exploring LLMs for novel recommender systems. However, we have observed that
directly using LLMs as a recommender system is usually unstable due to its
inherent position bias. To this end, we introduce exploratory research and find
consistent patterns of positional bias in LLMs that influence the performance
of recommendation across a range of scenarios. Then, we propose a Bayesian
probabilistic framework, STELLA (Stable LLM for Recommendation), which involves
a two-stage pipeline. During the first probing stage, we identify patterns in a
transition matrix using a probing detection dataset. And in the second
recommendation stage, a Bayesian strategy is employed to adjust the biased
output of LLMs with an entropy indicator. Therefore, our framework can
capitalize on existing pattern information to calibrate instability of LLMs,
and enhance recommendation performance. Finally, extensive experiments clearly
validate the effectiveness of our framework.

中文翻译:
随着大语言模型（LLM）在众多自然语言处理任务中取得显著成功，研究者们日益关注如何利用LLM构建新型推荐系统。然而我们发现，由于LLM固有的位置偏差特性，直接将其作为推荐系统通常会导致结果不稳定。为此，我们通过探索性研究发现了LLM中普遍存在的位置偏差模式，这些模式会持续影响不同场景下的推荐性能。基于此，我们提出了贝叶斯概率框架STELLA（面向推荐的稳定大语言模型），该框架采用两阶段处理流程：在初始探测阶段，我们通过探测数据集识别状态转移矩阵中的偏差模式；在后续推荐阶段，则采用贝叶斯策略配合熵值指标对LLM的偏差输出进行校准。该框架能够充分利用已发现的模式信息来消除LLM的不稳定性，从而提升推荐性能。最终，大量实验充分验证了我们框架的有效性。

（翻译说明：
1. 专业术语处理："position bias"译为"位置偏差"符合计算机领域术语规范，"transition matrix"保留数学概念译为"状态转移矩阵"
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"which involves..."处理为独立分句
3. 被动语态转换：将"is employed"等被动式转为"采用"的主动表达
4. 概念显化："probing detection dataset"译为"探测数据集"时补充"数据"范畴词
5. 术语一致性：全篇统一"LLM"与"大语言模型"的对应关系
6. 技术表述准确性：严格区分"adjust"（校准）与"calibrate"（消除）的差异）
