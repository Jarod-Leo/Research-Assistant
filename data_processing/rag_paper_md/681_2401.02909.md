# Introducing Bode: A Fine-Tuned Large Language Model for Portuguese Prompt-Based Task

链接: http://arxiv.org/abs/2401.02909v1

原文摘要:
Large Language Models (LLMs) are increasingly bringing advances to Natural
Language Processing. However, low-resource languages, those lacking extensive
prominence in datasets for various NLP tasks, or where existing datasets are
not as substantial, such as Portuguese, already obtain several benefits from
LLMs, but not to the same extent. LLMs trained on multilingual datasets
normally struggle to respond to prompts in Portuguese satisfactorily,
presenting, for example, code switching in their responses. This work proposes
a fine-tuned LLaMA 2-based model for Portuguese prompts named Bode in two
versions: 7B and 13B. We evaluate the performance of this model in
classification tasks using the zero-shot approach with in-context learning, and
compare it with other LLMs. Our main contribution is to bring an LLM with
satisfactory results in the Portuguese language, as well as to provide a model
that is free for research or commercial purposes.

中文翻译:
大型语言模型（LLMs）正日益推动自然语言处理领域的进步。然而，对于资源匮乏的语言（即在各类NLP任务数据集中缺乏广泛代表性，或现有数据集规模不足的语言，如葡萄牙语），虽然已从LLMs中获益良多，但成效仍有限。基于多语言数据集训练的LLMs通常难以对葡萄牙语提示给出令人满意的响应，例如会出现回答中的语码混杂现象。本研究提出了一个基于LLaMA 2的葡萄牙语微调模型Bode，包含7B和13B两个版本。我们采用零样本学习结合上下文学习的方法评估该模型在分类任务中的表现，并与其他LLMs进行对比。主要贡献在于推出一个能提供优质葡萄牙语处理效果的LLM，同时提供可免费用于研究或商业用途的模型。
