# A Prompting-Based Representation Learning Method for Recommendation with Large Language Models

链接: http://arxiv.org/abs/2409.16674v1

原文摘要:
In recent years, Recommender Systems (RS) have witnessed a transformative
shift with the advent of Large Language Models (LLMs) in the field of Natural
Language Processing (NLP). Models such as GPT-3.5/4, Llama, have demonstrated
unprecedented capabilities in understanding and generating human-like text. The
extensive information pre-trained by these LLMs allows for the potential to
capture a more profound semantic representation from different contextual
information of users and items.
  While the great potential lies behind the thriving of LLMs, the challenge of
leveraging user-item preferences from contextual information and its alignment
with the improvement of Recommender Systems needs to be addressed. Believing
that a better understanding of the user or item itself can be the key factor in
improving recommendation performance, we conduct research on generating
informative profiles using state-of-the-art LLMs.
  To boost the linguistic abilities of LLMs in Recommender Systems, we
introduce the Prompting-Based Representation Learning Method for Recommendation
(P4R). In our P4R framework, we utilize the LLM prompting strategy to create
personalized item profiles. These profiles are then transformed into semantic
representation spaces using a pre-trained BERT model for text embedding.
Furthermore, we incorporate a Graph Convolution Network (GCN) for collaborative
filtering representation. The P4R framework aligns these two embedding spaces
in order to address the general recommendation tasks. In our evaluation, we
compare P4R with state-of-the-art Recommender models and assess the quality of
prompt-based profile generation.

中文翻译:
近年来，随着自然语言处理（NLP）领域大型语言模型（LLMs）的出现，推荐系统（RS）经历了革命性变革。GPT-3.5/4、Llama等模型在理解和生成类人文本方面展现出前所未有的能力。这些LLMs通过海量信息预训练，能够从用户与项目的多维度上下文信息中捕捉更深层次的语义表征。

尽管LLMs的蓬勃发展蕴含着巨大潜力，但如何从上下文信息中提取用户-项目偏好，并将其与推荐系统优化相融合仍面临挑战。我们认为深入理解用户或项目本体是提升推荐性能的关键因素，因此采用前沿LLMs开展信息型画像生成研究。

为增强LLMs在推荐系统中的语言处理能力，我们提出基于提示学习的推荐表征学习方法（P4R）。该框架运用LLM提示策略构建个性化项目画像，通过预训练BERT模型将画像转化为语义表征空间。同时整合图卷积网络（GCN）实现协同过滤表征，通过双表征空间对齐完成通用推荐任务。实验评估中，P4R与前沿推荐模型进行了性能对比，并对提示式画像生成质量进行了系统评测。
