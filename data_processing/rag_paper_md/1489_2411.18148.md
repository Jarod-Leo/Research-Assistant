# A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs

链接: http://arxiv.org/abs/2411.18148v1

原文摘要:
Transformer neural networks (TNN) excel in natural language processing (NLP),
machine translation, and computer vision (CV) without relying on recurrent or
convolutional layers. However, they have high computational and memory demands,
particularly on resource-constrained devices like FPGAs. Moreover, transformer
models vary in processing time across applications, requiring custom models
with specific parameters. Designing custom accelerators for each model is
complex and time-intensive. Some custom accelerators exist with no runtime
adaptability, and they often rely on sparse matrices to reduce latency.
However, hardware designs become more challenging due to the need for
application-specific sparsity patterns. This paper introduces ADAPTOR, a
runtime-adaptive accelerator for dense matrix computations in transformer
encoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing
elements and on-chip memory, enhancing parallelism and reducing latency. It
incorporates efficient matrix tiling to distribute resources across FPGA
platforms and is fully quantized for computational efficiency and portability.
Evaluations on Xilinx Alveo U55C data center cards and embedded platforms like
VC707 and ZCU102 show that our design is 1.2$\times$ and 2.87$\times$ more
power efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively.
Additionally, it achieves a speedup of 1.7 to 2.25$\times$ compared to some
state-of-the-art FPGA-based accelerators.

中文翻译:
Transformer神经网络（TNN）在不依赖循环或卷积层的情况下，于自然语言处理（NLP）、机器翻译和计算机视觉（CV）领域表现卓越。然而，其计算与内存需求较高，尤其在FPGA等资源受限设备上更为显著。此外，Transformer模型在不同应用中的处理时间各异，需定制具有特定参数的模型。为每种模型设计专用加速器不仅复杂且耗时。现有部分定制加速器缺乏运行时适应性，且常依赖稀疏矩阵以降低延迟，但硬件设计因需适配特定应用的稀疏模式而更具挑战性。本文提出ADAPTOR——一种面向FPGA上Transformer编码器与解码器中稠密矩阵计算的运行时自适应加速器。该方案通过提升处理单元与片上内存利用率，增强并行性并减少延迟，采用高效矩阵分块技术分配FPGA平台资源，并实现全量化以优化计算效率与可移植性。在Xilinx Alveo U55C数据中心卡及VC707、ZCU102等嵌入式平台上的测试表明，本设计能效分别较NVIDIA K80 GPU和i7-8700K CPU提升1.2倍与2.87倍，相比部分前沿FPGA加速器更可获得1.7至2.25倍的性能加速。
