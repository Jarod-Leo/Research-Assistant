# LP-MusicCaps: LLM-Based Pseudo Music Captioning

链接: http://arxiv.org/abs/2307.16372v1

原文摘要:
Automatic music captioning, which generates natural language descriptions for
given music tracks, holds significant potential for enhancing the understanding
and organization of large volumes of musical data. Despite its importance,
researchers face challenges due to the costly and time-consuming collection
process of existing music-language datasets, which are limited in size. To
address this data scarcity issue, we propose the use of large language models
(LLMs) to artificially generate the description sentences from large-scale tag
datasets. This results in approximately 2.2M captions paired with 0.5M audio
clips. We term it Large Language Model based Pseudo music caption dataset,
shortly, LP-MusicCaps. We conduct a systemic evaluation of the large-scale
music captioning dataset with various quantitative evaluation metrics used in
the field of natural language processing as well as human evaluation. In
addition, we trained a transformer-based music captioning model with the
dataset and evaluated it under zero-shot and transfer-learning settings. The
results demonstrate that our proposed approach outperforms the supervised
baseline model.

中文翻译:
自动音乐描述技术旨在为给定音乐曲目生成自然语言描述，其在提升海量音乐数据的理解与组织方面具有重要潜力。尽管该技术意义重大，但研究者们面临现有音乐-语言数据集规模有限且采集过程成本高昂、耗时巨大的挑战。为解决数据稀缺问题，我们提出利用大语言模型（LLMs）从大规模标签数据集中人工生成描述语句，最终构建了包含约220万条描述文本与50万条音频片段配对的伪音乐描述数据集（简称LP-MusicCaps）。我们采用自然语言处理领域的多种定量评估指标结合人工评测，对该大规模音乐描述数据集进行了系统性评估。此外，基于该数据集训练了基于Transformer架构的音乐描述模型，并在零样本和迁移学习场景下进行验证。实验结果表明，我们提出的方法显著优于有监督基线模型。
