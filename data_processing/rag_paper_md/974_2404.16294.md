# LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications

链接: http://arxiv.org/abs/2404.16294v1

原文摘要:
Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.

中文翻译:
电子健康记录（EHR）虽为医疗从业者带来便利，但其内容日益复杂冗长。从这些繁冗的EHR中筛选信息不仅耗费精力，更成为医患互动中的沉重负担。尽管已有多种方法尝试通过摘要生成或章节划分来缓解这一普遍问题，但真正有效的解决方案寥寥无几。随着自动化技术的兴起，机器学习（ML）在识别EHR相关章节任务中展现出潜力，但大多数ML方法依赖标注数据——这在医疗领域获取难度极高。相比之下，大语言模型（LLM）在自然语言处理（NLP）领域展现出惊人能力，甚至能以零样本（zero-shot）方式（即无需任何标注数据）完成任务。为此，我们提出利用LLM识别相关章节标题。研究发现，GPT-4在零样本和少样本（few-shot）设定下均能有效完成任务，其分割效果显著优于现有最优方法。此外，我们还标注了一个更具挑战性的真实世界数据集，发现GPT-4表现欠佳，这提示该领域需要进一步研究并建立更严格的基准测试。
