# Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective

链接: http://arxiv.org/abs/2411.14258v1

原文摘要:
Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

中文翻译:
大型语言模型（LLMs）彻底改变了基于自然语言处理（NLP）的应用，包括自动文本生成、问答系统、聊天机器人等。然而，它们面临一个重大挑战：幻觉现象，即模型生成看似合理但事实错误的回答。这削弱了信任，并限制了LLMs在不同领域的适用性。另一方面，知识图谱（KGs）以实体（节点）及其关系（边）的形式提供了结构化、互联的事实集合。近期研究中，KGs被用于填补LLMs对特定主题理解的空白，为缓解LLMs的幻觉问题提供了可行方案，在保持其广泛适用性的同时提升了可靠性与准确性。尽管如此，这仍是一个活跃的研究领域，存在诸多未解决的开放性问题。本文探讨了这些开放挑战，涵盖前沿数据集与基准测试、知识整合方法及幻觉评估技术。在讨论中，我们分析了KGs在LLM系统中的当前应用，并针对每项挑战提出了未来研究方向。
