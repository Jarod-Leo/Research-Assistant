# Graph Reasoning with Large Language Models via Pseudo-code Prompting

链接: http://arxiv.org/abs/2409.17906v1

原文摘要:
Large language models (LLMs) have recently achieved remarkable success in
various reasoning tasks in the field of natural language processing. This
success of LLMs has also motivated their use in graph-related tasks. Among
others, recent work has explored whether LLMs can solve graph problems such as
counting the number of connected components of a graph or computing the
shortest path distance between two nodes. Although LLMs possess preliminary
graph reasoning abilities, they might still struggle to solve some seemingly
simple problems. In this paper, we investigate whether prompting via
pseudo-code instructions can improve the performance of LLMs in solving graph
problems. Our experiments demonstrate that using pseudo-code instructions
generally improves the performance of all considered LLMs. The graphs,
pseudo-code prompts, and evaluation code are publicly available.

中文翻译:
近期，大型语言模型（LLMs）在自然语言处理领域的各类推理任务中取得了显著成功。这一成就也激发了研究者将其应用于图相关任务的探索。其中，最新研究尝试让LLMs解决诸如计算图的连通分量数量或节点间最短路径距离等图论问题。尽管LLMs已展现出初步的图推理能力，但在处理某些看似简单的问题时仍存在困难。本文通过实验验证：采用伪代码指令提示是否能提升LLMs解决图论问题的性能。结果表明，伪代码提示策略普遍提高了所有测试模型的性能。相关图数据、伪代码提示模板及评估代码已开源。
