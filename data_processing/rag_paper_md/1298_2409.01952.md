# Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor

链接: http://arxiv.org/abs/2409.01952v1

原文摘要:
Deep neural networks (DNNs) have long been recognized as vulnerable to
backdoor attacks. By providing poisoned training data in the fine-tuning
process, the attacker can implant a backdoor into the victim model. This
enables input samples meeting specific textual trigger patterns to be
classified as target labels of the attacker's choice. While such black-box
attacks have been well explored in both computer vision and natural language
processing (NLP), backdoor attacks relying on white-box attack philosophy have
hardly been thoroughly investigated. In this paper, we take the first step to
introduce a new type of backdoor attack that conceals itself within the
underlying model architecture. Specifically, we propose to design separate
backdoor modules consisting of two functions: trigger detection and noise
injection. The add-on modules of model architecture layers can detect the
presence of input trigger tokens and modify layer weights using Gaussian noise
to disturb the feature distribution of the baseline model. We conduct extensive
experiments to evaluate our attack methods using two model architecture
settings on five different large language datasets. We demonstrate that the
training-free architectural backdoor on a large language model poses a genuine
threat. Unlike the-state-of-art work, it can survive the rigorous fine-tuning
and retraining process, as well as evade output probability-based defense
methods (i.e. BDDR). All the code and data is available
https://github.com/SiSL-URI/Arch_Backdoor_LLM.

中文翻译:
深度神经网络（DNNs）长期以来被认为易受后门攻击。通过在微调过程中提供被污染的训练数据，攻击者能将后门植入受害者模型，使得符合特定文本触发模式的输入样本被分类为攻击者预设的目标标签。尽管这类黑盒攻击在计算机视觉和自然语言处理（NLP）领域已有充分研究，但基于白盒攻击理念的后门攻击尚未得到深入探索。本文首次提出一种新型后门攻击，将攻击机制隐藏于底层模型架构中。具体而言，我们设计了由触发检测和噪声注入两个功能组成的独立后门模块，这些附加在模型架构层的模块能检测输入触发词的存在，并通过高斯噪声修改层权重以干扰基线模型的特征分布。我们在五种不同的大规模语言数据集上采用两种模型架构设置进行了广泛实验，证明大型语言模型中这种无需训练的架构后门构成真实威胁。与现有技术不同，该攻击能经受严格的微调与重训练过程，并能规避基于输出概率的防御方法（如BDDR）。所有代码与数据已开源：https://github.com/SiSL-URI/Arch_Backdoor_LLM。
