# Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis

链接: http://arxiv.org/abs/2306.07664v1

原文摘要:
In recent years, language models (LMs) have made remarkable progress in
advancing the field of natural language processing (NLP). However, the impact
of data augmentation (DA) techniques on the fine-tuning (FT) performance of
these LMs has been a topic of ongoing debate. In this study, we evaluate the
effectiveness of three different FT methods in conjugation with
back-translation across an array of 7 diverse NLP tasks, including
classification and regression types, covering single-sentence and sentence-pair
tasks. Contrary to prior assumptions that DA does not contribute to the
enhancement of LMs' FT performance, our findings reveal that continued
pre-training on augmented data can effectively improve the FT performance of
the downstream tasks. In the most favourable case, continued pre-training
improves the performance of FT by more than 10% in the few-shot learning
setting. Our finding highlights the potential of DA as a powerful tool for
bolstering LMs' performance.

中文翻译:
近年来，语言模型（LMs）在推动自然语言处理（NLP）领域发展方面取得了显著进展。然而，数据增强（DA）技术对这些LMs微调（FT）性能的影响一直是持续讨论的话题。本研究通过7项涵盖分类与回归类型的多样化NLP任务（包括单句和句对任务），评估了三种不同FT方法结合回译策略的有效性。与先前认为DA无助于提升LMs微调性能的假设相反，我们的研究结果表明：在增强数据上持续进行预训练能有效提升下游任务的微调性能。在最理想情况下，持续预训练使小样本学习场景中的微调性能提升超过10%。这一发现揭示了DA作为增强语言模型性能的强大工具的潜在价值。
