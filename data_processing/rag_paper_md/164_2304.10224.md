# Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?

链接: http://arxiv.org/abs/2304.10224v1

原文摘要:
Point cloud based 3D deep model has wide applications in many applications
such as autonomous driving, house robot, and so on. Inspired by the recent
prompt learning in natural language processing, this work proposes a novel
Multi-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud
classification. MvNet investigates the possibility of leveraging the
off-the-shelf 2D pre-trained models to achieve the few-shot classification,
which can alleviate the over-dependence issue of the existing baseline models
towards the large-scale annotated 3D point cloud data. Specifically, MvNet
first encodes a 3D point cloud into multi-view image features for a number of
different views. Then, a novel multi-view prompt fusion module is developed to
effectively fuse information from different views to bridge the gap between 3D
point cloud data and 2D pre-trained models. A set of 2D image prompts can then
be derived to better describe the suitable prior knowledge for a large-scale
pre-trained image model for few-shot 3D point cloud classification. Extensive
experiments on ModelNet, ScanObjectNN, and ShapeNet datasets demonstrate that
MvNet achieves new state-of-the-art performance for 3D few-shot point cloud
image classification. The source code of this work will be available soon.

中文翻译:
基于点云的三维深度学习模型在自动驾驶、家用机器人等诸多领域具有广泛应用。受自然语言处理中提示学习技术的启发，本研究提出了一种新颖的多视角视觉提示融合网络（MvNet），用于小样本三维点云分类。该网络探索了利用现成二维预训练模型实现小样本分类的可能性，从而缓解现有基线模型对大规模标注三维点云数据的过度依赖问题。具体而言，MvNet首先将三维点云编码为多视角图像特征，继而通过创新的多视角提示融合模块有效整合不同视角信息，弥合三维点云数据与二维预训练模型之间的鸿沟。通过生成一组二维图像提示，系统能更精准地描述适用于大规模预训练图像模型的三维点云分类先验知识。在ModelNet、ScanObjectNN和ShapeNet数据集上的大量实验表明，MvNet在小样本三维点云图像分类任务中取得了最先进的性能。本研究源代码即将公开。
