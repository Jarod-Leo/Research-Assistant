# Nested-TNT: Hierarchical Vision Transformers with Multi-Scale Feature Processing

链接: http://arxiv.org/abs/2404.13434v1

原文摘要:
Transformer has been applied in the field of computer vision due to its
excellent performance in natural language processing, surpassing traditional
convolutional neural networks and achieving new state-of-the-art. ViT divides
an image into several local patches, known as "visual sentences". However, the
information contained in the image is vast and complex, and focusing only on
the features at the "visual sentence" level is not enough. The features between
local patches should also be taken into consideration. In order to achieve
further improvement, the TNT model is proposed, whose algorithm further divides
the image into smaller patches, namely "visual words," achieving more accurate
results. The core of Transformer is the Multi-Head Attention mechanism, and
traditional attention mechanisms ignore interactions across different attention
heads. In order to reduce redundancy and improve utilization, we introduce the
nested algorithm and apply the Nested-TNT to image classification tasks. The
experiment confirms that the proposed model has achieved better classification
performance over ViT and TNT, exceeding 2.25%, 1.1% on dataset CIFAR10 and
2.78%, 0.25% on dataset FLOWERS102 respectively.

中文翻译:
Transformer凭借其在自然语言处理领域的卓越表现被引入计算机视觉领域，超越了传统卷积神经网络并达到新的最优水平。ViT将图像划分为若干局部块，称为“视觉语句”。然而图像所包含的信息庞大且复杂，仅关注“视觉语句”层面的特征是不够的，局部块之间的特征也应纳入考量。为了取得进一步的提升，TNT模型被提出，其算法将图像进一步划分为更小的块，即“视觉单词”，实现了更精确的结果。Transformer的核心是多头注意力机制，而传统注意力机制忽略了不同注意力头之间的交互。为了减少冗余并提高利用率，我们引入嵌套算法并将Nested-TNT应用于图像分类任务。实验证实所提模型在CIFAR10数据集上分类性能较ViT、TNT分别提升2.25%、1.1%，在FLOWERS102数据集上分别提升2.78%、0.25%，取得了更好的分类效果。
