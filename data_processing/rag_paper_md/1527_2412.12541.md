# LLMCL-GEC: Advancing Grammatical Error Correction with LLM-Driven Curriculum Learning

链接: http://arxiv.org/abs/2412.12541v1

原文摘要:
While large-scale language models (LLMs) have demonstrated remarkable
capabilities in specific natural language processing (NLP) tasks, they may
still lack proficiency compared to specialized models in certain domains, such
as grammatical error correction (GEC). Drawing inspiration from the concept of
curriculum learning, we have delved into refining LLMs into proficient GEC
experts by devising effective curriculum learning (CL) strategies. In this
paper, we introduce a novel approach, termed LLM-based curriculum learning,
which capitalizes on the robust semantic comprehension and discriminative
prowess inherent in LLMs to gauge the complexity of GEC training data. Unlike
traditional curriculum learning techniques, our method closely mirrors human
expert-designed curriculums. Leveraging the proposed LLM-based CL method, we
sequentially select varying levels of curriculums ranging from easy to hard,
and iteratively train and refine using the pretrianed T5 and LLaMA series
models. Through rigorous testing and analysis across diverse benchmark
assessments in English GEC, including the CoNLL14 test, BEA19 test, and BEA19
development sets, our approach showcases a significant performance boost over
baseline models and conventional curriculum learning methodologies.

中文翻译:
尽管大规模语言模型（LLMs）在特定自然语言处理（NLP）任务中展现出卓越能力，但在某些领域（如语法错误修正GEC）仍可能逊色于专业模型。受课程学习理念启发，我们通过设计有效的课程学习（CL）策略，深入探索如何将LLMs精进为GEC专家。本文提出一种创新方法——基于LLM的课程学习，该方法利用LLMs强大的语义理解与判别能力来评估GEC训练数据的复杂度。与传统课程学习技术不同，我们的方法高度贴合人类专家设计的课程体系。借助所提出的LLM-CL方法，我们依次选择由易至难的多级课程，并基于预训练的T5和LLaMA系列模型进行迭代训练与优化。通过在英语GEC多项基准测试（包括CoNLL14测试集、BEA19测试集及开发集）中的严格验证与分析，该方法相较于基线模型和传统课程学习方法展现出显著的性能提升。
