# Can Generative Large Language Models Perform ASR Error Correction?

链接: http://arxiv.org/abs/2307.04172v1

原文摘要:
ASR error correction is an interesting option for post processing speech
recognition system outputs. These error correction models are usually trained
in a supervised fashion using the decoding results of a target ASR system. This
approach can be computationally intensive and the model is tuned to a specific
ASR system. Recently generative large language models (LLMs) have been applied
to a wide range of natural language processing tasks, as they can operate in a
zero-shot or few shot fashion. In this paper we investigate using ChatGPT, a
generative LLM, for ASR error correction. Based on the ASR N-best output, we
propose both unconstrained and constrained, where a member of the N-best list
is selected, approaches. Additionally, zero and 1-shot settings are evaluated.
Experiments show that this generative LLM approach can yield performance gains
for two different state-of-the-art ASR architectures, transducer and
attention-encoder-decoder based, and multiple test sets.

中文翻译:
自动语音识别（ASR）纠错作为后处理环节，为语音识别系统输出提供了优化可能。传统纠错模型通常需依赖目标ASR系统的解码结果进行监督训练，这种方法不仅计算成本高昂，且模型会过度适配特定ASR系统。近年来，生成式大语言模型（LLM）凭借其零样本或少样本学习能力，在自然语言处理领域展现出广泛应用潜力。本文探索利用生成式LLM（ChatGPT）实现ASR纠错的新范式：基于ASR的N-best列表输出，我们提出无约束方案（自由生成修正文本）和约束方案（从N-best候选中择优选取）两种策略，并评估零样本与单样本场景下的表现。实验表明，该生成式LLM方案能在基于transducer和注意力编码器-解码器两种前沿ASR架构上取得性能提升，且在多测试集上均表现稳健。
