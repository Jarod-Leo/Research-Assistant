# Knowledge-Infused Self Attention Transformers

链接: http://arxiv.org/abs/2306.13501v1

原文摘要:
Transformer-based language models have achieved impressive success in various
natural language processing tasks due to their ability to capture complex
dependencies and contextual information using self-attention mechanisms.
However, they are not without limitations. These limitations include
hallucinations, where they produce incorrect outputs with high confidence, and
alignment issues, where they generate unhelpful and unsafe outputs for human
users. These limitations stem from the absence of implicit and missing context
in the data alone. To address this, researchers have explored augmenting these
models with external knowledge from knowledge graphs to provide the necessary
additional context. However, the ad-hoc nature of existing methods makes it
difficult to properly analyze the effects of knowledge infusion on the many
moving parts or components of a transformer. This paper introduces a systematic
method for infusing knowledge into different components of a transformer-based
model. A modular framework is proposed to identify specific components within
the transformer architecture, such as the self-attention mechanism, encoder
layers, or the input embedding layer, where knowledge infusion can be applied.
Additionally, extensive experiments are conducted on the General Language
Understanding Evaluation (GLUE) benchmark tasks, and the findings are reported.
This systematic approach aims to facilitate more principled approaches to
incorporating knowledge into language model architectures.

中文翻译:
基于Transformer的语言模型凭借其利用自注意力机制捕捉复杂依赖关系和上下文信息的能力，已在各类自然语言处理任务中取得显著成功。然而这类模型仍存在明显局限，包括会产生高置信度错误输出的"幻觉"问题，以及生成对人类用户无益甚至有害内容的"对齐偏差"问题。这些缺陷源于模型仅依赖数据本身而缺乏隐含和缺失的上下文信息。为解决这一问题，研究者尝试通过引入知识图谱的外部知识来提供必要的补充语境。但现有方法多为临时性方案，难以系统分析知识注入对Transformer各动态组件的影响机制。

本文提出了一种将知识系统化注入Transformer模型不同组件的创新方法。通过设计模块化框架，我们明确了模型架构中可实施知识注入的具体组件，包括自注意力机制、编码器层及输入嵌入层等。研究团队在通用语言理解评估(GLUE)基准任务上开展了大量实验，并对实验结果进行了详细分析。这种系统化方法旨在为语言模型架构的知识融合提供更具原则性的实现路径。
