# A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks

链接: http://arxiv.org/abs/2407.12994v1

原文摘要:
Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years.

中文翻译:
大型语言模型（LLMs）在众多自然语言处理（NLP）任务中展现出卓越性能。提示工程通过设计自然语言指令（即提示），以结构化方式激发LLMs内嵌知识，无需针对特定任务进行大规模参数重训练或微调，即可显著提升模型表现，成为释放LLMs潜力的关键。相较于传统最优模型（SoTA），该方法降低了技术门槛，即使缺乏深厚机器学习背景的研究者也能通过自然语言交互探索LLMs能力。

随着近两年提示工程的兴起，研究者已开发出多种提示设计技术以提高信息提取精度。本文系统梳理了不同提示技术，并按其适用的NLP任务进行分类整合。我们细粒度分析了这些策略在各类任务数据集上的性能表现，探讨了对应使用的LLMs模型，绘制了技术分类图谱，并针对特定数据集讨论了可能的SoTA方案。研究共涵盖44篇学术文献（多数发表于近两年），涉及29项NLP任务中的39种提示方法，为当前提示工程研究提供了全景式综述。
