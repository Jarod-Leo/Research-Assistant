# NLPBench: Evaluating Large Language Models on Solving NLP Problems

链接: http://arxiv.org/abs/2309.15630v1

原文摘要:
Recent developments in large language models (LLMs) have shown promise in
enhancing the capabilities of natural language processing (NLP). Despite these
successes, there remains a dearth of research dedicated to the NLP
problem-solving abilities of LLMs. To fill the gap in this area, we present a
unique benchmarking dataset, NLPBench, comprising 378 college-level NLP
questions spanning various NLP topics sourced from Yale University's prior
final exams. NLPBench includes questions with context, in which multiple
sub-questions share the same public information, and diverse question types,
including multiple choice, short answer, and math. Our evaluation, centered on
LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting
strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study
reveals that the effectiveness of the advanced prompting strategies can be
inconsistent, occasionally damaging LLM performance, especially in smaller
models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated
specific shortcomings in LLMs' scientific problem-solving skills, with
weaknesses in logical decomposition and reasoning notably affecting results.

中文翻译:
大型语言模型（LLM）的最新进展展现了增强自然语言处理（NLP）能力的潜力。尽管取得这些成果，针对LLM解决NLP问题能力的研究仍显不足。为填补这一领域空白，我们推出了独特基准数据集NLPBench，包含378道大学水平的NLP题目，涵盖耶鲁大学历年期末考试中各类NLP主题。该数据集包含上下文关联题（多个子题共享公共背景信息）以及多样化题型，如选择题、简答题和计算题。我们以GPT-3.5/4、PaLM-2和LLAMA-2等模型为核心进行评估，并采用思维链（CoT）和思维树（ToT）等高级提示策略。研究发现：先进提示策略的效果存在不稳定性，有时会损害模型表现，尤其在LLAMA-2（13b）等较小模型中更为明显；人工评估还揭示了LLM在科学问题解决中的特定缺陷，逻辑分解与推理能力的不足对结果产生显著影响。
