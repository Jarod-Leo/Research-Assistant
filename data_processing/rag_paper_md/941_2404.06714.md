# Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness

链接: http://arxiv.org/abs/2404.06714v2

原文摘要:
Recent advancements in Natural Language Processing (NLP) have seen
Large-scale Language Models (LLMs) excel at producing high-quality text for
various purposes. Notably, in Text-To-Speech (TTS) systems, the integration of
BERT for semantic token generation has underscored the importance of semantic
content in producing coherent speech outputs. Despite this, the specific
utility of LLMs in enhancing TTS synthesis remains considerably limited. This
research introduces an innovative approach, Llama-VITS, which enhances TTS
synthesis by enriching the semantic content of text using LLM. Llama-VITS
integrates semantic embeddings from Llama2 with the VITS model, a leading
end-to-end TTS framework. By leveraging Llama2 for the primary speech synthesis
process, our experiments demonstrate that Llama-VITS matches the naturalness of
the original VITS (ORI-VITS) and those incorporate BERT (BERT-VITS), on the
LJSpeech dataset, a substantial collection of neutral, clear speech. Moreover,
our method significantly enhances emotive expressiveness on the EmoV_DB_bea_sem
dataset, a curated selection of emotionally consistent speech from the EmoV_DB
dataset, highlighting its potential to generate emotive speech.

中文翻译:
自然语言处理（NLP）领域的最新进展中，大规模语言模型（LLMs）已能出色生成多种用途的高质量文本。值得注意的是，在文本转语音（TTS）系统中，通过整合BERT模型生成语义标记，凸显了语义内容对生成连贯语音输出的重要性。尽管如此，LLMs在提升TTS合成效果方面的具体应用仍存在显著局限。本研究提出创新方法Llama-VITS，利用LLM增强文本语义内容以优化TTS合成。该方案将Llama2的语义嵌入与领先的端到端TTS框架VITS模型相结合。实验表明，在包含大量中性清晰语音的LJSpeech数据集上，Llama-VITS采用Llama2主导语音合成流程时，其自然度与原版VITS（ORI-VITS）及整合BERT的版本（BERT-VITS）相当。更重要的是，在精选情感一致性语音数据集EmoV_DB_bea_sem（源自EmoV_DB数据集）上的测试显示，本方法显著提升了情感表现力，彰显其生成情感化语音的潜力。
