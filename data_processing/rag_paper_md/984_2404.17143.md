# Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls

链接: http://arxiv.org/abs/2404.17143v1

原文摘要:
Dominant pre-trained language models (PLMs) have demonstrated the potential
risk of memorizing and outputting the training data. While this concern has
been discussed mainly in English, it is also practically important to focus on
domain-specific PLMs. In this study, we pre-trained domain-specific GPT-2
models using a limited corpus of Japanese newspaper articles and evaluated
their behavior. Experiments replicated the empirical finding that memorization
of PLMs is related to the duplication in the training data, model size, and
prompt length, in Japanese the same as in previous English studies.
Furthermore, we attempted membership inference attacks, demonstrating that the
training data can be detected even in Japanese, which is the same trend as in
English. The study warns that domain-specific PLMs, sometimes trained with
valuable private data, can ''copy and paste'' on a large scale.

中文翻译:
主流预训练语言模型(PLMs)已被证实存在记忆并输出训练数据的潜在风险。尽管这一现象主要在英语领域被讨论，但关注领域专用PLMs同样具有现实意义。本研究使用有限规模的日语新闻语料库预训练了领域专用GPT-2模型，并评估其行为特征。实验复现了PLMs记忆效应与训练数据重复率、模型规模及提示词长度相关的实证结论，证明该现象在日语中与既往英语研究具有一致性。进一步通过成员推理攻击实验表明，日语训练数据同样可被检测识别，这与英语研究趋势相符。本研究警示：那些使用宝贵私有数据训练的领域专用PLMs，同样可能引发大规模"复制粘贴"风险。
