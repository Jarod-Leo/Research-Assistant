# Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention

链接: http://arxiv.org/abs/2410.12462v1

原文摘要:
Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing but exhibit significant performance gaps among different
languages. Most existing approaches to address these disparities rely on
pretraining or fine-tuning, which are resource-intensive. To overcome these
limitations without incurring significant costs, we propose Inference-Time
Cross-Lingual Intervention (INCLINE), a novel framework that enhances LLM
performance on low-performing (source) languages by aligning their internal
representations with those of high-performing (target) languages during
inference. INCLINE initially learns alignment matrices using parallel sentences
from source and target languages through a Least-Squares optimization, and then
applies these matrices during inference to transform the low-performing
language representations toward the high-performing language space. Extensive
experiments on nine benchmarks with five LLMs demonstrate that INCLINE
significantly improves performance across diverse tasks and languages, compared
to recent strong baselines. Our analysis demonstrates that INCLINE is highly
cost-effective and applicable to a wide range of applications. In addition, we
release the code to foster research along this line:
https://github.com/weixuan-wang123/INCLINE.

中文翻译:
大型语言模型（LLMs）在自然语言处理领域展现出卓越能力，但不同语言间存在显著的性能差异。现有方法多依赖预训练或微调来解决这些差异，然而这些方法资源消耗巨大。为在不增加显著成本的前提下突破这一局限，我们提出推理时跨语言干预框架（INCLINE），该创新方案通过在推理阶段将低性能（源）语言的内部表征与高性能（目标）语言对齐来提升模型表现。INCLINE首先通过最小二乘优化利用平行语料学习源语言与目标语言的对齐矩阵，随后在推理时应用这些矩阵将低性能语言表征转换至高性能语言空间。基于五种LLM在九个基准测试上的广泛实验表明，相较于近期强基线模型，INCLINE能显著提升跨任务和跨语言的性能表现。分析显示该框架具有极高成本效益且适用场景广泛。我们同步公开了代码以促进相关研究：https://github.com/weixuan-wang123/INCLINE。
