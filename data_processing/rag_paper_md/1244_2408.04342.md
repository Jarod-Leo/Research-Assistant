# Towards Explainable Network Intrusion Detection using Large Language Models

链接: http://arxiv.org/abs/2408.04342v1

原文摘要:
Large Language Models (LLMs) have revolutionised natural language processing
tasks, particularly as chat agents. However, their applicability to threat
detection problems remains unclear. This paper examines the feasibility of
employing LLMs as a Network Intrusion Detection System (NIDS), despite their
high computational requirements, primarily for the sake of explainability.
Furthermore, considerable resources have been invested in developing LLMs, and
they may offer utility for NIDS. Current state-of-the-art NIDS rely on
artificial benchmarking datasets, resulting in skewed performance when applied
to real-world networking environments. Therefore, we compare the GPT-4 and
LLama3 models against traditional architectures and transformer-based models to
assess their ability to detect malicious NetFlows without depending on
artificially skewed datasets, but solely on their vast pre-trained acquired
knowledge. Our results reveal that, although LLMs struggle with precise attack
detection, they hold significant potential for a path towards explainable NIDS.
Our preliminary exploration shows that LLMs are unfit for the detection of
Malicious NetFlows. Most promisingly, however, these exhibit significant
potential as complementary agents in NIDS, particularly in providing
explanations and aiding in threat response when integrated with Retrieval
Augmented Generation (RAG) and function calling capabilities.

中文翻译:
大型语言模型（LLMs）已彻底改变了自然语言处理任务，尤其在聊天代理领域表现突出。然而，其在威胁检测问题上的适用性仍不明确。本文探讨了将LLMs用作网络入侵检测系统（NIDS）的可行性——尽管存在高计算资源需求，但主要着眼于其可解释性优势。此外，鉴于已投入大量资源开发LLMs，它们可能为NIDS提供独特价值。当前最先进的NIDS依赖于人工基准数据集，导致在真实网络环境中性能出现偏差。为此，我们对比了GPT-4和LLama3模型与传统架构及基于Transformer的模型，评估其在脱离人工偏差数据集、仅依靠预训练知识的情况下检测恶意网络流（NetFlows）的能力。研究结果表明：虽然LLMs在精确攻击检测方面存在困难，但为实现可解释NIDS提供了重要潜力。初步探索显示LLMs不适合直接检测恶意网络流，但最具前景的是，当与检索增强生成（RAG）和函数调用功能结合时，这些模型作为NIDS的辅助代理展现出显著潜力，特别是在提供解释说明和协助威胁响应方面。
