# Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey

链接: http://arxiv.org/abs/2406.07973v1

原文摘要:
With the rapid development of artificial intelligence, large language models
(LLMs) have made remarkable advancements in natural language processing. These
models are trained on vast datasets to exhibit powerful language understanding
and generation capabilities across various applications, including machine
translation, chatbots, and agents. However, LLMs have revealed a variety of
privacy and security issues throughout their life cycle, drawing significant
academic and industrial attention. Moreover, the risks faced by LLMs differ
significantly from those encountered by traditional language models. Given that
current surveys lack a clear taxonomy of unique threat models across diverse
scenarios, we emphasize the unique privacy and security threats associated with
five specific scenarios: pre-training, fine-tuning, retrieval-augmented
generation systems, deployment, and LLM-based agents. Addressing the
characteristics of each risk, this survey outlines potential threats and
countermeasures. Research on attack and defense situations can offer feasible
research directions, enabling more areas to benefit from LLMs.

中文翻译:
随着人工智能的飞速发展，大语言模型在自然语言处理领域取得了显著突破。这类模型通过海量数据训练，在机器翻译、聊天机器人、智能体等多元场景中展现出强大的语言理解与生成能力。然而在其全生命周期中暴露出的隐私与安全问题已引发学界和产业界高度关注，且其风险特征与传统语言模型存在显著差异。鉴于现有研究缺乏对不同场景下特有威胁模型的系统梳理，本文重点聚焦预训练、微调、检索增强生成系统、部署应用及基于大语言模型的智能体这五大特定场景中的独特隐私安全威胁，针对各环节风险特征，系统阐述了潜在威胁与应对策略。攻防态势研究可为相关领域提供可行的研究方向，使更多领域能安全受益于大语言模型技术。
