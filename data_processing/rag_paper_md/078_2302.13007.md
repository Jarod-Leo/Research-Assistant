# ChatAug: Leveraging ChatGPT for Text Data Augmentation

链接: http://arxiv.org/abs/2302.13007v1

原文摘要:
Text data augmentation is an effective strategy for overcoming the challenge
of limited sample sizes in many natural language processing (NLP) tasks. This
challenge is especially prominent in the few-shot learning scenario, where the
data in the target domain is generally much scarcer and of lowered quality. A
natural and widely-used strategy to mitigate such challenges is to perform data
augmentation to better capture the data invariance and increase the sample
size. However, current text data augmentation methods either can't ensure the
correct labeling of the generated data (lacking faithfulness) or can't ensure
sufficient diversity in the generated data (lacking compactness), or both.
Inspired by the recent success of large language models, especially the
development of ChatGPT, which demonstrated improved language comprehension
abilities, in this work, we propose a text data augmentation approach based on
ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training samples
into multiple conceptually similar but semantically different samples. The
augmented samples can then be used in downstream model training. Experiment
results on few-shot learning text classification tasks show the superior
performance of the proposed AugGPT approach over state-of-the-art text data
augmentation methods in terms of testing accuracy and distribution of the
augmented samples.

中文翻译:
文本数据增强是应对诸多自然语言处理（NLP）任务中样本量不足挑战的有效策略，这一挑战在小样本学习场景下尤为突出——目标领域的数据通常更为稀缺且质量较低。缓解此类挑战的常见策略是通过数据增强来更好地捕捉数据不变性并扩大样本规模。然而，现有文本数据增强方法要么无法保证生成数据的正确标注（缺乏忠实性），要么难以确保生成数据的充分多样性（缺乏紧凑性），或二者兼有。受大语言模型最新进展（尤其是展现卓越语言理解能力的ChatGPT）的启发，本研究提出基于ChatGPT的文本数据增强方法AugGPT。该方法将训练样本中的每个句子重述为多个概念相似但语义不同的样本，生成的增强样本可用于下游模型训练。在小样本文本分类任务的实验中，AugGPT在测试准确率和增强样本分布方面均优于当前最先进的文本数据增强方法。
