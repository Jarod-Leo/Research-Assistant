# Harnessing the power of LLMs for normative reasoning in MASs

链接: http://arxiv.org/abs/2403.16524v1

原文摘要:
Software agents, both human and computational, do not exist in isolation and
often need to collaborate or coordinate with others to achieve their goals. In
human society, social mechanisms such as norms ensure efficient functioning,
and these techniques have been adopted by researchers in multi-agent systems
(MAS) to create socially aware agents. However, traditional techniques have
limitations, such as operating in limited environments often using brittle
symbolic reasoning. The advent of Large Language Models (LLMs) offers a
promising solution, providing a rich and expressive vocabulary for norms and
enabling norm-capable agents that can perform a range of tasks such as norm
discovery, normative reasoning and decision-making. This paper examines the
potential of LLM-based agents to acquire normative capabilities, drawing on
recent Natural Language Processing (NLP) and LLM research. We present our
vision for creating normative LLM agents. In particular, we discuss how the
recently proposed "LLM agent" approaches can be extended to implement such
normative LLM agents. We also highlight challenges in this emerging field. This
paper thus aims to foster collaboration between MAS, NLP and LLM researchers in
order to advance the field of normative agents.

中文翻译:
软件智能体，无论是人类还是计算型，均非孤立存在，常需通过协作或协调来实现目标。人类社会依靠规范等社会机制保障高效运转，这一理念已被多智能体系统（MAS）研究者借鉴，用于开发具备社会意识的智能体。然而传统技术存在局限性，例如仅能在有限环境中运行且依赖脆弱的符号推理。大型语言模型（LLMs）的出现提供了突破性解决方案，其丰富的语义表达能力为规范建模创造了条件，使智能体能够执行规范发现、规范性推理与决策等任务。本文结合自然语言处理（NLP）与LLM领域最新进展，系统探讨了基于LLM的智能体获取规范性能力的潜力。我们提出了构建规范性LLM智能体的技术路线，重点阐释如何扩展近期提出的"LLM智能体"方法来实现此类智能体，并指出该新兴领域的核心挑战。本研究旨在促进MAS、NLP与LLM领域的跨学科合作，共同推进规范性智能体的发展。
