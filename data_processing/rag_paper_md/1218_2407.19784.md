# Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting

链接: http://arxiv.org/abs/2407.19784v1

原文摘要:
Alongside the continuous process of improving AI performance through the
development of more sophisticated models, researchers have also focused their
attention to the emerging concept of data-centric AI, which emphasizes the
important role of data in a systematic machine learning training process.
Nonetheless, the development of models has also continued apace. One result of
this progress is the development of the Transformer Architecture, which
possesses a high level of capability in multiple domains such as Natural
Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting
(TSF). Its performance is, however, heavily dependent on input data
preprocessing and output data evaluation, justifying a data-centric approach to
future research. We argue that data-centric AI is essential for training AI
models, particularly for transformer-based TSF models efficiently. However,
there is a gap regarding the integration of transformer-based TSF and
data-centric AI. This survey aims to pin down this gap via the extensive
literature review based on the proposed taxonomy. We review the previous
research works from a data-centric AI perspective and we intend to lay the
foundation work for the future development of transformer-based architecture
and data-centric AI.

中文翻译:
在通过开发更复杂模型持续提升AI性能的同时，研究者们也将目光投向了新兴的"以数据为中心的人工智能"理念，该理念强调数据在系统化机器学习训练过程中的核心作用。尽管如此，模型研发的步伐从未停歇。这一进程的重要成果便是Transformer架构的诞生，该架构在自然语言处理（NLP）、计算机视觉（CV）和时间序列预测（TSF）等多个领域展现出卓越性能。然而其表现高度依赖于输入数据预处理与输出数据评估环节，这为未来研究采用以数据为中心的方法提供了充分依据。我们认为，以数据为中心的AI对于高效训练AI模型（特别是基于Transformer的TSF模型）具有决定性意义。但目前关于Transformer架构TSF与数据中心化AI的融合研究仍存在空白。本综述通过基于分类法的系统性文献梳理，旨在明确这一研究缺口。我们从数据中心化AI视角审视前人研究成果，力求为Transformer架构与数据中心化AI的协同发展奠定理论基础。
