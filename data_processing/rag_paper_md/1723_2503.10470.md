# Statistical Analysis of Sentence Structures through ASCII, Lexical Alignment and PCA

链接: http://arxiv.org/abs/2503.10470v1

原文摘要:
While utilizing syntactic tools such as parts-of-speech (POS) tagging has
helped us understand sentence structures and their distribution across diverse
corpora, it is quite complex and poses a challenge in natural language
processing (NLP). This study focuses on understanding sentence structure
balance - usages of nouns, verbs, determiners, etc - harmoniously without
relying on such tools. It proposes a novel statistical method that uses
American Standard Code for Information Interchange (ASCII) codes to represent
text of 11 text corpora from various sources and their lexical category
alignment after using their compressed versions through PCA, and analyzes the
results through histograms and normality tests such as Shapiro-Wilk and
Anderson-Darling Tests. By focusing on ASCII codes, this approach simplifies
text processing, although not replacing any syntactic tools but complementing
them by offering it as a resource-efficient tool for assessing text balance.
The story generated by Grok shows near normality indicating balanced sentence
structures in LLM outputs, whereas 4 out of the remaining 10 pass the normality
tests. Further research could explore potential applications in text quality
evaluation and style analysis with syntactic integration for more broader
tasks.

中文翻译:
尽管利用词性标注（POS）等句法工具帮助我们理解了句子结构及其在不同语料库中的分布规律，但其复杂性仍对自然语言处理（NLP）构成挑战。本研究提出一种不依赖传统句法工具的新颖统计方法，通过美国信息交换标准代码（ASCII）表征11个多源文本语料库的内容，在运用主成分分析（PCA）压缩后分析其词汇类别对齐特征，并借助直方图及夏皮罗-威尔克检验、安德森-达林检验等正态性测试评估结果。该方法以ASCII编码为核心简化了文本处理流程，虽不能替代现有句法工具，但可作为评估文本平衡性的资源高效型补充工具。实验显示Grok生成的故事文本呈现接近正态分布，表明大语言模型输出具有均衡的句子结构，而其余10个语料库中有4个通过正态性检验。未来研究可探索该方法与句法分析结合在文本质量评估、风格分析等更广泛任务中的应用潜力。
