# Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions

链接: http://arxiv.org/abs/2406.09264v1

原文摘要:
Recent advancements in general-purpose AI have highlighted the importance of
guiding AI systems towards the intended goals, ethical principles, and values
of individuals and groups, a concept broadly recognized as alignment. However,
the lack of clarified definitions and scopes of human-AI alignment poses a
significant obstacle, hampering collaborative efforts across research domains
to achieve this alignment. In particular, ML- and philosophy-oriented alignment
research often views AI alignment as a static, unidirectional process (i.e.,
aiming to ensure that AI systems' objectives match humans) rather than an
ongoing, mutual alignment problem. This perspective largely neglects the
long-term interaction and dynamic changes of alignment. To understand these
gaps, we introduce a systematic review of over 400 papers published between
2019 and January 2024, spanning multiple domains such as Human-Computer
Interaction (HCI), Natural Language Processing (NLP), Machine Learning (ML). We
characterize, define and scope human-AI alignment. From this, we present a
conceptual framework of "Bidirectional Human-AI Alignment" to organize the
literature from a human-centered perspective. This framework encompasses both
1) conventional studies of aligning AI to humans that ensures AI produces the
intended outcomes determined by humans, and 2) a proposed concept of aligning
humans to AI, which aims to help individuals and society adjust to AI
advancements both cognitively and behaviorally. Additionally, we articulate the
key findings derived from literature analysis, including literature gaps and
trends, human values, and interaction techniques. To pave the way for future
studies, we envision three key challenges and give recommendations for future
research.

中文翻译:
通用人工智能领域的最新进展凸显了引导AI系统符合个人及群体预期目标、伦理原则与价值观的重要性，这一理念被广泛称为"对齐"。然而，人类-AI对齐概念定义与研究范畴的模糊性构成了重大障碍，阻碍了跨研究领域实现对齐目标的协作努力。尤其值得注意的是，以机器学习和哲学为导向的对齐研究通常将AI对齐视为静态、单向的过程（即确保AI系统目标与人类一致），而非持续、双向的协同调适问题。这种视角很大程度上忽视了对齐的长期互动性与动态演变特征。

为厘清这些研究缺口，我们对2019年至2024年1月期间发表的400余篇跨领域文献（涵盖人机交互、自然语言处理、机器学习等方向）进行了系统综述，界定了人类-AI对齐的特征定义与研究边界。基于此，我们提出"双向人类-AI对齐"概念框架，从人本视角整合现有研究：既包含1）传统"AI向人类对齐"研究（确保AI产出符合人类预期结果），也创新性地提出2）"人类向AI对齐"概念（帮助个体与社会在认知行为层面适应AI发展）。研究进一步提炼出文献分析的关键发现，包括研究空白、发展趋势、人类价值观维度及交互技术等。最后，我们提出未来研究面临的三大挑战与具体建议，为后续探索指明方向。
