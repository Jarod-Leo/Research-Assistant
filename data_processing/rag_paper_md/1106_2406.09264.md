# Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions

链接: http://arxiv.org/abs/2406.09264v1

原文摘要:
Recent advancements in general-purpose AI have highlighted the importance of
guiding AI systems towards the intended goals, ethical principles, and values
of individuals and groups, a concept broadly recognized as alignment. However,
the lack of clarified definitions and scopes of human-AI alignment poses a
significant obstacle, hampering collaborative efforts across research domains
to achieve this alignment. In particular, ML- and philosophy-oriented alignment
research often views AI alignment as a static, unidirectional process (i.e.,
aiming to ensure that AI systems' objectives match humans) rather than an
ongoing, mutual alignment problem. This perspective largely neglects the
long-term interaction and dynamic changes of alignment. To understand these
gaps, we introduce a systematic review of over 400 papers published between
2019 and January 2024, spanning multiple domains such as Human-Computer
Interaction (HCI), Natural Language Processing (NLP), Machine Learning (ML). We
characterize, define and scope human-AI alignment. From this, we present a
conceptual framework of "Bidirectional Human-AI Alignment" to organize the
literature from a human-centered perspective. This framework encompasses both
1) conventional studies of aligning AI to humans that ensures AI produces the
intended outcomes determined by humans, and 2) a proposed concept of aligning
humans to AI, which aims to help individuals and society adjust to AI
advancements both cognitively and behaviorally. Additionally, we articulate the
key findings derived from literature analysis, including literature gaps and
trends, human values, and interaction techniques. To pave the way for future
studies, we envision three key challenges and give recommendations for future
research.

中文翻译:
通用人工智能领域的最新进展凸显了引导AI系统符合个人及群体预期目标、伦理准则与价值取向的重要性，这一理念被广泛称为"对齐"。然而，人类与AI对齐概念在定义与范畴上的模糊性构成了重大障碍，阻碍了跨研究领域为实现对齐而开展的协作。值得注意的是，以机器学习和哲学为导向的对齐研究通常将AI对齐视为静态的单向过程（即确保AI系统目标与人类一致），而非持续的双向调适问题。这种视角很大程度上忽视了对齐的长期互动性与动态演变特征。

为厘清这些认知缺口，我们对2019年至2024年1月期间发表的400余篇跨领域文献（涵盖人机交互、自然语言处理、机器学习等）进行了系统综述，进而界定并廓清了人类-AI对齐的概念范畴。基于此，我们提出"双向人类-AI对齐"概念框架，从人本视角整合现有研究：1）传统"AI向人类对齐"研究——确保AI产出符合人类预设目标；2）创新性提出"人类向AI对齐"概念——帮助个体与社会在认知行为层面适应AI技术发展。研究进一步阐明了文献分析的关键发现，包括研究空白、发展趋势、人类价值维度及交互技术等。最后，我们提出未来研究面临的三大挑战与方向性建议，为后续探索铺路。

（译文特点说明：
1. 专业术语统一处理："alignment"根据语境分别译为"对齐"（学科术语）和"调适"（动态过程）
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将"ML- and philosophy-oriented..."复杂句式拆解为两个逻辑层级
3. 被动语态转化："are often viewed as"等被动结构转换为中文主动句式
4. 概念显化处理："Bidirectional Human-AI Alignment"通过添加引导词"创新性提出"来突出其学术贡献
5. 学术风格保持：使用"廓清""阐明"等符合学术论文特征的词汇，同时通过"铺路"等隐喻保持可读性）
