# Think and Retrieval: A Hypothesis Knowledge Graph Enhanced Medical Large Language Models

链接: http://arxiv.org/abs/2312.15883v1

原文摘要:
In this paper, we investigate the retrieval-augmented generation (RAG) based
on Knowledge Graphs (KGs) to improve the accuracy and reliability of Large
Language Models (LLMs). Recent approaches suffer from insufficient and
repetitive knowledge retrieval, tedious and time-consuming query parsing, and
monotonous knowledge utilization. To this end, we develop a Hypothesis
Knowledge Graph Enhanced (HyKGE) framework, which leverages LLMs' powerful
reasoning capacity to compensate for the incompleteness of user queries,
optimizes the interaction process with LLMs, and provides diverse retrieved
knowledge. Specifically, HyKGE explores the zero-shot capability and the rich
knowledge of LLMs with Hypothesis Outputs to extend feasible exploration
directions in the KGs, as well as the carefully curated prompt to enhance the
density and efficiency of LLMs' responses. Furthermore, we introduce the HO
Fragment Granularity-aware Rerank Module to filter out noise while ensuring the
balance between diversity and relevance in retrieved knowledge. Experiments on
two Chinese medical multiple-choice question datasets and one Chinese
open-domain medical Q&A dataset with two LLM turbos demonstrate the superiority
of HyKGE in terms of accuracy and explainability.

中文翻译:
本文研究基于知识图谱（KG）的检索增强生成（RAG）技术，旨在提升大语言模型（LLM）的准确性与可靠性。针对现有方法存在的知识检索不足且重复、查询解析过程冗长耗时、知识利用方式单一等问题，我们提出假设知识图谱增强框架（HyKGE）。该框架通过激发LLM强大的推理能力来弥补用户查询的完整性缺陷，优化与LLM的交互流程，并提供多样化的检索知识。具体而言，HyKGE利用LLM的零样本能力和假设输出（Hypothesis Outputs）拓展知识图谱的可行探索方向，并通过精心设计的提示词提升LLM响应的信息密度与生成效率。此外，我们提出假设输出片段粒度感知重排模块（HO Fragment Granularity-aware Rerank Module），在过滤噪声的同时确保检索知识在多样性与相关性之间的平衡。在两项中文医疗多选题数据集和一项中文开放域医疗问答数据集上，基于两种LLM基座的实验表明，HyKGE在准确性和可解释性方面均具有显著优势。

（翻译说明：
1. 专业术语采用"知识图谱/假设输出"等学界通用译法
2. 机构名称HyKGE保留英文缩写并首次出现标注全称
3. 长难句进行合理切分，如将"compensate for..."独立译为"弥补...缺陷"
4. 被动语态转换为中文主动表达，如"are demonstrated"译为"实验表明"
5. 技术概念如"zero-shot capability"译为"零样本能力"符合NLP领域规范
6. 保持学术文本的严谨性，避免口语化表达）
