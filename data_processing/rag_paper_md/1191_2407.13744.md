# LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation

链接: http://arxiv.org/abs/2407.13744v1

原文摘要:
Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like "artificial general intelligences"
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as "prompt injection" and
"jailbreaking").

中文翻译:
自然语言处理领域的发展轨迹已从针对特定任务建模，迅速转向采用通用预训练模型并进行任务微调，直至今日涌现出看似具备本质通用性的模型。本文指出，这种演变导致我们难以清晰界定这些模型的实际建模对象，进而催生出"人工通用智能"等无助于客观评估模型优劣的隐喻概念。我们主张从"基于自然语言规范逼近专业功能"的视角来理解其通用性与潜在价值。这一理论框架不仅凸显出功能逼近的质量问题，更延伸出关于功能可发现性、稳定性和可保护性等深层议题。如本文所示，该框架能将实践与理论层面的各类评估维度（包括常被边缘化的"提示注入"和"越狱"等问题）统一纳入同一概念体系。
