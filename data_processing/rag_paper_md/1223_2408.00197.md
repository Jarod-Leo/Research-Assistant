# Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models

链接: http://arxiv.org/abs/2408.00197v1

原文摘要:
Generative Pre-Trained Transformer models have been shown to be surprisingly
effective at a variety of natural language processing tasks -- including
generating computer code. We evaluate the effectiveness of open source GPT
models for the task of automatic identification of the presence of vulnerable
code syntax (specifically targeting C and C++ source code). This task is
evaluated on a selection of 36 source code examples from the NIST SARD dataset,
which are specifically curated to not contain natural English that indicates
the presence, or lack thereof, of a particular vulnerability. The NIST SARD
source code dataset contains identified vulnerable lines of source code that
are examples of one out of the 839 distinct Common Weakness Enumerations (CWE),
allowing for exact quantification of the GPT output classification error rate.
A total of 5 GPT models are evaluated, using 10 different inference
temperatures and 100 repetitions at each setting, resulting in 5,000 GPT
queries per vulnerable source code analyzed. Ultimately, we find that the GPT
models that we evaluated are not suitable for fully automated vulnerability
scanning because the false positive and false negative rates are too high to
likely be useful in practice. However, we do find that the GPT models perform
surprisingly well at automated vulnerability detection for some of the test
cases, in particular surpassing random sampling, and being able to identify the
exact lines of code that are vulnerable albeit at a low success rate. The best
performing GPT model result found was Llama-2-70b-chat-hf with inference
temperature of 0.1 applied to NIST SARD test case 149165 (which is an example
of a buffer overflow vulnerability), which had a binary classification recall
score of 1.0 and a precision of 1.0 for correctly and uniquely identifying the
vulnerable line of code and the correct CWE number.

中文翻译:
研究表明，生成式预训练Transformer模型在多种自然语言处理任务中表现出惊人的有效性——包括生成计算机代码。本文评估了开源GPT模型在自动识别易受攻击代码语法（特别针对C和C++源代码）任务中的表现。该评估基于从NIST SARD数据集中精选的36个源代码样本，这些样本经过特殊设计，不包含任何暗示特定漏洞存在与否的自然英语描述。NIST SARD源代码数据集标注了839种不同通用缺陷枚举(CWE)示例中的易受攻击代码行，可精确量化GPT输出分类的错误率。

研究共评估了5个GPT模型，采用10种不同推理温度参数，每种设置下重复100次，每个待分析的漏洞源代码共执行5,000次GPT查询。最终发现，所评估的GPT模型并不适用于全自动漏洞扫描，因为其误报率和漏报率过高，实际应用价值有限。但值得注意的是，在某些测试案例中，这些模型展现出超预期的自动化漏洞检测能力：其表现优于随机抽样，并能以较低成功率精确定位易受攻击的代码行。最佳表现为Llama-2-70b-chat-hf模型（推理温度0.1）在NIST SARD测试案例149165（缓冲区溢出漏洞示例）中取得：该模型以1.0的召回率和1.0的精确度，准确且唯一地识别出漏洞代码行及正确CWE编号。
