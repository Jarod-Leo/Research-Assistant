# Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning

链接: http://arxiv.org/abs/2305.18170v1

原文摘要:
Chain-of-thought (CoT) prompting with large language models has proven
effective in numerous natural language processing tasks, but designing prompts
that generalize well to diverse problem types can be challenging, especially in
the context of math word problem (MWP) solving. Additionally, it is common to
have a large amount of training data that have a better diversity coverage but
CoT annotations are not available, which limits the use of supervised learning
techniques. To address these issues, we investigate two approaches to leverage
the training data in a few-shot prompting scenario: dynamic program prompting
and program distillation. Our approach is largely inspired by Gao et al.,
(2022), where they proposed to replace the CoT with the programs as the
intermediate reasoning step. Such a prompting strategy allows us to accurately
verify the answer correctness through program execution in MWP solving. Our
dynamic program prompting involves annotating the training data by sampling
correct programs from a large language model, while program distillation
involves adapting a smaller model to the program-annotated training data. Our
experiments on three standard MWP datasets demonstrate the effectiveness of
these approaches, yielding significant improvements over previous baselines for
prompting and fine-tuning. Our results suggest that leveraging a large amount
of training data can improve the generalization ability of prompts and boost
the performance of fine-tuned small models in MWP solving.

中文翻译:
在大语言模型中使用思维链（CoT）提示已被证明对众多自然语言处理任务有效，但设计能泛化至多样化问题类型的提示仍具挑战性，尤其在数学应用题（MWP）求解场景中。此外，尽管常存在大量覆盖更广多样性的训练数据，却缺乏CoT标注，这限制了监督学习技术的应用。针对这些问题，我们探索了两种在少样本提示场景下利用训练数据的方法：动态程序提示与程序蒸馏。该方法主要受Gao等人（2022）研究的启发，他们提出用程序替代CoT作为中间推理步骤。此类提示策略使我们能通过程序执行在MWP求解中精准验证答案正确性。动态程序提示涉及从大语言模型采样正确程序来标注训练数据，而程序蒸馏则使小模型适配程序标注的训练数据。在三个标准MWP数据集上的实验表明，这些方法显著超越了先前的提示与微调基线。结果表明，利用大量训练数据可提升提示的泛化能力，并增强微调后小模型在MWP求解中的表现。
