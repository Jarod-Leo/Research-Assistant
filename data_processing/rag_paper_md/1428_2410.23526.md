# LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models

链接: http://arxiv.org/abs/2410.23526v1

原文摘要:
Large language models (LLMs) have shown remarkable capabilities in various
natural language processing tasks, yet they often struggle with maintaining
factual accuracy, particularly in knowledge-intensive domains like healthcare.
This study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,
a novel approach designed to enhance the factual reliability of LLMs, with a
focus on medical question answering (QA). LEAF utilizes a dual strategy to
enhance the factual accuracy of responses from models such as Llama 3 70B
Instruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,
improves Retrieval-Augmented Generation (RAG) by incorporating fact-checking
results to guide the retrieval process without updating model parameters. The
second strategy, Learning from Fact-Checks via Self-Training, involves
supervised fine-tuning (SFT) on fact-checked responses or applying Simple
Preference Optimization (SimPO) with fact-checking as a ranking mechanism, both
updating LLM parameters from supervision. These findings suggest that
integrating fact-checked responses whether through RAG enhancement or
self-training enhances the reliability and factual correctness of LLM outputs,
offering a promising solution for applications where information accuracy is
crucial.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理任务中展现出卓越能力，但在保持事实准确性方面仍存在挑战，尤其在医疗等知识密集型领域。本研究提出LEAF框架（基于事实核查的学习与评估），通过创新方法提升LLMs的事实可靠性，重点关注医学问答（QA）场景。LEAF采用双重策略优化Llama 3 70B Instruct和Llama 3 8B Instruct等模型输出的准确性：其一是"先核查后检索增强生成"（Fact-Check-Then-RAG），通过将事实核查结果融入检索过程来改进检索增强生成技术（RAG），无需更新模型参数；其二是"基于事实核查的自训练学习"（Learning from Fact-Checks via Self-Training），采用监督微调（SFT）处理核查后的响应数据，或应用以事实核查为排序机制的简单偏好优化（SimPO），这两种方式都通过监督信号更新LLM参数。实验表明，无论是通过RAG增强还是自训练机制，整合事实核查结果都能显著提升模型输出的可靠性与事实准确性，为信息准确性至关重要的应用场景提供了有效解决方案。
