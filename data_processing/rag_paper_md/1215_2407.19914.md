# Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models

链接: http://arxiv.org/abs/2407.19914v1

原文摘要:
Sentiment analysis is a widely researched area within Natural Language
Processing (NLP), attracting significant interest due to the advent of
automated solutions. Despite this, the task remains challenging because of the
inherent complexity of languages and the subjective nature of sentiments. It is
even more challenging for less-studied and less-resourced languages such as
Lithuanian. Our review of existing Lithuanian NLP research reveals that
traditional machine learning methods and classification algorithms have limited
effectiveness for the task. In this work, we address sentiment analysis of
Lithuanian five-star-based online reviews from multiple domains that we collect
and clean. We apply transformer models to this task for the first time,
exploring the capabilities of pre-trained multilingual Large Language Models
(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the
inherent difficulty of the task, the fine-tuned models perform quite well,
especially when the sentiments themselves are less ambiguous: 80.74% and 89.61%
testing recognition accuracy of the most popular one- and five-star reviews
respectively. They significantly outperform current commercial state-of-the-art
general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.

中文翻译:
情感分析是自然语言处理(NLP)领域中一个被广泛研究的课题，随着自动化解决方案的出现而备受关注。尽管如此，由于语言固有的复杂性和情感的主观性，这项任务仍然具有挑战性。对于立陶宛语等研究较少且资源匮乏的语言而言，这一挑战更为严峻。我们对现有立陶宛语NLP研究的回顾表明，传统机器学习方法和分类算法在该任务上效果有限。本研究针对从多领域收集并清洗的立陶宛语五星制在线评论进行情感分析，首次将Transformer模型应用于该任务，探索了预训练多语言大语言模型(LLMs)的能力，特别聚焦于微调BERT和T5模型。鉴于任务本身的高难度，经过微调的模型表现相当出色，尤其在情感表达较为明确时：对最常见的一星和五星评论的测试识别准确率分别达到80.74%和89.61%。这些模型显著优于当前最先进的商用通用大语言模型GPT-4。我们已将微调后的大语言模型在线公开分享。
