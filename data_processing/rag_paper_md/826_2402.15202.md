# Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models

链接: http://arxiv.org/abs/2402.15202v1

原文摘要:
Impressive results have been achieved in natural language processing (NLP)
tasks through the training of large language models (LLMs). However, these
models occasionally produce toxic content such as insults, threats, and
profanity in response to certain prompts, thereby constraining their practical
utility. To tackle this issue, various finetuning-based and decoding-based
approaches have been utilized to mitigate toxicity. However, these methods
typically necessitate additional costs such as high-quality training data or
auxiliary models. In this paper, we propose fine-grained detoxification via
instance-level prefixes (FGDILP) to mitigate toxic text without additional
cost. Specifically, FGDILP contrasts the contextualized representation in
attention space using a positive prefix-prepended prompt against multiple
negative prefix-prepended prompts at the instance level. This allows for
constructing fine-grained subtoxicity vectors, which enables collaborative
detoxification by fusing them to correct the normal generation process when
provided with a raw prompt. We validate that FGDILP enables controlled text
generation with regard to toxicity at both the utterance and context levels.
Our method surpasses prompt-based baselines in detoxification, although at a
slight cost to generation fluency and diversity.

中文翻译:
通过大规模语言模型（LLMs）的训练，自然语言处理（NLP）任务已取得显著成果。然而，这些模型在响应某些提示时偶尔会产生侮辱性、威胁性或污秽内容等有害输出，从而限制了其实际应用。为解决该问题，研究者采用了基于微调和基于解码的多种方法来降低毒性，但这些方法通常需要额外成本（如高质量训练数据或辅助模型）。本文提出基于实例级前缀的细粒度去毒方法（FGDILP），在不增加额外成本的前提下实现文本去毒。具体而言，FGDILP在注意力空间中将添加正向前缀的提示与多个添加负向前缀的提示进行实例级表征对比，由此构建细粒度亚毒性向量。通过融合这些向量对原始提示的正常生成过程进行协同校正，实现去毒目标。实验验证表明，FGDILP能在语句和上下文层面实现毒性可控的文本生成。尽管在生成流畅性和多样性方面略有损耗，本方法在去毒效果上超越了基于提示的基线模型。
