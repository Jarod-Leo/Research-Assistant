# Fine-Grained Detoxification via Instance-Level Prefixes for Large Language Models

链接: http://arxiv.org/abs/2402.15202v1

原文摘要:
Impressive results have been achieved in natural language processing (NLP)
tasks through the training of large language models (LLMs). However, these
models occasionally produce toxic content such as insults, threats, and
profanity in response to certain prompts, thereby constraining their practical
utility. To tackle this issue, various finetuning-based and decoding-based
approaches have been utilized to mitigate toxicity. However, these methods
typically necessitate additional costs such as high-quality training data or
auxiliary models. In this paper, we propose fine-grained detoxification via
instance-level prefixes (FGDILP) to mitigate toxic text without additional
cost. Specifically, FGDILP contrasts the contextualized representation in
attention space using a positive prefix-prepended prompt against multiple
negative prefix-prepended prompts at the instance level. This allows for
constructing fine-grained subtoxicity vectors, which enables collaborative
detoxification by fusing them to correct the normal generation process when
provided with a raw prompt. We validate that FGDILP enables controlled text
generation with regard to toxicity at both the utterance and context levels.
Our method surpasses prompt-based baselines in detoxification, although at a
slight cost to generation fluency and diversity.

中文翻译:
在自然语言处理（NLP）任务中，通过训练大语言模型（LLMs）已取得显著成果。然而，这些模型在响应某些提示时偶尔会产生侮辱性言论、威胁内容或污言秽语等有害输出，从而限制了其实用价值。为解决该问题，现有研究主要采用基于微调和基于解码的两类方法来降低毒性，但这些方法通常需要额外成本（如高质量训练数据或辅助模型）。本文提出基于实例级前缀的细粒度去毒方法（FGDILP），无需额外资源即可实现文本脱毒。具体而言，FGDILP在注意力空间中对添加正向前缀的提示与多个添加负向前缀的提示进行实例级上下文表征对比，由此构建细粒度亚毒性向量。通过融合这些向量对原始提示的正常生成过程进行协同校正，实现去毒目标。实验证明，FGDILP能在语句级和上下文级实现毒性可控的文本生成。尽管该方法会轻微影响生成流畅度与多样性，但其去毒效果显著优于基于提示的基线模型。

（翻译说明：采用学术论文摘要的标准表述方式，通过以下处理确保专业性：
1. 术语统一："toxicity"译为"毒性"，"detoxification"译为"去毒/脱毒"
2. 技术概念准确传达："instance-level prefixes"译为"实例级前缀"，"contextualized representation"译为"上下文表征"
3. 长句拆分重组：将原文复合句按中文习惯分解为多个短句，如方法原理部分
4. 被动语态转化："are utilized"译为"主要采用"
5. 逻辑连接显化：通过"由此""通过...实现"等衔接词保持论证连贯性
6. 学术用语规范："surpasses...baselines"译为"显著优于基线模型"）
