# A Zero-shot Learning Method Based on Large Language Models for Multi-modal Knowledge Graph Embedding

链接: http://arxiv.org/abs/2503.07202v1

原文摘要:
Zero-shot learning (ZL) is crucial for tasks involving unseen categories,
such as natural language processing, image classification, and cross-lingual
transfer.Current applications often fail to accurately infer and handle new
relations orentities involving unseen categories, severely limiting their
scalability and prac-ticality in open-domain scenarios. ZL learning faces the
challenge of effectivelytransferring semantic information of unseen categories
in multi-modal knowledgegraph (MMKG) embedding representation learning. In this
paper, we proposeZSLLM, a framework for zero-shot embedding learning of MMKGs
using largelanguage models (LLMs). We leverage textual modality information of
unseencategories as prompts to fully utilize the reasoning capabilities of
LLMs, enablingsemantic information transfer across different modalities for
unseen categories.Through model-based learning, the embedding representation of
unseen cate-gories in MMKG is enhanced. Extensive experiments conducted on
multiplereal-world datasets demonstrate the superiority of our approach
compared tostate-of-the-art methods.

中文翻译:
零样本学习（ZL）在涉及未知类别的任务中至关重要，例如自然语言处理、图像分类和跨语言迁移。现有应用往往无法准确推断和处理涉及未知类别的新关系或实体，严重限制了其在开放域场景中的扩展性和实用性。ZL学习面临的核心挑战是如何在多模态知识图谱（MMKG）嵌入表示学习中有效传递未知类别的语义信息。本文提出ZSLLM框架，利用大语言模型（LLM）实现MMKG的零样本嵌入学习。我们通过提取未知类别的文本模态信息作为提示，充分发挥LLM的推理能力，实现跨模态的未知类别语义信息迁移。基于模型的学习方法显著增强了MMKG中未知类别的嵌入表示能力。在多个真实数据集上的大量实验表明，本方法相较最先进技术具有显著优势。
