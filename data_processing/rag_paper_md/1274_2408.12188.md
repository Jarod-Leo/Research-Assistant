# Reasoning Factual Knowledge in Structured Data with Large Language Models

链接: http://arxiv.org/abs/2408.12188v1

原文摘要:
Large language models (LLMs) have made remarkable progress in various natural
language processing tasks as a benefit of their capability to comprehend and
reason with factual knowledge. However, a significant amount of factual
knowledge is stored in structured data, which possesses unique characteristics
that differ from the unstructured texts used for pretraining. This difference
can introduce imperceptible inference parameter deviations, posing challenges
for LLMs in effectively utilizing and reasoning with structured data to
accurately infer factual knowledge. To this end, we propose a benchmark named
StructFact, to evaluate the structural reasoning capabilities of LLMs in
inferring factual knowledge. StructFact comprises 8,340 factual questions
encompassing various tasks, domains, timelines, and regions. This benchmark
allows us to investigate the capability of LLMs across five factual tasks
derived from the unique characteristics of structural facts. Extensive
experiments on a set of LLMs with different training strategies reveal the
limitations of current LLMs in inferring factual knowledge from structured
data. We present this benchmark as a compass to navigate the strengths and
weaknesses of LLMs in reasoning with structured data for knowledge-sensitive
tasks, and to encourage advancements in related real-world applications. Please
find our code at https://github.com/EganGu/StructFact.

中文翻译:
大型语言模型（LLMs）凭借其对事实知识的理解与推理能力，在各类自然语言处理任务中取得了显著进展。然而，大量事实知识存储于结构化数据中，这类数据具有与预训练所用非结构化文本截然不同的特性。这种差异可能导致难以察觉的推理参数偏差，使得LLMs在有效利用结构化数据进行准确事实知识推断时面临挑战。为此，我们提出名为StructFact的基准测试，用于评估LLMs在推断事实知识时的结构化推理能力。该基准包含8,340道涵盖多任务、多领域、多时间线与多地域的事实性问题，通过从结构化事实特性中提炼出的五项任务维度，系统探究LLMs的能力边界。针对采用不同训练策略的LLMs系列模型的大规模实验表明，当前模型在从结构化数据推断事实知识方面存在明显局限。我们期望该基准能作为衡量LLMs在知识敏感任务中结构化数据推理能力的风向标，并为相关现实应用的进步提供推动力。代码详见https://github.com/EganGu/StructFact。
