# LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking

链接: http://arxiv.org/abs/2404.05624v1

原文摘要:
The use of LLMs for natural language processing has become a popular trend in
the past two years, driven by their formidable capacity for context
comprehension and learning, which has inspired a wave of research from
academics and industry professionals. However, for certain NLP tasks, such as
NER, the performance of LLMs still falls short when compared to supervised
learning methods. In our research, we developed a NER processing framework
called LTNER that incorporates a revolutionary Contextualized Entity Marking
Gen Method. By leveraging the cost-effective GPT-3.5 coupled with context
learning that does not require additional training, we significantly improved
the accuracy of LLMs in handling NER tasks. The F1 score on the CoNLL03 dataset
increased from the initial 85.9% to 91.9%, approaching the performance of
supervised fine-tuning. This outcome has led to a deeper understanding of the
potential of LLMs.

中文翻译:
过去两年，大语言模型（LLM）凭借其强大的上下文理解与学习能力，在自然语言处理领域的应用已成为一股热潮，激发了学术界与产业界的研究浪潮。然而针对命名实体识别（NER）等特定NLP任务，LLM的表现仍逊色于监督学习方法。本研究通过构建LTNER处理框架，创新性地提出语境化实体标记生成方法（Contextualized Entity Marking Gen Method），利用性价比优势显著的GPT-3.5结合无需额外训练的上下文学习，将LLM处理NER任务的准确率显著提升——CoNLL03数据集的F1值从初始85.9%提升至91.9%，逼近监督微调的表现。这一成果使我们对LLM的潜力有了更深刻的认识。
