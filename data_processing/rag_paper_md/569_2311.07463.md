# MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks

链接: http://arxiv.org/abs/2311.07463v1

原文摘要:
There has been a surge in LLM evaluation research to understand LLM
capabilities and limitations. However, much of this research has been confined
to English, leaving LLM building and evaluation for non-English languages
relatively unexplored. Several new LLMs have been introduced recently,
necessitating their evaluation on non-English languages. This study aims to
perform a thorough evaluation of the non-English capabilities of SoTA LLMs
(GPT-3.5-Turbo, GPT-4, PaLM2, Gemini-Pro, Mistral, Llama2, and Gemma) by
comparing them on the same set of multilingual datasets. Our benchmark
comprises 22 datasets covering 83 languages, including low-resource African
languages. We also include two multimodal datasets in the benchmark and compare
the performance of LLaVA models, GPT-4-Vision and Gemini-Pro-Vision. Our
experiments show that larger models such as GPT-4, Gemini-Pro and PaLM2
outperform smaller models on various tasks, notably on low-resource languages,
with GPT-4 outperforming PaLM2 and Gemini-Pro on more datasets. We also perform
a study on data contamination and find that several models are likely to be
contaminated with multilingual evaluation benchmarks, necessitating approaches
to detect and handle contamination while assessing the multilingual performance
of LLMs.

中文翻译:
为深入理解大语言模型（LLM）的能力与局限，相关评估研究呈现爆发式增长。然而，这类研究大多局限于英语领域，针对非英语语言的LLM构建与评估仍处于探索不足的状态。随着GPT-3.5-Turbo、GPT-4、PaLM2、Gemini-Pro、Mistral、Llama2和Gemma等新一代模型的相继问世，亟需对其非英语语言能力进行系统评估。本研究通过统一的多语言数据集对比测试，对上述前沿LLM的非英语能力展开全面评估。我们的基准测试涵盖22个数据集、83种语言（包括资源稀缺的非洲语言），并纳入两个多模态数据集以对比LLaVA模型、GPT-4-Vision和Gemini-Pro-Vision的表现。实验表明，GPT-4、Gemini-Pro和PaLM2等大型模型在各类任务（尤其是低资源语言任务）上显著优于小型模型，其中GPT-4在多数数据集上表现优于PaLM2和Gemini-Pro。此外，我们进行了数据污染专项研究，发现多个模型可能受到多语言评估基准数据的污染，这提示在评估LLM多语言性能时需建立污染检测与处理机制。
