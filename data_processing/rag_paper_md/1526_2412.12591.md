# LLMs are Also Effective Embedding Models: An In-depth Overview

链接: http://arxiv.org/abs/2412.12591v1

原文摘要:
Large language models (LLMs) have revolutionized natural language processing
by achieving state-of-the-art performance across various tasks. Recently, their
effectiveness as embedding models has gained attention, marking a paradigm
shift from traditional encoder-only models like ELMo and BERT to decoder-only,
large-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an
in-depth overview of this transition, beginning with foundational techniques
before the LLM era, followed by LLM-based embedding models through two main
strategies to derive embeddings from LLMs. 1) Direct prompting: We mainly
discuss the prompt designs and the underlying rationale for deriving
competitive embeddings. 2) Data-centric tuning: We cover extensive aspects that
affect tuning an embedding model, including model architecture, training
objectives, data constructions, etc. Upon the above, we also cover advanced
methods, such as handling longer texts, and multilingual and cross-modal data.
Furthermore, we discuss factors affecting choices of embedding models, such as
performance/efficiency comparisons, dense vs sparse embeddings, pooling
strategies, and scaling law. Lastly, the survey highlights the limitations and
challenges in adapting LLMs for embeddings, including cross-task embedding
quality, trade-offs between efficiency and accuracy, low-resource,
long-context, data bias, robustness, etc. This survey serves as a valuable
resource for researchers and practitioners by synthesizing current
advancements, highlighting key challenges, and offering a comprehensive
framework for future work aimed at enhancing the effectiveness and efficiency
of LLMs as embedding models.

中文翻译:
大语言模型（LLM）通过在各种任务中实现最先进的性能，彻底改变了自然语言处理领域。近期，其作为嵌入模型的有效性备受关注，标志着从ELMo、BERT等传统仅编码器模型向GPT、LLaMA、Mistral等仅解码器大规模LLM的范式转变。本综述深入探讨了这一转型：首先回顾LLM时代之前的基础技术，随后聚焦基于LLM的嵌入模型，系统阐述从LLM生成嵌入向量的两大策略：1）直接提示法：重点分析提示设计原理及其生成优质嵌入的理论基础；2）数据导向调优法：全面探讨影响嵌入模型调优的要素，包括模型架构、训练目标、数据构建等。在此基础上，我们还涵盖处理长文本、多语言及跨模态数据等前沿方法。此外，本文深入分析影响嵌入模型选择的因素，如性能/效率对比、稠密与稀疏嵌入差异、池化策略及缩放规律。最后，研究揭示了LLM适配嵌入任务时的局限与挑战，包括跨任务嵌入质量、效率与精度权衡、低资源场景、长上下文处理、数据偏见及鲁棒性等问题。本综述通过整合当前进展、突出关键挑战，并为提升LLM作为嵌入模型的效能与效率提供系统框架，为研究者和实践者提供了重要参考。
