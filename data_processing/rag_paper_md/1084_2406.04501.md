# FLUID-LLM: Learning Computational Fluid Dynamics with Spatiotemporal-aware Large Language Models

链接: http://arxiv.org/abs/2406.04501v1

原文摘要:
Learning computational fluid dynamics (CFD) traditionally relies on
computationally intensive simulations of the Navier-Stokes equations. Recently,
large language models (LLMs) have shown remarkable pattern recognition and
reasoning abilities in natural language processing (NLP) and computer vision
(CV). However, these models struggle with the complex geometries inherent in
fluid dynamics. We introduce FLUID-LLM, a novel framework combining pre-trained
LLMs with spatiotemporal-aware encoding to predict unsteady fluid dynamics. Our
approach leverages the temporal autoregressive abilities of LLMs alongside
spatial-aware layers, bridging the gap between previous CFD prediction methods.
Evaluations on standard benchmarks reveal significant performance improvements
across various fluid datasets. Our results demonstrate that FLUID-LLM
effectively integrates spatiotemporal information into pre-trained LLMs,
enhancing CFD task performance.

中文翻译:
传统上，学习计算流体力学（CFD）依赖于对纳维-斯托克斯方程进行高计算成本的数值模拟。近年来，大语言模型（LLMs）在自然语言处理（NLP）和计算机视觉（CV）领域展现出卓越的模式识别与推理能力。然而，这些模型难以处理流体力学中固有的复杂几何结构。我们提出FLUID-LLM这一创新框架，通过将预训练大语言模型与时空感知编码相结合，实现对非定常流体动力学的高效预测。该方法充分发挥LLMs的时间自回归能力，同时结合空间感知层，弥合了现有CFD预测方法间的技术鸿沟。在标准基准测试中，该模型在多种流体数据集上均展现出显著的性能提升。实验结果表明，FLUID-LLM成功将时空信息整合至预训练大语言模型中，有效提升了CFD任务的处理效能。

（翻译说明：采用学术论文的规范表述，保留"CFD/LLMs"等专业缩写首次出现时的全称；将"spatiotemporal-aware encoding"译为专业术语"时空感知编码"；"unsteady fluid dynamics"按流体力学规范译为"非定常流体动力学"；通过"技术鸿沟""处理效能"等措辞体现学术文本的严谨性；长句拆分符合中文表达习惯，如将"leveraging...alongside..."处理为并列结构；保持被动语态与主动语态的合理转换，如"Evaluations reveal"译为主动式"测试中展现"。）
