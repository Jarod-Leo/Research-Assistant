# Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health

链接: http://arxiv.org/abs/2412.12981v1

原文摘要:
Large language models (LLMs) have shown promising capabilities in healthcare
analysis but face several challenges like hallucinations, parroting, and bias
manifestation. These challenges are exacerbated in complex, sensitive, and
low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an
expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by
generating in-context conversational dialogues leveraging LLMs, particularly
ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues
and tailored information, taking into account therapy style (empathy,
reflection), contextual relevance, and false semantic change. Subsequently, the
dialogues are annotated by experts, strictly adhering to the Motivational
Interviewing Skills Code (MISC), focusing on both the psychological and
linguistic dimensions of MI dialogues. We comprehensively evaluate the
IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding
of domain intricacies by modeling novel classification tasks employing several
classical machine learning and current state-of-the-art transformer approaches.
Finally, we discuss the effects of progressive prompting strategies and the
impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our
contributions provide the MI community with not only a comprehensive dataset
but also valuable insights for using LLMs in empathetic text generation for
conversational therapy in supervised settings.

中文翻译:
大型语言模型（LLMs）在医疗健康分析中展现出潜力，但仍面临幻觉、机械重复及偏见显现等挑战，这些在复杂、敏感且资源匮乏的领域尤为突出。为此，本研究基于AnnoMI框架，引入专家标注的动机性访谈（MI）数据集IC-AnnoMI——通过LLMs（特别是ChatGPT）生成上下文关联的对话语料。该数据集采用精准设计的提示策略，整合治疗风格要素（共情、反思）、语境相关性及语义真实性校验，并严格遵循《动机性访谈技能编码手册》（MISC），由专家从心理与语言双维度进行标注。我们通过构建新型分类任务，采用经典机器学习与前沿Transformer方法对IC-AnnoMI数据集及ChatGPT的情感推理与领域理解能力进行全面评估。最后探讨渐进式提示策略的效果，以及增强数据对缓解IC-AnnoMI中偏见的影响。本成果不仅为MI研究社区提供了系统化的数据集，更为监督环境下LLMs在对话治疗共情文本生成中的应用提供了重要洞见。
