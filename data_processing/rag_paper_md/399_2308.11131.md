# ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation

链接: http://arxiv.org/abs/2308.11131v1

原文摘要:
With large language models (LLMs) achieving remarkable breakthroughs in
natural language processing (NLP) domains, LLM-enhanced recommender systems
have received much attention and have been actively explored currently. In this
paper, we focus on adapting and empowering a pure large language model for
zero-shot and few-shot recommendation tasks. First and foremost, we identify
and formulate the lifelong sequential behavior incomprehension problem for LLMs
in recommendation domains, i.e., LLMs fail to extract useful information from a
textual context of long user behavior sequence, even if the length of context
is far from reaching the context limitation of LLMs. To address such an issue
and improve the recommendation performance of LLMs, we propose a novel
framework, namely Retrieval-enhanced Large Language models (ReLLa) for
recommendation tasks in both zero-shot and few-shot settings. For zero-shot
recommendation, we perform semantic user behavior retrieval (SUBR) to improve
the data quality of testing samples, which greatly reduces the difficulty for
LLMs to extract the essential knowledge from user behavior sequences. As for
few-shot recommendation, we further design retrieval-enhanced instruction
tuning (ReiT) by adopting SUBR as a data augmentation technique for training
samples. Specifically, we develop a mixed training dataset consisting of both
the original data samples and their retrieval-enhanced counterparts. We conduct
extensive experiments on three real-world public datasets to demonstrate the
superiority of ReLLa compared with existing baseline models, as well as its
capability for lifelong sequential behavior comprehension. To be highlighted,
with only less than 10% training samples, few-shot ReLLa can outperform
traditional CTR models that are trained on the entire training set (e.g.,
DCNv2, DIN, SIM). The code is available
\url{https://github.com/LaVieEnRose365/ReLLa}.

中文翻译:
随着大语言模型（LLM）在自然语言处理（NLP）领域取得显著突破，LLM增强的推荐系统受到广泛关注并成为当前研究热点。本文聚焦于如何适配并赋能纯大语言模型，使其胜任零样本和小样本推荐任务。首先，我们首次发现并系统阐述了LLM在推荐领域面临的终身序列行为理解障碍问题——即当用户行为序列的文本上下文长度远未达到模型限制时，LLM仍无法有效提取长行为序列中的关键信息。针对这一核心问题，我们提出创新框架ReLLa（检索增强的大语言模型），通过双重机制提升推荐性能：在零样本场景下，采用语义用户行为检索（SUBR）技术优化测试样本数据质量，显著降低LLM从长行为序列中提取本质知识的难度；在小样本场景下，进一步设计检索增强指令微调（ReiT），将SUBR作为训练样本的数据增强手段，构建由原始样本及其检索增强版本组成的混合训练集。基于三个真实公开数据集的实验表明，ReLLa不仅显著优于现有基线模型，更展现出卓越的终身序列行为理解能力。值得强调的是，仅需不足10%的训练样本，小样本ReLLa即可超越传统点击率模型（如DCNv2、DIN、SIM）在全量训练集上的表现。代码已开源于\url{https://github.com/LaVieEnRose365/ReLLa}。
