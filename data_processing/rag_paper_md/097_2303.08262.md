# Clinical Concept and Relation Extraction Using Prompt-based Machine Reading Comprehension

链接: http://arxiv.org/abs/2303.08262v1

原文摘要:
Objective: To develop a natural language processing system that solves both
clinical concept extraction and relation extraction in a unified prompt-based
machine reading comprehension (MRC) architecture with good generalizability for
cross-institution applications.
  Methods: We formulate both clinical concept extraction and relation
extraction using a unified prompt-based MRC architecture and explore
state-of-the-art transformer models. We compare our MRC models with existing
deep learning models for concept extraction and end-to-end relation extraction
using two benchmark datasets developed by the 2018 National NLP Clinical
Challenges (n2c2) challenge (medications and adverse drug events) and the 2022
n2c2 challenge (relations of social determinants of health [SDoH]). We also
evaluate the transfer learning ability of the proposed MRC models in a
cross-institution setting. We perform error analyses and examine how different
prompting strategies affect the performance of MRC models.
  Results and Conclusion: The proposed MRC models achieve state-of-the-art
performance for clinical concept and relation extraction on the two benchmark
datasets, outperforming previous non-MRC transformer models. GatorTron-MRC
achieves the best strict and lenient F1-scores for concept extraction,
outperforming previous deep learning models on the two datasets by 1%~3% and
0.7%~1.3%, respectively. For end-to-end relation extraction, GatorTron-MRC and
BERT-MIMIC-MRC achieve the best F1-scores, outperforming previous deep learning
models by 0.9%~2.4% and 10%-11%, respectively. For cross-institution
evaluation, GatorTron-MRC outperforms traditional GatorTron by 6.4% and 16% for
the two datasets, respectively. The proposed method is better at handling
nested/overlapped concepts, extracting relations, and has good portability for
cross-institute applications.

中文翻译:
目的：开发一种自然语言处理系统，采用基于提示的统一机器阅读理解（MRC）架构，同步解决临床概念抽取与关系抽取任务，并具备跨机构应用的优异泛化能力。

方法：通过统一提示框架将临床概念与关系抽取重构为MRC任务，探索前沿Transformer模型的应用。基于2018年n2c2挑战赛（药物与不良反应）和2022年n2c2挑战赛（健康社会决定因素[SDoH]关系）两个基准数据集，将所提MRC模型与现有深度学习模型在概念抽取及端到端关系抽取任务上进行对比。同时评估模型在跨机构场景下的迁移学习能力，通过错误分析探究不同提示策略对模型性能的影响。

结果与结论：所提MRC模型在两个基准数据集上均取得最先进的临床概念与关系抽取性能。GatorTron-MRC在概念抽取任务中严格/宽松F1值分别超越原深度学习模型1%~3%和0.7%~1.3%；在端到端关系抽取中，GatorTron-MRC与BERT-MIMIC-MRC分别以0.9%~2.4%和10%-11%的优势领先。跨机构评估显示，GatorTron-MRC相较传统GatorTron在两个数据集上分别提升6.4%和16%。该方法在嵌套/重叠概念处理、关系抽取方面表现更优，且具备良好的跨机构移植性。
