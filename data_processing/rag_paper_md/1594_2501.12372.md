# Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL

链接: http://arxiv.org/abs/2501.12372v1

原文摘要:
Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of natural language processing tasks. In particular, improvements in
reasoning abilities and the expansion of context windows have opened new
avenues for leveraging these powerful models. NL2SQL is challenging in that the
natural language question is inherently ambiguous, while the SQL generation
requires a precise understanding of complex data schema and semantics. One
approach to this semantic ambiguous problem is to provide more and sufficient
contextual information.
  In this work, we explore the performance and the latency trade-offs of the
extended context window (a.k.a., long context) offered by Google's
state-of-the-art LLM (\textit{gemini-1.5-pro}). We study the impact of various
contextual information, including column example values, question and SQL query
pairs, user-provided hints, SQL documentation, and schema. To the best of our
knowledge, this is the first work to study how the extended context window and
extra contextual information can help NL2SQL generation with respect to both
accuracy and latency cost. We show that long context LLMs are robust and do not
get lost in the extended contextual information. Additionally, our long-context
NL2SQL pipeline based on Google's \textit{gemini-pro-1.5} achieve strong
performances on various benchmark datasets without finetuning and expensive
self-consistency based techniques.

中文翻译:
大型语言模型（LLMs）在一系列自然语言处理任务中展现出卓越能力，尤其是推理能力的提升与上下文窗口的扩展为利用这些强大模型开辟了新途径。自然语言转SQL（NL2SQL）的挑战在于自然语言问题本身具有模糊性，而SQL生成却需要精确理解复杂的数据模式与语义。解决这一语义模糊问题的途径之一是提供更充分的情境信息。

本研究探索了谷歌前沿LLM模型（gemini-1.5-pro）提供的扩展上下文窗口（即长上下文）在性能与延迟间的权衡。我们系统考察了多种情境信息的影响，包括列示例值、问答对与SQL查询对、用户提示、SQL文档及数据模式。据我们所知，这是首个针对扩展上下文窗口与额外情境信息如何提升NL2SQL生成准确性及延迟代价的综合性研究。实验表明，长上下文LLM具有强健性，不会在扩展情境信息中迷失方向。此外，基于谷歌gemini-pro-1.5构建的长上下文NL2SQL流程，在不进行微调且未采用昂贵自洽技术的情况下，于多个基准数据集上均取得了优异表现。
