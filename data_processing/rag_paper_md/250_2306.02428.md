# Taught by the Internet, Exploring Bias in OpenAIs GPT3

链接: http://arxiv.org/abs/2306.02428v1

原文摘要:
This research delves into the current literature on bias in Natural Language
Processing Models and the techniques proposed to mitigate the problem of bias,
including why it is important to tackle bias in the first place. Additionally,
these techniques are further analysed in the light of newly developed models
that tower in size over past editions. To achieve those aims, the authors of
this paper conducted their research on GPT3 by OpenAI, the largest NLP model
available to consumers today. With 175 billion parameters in contrast to BERTs
340 million, GPT3 is the perfect model to test the common pitfalls of NLP
models. Tests were conducted through the development of an Applicant Tracking
System using GPT3. For the sake of feasibility and time constraints, the tests
primarily focused on gender bias, rather than all or multiple types of bias.
Finally, current mitigation techniques are considered and tested to measure
their degree of functionality.

中文翻译:
本研究深入探讨了当前关于自然语言处理模型中偏见问题的文献，以及为解决偏见问题所提出的技术方法，包括为何首先解决偏见问题至关重要。此外，结合新开发的大规模模型（其体量远超以往版本），对这些技术进行了进一步分析。为实现这些目标，本文作者对OpenAI开发的GPT-3（目前面向用户的最大自然语言处理模型）进行了研究。相较于BERT的3.4亿参数，GPT-3拥有1750亿参数，是测试自然语言处理模型常见缺陷的理想对象。研究通过开发一个基于GPT-3的申请人追踪系统进行测试。鉴于可行性和时间限制，测试主要聚焦于性别偏见，而非涵盖所有或多种偏见类型。最后，对现有缓解技术进行了考量与测试，以评估其实际效果程度。
