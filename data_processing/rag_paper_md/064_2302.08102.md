# Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition

链接: http://arxiv.org/abs/2302.08102v1

原文摘要:
Visual Speech Recognition (VSR) aims to infer speech into text depending on
lip movements alone. As it focuses on visual information to model the speech,
its performance is inherently sensitive to personal lip appearances and
movements, and this makes the VSR models show degraded performance when they
are applied to unseen speakers. In this paper, to remedy the performance
degradation of the VSR model on unseen speakers, we propose prompt tuning
methods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,
motivated by recent advances in Natural Language Processing (NLP), we finetune
prompts on adaptation data of target speakers instead of modifying the
pre-trained model parameters. Different from the previous prompt tuning methods
mainly limited to Transformer variant architecture, we explore different types
of prompts, the addition, the padding, and the concatenation form prompts that
can be applied to the VSR model which is composed of CNN and Transformer in
general. With the proposed prompt tuning, we show that the performance of the
pre-trained VSR model on unseen speakers can be largely improved by using a
small amount of adaptation data (e.g., less than 5 minutes), even if the
pre-trained model is already developed with large speaker variations. Moreover,
by analyzing the performance and parameters of different types of prompts, we
investigate when the prompt tuning is preferred over the finetuning methods.
The effectiveness of the proposed method is evaluated on both word- and
sentence-level VSR databases, LRW-ID and GRID.

中文翻译:
视觉语音识别（VSR）旨在仅通过唇部动作推断出对应的文本内容。由于该技术依赖视觉信息建模语音，其性能本质上对个体唇部外观与运动特征敏感，导致预训练模型在面对陌生说话者时表现显著下降。针对这一问题，本文提出基于深度神经网络（DNN）的提示调优方法，实现说话者自适应的VSR模型优化。受自然语言处理（NLP）领域最新进展启发，我们通过在目标说话者的适配数据上微调提示向量（而非调整预训练模型参数）来实现性能提升。不同于以往主要局限于Transformer架构的提示调优方法，我们探索了适用于CNN-Transformer混合架构VSR模型的多种提示形式：加法型提示、填充型提示和拼接型提示。实验表明，即使预训练模型已涵盖大量说话者变体，采用少量适配数据（如不足5分钟）进行提示调优仍能大幅提升模型对陌生说话者的识别准确率。通过对比分析不同类型提示的性能表现与参数规模，我们进一步揭示了提示调优相较于传统微调方法的适用场景。该方法在词汇级（LRW-ID）和句子级（GRID）VSR数据库上的有效性均得到验证。
