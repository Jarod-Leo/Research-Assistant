# Perplexed: Understanding When Large Language Models are Confused

链接: http://arxiv.org/abs/2404.06634v1

原文摘要:
Large Language Models (LLMs) have become dominant in the Natural Language
Processing (NLP) field causing a huge surge in progress in a short amount of
time. However, their limitations are still a mystery and have primarily been
explored through tailored datasets to analyze a specific human-level skill such
as negation, name resolution, etc. In this paper, we introduce perplexed, a
library for exploring where a particular language model is perplexed. To show
the flexibility and types of insights that can be gained by perplexed, we
conducted a case study focused on LLMs for code generation using an additional
tool we built to help with the analysis of code models called codetokenizer.
Specifically, we explore success and failure cases at the token level of code
LLMs under different scenarios pertaining to the type of coding structure the
model is predicting, e.g., a variable name or operator, and how predicting of
internal verses external method invocations impact performance. From this
analysis, we found that our studied code LLMs had their worst performance on
coding structures where the code was not syntactically correct. Additionally,
we found the models to generally perform worse at predicting internal method
invocations than external ones. We have open sourced both of these tools to
allow the research community to better understand LLMs in general and LLMs for
code generation.

中文翻译:
大型语言模型（LLMs）已在自然语言处理（NLP）领域占据主导地位，短时间内推动研究取得巨大进展。然而，其局限性仍不明确，目前主要通过针对特定人类能力（如否定、名称解析等）构建的定制数据集进行分析。本文介绍了一个名为perplexed的开源工具库，用于探索特定语言模型的困惑边界。为展示该工具的灵活性和可获取的洞察类型，我们以代码生成LLMs为案例展开研究，并开发了辅助分析工具codetokenizer。研究聚焦于代码模型在预测不同编程结构（如变量名、运算符）时的令牌级表现差异，以及内部与外部方法调用预测对性能的影响。分析发现：所研究的代码LLMs在语法不正确的代码结构上表现最差；且模型预测内部方法调用的表现普遍逊色于外部调用。我们已将这两个工具开源，以助力研究社区更深入地理解通用LLMs及代码生成专用LLMs的特性。
