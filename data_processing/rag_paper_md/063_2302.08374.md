# Efficiency 360: Efficient Vision Transformers

链接: http://arxiv.org/abs/2302.08374v2

原文摘要:
Transformers are widely used for solving tasks in natural language
processing, computer vision, speech, and music domains. In this paper, we talk
about the efficiency of transformers in terms of memory (the number of
parameters), computation cost (number of floating points operations), and
performance of models, including accuracy, the robustness of the model, and
fair \& bias-free features. We mainly discuss the vision transformer for the
image classification task. Our contribution is to introduce an efficient 360
framework, which includes various aspects of the vision transformer, to make it
more efficient for industrial applications. By considering those applications,
we categorize them into multiple dimensions such as privacy, robustness,
transparency, fairness, inclusiveness, continual learning, probabilistic
models, approximation, computational complexity, and spectral complexity. We
compare various vision transformer models based on their performance, the
number of parameters, and the number of floating point operations (FLOPs) on
multiple datasets.

中文翻译:
以下是符合要求的学术摘要中文翻译：

Transformer模型已广泛应用于自然语言处理、计算机视觉、语音及音乐领域的任务求解。本文从内存占用（参数量）、计算成本（浮点运算次数）及模型性能（包括准确率、鲁棒性、公平无偏特性）三个维度探讨Transformer的效率问题。我们以图像分类任务中的视觉Transformer为核心研究对象，提出一个高效的360度评估框架，该框架涵盖视觉Transformer的多个优化层面，旨在提升其工业应用效率。基于实际应用需求，我们将优化维度划分为隐私保护、鲁棒性、可解释性、公平性、包容性、持续学习、概率模型、近似计算、计算复杂度与谱复杂度等类别。通过在多个数据集上对比不同视觉Transformer模型的参数量、浮点运算量（FLOPs）及性能指标，进行了系统性评估。

（注：根据学术翻译规范，关键术语处理如下：
1. "floating points operations" 采用计算机领域通用译法"浮点运算"
2. "360 framework" 译为"360度评估框架"以保留原文的全方位评估含义
3. 专业术语如"FLOPs"、"鲁棒性"等采用学科通用译法
4. 长难句按中文表达习惯进行了分切重组，如将原文最后两句合并为符合中文论文摘要的结论句式）
