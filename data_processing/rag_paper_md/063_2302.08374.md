# Efficiency 360: Efficient Vision Transformers

链接: http://arxiv.org/abs/2302.08374v2

原文摘要:
Transformers are widely used for solving tasks in natural language
processing, computer vision, speech, and music domains. In this paper, we talk
about the efficiency of transformers in terms of memory (the number of
parameters), computation cost (number of floating points operations), and
performance of models, including accuracy, the robustness of the model, and
fair \& bias-free features. We mainly discuss the vision transformer for the
image classification task. Our contribution is to introduce an efficient 360
framework, which includes various aspects of the vision transformer, to make it
more efficient for industrial applications. By considering those applications,
we categorize them into multiple dimensions such as privacy, robustness,
transparency, fairness, inclusiveness, continual learning, probabilistic
models, approximation, computational complexity, and spectral complexity. We
compare various vision transformer models based on their performance, the
number of parameters, and the number of floating point operations (FLOPs) on
multiple datasets.

中文翻译:
Transformer模型在自然语言处理、计算机视觉、语音及音乐领域被广泛用于解决各类任务。本文重点探讨了Transformer在内存占用（参数量）、计算成本（浮点运算次数）以及模型性能（包括准确率、鲁棒性、公平性与无偏见特性）三个维度的效率问题，并以图像分类任务中的视觉Transformer为核心研究对象。我们提出了一种高效的360度评估框架，该框架涵盖视觉Transformer的多个层面，旨在提升其在工业应用中的效率。基于实际应用需求，我们将评估维度划分为隐私保护、鲁棒性、可解释性、公平性、包容性、持续学习能力、概率建模、近似计算、计算复杂度与频谱复杂度等类别。通过在多数据集上对比不同视觉Transformer模型的性能表现、参数量及浮点运算量（FLOPs），为模型选择提供量化依据。
