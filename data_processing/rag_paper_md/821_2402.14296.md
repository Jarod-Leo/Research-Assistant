# Mitigating Biases of Large Language Models in Stance Detection with Calibration

链接: http://arxiv.org/abs/2402.14296v1

原文摘要:
Stance detection is critical for understanding the underlying position or
attitude expressed toward a topic. Large language models (LLMs) have
demonstrated significant advancements across various natural language
processing tasks including stance detection, however, their performance in
stance detection is limited by biases and spurious correlations inherent due to
their data-driven nature. Our statistical experiment reveals that LLMs are
prone to generate biased stances due to sentiment-stance spurious correlations
and preference towards certain individuals and topics. Furthermore, the results
demonstrate a strong negative correlation between stance bias and stance
detection performance, underscoring the importance of mitigating bias to
enhance the utility of LLMs in stance detection. Therefore, in this paper, we
propose a Counterfactual Augmented Calibration Network (FACTUAL), which a novel
calibration network is devised to calibrate potential bias in the stance
prediction of LLMs. Further, to address the challenge of effectively learning
bias representations and the difficulty in the generalizability of debiasing,
we construct counterfactual augmented data. This approach enhances the
calibration network, facilitating the debiasing and out-of-domain
generalization. Experimental results on in-target and zero-shot stance
detection tasks show that the proposed FACTUAL can effectively mitigate biases
of LLMs, achieving state-of-the-art results.

中文翻译:
立场检测对于理解针对某一主题所表达的基本立场或态度至关重要。大型语言模型（LLMs）在包括立场检测在内的多种自然语言处理任务中展现出显著进步，但其立场检测性能受限于数据驱动特性固有的偏见与虚假关联。我们的统计实验表明，由于情感-立场虚假关联以及对特定个体和话题的倾向性，LLMs容易生成带有偏见的立场。此外，研究结果揭示了立场偏见与检测性能之间存在显著负相关，凸显了减少偏见对提升LLMs在立场检测中实用性的重要性。为此，本文提出反事实增强校准网络（FACTUAL），通过设计新型校准网络来修正LLMs立场预测中的潜在偏差。针对有效学习偏差表征的挑战及去偏泛化难题，我们构建了反事实增强数据。该方法强化了校准网络的去偏能力，促进了跨领域泛化。在目标内和零样本立场检测任务上的实验结果表明，所提出的FACTUAL能有效降低LLMs的偏见，取得最先进的性能表现。
