# Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)

链接: http://arxiv.org/abs/2404.16653v1

原文摘要:
Linguistic ambiguity continues to represent a significant challenge for
natural language processing (NLP) systems, notwithstanding the advancements in
architectures such as Transformers and BERT. Inspired by the recent success of
instructional models like ChatGPT and Gemini (In 2023, the artificial
intelligence was called Bard.), this study aims to analyze and discuss
linguistic ambiguity within these models, focusing on three types prevalent in
Brazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a
corpus comprising 120 sentences, both ambiguous and unambiguous, for
classification, explanation, and disambiguation. The models capability to
generate ambiguous sentences was also explored by soliciting sets of sentences
for each type of ambiguity. The results underwent qualitative analysis, drawing
on recognized linguistic references, and quantitative assessment based on the
accuracy of the responses obtained. It was evidenced that even the most
sophisticated models, such as ChatGPT and Gemini, exhibit errors and
deficiencies in their responses, with explanations often providing
inconsistent. Furthermore, the accuracy peaked at 49.58 percent, indicating the
need for descriptive studies for supervised learning.

中文翻译:
语言歧义性始终是自然语言处理（NLP）系统面临的重大挑战，即便Transformer架构和BERT等模型已取得显著进展。受ChatGPT、Gemini（2023年该人工智能曾命名为Bard）等指令型模型近期成功的启发，本研究聚焦巴西葡萄牙语中常见的语义、句法和词汇三类歧义现象，旨在分析探讨这些模型对语言歧义的处理能力。我们构建了包含120个歧义与非歧义句子的语料库，用于分类、解释及消歧任务，并通过要求模型生成各类歧义句来考察其创造能力。研究结果采用定性分析（基于权威语言学理论）与定量评估（依据回答准确率）相结合的方法，发现即便是ChatGPT和Gemini这类最先进的模型，其回答仍存在错误与缺陷，解释内容常出现前后矛盾。最高准确率仅达49.58%，这表明亟需开展描述性研究以支持监督学习。
