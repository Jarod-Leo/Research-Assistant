# Research about the Ability of LLM in the Tamper-Detection Area

链接: http://arxiv.org/abs/2401.13504v1

原文摘要:
In recent years, particularly since the early 2020s, Large Language Models
(LLMs) have emerged as the most powerful AI tools in addressing a diverse range
of challenges, from natural language processing to complex problem-solving in
various domains. In the field of tamper detection, LLMs are capable of
identifying basic tampering activities.To assess the capabilities of LLMs in
more specialized domains, we have collected five different LLMs developed by
various companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. This
diverse range of models allows for a comprehensive evaluation of their
performance in detecting sophisticated tampering instances.We devised two
domains of detection: AI-Generated Content (AIGC) detection and manipulation
detection. AIGC detection aims to test the ability to distinguish whether an
image is real or AI-generated. Manipulation detection, on the other hand,
focuses on identifying tampered images. According to our experiments, most LLMs
can identify composite pictures that are inconsistent with logic, and only more
powerful LLMs can distinguish logical, but visible signs of tampering to the
human eye. All of the LLMs can't identify carefully forged images and very
realistic images generated by AI. In the area of tamper detection, LLMs still
have a long way to go, particularly in reliably identifying highly
sophisticated forgeries and AI-generated images that closely mimic reality.

中文翻译:
近年来，尤其是自2020年代初以来，大型语言模型（LLMs）已成为应对从自然语言处理到各领域复杂问题解决等多样化挑战的最强人工智能工具。在篡改检测领域，LLMs能够识别基础的篡改行为。为评估LLMs在更专业领域的表现，我们汇集了由不同企业开发的五种模型：GPT-4、LLaMA、Bard、文心一言4.0和通义千问。这种多元化的模型组合为全面评估其在检测复杂篡改实例中的性能提供了条件。

我们设定了两大检测方向：AI生成内容（AIGC）检测和人工篡改检测。AIGC检测旨在测试模型区分图像真伪（是否为AI生成）的能力，而人工篡改检测则聚焦于识别经过篡改的图像。实验表明，多数LLMs能够识别存在逻辑矛盾的合成图片，但只有性能更强的模型才能辨别出符合逻辑但肉眼可见篡改痕迹的图像。所有测试模型均无法识别精心伪造的图片及AI生成的高度逼真图像。在篡改检测领域，LLMs仍有长足发展空间，特别是在可靠识别高度复杂的伪造手法和以假乱真的AI生成图像方面。
