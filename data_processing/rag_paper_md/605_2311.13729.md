# Comparison of pipeline, sequence-to-sequence, and GPT models for end-to-end relation extraction: experiments with the rare disease use-case

链接: http://arxiv.org/abs/2311.13729v1

原文摘要:
End-to-end relation extraction (E2ERE) is an important and realistic
application of natural language processing (NLP) in biomedicine. In this paper,
we aim to compare three prevailing paradigms for E2ERE using a complex dataset
focused on rare diseases involving discontinuous and nested entities. We use
the RareDis information extraction dataset to evaluate three competing
approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to
sequence models, and generative pre-trained transformer (GPT) models. We use
comparable state-of-the-art models and best practices for each of these
approaches and conduct error analyses to assess their failure modes. Our
findings reveal that pipeline models are still the best, while
sequence-to-sequence models are not far behind; GPT models with eight times as
many parameters are worse than even sequence-to-sequence models and lose to
pipeline models by over 10 F1 points. Partial matches and discontinuous
entities caused many NER errors contributing to lower overall E2E performances.
We also verify these findings on a second E2ERE dataset for chemical-protein
interactions. Although generative LM-based methods are more suitable for
zero-shot settings, when training data is available, our results show that it
is better to work with more conventional models trained and tailored for E2ERE.
More innovative methods are needed to marry the best of the both worlds from
smaller encoder-decoder pipeline models and the larger GPT models to improve
E2ERE. As of now, we see that well designed pipeline models offer substantial
performance gains at a lower cost and carbon footprint for E2ERE. Our
contribution is also the first to conduct E2ERE for the RareDis dataset.

中文翻译:
端到端关系抽取（E2ERE）是自然语言处理（NLP）在生物医学领域的重要实际应用。本文旨在利用一个包含不连续及嵌套实体的罕见病复杂数据集，比较当前主流的三种E2ERE范式。我们采用RareDis信息抽取数据集评估了三种竞争性方法：命名实体识别→关系抽取的流水线模型、联合序列到序列模型，以及生成式预训练变换器（GPT）模型。针对每种方法，我们选用可比的最先进模型与最佳实践方案，并通过错误分析评估其失效模式。

研究发现，流水线模型仍保持最优性能，序列到序列模型稍逊但差距不大；而参数量达八倍的GPT模型表现甚至不及序列到序列模型，较流水线模型F1值落后超过10分。部分匹配与不连续实体导致的命名实体识别错误显著降低了整体端到端性能。我们在化学蛋白质相互作用的第二个E2ERE数据集上验证了这些结论。虽然基于生成式语言模型的方法更适用于零样本场景，但当存在训练数据时，结果表明针对E2ERE专门训练的传统模型更具优势。未来需要创新方法融合小型编码器-解码器流水线模型与大型GPT模型的优势以提升E2ERE性能。目前研究表明，精心设计的流水线模型能以更低成本与碳足迹实现显著的性能提升。本研究亦为首个针对RareDis数据集开展的端到端关系抽取工作。
