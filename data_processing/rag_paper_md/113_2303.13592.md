# Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages

链接: http://arxiv.org/abs/2303.13592v1

原文摘要:
While code-mixing is a common linguistic practice in many parts of the world,
collecting high-quality and low-cost code-mixed data remains a challenge for
natural language processing (NLP) research. The recent proliferation of Large
Language Models (LLMs) compels one to ask: how capable are these systems in
generating code-mixed data? In this paper, we explore prompting multilingual
LLMs in a zero-shot manner to generate code-mixed data for seven languages in
South East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese,
Tamil, and Singlish. We find that publicly available multilingual
instruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of
producing texts with phrases or clauses from different languages. ChatGPT
exhibits inconsistent capabilities in generating code-mixed texts, wherein its
performance varies depending on the prompt template and language pairing. For
instance, ChatGPT generates fluent and natural Singlish texts (an English-based
creole spoken in Singapore), but for English-Tamil language pair, the system
mostly produces grammatically incorrect or semantically meaningless utterances.
Furthermore, it may erroneously introduce languages not specified in the
prompt. Based on our investigation, existing multilingual LLMs exhibit a wide
range of proficiency in code-mixed data generation for SEA languages. As such,
we advise against using LLMs in this context without extensive human checks.

中文翻译:
虽然语码混合是全球许多地区常见的语言现象，但如何获取高质量、低成本的混合语料数据始终是自然语言处理（NLP）研究面临的挑战。随着大语言模型（LLM）的迅猛发展，我们不禁要问：这些系统生成混合语料的能力究竟如何？本文以零样本提示的方式，探索多语言大模型对东南亚七种语言（印尼语、马来语、汉语、他加禄语、越南语、泰米尔语及新加坡式英语）的混合语料生成能力。研究发现，当前公开的多语言指令微调模型（如BLOOMZ和Flan-T5-XXL）无法生成包含跨语言短语或从句的文本。ChatGPT在生成混合文本时表现不稳定，其效果受提示模板和语言组合的影响显著：例如该模型能生成流畅自然的新加坡式英语（一种基于英语的新加坡克里奥尔语），但在英语-泰米尔语组合中，其产出多为语法错误或语义混乱的语句，甚至可能错误引入提示词未指定的语言。研究表明，现有多语言大模型对东南亚语言的混合语料生成能力存在显著差异。据此，我们建议在此类应用场景中需经过严格人工校验方可使用大语言模型。  

（注：根据学术文本特点，翻译中进行了以下处理：  
1. "code-mixing"译为"语码混合"（语言学标准译法）  
2. "Singlish"保留特色译法"新加坡式英语"并添加括号说明  
3. 长难句拆分重组（如ChatGPT表现部分）  
4. 专业术语统一性（如"zero-shot"统一译为"零样本"）  
5. 被动语态转化（如"are incapable of"译为"无法"）  
6. 补充逻辑连接词（如"据此"）增强段落连贯性）
