# BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing

链接: http://arxiv.org/abs/2310.19975v1

原文摘要:
To enhance the performance of large language models (LLMs) in biomedical
natural language processing (BioNLP) by introducing a domain-specific
instruction dataset and examining its impact when combined with multi-task
learning principles. We created the BioInstruct, comprising 25,005 instructions
to instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were
created by prompting the GPT-4 language model with three-seed samples randomly
drawn from an 80 human curated instructions. We employed Low-Rank
Adaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these
instruction-tuned LLMs on several BioNLP tasks, which can be grouped into three
major categories: question answering(QA), information extraction(IE), and text
generation(GEN). We also examined whether categories(e.g., QA, IE, and
generation) of instructions impact model performance. Comparing with LLMs
without instruction-tuned, our instruction-tuned LLMs demonstrated marked
performance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our
7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed
other LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with
vast domain-specific data or a variety of tasks. Our results also show that the
performance gain is significantly higher when instruction fine-tuning is
conducted with closely related tasks. Our findings align with the observations
of multi-task learning, suggesting the synergies between two tasks. The
BioInstruct dataset serves as a valuable resource and instruction tuned LLMs
lead to the best performing BioNLP applications.

中文翻译:
为提升大语言模型（LLM）在生物医学自然语言处理（BioNLP）中的性能，本研究引入领域专用指令数据集，并探究其与多任务学习原则结合的效果。我们构建了包含25,005条指令的BioInstruct数据集，用于对LLaMA 1&2（7B和13B版本）进行指令微调。这些指令通过向GPT-4模型输入从80条人工编制指令中随机选取的三样本种子生成。采用低秩自适应（LoRA）方法实现参数高效微调，随后在三大类BioNLP任务（问答QA、信息抽取IE、文本生成GEN）上评估微调效果，并分析指令类别对性能的影响。

实验表明，经指令微调的模型相较基线模型取得显著提升：QA任务提高17.3%，IE任务提升5.7%，生成任务增幅达96%。其中7B参数的微调版LLaMA 1模型性能媲美甚至超越其他基于LLaMA 1架构、使用海量领域数据或多任务微调的生物医学LLM。研究还发现，当指令微调任务与目标任务高度相关时，性能增益更为显著，这与多任务学习的协同效应观察结果一致。BioInstruct数据集作为重要资源，其衍生的指令微调模型能实现最优BioNLP应用效果。

（注：根据学术摘要规范，采用以下处理：
1. 专业术语保留英文缩写并首次出现时标注全称
2. 长句拆分符合中文表达习惯
3. 被动语态转换为主动表述
4. 关键数据保留原貌
5. 逻辑连接词按中文习惯调整）
