# Image Recognition with Online Lightweight Vision Transformer: A Survey

链接: http://arxiv.org/abs/2505.03113v1

原文摘要:
The Transformer architecture has achieved significant success in natural
language processing, motivating its adaptation to computer vision tasks. Unlike
convolutional neural networks, vision transformers inherently capture
long-range dependencies and enable parallel processing, yet lack inductive
biases and efficiency benefits, facing significant computational and memory
challenges that limit its real-world applicability. This paper surveys various
online strategies for generating lightweight vision transformers for image
recognition, focusing on three key areas: Efficient Component Design, Dynamic
Network, and Knowledge Distillation. We evaluate the relevant exploration for
each topic on the ImageNet-1K benchmark, analyzing trade-offs among precision,
parameters, throughput, and more to highlight their respective advantages,
disadvantages, and flexibility. Finally, we propose future research directions
and potential challenges in the lightweighting of vision transformers with the
aim of inspiring further exploration and providing practical guidance for the
community. Project Page: https://github.com/ajxklo/Lightweight-VIT

中文翻译:
Transformer架构在自然语言处理领域取得显著成功后，其设计理念被引入计算机视觉任务。与卷积神经网络不同，视觉Transformer天生具备捕获长程依赖关系和支持并行处理的优势，但缺乏归纳偏置和计算效率，面临巨大的计算与内存开销，制约了其实际应用。本文系统综述了面向图像识别的轻量化视觉Transformer在线生成策略，聚焦三大核心方向：高效组件设计、动态网络和知识蒸馏。我们在ImageNet-1K基准上评估了各方向的相关探索，通过分析精度、参数量、吞吐量等指标的权衡关系，揭示了不同方法的优势、局限及灵活性。最后，针对视觉Transformer轻量化研究的未来发展方向与潜在挑战提出建议，旨在启发后续探索并为学界提供实践指导。项目页面：https://github.com/ajxklo/Lightweight-VIT
