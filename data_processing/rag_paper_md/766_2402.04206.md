# Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models

链接: http://arxiv.org/abs/2402.04206v1

原文摘要:
This paper introduces a system designed to generate explanations for the
actions performed by an autonomous robot in Human-Robot Interaction (HRI).
Explainability in robotics, encapsulated within the concept of an eXplainable
Autonomous Robot (XAR), is a growing research area. The work described in this
paper aims to take advantage of the capabilities of Large Language Models
(LLMs) in performing natural language processing tasks. This study focuses on
the possibility of generating explanations using such models in combination
with a Retrieval Augmented Generation (RAG) method to interpret data gathered
from the logs of autonomous systems. In addition, this work also presents a
formalization of the proposed explanation system. It has been evaluated through
a navigation test from the European Robotics League (ERL), a Europe-wide social
robotics competition. Regarding the obtained results, a validation
questionnaire has been conducted to measure the quality of the explanations
from the perspective of technical users. The results obtained during the
experiment highlight the potential utility of LLMs in achieving explanatory
capabilities in robots.

中文翻译:
本文介绍了一种专为自主机器人在人机交互(HRI)中行为生成解释的系统。机器人可解释性研究——即"可解释自主机器人"(XAR)概念所涵盖的领域——正成为日益重要的研究方向。本研究旨在利用大语言模型(LLMs)执行自然语言处理任务的优势，重点探索结合检索增强生成(RAG)方法解析自主系统日志数据以生成解释的可行性。研究同时提出了该解释系统的形式化框架，并通过欧洲机器人联盟(ERL)举办的跨欧洲社会机器人竞赛中的导航测试进行了评估。针对实验结果，研究团队面向技术用户开展了验证性问卷调查以评估解释质量。实验结果表明，大语言模型在实现机器人解释能力方面具有显著的应用潜力。
