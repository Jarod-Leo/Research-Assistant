# Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources

链接: http://arxiv.org/abs/2406.18049v1

原文摘要:
Adverse event (AE) extraction following COVID-19 vaccines from text data is
crucial for monitoring and analyzing the safety profiles of immunizations.
Traditional deep learning models are adept at learning intricate feature
representations and dependencies in sequential data, but often require
extensive labeled data. In contrast, large language models (LLMs) excel in
understanding contextual information, but exhibit unstable performance on named
entity recognition tasks, possibly due to their broad but unspecific training.
This study aims to evaluate the effectiveness of LLMs and traditional deep
learning models in AE extraction, and to assess the impact of ensembling these
models on performance. In this study, we utilized reports and posts from the
VAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal
was to extract three types of entities: "vaccine", "shot", and "ae". We
explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,
GPT-4, and Llama-2, as well as traditional deep learning models like RNN and
BioBERT. To enhance performance, we created ensembles of the three models with
the best performance. For evaluation, we used strict and relaxed F1 scores to
evaluate the performance for each entity type, and micro-average F1 was used to
assess the overall performance. The ensemble model achieved the highest
performance in "vaccine", "shot", and "ae" with strict F1-scores of 0.878,
0.930, and 0.925, respectively, along with a micro-average score of 0.903. In
conclusion, this study demonstrates the effectiveness and robustness of
ensembling fine-tuned traditional deep learning models and LLMs, for extracting
AE-related information. This study contributes to the advancement of biomedical
natural language processing, providing valuable insights into improving AE
extraction from text data for pharmacovigilance and public health surveillance.

中文翻译:
从文本数据中提取COVID-19疫苗接种后的不良事件（AE）对于监测和分析免疫接种的安全性至关重要。传统的深度学习模型擅长学习序列数据中复杂的特征表示和依赖关系，但通常需要大量标注数据。相比之下，大型语言模型（LLMs）在理解上下文信息方面表现出色，但在命名实体识别任务上表现不稳定，可能是由于其广泛但非特定的训练所致。本研究旨在评估LLMs和传统深度学习模型在AE提取中的有效性，并评估集成这些模型对性能的影响。在本研究中，我们使用了来自VAERS（n=621）、Twitter（n=9,133）和Reddit（n=131）的报告和帖子作为语料库。我们的目标是提取三种类型的实体：“疫苗”、“接种”和“不良事件”。我们探索并微调（除GPT-4外）了多种LLMs，包括GPT-2、GPT-3.5、GPT-4和Llama-2，以及传统的深度学习模型如RNN和BioBERT。为了提高性能，我们创建了表现最佳的三个模型的集成。在评估方面，我们使用严格和宽松的F1分数来评估每种实体类型的性能，并使用微平均F1来评估整体性能。集成模型在“疫苗”、“接种”和“不良事件”上取得了最高性能，严格的F1分数分别为0.878、0.930和0.925，微平均分数为0.903。总之，本研究证明了集成微调的传统深度学习模型和LLMs在提取AE相关信息方面的有效性和鲁棒性。这项研究有助于推动生物医学自然语言处理的进步，为药物警戒和公共卫生监测中从文本数据中改进AE提取提供了宝贵的见解。
