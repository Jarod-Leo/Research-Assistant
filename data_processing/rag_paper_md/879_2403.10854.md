# A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment

链接: http://arxiv.org/abs/2403.10854v1

原文摘要:
While Multimodal Large Language Models (MLLMs) have experienced significant
advancement in visual understanding and reasoning, their potential to serve as
powerful, flexible, interpretable, and text-driven models for Image Quality
Assessment (IQA) remains largely unexplored. In this paper, we conduct a
comprehensive and systematic study of prompting MLLMs for IQA. We first
investigate nine prompting systems for MLLMs as the combinations of three
standardized testing procedures in psychophysics (i.e., the single-stimulus,
double-stimulus, and multiple-stimulus methods) and three popular prompting
strategies in natural language processing (i.e., the standard, in-context, and
chain-of-thought prompting). We then present a difficult sample selection
procedure, taking into account sample diversity and uncertainty, to further
challenge MLLMs equipped with the respective optimal prompting systems. We
assess three open-source and one closed-source MLLMs on several visual
attributes of image quality (e.g., structural and textural distortions,
geometric transformations, and color differences) in both full-reference and
no-reference scenarios. Experimental results show that only the closed-source
GPT-4V provides a reasonable account for human perception of image quality, but
is weak at discriminating fine-grained quality variations (e.g., color
differences) and at comparing visual quality of multiple images, tasks humans
can perform effortlessly.

中文翻译:
虽然多模态大语言模型（MLLMs）在视觉理解与推理领域取得了显著进展，但其作为强大、灵活、可解释且文本驱动的图像质量评估（IQA）工具的潜力仍未被充分发掘。本文对MLLMs在IQA任务中的提示方法进行了全面系统的研究：首先探索了九种提示系统，这些系统结合了心理物理学中的三种标准化测试方法（单刺激法、双刺激法和多刺激法）与自然语言处理中的三种主流提示策略（标准提示、上下文提示和思维链提示）；随后提出了一种综合考虑样本多样性与不确定性的困难样本选择流程，用以进一步检验配备最优提示系统的MLLMs。我们在全参考和无参考场景下，针对图像质量的多个视觉属性（如结构/纹理失真、几何变换、色彩差异等），评估了三个开源模型和一个闭源模型。实验结果表明，仅有闭源的GPT-4V能合理反映人类对图像质量的感知，但在辨别细粒度质量差异（如色彩差异）及多图像质量比较任务中表现欠佳——这些恰恰是人类能够轻松完成的工作。
