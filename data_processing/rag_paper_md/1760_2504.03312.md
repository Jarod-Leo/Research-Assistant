# Evaluating Compact LLMs for Zero-Shot Iberian Language Tasks on End-User Devices

链接: http://arxiv.org/abs/2504.03312v1

原文摘要:
Large Language Models have significantly advanced natural language
processing, achieving remarkable performance in tasks such as language
generation, translation, and reasoning. However, their substantial
computational requirements restrict deployment to high-end systems, limiting
accessibility on consumer-grade devices. This challenge is especially
pronounced for under-resourced languages like those spoken in the Iberian
Peninsula, where relatively limited linguistic resources and benchmarks hinder
effective evaluation. This work presents a comprehensive evaluation of compact
state-of-the-art LLMs across several essential NLP tasks tailored for Iberian
languages. The results reveal that while some models consistently excel in
certain tasks, significant performance gaps remain, particularly for languages
such as Basque. These findings highlight the need for further research on
balancing model compactness with robust multilingual performance

中文翻译:
大型语言模型在自然语言处理领域取得了显著进展，在文本生成、翻译和推理等任务中展现出卓越性能。然而，其庞大的计算需求限制了这些模型只能部署于高端系统，导致消费级设备难以应用。这一挑战对于伊比利亚半岛等资源匮乏的语言尤为突出——相对有限的语言资源和基准测试阻碍了有效评估。本研究针对伊比利亚语言定制了多项核心NLP任务，对紧凑型前沿大语言模型进行了全面评估。结果表明，虽然某些模型在特定任务中表现优异，但依然存在明显的性能差距，尤其是巴斯克语等语言。这些发现凸显了在模型轻量化与稳健的多语言性能之间寻求平衡的迫切需求。
