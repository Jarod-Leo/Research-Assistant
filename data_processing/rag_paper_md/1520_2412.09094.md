# Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion

链接: http://arxiv.org/abs/2412.09094v1

原文摘要:
Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a filter-then-generate paradigm and formulate the KGC task into a
multiple-choice question format. In this way, we can harness the capability of
LLMs while mitigating the issue casused by hallucinations. Moreover, we devise
a flexible ego-graph serialization prompt and employ a structure-text adapter
to couple structure and text information in a contextualized manner.
Experimental results demonstrate that FtG achieves substantial performance gain
compared to existing state-of-the-art methods. The instruction dataset and code
are available at https://github.com/LB0828/FtG.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）具备海量先验知识与卓越的语义理解能力，为自然语言处理领域的各项任务带来了革命性变革。然而在知识图谱补全（KGC）任务中，现有研究表明即便采用精妙的提示设计或定制化的指令微调，LLMs的表现仍持续逊色于传统KGC方法。究其本质，将LLMs应用于KGC面临三大核心挑战：实体候选集规模庞大、模型幻觉问题突出，以及图结构信息利用不足。

针对这些挑战，我们提出了一种基于指令微调的创新方法FtG。具体而言：首先构建"筛选-生成"范式，将KGC任务重构为多项选择题形式，在保留LLMs核心能力的同时有效缓解幻觉问题；其次设计动态化的自我中心图序列化提示模板，并采用结构-文本适配器实现图结构与文本信息的上下文感知融合。实验结果表明，FtG相较现有最优方法实现了显著性能提升。相关指令数据集与代码已开源在https://github.com/LB0828/FtG。

（翻译说明：
1. 专业术语处理：LLMs/KGC等专业缩写首次出现时保留英文并添加中文全称
2. 长句拆分：将原文复合长句按中文表达习惯拆分为多个短句
3. 被动语态转换："are employed"等被动结构转换为主动语态
4. 逻辑显化：通过"究其本质"等连接词强化段落逻辑性
5. 学术风格保持：使用"范式""适配器"等规范学术用语
6. 文化适配："hallucination"译为业界通用术语"幻觉问题"而非字面直译）
