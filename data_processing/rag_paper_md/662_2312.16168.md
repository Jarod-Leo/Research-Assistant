# Social-Transmotion: Promptable Human Trajectory Prediction

链接: http://arxiv.org/abs/2312.16168v1

原文摘要:
Accurate human trajectory prediction is crucial for applications such as
autonomous vehicles, robotics, and surveillance systems. Yet, existing models
often fail to fully leverage the non-verbal social cues human subconsciously
communicate when navigating the space. To address this, we introduce
Social-Transmotion, a generic Transformer-based model that exploits diverse and
numerous visual cues to predict human behavior. We translate the idea of a
prompt from Natural Language Processing (NLP) to the task of human trajectory
prediction, where a prompt can be a sequence of x-y coordinates on the ground,
bounding boxes in the image plane, or body pose keypoints in either 2D or 3D.
This, in turn, augments trajectory data, leading to enhanced human trajectory
prediction. Using masking technique, our model exhibits flexibility and
adaptability by capturing spatiotemporal interactions between agents based on
the available visual cues. We delve into the merits of using 2D versus 3D
poses, and a limited set of poses. Additionally, we investigate the spatial and
temporal attention map to identify which keypoints and time-steps in the
sequence are vital for optimizing human trajectory prediction. Our approach is
validated on multiple datasets, including JTA, JRDB, Pedestrians and Cyclists
in Road Traffic, and ETH-UCY. The code is publicly available:
https://github.com/vita-epfl/social-transmotion.

中文翻译:
精准预测人类运动轨迹对于自动驾驶车辆、机器人及监控系统等应用至关重要。然而现有模型往往未能充分利用人类在空间移动时潜意识传递的非语言社交信号。为此，我们提出Social-Transmotion——一种基于Transformer架构的通用模型，通过整合多样化视觉线索来预测人类行为。我们将自然语言处理中的提示（prompt）概念创新性地应用于轨迹预测任务，提示可以是地面x-y坐标序列、图像平面边界框，或二维/三维人体姿态关键点。这种处理方式有效扩充了轨迹数据，从而提升预测性能。借助掩码技术，我们的模型能根据可用视觉线索捕捉智能体间的时空交互，展现出卓越的灵活性与适应性。我们深入分析了二维与三维姿态数据、以及有限姿态集的优劣差异，并通过时空注意力图定位序列中对优化预测至关重要的关键点与时间步。本方法在JTA、JRDB、道路交通中的行人自行车（Pedestrians and Cyclists in Road Traffic）及ETH-UCY等多个数据集上验证有效，代码已开源。
