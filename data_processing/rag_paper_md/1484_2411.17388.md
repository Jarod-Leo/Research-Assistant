# Can LLMs be Good Graph Judger for Knowledge Graph Construction?

链接: http://arxiv.org/abs/2411.17388v1

原文摘要:
In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

中文翻译:
在实际应用场景中，从信息检索系统获取的数据大多是非结构化的。如何将自然语言句子转化为结构化的知识图谱（KG）仍是一个关键挑战。构建的知识图谱质量还会影响GraphRAG系统、推荐系统等依赖图谱的领域性能。近年来，大语言模型（LLM）在解决各类自然语言处理任务中展现出卓越能力，但将其用于生成结构化知识图谱仍存在挑战。我们总结了现有知识图谱构建方法的三大局限：（1）现实文档信息量大且噪声过多，易导致提取信息混乱；（2）原生LLM难以从专业领域文档准确提取知识；（3）直接使用LLM作为无监督图谱构建方法时，幻觉现象不可忽视。

本文提出GraphJudger框架以应对上述挑战，创新性地引入三个模块：以实体为核心的迭代式文本去噪、知识感知的指令微调，以及图谱判定机制。我们突破性地将LLM作为图谱判定器（而非传统预测器）来发挥其优势。在两个通用文本-图谱数据集和一个领域专用数据集上的实验表明，本方法显著优于基线模型。项目代码已开源于https://github.com/hhy-huang/GraphJudger。
