# Vision-Language Models for Edge Networks: A Comprehensive Survey

链接: http://arxiv.org/abs/2502.07855v1

原文摘要:
Vision Large Language Models (VLMs) combine visual understanding with natural
language processing, enabling tasks like image captioning, visual question
answering, and video analysis. While VLMs show impressive capabilities across
domains such as autonomous vehicles, smart surveillance, and healthcare, their
deployment on resource-constrained edge devices remains challenging due to
processing power, memory, and energy limitations. This survey explores recent
advancements in optimizing VLMs for edge environments, focusing on model
compression techniques, including pruning, quantization, knowledge
distillation, and specialized hardware solutions that enhance efficiency. We
provide a detailed discussion of efficient training and fine-tuning methods,
edge deployment challenges, and privacy considerations. Additionally, we
discuss the diverse applications of lightweight VLMs across healthcare,
environmental monitoring, and autonomous systems, illustrating their growing
impact. By highlighting key design strategies, current challenges, and offering
recommendations for future directions, this survey aims to inspire further
research into the practical deployment of VLMs, ultimately making advanced AI
accessible in resource-limited settings.

中文翻译:
视觉大语言模型（VLMs）通过融合视觉理解与自然语言处理能力，实现了图像描述生成、视觉问答及视频分析等任务。尽管该技术在自动驾驶、智能安防和医疗等领域展现出卓越性能，但由于边缘设备的算力、内存和能耗限制，其实际部署仍面临重大挑战。本文系统综述了面向边缘环境优化VLMs的最新进展，重点探讨了模型压缩技术（包括剪枝、量化、知识蒸馏）以及提升效率的专用硬件解决方案。我们详细分析了高效训练与微调方法、边缘部署难点及隐私考量，并阐述了轻量化VLMs在医疗健康、环境监测和自主系统等领域的多样化应用场景，揭示其日益增长的影响力。通过提炼关键设计策略、剖析现存挑战并提出未来研究方向，本综述旨在推动VLMs在资源受限场景中的实用化进程，最终实现先进人工智能在边缘计算环境中的普惠化应用。
