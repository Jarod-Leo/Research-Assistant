# ConvMixFormer- A Resource-efficient Convolution Mixer for Transformer-based Dynamic Hand Gesture Recognition

链接: http://arxiv.org/abs/2411.07118v1

原文摘要:
Transformer models have demonstrated remarkable success in many domains such
as natural language processing (NLP) and computer vision. With the growing
interest in transformer-based architectures, they are now utilized for gesture
recognition. So, we also explore and devise a novel ConvMixFormer architecture
for dynamic hand gestures. The transformers use quadratic scaling of the
attention features with the sequential data, due to which these models are
computationally complex and heavy. We have considered this drawback of the
transformer and designed a resource-efficient model that replaces the
self-attention in the transformer with the simple convolutional layer-based
token mixer. The computational cost and the parameters used for the
convolution-based mixer are comparatively less than the quadratic
self-attention. Convolution-mixer helps the model capture the local spatial
features that self-attention struggles to capture due to their sequential
processing nature. Further, an efficient gate mechanism is employed instead of
a conventional feed-forward network in the transformer to help the model
control the flow of features within different stages of the proposed model.
This design uses fewer learnable parameters which is nearly half the vanilla
transformer that helps in fast and efficient training. The proposed method is
evaluated on NVidia Dynamic Hand Gesture and Briareo datasets and our model has
achieved state-of-the-art results on single and multimodal inputs. We have also
shown the parameter efficiency of the proposed ConvMixFormer model compared to
other methods. The source code is available at
https://github.com/mallikagarg/ConvMixFormer.

中文翻译:
Transformer模型在自然语言处理（NLP）和计算机视觉等多个领域展现出卓越性能。随着基于Transformer架构的研究热潮兴起，其应用已扩展至手势识别领域。为此，我们探索并设计了一种面向动态手势识别的新型ConvMixFormer架构。传统Transformer模型因注意力机制对序列数据的二次方复杂度计算，存在计算资源消耗大、模型体量重的缺陷。针对这一不足，我们构建了资源高效的改进模型——用基于简单卷积层的令牌混合器替代原Transformer中的自注意力机制。相较于二次方复杂度的自注意力，基于卷积的混合器在计算成本和参数量上具有显著优势。卷积混合器能有效捕捉局部空间特征，而这正是序列处理方式的自注意力机制所难以实现的。此外，模型采用高效门控机制替代传统前馈网络，以精准调控不同层级间的特征流动。该设计使可训练参数量缩减至原始Transformer的近一半，实现了快速高效的模型训练。在NVidia动态手势数据集和Briareo数据集上的实验表明，无论是单模态还是多模态输入，本方法均取得了最先进的识别效果。参数量对比实验进一步验证了ConvMixFormer的优越性。源代码已开源：https://github.com/mallikagarg/ConvMixFormer。
