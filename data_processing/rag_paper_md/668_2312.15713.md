# PersianLLaMA: Towards Building First Persian Large Language Model

链接: http://arxiv.org/abs/2312.15713v1

原文摘要:
Despite the widespread use of the Persian language by millions globally,
limited efforts have been made in natural language processing for this
language. The use of large language models as effective tools in various
natural language processing tasks typically requires extensive textual data and
robust hardware resources. Consequently, the scarcity of Persian textual data
and the unavailability of powerful hardware resources have hindered the
development of large language models for Persian. This paper introduces the
first large Persian language model, named PersianLLaMA, trained on a collection
of Persian texts and datasets. This foundational model comes in two versions,
with 7 and 13 billion parameters, trained on formal and colloquial Persian
texts using two different approaches. PersianLLaMA has been evaluated for
natural language generation tasks based on the latest evaluation methods,
namely using larger language models, and for natural language understanding
tasks based on automated machine metrics. The results indicate that
PersianLLaMA significantly outperforms its competitors in both understanding
and generating Persian text. PersianLLaMA marks an important step in the
development of Persian natural language processing and can be a valuable
resource for the Persian-speaking community. This large language model can be
used for various natural language processing tasks, especially text generation
like chatbots, question-answering, machine translation, and text summarization

中文翻译:
尽管波斯语在全球范围内被数百万人广泛使用，但针对该语言的自然语言处理研究却相对有限。大型语言模型作为各类自然语言处理任务的有效工具，通常需要海量文本数据和强大硬件资源的支持。然而，波斯语文本数据的匮乏与高性能硬件资源的不可及性，长期阻碍着波斯语大语言模型的研发。本文首次推出了基于波斯语文本与数据集训练的大型语言模型PersianLLaMA，该基础模型包含70亿和130亿参数两个版本，分别采用两种不同训练方法处理正式与口语化波斯语文本。通过最新评估方法——即采用更大型语言模型进行自然语言生成任务测试，以及基于自动化机器指标的自然语言理解任务评估，结果表明PersianLLaMA在波斯语文本理解与生成方面均显著优于同类模型。该模型的诞生标志着波斯语自然语言处理发展的重要里程碑，将为波斯语社区提供宝贵资源。这一大型语言模型可应用于多种自然语言处理任务，特别适用于聊天机器人、问答系统、机器翻译及文本摘要等文本生成场景。
