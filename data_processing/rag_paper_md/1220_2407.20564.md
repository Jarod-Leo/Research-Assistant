# CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge

链接: http://arxiv.org/abs/2407.20564v1

原文摘要:
While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

中文翻译:
尽管大型语言模型（LLMs）通过从海量训练数据中获取丰富的事实知识，在各种自然语言处理任务中展现出卓越能力，但其以复杂方式综合运用知识进行逻辑推理的潜力仍未得到充分探索。本研究通过构建一个基于通用领域和生物医学知识图谱自动生成的复杂推理问题基准测试，对前沿LLMs的复杂逻辑推理能力展开系统性评估。我们采用多样化的上下文学习技术进行广泛实验，发现LLMs在通用世界知识推理方面表现优异，但在专业领域知识处理上存在显著困难。研究表明，通过显式思维链提示可显著提升LLMs在包含多样化逻辑运算的复杂推理任务中的表现。值得注意的是，对照实验揭示了一个不对称现象：LLMs擅长处理集合并运算，却在作为逻辑推理关键要素的集合交运算上表现欠佳。为促进后续研究，我们将公开评测基准与相关代码。
