# Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation

链接: http://arxiv.org/abs/2501.10150v1

原文摘要:
Mitigation of biases, such as language models' reliance on gender
stereotypes, is a crucial endeavor required for the creation of reliable and
useful language technology. The crucial aspect of debiasing is to ensure that
the models preserve their versatile capabilities, including their ability to
solve language tasks and equitably represent various genders. To address this
issue, we introduce a streamlined Dual Dabiasing Algorithm through Model
Adaptation (2DAMA). Novel Dual Debiasing enables robust reduction of
stereotypical bias while preserving desired factual gender information encoded
by language models. We show that 2DAMA effectively reduces gender bias in
English and is one of the first approaches facilitating the mitigation of
stereotypical tendencies in translation. The proposed method's key advantage is
the preservation of factual gender cues, which are useful in a wide range of
natural language processing tasks.

中文翻译:
减轻语言模型对性别刻板印象等偏见的依赖，是构建可靠实用语言技术的关键任务。去偏过程中的核心在于确保模型在消除偏见的同时，仍能保持其多方面的能力——包括解决语言任务和公平呈现不同性别的能力。针对这一挑战，我们提出了一种通过模型适配实现的双重去偏算法2DAMA（Dual Debiasing Algorithm through Model Adaptation）。这种创新的双重去偏机制能在保留语言模型编码的真实性别信息前提下，有效削弱刻板印象偏见。研究表明，2DAMA不仅能显著降低英语中的性别偏见，还成为首批能缓解翻译过程中刻板化倾向的方法之一。该方案的核心优势在于保留了具有实际价值的性别线索，这些线索对各类自然语言处理任务都具有重要意义。
