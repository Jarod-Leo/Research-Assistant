# Emoji Prediction using Transformer Models

链接: http://arxiv.org/abs/2307.02054v1

原文摘要:
In recent years, the use of emojis in social media has increased
dramatically, making them an important element in understanding online
communication. However, predicting the meaning of emojis in a given text is a
challenging task due to their ambiguous nature. In this study, we propose a
transformer-based approach for emoji prediction using BERT, a widely-used
pre-trained language model. We fine-tuned BERT on a large corpus of text
(tweets) containing both text and emojis to predict the most appropriate emoji
for a given text. Our experimental results demonstrate that our approach
outperforms several state-of-the-art models in predicting emojis with an
accuracy of over 75 percent. This work has potential applications in natural
language processing, sentiment analysis, and social media marketing.

中文翻译:
近年来，社交媒体中表情符号的使用量激增，使其成为理解网络交流的重要元素。然而由于表情符号的歧义性，预测特定文本中表情符号的含义成为一项具有挑战性的任务。本研究提出了一种基于Transformer架构的BERT模型表情预测方法，该预训练语言模型已被广泛应用。我们通过在包含文本和表情符号的大型推文语料库上对BERT进行微调，实现了给定文本最适配表情符号的预测。实验结果表明，该方法以超过75%的准确率在表情预测任务上优于多种前沿模型。这项研究在自然语言处理、情感分析和社交媒体营销等领域具有潜在应用价值。
