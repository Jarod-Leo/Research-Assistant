# Towards Equitable AI: Detecting Bias in Using Large Language Models for Marketing

链接: http://arxiv.org/abs/2502.12838v1

原文摘要:
The recent advances in large language models (LLMs) have revolutionized
industries such as finance, marketing, and customer service by enabling
sophisticated natural language processing tasks. However, the broad adoption of
LLMs brings significant challenges, particularly in the form of social biases
that can be embedded within their outputs. Biases related to gender, age, and
other sensitive attributes can lead to unfair treatment, raising ethical
concerns and risking both company reputation and customer trust. This study
examined bias in finance-related marketing slogans generated by LLMs (i.e.,
ChatGPT) by prompting tailored ads targeting five demographic categories:
gender, marital status, age, income level, and education level. A total of
1,700 slogans were generated for 17 unique demographic groups, and key terms
were categorized into four thematic groups: empowerment, financial, benefits
and features, and personalization. Bias was systematically assessed using
relative bias calculations and statistically tested with the Kolmogorov-Smirnov
(KS) test against general slogans generated for any individual. Results
revealed that marketing slogans are not neutral; rather, they emphasize
different themes based on demographic factors. Women, younger individuals,
low-income earners, and those with lower education levels receive more distinct
messaging compared to older, higher-income, and highly educated individuals.
This underscores the need to consider demographic-based biases in AI-generated
marketing strategies and their broader societal implications. The findings of
this study provide a roadmap for developing more equitable AI systems,
highlighting the need for ongoing bias detection and mitigation efforts in
LLMs.

中文翻译:
近年来，大型语言模型（LLMs）的突破性进展通过实现复杂的自然语言处理任务，彻底改变了金融、营销和客户服务等行业。然而，LLMs的广泛应用也带来了重大挑战，尤其是其输出中可能隐含的社会偏见。涉及性别、年龄等敏感属性的偏见会导致不公平待遇，不仅引发伦理争议，更可能危及企业声誉与客户信任。本研究以ChatGPT生成的金融营销口号为对象，通过针对性别、婚姻状况、年龄、收入水平和教育程度五类人口统计特征定制广告语，系统分析了其中存在的偏见。研究共为17个独特人群生成了1700条口号，将核心术语划分为四大主题类别：赋权、金融属性、利益与功能、个性化表达。采用相对偏差计算法进行系统评估，并通过Kolmogorov-Smirnov检验与面向普通个体的通用口号进行统计比较。结果显示营销口号并非中立，而是基于人口统计因素强调不同主题。相较于年长、高收入和高学历群体，女性、年轻人、低收入者和低教育水平者接收到的信息呈现更显著的差异化特征。这凸显了在AI生成的营销策略中考虑人口统计学偏见及其社会影响的必要性。本研究结果为开发更公平的AI系统提供了路线图，强调了对LLMs进行持续偏见检测与缓解的重要性。
