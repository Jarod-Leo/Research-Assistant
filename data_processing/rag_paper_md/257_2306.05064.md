# Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization

链接: http://arxiv.org/abs/2306.05064v1

原文摘要:
Large language models (LLMs) have achieved great success in general domains
of natural language processing. In this paper, we bring LLMs to the realm of
geoscience with the objective of advancing research and applications in this
field. To this end, we present the first-ever LLM in geoscience, K2, alongside
a suite of resources developed to further promote LLM research within
geoscience. For instance, we have curated the first geoscience instruction
tuning dataset, GeoSignal, which aims to align LLM responses to
geoscience-related user queries. Additionally, we have established the first
geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience.
In this work, we experiment with a complete recipe to adapt a pre-trained
general-domain LLM to the geoscience domain. Specifically, we further train the
LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1
million pieces of geoscience literature, and utilize GeoSignal's supervised
data to fine-tune the model. Moreover, we share a protocol that can efficiently
gather domain-specific data and construct domain-supervised data, even in
situations where manpower is scarce. Meanwhile, we equip K2 with the abilities
of using tools to be a naive geoscience aide. Experiments conducted on the
GeoBench demonstrate the effectiveness of our approach and datasets on
geoscience knowledge understanding and utilization.We open-source all the
training data and K2 model checkpoints at https://github.com/davendw49/k2.

中文翻译:
以下是符合要求的学术中文翻译：

【译文】
大语言模型（LLMs）在自然语言处理的通用领域已取得显著成就。本文通过将LLMs引入地球科学领域，旨在推动该领域的研究与应用。为此，我们首次提出地球科学专用大语言模型K2，并配套开发了一系列资源以促进该领域的LLM研究。具体包括：1）构建首个地球科学指令微调数据集GeoSignal，用于对齐LLMs对地学相关查询的响应；2）建立首个地学基准测试GeoBench，用于评估LLMs在地球科学场景下的表现。本研究探索了将预训练通用LLM适配至地学领域的完整方案：基于55亿地学文本语料（含超百万篇地学文献）对LLaMA-7B模型进行领域适应训练，并利用GeoSignal的监督数据微调模型。我们还提出一种在人力稀缺情况下仍能高效收集领域数据并构建监督数据的方案。同时，K2被赋予工具使用能力，可作为基础地学助手。GeoBench上的实验表明，我们的方法与数据集在地学知识理解与应用方面成效显著。所有训练数据及K2模型检查点已开源于https://github.com/davendw49/k2。

【翻译要点说明】
1. 专业术语处理：
- "instruction tuning dataset"译为"指令微调数据集"（学界通用译法）
- "benchmark"译为"基准测试"（计算机领域标准译法）
- "model checkpoints"译为"模型检查点"（深度学习领域规范术语）

2. 长句拆分与重组：
- 将原文复合长句拆分为符合中文表达习惯的短句结构
- 使用分号与项目符号（1）2））清晰呈现并列内容

3. 被动语态转换：
- "are developed"译为主动式"配套开发"
- "can be efficiently gathered"转换为"能高效收集"

4. 数字表达规范：
- "5.5B tokens"译为"55亿文本语料"（符合中文计量单位习惯）
- "1 million"译为"百万"（保持学术文本简洁性）

5. 学术风格保持：
- 使用"旨在""为此""具体包括"等学术论文常用连接词
- 保留"LLaMA-7B"等技术型号原文写法

6. 文化适配：
- "naive geoscience aide"意译为"基础地学助手"（避免直译"朴素"可能引发的歧义）
