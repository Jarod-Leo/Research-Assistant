# Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text

链接: http://arxiv.org/abs/2407.11774v1

原文摘要:
Detecting Machine-Generated Text (MGT) has emerged as a significant area of
study within Natural Language Processing. While language models generate text,
they often leave discernible traces, which can be scrutinized using either
traditional feature-based methods or more advanced neural language models. In
this research, we explore the effectiveness of fine-tuning a RoBERTa-base
transformer, a powerful neural architecture, to address MGT detection as a
binary classification task. Focusing specifically on Subtask A
(Monolingual-English) within the SemEval-2024 competition framework, our
proposed system achieves an accuracy of 78.9% on the test dataset, positioning
us at 57th among participants. Our study addresses this challenge while
considering the limited hardware resources, resulting in a system that excels
at identifying human-written texts but encounters challenges in accurately
discerning MGTs.

中文翻译:
机器生成文本检测（MGT）已成为自然语言处理领域的重要研究方向。尽管语言模型生成的文本常会留下可辨识的痕迹，这些痕迹既可通过传统基于特征的方法，也能借助更先进的神经语言模型进行分析。本研究探索了微调RoBERTa-base这一强大神经架构的效果，将其作为二元分类任务来解决MGT检测问题。在SemEval-2024竞赛框架下专门针对子任务A（单语英语场景），我们提出的系统在测试数据集上取得了78.9%的准确率，在参赛队伍中位列第57名。本研究在应对该挑战时充分考虑了硬件资源限制，最终开发的系统在识别人工书写文本方面表现优异，但在准确辨别机器生成文本时仍面临挑战。

（注：根据学术翻译规范，对部分术语进行了标准化处理：
1. "discernible traces"译为"可辨识的痕迹"而非字面的"可辨别的痕迹"，更符合中文表达习惯
2. "scrutinized"根据上下文译为"分析"而非直译"审查"
3. "binary classification task"统一采用机器学习领域通用译法"二元分类任务"
4. 竞赛名"SemEval-2024"保留英文原名符合学术惯例
5. 技术术语"RoBERTa-base"保持原名不翻译，这是NLP领域的标准做法）
