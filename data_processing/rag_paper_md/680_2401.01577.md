# Test-Time Personalization with Meta Prompt for Gaze Estimation

链接: http://arxiv.org/abs/2401.01577v1

原文摘要:
Despite the recent remarkable achievement in gaze estimation, efficient and
accurate personalization of gaze estimation without labels is a practical
problem but rarely touched on in the literature. To achieve efficient
personalization, we take inspiration from the recent advances in Natural
Language Processing (NLP) by updating a negligible number of parameters,
"prompts", at the test time. Specifically, the prompt is additionally attached
without perturbing original network and can contain less than 1% of a
ResNet-18's parameters. Our experiments show high efficiency of the prompt
tuning approach. The proposed one can be 10 times faster in terms of adaptation
speed than the methods compared. However, it is non-trivial to update the
prompt for personalized gaze estimation without labels. At the test time, it is
essential to ensure that the minimizing of particular unsupervised loss leads
to the goals of minimizing gaze estimation error. To address this difficulty,
we propose to meta-learn the prompt to ensure that its updates align with the
goal. Our experiments show that the meta-learned prompt can be effectively
adapted even with a simple symmetry loss. In addition, we experiment on four
cross-dataset validations to show the remarkable advantages of the proposed
method. Code is available at https://github.com/hmarkamcan/TPGaze.

中文翻译:
尽管视线估计领域近期取得了显著进展，但如何在无标注条件下实现高效精准的个性化视线估计仍是一个鲜有文献涉足的实际难题。为实现高效个性化，我们受自然语言处理（NLP）领域最新进展启发，提出在测试时仅更新可忽略数量的"提示"参数（占ResNet-18模型参数总量不足1%）。实验证明这种提示调优方法具有极高效率，其自适应速度可达对比方法的10倍以上。

然而，无监督条件下的提示参数更新面临本质性挑战：必须确保特定无监督损失的最小化能有效降低视线估计误差。为此，我们提出通过元学习来优化提示参数，使其更新方向与目标保持一致。实验表明，经元学习训练的提示参数即使配合简单的对称性损失也能有效适配。我们在四个跨数据集验证场景中的实验进一步证实了该方法的显著优势。代码已开源于https://github.com/hmarkamcan/TPGaze。
