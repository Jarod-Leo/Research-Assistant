# Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures

链接: http://arxiv.org/abs/2501.09588v1

原文摘要:
Transformer architectures have become the standard neural network model for
various machine learning applications including natural language processing and
computer vision. However, the compute and memory requirements introduced by
transformer models make them challenging to adopt for edge applications.
Furthermore, fine-tuning pre-trained transformers (e.g., foundation models) is
a common task to enhance the model's predictive performance on specific
tasks/applications. Existing transformer accelerators are oblivious to
complexities introduced by fine-tuning. In this paper, we propose the design of
a three-dimensional (3D) heterogeneous architecture referred to as Atleus that
incorporates heterogeneous computing resources specifically optimized to
accelerate transformer models for the dual purposes of fine-tuning and
inference. Specifically, Atleus utilizes non-volatile memory and systolic array
for accelerating transformer computational kernels using an integrated 3D
platform. Moreover, we design a suitable NoC to achieve high performance and
energy efficiency. Finally, Atleus adopts an effective quantization scheme to
support model compression. Experimental results demonstrate that Atleus
outperforms existing state-of-the-art by up to 56x and 64.5x in terms of
performance and energy efficiency respectively

中文翻译:
Transformer架构已成为自然语言处理、计算机视觉等各类机器学习应用的标准神经网络模型。然而，该模型对计算资源和内存的高需求使其难以应用于边缘场景。此外，针对特定任务/应用对预训练Transformer（如基础模型）进行微调以提升预测性能已成为常规操作，但现有加速器均未考虑微调带来的计算复杂度问题。本文提出名为Atleus的三维异构架构设计，通过集成专为Transformer优化的异构计算资源，实现微调与推理的双重加速。该架构创新性地采用三维集成平台，结合非易失性存储器和脉动阵列加速Transformer核心运算，并设计高性能低功耗片上网络，同时引入高效量化方案支持模型压缩。实验表明，Atleus在性能和能效方面分别较现有最优方案提升达56倍和64.5倍。

（注：译文严格遵循技术文献的学术规范，主要特点包括：
1. 专业术语准确统一："non-volatile memory"译为"非易失性存储器"，"systolic array"保留专业称谓"脉动阵列"
2. 长句拆分重构：将原文复合句按中文表达习惯分解为多个短句，如将"accelerators are oblivious to..."转化为主动语态"加速器均未考虑..."
3. 概念显化处理："dual purposes"译为"双重加速"而非字面直译，突出技术价值
4. 数据呈现规范：精确保持"56x/64.5x"等技术指标的原始表达
5. 逻辑连接优化：使用"此外""同时"等衔接词替代英文连接词，符合中文论文摘要的连贯性要求）
