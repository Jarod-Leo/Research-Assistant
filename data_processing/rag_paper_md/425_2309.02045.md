# Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies

链接: http://arxiv.org/abs/2309.02045v1

原文摘要:
Large Language Models (LLMs) have made significant strides in both scientific
research and practical applications. Existing studies have demonstrated the
state-of-the-art (SOTA) performance of LLMs in various natural language
processing tasks. However, the question of how to further enhance LLMs'
performance in specific task using prompting strategies remains a pivotal
concern. This paper explores the enhancement of LLMs' performance in sentiment
analysis through the application of prompting strategies. We formulate the
process of prompting for sentiment analysis tasks and introduce two novel
strategies tailored for sentiment analysis: RolePlaying (RP) prompting and
Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT
prompting strategy which is a combination of RP prompting and CoT prompting. We
conduct comparative experiments on three distinct domain datasets to evaluate
the effectiveness of the proposed sentiment analysis strategies. The results
demonstrate that the adoption of the proposed prompting strategies leads to a
increasing enhancement in sentiment analysis accuracy. Further, the CoT
prompting strategy exhibits a notable impact on implicit sentiment analysis,
with the RP-CoT prompting strategy delivering the most superior performance
among all strategies.

中文翻译:
大语言模型（LLMs）在科学研究与实际应用中取得了显著进展。现有研究已证明LLMs在各类自然语言处理任务中具备最先进的性能表现。然而，如何通过提示策略进一步提升LLMs在特定任务中的性能仍是关键问题。本文探索了通过提示策略增强LLMs情感分析性能的方法，系统构建了情感分析任务的提示流程，并针对性地提出两种创新策略：角色扮演（RP）提示和思维链（CoT）提示。特别地，我们还提出了融合RP提示与CoT提示的RP-CoT组合策略。通过在三个不同领域数据集上的对比实验，验证了所提情感分析策略的有效性。结果表明，采用所提出的提示策略能持续提升情感分析准确率，其中CoT策略对隐式情感分析具有显著效果，而RP-CoT策略在所有策略中展现出最优性能。
