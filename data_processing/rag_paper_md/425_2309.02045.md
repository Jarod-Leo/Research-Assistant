# Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies

链接: http://arxiv.org/abs/2309.02045v1

原文摘要:
Large Language Models (LLMs) have made significant strides in both scientific
research and practical applications. Existing studies have demonstrated the
state-of-the-art (SOTA) performance of LLMs in various natural language
processing tasks. However, the question of how to further enhance LLMs'
performance in specific task using prompting strategies remains a pivotal
concern. This paper explores the enhancement of LLMs' performance in sentiment
analysis through the application of prompting strategies. We formulate the
process of prompting for sentiment analysis tasks and introduce two novel
strategies tailored for sentiment analysis: RolePlaying (RP) prompting and
Chain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT
prompting strategy which is a combination of RP prompting and CoT prompting. We
conduct comparative experiments on three distinct domain datasets to evaluate
the effectiveness of the proposed sentiment analysis strategies. The results
demonstrate that the adoption of the proposed prompting strategies leads to a
increasing enhancement in sentiment analysis accuracy. Further, the CoT
prompting strategy exhibits a notable impact on implicit sentiment analysis,
with the RP-CoT prompting strategy delivering the most superior performance
among all strategies.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大语言模型（LLMs）在科学研究和实际应用领域均取得了显著进展。现有研究已证明LLMs在各种自然语言处理任务中具备最先进的性能表现。然而，如何通过提示策略进一步提升LLMs在特定任务中的性能，仍是当前的核心研究问题。本文探索如何运用提示策略增强LLMs在情感分析任务中的表现：我们系统构建了情感分析任务的提示流程，并针对性地提出两种创新策略——角色扮演（RP）提示和思维链（CoT）提示。特别地，我们还提出了融合RP提示与CoT提示的RP-CoT组合策略。通过在三个不同领域数据集上的对比实验，我们评估了所提情感分析策略的有效性。实验结果表明：采用这些提示策略能持续提升情感分析准确率；其中CoT策略对隐式情感分析具有显著提升效果，而RP-CoT组合策略在所有策略中展现出最优异的性能表现。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如SOTA译为"最先进的"）
2. 被动语态转换为中文主动句式（如"have been demonstrated"译为"已证明"）
3. 长难句合理切分（如将英文复合句拆解为中文流水句）
4. 学术用语规范化（如"propose"译为"提出"而非"建议"）
5. 保持逻辑严谨性（精确传达原文的因果关系和比较关系）
6. 文化适应性调整（如"RolePlaying"译为更符合中文认知的"角色扮演"而非直译））
