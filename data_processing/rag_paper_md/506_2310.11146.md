# The Quo Vadis of the Relationship between Language and Large Language Models

链接: http://arxiv.org/abs/2310.11146v1

原文摘要:
In the field of Artificial (General) Intelligence (AI), the several recent
advancements in Natural language processing (NLP) activities relying on Large
Language Models (LLMs) have come to encourage the adoption of LLMs as
scientific models of language. While the terminology employed for the
characterization of LLMs favors their embracing as such, it is not clear that
they are in a place to offer insights into the target system they seek to
represent. After identifying the most important theoretical and empirical risks
brought about by the adoption of scientific models that lack transparency, we
discuss LLMs relating them to every scientific model's fundamental components:
the object, the medium, the meaning and the user. We conclude that, at their
current stage of development, LLMs hardly offer any explanations for language,
and then we provide an outlook for more informative future research directions
on this topic.

中文翻译:
在人工智能（通用智能，AI）领域，近期基于大语言模型（LLMs）的自然语言处理（NLP）研究进展，促使学界开始将LLMs视为语言的科学模型。尽管用于描述LLMs的术语体系倾向于支持这种定位，但尚不清楚它们能否真正揭示其所试图表征的目标系统的内在机制。本文首先剖析了采用缺乏透明度的科学模型可能引发的重大理论与实证风险，继而从科学模型的四个核心要素——对象、媒介、意义与使用者——出发对LLMs进行系统性解构。研究结论表明：在当前发展阶段，LLMs几乎无法为语言现象提供任何实质性解释。最后，本文展望了该领域未来更具启发性的研究方向。
