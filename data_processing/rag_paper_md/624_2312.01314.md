# NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian

链接: http://arxiv.org/abs/2312.01314v1

原文摘要:
Norwegian, spoken by only 5 million population, is under-representative
within the most impressive breakthroughs in NLP tasks. To the best of our
knowledge, there has not yet been a comprehensive evaluation of the existing
language models (LMs) on Norwegian generation tasks during the article writing
process. To fill this gap, we 1) compiled the existing Norwegian dataset and
pre-trained 4 Norwegian Open Language Models varied from parameter scales and
architectures, collectively called NorGLM; 2) introduced a comprehensive
benchmark, NLEBench, for evaluating natural language generation capabilities in
Norwegian, encompassing translation and human annotation. Based on the
investigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5
has limited capability in understanding the Norwegian context; 2) the increase
in model parameter scales demonstrates limited impact on the performance of
downstream tasks when the pre-training dataset is constrained in size; 3)
smaller models also demonstrate the reasoning capability through
Chain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be
used to verify the generalizability of LLMs on natural language understanding
and, meanwhile, test the interconnectedness of these NLP tasks. We share our
resources and code for reproducibility under a CC BY-NC 4.0 license.

中文翻译:
以下是符合学术规范的中文翻译：

挪威语作为仅有500万使用者的语言，在自然语言处理领域重大突破中的代表性严重不足。据我们所知，目前尚无研究对现有语言模型在挪威语文本生成任务中的表现进行系统评估。为填补这一空白，本研究：1）整合现有挪威语数据集，预训练了4个不同参数量级与架构的挪威开源语言模型（统称NorGLM）；2）构建综合性评测基准NLEBench，通过翻译任务和人工标注评估挪威语自然语言生成能力。研究发现：1）主流英语主导型模型GPT-3.5对挪威语语境理解能力有限；2）当预训练数据规模受限时，参数规模扩大对下游任务性能提升效果有限；3）小规模模型通过思维链技术同样展现推理能力；4）包含协同任务的多任务数据集可验证大语言模型在自然语言理解上的泛化能力，同时检验不同NLP任务间的关联性。本研究的资源与代码遵循CC BY-NC 4.0协议开源以保障可复现性。

（翻译说明：采用学术论文摘要的标准四段式结构，专业术语如"Chain-of-Thought"规范译为"思维链"，保持被动语态与客观表述风格，长句按中文习惯切分，计量单位统一转换，机构名称保留英文缩写并首次出现标注全称）
