# NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian

链接: http://arxiv.org/abs/2312.01314v1

原文摘要:
Norwegian, spoken by only 5 million population, is under-representative
within the most impressive breakthroughs in NLP tasks. To the best of our
knowledge, there has not yet been a comprehensive evaluation of the existing
language models (LMs) on Norwegian generation tasks during the article writing
process. To fill this gap, we 1) compiled the existing Norwegian dataset and
pre-trained 4 Norwegian Open Language Models varied from parameter scales and
architectures, collectively called NorGLM; 2) introduced a comprehensive
benchmark, NLEBench, for evaluating natural language generation capabilities in
Norwegian, encompassing translation and human annotation. Based on the
investigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5
has limited capability in understanding the Norwegian context; 2) the increase
in model parameter scales demonstrates limited impact on the performance of
downstream tasks when the pre-training dataset is constrained in size; 3)
smaller models also demonstrate the reasoning capability through
Chain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be
used to verify the generalizability of LLMs on natural language understanding
and, meanwhile, test the interconnectedness of these NLP tasks. We share our
resources and code for reproducibility under a CC BY-NC 4.0 license.

中文翻译:
挪威语作为一种仅由500万人口使用的语言，在自然语言处理领域最引人注目的突破性进展中代表性不足。据我们所知，在本文撰写期间尚未有研究对现有语言模型在挪威语生成任务上的表现进行全面评估。为填补这一空白，我们：1）整合现有挪威语数据集，预训练了4个不同参数量级和架构的挪威开源语言模型（统称为NorGLM）；2）推出综合性评测基准NLEBench，涵盖翻译和人工标注任务，用于评估挪威语自然语言生成能力。研究发现：1）主流英语主导型语言模型GPT-3.5对挪威语语境的理解能力有限；2）当预训练数据集规模受限时，模型参数规模的增加对下游任务性能影响有限；3）小型模型通过思维链技术同样展现出推理能力；4）包含协同任务的多任务数据集可验证大语言模型在自然语言理解方面的泛化能力，同时检验这些NLP任务间的关联性。我们依据CC BY-NC 4.0许可协议共享所有资源与代码以确保可复现性。
