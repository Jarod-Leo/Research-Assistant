# LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo Molecular Design

链接: http://arxiv.org/abs/2311.14407v1

原文摘要:
Generative models have demonstrated substantial promise in Natural Language
Processing (NLP) and have found application in designing molecules, as seen in
General Pretrained Transformer (GPT) models. In our efforts to develop such a
tool for exploring the organic chemical space in search of potentially
electro-active compounds, we present "LLamol", a single novel generative
transformer model based on the LLama 2 architecture, which was trained on a 13M
superset of organic compounds drawn from diverse public sources. To allow for a
maximum flexibility in usage and robustness in view of potentially incomplete
data, we introduce "Stochastic Context Learning" as a new training procedure.
We demonstrate that the resulting model adeptly handles single- and
multi-conditional organic molecule generation with up to four conditions, yet
more are possible. The model generates valid molecular structures in SMILES
notation while flexibly incorporating three numerical and/or one token sequence
into the generative process, just as requested. The generated compounds are
very satisfactory in all scenarios tested. In detail, we showcase the model's
capability to utilize token sequences for conditioning, either individually or
in combination with numerical properties, making LLamol a potent tool for de
novo molecule design, easily expandable with new properties.

中文翻译:
生成模型在自然语言处理（NLP）领域展现出巨大潜力，并已应用于分子设计，例如通用预训练Transformer（GPT）模型。为开发一种探索有机化学空间、寻找潜在电活性化合物的工具，我们推出了"LLamol"——基于LLama 2架构的新型生成式Transformer模型。该模型通过从多个公共来源提取的1300万种有机化合物超集进行训练。针对数据可能不完整的情况，我们引入"随机上下文学习"作为新型训练方法，以最大限度提升使用灵活性和模型鲁棒性。实验表明，该模型能熟练处理最多包含四个条件（可扩展更多）的单条件及多条件有机分子生成任务，能按要求灵活整合三个数值属性和/或一个标记序列到生成过程中，输出符合SMILES表示法的有效分子结构。在所有测试场景中，生成化合物均表现优异。具体而言，我们展示了模型单独使用标记序列或结合数值属性进行条件调控的能力，这使得LLamol成为从头分子设计的强大工具，且能轻松扩展新属性。
