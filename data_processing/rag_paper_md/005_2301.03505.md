# Advances in Medical Image Analysis with Vision Transformers: A Comprehensive Review

链接: http://arxiv.org/abs/2301.03505v2

原文摘要:
The remarkable performance of the Transformer architecture in natural
language processing has recently also triggered broad interest in Computer
Vision. Among other merits, Transformers are witnessed as capable of learning
long-range dependencies and spatial correlations, which is a clear advantage
over convolutional neural networks (CNNs), which have been the de facto
standard in Computer Vision problems so far. Thus, Transformers have become an
integral part of modern medical image analysis. In this review, we provide an
encyclopedic review of the applications of Transformers in medical imaging.
Specifically, we present a systematic and thorough review of relevant recent
Transformer literature for different medical image analysis tasks, including
classification, segmentation, detection, registration, synthesis, and clinical
report generation. For each of these applications, we investigate the novelty,
strengths and weaknesses of the different proposed strategies and develop
taxonomies highlighting key properties and contributions. Further, if
applicable, we outline current benchmarks on different datasets. Finally, we
summarize key challenges and discuss different future research directions. In
addition, we have provided cited papers with their corresponding
implementations in https://github.com/mindflow-institue/Awesome-Transformer.

中文翻译:
Transformer架构在自然语言处理领域的卓越表现，近期也引发了计算机视觉界的广泛关注。相较于长期以来被视为计算机视觉问题事实标准的卷积神经网络（CNN），Transformer的优势在于能够学习长程依赖关系和空间相关性。这使得Transformer已成为现代医学图像分析不可或缺的组成部分。本文对Transformer在医学影像中的应用进行了百科全书式的综述：我们系统梳理了近期针对分类、分割、检测、配准、合成及临床报告生成等不同医学图像分析任务的Transformer相关文献，详细分析了各类方法的创新性、优势与不足，并通过分类体系图突出关键特性和贡献；对于适用场景，我们还列出了不同数据集的当前基准测试结果；最后总结了核心挑战并探讨了未来研究方向。相关论文及实现代码已整理于https://github.com/mindflow-institue/Awesome-Transformer。
