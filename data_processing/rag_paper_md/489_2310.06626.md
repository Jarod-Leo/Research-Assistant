# Topic-DPR: Topic-based Prompts for Dense Passage Retrieval

链接: http://arxiv.org/abs/2310.06626v1

原文摘要:
Prompt-based learning's efficacy across numerous natural language processing
tasks has led to its integration into dense passage retrieval. Prior research
has mainly focused on enhancing the semantic understanding of pre-trained
language models by optimizing a single vector as a continuous prompt. This
approach, however, leads to a semantic space collapse; identical semantic
information seeps into all representations, causing their distributions to
converge in a restricted region. This hinders differentiation between relevant
and irrelevant passages during dense retrieval. To tackle this issue, we
present Topic-DPR, a dense passage retrieval model that uses topic-based
prompts. Unlike the single prompt method, multiple topic-based prompts are
established over a probabilistic simplex and optimized simultaneously through
contrastive learning. This encourages representations to align with their topic
distributions, improving space uniformity. Furthermore, we introduce a novel
positive and negative sampling strategy, leveraging semi-structured data to
boost dense retrieval efficiency. Experimental results from two datasets affirm
that our method surpasses previous state-of-the-art retrieval techniques.

中文翻译:
基于提示学习的方法在众多自然语言处理任务中展现出的卓越效能，已促使其被引入密集段落检索领域。既往研究主要聚焦于通过优化单一连续提示向量来增强预训练语言模型的语义理解能力。然而，这种处理方式会导致语义空间坍缩——相同的语义信息渗入所有表征，致使其分布收敛于受限区域，从而阻碍密集检索过程中相关段落与非相关段落的区分。为解决这一问题，我们提出Topic-DPR模型，这是一种采用主题化提示的密集段落检索框架。区别于单一提示策略，该模型在概率单纯形上构建多组主题提示，并通过对比学习同步优化，促使表征与其主题分布对齐，从而提升空间均匀性。此外，我们创新性地提出基于半结构化数据的正负例采样策略，有效增强了密集检索效能。在两个基准数据集上的实验结果表明，本方法显著超越了现有最先进检索技术。
