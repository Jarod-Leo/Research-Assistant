# BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers Models for Vietnamese Visual Question Answering

链接: http://arxiv.org/abs/2307.15335v1

原文摘要:
Visual Question Answering (VQA) is an intricate and demanding task that
integrates natural language processing (NLP) and computer vision (CV),
capturing the interest of researchers. The English language, renowned for its
wealth of resources, has witnessed notable advancements in both datasets and
models designed for VQA. However, there is a lack of models that target
specific countries such as Vietnam. To address this limitation, we introduce a
transformer-based Vietnamese model named BARTPhoBEiT. This model includes
pre-trained Sequence-to-Sequence and bidirectional encoder representation from
Image Transformers in Vietnamese and evaluates Vietnamese VQA datasets.
Experimental results demonstrate that our proposed model outperforms the strong
baseline and improves the state-of-the-art in six metrics: Accuracy, Precision,
Recall, F1-score, WUPS 0.0, and WUPS 0.9.

中文翻译:
视觉问答（VQA）作为一项融合自然语言处理（NLP）与计算机视觉（CV）的复杂任务，正日益吸引研究者的关注。英语凭借其丰富的资源优势，在VQA数据集和模型研发方面取得了显著进展，但针对越南等特定国家的专用模型仍属空白。为此，我们提出了基于Transformer的越南语模型BARTPhoBEiT，该模型整合了越南语序列到序列预训练架构与图像Transformer双向编码表征，并在越南语VQA数据集上进行评估。实验结果表明，我们所提出的模型在准确率、精确率、召回率、F1值、WUPS 0.0和WUPS 0.9六项指标上均超越强基线模型，实现了当前最优性能的提升。
