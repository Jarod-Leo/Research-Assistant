# Make A Long Image Short: Adaptive Token Length for Vision Transformers

链接: http://arxiv.org/abs/2307.02092v1

原文摘要:
The vision transformer is a model that breaks down each image into a sequence
of tokens with a fixed length and processes them similarly to words in natural
language processing. Although increasing the number of tokens typically results
in better performance, it also leads to a considerable increase in
computational cost. Motivated by the saying "A picture is worth a thousand
words," we propose an innovative approach to accelerate the ViT model by
shortening long images. Specifically, we introduce a method for adaptively
assigning token length for each image at test time to accelerate inference
speed. First, we train a Resizable-ViT (ReViT) model capable of processing
input with diverse token lengths. Next, we extract token-length labels from
ReViT that indicate the minimum number of tokens required to achieve accurate
predictions. We then use these labels to train a lightweight Token-Length
Assigner (TLA) that allocates the optimal token length for each image during
inference. The TLA enables ReViT to process images with the minimum sufficient
number of tokens, reducing token numbers in the ViT model and improving
inference speed. Our approach is general and compatible with modern vision
transformer architectures, significantly reducing computational costs. We
verified the effectiveness of our methods on multiple representative ViT models
on image classification and action recognition.

中文翻译:
视觉Transformer是一种将每幅图像分解为固定长度的标记序列，并采用类似自然语言处理中词语处理方式操作的模型。尽管增加标记数量通常能提升性能，但也会导致计算成本大幅上升。受"一图胜千言"启发，我们提出了一种通过缩短长图像来加速ViT模型的创新方法。具体而言，我们引入了一种在测试时自适应分配每幅图像标记长度的技术以提升推理速度。首先，我们训练了一个可处理不同标记长度输入的Resizable-ViT（ReViT）模型；其次，从ReViT中提取能实现准确预测所需最小标记数的标记长度标签；随后利用这些标签训练轻量级标记长度分配器（TLA），在推理阶段为每幅图像分配合适的标记长度。TLA使ReViT能以最小充足标记数处理图像，从而减少ViT模型中的标记数量并提升推理速度。该方法具有通用性，可与现代视觉Transformer架构兼容，显著降低计算成本。我们在图像分类和行为识别任务中，通过多个代表性ViT模型验证了方法的有效性。
