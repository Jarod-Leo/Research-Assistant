# An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing

链接: http://arxiv.org/abs/2309.08008v1

原文摘要:
Large language models (LLMs) have shown remarkable capabilities in Natural
Language Processing (NLP), especially in domains where labeled data is scarce
or expensive, such as clinical domain. However, to unlock the clinical
knowledge hidden in these LLMs, we need to design effective prompts that can
guide them to perform specific clinical NLP tasks without any task-specific
training data. This is known as in-context learning, which is an art and
science that requires understanding the strengths and weaknesses of different
LLMs and prompt engineering approaches. In this paper, we present a
comprehensive and systematic experimental study on prompt engineering for five
clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence
Extraction, Coreference Resolution, Medication Status Extraction, and
Medication Attribute Extraction. We assessed the prompts proposed in recent
literature, including simple prefix, simple cloze, chain of thought, and
anticipatory prompts, and introduced two new types of prompts, namely heuristic
prompting and ensemble prompting. We evaluated the performance of these prompts
on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted
zero-shot prompting with few-shot prompting, and provide novel insights and
guidelines for prompt engineering for LLMs in clinical NLP. To the best of our
knowledge, this is one of the first works on the empirical evaluation of
different prompt engineering approaches for clinical NLP in this era of
generative AI, and we hope that it will inspire and inform future research in
this area.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）在自然语言处理（NLP）领域展现出卓越能力，尤其在标注数据稀缺或获取成本高的临床领域表现突出。然而，要释放这些LLMs中隐含的临床知识，需要设计有效的提示词（prompt）来引导其在不依赖任务特定训练数据的情况下完成临床NLP任务——这一过程被称为上下文学习（in-context learning），它既是艺术也是科学，需要深入理解不同LLMs的特性与各类提示工程方法的优劣。本文针对五项临床NLP任务（临床词义消歧、生物医学证据抽取、共指消解、用药状态提取和药物属性提取）开展了系统性的提示工程实验研究。我们评估了现有文献提出的多种提示策略（包括简单前缀型、完型填空型、思维链和预期型提示），并创新性地提出启发式提示和集成提示两种新型范式。研究在GPT-3.5、BARD和LLAMA2三种前沿LLMs上测试了这些提示方法的性能，对比了零样本提示与少样本提示的效果差异，最终为临床NLP领域的提示工程提供了新的理论见解和实践指南。据我们所知，这是生成式AI时代首批针对临床NLP提示工程方法的实证评估研究之一，有望为该领域的后续研究提供重要参考。

（翻译严格遵循了以下原则：
1. 专业术语准确统一（如LLMs/提示词/上下文学习等）
2. 长句合理切分，符合中文表达习惯
3. 被动语态转换为主动表述
4. 保留学术论文的正式语体
5. 关键概念首次出现标注英文原名
6. 逻辑关系显性化处理
7. 文化适配性调整）
