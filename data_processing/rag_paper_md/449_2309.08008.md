# An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing

链接: http://arxiv.org/abs/2309.08008v1

原文摘要:
Large language models (LLMs) have shown remarkable capabilities in Natural
Language Processing (NLP), especially in domains where labeled data is scarce
or expensive, such as clinical domain. However, to unlock the clinical
knowledge hidden in these LLMs, we need to design effective prompts that can
guide them to perform specific clinical NLP tasks without any task-specific
training data. This is known as in-context learning, which is an art and
science that requires understanding the strengths and weaknesses of different
LLMs and prompt engineering approaches. In this paper, we present a
comprehensive and systematic experimental study on prompt engineering for five
clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence
Extraction, Coreference Resolution, Medication Status Extraction, and
Medication Attribute Extraction. We assessed the prompts proposed in recent
literature, including simple prefix, simple cloze, chain of thought, and
anticipatory prompts, and introduced two new types of prompts, namely heuristic
prompting and ensemble prompting. We evaluated the performance of these prompts
on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted
zero-shot prompting with few-shot prompting, and provide novel insights and
guidelines for prompt engineering for LLMs in clinical NLP. To the best of our
knowledge, this is one of the first works on the empirical evaluation of
different prompt engineering approaches for clinical NLP in this era of
generative AI, and we hope that it will inspire and inform future research in
this area.

中文翻译:
大型语言模型（LLM）在自然语言处理（NLP）领域展现出卓越能力，尤其在标注数据稀缺或获取成本高的临床领域表现突出。然而，要释放这些模型中隐含的临床知识，需设计有效的提示词（prompt），使其无需任务特定训练数据即可执行临床NLP任务。这种情境学习（in-context learning）是一门融合艺术与科学的技艺，需要深入理解不同LLM的优劣势及提示工程方法。本文针对五项临床NLP任务（临床语义消歧、生物医学证据抽取、共指消解、用药状态提取和用药属性提取），开展了系统化的提示工程实验研究。我们评估了现有文献提出的简单前缀型、完型填空型、思维链式和前瞻性提示等策略，并创新性地引入启发式提示和集成提示两种新方法。在GPT-3.5、BARD和LLAMA2三种前沿LLM上测试了这些提示策略的效果，对比了零样本提示与少样本提示的差异，最终提出了临床NLP领域LLM提示工程的新见解与实用指南。据我们所知，这是生成式AI时代首批针对临床NLP提示工程方法的实证研究之一，有望为该领域的后续研究提供重要参考。
