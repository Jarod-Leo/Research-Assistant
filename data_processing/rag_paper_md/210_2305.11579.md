# Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment

链接: http://arxiv.org/abs/2305.11579v1

原文摘要:
Recently, speech-text pre-training methods have shown remarkable success in
many speech and natural language processing tasks. However, most previous
pre-trained models are usually tailored for one or two specific tasks, but fail
to conquer a wide range of speech-text tasks. In addition, existing speech-text
pre-training methods fail to explore the contextual information within a
dialogue to enrich utterance representations. In this paper, we propose
Speech-text dialog Pre-training for spoken dialog understanding with ExpliCiT
cRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog
pre-training model. Concretely, to consider the temporality of speech modality,
we design a novel temporal position prediction task to capture the speech-text
alignment. This pre-training task aims to predict the start and end time of
each textual word in the corresponding speech waveform. In addition, to learn
the characteristics of spoken dialogs, we generalize a response selection task
from textual dialog pre-training to speech-text dialog pre-training scenarios.
Experimental results on four different downstream speech-text tasks demonstrate
the superiority of SPECTRA in learning speech-text alignment and multi-turn
dialog context.

中文翻译:
近期，语音-文本联合预训练方法在多项语音与自然语言处理任务中展现出显著成效。然而，现有预训练模型大多仅针对一两种特定任务设计，难以覆盖广泛的语音-文本应用场景。此外，当前方法未能充分挖掘对话中的上下文信息来增强话语表征。本文首次提出面向口语对话理解的显式跨模态对齐语音-文本对话预训练模型SPECTRA。具体而言，针对语音模态的时间特性，我们设计了新颖的时间位置预测任务来捕捉语音-文本对齐关系，该任务通过预测文本单词在对应语音波形中的起止时间实现跨模态对齐。同时，为学习口语对话特性，我们将文本对话预训练中的响应选择任务扩展至语音-文本对话场景。在四项不同下游任务上的实验结果表明，SPECTRA在语音-文本对齐学习和多轮对话上下文建模方面具有显著优势。
