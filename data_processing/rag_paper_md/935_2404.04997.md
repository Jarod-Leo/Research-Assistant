# Adapting LLMs for Efficient Context Processing through Soft Prompt Compression

链接: http://arxiv.org/abs/2404.04997v1

原文摘要:
The rapid advancement of Large Language Models (LLMs) has inaugurated a
transformative epoch in natural language processing, fostering unprecedented
proficiency in text generation, comprehension, and contextual scrutiny.
Nevertheless, effectively handling extensive contexts, crucial for myriad
applications, poses a formidable obstacle owing to the intrinsic constraints of
the models' context window sizes and the computational burdens entailed by
their operations. This investigation presents an innovative framework that
strategically tailors LLMs for streamlined context processing by harnessing the
synergies among natural language summarization, soft prompt compression, and
augmented utility preservation mechanisms. Our methodology, dubbed
SoftPromptComp, amalgamates natural language prompts extracted from
summarization methodologies with dynamically generated soft prompts to forge a
concise yet semantically robust depiction of protracted contexts. This
depiction undergoes further refinement via a weighting mechanism optimizing
information retention and utility for subsequent tasks. We substantiate that
our framework markedly diminishes computational overhead and enhances LLMs'
efficacy across various benchmarks, while upholding or even augmenting the
caliber of the produced content. By amalgamating soft prompt compression with
sophisticated summarization, SoftPromptComp confronts the dual challenges of
managing lengthy contexts and ensuring model scalability. Our findings point
towards a propitious trajectory for augmenting LLMs' applicability and
efficiency, rendering them more versatile and pragmatic for real-world
applications. This research enriches the ongoing discourse on optimizing
language models, providing insights into the potency of soft prompts and
summarization techniques as pivotal instruments for the forthcoming generation
of NLP solutions.

中文翻译:
大型语言模型（LLMs）的快速发展开启了自然语言处理的变革时代，其在文本生成、理解与上下文分析方面展现出前所未有的能力。然而，受限于模型上下文窗口的固有约束及运算带来的计算负担，如何有效处理对众多应用至关重要的长文本语境成为重大挑战。本研究提出一个创新框架，通过整合自然语言摘要、软提示压缩与增强型效用保留机制的协同效应，战略性地优化LLMs以实现高效上下文处理。我们提出的SoftPromptComp方法，将摘要技术提取的自然语言提示与动态生成的软提示相结合，构建出既简洁又语义丰富的长语境表征。该表征通过权重机制进一步优化，以最大化后续任务中的信息保留与实用价值。实验证明，该框架能显著降低计算开销并提升LLMs在多项基准测试中的性能，同时保持甚至提升生成内容的质量。通过融合软提示压缩与智能摘要技术，SoftPromptComp成功解决了长语境处理与模型可扩展性的双重挑战。研究结果表明，该方法为增强LLMs的适用性与效率开辟了可行路径，使其在现实应用中更具通用性与实用性。本研究成果深化了语言模型优化领域的讨论，揭示了软提示与摘要技术作为下一代NLP解决方案关键工具的巨大潜力。
