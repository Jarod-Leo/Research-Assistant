# ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4

链接: http://arxiv.org/abs/2305.07490v1

原文摘要:
The success of large language models (LLMs) has inspired an emerging research
field of multimodal learning. However, a grand challenge of exploiting LLMs for
multimodal learning is the size of pre-trained LLMs which are always with
billions of parameters. To tackle this challenge, models such as MiniGPT-4 and
LLaVA have been developed to fine-tune the pre-trained models using fewer
parameters. Despite their promising performance, these models remain limited in
their understanding of artistic imagery. To facilitate better
artistic-understanding, in this paper, we propose ArtGPT-4, a pioneering large
vision-language model tailored to address the limitations of existing models in
artistic comprehension. The key innovation of ArtGPT-4 lies in its craft for
the sophisticated challenge of artistic image comprehension, setting it apart
from other models that overlook fine details for broader themes. Specifically,
it works by integrating some specialized adapter layers into the LLM, enabling
the model to more efficiently and effectively parse and interpret complex
visual tokens, instead of fine-tuning the whole LLM as in the existing method.
ArtGPT-4 has demonstrated its outstanding performance on the efficiency:
utilizing a Tesla A100 device, its training can be completed in mere 2 hours
with an image-text pair dataset comprising approximately 0.52M entries.
Additionally, ArtGPT-4 has also achieved state-of-the-art performance on the
ArtEmis and ArtEmis-v2.0 datasets as well as the benchmarks established in this
work, lagging behind professional artists' descriptions by a negligible 0.15
points on a 6-point scale. The outstanding performance of ArtGPT-4 shows that
it can render images with an artistic-understanding and convey the emotions
they inspire, mirroring human interpretation. The code and the pre-trained
model are accessible in \url{https://github.com/DLYuanGod/ArtGPT-4}.

中文翻译:
大型语言模型（LLM）的成功激发了多模态学习这一新兴研究领域的兴起。然而，利用LLM进行多模态学习面临的核心挑战在于预训练模型庞大的参数量——通常高达数十亿级别。为应对这一挑战，MiniGPT-4和LLaVA等模型通过减少参数量的方式进行微调。尽管这些模型展现出良好性能，但其在艺术图像理解方面仍存在明显局限。为提升艺术理解能力，本文提出ArtGPT-4这一开创性的大型视觉语言模型，专门解决现有模型在艺术理解方面的不足。

ArtGPT-4的核心创新在于其针对艺术图像理解这一复杂挑战的精细设计，使其区别于其他忽视细节而侧重宏观主题的模型。具体而言，该模型通过在LLM中集成专用适配层（而非如现有方法般微调整个LLM），能更高效地解析和诠释复杂的视觉符号。ArtGPT-4在效率方面表现卓越：使用Tesla A100设备时，仅需2小时即可完成包含约52万条图文对数据集的训练。此外，该模型在ArtEmis、ArtEmis-v2.0数据集及本文建立的基准测试中均达到最先进水平，在6分制评估中仅落后专业艺术家描述0.15分。

ArtGPT-4的卓越表现证明其能实现具有艺术深度的图像渲染，并准确传达图像激发的情感，完美复现人类的理解方式。相关代码与预训练模型已发布于\url{https://github.com/DLYuanGod/ArtGPT-4}。
