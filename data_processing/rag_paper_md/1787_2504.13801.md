# Transformer Encoder and Multi-features Time2Vec for Financial Prediction

链接: http://arxiv.org/abs/2504.13801v1

原文摘要:
Financial prediction is a complex and challenging task of time series
analysis and signal processing, expected to model both short-term fluctuations
and long-term temporal dependencies. Transformers have remarkable success
mostly in natural language processing using attention mechanism, which also
influenced the time series community. The ability to capture both short and
long-range dependencies helps to understand the financial market and to
recognize price patterns, leading to successful applications of Transformers in
stock prediction. Although, the previous research predominantly focuses on
individual features and singular predictions, that limits the model's ability
to understand broader market trends. In reality, within sectors such as finance
and technology, companies belonging to the same industry often exhibit
correlated stock price movements.
  In this paper, we develop a novel neural network architecture by integrating
Time2Vec with the Encoder of the Transformer model. Based on the study of
different markets, we propose a novel correlation feature selection method.
Through a comprehensive fine-tuning of multiple hyperparameters, we conduct a
comparative analysis of our results against benchmark models. We conclude that
our method outperforms other state-of-the-art encoding methods such as
positional encoding, and we also conclude that selecting correlation features
enhance the accuracy of predicting multiple stock prices.

中文翻译:
金融预测是一项复杂且具有挑战性的时间序列分析与信号处理任务，需要同时建模短期波动与长期时序依赖关系。Transformer凭借其注意力机制在自然语言处理领域取得显著成功，这一技术也深刻影响了时间序列研究领域。捕捉短期与长期依赖关系的能力有助于理解金融市场并识别价格模式，这使得Transformer在股票预测中得以成功应用。然而既有研究主要聚焦于单一特征和独立预测，限制了模型理解更广泛市场趋势的能力。现实中在金融、科技等行业中，同领域企业的股价往往呈现联动特征。

本文通过将Time2Vec与Transformer编码器集成，开发了一种新型神经网络架构。基于对不同市场的研究，我们提出了一种创新的相关性特征选择方法。通过对多重超参数的系统调优，我们将实验结果与基准模型进行了对比分析。研究结果表明：我们的方法优于位置编码等其他前沿编码技术，同时证实相关性特征选择能有效提升多股价格预测的准确度。
