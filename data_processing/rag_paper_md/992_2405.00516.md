# Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning

链接: http://arxiv.org/abs/2405.00516v1

原文摘要:
Recent advancements in language models have demonstrated remarkable
improvements in various natural language processing (NLP) tasks such as web
navigation. Supervised learning (SL) approaches have achieved impressive
performance while utilizing significantly less training data compared to
previous methods. However, these SL-based models fall short when compared to
reinforcement learning (RL) approaches, which have shown superior results. In
this paper, we propose a novel approach that combines SL and RL techniques over
the MiniWoB benchmark to leverage the strengths of both methods. We also
address a critical limitation in previous models' understanding of HTML
content, revealing a tendency to memorize target elements rather than
comprehend the underlying structure. To rectify this, we propose methods to
enhance true understanding and present a new baseline of results. Our
experiments demonstrate that our approach outperforms previous SL methods on
certain tasks using less data and narrows the performance gap with RL models,
achieving 43.58\% average accuracy in SL and 36.69\% when combined with a
multimodal RL approach. This study sets a new direction for future web
navigation and offers insights into the limitations and potential of language
modeling for computer tasks.

中文翻译:
语言模型的最新进展在网页导航等多种自然语言处理（NLP）任务中展现出显著提升。监督学习（SL）方法仅需使用远少于传统方案的训练数据，就能实现令人瞩目的性能表现。然而与强化学习（RL）方法相比，这些基于SL的模型仍存在差距——后者始终保持着性能优势。本文创新性地提出在MiniWoB基准测试中融合SL与RL技术的方法，以整合两种范式的优势。同时我们发现既有模型对HTML内容的理解存在重大缺陷：它们更倾向于记忆目标元素而非真正理解底层结构。为此，我们提出了增强真实理解能力的方法，并建立了新的性能基线。实验表明，本方案在部分任务中以更少数据超越了先前SL方法，同时将RL模型的性能差距缩小至43.58%（纯SL）和36.69%（多模态RL混合方案），为未来网页导航研究指明了新方向，也为语言模型处理计算机任务的局限性与潜力提供了重要启示。
