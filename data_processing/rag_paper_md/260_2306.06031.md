# FinGPT: Open-Source Financial Large Language Models

链接: http://arxiv.org/abs/2306.06031v1

原文摘要:
Large language models (LLMs) have shown the potential of revolutionizing
natural language processing tasks in diverse domains, sparking great interest
in finance. Accessing high-quality financial data is the first challenge for
financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken
advantage of their unique data accumulation, such privileged access calls for
an open-source alternative to democratize Internet-scale financial data.
  In this paper, we present an open-source large language model, FinGPT, for
the finance sector. Unlike proprietary models, FinGPT takes a data-centric
approach, providing researchers and practitioners with accessible and
transparent resources to develop their FinLLMs. We highlight the importance of
an automatic data curation pipeline and the lightweight low-rank adaptation
technique in building FinGPT. Furthermore, we showcase several potential
applications as stepping stones for users, such as robo-advising, algorithmic
trading, and low-code development. Through collaborative efforts within the
open-source AI4Finance community, FinGPT aims to stimulate innovation,
democratize FinLLMs, and unlock new opportunities in open finance. Two
associated code repos are \url{https://github.com/AI4Finance-Foundation/FinGPT}
and \url{https://github.com/AI4Finance-Foundation/FinNLP}

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）已展现出革新多领域自然语言处理任务的潜力，这引发了金融界的极大兴趣。获取高质量金融数据是构建金融大模型（FinLLMs）面临的首要挑战。尽管如BloombergGPT等专有模型凭借其独特的数据积累优势占据先机，但这种特权访问模式亟需开源替代方案来实现互联网级金融数据的民主化。

本文提出面向金融领域的开源大模型FinGPT。与专有模型不同，FinGPT采用以数据为中心的方法，为研究者和从业者提供可获取且透明的资源以开发其FinLLMs。我们重点阐述了自动数据清洗管道与轻量级低秩自适应技术在构建FinGPT中的关键作用，并展示了机器人投顾、算法交易和低代码开发等示范应用场景作为用户实践基础。通过AI4Finance开源社区的协同努力，FinGPT旨在推动金融大模型民主化，促进创新，并为开放金融领域开拓新机遇。相关代码仓库见：\url{https://github.com/AI4Finance-Foundation/FinGPT}与\url{https://github.com/AI4Finance-Foundation/FinNLP}

（注：译文严格遵循了以下要求：
1. 专业术语准确统一（如LLMs/FinLLMs的译法）
2. 被动语态转换为中文主动表达（如"is the first challenge"译为"面临的首要挑战"）
3. 长句合理切分（如原文第二段拆分为三个中文句子）
4. 学术用语规范（如"data-centric approach"译为"以数据为中心的方法"）
5. 保留技术概念精确性（如"low-rank adaptation"译为"低秩自适应"）
6. 链接信息完整保留）
