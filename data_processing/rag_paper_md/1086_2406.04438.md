# TexIm FAST: Text-to-Image Representation for Semantic Similarity Evaluation using Transformers

链接: http://arxiv.org/abs/2406.04438v1

原文摘要:
One of the principal objectives of Natural Language Processing (NLP) is to
generate meaningful representations from text. Improving the informativeness of
the representations has led to a tremendous rise in the dimensionality and the
memory footprint. It leads to a cascading effect amplifying the complexity of
the downstream model by increasing its parameters. The available techniques
cannot be applied to cross-modal applications such as text-to-image. To
ameliorate these issues, a novel Text-to-Image methodology for generating
fixed-length representations through a self-supervised Variational Auto-Encoder
(VAE) for semantic evaluation applying transformers (TexIm FAST) has been
proposed in this paper. The pictorial representations allow oblivious inference
while retaining the linguistic intricacies, and are potent in cross-modal
applications. TexIm FAST deals with variable-length sequences and generates
fixed-length representations with over 75% reduced memory footprint. It
enhances the efficiency of the models for downstream tasks by reducing its
parameters. The efficacy of TexIm FAST has been extensively analyzed for the
task of Semantic Textual Similarity (STS) upon the MSRPC, CNN/ Daily Mail, and
XSum data-sets. The results demonstrate 6% improvement in accuracy compared to
the baseline and showcase its exceptional ability to compare disparate length
sequences such as a text with its summary.

中文翻译:
自然语言处理（NLP）的核心目标之一是从文本中生成有意义的表征。随着表征信息量的提升，其维度与内存占用呈爆炸式增长，这会通过增加下游模型参数引发级联效应，进而放大模型复杂度。现有技术无法应用于文本到图像等跨模态场景。针对这些问题，本文提出了一种创新的文本到图像方法——基于自监督变分自编码器（VAE）和Transformer的语义评估固定长度表征生成框架（TexIm FAST）。该方法通过图像化表征在保留语言复杂性的同时实现无感知推理，并具备强大的跨模态应用能力。TexIm FAST能处理变长序列，生成内存占用减少75%以上的定长表征，通过精简下游任务模型参数显著提升效率。在MSRPC、CNN/Daily Mail和XSum数据集上进行的语义文本相似度（STS）任务验证表明，该方法较基线模型准确率提升6%，尤其擅长处理原文与摘要等长度差异显著的序列比对任务。
