# On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis

链接: http://arxiv.org/abs/2304.03347v1

原文摘要:
The latest large language models (LLMs) such as ChatGPT, exhibit strong
capabilities in automated mental health analysis. However, existing relevant
studies bear several limitations, including inadequate evaluations, lack of
prompting strategies, and ignorance of exploring LLMs for explainability. To
bridge these gaps, we comprehensively evaluate the mental health analysis and
emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore
the effects of different prompting strategies with unsupervised and distantly
supervised emotional information. Based on these prompts, we explore LLMs for
interpretable mental health analysis by instructing them to generate
explanations for each of their decisions. We convey strict human evaluations to
assess the quality of the generated explanations, leading to a novel dataset
with 163 human-assessed explanations. We benchmark existing automatic
evaluation metrics on this dataset to guide future related works. According to
the results, ChatGPT shows strong in-context learning ability but still has a
significant gap with advanced task-specific methods. Careful prompt engineering
with emotional cues and expert-written few-shot examples can also effectively
improve performance on mental health analysis. In addition, ChatGPT generates
explanations that approach human performance, showing its great potential in
explainable mental health analysis.

中文翻译:
以ChatGPT为代表的最新大型语言模型（LLMs）在自动化心理健康分析方面展现出强大能力。然而现有相关研究存在若干局限：评估体系不完善、提示策略缺失、以及忽视模型可解释性探索。为填补这些空白，我们在5类任务的11个数据集上全面评估了LLMs的心理健康分析与情绪推理能力，探究了无监督和远程监督情绪信息下不同提示策略的效果。基于这些提示策略，我们通过指令模型为每个决策生成解释，探索了LLMs的可解释心理健康分析。通过严格人工评估生成的解释质量，我们构建了包含163条人工评注解释的新型数据集，并在此数据集上对现有自动评估指标进行基准测试以指导未来研究。结果表明：ChatGPT展现出强大的上下文学习能力，但与先进的任务专用方法仍存在显著差距；结合情绪线索的精细提示工程与专家撰写的少量示例能有效提升心理健康分析性能；此外，ChatGPT生成的解释接近人类水平，在可解释心理健康分析方面具有巨大潜力。
