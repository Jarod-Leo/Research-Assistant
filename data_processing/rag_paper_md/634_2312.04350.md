# CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models

链接: http://arxiv.org/abs/2312.04350v1

原文摘要:
The ability to perform causal reasoning is widely considered a core feature
of intelligence. In this work, we investigate whether large language models
(LLMs) can coherently reason about causality. Much of the existing work in
natural language processing (NLP) focuses on evaluating commonsense causal
reasoning in LLMs, thus failing to assess whether a model can perform causal
inference in accordance with a set of well-defined formal rules. To address
this, we propose a new NLP task, causal inference in natural language, inspired
by the "causal inference engine" postulated by Judea Pearl et al. We compose a
large dataset, CLadder, with 10K samples: based on a collection of causal
graphs and queries (associational, interventional, and counterfactual), we
obtain symbolic questions and ground-truth answers, through an oracle causal
inference engine. These are then translated into natural language. We evaluate
multiple LLMs on our dataset, and we introduce and evaluate a bespoke
chain-of-thought prompting strategy, CausalCoT. We show that our task is highly
challenging for LLMs, and we conduct an in-depth analysis to gain deeper
insights into the causal reasoning abilities of LLMs. Our data is open-sourced
at https://huggingface.co/datasets/causalNLP/cladder, and our code can be found
at https://github.com/causalNLP/cladder.

中文翻译:
进行因果推理的能力被广泛视为智能的核心特征。本研究探讨大型语言模型（LLMs）能否连贯地进行因果推理。现有自然语言处理（NLP）研究多聚焦于评估LLMs的常识性因果推理，却未能检验模型是否遵循一套明确定义的规则执行因果推断。为此，我们受Judea Pearl等人提出的"因果推理引擎"启发，设计了一项新NLP任务——自然语言因果推断，并构建了包含10K样本的大型数据集CLadder：基于因果图与查询（关联性、干预性及反事实性），通过因果推理引擎生成符号化问题与真实答案，再转译为自然语言。我们在该数据集上评估了多种LLM，并提出并验证了定制化的思维链提示策略CausalCoT。研究表明，该任务对LLMs极具挑战性，我们通过深入分析揭示了LLMs因果推理能力的本质。数据集已开源于https://huggingface.co/datasets/causalNLP/cladder，代码详见https://github.com/causalNLP/cladder。
