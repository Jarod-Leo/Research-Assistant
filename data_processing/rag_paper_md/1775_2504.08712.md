# Beyond Black-Box Predictions: Identifying Marginal Feature Effects in Tabular Transformer Networks

链接: http://arxiv.org/abs/2504.08712v1

原文摘要:
In recent years, deep neural networks have showcased their predictive power
across a variety of tasks. Beyond natural language processing, the transformer
architecture has proven efficient in addressing tabular data problems and
challenges the previously dominant gradient-based decision trees in these
areas. However, this predictive power comes at the cost of intelligibility:
Marginal feature effects are almost completely lost in the black-box nature of
deep tabular transformer networks. Alternative architectures that use the
additivity constraints of classical statistical regression models can maintain
intelligible marginal feature effects, but often fall short in predictive power
compared to their more complex counterparts. To bridge the gap between
intelligibility and performance, we propose an adaptation of tabular
transformer networks designed to identify marginal feature effects. We provide
theoretical justifications that marginal feature effects can be accurately
identified, and our ablation study demonstrates that the proposed model
efficiently detects these effects, even amidst complex feature interactions. To
demonstrate the model's predictive capabilities, we compare it to several
interpretable as well as black-box models and find that it can match black-box
performances while maintaining intelligibility. The source code is available at
https://github.com/OpenTabular/NAMpy.

中文翻译:
近年来，深度神经网络在各类任务中展现了强大的预测能力。尤其在自然语言处理领域之外，Transformer架构已证明能有效解决表格数据问题，并对传统梯度决策树模型的主导地位形成挑战。然而这种预测能力的提升伴随着可解释性的丧失——深度表格Transformer网络的黑箱特性几乎完全掩盖了特征的边际效应。采用经典统计回归模型可加性约束的替代架构虽能保持可解释的边际特征效应，但其预测性能往往难以与复杂模型匹敌。

为弥合可解释性与性能之间的鸿沟，我们提出一种改进的表格Transformer网络架构，专门用于识别边际特征效应。通过理论论证，我们证实该架构能准确识别边际效应，消融实验表明即便存在复杂特征交互，模型仍能有效检测这些效应。为验证模型的预测能力，我们将其与多种可解释模型及黑箱模型进行对比，发现其在保持可解释性的同时能达到黑箱模型的性能水平。源代码已发布于https://github.com/OpenTabular/NAMpy。
