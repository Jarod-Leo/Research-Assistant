# An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration

链接: http://arxiv.org/abs/2402.04978v1

原文摘要:
While Large Language Models (LLMs) demonstrate exceptional performance in a
multitude of Natural Language Processing (NLP) tasks, they encounter challenges
in practical applications, including issues with hallucinations, inadequate
knowledge updating, and limited transparency in the reasoning process. To
overcome these limitations, this study innovatively proposes a collaborative
training-free reasoning scheme involving tight cooperation between Knowledge
Graph (KG) and LLMs. This scheme first involves using LLMs to iteratively
explore KG, selectively retrieving a task-relevant knowledge subgraph to
support reasoning. The LLMs are then guided to further combine inherent
implicit knowledge to reason on the subgraph while explicitly elucidating the
reasoning process. Through such a cooperative approach, our scheme achieves
more reliable knowledge-based reasoning and facilitates the tracing of the
reasoning results. Experimental results show that our scheme significantly
progressed across multiple datasets, notably achieving over a 10% improvement
on the QALD10 dataset compared to the best baseline and the fine-tuned
state-of-the-art (SOTA) work. Building on this success, this study hopes to
offer a valuable reference for future research in the fusion of KG and LLMs,
thereby enhancing LLMs' proficiency in solving complex issues.

中文翻译:
尽管大语言模型（LLMs）在众多自然语言处理（NLP）任务中展现出卓越性能，但在实际应用中仍面临诸多挑战，包括幻觉问题、知识更新滞后以及推理过程透明度不足等。为突破这些局限，本研究创新性地提出一种知识图谱（KG）与LLMs深度协作的无训练推理方案。该方案首先利用LLMs对KG进行迭代探索，选择性检索出与任务相关的知识子图以支撑推理；随后引导LLMs进一步结合自身隐式知识，在子图基础上进行推理并显式阐明推理过程。通过这种协同机制，我们的方案实现了更可靠的基于知识的推理，同时保障了推理结果的可追溯性。实验结果表明，该方案在多个数据集上取得显著进展，尤其在QALD10数据集上相较最佳基线方法和微调后的前沿（SOTA）工作提升了超过10%的性能。基于这一成果，本研究期望为未来知识图谱与大语言模型的融合研究提供有益参考，从而提升LLMs解决复杂问题的能力。

（译文特点说明：
1. 专业术语准确对应："hallucinations"译为"幻觉问题"，"state-of-the-art"保留技术领域惯用译法"前沿（SOTA）工作"
2. 长句拆分重构：将原文复合长句按中文表达习惯分解为多个短句，如将"selectively retrieving..."独立成短句
3. 被动语态转化："are guided to"译为主动式"引导LLMs"
4. 概念显化处理："implicit knowledge"补充译为"自身隐式知识"以明确知识归属
5. 逻辑连接优化：通过"首先/随后"等时序词清晰呈现方案执行流程
6. 学术风格保持：使用"显著进展""可追溯性"等符合学术论文表达的措辞）
