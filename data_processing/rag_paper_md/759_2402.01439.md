# From Words to Molecules: A Survey of Large Language Models in Chemistry

链接: http://arxiv.org/abs/2402.01439v1

原文摘要:
In recent years, Large Language Models (LLMs) have achieved significant
success in natural language processing (NLP) and various interdisciplinary
areas. However, applying LLMs to chemistry is a complex task that requires
specialized domain knowledge. This paper provides a thorough exploration of the
nuanced methodologies employed in integrating LLMs into the field of chemistry,
delving into the complexities and innovations at this interdisciplinary
juncture. Specifically, our analysis begins with examining how molecular
information is fed into LLMs through various representation and tokenization
methods. We then categorize chemical LLMs into three distinct groups based on
the domain and modality of their input data, and discuss approaches for
integrating these inputs for LLMs. Furthermore, this paper delves into the
pretraining objectives with adaptations to chemical LLMs. After that, we
explore the diverse applications of LLMs in chemistry, including novel
paradigms for their application in chemistry tasks. Finally, we identify
promising research directions, including further integration with chemical
knowledge, advancements in continual learning, and improvements in model
interpretability, paving the way for groundbreaking developments in the field.

中文翻译:
近年来，大型语言模型（LLMs）在自然语言处理（NLP）及多学科交叉领域取得了显著成就。然而将LLMs应用于化学领域是一项复杂任务，需要专业领域知识支撑。本文系统探究了LLMs与化学学科融合过程中的精细化方法，深入剖析了这一交叉领域的复杂性与创新点。具体而言，我们首先分析了通过不同表征与标记化方法将分子信息输入LLMs的技术路径；继而根据输入数据的领域与模态特征，将化学LLMs划分为三大类型，并探讨了多源输入整合策略；随后详细阐释了针对化学LLMs的预训练目标函数适配方法。在此基础上，本文系统梳理了LLMs在化学领域的多元化应用场景，包括创新性的任务解决范式。最后，我们提出了与化学知识深度整合、持续学习机制优化以及模型可解释性增强等前瞻性研究方向，为领域突破性发展提供了路线图。
