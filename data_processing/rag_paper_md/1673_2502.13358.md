# Bridging the Editing Gap in LLMs: FineEdit for Precise and Targeted Text Modifications

链接: http://arxiv.org/abs/2502.13358v1

原文摘要:
Large Language Models (LLMs) have transformed natural language processing,
yet they still struggle with direct text editing tasks that demand precise,
context-aware modifications. While models like ChatGPT excel in text generation
and analysis, their editing abilities often fall short, addressing only
superficial issues rather than deeper structural or logical inconsistencies. In
this work, we introduce a dual approach to enhance LLMs editing performance.
First, we present InstrEditBench, a high-quality benchmark dataset comprising
over 20,000 structured editing tasks spanning Wiki articles, LaTeX documents,
code, and database Domain-specific Languages (DSL). InstrEditBench is generated
using an innovative automated workflow that accurately identifies and evaluates
targeted edits, ensuring that modifications adhere strictly to specified
instructions without altering unrelated content. Second, we propose FineEdit, a
specialized model trained on this curated benchmark. Experimental results
demonstrate that FineEdit achieves significant improvements around {10\%}
compared with Gemini on direct editing tasks, convincingly validating its
effectiveness.

中文翻译:
大型语言模型（LLMs）已彻底改变了自然语言处理领域，但在需要精准、上下文感知修改的直接文本编辑任务上仍面临挑战。尽管ChatGPT等模型在文本生成与分析方面表现卓越，其编辑能力往往仅能处理表层问题，而难以应对深层次的结构或逻辑不一致性。本研究提出了一种双重优化方案：首先，我们构建了InstrEditBench——一个包含20,000余项结构化编辑任务的高质量基准数据集，涵盖维基百科条目、LaTeX文档、代码及数据库领域特定语言（DSL）。该数据集通过创新自动化流程生成，能精准定位并评估目标编辑，确保修改严格遵循指令且不干扰无关内容。其次，我们基于此基准训练出专用模型FineEdit。实验表明，FineEdit在直接编辑任务中较Gemini实现了约10%的性能提升，有力验证了其有效性。
