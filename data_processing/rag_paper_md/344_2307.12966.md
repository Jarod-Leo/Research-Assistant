# Aligning Large Language Models with Human: A Survey

链接: http://arxiv.org/abs/2307.12966v1

原文摘要:
Large Language Models (LLMs) trained on extensive textual corpora have
emerged as leading solutions for a broad array of Natural Language Processing
(NLP) tasks. Despite their notable performance, these models are prone to
certain limitations such as misunderstanding human instructions, generating
potentially biased content, or factually incorrect (hallucinated) information.
Hence, aligning LLMs with human expectations has become an active area of
interest within the research community. This survey presents a comprehensive
overview of these alignment technologies, including the following aspects. (1)
Data collection: the methods for effectively collecting high-quality
instructions for LLM alignment, including the use of NLP benchmarks, human
annotations, and leveraging strong LLMs. (2) Training methodologies: a detailed
review of the prevailing training methods employed for LLM alignment. Our
exploration encompasses Supervised Fine-tuning, both Online and Offline human
preference training, along with parameter-efficient training mechanisms. (3)
Model Evaluation: the methods for evaluating the effectiveness of these
human-aligned LLMs, presenting a multifaceted approach towards their
assessment. In conclusion, we collate and distill our findings, shedding light
on several promising future research avenues in the field. This survey,
therefore, serves as a valuable resource for anyone invested in understanding
and advancing the alignment of LLMs to better suit human-oriented tasks and
expectations. An associated GitHub link collecting the latest papers is
available at https://github.com/GaryYufei/AlignLLMHumanSurvey.

中文翻译:
基于海量文本语料训练的大语言模型（LLMs）已成为解决各类自然语言处理（NLP）任务的主流方案。尽管这些模型表现出卓越性能，但仍存在误解人类指令、生成潜在偏见内容或事实性错误（幻觉）信息等局限性。因此，如何使大语言模型与人类期望对齐已成为研究界的热点领域。本综述系统梳理了相关对齐技术，涵盖以下维度：（1）数据收集：高效获取高质量指令数据的方法，包括利用NLP基准数据集、人工标注以及调用强语言模型；（2）训练方法：详细分析主流对齐训练策略，涵盖监督微调、在线/离线人类偏好训练以及参数高效训练机制；（3）模型评估：多维度评估对齐效果的方法体系。最后，我们凝练研究发现并指明未来研究方向。本综述为推进语言模型与人类需求对齐提供了系统性参考，相关GitHub链接持续更新最新论文：https://github.com/GaryYufei/AlignLLMHumanSurvey。
