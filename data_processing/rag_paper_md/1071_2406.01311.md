# FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs

链接: http://arxiv.org/abs/2406.01311v1

原文摘要:
Fact-checking is a crucial natural language processing (NLP) task that
verifies the truthfulness of claims by considering reliable evidence.
Traditional methods are often limited by labour-intensive data curation and
rule-based approaches. In this paper, we present FactGenius, a novel method
that enhances fact-checking by combining zero-shot prompting of large language
models (LLMs) with fuzzy text matching on knowledge graphs (KGs). Leveraging
DBpedia, a structured linked data dataset derived from Wikipedia, FactGenius
refines LLM-generated connections using similarity measures to ensure accuracy.
The evaluation of FactGenius on the FactKG, a benchmark dataset for fact
verification, demonstrates that it significantly outperforms existing
baselines, particularly when fine-tuning RoBERTa as a classifier. The two-stage
approach of filtering and validating connections proves crucial, achieving
superior performance across various reasoning types and establishing FactGenius
as a promising tool for robust fact-checking. The code and materials are
available at https://github.com/SushantGautam/FactGenius.

中文翻译:
事实核查是一项关键的自然语言处理（NLP）任务，其通过参考可靠证据来验证陈述的真实性。传统方法常受限于人工密集型数据整理与基于规则的处理模式。本文提出FactGenius——一种创新方法，通过结合大型语言模型（LLM）的零样本提示与知识图谱（KG）的模糊文本匹配技术，显著提升了事实核查效能。该方法利用源自维基百科的结构化关联数据集DBpedia，采用相似度度量对LLM生成的关联进行优化以确保准确性。在事实核查基准数据集FactKG上的评估表明，FactGenius明显优于现有基线模型，尤其在将RoBERTa微调为分类器时表现突出。分阶段实施关联筛选与验证的策略被证明具有决定性作用，该方法在不同推理类型中均展现出卓越性能，使FactGenius成为鲁棒性事实核查的理想工具。代码与相关材料详见https://github.com/SushantGautam/FactGenius。
