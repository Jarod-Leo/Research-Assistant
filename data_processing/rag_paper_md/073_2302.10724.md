# ChatGPT: Jack of all trades, master of none

链接: http://arxiv.org/abs/2302.10724v1

原文摘要:
OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and
revolutionized the approach in artificial intelligence to human-model
interaction. Several publications on ChatGPT evaluation test its effectiveness
on well-known natural language processing (NLP) tasks. However, the existing
studies are mostly non-automated and tested on a very limited scale. In this
work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,
most of them subjective even to humans, such as sentiment analysis, emotion
recognition, offensiveness, and stance detection. In contrast, the other tasks
require more objective reasoning like word sense disambiguation, linguistic
acceptability, and question answering. We also evaluated GPT-4 model on five
selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process
and analyzed more than 49k responses. Our comparison of its results with
available State-of-the-Art (SOTA) solutions showed that the average loss in
quality of the ChatGPT model was about 25% for zero-shot and few-shot
evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower
than for ChatGPT. We showed that the more difficult the task (lower SOTA
performance), the higher the ChatGPT loss. It especially refers to pragmatic
NLP problems like emotion recognition. We also tested the ability to
personalize ChatGPT responses for selected subjective tasks via Random
Contextual Few-Shot Personalization, and we obtained significantly better
user-based predictions. Additional qualitative analysis revealed a ChatGPT
bias, most likely due to the rules imposed on human trainers by OpenAI. Our
results provide the basis for a fundamental discussion of whether the high
quality of recent predictive NLP models can indicate a tool's usefulness to
society and how the learning and validation procedures for such systems should
be established.

中文翻译:
OpenAI推出的Chat生成预训练转换器（ChatGPT）彻底革新了人工智能中人机交互的方式。多项针对ChatGPT的评估研究测试了其在知名自然语言处理（NLP）任务上的表现。然而现有研究大多采用非自动化方式，且测试规模极为有限。本研究系统考察了ChatGPT在25项多样化NLP分析任务中的能力，其中多数任务（如情感分析、情绪识别、冒犯性检测和立场判断）对人类而言也具有主观性，其余任务（如词义消歧、语言可接受性判断和问答系统）则需要更客观的推理能力。我们还评估了GPT-4模型在五个精选NLP任务子集上的表现。通过自动化提示流程，我们分析了超过4.9万条响应数据。与现有最先进（SOTA）解决方案的对比显示：ChatGPT模型在零样本和小样本评估中的平均质量损失约为25%；GPT-4模型在语义任务上的损失显著低于ChatGPT；任务难度越大（SOTA性能越低），ChatGPT的损失越高，这在情绪识别等语用NLP问题上表现尤为突出。通过随机上下文小样本个性化方法，我们验证了ChatGPT在选定主观任务中的响应个性化能力，获得了显著优化的用户导向预测结果。定性分析还揭示了ChatGPT存在偏见倾向，很可能源于OpenAI对训练人员制定的规则。这些发现引发了根本性讨论：当前预测性NLP模型的高质量是否真能体现其对社会的实用价值？以及此类系统的学习与验证机制应如何建立？
