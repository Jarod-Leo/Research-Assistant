# ChatGPT: Jack of all trades, master of none

链接: http://arxiv.org/abs/2302.10724v1

原文摘要:
OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and
revolutionized the approach in artificial intelligence to human-model
interaction. Several publications on ChatGPT evaluation test its effectiveness
on well-known natural language processing (NLP) tasks. However, the existing
studies are mostly non-automated and tested on a very limited scale. In this
work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,
most of them subjective even to humans, such as sentiment analysis, emotion
recognition, offensiveness, and stance detection. In contrast, the other tasks
require more objective reasoning like word sense disambiguation, linguistic
acceptability, and question answering. We also evaluated GPT-4 model on five
selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process
and analyzed more than 49k responses. Our comparison of its results with
available State-of-the-Art (SOTA) solutions showed that the average loss in
quality of the ChatGPT model was about 25% for zero-shot and few-shot
evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower
than for ChatGPT. We showed that the more difficult the task (lower SOTA
performance), the higher the ChatGPT loss. It especially refers to pragmatic
NLP problems like emotion recognition. We also tested the ability to
personalize ChatGPT responses for selected subjective tasks via Random
Contextual Few-Shot Personalization, and we obtained significantly better
user-based predictions. Additional qualitative analysis revealed a ChatGPT
bias, most likely due to the rules imposed on human trainers by OpenAI. Our
results provide the basis for a fundamental discussion of whether the high
quality of recent predictive NLP models can indicate a tool's usefulness to
society and how the learning and validation procedures for such systems should
be established.

中文翻译:
OpenAI推出的生成式预训练对话模型（ChatGPT）彻底革新了人工智能领域的人机交互方式。已有大量关于ChatGPT评估的研究测试其在经典自然语言处理（NLP）任务中的表现，但现有研究大多采用非自动化方式且测试规模有限。本研究系统考察了ChatGPT在25项多样化NLP分析任务中的能力，其中多数任务（如情感分析、情绪识别、冒犯性检测和立场检测）对人类而言都具有主观性挑战，另一些任务（如词义消歧、语言可接受性判断和问答系统）则需要更客观的推理能力。我们还针对五个精选NLP任务子集评估了GPT-4模型。通过自动化提示流程，我们分析了超过49,000条响应数据。与现有最先进（SOTA）解决方案的对比显示：ChatGPT模型在零样本和小样本评估中的平均质量损失约为25%；而GPT-4模型在语义任务上的损失显著低于ChatGPT。研究发现任务难度越大（SOTA性能越低），ChatGPT的质量损失越高，这在情绪识别等语用NLP问题上表现尤为突出。通过"随机上下文小样本个性化"方法，我们测试了ChatGPT在特定主观任务中的响应个性化能力，获得了显著优化的用户预测结果。定性分析还揭示了ChatGPT存在偏见，这可能源于OpenAI对人工训练员设定的规则限制。本研究为深入探讨"预测型NLP模型的高性能是否能真正体现其社会实用性"以及"如何建立此类系统的学习与验证流程"等根本性问题提供了实证基础。  

（翻译说明：  
1. 专业术语处理："State-of-the-Art"译为"最先进"，"zero-shot/few-shot"保留专业表述"零样本/小样本"  
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句  
3. 被动语态转换："it was shown that"转化为主动句式"研究发现"  
4. 概念显化："pragmatic NLP problems"译为"语用NLP问题"以区别于语义任务  
5. 文化适配："Random Contextual Few-Shot Personalization"采用意译+注释的混合译法  
6. 学术风格保持：使用"实证基础""系统考察"等符合学术论文表达的措辞）
