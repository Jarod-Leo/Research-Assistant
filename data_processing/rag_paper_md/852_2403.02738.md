# Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment

链接: http://arxiv.org/abs/2403.02738v1

原文摘要:
Despite the notable advancements of existing prompting methods, such as
In-Context Learning and Chain-of-Thought for Large Language Models (LLMs), they
still face challenges related to various biases. Traditional debiasing methods
primarily focus on the model training stage, including approaches based on data
augmentation and reweighting, yet they struggle with the complex biases
inherent in LLMs. To address such limitations, the causal relationship behind
the prompting methods is uncovered using a structural causal model, and a novel
causal prompting method based on front-door adjustment is proposed to
effectively mitigate LLMs biases. In specific, causal intervention is achieved
by designing the prompts without accessing the parameters and logits of LLMs.
The chain-of-thought generated by LLM is employed as the mediator variable and
the causal effect between input prompts and output answers is calculated
through front-door adjustment to mitigate model biases. Moreover, to accurately
represent the chain-of-thoughts and estimate the causal effects, contrastive
learning is used to fine-tune the encoder of chain-of-thought by aligning its
space with that of the LLM. Experimental results show that the proposed causal
prompting approach achieves excellent performance across seven natural language
processing datasets on both open-source and closed-source LLMs.

中文翻译:
尽管现有提示方法（如大语言模型中的上下文学习与思维链技术）已取得显著进展，但仍面临各类偏差问题的挑战。传统去偏方法主要聚焦于模型训练阶段，包括基于数据增强和重新加权的策略，却难以应对大语言模型固有的复杂偏差。为突破这一局限，本研究通过结构因果模型揭示了提示方法背后的因果关系，并提出一种基于前门调整的新型因果提示方法，以有效缓解大语言模型的偏差问题。具体而言，该方法在不访问模型参数和逻辑值的前提下，通过精心设计的提示实现因果干预：将大语言模型生成的思维链作为中介变量，运用前门调整计算输入提示与输出答案间的因果效应来削弱模型偏差。此外，为精确表征思维链并估算因果效应，研究采用对比学习微调思维链编码器，使其表征空间与大语言模型对齐。实验结果表明，所提出的因果提示方法在开源与闭源大语言模型上均表现优异，覆盖七种自然语言处理基准数据集。
