# Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models

链接: http://arxiv.org/abs/2311.00287v1

原文摘要:
Clinical natural language processing requires methods that can address
domain-specific challenges, such as complex medical terminology and clinical
contexts. Recently, large language models (LLMs) have shown promise in this
domain. Yet, their direct deployment can lead to privacy issues and are
constrained by resources. To address this challenge, we delve into synthetic
clinical text generation using LLMs for clinical NLP tasks. We propose an
innovative, resource-efficient approach, ClinGen, which infuses knowledge into
the process. Our model involves clinical knowledge extraction and
context-informed LLM prompting. Both clinical topics and writing styles are
drawn from external domain-specific knowledge graphs and LLMs to guide data
generation. Our extensive empirical study across 7 clinical NLP tasks and 16
datasets reveals that ClinGen consistently enhances performance across various
tasks, effectively aligning the distribution of real datasets and significantly
enriching the diversity of generated training instances. Our code is available
at \url{https://github.com/ritaranx/ClinGen}.

中文翻译:
临床自然语言处理需要能够应对领域特有挑战的方法，例如复杂的医学术语和临床情境。近年来，大型语言模型（LLMs）在该领域展现出潜力，但直接部署可能引发隐私问题并受资源限制。为此，我们深入探索利用LLMs生成合成临床文本以支持临床NLP任务，提出了一种创新且资源高效的ClinGen方法，将知识注入生成过程。该模型通过临床知识提取和情境感知的LLM提示技术，从外部领域知识图谱和LLMs中提取临床主题与写作风格来指导数据生成。我们在7项临床NLP任务和16个数据集上的广泛实验表明，ClinGen能持续提升各类任务性能，有效对齐真实数据分布，并显著增强生成训练实例的多样性。代码已开源于\url{https://github.com/ritaranx/ClinGen}。
