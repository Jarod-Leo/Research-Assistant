# Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model

链接: http://arxiv.org/abs/2305.17116v1

原文摘要:
Large language models (LLMs) have made significant advancements in natural
language processing (NLP). Broad corpora capture diverse patterns but can
introduce irrelevance, while focused corpora enhance reliability by reducing
misleading information. Training LLMs on focused corpora poses computational
challenges. An alternative approach is to use a retrieval-augmentation (RetA)
method tested in a specific domain.
  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a
custom RetA model were compared using 19 questions on diffuse large B-cell
lymphoma (DLBCL) disease. Eight independent reviewers assessed responses based
on accuracy, relevance, and readability (rated 1-3).
  The RetA model performed best in accuracy (12/19 3-point scores, total=47)
and relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4
received the highest readability scores (17/19, 55), followed by GPT-3 (15/19,
53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),
relevance (32), and readability (38).
  Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared
to the RetA model and Prometheus. Hallucinations were mostly associated with
non-existent references or fabricated efficacy data.
  These findings suggest that RetA models, supplemented with domain-specific
corpora, may outperform general-purpose LLMs in accuracy and relevance within
specific domains. However, this evaluation was limited to specific questions
and metrics and may not capture challenges in semantic search and other NLP
tasks. Further research will explore different LLM architectures, RetA
methodologies, and evaluation methods to assess strengths and limitations more
comprehensively.

中文翻译:
大型语言模型（LLM）在自然语言处理（NLP）领域取得了显著进展。广泛语料库虽能捕捉多样模式但可能引入无关信息，而聚焦语料库通过减少误导性信息提升了可靠性。针对聚焦语料库训练LLM存在计算挑战，替代方案是采用在特定领域测试过的检索增强（RetA）方法。

为评估模型性能，研究使用19个弥漫性大B细胞淋巴瘤（DLBCL）相关问题对比了OpenAI的GPT-3、GPT-4、Bing的Prometheus和定制RetA模型。八位独立评审从准确性、相关性和可读性（1-3分制）三个维度进行评分。

RetA模型在准确性（12/19题获3分，总分47）和相关性（13/19，50分）表现最佳，GPT-4次之（8/19，43分；11/19，49分）。GPT-4可读性得分最高（17/19，55分），其次是GPT-3（15/19，53分）和RetA模型（11/19，47分）。Prometheus在三项指标上均表现不佳（准确性34分，相关性32分，可读性38分）。

相较于RetA模型和Prometheus，GPT-3.5和GPT-4在全部19个回答中出现了更多幻觉现象，主要表现为虚构参考文献或疗效数据。这表明在特定领域内，辅以专业语料库的RetA模型可能在准确性和相关性上优于通用LLM。但本次评估仅针对特定问题和指标，未能涵盖语义搜索等NLP任务的挑战。后续研究将探索不同LLM架构、RetA方法和评估体系，以更全面评估其优势与局限。
