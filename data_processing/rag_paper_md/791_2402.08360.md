# Visual Question Answering Instruction: Unlocking Multimodal Large Language Model To Domain-Specific Visual Multitasks

链接: http://arxiv.org/abs/2402.08360v1

原文摘要:
Having revolutionized natural language processing (NLP) applications, large
language models (LLMs) are expanding into the realm of multimodal inputs. Owing
to their ability to interpret images, multimodal LLMs (MLLMs) have been
primarily used for vision-language tasks. Currently, MLLMs have not yet been
extended for domain-specific visual tasks, which require a more explicit
understanding of visual information. We developed a method to transform
domain-specific visual and vision-language datasets into a unified question
answering format called Visual Question Answering Instruction (VQA-IN), thereby
extending MLLM to domain-specific tasks. The VQA-IN was applied to train
multiple MLLM architectures using smaller versions of LLMs (sLLMs). The
experimental results indicated that the proposed method achieved a high score
metric on domainspecific visual tasks while also maintaining its performance on
vision-language tasks in a multitask manner.

中文翻译:
在彻底变革自然语言处理（NLP）应用后，大语言模型（LLMs）正将应用边界拓展至多模态输入领域。得益于图像解析能力，多模态大语言模型（MLLMs）当前主要应用于视觉-语言任务。目前MLLMs尚未延伸至专业领域视觉任务——这类任务需要对视觉信息进行更显式的理解。我们开发了一种将专业领域视觉及视觉-语言数据集转化为统一问答格式的方法（称为视觉问答指令VQA-IN），从而将MLLM扩展至专业领域任务。通过采用较小规模的大语言模型（sLLMs），我们运用VQA-IN对多种MLLM架构进行训练。实验结果表明：该方法在专业视觉任务上获得了优异的评分指标，同时以多任务方式保持了在视觉-语言任务上的性能表现。

（翻译说明：
1. 专业术语处理："domain-specific"译为"专业领域"以突出其垂直性，"explicit understanding"译为"显式理解"符合计算机视觉领域术语习惯
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"Owing to..."状语从句转化为独立短句
3. 被动语态转化："have been primarily used"等被动结构转换为中文主动表述
4. 概念显化："smaller versions of LLMs"译为"较小规模的大语言模型"并补充括号标注"sLLMs"确保专业性
5. 指标表述："high score metric"译为"优异的评分指标"既保持准确性又符合中文科技论文表达规范）
