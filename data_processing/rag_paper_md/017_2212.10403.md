# Towards Reasoning in Large Language Models: A Survey

链接: http://arxiv.org/abs/2212.10403v1

原文摘要:
Reasoning is a fundamental aspect of human intelligence that plays a crucial
role in activities such as problem solving, decision making, and critical
thinking. In recent years, large language models (LLMs) have made significant
progress in natural language processing, and there is observation that these
models may exhibit reasoning abilities when they are sufficiently large.
However, it is not yet clear to what extent LLMs are capable of reasoning. This
paper provides a comprehensive overview of the current state of knowledge on
reasoning in LLMs, including techniques for improving and eliciting reasoning
in these models, methods and benchmarks for evaluating reasoning abilities,
findings and implications of previous research in this field, and suggestions
on future directions. Our aim is to provide a detailed and up-to-date review of
this topic and stimulate meaningful discussion and future work.

中文翻译:
推理作为人类智能的核心要素，在问题解决、决策制定和批判性思维等活动中发挥着关键作用。近年来，大型语言模型（LLMs）在自然语言处理领域取得显著突破，有观察表明当模型规模足够大时可能展现出推理能力。然而，目前尚不清楚LLMs的推理能力究竟达到何种程度。本文系统梳理了LLMs推理研究的现状，包括提升和激发模型推理能力的技术手段、评估推理能力的方法与基准测试、该领域已有研究的发现与启示，并对未来研究方向提出建议。我们旨在为这一主题提供全面而前沿的综述，以促进深入讨论和后续研究。
