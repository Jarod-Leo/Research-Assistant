# Investigating LLM Applications in E-Commerce

链接: http://arxiv.org/abs/2408.12779v1

原文摘要:
The emergence of Large Language Models (LLMs) has revolutionized natural
language processing in various applications especially in e-commerce. One
crucial step before the application of such LLMs in these fields is to
understand and compare the performance in different use cases in such tasks.
This paper explored the efficacy of LLMs in the e-commerce domain, focusing on
instruction-tuning an open source LLM model with public e-commerce datasets of
varying sizes and comparing the performance with the conventional models
prevalent in industrial applications. We conducted a comprehensive comparison
between LLMs and traditional pre-trained language models across specific tasks
intrinsic to the e-commerce domain, namely classification, generation,
summarization, and named entity recognition (NER). Furthermore, we examined the
effectiveness of the current niche industrial application of very large LLM,
using in-context learning, in e-commerce specific tasks. Our findings indicate
that few-shot inference with very large LLMs often does not outperform
fine-tuning smaller pre-trained models, underscoring the importance of
task-specific model optimization.Additionally, we investigated different
training methodologies such as single-task training, mixed-task training, and
LoRA merging both within domain/tasks and between different tasks. Through
rigorous experimentation and analysis, this paper offers valuable insights into
the potential effectiveness of LLMs to advance natural language processing
capabilities within the e-commerce industry.

中文翻译:
大型语言模型（LLMs）的出现为自然语言处理领域带来了革命性变革，尤其在电子商务应用中表现突出。在这些领域应用LLMs之前，关键步骤是理解并比较其在不同任务场景中的性能表现。本文探究了LLMs在电商领域的效能，重点研究了基于不同规模公开电商数据集对开源LLM模型进行指令微调的效果，并与工业应用中传统模型进行性能对比。我们针对电商领域核心任务——分类、生成、摘要和命名实体识别（NER），对LLMs与传统预训练语言模型展开了全面比较。此外，我们还验证了当前超大规模LLM通过上下文学习在电商专项任务中的实际应用效果。研究结果表明：采用少量样本推理的超大LLM往往无法超越经过微调的小型预训练模型，这凸显了任务特定模型优化的重要性。我们还探索了单任务训练、混合任务训练以及领域内/跨任务的LoRA融合等不同训练方法。通过严谨的实验与分析，本文为LLMs提升电商行业自然语言处理能力的潜在有效性提供了重要见解。
