# Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning

链接: http://arxiv.org/abs/2412.02904v1

原文摘要:
Large language models (LLMs) have revolutionized the field of natural
language processing with their impressive reasoning and question-answering
capabilities. However, these models are sometimes prone to generating
credible-sounding but incorrect information, a phenomenon known as LLM
hallucinations. Reliable uncertainty estimation in LLMs is essential for
fostering trust in their generated responses and serves as a critical tool for
the detection and prevention of erroneous or hallucinated outputs. To achieve
reliable and well-calibrated uncertainty quantification in open-ended and
free-form natural language generation, we propose an uncertainty-aware
fine-tuning approach for LLMs. This approach enhances the model's ability to
provide reliable uncertainty estimates without compromising accuracy, thereby
guiding them to produce more trustworthy responses. We introduce a novel
uncertainty-aware causal language modeling loss function, grounded in the
principles of decision theory. Through rigorous evaluation on multiple
free-form question-answering datasets and models, we demonstrate that our
uncertainty-aware fine-tuning approach yields better calibrated uncertainty
estimates in natural language generation tasks than fine-tuning with the
standard causal language modeling loss. Furthermore, the experimental results
show that the proposed method significantly improves the model's ability to
detect hallucinations and identify out-of-domain prompts.

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLMs）凭借其卓越的推理与问答能力，彻底革新了自然语言处理领域。然而，这类模型有时会生成看似可信实则错误的信息，这种现象被称为"LLM幻觉"。实现可靠的不确定性估计对建立用户信任至关重要，同时也是检测和预防错误输出或幻觉内容的关键工具。

为在开放式自然语言生成任务中实现可靠且校准良好的不确定性量化，我们提出了一种不确定性感知的LLM微调方法。该方法能在保持模型准确性的同时增强其不确定性估计能力，从而引导模型生成更可信的响应。基于决策理论原理，我们创新性地设计了一种不确定性感知因果语言建模损失函数。

通过在多个开放式问答数据集和模型上的严格评估，我们证明：相较于标准因果语言建模损失的微调方法，我们的不确定性感知微调方案能产生校准效果更优的不确定性估计。实验结果进一步表明，该方法显著提升了模型检测幻觉内容和识别域外提示的能力。

（翻译严格遵循以下要点：
1. 专业术语准确统一："hallucinations"译为"幻觉"，"calibrated"译为"校准"
2. 被动语态转化："are prone to"译为"会"，"is essential"译为"对...至关重要"
3. 长句拆分：将原文复合句分解为符合中文表达习惯的短句
4. 学术风格保持：使用"域外提示"等专业表述，避免口语化
5. 逻辑显化：通过"同时""从而"等连接词明确原文隐含的逻辑关系）
