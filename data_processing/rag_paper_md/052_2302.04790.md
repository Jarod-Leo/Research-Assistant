# Massively Multilingual Language Models for Cross Lingual Fact Extraction from Low Resource Indian Languages

链接: http://arxiv.org/abs/2302.04790v1

原文摘要:
Massive knowledge graphs like Wikidata attempt to capture world knowledge
about multiple entities. Recent approaches concentrate on automatically
enriching these KGs from text. However a lot of information present in the form
of natural text in low resource languages is often missed out. Cross Lingual
Information Extraction aims at extracting factual information in the form of
English triples from low resource Indian Language text. Despite its massive
potential, progress made on this task is lagging when compared to Monolingual
Information Extraction. In this paper, we propose the task of Cross Lingual
Fact Extraction(CLFE) from text and devise an end-to-end generative approach
for the same which achieves an overall F1 score of 77.46.

中文翻译:
以下为符合学术规范的中文翻译：

【摘要】诸如维基数据等大规模知识图谱旨在收录关于多元实体的世界知识。当前主流研究方法集中于从文本中自动扩展这些知识图谱，但大量以低资源语言自然文本形式存在的信息往往被遗漏。跨语言信息抽取的核心目标是从印度低资源语言文本中提取以英语三元组形式呈现的事实信息。尽管该领域潜力巨大，但与单语信息抽取相比，其研究进展明显滞后。本文提出文本跨语言事实抽取（CLFE）任务，并设计了一种端到端的生成式方法，最终实现了77.46的综合F1值。

注：
1. 专业术语处理：
- "knowledge graphs"译为"知识图谱"（学界标准译法）
- "triples"译为"三元组"（信息抽取领域通用术语）
- "F1 score"保留英文缩写并补充说明为"综合F1值"

2. 句式重构：
- 将英文长句拆分为符合中文表达习惯的短句（如第二句的拆分）
- 被动语态转为主动表述（如"is often missed out"译为"被遗漏"转为"往往被遗漏"）

3. 概念显化：
- "low resource languages"译为"低资源语言"后补充说明"印度低资源语言"（根据原文Indian Language特指）
- "generative approach"译为"生成式方法"（突出NLP领域方法特性）

4. 数字规范：
- 保留精确数值77.46，符合科技论文数字表达规范
