# BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation

链接: http://arxiv.org/abs/2402.08793v1

原文摘要:
The accurate segmentation of medical images is critical for various
healthcare applications. Convolutional neural networks (CNNs), especially Fully
Convolutional Networks (FCNs) like U-Net, have shown remarkable success in
medical image segmentation tasks. However, they have limitations in capturing
global context and long-range relations, especially for objects with
significant variations in shape, scale, and texture. While transformers have
achieved state-of-the-art results in natural language processing and image
recognition, they face challenges in medical image segmentation due to image
locality and translational invariance issues. To address these challenges, this
paper proposes an innovative U-shaped network called BEFUnet, which enhances
the fusion of body and edge information for precise medical image segmentation.
The BEFUnet comprises three main modules, including a novel Local
Cross-Attention Feature (LCAF) fusion module, a novel Double-Level Fusion (DLF)
module, and dual-branch encoder. The dual-branch encoder consists of an edge
encoder and a body encoder. The edge encoder employs PDC blocks for effective
edge information extraction, while the body encoder uses the Swin Transformer
to capture semantic information with global attention. The LCAF module
efficiently fuses edge and body features by selectively performing local
cross-attention on features that are spatially close between the two
modalities. This local approach significantly reduces computational complexity
compared to global cross-attention while ensuring accurate feature matching.
BEFUnet demonstrates superior performance over existing methods across various
evaluation metrics on medical image segmentation datasets.

中文翻译:
医学图像的精准分割对众多医疗应用至关重要。卷积神经网络（CNN），尤其是U-Net等全卷积网络（FCN），在医学图像分割任务中展现出卓越成效。然而，这类网络在捕捉全局上下文和长程关联方面存在局限，特别是对于形状、尺度和纹理差异显著的物体。尽管Transformer模型在自然语言处理和图像识别领域取得了最先进的成果，但由于图像局部性和平移不变性问题，其在医学图像分割中面临挑战。为此，本文提出了一种创新的U型网络架构BEFUnet，通过强化主体与边缘信息的融合来实现精确的医学图像分割。

BEFUnet包含三大核心模块：新型局部交叉注意力特征融合模块（LCAF）、创新性双层级融合模块（DLF）以及双分支编码器。双分支编码器由边缘编码器和主体编码器构成：边缘编码器采用PDC模块高效提取边缘特征，主体编码器则利用Swin Transformer通过全局注意力机制捕获语义信息。LCAF模块通过选择性执行空间邻近特征间的局部交叉注意力，实现了边缘与主体特征的高效融合。相较于全局交叉注意力，这种局部策略在确保特征匹配精度的同时显著降低了计算复杂度。在多个医学图像分割数据集的综合评估中，BEFUnet各项指标均优于现有方法。
