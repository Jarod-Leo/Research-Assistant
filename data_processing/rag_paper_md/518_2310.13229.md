# The GitHub Recent Bugs Dataset for Evaluating LLM-based Debugging Applications

链接: http://arxiv.org/abs/2310.13229v1

原文摘要:
Large Language Models (LLMs) have demonstrated strong natural language
processing and code synthesis capabilities, which has led to their rapid
adoption in software engineering applications. However, details about LLM
training data are often not made public, which has caused concern as to whether
existing bug benchmarks are included. In lieu of the training data for the
popular GPT models, we examine the training data of the open-source LLM
StarCoder, and find it likely that data from the widely used Defects4J
benchmark was included, raising the possibility of its inclusion in GPT
training data as well. This makes it difficult to tell how well LLM-based
results on Defects4J would generalize, as for any results it would be unclear
whether a technique's performance is due to LLM generalization or memorization.
To remedy this issue and facilitate continued research on LLM-based SE, we
present the GitHub Recent Bugs (GHRB) dataset, which includes 76 real-world
Java bugs that were gathered after the OpenAI data cut-off point.

中文翻译:
大型语言模型（LLMs）已展现出强大的自然语言处理与代码生成能力，这使其在软件工程领域迅速得到广泛应用。然而，由于LLM训练数据的细节通常未公开，人们担忧现有缺陷基准测试集（如Defects4J）可能已被纳入训练数据。针对主流GPT模型训练数据不可获取的情况，我们分析了开源LLM StarCoder的训练数据，发现其很可能包含了Defects4J基准测试集的数据，这意味着GPT模型的训练数据也可能存在相同情况。这种现象导致基于LLM在Defects4J上的性能评估难以判断——模型表现究竟源于其泛化能力还是对训练数据的记忆，目前缺乏有效区分标准。为应对这一问题并推动基于LLM的软件工程研究持续发展，我们构建了GitHub近期缺陷数据集（GHRB），该数据集包含76个真实世界的Java程序错误，这些错误均出现在OpenAI数据截止日期之后，可有效避免训练数据污染问题。
