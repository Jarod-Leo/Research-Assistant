# The GitHub Recent Bugs Dataset for Evaluating LLM-based Debugging Applications

链接: http://arxiv.org/abs/2310.13229v1

原文摘要:
Large Language Models (LLMs) have demonstrated strong natural language
processing and code synthesis capabilities, which has led to their rapid
adoption in software engineering applications. However, details about LLM
training data are often not made public, which has caused concern as to whether
existing bug benchmarks are included. In lieu of the training data for the
popular GPT models, we examine the training data of the open-source LLM
StarCoder, and find it likely that data from the widely used Defects4J
benchmark was included, raising the possibility of its inclusion in GPT
training data as well. This makes it difficult to tell how well LLM-based
results on Defects4J would generalize, as for any results it would be unclear
whether a technique's performance is due to LLM generalization or memorization.
To remedy this issue and facilitate continued research on LLM-based SE, we
present the GitHub Recent Bugs (GHRB) dataset, which includes 76 real-world
Java bugs that were gathered after the OpenAI data cut-off point.

中文翻译:
以下是符合要求的学术化中文翻译：

大型语言模型（LLMs）已展现出强大的自然语言处理与代码生成能力，这使其在软件工程领域获得快速应用。然而，由于LLM训练数据的细节通常未公开，业界对现有缺陷基准集（如Defects4J）是否被纳入训练数据存在普遍担忧。鉴于主流GPT模型训练数据不可获取，本研究通过分析开源LLM StarCoder的训练数据，发现广泛使用的Defects4J基准集极可能被包含其中，这同样暗示GPT训练数据可能存在类似情况。该现象导致基于Defects4J的LLM评估结果难以判断其泛化能力——我们无法确定模型表现是源于算法泛化还是数据记忆。为应对此问题并促进LLM在软件工程领域的持续研究，本研究构建了GitHub近期缺陷数据集（GHRB），包含76个在OpenAI数据截止日期后收集的真实Java程序错误案例。

注：翻译过程中采取了以下专业处理：
1. 术语统一："bug"根据语境分别译为"缺陷"（学术规范）和"程序错误"（具体案例）
2. 被动语态转换：将英文被动结构转换为中文主动表述（如"details are not made public"→"通常未公开"）
3. 长句拆分：将原文复合句按中文表达习惯分解为多个短句
4. 概念显化：如"data cut-off point"译为"数据截止日期"以明确时间属性
5. 学术用语："generalization"译为"泛化能力"符合机器学习领域术语规范
