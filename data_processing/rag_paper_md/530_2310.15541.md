# Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary

链接: http://arxiv.org/abs/2310.15541v1

原文摘要:
The non-humanlike behaviour of contemporary pre-trained language models
(PLMs) is a leading cause undermining their trustworthiness. A striking
phenomenon of such faulty behaviours is the generation of inconsistent
predictions, which produces logically contradictory results, such as generating
different predictions for texts delivering the same meaning or violating
logical properties. Previous studies exploited data augmentation or implemented
specialised loss functions to alleviate the issue. However, their usage is
limited, because they consume expensive training resources for large-sized PLMs
and can only handle a certain consistency type. To this end, we propose a
practical approach that alleviates the inconsistent behaviour issue by
fundamentally improving PLMs' meaning awareness. Based on the conceptual role
theory, our method allows PLMs to capture accurate meaning by learning precise
interrelationships between concepts from word-definition pairs in a dictionary.
Next, we propose an efficient parameter integration technique that updates only
a few additional parameters to combine the learned interrelationship with PLMs'
pre-trained knowledge. Our experimental results reveal that the approach can
concurrently improve multiple types of consistency, enables efficient knowledge
integration, and easily applies to other languages.

中文翻译:
当代预训练语言模型（PLMs）的非人类行为是削弱其可信度的主要原因之一。此类错误行为的一个突出表现是生成不一致的预测，即产生逻辑矛盾的结果，例如对表达相同含义的文本给出不同预测，或违反逻辑属性。先前研究通过数据增强或设计特殊损失函数来缓解该问题，但这些方法存在局限性：它们需要为大型PLMs消耗昂贵的训练资源，且仅能处理特定类型的一致性。为此，我们提出一种实用方法，通过从根本上提升PLMs的语义感知能力来解决不一致行为问题。基于概念角色理论，该方法通过让PLMs从词典中的词-定义对学习概念间的精确关联关系来捕捉准确语义。接着，我们提出高效的参数集成技术，仅需更新少量附加参数即可将习得的关联关系与PLMs的预训练知识相结合。实验结果表明，该方法能同时改善多种一致性类型，实现高效知识整合，并可轻松迁移至其他语言。
