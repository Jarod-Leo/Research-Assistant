# Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models

链接: http://arxiv.org/abs/2411.02382v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

中文翻译:
以下是符合要求的专业学术翻译：

大型语言模型（LLMs）在从自然语言处理到复杂问题求解等多个科学领域展现出卓越能力。其理解和生成类人文本的特性为科研进步开辟了新途径，可支持数据分析、文献综述乃至实验设计等任务。在此背景下，LLMs最具前景的应用之一是假设生成——通过分析现有知识发现新颖研究方向。然而尽管潜力巨大，LLMs易产生"幻觉"现象，即生成看似合理实则事实错误的输出。这类问题在要求严格准确性与可验证性的科学领域构成重大挑战，可能导致错误或误导性结论。

为应对这些挑战，我们提出KG-CoI（知识图谱支撑的思维链）——一种通过整合知识图谱（KGs）外部结构化知识来增强LLM假设生成的新系统。KG-CoI通过结构化推理流程引导LLMs，将其输出组织为思维链（CoI），并包含基于KG的幻觉检测模块。在我们新构建的假设生成数据集上的实验表明，KG-CoI不仅能提升LLM生成假设的准确性，还可减少推理链中的幻觉现象，凸显其在推动现实科学研究中的有效性。

（翻译严格遵循以下原则：
1. 专业术语统一（如LLMs/KGs保持英文缩写，首次出现标注全称）
2. 被动语态转换为中文主动句式（如"are prone to"译为"易产生"）
3. 长难句拆分重组（如原文第二句拆分为两个中文流水句）
4. 学术概念准确传达（"hallucinations"保留专业译法"幻觉"并加引号强调）
5. 逻辑连接显性化（添加破折号、冒号等衔接手段）
6. 重要概念首次出现时中英对照（如"chain of ideas (CoI)"））
