# Whether and When does Endoscopy Domain Pretraining Make Sense?

链接: http://arxiv.org/abs/2303.17636v1

原文摘要:
Automated endoscopy video analysis is a challenging task in medical computer
vision, with the primary objective of assisting surgeons during procedures. The
difficulty arises from the complexity of surgical scenes and the lack of a
sufficient amount of annotated data. In recent years, large-scale pretraining
has shown great success in natural language processing and computer vision
communities. These approaches reduce the need for annotated data, which is
always a concern in the medical domain. However, most works on endoscopic video
understanding use models pretrained on natural images, creating a domain gap
between pretraining and finetuning. In this work, we investigate the need for
endoscopy domain-specific pretraining based on downstream objectives. To this
end, we first collect Endo700k, the largest publicly available corpus of
endoscopic images, extracted from nine public Minimally Invasive Surgery (MIS)
datasets. Endo700k comprises more than 700,000 unannotated raw images. Next, we
introduce EndoViT, an endoscopy pretrained Vision Transformer (ViT). Through
ablations, we demonstrate that domain-specific pretraining is particularly
beneficial for more complex downstream tasks, such as Action Triplet Detection,
and less effective and even unnecessary for simpler tasks, such as Surgical
Phase Recognition. We will release both our code and pretrained models upon
acceptance to facilitate further research in this direction.

中文翻译:
内窥镜视频自动分析是医学计算机视觉领域的一项挑战性任务，其主要目标在于辅助外科医生进行手术操作。该任务的难点源于手术场景的复杂性以及标注数据量的不足。近年来，大规模预训练技术在自然语言处理和计算机视觉领域取得了显著成功，这种方法降低了对标注数据的依赖，而这正是医疗领域长期面临的痛点。然而当前大多数内窥镜视频理解研究仍采用基于自然图像预训练的模型，导致预训练与微调阶段存在领域差异。本研究基于下游任务目标，系统探究了内窥镜领域专用预训练的必要性。为此，我们首先构建了Endo700k——目前最大的公开内窥镜图像数据集，该数据集从九个公开微创手术(MIS)数据集中提取，包含超过70万张未标注的原始图像。随后我们提出了EndoViT，一种专用于内窥镜的视觉Transformer预训练模型。通过消融实验证实：领域专用预训练对于复杂下游任务（如动作三元组检测）效果显著，而对于简单任务（如手术阶段识别）则效果有限甚至无需专门预训练。论文录用后我们将公开代码与预训练模型，以推动该方向的后续研究。
