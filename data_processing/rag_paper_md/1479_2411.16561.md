# EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code

链接: http://arxiv.org/abs/2411.16561v1

原文摘要:
Automated detection of software vulnerabilities is critical for enhancing
security, yet existing methods often struggle with the complexity and diversity
of modern codebases. In this paper, we introduce EnStack, a novel ensemble
stacking framework that enhances vulnerability detection using natural language
processing (NLP) techniques. Our approach synergizes multiple pre-trained large
language models (LLMs) specialized in code understanding CodeBERT for semantic
analysis, GraphCodeBERT for structural representation, and UniXcoder for
cross-modal capabilities. By fine-tuning these models on the Draper VDISC
dataset and integrating their outputs through meta-classifiers such as Logistic
Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack
effectively captures intricate code patterns and vulnerabilities that
individual models may overlook. The meta-classifiers consolidate the strengths
of each LLM, resulting in a comprehensive model that excels in detecting subtle
and complex vulnerabilities across diverse programming contexts. Experimental
results demonstrate that EnStack significantly outperforms existing methods,
achieving notable improvements in accuracy, precision, recall, and F1-score.
This work highlights the potential of ensemble LLM approaches in code analysis
tasks and offers valuable insights into applying NLP techniques for advancing
automated vulnerability detection.

中文翻译:
软件漏洞的自动化检测对提升安全性至关重要，然而现有方法常因现代代码库的复杂性与多样性而表现不佳。本文提出EnStack——一种创新的集成堆叠框架，通过自然语言处理（NLP）技术增强漏洞检测能力。该框架协同整合了多个专精于代码理解的预训练大语言模型（LLM）：CodeBERT负责语义分析，GraphCodeBERT处理结构表征，UniXcoder则发挥跨模态优势。这些模型在Draper VDISC数据集上微调后，经由逻辑回归、支持向量机（SVM）、随机森林和XGBoost等元分类器集成输出，使EnStack能有效捕捉单一模型可能忽略的复杂代码模式与潜在漏洞。元分类器通过融合各LLM优势，构建出可跨编程语境精准识别细微复杂漏洞的综合性模型。实验结果表明，EnStack在准确率、精确率、召回率和F1分数上显著超越现有方法，证实了集成LLM在代码分析任务中的潜力，为应用NLP技术推进自动化漏洞检测提供了重要启示。
