# Evaluating the Capability of Large-scale Language Models on Chinese Grammatical Error Correction Task

链接: http://arxiv.org/abs/2307.03972v1

原文摘要:
Large-scale language models (LLMs) has shown remarkable capability in various
of Natural Language Processing (NLP) tasks and attracted lots of attention
recently. However, some studies indicated that large language models fail to
achieve promising result beyond the state-of-the-art models in English
grammatical error correction (GEC) tasks. In this report, we aim to explore the
how large language models perform on Chinese grammatical error correction tasks
and provide guidance for future work. We conduct experiments with 3 different
LLMs of different model scale on 4 Chinese GEC dataset. Our experimental
results indicate that the performances of LLMs on automatic evaluation metrics
falls short of the previous sota models because of the problem of
over-correction. Furthermore, we also discover notable variations in the
performance of LLMs when evaluated on different data distributions. Our
findings demonstrates that further investigation is required for the
application of LLMs on Chinese GEC task.

中文翻译:
大规模语言模型（LLMs）在多种自然语言处理任务中展现出卓越能力，近期备受关注。然而，部分研究表明，在英语语法错误修正（GEC）任务中，大语言模型未能超越现有最优模型的性能表现。本报告旨在探究大语言模型在中文语法错误修正任务中的表现，并为后续研究提供方向。我们选取了三种不同规模的LLM模型，在四个中文GEC数据集上进行实验。实验结果表明，由于过度修正问题，LLMs在自动评估指标上的表现未能达到先前最优模型水平。此外，我们还发现LLMs在不同数据分布下的性能存在显著差异。这些发现表明，大语言模型在中文GEC任务中的应用仍需进一步深入研究。
