# Through the Lens of Core Competency: Survey on Evaluation of Large Language Models

链接: http://arxiv.org/abs/2308.07902v1

原文摘要:
From pre-trained language model (PLM) to large language model (LLM), the
field of natural language processing (NLP) has witnessed steep performance
gains and wide practical uses. The evaluation of a research field guides its
direction of improvement. However, LLMs are extremely hard to thoroughly
evaluate for two reasons. First of all, traditional NLP tasks become inadequate
due to the excellent performance of LLM. Secondly, existing evaluation tasks
are difficult to keep up with the wide range of applications in real-world
scenarios. To tackle these problems, existing works proposed various benchmarks
to better evaluate LLMs. To clarify the numerous evaluation tasks in both
academia and industry, we investigate multiple papers concerning LLM
evaluations. We summarize 4 core competencies of LLM, including reasoning,
knowledge, reliability, and safety. For every competency, we introduce its
definition, corresponding benchmarks, and metrics. Under this competency
architecture, similar tasks are combined to reflect corresponding ability,
while new tasks can also be easily added into the system. Finally, we give our
suggestions on the future direction of LLM's evaluation.

中文翻译:
从预训练语言模型（PLM）到大规模语言模型（LLM），自然语言处理（NLP）领域经历了性能的飞跃式提升与应用场景的广泛拓展。对一个研究领域的评估指引着其改进方向，然而当前LLM的全面评估面临两大挑战：一方面，传统NLP任务因LLM的卓越表现逐渐失去区分度；另一方面，现有评估体系难以覆盖现实场景中多样化的应用需求。为解决这些问题，学界已提出多种基准测试框架。为厘清学术界与工业界纷繁复杂的评估任务，本文系统研究了多篇LLM评估相关文献，提炼出推理、知识、可靠性与安全性四大核心能力维度。针对每个能力维度，我们明确定义、梳理对应评测基准与量化指标。该能力架构体系既能整合相似任务以反映特定能力，又可灵活扩展新兴评测需求。最后，我们对LLM评估的未来发展方向提出了建设性意见。

（翻译说明：
1. 专业术语处理：PLM/LLM等缩写首次出现时保留英文全称，后续直接使用缩写；专业词汇如"benchmarks"译为"基准测试框架"符合计算机领域表述习惯
2. 长句拆分重构：将原文复合句拆分为符合中文表达习惯的短句，如将"for two reasons..."处理为分号连接的并列结构
3. 学术语体保持：使用"厘清""提炼""维度"等学术用语，保持原文严谨性
4. 动态对等翻译："steep performance gains"译为"飞跃式提升"既准确传达指数级增长含义，又符合中文科技文本表达
5. 逻辑显化处理："under this competency architecture"译为"该能力架构体系"，通过添加"体系"使抽象概念具体化）
