# Pseudo-Prompt Generating in Pre-trained Vision-Language Models for Multi-Label Medical Image Classification

链接: http://arxiv.org/abs/2405.06468v1

原文摘要:
The task of medical image recognition is notably complicated by the presence
of varied and multiple pathological indications, presenting a unique challenge
in multi-label classification with unseen labels. This complexity underlines
the need for computer-aided diagnosis methods employing multi-label zero-shot
learning. Recent advancements in pre-trained vision-language models (VLMs) have
showcased notable zero-shot classification abilities on medical images.
However, these methods have limitations on leveraging extensive pre-trained
knowledge from broader image datasets, and often depend on manual prompt
construction by expert radiologists. By automating the process of prompt
tuning, prompt learning techniques have emerged as an efficient way to adapt
VLMs to downstream tasks. Yet, existing CoOp-based strategies fall short in
performing class-specific prompts on unseen categories, limiting
generalizability in fine-grained scenarios. To overcome these constraints, we
introduce a novel prompt generation approach inspirited by text generation in
natural language processing (NLP). Our method, named Pseudo-Prompt Generating
(PsPG), capitalizes on the priori knowledge of multi-modal features. Featuring
a RNN-based decoder, PsPG autoregressively generates class-tailored embedding
vectors, i.e., pseudo-prompts. Comparative evaluations on various multi-label
chest radiograph datasets affirm the superiority of our approach against
leading medical vision-language and multi-label prompt learning methods. The
source code is available at https://github.com/fallingnight/PsPG

中文翻译:
医学图像识别任务因存在多样且多重的病理指征而尤为复杂，这为包含未知标签的多标签分类带来了独特挑战。这一复杂性凸显了采用多标签零样本学习的计算机辅助诊断方法的必要性。预训练视觉语言模型（VLM）的最新进展已展现出在医学图像上显著的零样本分类能力，但这些方法在利用更广泛图像数据集中的预训练知识方面存在局限，且常依赖放射科专家手动构建提示词。通过自动化提示调优过程，提示学习技术已成为适配VLM至下游任务的有效途径。然而现有基于CoOp的策略无法针对未见类别生成特定于类的提示词，限制了细粒度场景下的泛化能力。

为突破这些限制，我们受自然语言处理（NLP）中文本生成技术启发，提出了一种新型提示生成方法。该技术名为伪提示生成（PsPG），通过基于RNN的解码器自回归地生成适配各类别的嵌入向量（即伪提示词），充分利用了多模态特征的先验知识。在多标签胸部X光数据集上的对比实验表明，该方法优于当前主流医学视觉语言模型和多标签提示学习技术。源代码已发布于https://github.com/fallingnight/PsPG。
