# Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges

链接: http://arxiv.org/abs/2311.15766v1

原文摘要:
In recent years, large language models (LLMs) have spurred a new research
paradigm in natural language processing. Despite their excellent capability in
knowledge-based question answering and reasoning, their potential to retain
faulty or even harmful knowledge poses risks of malicious application. The
challenge of mitigating this issue and transforming these models into purer
assistants is crucial for their widespread applicability. Unfortunately,
Retraining LLMs repeatedly to eliminate undesirable knowledge is impractical
due to their immense parameters. Knowledge unlearning, derived from analogous
studies on machine unlearning, presents a promising avenue to address this
concern and is notably advantageous in the context of LLMs. It allows for the
removal of harmful knowledge in an efficient manner, without affecting
unrelated knowledge in the model. To this end, we provide a survey of knowledge
unlearning in the era of LLMs. Firstly, we formally define the knowledge
unlearning problem and distinguish it from related works. Subsequently, we
categorize existing knowledge unlearning methods into three classes: those
based on parameter optimization, parameter merging, and in-context learning,
and introduce details of these unlearning methods. We further present
evaluation datasets used in existing methods, and finally conclude this survey
by presenting the ongoing challenges and future directions.

中文翻译:
近年来，大型语言模型（LLMs）推动了自然语言处理领域的新研究范式。尽管其在基于知识的问答与推理任务中展现出卓越能力，但模型可能保留错误甚至有害知识的特点带来了恶意应用风险。如何缓解这一问题，将模型转化为更纯净的辅助工具，对其广泛应用至关重要。然而，由于参数量庞大，通过反复重训练来消除不良知识显然不切实际。知识遗忘技术——源自机器学习遗忘领域的类似研究——为解决该问题提供了可行路径，在LLM应用场景中尤具优势。该技术能以高效方式定向移除有害知识，同时保持模型中其他无关知识的完整性。为此，本文系统梳理了LLM时代的知识遗忘研究进展：首先明确定义知识遗忘问题并厘清其与相关工作的界限；继而将现有方法划分为基于参数优化、参数融合和上下文学习的三类框架，详细阐述各类技术原理；进一步汇总当前采用的评估数据集；最后指出该领域面临的持续性挑战与未来发展方向。
