# On Zero-Shot Counterspeech Generation by LLMs

链接: http://arxiv.org/abs/2403.14938v1

原文摘要:
With the emergence of numerous Large Language Models (LLM), the usage of such
models in various Natural Language Processing (NLP) applications is increasing
extensively. Counterspeech generation is one such key task where efforts are
made to develop generative models by fine-tuning LLMs with hatespeech -
counterspeech pairs, but none of these attempts explores the intrinsic
properties of large language models in zero-shot settings. In this work, we
present a comprehensive analysis of the performances of four LLMs namely GPT-2,
DialoGPT, ChatGPT and FlanT5 in zero-shot settings for counterspeech
generation, which is the first of its kind. For GPT-2 and DialoGPT, we further
investigate the deviation in performance with respect to the sizes (small,
medium, large) of the models. On the other hand, we propose three different
prompting strategies for generating different types of counterspeech and
analyse the impact of such strategies on the performance of the models. Our
analysis shows that there is an improvement in generation quality for two
datasets (17%), however the toxicity increase (25%) with increase in model
size. Considering type of model, GPT-2 and FlanT5 models are significantly
better in terms of counterspeech quality but also have high toxicity as
compared to DialoGPT. ChatGPT are much better at generating counter speech than
other models across all metrics. In terms of prompting, we find that our
proposed strategies help in improving counter speech generation across all the
models.

中文翻译:
随着众多大型语言模型（LLM）的涌现，这类模型在各类自然语言处理（NLP）任务中的应用正迅速扩展。反制言论生成便是其中一项关键任务，研究者们尝试通过微调LLM来构建基于仇恨言论-反制言论配对数据的生成模型，但现有研究均未探索大型语言模型在零样本设置下的内在特性。本研究首次系统分析了GPT-2、DialoGPT、ChatGPT和FlanT5四种LLM在零样本环境下生成反制言论的表现：针对GPT-2和DialoGPT，我们进一步考察了模型规模（小/中/大）对性能的影响；同时提出三种提示策略以生成不同类型的反制言论，并评估策略对模型表现的影响。实验表明，两个数据集的生成质量随模型规模扩大提升17%，但毒性水平也同步增加25%。就模型类型而言，GPT-2和FlanT5在反制言论质量上显著优于DialoGPT，但毒性更高；ChatGPT在所有指标上均展现出更优的生成能力。在提示策略方面，我们提出的方法有效提升了所有模型的生成效果。
