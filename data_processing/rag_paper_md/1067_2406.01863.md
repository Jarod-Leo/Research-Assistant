# Towards Effective Time-Aware Language Representation: Exploring Enhanced Temporal Understanding in Language Models

链接: http://arxiv.org/abs/2406.01863v1

原文摘要:
In the evolving field of Natural Language Processing (NLP), understanding the
temporal context of text is increasingly critical for applications requiring
advanced temporal reasoning. Traditional pre-trained language models like BERT,
which rely on synchronic document collections such as BookCorpus and Wikipedia,
often fall short in effectively capturing and leveraging temporal information.
To address this limitation, we introduce BiTimeBERT 2.0, a novel time-aware
language model pre-trained on a temporal news article collection. BiTimeBERT
2.0 incorporates temporal information through three innovative pre-training
objectives: Extended Time-Aware Masked Language Modeling (ETAMLM), Document
Dating (DD), and Time-Sensitive Entity Replacement (TSER). Each objective is
specifically designed to target a distinct dimension of temporal information:
ETAMLM enhances the model's understanding of temporal contexts and relations,
DD integrates document timestamps as explicit chronological markers, and TSER
focuses on the temporal dynamics of "Person" entities. Moreover, our refined
corpus preprocessing strategy reduces training time by nearly 53\%, making
BiTimeBERT 2.0 significantly more efficient while maintaining high performance.
Experimental results show that BiTimeBERT 2.0 achieves substantial improvements
across a broad range of time-related tasks and excels on datasets spanning
extensive temporal ranges. These findings underscore BiTimeBERT 2.0's potential
as a powerful tool for advancing temporal reasoning in NLP.

中文翻译:
在自然语言处理（NLP）这一快速发展的领域中，理解文本的时间语境对于需要高级时序推理的应用愈发关键。传统预训练语言模型（如BERT）依赖BookCorpus和维基百科等共时性文档集，往往难以有效捕捉和利用时间信息。为突破这一局限，我们推出了BiTimeBERT 2.0——基于时序新闻文章集的新型时间感知预训练模型。该模型通过三项创新预训练目标整合时间信息：扩展时间感知掩码语言建模（ETAMLM）、文档时间标注（DD）以及时序敏感实体替换（TSER）。每个目标分别针对不同维度的时间信息：ETAMLM增强模型对时序上下文和关系的理解，DD将文档时间戳作为显式时间标记，TSER则聚焦"人物"实体的时序动态特征。此外，我们优化的语料预处理策略使训练时间缩短近53%，在保持高性能的同时显著提升效率。实验表明，BiTimeBERT 2.0在各类时间相关任务中均取得显著提升，尤其在跨越长期时间范围的数据集上表现优异。这些发现印证了BiTimeBERT 2.0作为推进NLP时序推理研究的强效工具的潜力。
