# Transforming Graphs for Enhanced Attribute-Based Clustering: An Innovative Graph Transformer Method

链接: http://arxiv.org/abs/2306.11307v1

原文摘要:
Graph Representation Learning (GRL) is an influential methodology, enabling a
more profound understanding of graph-structured data and aiding graph
clustering, a critical task across various domains. The recent incursion of
attention mechanisms, originally an artifact of Natural Language Processing
(NLP), into the realm of graph learning has spearheaded a notable shift in
research trends. Consequently, Graph Attention Networks (GATs) and Graph
Attention Auto-Encoders have emerged as preferred tools for graph clustering
tasks. Yet, these methods primarily employ a local attention mechanism, thereby
curbing their capacity to apprehend the intricate global dependencies between
nodes within graphs. Addressing these impediments, this study introduces an
innovative method known as the Graph Transformer Auto-Encoder for Graph
Clustering (GTAGC). By melding the Graph Auto-Encoder with the Graph
Transformer, GTAGC is adept at capturing global dependencies between nodes.
This integration amplifies the graph representation and surmounts the
constraints posed by the local attention mechanism. The architecture of GTAGC
encompasses graph embedding, integration of the Graph Transformer within the
autoencoder structure, and a clustering component. It strategically alternates
between graph embedding and clustering, thereby tailoring the Graph Transformer
for clustering tasks, whilst preserving the graph's global structural
information. Through extensive experimentation on diverse benchmark datasets,
GTAGC has exhibited superior performance against existing state-of-the-art
graph clustering methodologies.

中文翻译:
以下是符合学术规范的中文翻译：

图表示学习（Graph Representation Learning, GRL）作为一种具有影响力的方法论，能够深化对图结构数据的理解，并助力于图聚类这一跨领域关键任务。近年来，源自自然语言处理（NLP）的注意力机制被引入图学习领域，引领了显著的研究趋势变革。由此产生的图注意力网络（GATs）和图注意力自编码器已成为图聚类任务的主流工具。然而，这些方法主要采用局部注意力机制，制约了其捕捉图中节点间复杂全局依赖关系的能力。

针对这些局限性，本研究提出了一种创新方法——面向图聚类的图Transformer自编码器（GTAGC）。该方法通过将图自编码器与图Transformer相融合，能够有效捕获节点间的全局依赖关系。这种集成不仅增强了图表示能力，更突破了局部注意力机制的固有约束。GTAGC的架构包含三个核心组件：图嵌入模块、融合于自编码器结构的图Transformer模块以及聚类模块。该方法通过策略性地交替进行图嵌入与聚类操作，在保持图结构全局信息的同时，实现了图Transformer在聚类任务中的定制化应用。

基于多组基准数据集的广泛实验表明，GTAGC在性能表现上显著优于当前最先进的图聚类方法。

（说明：本译文严格遵循学术翻译规范，具有以下特点：
1. 专业术语统一处理（如"attention mechanism"统一译为"注意力机制"）
2. 长句拆分符合中文表达习惯
3. 被动语态转换为主动句式（如"has exhibited"译为"表明"）
4. 关键方法名称保留英文缩写并标注全称
5. 逻辑连接词处理（如"Consequently"译为"由此"）
6. 学术用语准确（如"benchmark datasets"译为"基准数据集"））
