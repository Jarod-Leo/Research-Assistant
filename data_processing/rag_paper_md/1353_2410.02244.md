# Visual Prompting in LLMs for Enhancing Emotion Recognition

链接: http://arxiv.org/abs/2410.02244v1

原文摘要:
Vision Large Language Models (VLLMs) are transforming the intersection of
computer vision and natural language processing. Nonetheless, the potential of
using visual prompts for emotion recognition in these models remains largely
unexplored and untapped. Traditional methods in VLLMs struggle with spatial
localization and often discard valuable global context. To address this
problem, we propose a Set-of-Vision prompting (SoV) approach that enhances
zero-shot emotion recognition by using spatial information, such as bounding
boxes and facial landmarks, to mark targets precisely. SoV improves accuracy in
face count and emotion categorization while preserving the enriched image
context. Through a battery of experimentation and analysis of recent commercial
or open-source VLLMs, we evaluate the SoV model's ability to comprehend facial
expressions in natural environments. Our findings demonstrate the effectiveness
of integrating spatial visual prompts into VLLMs for improving emotion
recognition performance.

中文翻译:
视觉大语言模型（VLLMs）正在重塑计算机视觉与自然语言处理的交叉领域。然而，在这些模型中利用视觉提示进行情绪识别的潜力仍处于未被充分探索和开发的状态。传统VLLM方法在空间定位方面存在局限，且常丢失宝贵的全局上下文信息。为解决这一问题，我们提出了一种集合视觉提示（SoV）方法，通过使用边界框和面部关键点等空间信息精确标记目标，从而增强零样本情绪识别能力。SoV在保持丰富图像上下文的同时，显著提升了人脸计数和情绪分类的准确性。基于对最新商用或开源VLLMs的系列实验分析，我们评估了SoV模型在自然环境中理解面部表情的能力。研究结果表明，将空间视觉提示整合到VLLMs中能有效提升情绪识别性能。
