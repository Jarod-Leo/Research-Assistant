# Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages

链接: http://arxiv.org/abs/2411.04025v1

原文摘要:
Language Identification (LI) is crucial for various natural language
processing tasks, serving as a foundational step in applications such as
sentiment analysis, machine translation, and information retrieval. In
multilingual societies like India, particularly among the youth engaging on
social media, text often exhibits code-mixing, blending local languages with
English at different linguistic levels. This phenomenon presents formidable
challenges for LI systems, especially when languages intermingle within single
words. Dravidian languages, prevalent in southern India, possess rich
morphological structures yet suffer from under-representation in digital
platforms, leading to the adoption of Roman or hybrid scripts for
communication. This paper introduces a prompt based method for a shared task
aimed at addressing word-level LI challenges in Dravidian languages. In this
work, we leveraged GPT-3.5 Turbo to understand whether the large language
models is able to correctly classify words into correct categories. Our
findings show that the Kannada model consistently outperformed the Tamil model
across most metrics, indicating a higher accuracy and reliability in
identifying and categorizing Kannada language instances. In contrast, the Tamil
model showed moderate performance, particularly needing improvement in
precision and recall.

中文翻译:
语言识别（LI）是诸多自然语言处理任务的关键基础环节，在情感分析、机器翻译和信息检索等应用中具有重要作用。在印度等多语言社会环境中，尤其是活跃于社交媒体的年轻群体，文本常呈现语码混合现象——当地语言与英语在不同语言层级上相互交融。这一现象为语言识别系统带来了严峻挑战，特别是当不同语言在单词层面发生混合时。德拉维达语系作为印度南部主要语言，虽拥有丰富的形态结构，却在数字平台中面临表征不足的问题，导致人们常采用罗马字母或混合文字进行交流。本文针对德拉维达语系单词级语言识别任务，提出了一种基于提示词的方法。本研究通过GPT-3.5 Turbo模型探究大语言模型对单词分类的准确性，实验结果表明：在多数评估指标中，卡纳达语模型表现持续优于泰米尔语模型，显示出更高的识别准确率和分类可靠性；而泰米尔语模型仅达到中等性能水平，尤其在精确率和召回率指标上亟待提升。
