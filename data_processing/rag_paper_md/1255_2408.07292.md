# LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models

链接: http://arxiv.org/abs/2408.07292v1

原文摘要:
Language models have achieved remarkable success in various natural language
processing tasks. However, their application to time series data, a crucial
component in many domains, remains limited. This paper proposes LiPCoT (Linear
Predictive Coding based Tokenizer for time series), a novel tokenizer that
encodes time series data into a sequence of tokens, enabling self-supervised
learning of time series using existing Language model architectures such as
BERT. Unlike traditional time series tokenizers that rely heavily on CNN
encoder for time series feature generation, LiPCoT employs stochastic modeling
through linear predictive coding to create a latent space for time series
providing a compact yet rich representation of the inherent stochastic nature
of the data. Furthermore, LiPCoT is computationally efficient and can
effectively handle time series data with varying sampling rates and lengths,
overcoming common limitations of existing time series tokenizers. In this
proof-of-concept work, we present the effectiveness of LiPCoT in classifying
Parkinson's disease (PD) using an EEG dataset from 46 participants. In
particular, we utilize LiPCoT to encode EEG data into a small vocabulary of
tokens and then use BERT for self-supervised learning and the downstream task
of PD classification. We benchmark our approach against several
state-of-the-art CNN-based deep learning architectures for PD detection. Our
results reveal that BERT models utilizing self-supervised learning outperformed
the best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%
in accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for
self-supervised learning even on small datasets. Our work will inform future
foundational models for time series, particularly for self-supervised learning.

中文翻译:
语言模型在各类自然语言处理任务中取得了显著成就，然而其在时间序列数据这一关键领域的应用仍存在局限。本文提出LiPCoT（基于线性预测编码的时间序列标记器），这是一种创新性标记器，能将时间序列数据编码为符号序列，从而利用BERT等现有语言模型架构实现时间序列的自监督学习。与传统时间序列标记器严重依赖CNN编码器生成特征不同，LiPCoT通过线性预测编码进行随机建模，构建出能紧凑且丰富表征数据内在随机特性的潜在空间。该标记器具有计算高效性，可有效处理不同采样率和长度的时序数据，克服了现有方法的常见缺陷。在本概念验证工作中，我们使用46名参与者的脑电图数据集验证了LiPCoT在帕金森病分类中的有效性：先将脑电数据编码为小规模符号表，再通过BERT进行自监督学习及下游分类任务。与当前最先进的基于CNN的帕金森检测架构相比，采用自监督学习的BERT模型在精确率（提升7.1%）、召回率（提升2.3%）、准确率（提升5.5%）、AUC值（提升4%）和F1分数（提升5%）上全面超越现有最佳方法，证明了小数据集上自监督学习的巨大潜力。本研究将为未来时间序列基础模型，特别是自监督学习方向的发展提供重要参考。
