# ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity

链接: http://arxiv.org/abs/2404.12010v1

原文摘要:
Paraphrase generation is a pivotal task in natural language processing (NLP).
Existing datasets in the domain lack syntactic and lexical diversity, resulting
in paraphrases that closely resemble the source sentences. Moreover, these
datasets often contain hate speech and noise, and may unintentionally include
non-English language sentences. This research introduces ParaFusion, a
large-scale, high-quality English paraphrase dataset developed using Large
Language Models (LLM) to address these challenges. ParaFusion augments existing
datasets with high-quality data, significantly enhancing both lexical and
syntactic diversity while maintaining close semantic similarity. It also
mitigates the presence of hate speech and reduces noise, ensuring a cleaner and
more focused English dataset. Results show that ParaFusion offers at least a
25% improvement in both syntactic and lexical diversity, measured across
several metrics for each data source. The paper also aims to set a gold
standard for paraphrase evaluation as it contains one of the most comprehensive
evaluation strategies to date. The results underscore the potential of
ParaFusion as a valuable resource for improving NLP applications.

中文翻译:
复述生成是自然语言处理（NLP）中的关键任务。当前该领域的数据集在句法和词汇多样性方面存在不足，导致生成的复述与源句高度相似。此外，这些数据集常包含仇恨言论和噪声，并可能无意混入非英语句子。本研究推出ParaFusion——一个利用大语言模型（LLM）构建的大规模高质量英语复述数据集，以解决上述问题。ParaFusion通过补充高质量数据，在保持紧密语义相似性的同时，显著提升了词汇和句法多样性。该数据集有效减少了仇恨言论和噪声干扰，确保了更纯净、更专注的英语语料。测试结果表明，针对各数据源的多种评估指标，ParaFusion在句法和词汇多样性上均实现了至少25%的提升。本文还致力于建立复述评估的黄金标准，提出了迄今为止最全面的评估策略之一。研究成果印证了ParaFusion作为提升NLP应用价值的优质资源潜力。
