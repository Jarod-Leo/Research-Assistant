# Inverse Dynamics Pretraining Learns Good Representations for Multitask Imitation

链接: http://arxiv.org/abs/2305.16985v1

原文摘要:
In recent years, domains such as natural language processing and image
recognition have popularized the paradigm of using large datasets to pretrain
representations that can be effectively transferred to downstream tasks. In
this work we evaluate how such a paradigm should be done in imitation learning,
where both pretraining and finetuning data are trajectories collected by
experts interacting with an unknown environment. Namely, we consider a setting
where the pretraining corpus consists of multitask demonstrations and the task
for each demonstration is set by an unobserved latent context variable. The
goal is to use the pretraining corpus to learn a low dimensional representation
of the high dimensional (e.g., visual) observation space which can be
transferred to a novel context for finetuning on a limited dataset of
demonstrations. Among a variety of possible pretraining objectives, we argue
that inverse dynamics modeling -- i.e., predicting an action given the
observations appearing before and after it in the demonstration -- is
well-suited to this setting. We provide empirical evidence of this claim
through evaluations on a variety of simulated visuomotor manipulation problems.
While previous work has attempted various theoretical explanations regarding
the benefit of inverse dynamics modeling, we find that these arguments are
insufficient to explain the empirical advantages often observed in our
settings, and so we derive a novel analysis using a simple but general
environment model.

中文翻译:
近年来，自然语言处理和图像识别等领域普遍采用了一种范式：利用大规模数据集预训练表征模型，并将其高效迁移至下游任务。本研究探讨了模仿学习领域应如何实施这一范式——在该场景中，预训练与微调数据均为专家与未知环境交互产生的轨迹数据。具体而言，我们设定预训练语料由多任务演示组成，每个演示任务由未观测的潜在上下文变量决定。研究目标是通过预训练语料学习高维（如视觉）观测空间的低维表征，该表征可迁移至新上下文环境，并在有限演示数据集上进行微调。

在多种可能的预训练目标中，我们提出逆向动力学建模（即根据演示中动作前后出现的观测数据预测该动作）特别适合此场景。通过多种仿真视觉运动操控任务的评估，我们为此论断提供了实证依据。尽管先前研究尝试从理论层面解释逆向动力学建模的优势，但我们发现这些解释不足以完全说明本研究中观察到的实证优势。因此，我们基于简单但普适的环境模型，提出了新的理论分析框架。
