# Self-Correction Makes LLMs Better Parsers

链接: http://arxiv.org/abs/2504.14165v1

原文摘要:
Large language models (LLMs) have achieved remarkable success across various
natural language processing (NLP) tasks. However, recent studies suggest that
they still face challenges in performing fundamental NLP tasks essential for
deep language understanding, particularly syntactic parsing. In this paper, we
conduct an in-depth analysis of LLM parsing capabilities, delving into the
specific shortcomings of their parsing results. We find that LLMs may stem from
limitations to fully leverage grammar rules in existing treebanks, which
restricts their capability to generate valid syntactic structures. To help LLMs
acquire knowledge without additional training, we propose a self-correction
method that leverages grammar rules from existing treebanks to guide LLMs in
correcting previous errors. Specifically, we automatically detect potential
errors and dynamically search for relevant rules, offering hints and examples
to guide LLMs in making corrections themselves. Experimental results on three
datasets with various LLMs, demonstrate that our method significantly improves
performance in both in-domain and cross-domain settings on the English and
Chinese datasets.

中文翻译:
大型语言模型（LLMs）在各类自然语言处理（NLP）任务中取得了显著成就。然而最新研究表明，其在实现深度语言理解所需的基础NLP任务——尤其是句法解析方面仍存在挑战。本文通过深入分析LLMs的解析能力，系统剖析其输出结果的具体缺陷，发现模型可能受限于无法充分利用现有树库中的语法规则，导致生成有效句法结构的能力受限。为帮助LLMs在不额外训练的情况下获取知识，我们提出一种自我校正方法，利用现有树库的语法规则引导模型修正错误。具体而言，该方法自动检测潜在错误并动态检索相关规则，通过提供提示和示例指导LLMs自主完成修正。在涵盖英语和汉语的三个数据集上，多种LLMs的实验结果表明，该方法在领域内和跨领域场景下均能显著提升解析性能。
