# LLM-Empowered IoT for 6G Networks: Architecture, Challenges, and Solutions

链接: http://arxiv.org/abs/2503.13819v1

原文摘要:
The Internet of Things (IoT) in the sixth generation (6G) era is envisioned
to evolve towards intelligence, ubiquity, and self-optimization. Large language
models (LLMs) have demonstrated remarkable generalization capabilities across
diverse domains, including natural language processing (NLP), computer vision
(CV), and beyond. In this article, we propose an LLM-empowered IoT architecture
for 6G networks to achieve intelligent autonomy while supporting advanced IoT
applications. LLMs are pushed to the edge of the 6G network to support the
synergy of LLMs and IoT. LLM solutions are tailored to both IoT application
requirements and IoT management needs, i.e., LLM for IoT. On the other hand,
edge inference and edge fine-tuning are discussed to support the deployment of
LLMs, i.e., LLM on IoT. Furthermore, we propose a memory-efficient split
federated learning (SFL) framework for LLM fine-tuning on heterogeneous IoT
devices that alleviates memory pressures on both IoT devices and the edge
server while achieving comparable performance and convergence time. Finally, a
case study is presented, followed by a discussion about open issues of
LLM-empowered IoT for 6G networks.

中文翻译:
第六代移动通信（6G）时代的物联网（IoT）正朝着智能化、泛在化与自优化的方向演进。大型语言模型（LLM）已在自然语言处理（NLP）、计算机视觉（CV）等多个领域展现出卓越的泛化能力。本文提出一种面向6G网络的LLM赋能物联网架构，在支持高级物联网应用的同时实现智能自治。通过将LLM部署至6G网络边缘，促进LLM与物联网的协同发展：一方面针对物联网应用需求与管理需求定制LLM解决方案（LLM for IoT），另一方面探讨支持LLM部署的边缘推理与微调技术（LLM on IoT）。进一步提出基于内存优化的分割联邦学习（SFL）框架，实现在异构物联网设备上进行LLM微调，既缓解终端设备与边缘服务器的内存压力，又保持与集中式训练相当的模型性能与收敛速度。最后通过案例研究，探讨6G网络中LLM赋能物联网面临的开放性问题。
