# Can Transformers Learn Optimal Filtering for Unknown Systems?

链接: http://arxiv.org/abs/2308.08536v1

原文摘要:
Transformer models have shown great success in natural language processing;
however, their potential remains mostly unexplored for dynamical systems. In
this work, we investigate the optimal output estimation problem using
transformers, which generate output predictions using all the past ones.
Particularly, we train the transformer using various distinct systems and then
evaluate the performance on unseen systems with unknown dynamics. Empirically,
the trained transformer adapts exceedingly well to different unseen systems and
even matches the optimal performance given by the Kalman filter for linear
systems. In more complex settings with non-i.i.d. noise, time-varying dynamics,
and nonlinear dynamics like a quadrotor system with unknown parameters,
transformers also demonstrate promising results. To support our experimental
findings, we provide statistical guarantees that quantify the amount of
training data required for the transformer to achieve a desired excess risk.
Finally, we point out some limitations by identifying two classes of problems
that lead to degraded performance, highlighting the need for caution when using
transformers for control and estimation.

中文翻译:
Transformer模型在自然语言处理领域已展现出卓越成效，但其在动态系统中的应用潜力仍鲜有探索。本研究聚焦于利用Transformer解决最优输出估计问题，该模型通过整合所有历史输出来生成预测。具体而言，我们采用多种不同系统训练Transformer，随后在动态特性未知的新系统上评估其性能。实证表明，经过训练的Transformer能出色适应各类未知系统，甚至在线性系统中达到了与卡尔曼滤波器相当的最优性能。在面对非独立同分布噪声、时变动态特性以及含未知参数的四旋翼系统等非线性复杂场景时，Transformer同样展现出令人瞩目的表现。为支撑实验发现，我们提供了统计理论保证，量化了Transformer达到预期超额风险所需的训练数据量。最后，通过识别两类导致性能下降的问题，我们指出了当前方法的局限性，强调在控制与估计领域应用Transformer时需保持审慎态度。
