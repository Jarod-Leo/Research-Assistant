# LlamaRestTest: Effective REST API Testing with Small Language Models

链接: http://arxiv.org/abs/2501.08598v1

原文摘要:
Modern web services rely heavily on REST APIs, typically documented using the
OpenAPI specification. The widespread adoption of this standard has resulted in
the development of many black-box testing tools that generate tests based on
OpenAPI specifications. Although Large Language Models (LLMs) have shown
promising test-generation abilities, their application to REST API testing
remains mostly unexplored. We present LlamaRestTest, a novel approach that
employs two custom LLMs-created by fine-tuning and quantizing the Llama3-8B
model using mined datasets of REST API example values and inter-parameter
dependencies-to generate realistic test inputs and uncover inter-parameter
dependencies during the testing process by analyzing server responses. We
evaluated LlamaRestTest on 12 real-world services (including popular services
such as Spotify), comparing it against RESTGPT, a GPT-powered
specification-enhancement tool, as well as several state-of-the-art REST API
testing tools, including RESTler, MoRest, EvoMaster, and ARAT-RL. Our results
demonstrate that fine-tuning enables smaller models to outperform much larger
models in detecting actionable parameter-dependency rules and generating valid
inputs for REST API testing. We also evaluated different tool configurations,
ranging from the base Llama3-8B model to fine-tuned versions, and explored
multiple quantization techniques, including 2-bit, 4-bit, and 8-bit integer
formats. Our study shows that small language models can perform as well as, or
better than, large language models in REST API testing, balancing effectiveness
and efficiency. Furthermore, LlamaRestTest outperforms state-of-the-art REST
API testing tools in code coverage achieved and internal server errors
identified, even when those tools use RESTGPT-enhanced specifications.

中文翻译:
现代网络服务高度依赖REST API，这类接口通常采用OpenAPI规范进行描述。该标准的广泛普及催生了众多基于OpenAPI规范生成测试用例的黑盒测试工具。尽管大语言模型（LLM）已展现出卓越的测试生成能力，但其在REST API测试领域的应用仍属空白。我们提出LlamaRestTest创新方案，通过微调量化Llama3-8B模型构建两个定制化LLM——利用挖掘的REST API示例值数据集和参数间依赖关系——在测试过程中生成逼真的测试输入，并通过分析服务器响应揭示参数间依赖关系。我们在12个真实服务（含Spotify等流行平台）上评估该工具，对比对象包括GPT驱动的规范增强工具RESTGPT，以及RESTler、MoRest、EvoMaster、ARAT-RL等前沿REST API测试工具。实验表明：微调后的小模型在检测可操作的参数依赖规则、生成有效测试输入方面能超越大模型。我们还评估了从基础Llama3-8B到微调版本的不同配置，探索了2位、4位、8位整数量化技术。研究表明：小语言模型在REST API测试中可达到甚至超越大模型的效果，实现效能与效率的平衡。值得注意的是，即便其他工具使用经RESTGPT增强的规范，LlamaRestTest在代码覆盖率和内部服务器错误识别方面仍优于现有最优测试工具。
