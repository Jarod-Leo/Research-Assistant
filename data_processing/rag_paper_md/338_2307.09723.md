# Improving Domain Generalization for Sound Classification with Sparse Frequency-Regularized Transformer

链接: http://arxiv.org/abs/2307.09723v1

原文摘要:
Sound classification models' performance suffers from generalizing on
out-of-distribution (OOD) data. Numerous methods have been proposed to help the
model generalize. However, most either introduce inference overheads or focus
on long-lasting CNN-variants, while Transformers has been proven to outperform
CNNs on numerous natural language processing and computer vision tasks. We
propose FRITO, an effective regularization technique on Transformer's
self-attention, to improve the model's generalization ability by limiting each
sequence position's attention receptive field along the frequency dimension on
the spectrogram. Experiments show that our method helps Transformer models
achieve SOTA generalization performance on TAU 2020 and Nsynth datasets while
saving 20% inference time.

中文翻译:
声音分类模型在分布外（OOD）数据上的泛化性能往往欠佳。尽管已有诸多方法被提出以提升模型泛化能力，但多数方案要么引入推理开销，要么仅针对长期主导的CNN变体进行优化。而Transformer架构已在多项自然语言处理和计算机视觉任务中被证明优于CNN。本文提出FRITO——一种针对Transformer自注意力机制的有效正则化技术，通过限制频谱图上各序列位置沿频率维度的注意力感受野，显著提升模型泛化能力。实验表明，该方法使Transformer模型在TAU 2020和Nsynth数据集上取得最先进的泛化性能，同时节省20%的推理时间。
