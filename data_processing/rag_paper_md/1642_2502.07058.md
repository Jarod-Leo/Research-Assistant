# Using Contextually Aligned Online Reviews to Measure LLMs' Performance Disparities Across Language Varieties

链接: http://arxiv.org/abs/2502.07058v1

原文摘要:
A language can have different varieties. These varieties can affect the
performance of natural language processing (NLP) models, including large
language models (LLMs), which are often trained on data from widely spoken
varieties. This paper introduces a novel and cost-effective approach to
benchmark model performance across language varieties. We argue that
international online review platforms, such as Booking.com, can serve as
effective data sources for constructing datasets that capture comments in
different language varieties from similar real-world scenarios, like reviews
for the same hotel with the same rating using the same language (e.g., Mandarin
Chinese) but different language varieties (e.g., Taiwan Mandarin, Mainland
Mandarin). To prove this concept, we constructed a contextually aligned dataset
comprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs
in a sentiment analysis task. Our results show that LLMs consistently
underperform in Taiwan Mandarin.

中文翻译:
一种语言可能存在多种变体，这些变体会影响自然语言处理（NLP）模型的性能——包括通常基于主流语言变体数据训练的大语言模型（LLMs）。本文提出了一种新颖且经济高效的方法，用于评估模型在不同语言变体上的表现。我们论证了国际在线评论平台（如Booking.com）可作为有效的数据来源，通过构建数据集来捕捉相似现实场景下不同语言变体的评论（例如对同一酒店、相同评分、使用同一语言但不同变体的评论，如台湾普通话与大陆普通话）。为验证这一构想，我们构建了语境对齐的数据集，包含台湾普通话和大陆普通话的酒店评论，并对六种大语言模型进行了情感分析测试。结果表明，所有模型在台湾普通话文本上的表现均持续逊色于大陆普通话。
