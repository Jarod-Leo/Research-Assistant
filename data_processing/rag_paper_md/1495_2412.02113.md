# Trust & Safety of LLMs and LLMs in Trust & Safety

链接: http://arxiv.org/abs/2412.02113v1

原文摘要:
In recent years, Large Language Models (LLMs) have garnered considerable
attention for their remarkable abilities in natural language processing tasks.
However, their widespread adoption has raised concerns pertaining to trust and
safety. This systematic review investigates the current research landscape on
trust and safety in LLMs, with a particular focus on the novel application of
LLMs within the field of Trust and Safety itself. We delve into the
complexities of utilizing LLMs in domains where maintaining trust and safety is
paramount, offering a consolidated perspective on this emerging trend.\
  By synthesizing findings from various studies, we identify key challenges and
potential solutions, aiming to benefit researchers and practitioners seeking to
understand the nuanced interplay between LLMs and Trust and Safety.
  This review provides insights on best practices for using LLMs in Trust and
Safety, and explores emerging risks such as prompt injection and jailbreak
attacks. Ultimately, this study contributes to a deeper understanding of how
LLMs can be effectively and responsibly utilized to enhance trust and safety in
the digital realm.

中文翻译:
近年来，大型语言模型（LLMs）因其在自然语言处理任务中的卓越表现而备受关注。然而，其广泛应用也引发了关于信任与安全的隐忧。本文通过系统性综述，深入探究LLMs在信任与安全领域的研究现状，尤其聚焦于该模型在"信任与安全"学科中的创新应用。我们剖析了在信任安全至关重要的场景下部署LLMs的复杂性，为这一新兴趋势提供整合性视角。

通过综合多项研究成果，我们梳理出核心挑战与潜在解决方案，旨在帮助研究者和从业者理解LLMs与信任安全之间微妙的互动关系。本综述不仅提出LLMs在信任安全领域的最佳实践指南，还揭示了即时注入攻击、越狱攻击等新兴风险。最终，本研究为推动LLMs在数字领域实现负责任的有效应用，从而提升信任与安全水平提供了深度洞见。
