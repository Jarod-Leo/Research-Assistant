# Impact of Position Bias on Language Models in Token Classification

链接: http://arxiv.org/abs/2304.13567v1

原文摘要:
Language Models (LMs) have shown state-of-the-art performance in Natural
Language Processing (NLP) tasks. Downstream tasks such as Named Entity
Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data
imbalance issues, particularly regarding the ratio of positive to negative
examples and class disparities. This paper investigates an often-overlooked
issue of encoder models, specifically the position bias of positive examples in
token classification tasks. For completeness, we also include decoders in the
evaluation. We evaluate the impact of position bias using different position
embedding techniques, focusing on BERT with Absolute Position Embedding (APE),
Relative Position Embedding (RPE), and Rotary Position Embedding (RoPE).
Therefore, we conduct an in-depth evaluation of the impact of position bias on
the performance of LMs when fine-tuned on token classification benchmarks. Our
study includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD\_en, and
TweeBank for POS tagging. We propose an evaluation approach to investigate
position bias in transformer models. We show that LMs can suffer from this bias
with an average drop ranging from 3\% to 9\% in their performance. To mitigate
this effect, we propose two methods: Random Position Shifting and Context
Perturbation, that we apply on batches during the training process. The results
show an improvement of $\approx$ 2\% in the performance of the model on
CoNLL03, UD\_en, and TweeBank.

中文翻译:
语言模型（Language Models, LMs）在自然语言处理（NLP）任务中展现出最先进的性能。然而，诸如命名实体识别（NER）或词性标注（POS）等下游任务普遍面临数据不平衡问题，尤其是正负样本比例及类别差异。本文聚焦于编码器模型中一个常被忽视的问题——在标记分类任务中正样本的位置偏差现象，同时为全面性也将解码器纳入评估范围。通过对比绝对位置嵌入（APE）、相对位置嵌入（RPE）和旋转位置嵌入（RoPE）三种技术，我们系统评估了BERT模型中位置偏差的影响。研究基于多个基准数据集展开深入分析：CoNLL03和OntoNote5.0用于NER任务，English Tree Bank UD_en与TweeBank用于POS标注任务。

我们提出了一种评估Transformer模型位置偏差的新方法，实验表明该偏差会导致语言模型性能平均下降3%至9%。为缓解此问题，本文创新性地提出两种训练阶段的批处理方法：随机位置偏移（Random Position Shifting）和上下文扰动（Context Perturbation）。在CoNLL03、UD_en和TweeBank数据集上的实验证明，这些方法能使模型性能提升约2%。
