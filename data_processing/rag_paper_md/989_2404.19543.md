# RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing

链接: http://arxiv.org/abs/2404.19543v1

原文摘要:
Large Language Models (LLMs) have catalyzed significant advancements in
Natural Language Processing (NLP), yet they encounter challenges such as
hallucination and the need for domain-specific knowledge. To mitigate these,
recent methodologies have integrated information retrieved from external
resources with LLMs, substantially enhancing their performance across NLP
tasks. This survey paper addresses the absence of a comprehensive overview on
Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented
Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an
in-depth examination of their paradigm, evolution, taxonomy, and applications.
The paper discusses the essential components of RALMs, including Retrievers,
Language Models, and Augmentations, and how their interactions lead to diverse
model structures and applications. RALMs demonstrate utility in a spectrum of
tasks, from translation and dialogue systems to knowledge-intensive
applications. The survey includes several evaluation methods of RALMs,
emphasizing the importance of robustness, accuracy, and relevance in their
assessment. It also acknowledges the limitations of RALMs, particularly in
retrieval quality and computational efficiency, offering directions for future
research. In conclusion, this survey aims to offer a structured insight into
RALMs, their potential, and the avenues for their future development in NLP.
The paper is supplemented with a Github Repository containing the surveyed
works and resources for further study:
https://github.com/2471023025/RALM_Survey.

中文翻译:
以下是符合学术规范的中文翻译：

大语言模型（LLMs）在自然语言处理（NLP）领域推动了重大进展，但仍面临幻觉生成和领域知识缺失等挑战。为缓解这些问题，近期研究通过将外部资源检索信息与大语言模型相融合，显著提升了各类NLP任务的性能。本综述论文针对检索增强语言模型（RALMs）——包括检索增强生成（RAG）与检索增强理解（RAU）——缺乏系统性综述的现状，深入剖析了其范式演变、分类体系及应用场景。论文阐释了RALMs的核心组件（检索器、语言模型和增强模块）及其交互机制如何衍生出多样化的模型结构与应用场景。研究表明，RALMs在机器翻译、对话系统乃至知识密集型应用等任务中均展现出卓越效用。本文系统梳理了RALMs的多种评估方法，强调鲁棒性、准确性和相关性在模型评估中的核心地位，同时指出当前在检索质量与计算效率方面的局限性，为未来研究指明方向。最后，本研究旨在为RALMs提供结构化认知框架，揭示其在NLP领域的发展潜力与演进路径。论文附带的GitHub资源库包含所有综述文献及相关研究资料：https://github.com/2471023025/RALM_Survey。

（翻译说明：1. 专业术语采用学界通用译法；2. 长句按中文习惯切分重组；3. 被动语态转换为主动表述；4. 关键概念首次出现标注英文缩写；5. 保留原文严谨客观的学术风格；6. 技术表述准确性与语言流畅性并重）
