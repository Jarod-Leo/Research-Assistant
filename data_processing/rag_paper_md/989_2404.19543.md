# RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing

链接: http://arxiv.org/abs/2404.19543v1

原文摘要:
Large Language Models (LLMs) have catalyzed significant advancements in
Natural Language Processing (NLP), yet they encounter challenges such as
hallucination and the need for domain-specific knowledge. To mitigate these,
recent methodologies have integrated information retrieved from external
resources with LLMs, substantially enhancing their performance across NLP
tasks. This survey paper addresses the absence of a comprehensive overview on
Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented
Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an
in-depth examination of their paradigm, evolution, taxonomy, and applications.
The paper discusses the essential components of RALMs, including Retrievers,
Language Models, and Augmentations, and how their interactions lead to diverse
model structures and applications. RALMs demonstrate utility in a spectrum of
tasks, from translation and dialogue systems to knowledge-intensive
applications. The survey includes several evaluation methods of RALMs,
emphasizing the importance of robustness, accuracy, and relevance in their
assessment. It also acknowledges the limitations of RALMs, particularly in
retrieval quality and computational efficiency, offering directions for future
research. In conclusion, this survey aims to offer a structured insight into
RALMs, their potential, and the avenues for their future development in NLP.
The paper is supplemented with a Github Repository containing the surveyed
works and resources for further study:
https://github.com/2471023025/RALM_Survey.

中文翻译:
大语言模型（LLMs）在自然语言处理（NLP）领域推动了重大进展，但仍面临幻觉问题和领域知识需求等挑战。为应对这些挑战，近期研究方法将外部资源检索信息与LLMs相结合，显著提升了各类NLP任务的性能。本综述论文针对检索增强语言模型（RALMs）——包括检索增强生成（RAG）和检索增强理解（RAU）——缺乏系统性概述的现状，深入剖析了其范式、演进历程、分类体系及应用场景。文章阐述了RALMs的核心组件（检索器、语言模型和增强模块）及其交互方式如何形成多样化模型结构与应用，展示了其在翻译、对话系统乃至知识密集型任务中的广泛适用性。研究还囊括了多种RALMs评估方法，强调鲁棒性、准确性和相关性在评估中的重要性，同时指出当前在检索质量和计算效率等方面的局限性，为未来研究方向提供指引。本文最终旨在为RALMs提供结构化认知框架，揭示其发展潜力及NLP领域的未来路径，并附含GitHub资源库（https://github.com/2471023025/RALM_Survey）收录相关研究文献以供深入探究。
