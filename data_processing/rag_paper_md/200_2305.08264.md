# MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling

链接: http://arxiv.org/abs/2305.08264v1

原文摘要:
We present MatSci-NLP, a natural language benchmark for evaluating the
performance of natural language processing (NLP) models on materials science
text. We construct the benchmark from publicly available materials science text
data to encompass seven different NLP tasks, including conventional NLP tasks
like named entity recognition and relation classification, as well as NLP tasks
specific to materials science, such as synthesis action retrieval which relates
to creating synthesis procedures for materials. We study various BERT-based
models pretrained on different scientific text corpora on MatSci-NLP to
understand the impact of pretraining strategies on understanding materials
science text. Given the scarcity of high-quality annotated data in the
materials science domain, we perform our fine-tuning experiments with limited
training data to encourage the generalize across MatSci-NLP tasks. Our
experiments in this low-resource training setting show that language models
pretrained on scientific text outperform BERT trained on general text. MatBERT,
a model pretrained specifically on materials science journals, generally
performs best for most tasks. Moreover, we propose a unified text-to-schema for
multitask learning on \benchmark and compare its performance with traditional
fine-tuning methods. In our analysis of different training methods, we find
that our proposed text-to-schema methods inspired by question-answering
consistently outperform single and multitask NLP fine-tuning methods. The code
and datasets are publicly available at
\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}.

中文翻译:
我们推出MatSci-NLP——一个用于评估自然语言处理（NLP）模型在材料科学文本上性能的基准测试平台。该基准基于公开可获取的材料科学文本数据构建，涵盖七种不同的NLP任务，既包含命名实体识别、关系分类等常规NLP任务，也包含材料科学特有的任务（如与材料合成流程相关的合成操作检索）。我们通过研究在各类科学文本语料库上预训练的基于BERT的模型在MatSci-NLP上的表现，探究预训练策略对理解材料科学文本的影响。鉴于材料科学领域高质量标注数据的稀缺性，我们在有限训练数据条件下进行微调实验，以促进模型在MatSci-NLP任务间的泛化能力。在低资源训练环境下的实验表明，基于科学文本预训练的语言模型显著优于通用文本训练的BERT模型。其中，专门针对材料科学期刊预训练的MatBERT模型在多数任务中表现最佳。此外，我们提出了一种面向多任务学习的统一文本-模式转换框架，并与传统微调方法进行性能对比。通过分析不同训练方法发现，受问答系统启发的文本-模式转换方法始终优于单任务及多任务NLP微调方法。相关代码与数据集已开源：\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}。
