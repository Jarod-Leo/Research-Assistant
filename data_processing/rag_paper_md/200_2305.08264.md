# MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling

链接: http://arxiv.org/abs/2305.08264v1

原文摘要:
We present MatSci-NLP, a natural language benchmark for evaluating the
performance of natural language processing (NLP) models on materials science
text. We construct the benchmark from publicly available materials science text
data to encompass seven different NLP tasks, including conventional NLP tasks
like named entity recognition and relation classification, as well as NLP tasks
specific to materials science, such as synthesis action retrieval which relates
to creating synthesis procedures for materials. We study various BERT-based
models pretrained on different scientific text corpora on MatSci-NLP to
understand the impact of pretraining strategies on understanding materials
science text. Given the scarcity of high-quality annotated data in the
materials science domain, we perform our fine-tuning experiments with limited
training data to encourage the generalize across MatSci-NLP tasks. Our
experiments in this low-resource training setting show that language models
pretrained on scientific text outperform BERT trained on general text. MatBERT,
a model pretrained specifically on materials science journals, generally
performs best for most tasks. Moreover, we propose a unified text-to-schema for
multitask learning on \benchmark and compare its performance with traditional
fine-tuning methods. In our analysis of different training methods, we find
that our proposed text-to-schema methods inspired by question-answering
consistently outperform single and multitask NLP fine-tuning methods. The code
and datasets are publicly available at
\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}.

中文翻译:
我们推出了MatSci-NLP，这是一个用于评估自然语言处理（NLP）模型在材料科学文本上性能的自然语言基准。该基准基于公开可获取的材料科学文本数据构建，涵盖七种不同的NLP任务，包括命名实体识别和关系分类等传统NLP任务，以及材料科学特有的NLP任务，如与材料合成程序创建相关的合成动作检索。我们研究了在MatSci-NLP上预训练于不同科学文本语料库的各种基于BERT的模型，以理解预训练策略对理解材料科学文本的影响。鉴于材料科学领域高质量标注数据的稀缺性，我们在有限的训练数据下进行微调实验，以促进模型在MatSci-NLP任务间的泛化能力。在这种低资源训练设置下的实验表明，预训练于科学文本的语言模型优于基于通用文本训练的BERT。特别是MatBERT——一个专门在材料科学期刊上预训练的模型，在大多数任务中表现最佳。此外，我们提出了一种统一的文本到模式（text-to-schema）方法用于\benchmark上的多任务学习，并将其性能与传统微调方法进行了比较。在不同训练方法的分析中，我们发现受问答启发的文本到模式方法在性能上持续优于单任务和多任务NLP微调方法。代码和数据集公开于\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}。
