# Integrating Cognitive Processing Signals into Language Models: A Review of Advances, Applications and Future Directions

链接: http://arxiv.org/abs/2504.06843v1

原文摘要:
Recently, the integration of cognitive neuroscience in Natural Language
Processing (NLP) has gained significant attention. This article provides a
critical and timely overview of recent advancements in leveraging cognitive
signals, particularly Eye-tracking (ET) signals, to enhance Language Models
(LMs) and Multimodal Large Language Models (MLLMs). By incorporating
user-centric cognitive signals, these approaches address key challenges,
including data scarcity and the environmental costs of training large-scale
models. Cognitive signals enable efficient data augmentation, faster
convergence, and improved human alignment. The review emphasises the potential
of ET data in tasks like Visual Question Answering (VQA) and mitigating
hallucinations in MLLMs, and concludes by discussing emerging challenges and
research trends.

中文翻译:
近年来，认知神经科学与自然语言处理（NLP）的融合备受关注。本文对利用认知信号（尤其是眼动追踪信号）增强语言模型（LMs）和多模态大语言模型（MLLMs）的最新进展进行了批判性、时效性的综述。通过整合以用户为中心的认知信号，这些方法有效应对了数据稀缺和大规模模型训练环境成本等核心挑战。认知信号能实现高效数据增强、加速模型收敛并提升人类对齐性。文章重点探讨了眼动数据在视觉问答（VQA）任务中的潜力及其对缓解多模态大模型幻觉的作用，最后展望了该领域新兴挑战与研究趋势。
