# Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression

链接: http://arxiv.org/abs/2310.15594v1

原文摘要:
Large-scale pre-trained language models (LLMs) have demonstrated exceptional
performance in various natural language processing (NLP) tasks. However, the
massive size of these models poses huge challenges for their deployment in
real-world applications. While numerous model compression techniques have been
proposed, most of them are not well-suited for achieving extreme model
compression when there is a significant gap in model scale. In this paper, we
introduce a novel compression paradigm called Retrieval-based Knowledge
Transfer (RetriKT), which effectively transfers the knowledge of LLMs to
extremely small-scale models (e.g., 1%). In particular, our approach extracts
knowledge from LLMs to construct a knowledge store, from which the small-scale
model can retrieve relevant information and leverage it for effective
inference. To improve the quality of the model, soft prompt tuning and Proximal
Policy Optimization (PPO) reinforcement learning techniques are employed.
Extensive experiments are conducted on low-resource tasks from SuperGLUE and
GLUE benchmarks. The results demonstrate that the proposed approach
significantly enhances the performance of small-scale models by leveraging the
knowledge from LLMs.

中文翻译:
大规模预训练语言模型（LLMs）在各类自然语言处理（NLP）任务中展现出卓越性能，但其庞大参数量给实际应用部署带来巨大挑战。尽管已有多种模型压缩技术被提出，当模型规模存在数量级差距时，这些方法往往难以实现极端压缩。本文提出了一种名为"基于检索的知识迁移"（RetriKT）的新型压缩范式，能够将LLMs的知识高效迁移至超小规模模型（如原模型1%参数量）。具体而言，该方法从LLMs中提取知识构建知识库，使小规模模型能检索相关信息并用于有效推理。为提升模型质量，研究采用了软提示调优和近端策略优化（PPO）强化学习技术。在SuperGLUE和GLUE基准的低资源任务上进行的大量实验表明，该方法通过利用LLMs的知识，显著提升了小规模模型的性能表现。
