# How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey

链接: http://arxiv.org/abs/2312.04775v1

原文摘要:
Transferability estimation has been attached to great attention in the
computer vision fields. Researchers try to estimate with low computational cost
the performance of a model when transferred from a source task to a given
target task. Considering the effectiveness of such estimations, the communities
of natural language processing also began to study similar problems for the
selection of pre-trained language models. However, there is a lack of a
comprehensive comparison between these estimation methods yet. Also, the
differences between vision and language scenarios make it doubtful whether
previous conclusions can be established across fields. In this paper, we first
conduct a thorough survey of existing transferability estimation methods being
able to find the most suitable model, then we conduct a detailed empirical
study for the surveyed methods based on the GLUE benchmark. From qualitative
and quantitative analyses, we demonstrate the strengths and weaknesses of
existing methods and show that H-Score generally performs well with
superiorities in effectiveness and efficiency. We also outline the difficulties
of consideration of training details, applicability to text generation, and
consistency to certain metrics which shed light on future directions.

中文翻译:
迁移性评估在计算机视觉领域备受关注，研究者们致力于以较低计算成本预估模型从源任务迁移至给定目标任务的性能表现。鉴于此类评估的有效性，自然语言处理领域也开始研究预训练语言模型选择的类似问题。然而目前仍缺乏对这些评估方法的系统性比较，且视觉与语言场景的差异使得跨领域结论的可靠性存疑。本文首先对现有可匹配最优模型的迁移性评估方法进行全面梳理，随后基于GLUE基准对调研方法展开详细实证研究。通过定性与定量分析，我们揭示了现有方法的优势与局限，证明H-Score在效果与效率方面总体表现优异。同时，我们指出训练细节考量、文本生成任务适用性以及与特定指标一致性等难点，为未来研究方向提供了启示。
