# ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models

链接: http://arxiv.org/abs/2403.20158v1

原文摘要:
In our rapidly evolving digital sphere, the ability to discern media bias
becomes crucial as it can shape public sentiment and influence pivotal
decisions. The advent of large language models (LLMs), such as ChatGPT, noted
for their broad utility in various natural language processing (NLP) tasks,
invites exploration of their efficacy in media bias detection. Can ChatGPT
detect media bias? This study seeks to answer this question by leveraging the
Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in
distinguishing six categories of media bias, juxtaposed against fine-tuned
models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy:
ChatGPT performs at par with fine-tuned models in detecting hate speech and
text-level context bias, yet faces difficulties with subtler elements of other
bias detections, namely, fake news, racial, gender, and cognitive biases.

中文翻译:
在我们快速演变的数字领域中，辨别媒体偏见的能力变得至关重要，因为它能够塑造公众情绪并影响关键决策。以ChatGPT为代表的大型语言模型（LLMs）因其在各种自然语言处理（NLP）任务中的广泛应用而备受瞩目，这促使人们探索其在媒体偏见检测中的有效性。ChatGPT能否识别媒体偏见？本研究试图通过利用媒体偏见识别基准（MBIB）来回答这个问题，评估ChatGPT在区分六类媒体偏见方面的能力，并与经过微调的模型（如BART、ConvBERT和GPT-2）进行对比。研究结果呈现出一种二分现象：ChatGPT在检测仇恨言论和文本层面的语境偏见方面表现与微调模型相当，但在其他偏见检测的细微元素上遇到困难，即假新闻、种族、性别和认知偏见。
