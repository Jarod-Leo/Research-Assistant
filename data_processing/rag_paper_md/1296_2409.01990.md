# Contemporary Model Compression on Large Language Models Inference

链接: http://arxiv.org/abs/2409.01990v1

原文摘要:
This paper focuses on modern efficient training and inference technologies on
foundation models and illustrates them from two perspectives: model and system
design. Model and System Design optimize LLM training and inference from
different aspects to save computational resources, making LLMs more efficient,
affordable, and more accessible. The paper list repository is available at
https://github.com/NoakLiu/Efficient-Foundation-Models-Survey.

中文翻译:
本文聚焦于现代高效的基础模型训练与推理技术，从模型和系统设计两个维度进行阐述。模型与系统设计通过不同层面的优化来节省大语言模型（LLM）训练和推理的计算资源，使其更高效、经济且易于普及。相关论文清单详见https://github.com/NoakLiu/Efficient-Foundation-Models-Survey。
