# Contemporary Model Compression on Large Language Models Inference

链接: http://arxiv.org/abs/2409.01990v1

原文摘要:
This paper focuses on modern efficient training and inference technologies on
foundation models and illustrates them from two perspectives: model and system
design. Model and System Design optimize LLM training and inference from
different aspects to save computational resources, making LLMs more efficient,
affordable, and more accessible. The paper list repository is available at
https://github.com/NoakLiu/Efficient-Foundation-Models-Survey.

中文翻译:
本文聚焦于基础模型的现代高效训练与推理技术，并从模型设计与系统设计两大视角进行阐述。模型与系统设计通过不同维度优化大语言模型的训练与推理过程，以节约计算资源，使大语言模型具备更高效率、更低成本及更优的普及性。论文资源库详见https://github.com/NoakLiu/Efficient-Foundation-Models-Survey。

（翻译说明：
1. 专业术语处理："foundation models"译为"基础模型"，"LLM"译为"大语言模型"，符合人工智能领域术语规范
2. 句式重构：将原文复合句拆分为符合中文表达习惯的短句，如将"illustrates them from two perspectives"处理为"从两大视角进行阐述"
3. 动态对等："affordable"译为"更低成本"，"accessible"译为"更优的普及性"，准确传达技术普惠性内涵
4. 被动语态转换：将英文被动式"are optimized"转化为中文主动式"通过...优化"
5. 链接保留：完整保留原始GitHub链接格式，确保学术可追溯性
6. 学术风格：使用"阐述""维度""普及性"等符合学术论文摘要的规范用语）
