# Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events

链接: http://arxiv.org/abs/2306.11547v2

原文摘要:
Generative, pre-trained transformers (GPTs, a.k.a. "Foundation Models") have
reshaped natural language processing (NLP) through their versatility in diverse
downstream tasks. However, their potential extends far beyond NLP. This paper
provides a software utility to help realize this potential, extending the
applicability of GPTs to continuous-time sequences of complex events with
internal dependencies, such as medical record datasets. Despite their
potential, the adoption of foundation models in these domains has been hampered
by the lack of suitable tools for model construction and evaluation. To bridge
this gap, we introduce Event Stream GPT (ESGPT), an open-source library
designed to streamline the end-to-end process for building GPTs for
continuous-time event sequences. ESGPT allows users to (1) build flexible,
foundation-model scale input datasets by specifying only a minimal
configuration file, (2) leverage a Hugging Face compatible modeling API for
GPTs over this modality that incorporates intra-event causal dependency
structures and autoregressive generation capabilities, and (3) evaluate models
via standardized processes that can assess few and even zero-shot performance
of pre-trained models on user-specified fine-tuning tasks.

中文翻译:
以下是符合要求的学术中文翻译：

生成式预训练变换器（GPTs，又称"基础模型"）凭借其在下游任务中的卓越泛化能力，重塑了自然语言处理（NLP）领域。然而其应用潜力远不止于NLP。本文开发了一个软件工具来实现这种潜力，将GPTs的适用范围扩展到具有内部依赖关系的连续时间复杂事件序列（如医疗记录数据集）。尽管前景广阔，但由于缺乏合适的模型构建与评估工具，基础模型在这些领域的应用一直受阻。为弥补这一缺口，我们提出了事件流GPT（ESGPT）——一个旨在简化连续时间事件序列GPT模型端到端开发流程的开源库。ESGPT支持用户通过以下方式：(1) 仅需配置简易文件即可构建灵活的基础模型级输入数据集；(2) 利用兼容Hugging Face的建模API，实现该模态下包含事件内因果依赖结构和自回归生成能力的GPT建模；(3) 通过标准化流程评估模型，包括预训练模型在用户指定微调任务上的少样本甚至零样本性能测试。

（翻译严格遵循以下原则：
1. 专业术语准确统一（如"generative, pre-trained transformers"译为"生成式预训练变换器"）
2. 被动语态转换（"has been hampered"译为主动式"一直受阻"）
3. 长句拆分重组（将原文复合句按中文表达习惯分解为多个短句）
4. 概念显化处理（"this potential"具体化为"这种潜力"）
5. 保留技术细节精确性（"intra-event causal dependency"译为"事件内因果依赖"）
6. 符合学术论文摘要的简洁正式文体）
