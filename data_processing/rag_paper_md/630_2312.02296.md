# LLMs Accelerate Annotation for Medical Information Extraction

链接: http://arxiv.org/abs/2312.02296v1

原文摘要:
The unstructured nature of clinical notes within electronic health records
often conceals vital patient-related information, making it challenging to
access or interpret. To uncover this hidden information, specialized Natural
Language Processing (NLP) models are required. However, training these models
necessitates large amounts of labeled data, a process that is both
time-consuming and costly when relying solely on human experts for annotation.
In this paper, we propose an approach that combines Large Language Models
(LLMs) with human expertise to create an efficient method for generating ground
truth labels for medical text annotation. By utilizing LLMs in conjunction with
human annotators, we significantly reduce the human annotation burden, enabling
the rapid creation of labeled datasets. We rigorously evaluate our method on a
medical information extraction task, demonstrating that our approach not only
substantially cuts down on human intervention but also maintains high accuracy.
The results highlight the potential of using LLMs to improve the utilization of
unstructured clinical data, allowing for the swift deployment of tailored NLP
solutions in healthcare.

中文翻译:
电子健康记录中临床笔记的非结构化特性常常掩盖了与患者相关的重要信息，使得获取或解读这些信息变得极具挑战性。为揭示这些隐藏信息，需要专门的自然语言处理（NLP）模型。然而，训练这些模型需要大量标注数据，若仅依赖专家人工标注，这一过程既耗时又昂贵。本文提出一种将大语言模型（LLMs）与人类专业知识相结合的方法，构建高效的医学文本标注真值标签生成方案。通过LLMs与人工标注者的协同工作，我们显著降低了人工标注负担，实现了标注数据集的快速构建。我们在医学信息抽取任务上对该方法进行了严格评估，结果表明该方法不仅大幅减少了人工干预需求，同时保持了较高的准确率。这些成果凸显了利用LLMs提升非结构化临床数据利用率的潜力，为医疗领域快速部署定制化NLP解决方案提供了可能。
