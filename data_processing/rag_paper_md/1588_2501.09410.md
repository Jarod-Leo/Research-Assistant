# MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models

链接: http://arxiv.org/abs/2501.09410v1

原文摘要:
Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of natural language processing tasks. Exploiting the heterogeneous
capabilities of edge LLMs is crucial for diverse emerging applications, as it
enables greater cost-effectiveness and reduced latency. In this work, we
introduce \textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative
inference framework for edge LLMs. We formulate the joint gating and expert
selection problem to optimize inference performance under energy and latency
constraints. Unlike conventional MoE problems, LLM expert selection is
significantly more challenging due to the combinatorial nature and the
heterogeneity of edge LLMs across various attributes. To this end, we propose a
two-level expert selection mechanism through which we uncover an
optimality-preserving property of gating parameters across expert selections.
This property enables the decomposition of the training and selection
processes, significantly reducing complexity. Furthermore, we leverage the
objective's monotonicity and design a discrete monotonic optimization algorithm
for optimal expert selection. We implement edge servers with NVIDIA Jetson AGX
Orins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results
validate that performance improvements of various LLM models and show that our
MoE$^2$ method can achieve optimal trade-offs among different delay and energy
budgets, and outperforms baselines under various system resource constraints.

中文翻译:
大型语言模型（LLMs）在广泛的自然语言处理任务中展现出卓越能力。充分利用边缘LLMs的异构能力对多样化新兴应用至关重要，因其能显著提升成本效益并降低延迟。本文提出\textit{边缘专家混合（MoE$^2$）}框架，这是一种面向边缘LLMs的新型协同推理架构。我们构建了联合门控与专家选择问题，以在能耗与延迟约束下优化推理性能。不同于传统MoE问题，由于组合特性及边缘LLMs在多重属性上的异构性，LLM专家选择面临更大挑战。为此，我们设计了两级专家选择机制，通过该机制揭示了门控参数在专家选择过程中保持最优性的特性。这一特性实现了训练与选择过程的解耦，大幅降低了复杂度。此外，利用目标函数的单调性，我们开发了离散单调优化算法以实现最优专家选择。基于NVIDIA Jetson AGX Orin和RTX 4090 GPU搭建边缘服务器进行大量实验，结果表明：多种LLM模型性能得到验证，且MoE$^2$方法能在不同延迟与能耗预算下实现最优权衡，在各类系统资源限制下均优于基线方案。
