# G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German

链接: http://arxiv.org/abs/2402.06584v1

原文摘要:
The advancement of natural language processing has paved the way for
automated scoring systems in various languages, such as German (e.g., German
BERT [G-BERT]). Automatically scoring written responses to science questions in
German is a complex task and challenging for standard G-BERT as they lack
contextual knowledge in the science domain and may be unaligned with student
writing styles. This paper presents a contextualized German Science Education
BERT (G-SciEdBERT), an innovative large language model tailored for scoring
German-written responses to science tasks and beyond. Using G-BERT, we
pre-trained G-SciEdBERT on a corpus of 30K German written science responses
with 3M tokens on the Programme for International Student Assessment (PISA)
2018. We fine-tuned G-SciEdBERT on an additional 20K student-written responses
with 2M tokens and examined the scoring accuracy. We then compared its scoring
performance with G-BERT. Our findings revealed a substantial improvement in
scoring accuracy with G-SciEdBERT, demonstrating a 10.2% increase of quadratic
weighted Kappa compared to G-BERT (mean difference = 0.1026, SD = 0.069). These
insights underline the significance of specialized language models like
G-SciEdBERT, which is trained to enhance the accuracy of contextualized
automated scoring, offering a substantial contribution to the field of AI in
education.

中文翻译:
自然语言处理技术的进步为多语种（如德语BERT[G-BERT]）自动评分系统的研发奠定了基础。针对德语科学问答题书面作答的自动评分是一项复杂任务，标准G-BERT模型因缺乏科学领域语境知识且难以适配学生写作风格而面临挑战。本文提出情境化德语科学教育BERT模型（G-SciEdBERT），这一创新性大语言模型专为德语科学问答题及其他类型作答的自动评分而设计。基于G-BERT框架，我们使用2018年国际学生评估计划（PISA）中3万份德语科学作答文本（含300万词符）对G-SciEdBERT进行预训练，并进一步用2万份学生作答（含200万词符）进行微调以检验评分准确性。与原始G-BERT的对比实验显示，G-SciEdBERT的评分准确率显著提升，二次加权Kappa系数平均提高10.2%（均值差=0.1026，标准差=0.069）。这些发现凸显了G-SciEdBERT等专业语言模型的价值——通过针对性训练提升情境化自动评分的精确度，为教育人工智能领域作出重要贡献。
