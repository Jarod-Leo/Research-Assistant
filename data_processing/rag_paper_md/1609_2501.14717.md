# Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models

链接: http://arxiv.org/abs/2501.14717v1

原文摘要:
Recent advances in natural language processing have leveraged instruction
tuning to enhance Large Language Models (LLMs) for table-related tasks.
However, previous works train different base models with different training
data, lacking an apples-to-apples comparison across the result table LLMs. To
address this, we fine-tune base models from the Mistral, OLMo, and Phi families
on existing public training datasets. Our replication achieves performance on
par with or surpassing existing table LLMs, establishing new state-of-the-art
performance on Hitab, a table question-answering dataset. More importantly,
through systematic out-of-domain evaluation, we decouple the contributions of
training data and the base model, providing insight into their individual
impacts. In addition, we assess the effects of table-specific instruction
tuning on general-purpose benchmarks, revealing trade-offs between
specialization and generalization.

中文翻译:
近期自然语言处理领域通过指令微调技术提升了大型语言模型（LLMs）在表格相关任务中的表现。然而既有研究使用不同基座模型和训练数据，导致各表格LLM之间缺乏直接可比性。为此，我们基于Mistral、OLMo和Phi系列基座模型，在现有公开训练数据集上进行微调。复现实验表明，我们的模型性能达到或超越现有表格LLM，在表格问答数据集Hitab上创造了最新性能记录。更重要的是，通过系统性跨领域评估，我们解构了训练数据与基座模型的独立贡献，揭示了二者各自的影响机制。此外，我们还评估了表格专用指令微调对通用基准测试的影响，发现专业化与泛化能力之间存在权衡关系。

（翻译说明：
1. 专业术语处理："instruction tuning"译为"指令微调"，"base model"译为"基座模型"，"state-of-the-art"译为"最新性能记录"符合计算机领域表述习惯
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如第二句通过"为此"进行逻辑衔接
3. 被动语态转换："are fine-tuned"主动化为"基于...进行微调"
4. 概念显化："apples-to-apples comparison"意译为"直接可比性"
5. 学术表达："decouple"译为"解构"，"revealing trade-offs"译为"发现...存在权衡关系"保持学术严谨性
6. 术语一致性：全篇统一"LLMs"的译法为"大型语言模型"）
