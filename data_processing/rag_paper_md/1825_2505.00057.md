# A Report on the llms evaluating the high school questions

链接: http://arxiv.org/abs/2505.00057v1

原文摘要:
This report aims to evaluate the performance of large language models (LLMs)
in solving high school science questions and to explore their potential
applications in the educational field. With the rapid development of LLMs in
the field of natural language processing, their application in education has
attracted widespread attention. This study selected mathematics exam questions
from the college entrance examinations (2019-2023) as evaluation data and
utilized at least eight LLM APIs to provide answers. A comprehensive assessment
was conducted based on metrics such as accuracy, response time, logical
reasoning, and creativity. Through an in-depth analysis of the evaluation
results, this report reveals the strengths and weaknesses of LLMs in handling
high school science questions and discusses their implications for educational
practice. The findings indicate that although LLMs perform excellently in
certain aspects, there is still room for improvement in logical reasoning and
creative problem-solving. This report provides an empirical foundation for
further research and application of LLMs in the educational field and offers
suggestions for improvement.

中文翻译:
本报告旨在评估大语言模型（LLMs）在解答高中理科题目方面的表现，并探讨其在教育领域的应用潜力。随着大语言模型在自然语言处理领域的快速发展，其在教育中的应用已引起广泛关注。本研究选取2019-2023年高考数学真题作为评估数据，调用至少8个大语言模型API进行作答，从准确率、响应时间、逻辑推理和创造性等维度进行综合评估。通过对评估结果的深入分析，本报告揭示了LLMs在处理高中理科题目时的优势与不足，并探讨了其对教育实践的启示。研究结果表明，虽然LLMs在某些方面表现优异，但在逻辑推理和创造性解题方面仍有提升空间。本报告为进一步研究和应用LLMs在教育领域提供了实证基础，并提出了改进建议。
