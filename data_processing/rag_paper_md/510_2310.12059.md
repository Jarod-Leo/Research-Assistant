# Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education

链接: http://arxiv.org/abs/2310.12059v1

原文摘要:
In this paper, we evaluate the ability of large language models (LLMs) to
perform multiple choice symbol binding (MCSB) for multiple choice question
answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus
on Vietnamese, with fewer challenging MCQA datasets than in English. The two
existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent
research in Vietnamese natural language processing (NLP) has focused on the
Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to
2023 to evaluate ChatGPT. However, these studies have mainly focused on how
ChatGPT solves the VNHSGE step by step. We aim to create a novel and
high-quality dataset by providing structured guidelines for typing LaTeX
formulas for mathematics, physics, chemistry, and biology. This dataset can be
used to evaluate the MCSB ability of LLMs and smaller language models (LMs)
because it is typed in a strict LaTeX style. We focus on predicting the
character (A, B, C, or D) that is the most likely answer to a question, given
the context of the question. Our evaluation of six well-known LLMs, namely
BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the
ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising
results on the MCSB ability of LLMs for Vietnamese. The dataset is available
for research purposes only.

中文翻译:
本文评估了大语言模型（LLM）在零样本、单样本和少样本设置下执行多选题符号绑定（MCSB）以完成多选题问答（MCQA）任务的能力。研究聚焦越南语领域——相较于英语，该语言目前缺乏具有挑战性的MCQA数据集。现有两个文学类数据集ViMMRC 1.0和ViMMRC 2.0，而近期越南自然语言处理研究主要基于2019-2023年越南国家高中毕业考试（VNHSGE）来评估ChatGPT，但这些研究多关注模型分步解题过程。我们通过制定严格的LaTeX公式输入规范，构建了包含数学、物理、化学和生物学科目的新颖高质量数据集。该数据集采用严格LaTeX格式编写，既能评估LLM也能测试较小语言模型的MCSB能力。研究核心是在给定问题上下文的情况下，预测最可能答案对应的选项字符（A、B、C或D）。通过对BLOOMZ-7.1B-MT、LLaMA-2-7B、LLaMA-2-70B、GPT-3、GPT-3.5和GPT-4.0六种知名LLM在ViMMRC基准集及本数据集上的测试，结果表明这些模型在越南语MCSB任务中展现出良好性能。本数据集仅限研究用途。
