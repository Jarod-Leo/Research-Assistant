# Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model

链接: http://arxiv.org/abs/2305.11176v1

原文摘要:
Foundation models have made significant strides in various applications,
including text-to-image generation, panoptic segmentation, and natural language
processing. This paper presents Instruct2Act, a framework that utilizes Large
Language Models to map multi-modal instructions to sequential actions for
robotic manipulation tasks. Specifically, Instruct2Act employs the LLM model to
generate Python programs that constitute a comprehensive perception, planning,
and action loop for robotic tasks. In the perception section, pre-defined APIs
are used to access multiple foundation models where the Segment Anything Model
(SAM) accurately locates candidate objects, and CLIP classifies them. In this
way, the framework leverages the expertise of foundation models and robotic
abilities to convert complex high-level instructions into precise policy codes.
Our approach is adjustable and flexible in accommodating various instruction
modalities and input types and catering to specific task demands. We validated
the practicality and efficiency of our approach by assessing it on robotic
tasks in different scenarios within tabletop manipulation domains. Furthermore,
our zero-shot method outperformed many state-of-the-art learning-based policies
in several tasks. The code for our proposed approach is available at
https://github.com/OpenGVLab/Instruct2Act, serving as a robust benchmark for
high-level robotic instruction tasks with assorted modality inputs.

中文翻译:
基础模型在文本到图像生成、全景分割及自然语言处理等多个应用领域取得了显著进展。本文提出Instruct2Act框架，该框架利用大语言模型将多模态指令映射为机器人操作任务的序列化动作。具体而言，Instruct2Act通过大语言模型生成构成机器人任务完整感知-规划-行动循环的Python程序：在感知环节，预定义API调用多模态基础模型，其中Segment Anything Model（SAM）精准定位目标候选对象，CLIP模型完成分类。该框架通过融合基础模型的专业能力与机器人操作技能，将复杂高层指令转化为精确的策略代码。我们的方法具有高度可调性和灵活性，能适配不同模态的指令输入类型，满足特定任务需求。通过在桌面操作领域多个场景下的机器人任务评估，我们验证了该方法的实用性与高效性。值得注意的是，这种零样本方法在多项任务中超越了众多基于学习的最优策略。项目代码已开源（https://github.com/OpenGVLab/Instruct2Act），为多模态输入的高层机器人指令任务提供了强有力的基准方案。
