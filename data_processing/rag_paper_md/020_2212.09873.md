# A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models

链接: http://arxiv.org/abs/2212.09873v1

原文摘要:
There is growing interest in incorporating eye-tracking data and other
implicit measures of human language processing into natural language processing
(NLP) pipelines. The data from human language processing contain unique insight
into human linguistic understanding that could be exploited by language models.
However, many unanswered questions remain about the nature of this data and how
it can best be utilized in downstream NLP tasks. In this paper, we present
eyeStyliency, an eye-tracking dataset for human processing of stylistic text
(e.g., politeness). We develop a variety of methods to derive style saliency
scores over text using the collected eye dataset. We further investigate how
this saliency data compares to both human annotation methods and model-based
interpretability metrics. We find that while eye-tracking data is unique, it
also intersects with both human annotations and model-based importance scores,
providing a possible bridge between human- and machine-based perspectives. We
propose utilizing this type of data to evaluate the cognitive plausibility of
models that interpret style. Our eye-tracking data and processing code are
publicly available.

中文翻译:
将眼动追踪数据及其他人类语言处理的隐性测量融入自然语言处理（NLP）流程的研究日益受到关注。这类人类语言加工数据蕴含着对语言理解的独特洞见，可为语言模型所利用。然而，关于此类数据的本质及其在下游NLP任务中的最佳应用方式仍存在诸多未解之谜。本文提出eyeStyliency——一个针对文体文本（如礼貌用语）人类加工过程的眼动数据集。我们开发了多种方法，利用所收集的眼动数据计算文本的文体显著性分数，并深入探究该显著性数据与人工标注方法及基于模型的解释性指标之间的关联。研究发现，眼动数据虽具独特性，但与人工标注和模型重要性评分均存在交集，为连接人类视角与机器视角提供了可能桥梁。我们建议利用此类数据评估文体解释模型的认知合理性。相关眼动数据及处理代码已公开。
