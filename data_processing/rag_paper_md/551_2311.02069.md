# Grounded Intuition of GPT-Vision's Abilities with Scientific Images

链接: http://arxiv.org/abs/2311.02069v1

原文摘要:
GPT-Vision has impressed us on a range of vision-language tasks, but it comes
with the familiar new challenge: we have little idea of its capabilities and
limitations. In our study, we formalize a process that many have instinctively
been trying already to develop "grounded intuition" of this new model. Inspired
by the recent movement away from benchmarking in favor of example-driven
qualitative evaluation, we draw upon grounded theory and thematic analysis in
social science and human-computer interaction to establish a rigorous framework
for qualitative evaluation in natural language processing. We use our technique
to examine alt text generation for scientific figures, finding that GPT-Vision
is particularly sensitive to prompting, counterfactual text in images, and
relative spatial relationships. Our method and analysis aim to help researchers
ramp up their own grounded intuitions of new models while exposing how
GPT-Vision can be applied to make information more accessible.

中文翻译:
GPT-Vision在一系列视觉-语言任务上的表现令人印象深刻，但也带来了熟悉的新挑战：我们对其能力边界与局限知之甚少。本研究将许多人本能尝试的模型"基础认知构建"过程系统化。受近期从基准测试转向案例驱动的定性评估趋势启发，我们融合社会科学与人机交互领域的扎根理论与主题分析法，为自然语言处理领域建立了严谨的定性评估框架。通过将该方法应用于科学图表替代文本生成研究，我们发现GPT-Vision对提示词设计、图像中的反事实文本以及相对空间关系具有特殊敏感性。本方法与分析旨在帮助研究者快速建立对新模型的基础认知，同时揭示如何运用GPT-Vision提升信息可及性。
