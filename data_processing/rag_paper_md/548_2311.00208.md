# Transformers as Recognizers of Formal Languages: A Survey on Expressivity

链接: http://arxiv.org/abs/2311.00208v1

原文摘要:
As transformers have gained prominence in natural language processing, some
researchers have investigated theoretically what problems they can and cannot
solve, by treating problems as formal languages. Exploring such questions can
help clarify the power of transformers relative to other models of computation,
their fundamental capabilities and limits, and the impact of architectural
choices. Work in this subarea has made considerable progress in recent years.
Here, we undertake a comprehensive survey of this work, documenting the diverse
assumptions that underlie different results and providing a unified framework
for harmonizing seemingly contradictory findings.

中文翻译:
随着Transformer模型在自然语言处理领域崭露头角，部分研究者开始从形式语言理论视角出发，系统探究其能力边界——即能够解决或无法解决哪些类型的问题。这类基础性研究对于厘清Transformer相较于其他计算模型的优势、揭示其核心能力与固有局限、以及评估架构设计的影响具有重要意义。近年来，该研究方向已取得显著进展。本文通过全面梳理相关研究成果，系统归纳不同结论背后的理论假设，并构建统一框架以调和表面矛盾的研究发现。
