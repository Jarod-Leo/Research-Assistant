# Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures

链接: http://arxiv.org/abs/2303.08259v1

原文摘要:
Objective: To develop a natural language processing (NLP) system to extract
medications and contextual information that help understand drug changes. This
project is part of the 2022 n2c2 challenge.
  Materials and methods: We developed NLP systems for medication mention
extraction, event classification (indicating medication changes discussed or
not), and context classification to classify medication changes context into 5
orthogonal dimensions related to drug changes. We explored 6 state-of-the-art
pretrained transformer models for the three subtasks, including GatorTron, a
large language model pretrained using >90 billion words of text (including >80
billion words from >290 million clinical notes identified at the University of
Florida Health). We evaluated our NLP systems using annotated data and
evaluation scripts provided by the 2022 n2c2 organizers.
  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for
medication extraction (ranked 3rd), 0.9379 for event classification (ranked
2nd), and the best micro-average accuracy of 0.9126 for context classification.
GatorTron outperformed existing transformer models pretrained using smaller
general English text and clinical text corpora, indicating the advantage of
large language models.
  Conclusion: This study demonstrated the advantage of using large transformer
models for contextual medication information extraction from clinical
narratives.

中文翻译:
目的：开发一套自然语言处理（NLP）系统，用于提取药物信息及辅助理解用药变更的上下文信息。本项目为2022年n2c2挑战赛组成部分。

材料与方法：我们构建了三个NLP子系统：药物实体识别系统（用于定位药物提及）、事件分类系统（判断是否讨论用药变更）及上下文分类系统（将用药变更情境划分为5个正交维度）。针对这三项子任务，我们探索了6种基于预训练Transformer架构的先进模型，其中包括GatorTron——该模型通过超过900亿单词文本（含佛罗里达大学健康中心识别的2.9亿份临床笔记中的800亿单词）进行预训练的大型语言模型。使用2022年n2c2组委会提供的标注数据与评估脚本对系统性能进行验证。

结果：GatorTron模型在药物实体识别任务中取得0.9828的最高F1值（排名第3），在事件分类任务中获得0.9379的F1值（排名第2），在上下文分类任务中以0.9126的微平均准确率位居榜首。相较于基于小型通用英语文本和临床语料库预训练的现有Transformer模型，GatorTron展现出显著优势，印证了大型语言模型的卓越性能。

结论：本研究证实了采用大型Transformer模型从临床叙事文本中提取情境化用药信息的优越性。
