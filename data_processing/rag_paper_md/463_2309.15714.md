# ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension

链接: http://arxiv.org/abs/2309.15714v1

原文摘要:
With the recent proliferation of large language models (LLMs), such as
Generative Pre-trained Transformers (GPT), there has been a significant shift
in exploring human and machine comprehension of semantic language meaning. This
shift calls for interdisciplinary research that bridges cognitive science and
natural language processing (NLP). This pilot study aims to provide insights
into individuals' neural states during a semantic relation
reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and
electroencephalographic (EEG) data to study how the brain processes words with
varying degrees of relevance to a keyword during reading. We also use a feature
engineering approach to improve the fixation-related EEG data classification
while participants read words with high versus low relevance to the keyword.
The best validation accuracy in this word-level classification is over 60\%
across 12 subjects. Words of high relevance to the inference keyword had
significantly more eye fixations per word: 1.0584 compared to 0.6576 when
excluding no-fixation words, and 1.5126 compared to 1.4026 when including them.
This study represents the first attempt to classify brain states at a word
level using LLM knowledge. It provides valuable insights into human cognitive
abilities and the realm of Artificial General Intelligence (AGI), and offers
guidance for developing potential reading-assisted technologies.

中文翻译:
随着生成式预训练变换模型（GPT）等大型语言模型（LLM）的近期激增，探索人类与机器对语义理解的方式发生了显著转变。这一转变需要融合认知科学与自然语言处理（NLP）的跨学科研究。本试点研究旨在揭示个体在执行语义关系阅读理解任务时的神经状态。我们提出联合分析LLM、眼动追踪和脑电图（EEG）数据，以研究大脑在阅读过程中如何处理与关键词相关度不同的词汇。通过特征工程方法，我们改进了被试阅读与关键词高/低相关度词汇时的注视相关EEG数据分类效果。在12名被试中，词汇级别分类的最高验证准确率超过60%。与关键词高相关度的词汇显示出显著更高的单次注视次数：排除零注视词汇时为1.0584次（低相关度0.6576次），包含零注视词汇时达1.5126次（低相关度1.4026次）。该研究首次尝试利用LLM知识实现词汇级别的脑状态分类，为理解人类认知能力与通用人工智能（AGI）领域提供了重要启示，并为开发潜在阅读辅助技术提供了指导方向。
