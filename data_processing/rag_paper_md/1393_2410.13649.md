# A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks

链接: http://arxiv.org/abs/2410.13649v1

原文摘要:
In virtual assistant (VA) systems it is important to reject or redirect user
queries that fall outside the scope of the system. One of the most accurate
approaches for out-of-scope (OOS) rejection is to combine it with the task of
intent classification on in-scope queries, and to use methods based on the
similarity of embeddings produced by transformer-based sentence encoders.
Typically, such encoders are fine-tuned for the intent-classification task,
using cross-entropy loss. Recent work has shown that while this produces
suitable embeddings for the intent-classification task, it also tends to
disperse in-scope embeddings over the full sentence embedding space. This
causes the in-scope embeddings to potentially overlap with OOS embeddings,
thereby making OOS rejection difficult. This is compounded when OOS data is
unknown. To mitigate this issue our work proposes to regularize the
cross-entropy loss with an in-scope embedding reconstruction loss learned using
an auto-encoder. Our method achieves a 1-4% improvement in the area under the
precision-recall curve for rejecting out-of-sample (OOS) instances, without
compromising intent classification performance.

中文翻译:
在虚拟助手（VA）系统中，准确拒斥或转接超出系统处理范围的用户查询至关重要。当前最精确的越界查询（OOS）拒斥方法之一，是将该任务与界内查询的意图分类相结合，并利用基于Transformer句子编码器生成的嵌入向量相似度进行判断。传统做法通常通过交叉熵损失对编码器进行意图分类任务的微调。最新研究表明，虽然这种方法能为意图分类生成适配的嵌入向量，但也会导致界内嵌入向量在整个句子嵌入空间中过度分散。这种分散可能使界内嵌入与越界嵌入发生重叠，从而增加拒斥难度——当越界数据未知时问题尤为突出。为解决这一难题，本研究提出采用自编码器学习界内嵌入重构损失，以此正则化交叉熵损失函数。该方法在不影响意图分类性能的前提下，将样本外（OOS）实例拒斥的精确率-召回率曲线下面积提升了1-4%。
