# SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe

链接: http://arxiv.org/abs/2410.05248v1

原文摘要:
To acquire instruction-following capabilities, large language models (LLMs)
undergo instruction tuning, where they are trained on instruction-response
pairs using next-token prediction (NTP). Efforts to improve instruction tuning
often focus on higher-quality supervised fine-tuning (SFT) datasets, typically
requiring data filtering with proprietary LLMs or human annotation. In this
paper, we take a different approach by proposing SFTMix, a novel Mixup-based
recipe that elevates LLM instruction tuning beyond the conventional NTP
paradigm, without relying on well-curated datasets. Observing that LLMs exhibit
uneven confidence across the semantic representation space, we argue that
examples with different confidence levels should play distinct roles in
instruction tuning--confident data is prone to overfitting, while unconfident
data is harder to generalize. Based on this insight, SFTMix leverages training
dynamics to identify examples with varying confidence levels, interpolates them
to bridge the confidence gap, and applies a Mixup-based regularization to
support learning on these additional, interpolated examples. By propagating
supervision signals across confidence regions and encouraging linear behavior
between them, SFTMix mitigates overfitting in confident examples while
enhancing generalization in unconfident ones. We demonstrate the effectiveness
of SFTMix in both instruction-following and healthcare-specific SFT tasks, with
consistent improvements across LLM families and SFT datasets of varying sizes
and qualities. Extensive analyses across six directions highlight SFTMix's
compatibility with data selection, adaptability to compute-constrained
scenarios, and scalability to broader applications.

中文翻译:
为了获得遵循指令的能力，大型语言模型（LLMs）需经过指令微调，即在指令-响应对上通过下一词预测（NTP）进行训练。提升指令微调效果的尝试通常聚焦于更高质量的监督微调（SFT）数据集，这往往需要依赖专有LLMs进行数据过滤或人工标注。本文另辟蹊径，提出SFTMix——一种基于Mixup的创新方法，能在不依赖精心策划数据集的前提下，突破传统NTP范式来增强LLM指令微调。通过观察发现LLMs在语义表示空间中表现出不均衡的置信度分布，我们认为不同置信度的样本应在指令微调中发挥差异化作用：高置信度数据易引发过拟合，而低置信度数据则更难泛化。基于此洞见，SFTMix利用训练动态识别不同置信度的样本，通过插值弥合置信度差距，并应用基于Mixup的正则化来支持对这些新增插值样本的学习。该方法通过在置信区域间传播监督信号并鼓励线性行为，既缓解了高置信样本的过拟合，又提升了低置信样本的泛化能力。我们在通用指令跟随和医疗领域SFT任务中验证了SFTMix的有效性，其在不同LLM家族、不同规模与质量SFT数据集上均表现出一致提升。通过六个维度的深入分析，我们揭示了SFTMix与数据选择策略的兼容性、在计算受限场景的适应性以及面向更广泛应用的可扩展性。
