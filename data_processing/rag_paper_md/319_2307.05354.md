# GujiBERT and GujiGPT: Construction of Intelligent Information Processing Foundation Language Models for Ancient Texts

链接: http://arxiv.org/abs/2307.05354v1

原文摘要:
In the context of the rapid development of large language models, we have
meticulously trained and introduced the GujiBERT and GujiGPT language models,
which are foundational models specifically designed for intelligent information
processing of ancient texts. These models have been trained on an extensive
dataset that encompasses both simplified and traditional Chinese characters,
allowing them to effectively handle various natural language processing tasks
related to ancient books, including but not limited to automatic sentence
segmentation, punctuation, word segmentation, part-of-speech tagging, entity
recognition, and automatic translation. Notably, these models have exhibited
exceptional performance across a range of validation tasks using publicly
available datasets. Our research findings highlight the efficacy of employing
self-supervised methods to further train the models using classical text
corpora, thus enhancing their capability to tackle downstream tasks. Moreover,
it is worth emphasizing that the choice of font, the scale of the corpus, and
the initial model selection all exert significant influence over the ultimate
experimental outcomes. To cater to the diverse text processing preferences of
researchers in digital humanities and linguistics, we have developed three
distinct categories comprising a total of nine model variations. We believe
that by sharing these foundational language models specialized in the domain of
ancient texts, we can facilitate the intelligent processing and scholarly
exploration of ancient literary works and, consequently, contribute to the
global dissemination of China's rich and esteemed traditional culture in this
new era.

中文翻译:
在大语言模型迅猛发展的背景下，我们精心训练并推出了GujiBERT与GujiGPT语言模型——这是专门面向古籍智能化信息处理的基础模型。该系列模型通过简繁双轨文本的大规模训练，能够有效完成古籍自动句读、标点、分词、词性标注、实体识别及自动翻译等多种自然语言处理任务，在基于公开数据集的多个验证任务中均展现出卓越性能。我们的研究成果表明：采用自监督方法通过古文语料对模型进行继续训练能有效提升其处理下游任务的能力；同时需要特别指出，字体选择、语料规模与初始模型选取都会对最终实验效果产生显著影响。为适应数字人文、语言学等领域研究者不同的文本处理需求，我们开发了三大类别共九种模型变体。相信通过分享这些古籍领域的专业基础语言模型，能够助力古代文学作品的智能化处理与学术研究，从而推动中国优秀传统文化在新时期的全球传播。
