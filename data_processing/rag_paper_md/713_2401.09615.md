# Learning Shortcuts: On the Misleading Promise of NLU in Language Models

链接: http://arxiv.org/abs/2401.09615v1

原文摘要:
The advent of large language models (LLMs) has enabled significant
performance gains in the field of natural language processing. However, recent
studies have found that LLMs often resort to shortcuts when performing tasks,
creating an illusion of enhanced performance while lacking generalizability in
their decision rules. This phenomenon introduces challenges in accurately
assessing natural language understanding in LLMs. Our paper provides a concise
survey of relevant research in this area and puts forth a perspective on the
implications of shortcut learning in the evaluation of language models,
specifically for NLU tasks. This paper urges more research efforts to be put
towards deepening our comprehension of shortcut learning, contributing to the
development of more robust language models, and raising the standards of NLU
evaluation in real-world scenarios.

中文翻译:
大型语言模型（LLMs）的出现为自然语言处理领域带来了显著的性能提升。然而，近期研究发现，LLMs在执行任务时往往依赖捷径策略，这种表面性能增强的假象背后，其决策规则实则缺乏泛化能力。该现象对准确评估LLMs的自然语言理解能力提出了新的挑战。本文系统梳理了该领域的相关研究，并就捷径学习对语言模型评估（特别是自然语言理解任务）的影响提出了见解。我们呼吁学界投入更多研究以深化对捷径学习的认识，从而推动开发更具鲁棒性的语言模型，并提升现实场景中自然语言理解评估的标准。
