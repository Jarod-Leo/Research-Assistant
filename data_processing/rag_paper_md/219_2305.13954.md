# Robust Instruction Optimization for Large Language Models with Distribution Shifts

链接: http://arxiv.org/abs/2305.13954v1

原文摘要:
Large Language Model (LLM) has demonstrated significant ability in various
Natural Language Processing tasks. However, their effectiveness is highly
dependent on the phrasing of the task prompt, leading to research on automatic
prompt optimization using labeled task data. We reveal that these prompt
optimization techniques are vulnerable to distribution shifts such as
subpopulation shifts, which are common for LLMs in real-world scenarios such as
customer reviews analysis. In this light, we propose a new problem of robust
prompt optimization for LLMs against distribution shifts, which requires the
prompt optimized over the labeled source group can simultaneously generalize to
an unlabeled target group. To solve this problem, we propose Generalized Prompt
Optimization framework, which incorporates the unlabeled data from the target
group into prompt optimization. Extensive experimental results demonstrate the
effectiveness of the proposed framework with significant performance
improvement on the target group and comparable performance on the source group.

中文翻译:
大型语言模型（LLM）在各类自然语言处理任务中展现出卓越能力，但其性能高度依赖于任务提示的表述方式，这促使学界开始利用标注数据研究自动提示优化技术。本文揭示现有提示优化方法存在分布偏移脆弱性——例如现实场景中LLM处理客户评论分析时常遇到的子群体分布偏移问题。基于此，我们首次提出面向分布偏移的LLM鲁棒提示优化新课题，要求基于标注源群体优化的提示能同步泛化至未标注目标群体。

为解决该问题，我们提出广义提示优化框架，通过将目标群体未标注数据纳入优化过程实现跨群体适应。大量实验表明，该框架在目标群体上取得显著性能提升的同时，在源群体上保持了可比性能表现。
