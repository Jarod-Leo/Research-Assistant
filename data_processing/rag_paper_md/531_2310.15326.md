# Specialist or Generalist? Instruction Tuning for Specific NLP Tasks

链接: http://arxiv.org/abs/2310.15326v1

原文摘要:
The potential of large language models (LLMs) to simultaneously perform a
wide range of natural language processing (NLP) tasks has been the subject of
extensive research. Although instruction tuning has proven to be a
data-efficient method for transforming LLMs into such generalist models, their
performance still lags behind specialist models trained exclusively for
specific tasks. In this paper, we investigate whether incorporating
broad-coverage generalist instruction tuning can contribute to building a
specialist model. We hypothesize that its efficacy depends on task specificity
and skill requirements. Our experiments assess four target tasks with distinct
coverage levels, revealing that integrating generalist instruction tuning
consistently enhances model performance when the task coverage is broad. The
effect is particularly pronounced when the amount of task-specific training
data is limited. Further investigation into three target tasks focusing on
different capabilities demonstrates that generalist instruction tuning improves
understanding and reasoning abilities. However, for tasks requiring factual
knowledge, generalist data containing hallucinatory information may negatively
affect the model's performance. Overall, our work provides a systematic guide
for developing specialist models with general instruction tuning. Our code and
other related resources can be found at
https://github.com/DavidFanzz/Generalist_or_Specialist.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）同时执行多种自然语言处理（NLP）任务的潜力已成为广泛研究的主题。尽管指令微调已被证明是将LLMs转化为此类通用模型的数据高效方法，但其性能仍落后于专为特定任务训练的专业模型。本文通过实验探究广泛覆盖的通用指令微调是否有助于构建专业模型，并提出其有效性取决于任务特异性与技能要求的假设。我们评估了四个覆盖范围不同的目标任务，发现当任务覆盖面较广时，整合通用指令微调能持续提升模型性能，在任务特定训练数据有限时效果尤为显著。针对三种不同能力需求的后续实验表明：通用指令微调能有效提升理解与推理能力，但对于需要事实性知识的任务，包含幻觉信息的通用数据可能对模型性能产生负面影响。本研究为基于通用指令微调开发专业模型提供了系统性指导，相关代码与资源详见https://github.com/DavidFanzz/Generalist_or_Specialist。

（翻译严格遵循以下原则：
1. 专业术语准确统一："instruction tuning"译为"指令微调"，"generalist/specialist model"译为"通用/专业模型"
2. 被动语态转化：将英文被动结构转换为中文主动表达（如"has been the subject of"译为"已成为"）
3. 长句拆分重组：将复合长句按中文习惯分解为多个短句（如第二句拆分为假设与发现两部分）
4. 学术风格保持：使用"探究""表明""显著"等规范学术用语
5. 逻辑显性化：通过"发现""针对""表明"等连接词强化论证逻辑
6. 文化适应性处理："hallucinatory information"译为专业术语"幻觉信息"而非字面直译）
