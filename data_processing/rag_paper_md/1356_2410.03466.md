# Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering

链接: http://arxiv.org/abs/2410.03466v1

原文摘要:
The potential effectiveness of counterspeech as a hate speech mitigation
strategy is attracting increasing interest in the NLG research community,
particularly towards the task of automatically producing it. However,
automatically generated responses often lack the argumentative richness which
characterises expert-produced counterspeech. In this work, we focus on two
aspects of counterspeech generation to produce more cogent responses. First, by
investigating the tension between helpfulness and harmlessness of LLMs, we test
whether the presence of safety guardrails hinders the quality of the
generations. Secondly, we assess whether attacking a specific component of the
hate speech results in a more effective argumentative strategy to fight online
hate. By conducting an extensive human and automatic evaluation, we show how
the presence of safety guardrails can be detrimental also to a task that
inherently aims at fostering positive social interactions. Moreover, our
results show that attacking a specific component of the hate speech, and in
particular its implicit negative stereotype and its hateful parts, leads to
higher-quality generations.

中文翻译:
作为一种仇恨言论缓解策略，反制言论的潜在有效性正日益受到自然语言生成研究界的关注，尤其是其自动化生成任务。然而，自动生成的回应往往缺乏专家制作反制言论所特有的论证丰富性。本研究聚焦反制言论生成的两个关键维度以产生更具说服力的回应：首先通过探究大语言模型在"有益性"与"无害性"之间的张力，验证安全护栏机制是否会损害生成质量；其次评估针对仇恨言论特定成分的攻击是否能形成更有效的线上反制策略。通过开展大规模人工与自动评估，我们揭示安全护栏机制对本质上旨在促进积极社会互动的任务同样可能产生负面影响。此外，研究结果表明针对仇恨言论特定成分（尤其是其隐含负面刻板印象及仇恨内容）的攻击能显著提升生成质量。
