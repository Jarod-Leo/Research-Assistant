# Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models

链接: http://arxiv.org/abs/2309.17050v1

原文摘要:
Many individuals are likely to face a legal dispute at some point in their
lives, but their lack of understanding of how to navigate these complex issues
often renders them vulnerable. The advancement of natural language processing
opens new avenues for bridging this legal literacy gap through the development
of automated legal aid systems. However, existing legal question answering
(LQA) approaches often suffer from a narrow scope, being either confined to
specific legal domains or limited to brief, uninformative responses. In this
work, we propose an end-to-end methodology designed to generate long-form
answers to any statutory law questions, utilizing a "retrieve-then-read"
pipeline. To support this approach, we introduce and release the Long-form
Legal Question Answering (LLeQA) dataset, comprising 1,868 expert-annotated
legal questions in the French language, complete with detailed answers rooted
in pertinent legal provisions. Our experimental results demonstrate promising
performance on automatic evaluation metrics, but a qualitative analysis
uncovers areas for refinement. As one of the only comprehensive,
expert-annotated long-form LQA dataset, LLeQA has the potential to not only
accelerate research towards resolving a significant real-world issue, but also
act as a rigorous benchmark for evaluating NLP models in specialized domains.
We publicly release our code, data, and models.

中文翻译:
许多人在一生中都有可能面临法律纠纷，但由于缺乏应对这类复杂问题的知识，他们往往处于弱势地位。自然语言处理技术的发展为通过自动化法律援助系统弥合这一法律认知鸿沟开辟了新途径。然而，现有法律问答（LQA）方法普遍存在适用范围狭窄的问题——要么局限于特定法律领域，要么只能生成简短且信息量不足的回应。本研究提出一种端到端解决方案，采用"检索-阅读"流程来生成针对任何成文法问题的详实回答。为支持该方法，我们构建并开源了长格式法律问答数据集（LLeQA），包含1,868个法语法律问题及其基于相关法律条款的专家标注详答。实验结果显示该方法在自动评估指标上表现良好，但定性分析仍揭示了改进空间。作为目前仅有的综合性专家标注长格式LQA数据集，LLeQA不仅有望加速解决这一重要现实问题的研究进程，更能为专业领域NLP模型评估提供严格基准。我们公开了相关代码、数据及模型资源。
