# Identifying and Extracting Rare Disease Phenotypes with Large Language Models

链接: http://arxiv.org/abs/2306.12656v1

原文摘要:
Rare diseases (RDs) are collectively common and affect 300 million people
worldwide. Accurate phenotyping is critical for informing diagnosis and
treatment, but RD phenotypes are often embedded in unstructured text and
time-consuming to extract manually. While natural language processing (NLP)
models can perform named entity recognition (NER) to automate extraction, a
major bottleneck is the development of a large, annotated corpus for model
training. Recently, prompt learning emerged as an NLP paradigm that can lead to
more generalizable results without any (zero-shot) or few labeled samples
(few-shot). Despite growing interest in ChatGPT, a revolutionary large language
model capable of following complex human prompts and generating high-quality
responses, none have studied its NER performance for RDs in the zero- and
few-shot settings. To this end, we engineered novel prompts aimed at extracting
RD phenotypes and, to the best of our knowledge, are the first the establish a
benchmark for evaluating ChatGPT's performance in these settings. We compared
its performance to the traditional fine-tuning approach and conducted an
in-depth error analysis. Overall, fine-tuning BioClinicalBERT resulted in
higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.591 in the
zero- and few-shot settings, respectively). Despite this, ChatGPT achieved
similar or higher accuracy for certain entities (i.e., rare diseases and signs)
in the one-shot setting (F1 of 0.776 and 0.725). This suggests that with
appropriate prompt engineering, ChatGPT has the potential to match or
outperform fine-tuned language models for certain entity types with just one
labeled sample. While the proliferation of large language models may provide
opportunities for supporting RD diagnosis and treatment, researchers and
clinicians should critically evaluate model outputs and be well-informed of
their limitations.

中文翻译:
罕见病（RDs）虽单病种发病率低，但总体患者数达3亿人。精准的表型分析对诊疗至关重要，但罕见病表型常埋藏于非结构化文本中，人工提取耗时费力。虽然自然语言处理（NLP）模型可通过命名实体识别（NER）实现自动化提取，但构建大规模标注训练集成为主要瓶颈。新兴的提示学习范式能在零样本或少量标注样本（少样本）条件下获得更强泛化能力。尽管ChatGPT作为革命性大语言模型能够理解复杂人类指令并生成高质量响应，但其在罕见病NER任务中的零样本和少样本表现尚未被研究。为此，我们设计了创新性提示模板用于提取罕见病表型，并首次建立了评估ChatGPT在此类场景性能的基准体系。通过与传统微调方法的对比及深度错误分析发现：BioClinicalBERT微调模型总体表现更优（F1值0.689），ChatGPT在零样本和少样本设定下分别获得0.472和0.591的F1值。值得注意的是，ChatGPT在单样本场景中对特定实体（如罕见病名称和体征）的识别准确率（F1值0.776和0.725）达到或超越微调模型。这表明通过精心设计的提示工程，ChatGPT仅需单个标注样本即可在某些实体类型上媲美或超越微调模型。尽管大语言模型的发展为罕见病诊疗支持带来新机遇，研究人员和临床医生仍需审慎评估模型输出，并充分认知其局限性。
