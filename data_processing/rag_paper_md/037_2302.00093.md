# Large Language Models Can Be Easily Distracted by Irrelevant Context

链接: http://arxiv.org/abs/2302.00093v1

原文摘要:
Large language models have achieved impressive performance on various natural
language processing tasks. However, so far they have been evaluated primarily
on benchmarks where all information in the input context is relevant for
solving the task. In this work, we investigate the distractibility of large
language models, i.e., how the model problem-solving accuracy can be influenced
by irrelevant context. In particular, we introduce Grade-School Math with
Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant
information in the problem description. We use this benchmark to measure the
distractibility of cutting-edge prompting techniques for large language models,
and find that the model performance is dramatically decreased when irrelevant
information is included. We also identify several approaches for mitigating
this deficiency, such as decoding with self-consistency and adding to the
prompt an instruction that tells the language model to ignore the irrelevant
information.

中文翻译:
大型语言模型在各类自然语言处理任务中展现出卓越性能，然而现有评估主要集中于输入上下文信息全部与任务相关的基准测试。本研究聚焦于大语言模型的抗干扰能力，即无关语境如何影响模型解题准确率。我们特别构建了"含无关信息的小学数学题集"(GSM-IC)，该算术推理数据集的题目描述中嵌入了无关内容。通过该基准测试当代前沿的大模型提示技术，发现当存在无关信息时模型性能显著下降。研究同时提出了若干改进方案，包括采用自洽性解码策略，以及在提示词中明确要求模型忽略无关信息等缓解措施。
