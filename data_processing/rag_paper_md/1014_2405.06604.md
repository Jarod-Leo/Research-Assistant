# Explaining Text Similarity in Transformer Models

链接: http://arxiv.org/abs/2405.06604v1

原文摘要:
As Transformers have become state-of-the-art models for natural language
processing (NLP) tasks, the need to understand and explain their predictions is
increasingly apparent. Especially in unsupervised applications, such as
information retrieval tasks, similarity models built on top of foundation model
representations have been widely applied. However, their inner prediction
mechanisms have mostly remained opaque. Recent advances in explainable AI have
made it possible to mitigate these limitations by leveraging improved
explanations for Transformers through layer-wise relevance propagation (LRP).
Using BiLRP, an extension developed for computing second-order explanations in
bilinear similarity models, we investigate which feature interactions drive
similarity in NLP models. We validate the resulting explanations and
demonstrate their utility in three corpus-level use cases, analyzing
grammatical interactions, multilingual semantics, and biomedical text
retrieval. Our findings contribute to a deeper understanding of different
semantic similarity tasks and models, highlighting how novel explainable AI
methods enable in-depth analyses and corpus-level insights.

中文翻译:
随着Transformer模型成为自然语言处理（NLP）任务的最先进技术，理解和解释其预测结果的需求日益凸显。特别是在无监督应用场景中（如信息检索任务），基于基础模型表征构建的相似性模型已得到广泛应用，但其内部预测机制大多仍不透明。近期可解释人工智能的进展通过分层相关性传播（LRP）技术为Transformer模型提供改进的解释，从而缓解了这一局限性。我们利用专为双线性相似模型设计的二阶解释扩展方法BiLRP，探究了NLP模型中驱动相似性的特征交互机制。通过三个语料库级别的应用案例（语法交互分析、多语言语义研究和生物医学文本检索），我们验证了所得解释的有效性并展示了其应用价值。本研究不仅深化了对不同语义相似性任务及模型的理解，更揭示了新型可解释AI方法如何实现深度分析和语料库层面的洞察。

（翻译说明：
1. 专业术语处理：采用"分层相关性传播"等学界通用译法，保持"Transformer/BiLRP"等专有名词原貌
2. 长句拆分：将原文复合句按中文表达习惯分解为多个短句，如将"Especially in..."长状语独立成句
3. 被动语态转换："have been widely applied"译为主动式"已得到广泛应用"
4. 概念显化："foundation model representations"译为"基础模型表征"而非字面直译
5. 逻辑衔接：通过"通过/利用"等介词保持技术路线的连贯性，使用"探究/揭示"等动词强化研究动作
6. 学术风格：采用"凸显/机制/深化"等学术用语，保持摘要的严谨性）
