# Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data

链接: http://arxiv.org/abs/2403.01133v1

原文摘要:
Traditional human-in-the-loop-based annotation for time-series data like
inertial data often requires access to alternate modalities like video or audio
from the environment. These alternate sources provide the necessary information
to the human annotator, as the raw numeric data is often too obfuscated even
for an expert. However, this traditional approach has many concerns surrounding
overall cost, efficiency, storage of additional modalities, time, scalability,
and privacy. Interestingly, recent large language models (LLMs) are also
trained with vast amounts of publicly available alphanumeric data, which allows
them to comprehend and perform well on tasks beyond natural language
processing. Naturally, this opens up a potential avenue to explore LLMs as
virtual annotators where the LLMs will be directly provided the raw sensor data
for annotation instead of relying on any alternate modality. Naturally, this
could mitigate the problems of the traditional human-in-the-loop approach.
Motivated by this observation, we perform a detailed study in this paper to
assess whether the state-of-the-art (SOTA) LLMs can be used as virtual
annotators for labeling time-series physical sensing data. To perform this in a
principled manner, we segregate the study into two major phases. In the first
phase, we investigate the challenges an LLM like GPT-4 faces in comprehending
raw sensor data. Considering the observations from phase 1, in the next phase,
we investigate the possibility of encoding the raw sensor data using SOTA SSL
approaches and utilizing the projected time-series data to get annotations from
the LLM. Detailed evaluation with four benchmark HAR datasets shows that
SSL-based encoding and metric-based guidance allow the LLM to make more
reasonable decisions and provide accurate annotations without requiring
computationally expensive fine-tuning or sophisticated prompt engineering.

中文翻译:
传统基于人工介入的惯性数据等时间序列标注方法，通常需要依赖环境中的视频或音频等多模态数据作为辅助。这些辅助数据为标注者提供了必要信息，因为原始数值数据即使对专家而言也往往过于晦涩难懂。然而这种传统方法在总体成本、效率、多模态存储、时间消耗、可扩展性和隐私保护等方面存在诸多问题。值得注意的是，当前大型语言模型（LLM）通过海量公开文本数据训练，已展现出超越自然语言处理任务的理解能力。这为探索LLM作为虚拟标注者提供了新思路——直接将原始传感器数据输入模型进行标注，而无需依赖其他模态数据，从而有望解决传统人工标注的固有缺陷。基于此，本文通过系统研究评估顶尖LLM模型作为时间序列物理感知数据虚拟标注者的可行性。研究采用两阶段框架：第一阶段揭示GPT-4等模型在理解原始传感器数据时面临的挑战；第二阶段结合自监督学习（SSL）编码技术，将投影后的时序数据输入LLM获取标注。在四个标准HAR数据集上的实验表明，基于SSL编码和度量引导的策略能使LLM做出更合理的判断，无需计算密集型微调或复杂提示工程即可实现精准标注。
