# Hardware Acceleration of LLMs: A comprehensive survey and comparison

链接: http://arxiv.org/abs/2409.03384v1

原文摘要:
Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. In this paper, we present a
comprehensive survey of the several research efforts that have been presented
for the acceleration of transformer networks for Large Language Models using
hardware accelerators.
  The survey presents the frameworks that have been proposed and then performs
a qualitative and quantitative comparison regarding the technology, the
processing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy
efficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each
framework. The main challenge in comparison is that every proposed scheme is
implemented on a different process technology making hard a fair comparison.
The main contribution of this paper is that we extrapolate the results of the
performance and the energy efficiency on the same technology to make a fair
comparison; one theoretical and one more practical. We implement part of the
LLMs on several FPGA chips to extrapolate the results to the same process
technology and then we make a fair comparison of the performance.

中文翻译:
大型语言模型（LLMs）已成为自然语言处理任务中的强大工具，其理解和生成类人文本的能力彻底改变了该领域。本文针对利用硬件加速器提升大型语言模型变压器网络性能的多种研究进行了系统性综述。  

综述首先梳理了现有加速框架，随后从技术路线、处理平台（FPGA、ASIC、存内计算、GPU）、加速比、能效比、运算性能（GOPs）及能效指标（GOPs/W）等维度展开定性与定量对比。研究面临的核心挑战在于：不同方案基于差异化的工艺节点实现，导致直接比较存在困难。  

本文的核心贡献在于通过技术归一化方法实现公平对比：我们采用理论推算与实践验证相结合的方式，将各方案性能与能效数据统一折算至相同工艺节点。具体而言，通过在多款FPGA芯片上实现LLM部分模块，将实验结果外推至相同工艺条件，最终建立起具有可比性的性能评估体系。
