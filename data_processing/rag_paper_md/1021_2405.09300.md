# Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support

链接: http://arxiv.org/abs/2405.09300v1

原文摘要:
Background: Rapid advancements in natural language processing have led to the
development of large language models with the potential to revolutionize mental
health care. These models have shown promise in assisting clinicians and
providing support to individuals experiencing various psychological challenges.
  Objective: This study aims to compare the performance of two large language
models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts,
to assess their potential applicability in mental health care settings.
  Methods: A blind methodology was employed, with a clinical psychologist
evaluating the models' responses without knowledge of their origins. The
prompts encompassed a diverse range of mental health topics, including
depression, anxiety, and trauma, to ensure a comprehensive assessment.
  Results: The results demonstrated a significant difference in performance
between the two models (p > 0.05). GPT-4 achieved an average rating of 8.29 out
of 10, while Chat-GPT received an average rating of 6.52. The clinical
psychologist's evaluation suggested that GPT-4 was more effective at generating
clinically relevant and empathetic responses, thereby providing better support
and guidance to potential users.
  Conclusions: This study contributes to the growing body of literature on the
applicability of large language models in mental health care settings. The
findings underscore the importance of continued research and development in the
field to optimize these models for clinical use. Further investigation is
necessary to understand the specific factors underlying the performance
differences between the two models and to explore their generalizability across
various populations and mental health conditions.

中文翻译:
背景：自然语言处理技术的快速发展催生了大型语言模型的诞生，这些模型有望为心理健康护理领域带来革命性变革。现有研究表明，这类模型在辅助临床医师工作、为面临各类心理困扰的个体提供支持方面展现出应用潜力。

目的：本研究通过对比GPT-4和Chat-GPT两款大型语言模型对18项心理提示词的反应表现，评估其在心理健康护理场景中的适用性。

方法：采用盲法评估设计，由临床心理学家在不知晓答案来源的情况下对模型回复进行评分。提示词涵盖抑郁、焦虑、创伤等多样化心理健康主题，以确保评估的全面性。

结果：两款模型表现存在显著差异(p>0.05)。GPT-4平均得分8.29分(满分10分)，显著高于Chat-GPT的6.52分。临床评估显示GPT-4在生成临床相关性强且具共情的回复方面更为出色，能为潜在用户提供更优质的支持与指导。

结论：本研究为大型语言模型在心理健康护理领域的适用性研究提供了新证据。研究结果强调需要持续优化面向临床应用的模型开发。未来需进一步探究影响模型性能差异的具体因素，并验证其在不同人群及心理健康状况中的普适性。
