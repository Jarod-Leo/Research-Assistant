# Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models

链接: http://arxiv.org/abs/2408.02085v1

原文摘要:
Instruction tuning plays a critical role in aligning large language models
(LLMs) with human preference. Despite the vast amount of open instruction
datasets, naively training a LLM on all existing instructions may not be
optimal and practical. To pinpoint the most beneficial datapoints, data
assessment and selection methods have been proposed in the fields of natural
language processing (NLP) and deep learning. However, under the context of
instruction tuning, there still exists a gap in knowledge on what kind of data
evaluation metrics can be employed and how they can be integrated into the
selection mechanism. To bridge this gap, we present a comprehensive review on
existing literature of data assessment and selection especially for instruction
tuning of LLMs. We systematically categorize all applicable methods into
quality-based, diversity-based, and importance-based ones where a unified,
fine-grained taxonomy is structured. For each category, representative methods
are elaborated to describe the landscape of relevant research. In addition,
comparison between the latest methods is conducted on their officially reported
results to provide in-depth discussions on their limitations. Finally, we
summarize the open challenges and propose the promosing avenues for future
studies. All related contents are available at
https://github.com/yuleiqin/fantastic-data-engineering.

中文翻译:
指令微调在将大语言模型（LLMs）与人类偏好对齐方面起着关键作用。尽管存在大量开放的指令数据集，简单地在所有现有指令上训练LLM可能并非最优或实用。为了精准识别最具价值的数据点，自然语言处理（NLP）和深度学习领域已提出多种数据评估与选择方法。然而在指令微调背景下，关于应采用何种数据评估指标及如何将其整合至选择机制中，仍存在认知空白。为填补这一空白，本文系统综述了面向LLM指令微调的数据评估与选择研究，将现有方法划分为质量导向型、多样性导向型和重要性导向型三大类，并构建了统一细粒度的分类体系。针对每种类别，详细阐述了代表性方法以展现相关研究全貌。此外，基于官方报告结果对前沿方法进行横向对比，深入探讨其局限性。最后总结当前面临的开放挑战，并指出未来研究的潜在方向。所有相关内容详见https://github.com/yuleiqin/fantastic-data-engineering。
