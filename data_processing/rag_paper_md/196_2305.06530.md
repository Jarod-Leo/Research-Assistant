# How Good are Commercial Large Language Models on African Languages?

链接: http://arxiv.org/abs/2305.06530v1

原文摘要:
Recent advancements in Natural Language Processing (NLP) has led to the
proliferation of large pretrained language models. These models have been shown
to yield good performance, using in-context learning, even on unseen tasks and
languages. They have also been exposed as commercial APIs as a form of
language-model-as-a-service, with great adoption. However, their performance on
African languages is largely unknown. We present a preliminary analysis of
commercial large language models on two tasks (machine translation and text
classification) across eight African languages, spanning different language
families and geographical areas. Our results suggest that commercial language
models produce below-par performance on African languages. We also find that
they perform better on text classification than machine translation. In
general, our findings present a call-to-action to ensure African languages are
well represented in commercial large language models, given their growing
popularity.

中文翻译:
自然语言处理（NLP）领域的最新进展促使大规模预训练语言模型迅速普及。研究表明，这些模型即使面对未见过的任务和语言，也能通过上下文学习展现出良好性能。它们还以语言模型即服务（LMaaS）的形式作为商业API开放，获得了广泛应用。然而，这些模型在非洲语言上的表现仍属未知领域。本文针对八种分属不同语系、分布在不同地理区域的非洲语言，对商业大语言模型在机器翻译和文本分类两项任务上的表现进行了初步分析。结果显示：商业语言模型对非洲语言的处理能力普遍低于基准水平；相较于机器翻译任务，模型在文本分类任务上表现更优。鉴于此类模型的日益流行，我们的发现为业界敲响了警钟——必须确保非洲语言在商业大语言模型中获得充分表征。
