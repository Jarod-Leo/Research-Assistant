# Conditioning LLMs with Emotion in Neural Machine Translation

链接: http://arxiv.org/abs/2408.03150v1

原文摘要:
Large Language Models (LLMs) have shown remarkable performance in Natural
Language Processing tasks, including Machine Translation (MT). In this work, we
propose a novel MT pipeline that integrates emotion information extracted from
a Speech Emotion Recognition (SER) model into LLMs to enhance translation
quality. We first fine-tune five existing LLMs on the Libri-trans dataset and
select the most performant model. Subsequently, we augment LLM prompts with
different dimensional emotions and train the selected LLM under these different
configurations. Our experiments reveal that integrating emotion information,
especially arousal, into LLM prompts leads to notable improvements in
translation quality.

中文翻译:
大型语言模型（LLMs）在自然语言处理任务中展现出卓越性能，包括机器翻译（MT）。本研究提出了一种创新的机器翻译流程，通过将从语音情感识别（SER）模型提取的情感信息融入LLMs来提升翻译质量。我们首先在Libri-trans数据集上对五种现有LLMs进行微调，并筛选出性能最优的模型。随后，通过将不同维度的情感特征融入LLM提示模板，我们在多种配置下对选定模型进行训练。实验结果表明，将情感信息（特别是唤醒度维度）整合至LLM提示中，能显著提升翻译质量。
