# ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model

链接: http://arxiv.org/abs/2403.06765v1

原文摘要:
The internet has brought both benefits and harms to society. A prime example
of the latter is misinformation, including conspiracy theories, which flood the
web. Recent advances in natural language processing, particularly the emergence
of large language models (LLMs), have improved the prospects of accurate
misinformation detection. However, most LLM-based approaches to conspiracy
theory detection focus only on binary classification and fail to account for
the important relationship between misinformation and affective features (i.e.,
sentiment and emotions). Driven by a comprehensive analysis of conspiracy text
that reveals its distinctive affective features, we propose ConspEmoLLM, the
first open-source LLM that integrates affective information and is able to
perform diverse tasks relating to conspiracy theories. These tasks include not
only conspiracy theory detection, but also classification of theory type and
detection of related discussion (e.g., opinions towards theories). ConspEmoLLM
is fine-tuned based on an emotion-oriented LLM using our novel ConDID dataset,
which includes five tasks to support LLM instruction tuning and evaluation. We
demonstrate that when applied to these tasks, ConspEmoLLM largely outperforms
several open-source general domain LLMs and ChatGPT, as well as an LLM that has
been fine-tuned using ConDID, but which does not use affective features. This
project will be released on https://github.com/lzw108/ConspEmoLLM/.

中文翻译:
互联网为社会带来了益处，同时也造成了危害，后者最典型的体现便是充斥网络的错误信息，包括阴谋论。自然语言处理技术的最新进展，尤其是大语言模型（LLMs）的出现，为提升错误信息检测的准确性带来了新机遇。然而，当前基于LLM的阴谋论检测方法大多仅关注二元分类，未能充分考虑错误信息与情感特征（即情绪与情感）之间的重要关联。通过对阴谋论文本的系统分析，我们发现其具有显著的情感特征差异，据此提出首个融合情感信息的开源大语言模型ConspEmoLLM。该模型不仅能进行阴谋论检测，还可完成理论类型分类、相关讨论识别（如对理论的评价）等多样化任务。我们基于情感导向的LLM，利用自主研发的ConDID数据集（包含五项支持LLM指令微调与评估的任务）对模型进行微调。实验表明，在各项任务中，ConspEmoLLM的性能显著优于多个开源通用领域LLM、ChatGPT以及未引入情感特征的ConDID微调模型。本项目代码将发布于https://github.com/lzw108/ConspEmoLLM/。
