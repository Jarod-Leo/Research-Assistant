# A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model

链接: http://arxiv.org/abs/2304.08109v2

原文摘要:
Recently, the instruction-tuning of large language models is a crucial area
of research in the field of natural language processing. Due to resource and
cost limitations, several researchers have employed parameter-efficient tuning
techniques, such as LoRA, for instruction tuning, and have obtained encouraging
results In comparison to full-parameter fine-tuning, LoRA-based tuning
demonstrates salient benefits in terms of training costs. In this study, we
undertook experimental comparisons between full-parameter fine-tuning and
LoRA-based tuning methods, utilizing LLaMA as the base model. The experimental
results show that the selection of the foundational model, training dataset
scale, learnable parameter quantity, and model training cost are all important
factors. We hope that the experimental conclusions of this paper can provide
inspiration for training large language models, especially in the field of
Chinese, and help researchers find a better trade-off strategy between training
cost and model performance. To facilitate the reproduction of the paper's
results, the dataset, model and code will be released.

中文翻译:
近年来，大型语言模型的指令微调已成为自然语言处理领域的重要研究方向。受限于资源与成本，部分研究者采用LoRA等参数高效调优技术进行指令微调，并取得了令人鼓舞的成果。相较于全参数微调，基于LoRA的调优方法在训练成本方面展现出显著优势。本研究以LLaMA为基础模型，通过实验对比了全参数微调与基于LoRA的调优方法。实验结果表明：基础模型的选择、训练数据集规模、可学习参数量以及模型训练成本均为重要影响因素。我们希望本文的实验结论能为大语言模型训练（尤其是中文领域）提供启发，助力研究者在训练成本与模型性能之间找到更优的权衡策略。为便于复现论文结果，相关数据集、模型及代码将予以开源。
