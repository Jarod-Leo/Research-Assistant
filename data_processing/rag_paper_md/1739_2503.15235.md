# Exploring Large Language Models for Word Games:Who is the Spy?

链接: http://arxiv.org/abs/2503.15235v1

原文摘要:
Word games hold significant research value for natural language processing
(NLP), game theory, and related fields due to their rule-based and situational
nature. This study explores how large language models (LLMs) can be effectively
involved in word games and proposes a training-free framework. "Shei Shi Wo Di"
or "Who is the Spy" in English, is a classic word game. Using this game as an
example, we introduce a Chain-of-Thought (CoT)-based scheduling framework to
enable LLMs to achieve excellent performance in tasks such as inferring role
words and disguising their identities. We evaluate the framework's performance
based on game success rates and the accuracy of the LLM agents' analytical
results. Experimental results affirm the framework's effectiveness,
demonstrating notable improvements in LLM performance across multiple datasets.
This work highlights the potential of LLMs in mastering situational reasoning
and social interactions within structured game environments. Our code is
publicly available at https://github.com/ct-wei/Who-is-The-Spy.

中文翻译:
文字游戏因其规则性与情境性特点，在自然语言处理（NLP）、博弈论及相关领域具有重要研究价值。本研究探索如何让大语言模型（LLMs）有效参与文字游戏，并提出一种免训练的实现框架。以经典游戏"谁是卧底"为例，我们引入基于思维链（CoT）的调度框架，使LLMs在推断角色词、伪装身份等任务中表现出色。通过游戏胜率与智能体分析结果准确率等指标评估框架性能，实验结果验证了该框架的有效性，在多个数据集上均使LLMs表现获得显著提升。这项工作展现了LLMs在结构化游戏环境中掌握情境推理与社交互动的潜力，相关代码已开源。
