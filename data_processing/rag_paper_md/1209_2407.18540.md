# A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models

链接: http://arxiv.org/abs/2407.18540v1

原文摘要:
Over the past decade, extensive research efforts have been dedicated to the
extraction of information from textual process descriptions. Despite the
remarkable progress witnessed in natural language processing (NLP), information
extraction within the Business Process Management domain remains predominantly
reliant on rule-based systems and machine learning methodologies. Data scarcity
has so far prevented the successful application of deep learning techniques.
However, the rapid progress in generative large language models (LLMs) makes it
possible to solve many NLP tasks with very high quality without the need for
extensive data. Therefore, we systematically investigate the potential of LLMs
for extracting information from textual process descriptions, targeting the
detection of process elements such as activities and actors, and relations
between them. Using a heuristic algorithm, we demonstrate the suitability of
the extracted information for process model generation. Based on a novel
prompting strategy, we show that LLMs are able to outperform state-of-the-art
machine learning approaches with absolute performance improvements of up to 8\%
$F_1$ score across three different datasets. We evaluate our prompting strategy
on eight different LLMs, showing it is universally applicable, while also
analyzing the impact of certain prompt parts on extraction quality. The number
of example texts, the specificity of definitions, and the rigour of format
instructions are identified as key for improving the accuracy of extracted
information. Our code, prompts, and data are publicly available.

中文翻译:
过去十年间，大量研究致力于从文本化流程描述中提取信息。尽管自然语言处理（NLP）领域取得了显著进展，但业务流程管理领域的信息提取仍主要依赖基于规则的系统与机器学习方法。数据稀缺问题迄今阻碍了深度学习技术的成功应用。然而，生成式大语言模型（LLMs）的快速发展使得无需大量数据即可高质量解决诸多NLP任务成为可能。为此，我们系统研究了LLMs从文本流程描述中提取信息的潜力，重点检测活动、参与者等流程要素及其相互关系。通过启发式算法，我们验证了所提取信息对流程模型生成的适用性。基于创新的提示策略，研究表明LLMs在三个不同数据集上能以高达8%的F1分数绝对优势超越现有最佳机器学习方法。我们在八种不同LLMs上评估了该提示策略，证明其具有普适性，同时分析了特定提示要素对提取质量的影响。研究发现示例文本数量、定义精确性及格式指令严谨度是提升信息提取准确性的关键因素。相关代码、提示模板及数据已公开。
