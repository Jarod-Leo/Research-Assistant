# Research and application of Transformer based anomaly detection model: A literature review

链接: http://arxiv.org/abs/2402.08975v1

原文摘要:
Transformer, as one of the most advanced neural network models in Natural
Language Processing (NLP), exhibits diverse applications in the field of
anomaly detection. To inspire research on Transformer-based anomaly detection,
this review offers a fresh perspective on the concept of anomaly detection. We
explore the current challenges of anomaly detection and provide detailed
insights into the operating principles of Transformer and its variants in
anomaly detection tasks. Additionally, we delineate various application
scenarios for Transformer-based anomaly detection models and discuss the
datasets and evaluation metrics employed. Furthermore, this review highlights
the key challenges in Transformer-based anomaly detection research and conducts
a comprehensive analysis of future research trends in this domain. The review
includes an extensive compilation of over 100 core references related to
Transformer-based anomaly detection. To the best of our knowledge, this is the
first comprehensive review that focuses on the research related to Transformer
in the context of anomaly detection. We hope that this paper can provide
detailed technical information to researchers interested in Transformer-based
anomaly detection tasks.

中文翻译:
Transformer作为自然语言处理领域最先进的神经网络模型之一，在异常检测领域展现出多样化应用。为启发基于Transformer的异常检测研究，本文对异常检测概念提出了全新视角解读，探讨了当前异常检测面临的挑战，并详细剖析了Transformer及其变体在异常检测任务中的工作原理。此外，我们系统梳理了基于Transformer的异常检测模型在不同场景下的应用范式，阐述了相关数据集与评估指标。本文进一步凝练了Transformer异常检测研究的关键挑战，并对该领域未来研究方向进行了全景式展望。本综述汇编了100余篇与Transformer异常检测相关的核心文献，据我们所知，这是首篇聚焦Transformer在异常检测领域研究的系统性综述，期望能为关注Transformer异常检测任务的研究者提供详尽的技术参考。
