# Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts

链接: http://arxiv.org/abs/2403.12918v1

原文摘要:
Pretrained Language Models (PLMs) have advanced Natural Language Processing
(NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses
significant challenges such as instability and overfitting. Previous methods
tackle these issues by finetuning a strategically chosen subnetwork on a
downstream task, while keeping the remaining weights fixed to the pretrained
weights. However, they rely on a suboptimal criteria for sub-network selection,
leading to suboptimal solutions. To address these limitations, we propose a
regularization method based on attention-guided weight mixup for finetuning
PLMs. Our approach represents each network weight as a mixup of task-specific
weight and pretrained weight, controlled by a learnable attention parameter,
providing finer control over sub-network selection. Furthermore, we employ a
bi-level optimization (BLO) based framework on two separate splits of the
training dataset, improving generalization and combating overfitting. We
validate the efficacy of our proposed method through extensive experiments,
demonstrating its superiority over previous methods, particularly in the
context of finetuning PLMs on low-resource datasets.

中文翻译:
预训练语言模型（PLMs）显著推动了自然语言处理（NLP）任务的进步，但在低资源数据集上微调PLMs时，模型不稳定和过拟合等问题尤为突出。现有方法通过在下游任务中微调策略性选取的子网络（其余权重保持预训练状态）来缓解这些挑战，但其子网络选择标准存在局限性，导致效果欠佳。为此，我们提出一种基于注意力引导权重混合的PLMs微调正则化方法。该方法将每个网络权重表示为任务特定权重与预训练权重的可学习注意力参数控制的混合形式，实现了对子网络选择的精细化调控。进一步地，我们在训练数据的两个独立子集上采用双层优化（BLO）框架，有效提升模型泛化能力并抑制过拟合。大量实验验证了所提方法的有效性，尤其在低资源数据集微调PLMs的场景中展现出超越现有方法的性能优势。
