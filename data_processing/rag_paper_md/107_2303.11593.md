# Difficulty in learning chirality for Transformer fed with SMILES

链接: http://arxiv.org/abs/2303.11593v1

原文摘要:
Recent years have seen rapid development of descriptor generation based on
representation learning of extremely diverse molecules, especially those that
apply natural language processing (NLP) models to SMILES, a literal
representation of molecular structure. However, little research has been done
on how these models understand chemical structure. To address this black box,
we investigated the relationship between the learning progress of SMILES and
chemical structure using a representative NLP model, the Transformer. We show
that while the Transformer learns partial structures of molecules quickly, it
requires extended training to understand overall structures. Consistently, the
accuracy of molecular property predictions using descriptors generated from
models at different learning steps was similar from the beginning to the end of
training. Furthermore, we found that the Transformer requires particularly long
training to learn chirality and sometimes stagnates with low performance due to
misunderstanding of enantiomers. These findings are expected to deepen the
understanding of NLP models in chemistry.

中文翻译:
近年来，基于海量分子表征学习的描述符生成技术发展迅猛，尤其是将自然语言处理（NLP）模型应用于SMILES（分子结构的字符串表示）的方法。然而，关于这些模型如何理解化学结构的研究却鲜有报道。为揭示这一"黑箱"机制，我们采用代表性NLP模型Transformer探究了SMILES学习进程与化学结构认知的关系。研究表明：Transformer能快速掌握分子的局部结构特征，但需要持续训练才能理解整体结构。相应地，在不同训练阶段生成的描述符进行分子性质预测时，其准确率从训练初期到后期始终维持相近水平。进一步发现该模型需要特别长的训练周期才能掌握手性特征，且常因对映体识别错误导致性能停滞在较低水平。这些发现有望深化对化学领域NLP模型工作机制的理解。
