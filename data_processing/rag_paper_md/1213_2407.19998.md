# Do LLMs Really Adapt to Domains? An Ontology Learning Perspective

链接: http://arxiv.org/abs/2407.19998v1

原文摘要:
Large Language Models (LLMs) have demonstrated unprecedented prowess across
various natural language processing tasks in various application domains.
Recent studies show that LLMs can be leveraged to perform lexical semantic
tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).
However, it has not effectively been verified whether their success is due to
their ability to reason over unstructured or semi-structured data, or their
effective learning of linguistic patterns and senses alone. This unresolved
question is particularly crucial when dealing with domain-specific data, where
the lexical senses and their meaning can completely differ from what a LLM has
learned during its training stage. This paper investigates the following
question: Do LLMs really adapt to domains and remain consistent in the
extraction of structured knowledge, or do they only learn lexical senses
instead of reasoning? To answer this question and, we devise a controlled
experiment setup that uses WordNet to synthesize parallel corpora, with English
and gibberish terms. We examine the differences in the outputs of LLMs for each
corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical
results show that, while adapting to the gibberish corpora, off-the-shelf LLMs
do not consistently reason over semantic relationships between concepts, and
instead leverage senses and their frame. However, fine-tuning improves the
performance of LLMs on lexical semantic tasks even when the domain-specific
terms are arbitrary and unseen during pre-training, hinting at the
applicability of pre-trained LLMs for OL.

中文翻译:
大型语言模型（LLMs）在多个应用领域的自然语言处理任务中展现出前所未有的能力。近期研究表明，LLMs可被用于执行词汇语义任务，如知识库补全（KBC）或本体学习（OL）。然而，其成功究竟源于对非结构化或半结构化数据的推理能力，还是仅依赖于对语言模式和词义的有效学习，尚未得到有效验证。这一未解问题在处理领域特定数据时尤为关键，因为此类数据的词汇语义可能与LLMs训练阶段所学内容截然不同。本文探究以下核心问题：LLMs是否真正能适应领域特性并在结构化知识抽取中保持一致性？抑或它们仅学习词汇语义而非真正进行推理？

为解答该问题，我们设计了一个受控实验框架：利用WordNet构建包含英语词汇与无意义术语的平行语料库。通过对比LLMs在两个OL任务（关系抽取与分类体系发现）中对不同语料库的输出差异，实证结果表明：现成LLMs在处理无意义语料时虽能适应，但并未持续保持对概念间语义关系的推理能力，而是依赖词汇框架及其表层意义。值得注意的是，微调能显著提升LLMs在词汇语义任务上的表现——即使领域术语在预训练阶段完全未出现过且具有任意性，这暗示了预训练LLMs在本体学习中的潜在适用性。
