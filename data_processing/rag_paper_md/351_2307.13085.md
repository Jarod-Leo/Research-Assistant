# Making Metadata More FAIR Using Large Language Models

链接: http://arxiv.org/abs/2307.13085v1

原文摘要:
With the global increase in experimental data artifacts, harnessing them in a
unified fashion leads to a major stumbling block - bad metadata. To bridge this
gap, this work presents a Natural Language Processing (NLP) informed
application, called FAIRMetaText, that compares metadata. Specifically,
FAIRMetaText analyzes the natural language descriptions of metadata and
provides a mathematical similarity measure between two terms. This measure can
then be utilized for analyzing varied metadata, by suggesting terms for
compliance or grouping similar terms for identification of replaceable terms.
The efficacy of the algorithm is presented qualitatively and quantitatively on
publicly available research artifacts and demonstrates large gains across
metadata related tasks through an in-depth study of a wide variety of Large
Language Models (LLMs). This software can drastically reduce the human effort
in sifting through various natural language metadata while employing several
experimental datasets on the same topic.

中文翻译:
随着全球实验数据资源的日益增多，如何统一利用这些资源面临一个主要障碍——低质量元数据。为解决这一问题，本研究开发了一款基于自然语言处理（NLP）的元数据比对应用FAIRMetaText。该工具通过分析元数据的自然语言描述，为两个术语提供数学化的相似度度量。该度量值可用于多样化元数据分析，既可推荐合规术语，也能通过聚类相似术语识别可替换项。我们通过公开研究资源对算法效能进行了定性与定量评估，并通过对多种大语言模型（LLM）的深入研究，证明了该工具在元数据相关任务中的显著优势。该软件能大幅减少研究人员在处理同一主题下多个实验数据集时筛选自然语言元数据的工作量。
