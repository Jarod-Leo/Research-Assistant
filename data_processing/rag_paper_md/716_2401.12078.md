# Temporal Blind Spots in Large Language Models

链接: http://arxiv.org/abs/2401.12078v1

原文摘要:
Large language models (LLMs) have recently gained significant attention due
to their unparalleled ability to perform various natural language processing
tasks. These models, benefiting from their advanced natural language
understanding capabilities, have demonstrated impressive zero-shot performance.
However, the pre-training data utilized in LLMs is often confined to a specific
corpus, resulting in inherent freshness and temporal scope limitations.
Consequently, this raises concerns regarding the effectiveness of LLMs for
tasks involving temporal intents. In this study, we aim to investigate the
underlying limitations of general-purpose LLMs when deployed for tasks that
require a temporal understanding. We pay particular attention to handling
factual temporal knowledge through three popular temporal QA datasets.
Specifically, we observe low performance on detailed questions about the past
and, surprisingly, for rather new information. In manual and automatic testing,
we find multiple temporal errors and characterize the conditions under which QA
performance deteriorates. Our analysis contributes to understanding LLM
limitations and offers valuable insights into developing future models that can
better cater to the demands of temporally-oriented tasks. The code is
available\footnote{https://github.com/jwallat/temporalblindspots}.

中文翻译:
以下是符合要求的学术摘要中文翻译：

大型语言模型（LLMs）近期因其执行多样化自然语言处理任务的卓越能力而备受关注。得益于先进的自然语言理解能力，这些模型展现出令人印象深刻的零样本性能。然而，由于LLMs所使用的预训练数据通常局限于特定语料库，其本质上存在时效性与时间范围的双重局限。这种情况引发了人们对LLMs在处理具有时间意图任务时有效性的担忧。本研究旨在探究通用型LLMs在需要时间理解能力的任务中存在的根本性局限。我们特别关注通过三个主流时序问答数据集来处理事实性时序知识的表现。研究发现：模型对历史细节问题的回答准确率较低，而令人惊讶的是，其对较新信息的处理同样不佳。通过人工与自动化测试，我们识别出多种时序错误类型，并系统归纳了导致问答性能下降的条件。本分析不仅有助于理解LLMs的局限性，更为开发能更好满足时序任务需求的未来模型提供了重要启示。相关代码已开源\footnote{https://github.com/jwallat/temporalblindspots}。

翻译说明：
1. 专业术语处理：LLMs统一译为"大型语言模型"并保留英文缩写，QA译为"问答"
2. 学术风格保持：使用"探究""识别""系统归纳"等学术动词，保持被动语态结构
3. 长句拆分重组：将原文复合句按中文习惯拆分为多个短句，如将"benefiting from..."独立成句
4. 逻辑显化处理：添加"研究发现"等过渡词明确行文逻辑
5. 文化适配调整："zero-shot"译为专业术语"零样本"，而非字面直译
6. 技术细节保留：完整保留数据集、测试方法等技术要素
7. 文献规范处理：严格保留原文脚注格式及超链接信息
