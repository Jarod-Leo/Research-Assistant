# Multitask Instruction-based Prompting for Fallacy Recognition

链接: http://arxiv.org/abs/2301.09992v1

原文摘要:
Fallacies are used as seemingly valid arguments to support a position and
persuade the audience about its validity. Recognizing fallacies is an
intrinsically difficult task both for humans and machines. Moreover, a big
challenge for computational models lies in the fact that fallacies are
formulated differently across the datasets with differences in the input format
(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,
social media, dialogue, news), as well as types and number of fallacies (from 5
to 18 types per dataset). To move towards solving the fallacy recognition task,
we approach these differences across datasets as multiple tasks and show how
instruction-based prompting in a multitask setup based on the T5 model improves
the results against approaches built for a specific dataset such as T5, BERT or
GPT-3. We show the ability of this multitask prompting approach to recognize 28
unique fallacies across domains and genres and study the effect of model size
and prompt choice by analyzing the per-class (i.e., fallacy type) results.
Finally, we analyze the effect of annotation quality on model performance, and
the feasibility of complementing this approach with external knowledge.

中文翻译:
谬误常被用作看似有效的论据来支持某种立场，并说服受众相信其合理性。无论是人类还是机器，识别谬误本质上都是一项极具挑战性的任务。对计算模型而言，更大的困难在于不同数据集中的谬误表述存在显著差异：输入格式（如问答对、含谬误片段的句子）、文本类型（如社交媒体、对话、新闻）以及谬误种类和数量（各数据集涵盖5至18种谬误类型）均不相同。为推进谬误识别任务的研究，我们将这些数据集差异视为多任务处理问题，并证明基于T5模型的多任务指令提示方法相较于T5、BERT或GPT-3等针对单一数据集构建的模型具有性能优势。实验表明，这种多任务提示方法能有效识别跨领域、跨文本类型的28种独特谬误，同时通过分析分类（即谬误类型）结果，探究了模型规模和提示选择的影响。最后，我们评估了标注质量对模型性能的影响，并探讨了结合外部知识增强该方法的可行性。
