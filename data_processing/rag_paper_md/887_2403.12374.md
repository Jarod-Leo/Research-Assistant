# Improving Generalizability of Extracting Social Determinants of Health Using Large Language Models through Prompt-tuning

链接: http://arxiv.org/abs/2403.12374v1

原文摘要:
The progress in natural language processing (NLP) using large language models
(LLMs) has greatly improved patient information extraction from clinical
narratives. However, most methods based on the fine-tuning strategy have
limited transfer learning ability for cross-domain applications. This study
proposed a novel approach that employs a soft prompt-based learning
architecture, which introduces trainable prompts to guide LLMs toward desired
outputs. We examined two types of LLM architectures, including encoder-only
GatorTron and decoder-only GatorTronGPT, and evaluated their performance for
the extraction of social determinants of health (SDoH) using a
cross-institution dataset from the 2022 n2c2 challenge and a cross-disease
dataset from the University of Florida (UF) Health. The results show that
decoder-only LLMs with prompt tuning achieved better performance in
cross-domain applications. GatorTronGPT achieved the best F1 scores for both
datasets, outperforming traditional fine-tuned GatorTron by 8.9% and 21.8% in a
cross-institution setting, and 5.5% and 14.5% in a cross-disease setting.

中文翻译:
利用大型语言模型（LLM）的自然语言处理（NLP）进展显著提升了从临床叙述中提取患者信息的能力。然而，基于微调策略的方法在跨领域应用中的迁移学习能力有限。本研究提出了一种新颖的软提示学习架构，通过引入可训练提示来引导LLM生成目标输出。我们测试了两种LLM架构——仅编码器的GatorTron和仅解码器的GatorTronGPT，并采用2022年n2c2挑战赛的跨机构数据集与佛罗里达大学（UF）健康的跨疾病数据集评估其在健康社会决定因素（SDoH）提取中的表现。结果表明，采用提示调优的仅解码器LLM在跨领域应用中表现更优。GatorTronGPT在两个数据集上均取得最佳F1分数：在跨机构场景中分别超越传统微调GatorTron模型8.9%和21.8%，在跨疾病场景中分别领先5.5%和14.5%。
