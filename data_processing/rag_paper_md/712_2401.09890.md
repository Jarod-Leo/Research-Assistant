# A Survey on Hardware Accelerators for Large Language Models

链接: http://arxiv.org/abs/2401.09890v1

原文摘要:
Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. As the demand for more sophisticated
LLMs continues to grow, there is a pressing need to address the computational
challenges associated with their scale and complexity. This paper presents a
comprehensive survey on hardware accelerators designed to enhance the
performance and energy efficiency of Large Language Models. By examining a
diverse range of accelerators, including GPUs, FPGAs, and custom-designed
architectures, we explore the landscape of hardware solutions tailored to meet
the unique computational demands of LLMs. The survey encompasses an in-depth
analysis of architecture, performance metrics, and energy efficiency
considerations, providing valuable insights for researchers, engineers, and
decision-makers aiming to optimize the deployment of LLMs in real-world
applications.

中文翻译:
以下是符合学术规范的中文翻译：

大型语言模型（LLMs）已成为自然语言处理领域的强大工具，其理解和生成类人文本的能力正在重塑该领域的技术格局。随着对复杂LLMs需求的持续增长，亟需解决其规模与复杂性带来的计算挑战。本文系统综述了旨在提升大型语言模型性能与能效的硬件加速器技术，通过考察包括GPU、FPGA及定制架构在内的多样化加速方案，深入探索了针对LLMs独特计算需求而设计的硬件解决方案全景。本综述涵盖架构设计、性能指标与能效考量等多维度的深度分析，为致力于优化LLMs实际应用部署的研究人员、工程师及决策者提供了重要参考依据。

翻译说明：
1. 专业术语处理：保留"LLMs"英文缩写并添加中文全称，技术术语（如FPGA）采用业界通用译法
2. 句式重构：将英文长句拆分为符合中文表达习惯的短句，如将"revolutionizing..."处理为独立分句
3. 学术风格：使用"系统综述""技术格局""多维度的深度分析"等符合学术论文表达的措辞
4. 逻辑显化：将"there is a pressing need"译为"亟需"，"aiming to"转化为"致力于"等动词结构，增强文本动感
5. 术语统一：全篇保持"加速器""能效""部署"等关键术语的一致性
