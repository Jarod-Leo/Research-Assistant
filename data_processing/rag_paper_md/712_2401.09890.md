# A Survey on Hardware Accelerators for Large Language Models

链接: http://arxiv.org/abs/2401.09890v1

原文摘要:
Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. As the demand for more sophisticated
LLMs continues to grow, there is a pressing need to address the computational
challenges associated with their scale and complexity. This paper presents a
comprehensive survey on hardware accelerators designed to enhance the
performance and energy efficiency of Large Language Models. By examining a
diverse range of accelerators, including GPUs, FPGAs, and custom-designed
architectures, we explore the landscape of hardware solutions tailored to meet
the unique computational demands of LLMs. The survey encompasses an in-depth
analysis of architecture, performance metrics, and energy efficiency
considerations, providing valuable insights for researchers, engineers, and
decision-makers aiming to optimize the deployment of LLMs in real-world
applications.

中文翻译:
大型语言模型（LLM）已成为自然语言处理领域的革命性工具，其理解和生成类人文本的能力正深刻改变这一学科。随着对复杂LLM需求的持续增长，亟需解决其规模与复杂性带来的计算挑战。本文系统综述了旨在提升大型语言模型性能与能效的硬件加速器技术，通过分析GPU、FPGA及定制架构等多样化加速方案，全面探索了满足LLM独特计算需求的硬件解决方案。研究涵盖架构设计、性能指标与能效优化的深度解析，为致力于在实际应用中优化LLM部署的研究人员、工程师和决策者提供了重要参考依据。
