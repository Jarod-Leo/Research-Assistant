# Equipping Pretrained Unconditional Music Transformers with Instrument and Genre Controls

链接: http://arxiv.org/abs/2311.12257v1

原文摘要:
The ''pretraining-and-finetuning'' paradigm has become a norm for training
domain-specific models in natural language processing and computer vision. In
this work, we aim to examine this paradigm for symbolic music generation
through leveraging the largest ever symbolic music dataset sourced from the
MuseScore forum. We first pretrain a large unconditional transformer model
using 1.5 million songs. We then propose a simple technique to equip this
pretrained unconditional music transformer model with instrument and genre
controls by finetuning the model with additional control tokens. Our proposed
representation offers improved high-level controllability and expressiveness
against two existing representations. The experimental results show that the
proposed model can successfully generate music with user-specified instruments
and genre. In a subjective listening test, the proposed model outperforms the
pretrained baseline model in terms of coherence, harmony, arrangement and
overall quality.

中文翻译:
“预训练-微调”范式已成为自然语言处理和计算机视觉领域训练专用模型的常规方法。本研究旨在通过利用源自MuseScore论坛、迄今规模最大的符号音乐数据集，验证该范式在符号音乐生成中的适用性。我们首先使用150万首乐曲预训练了一个大型无条件Transformer模型，随后提出一种简单技术：通过添加控制标记进行微调，使这个预训练的无条件音乐生成模型具备乐器与流派控制能力。相较于两种现有表征方法，我们提出的表征方案在高层可控性和表现力方面均有提升。实验结果表明，该模型能成功生成符合用户指定乐器与流派的音乐作品。主观听音测试显示，在连贯性、和声效果、编曲质量及整体表现上，本模型均优于预训练基线模型。
