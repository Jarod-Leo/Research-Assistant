# Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers

链接: http://arxiv.org/abs/2304.09948v1

原文摘要:
The proliferation of fake reviews of doctors has potentially detrimental
consequences for patient well-being and has prompted concern among consumer
protection groups and regulatory bodies. Yet despite significant advancements
in the fields of machine learning and natural language processing, there
remains limited comprehension of the characteristics differentiating fraudulent
from authentic reviews. This study utilizes a novel pre-labeled dataset of
38048 physician reviews to establish the effectiveness of large language models
in classifying reviews. Specifically, we compare the performance of traditional
ML models, such as logistic regression and support vector machines, to
generative pre-trained transformer models. Furthermore, we use GPT4, the newest
model in the GPT family, to uncover the key dimensions along which fake and
genuine physician reviews differ. Our findings reveal significantly superior
performance of GPT-3 over traditional ML models in this context. Additionally,
our analysis suggests that GPT3 requires a smaller training sample than
traditional models, suggesting its appropriateness for tasks with scarce
training data. Moreover, the superiority of GPT3 performance increases in the
cold start context i.e., when there are no prior reviews of a doctor. Finally,
we employ GPT4 to reveal the crucial dimensions that distinguish fake physician
reviews. In sharp contrast to previous findings in the literature that were
obtained using simulated data, our findings from a real-world dataset show that
fake reviews are generally more clinically detailed, more reserved in
sentiment, and have better structure and grammar than authentic ones.

中文翻译:
医生虚假评论的泛滥可能对患者健康造成潜在危害，已引发消费者保护组织和监管机构的高度关注。尽管机器学习和自然语言处理领域取得了重大进展，但学界对虚假评论与真实评论的区分特征仍缺乏深入理解。本研究采用包含38048条预标注医生评论的新型数据集，验证了大语言模型在评论分类中的有效性。我们系统比较了逻辑回归、支持向量机等传统机器学习模型与生成式预训练变换模型的性能差异，并运用GPT家族最新模型GPT4揭示了虚假医生评论的关键区分维度。

研究发现：在医生评论分类任务中，GPT-3模型性能显著优于传统机器学习模型；相较于传统模型，GPT-3所需训练样本量更少，表明其特别适用于训练数据稀缺的场景；当面临冷启动情境（即医生无历史评论记录）时，GPT-3的性能优势更为突出。通过GPT4的深度分析，我们基于真实世界数据得出了与既往文献使用模拟数据截然不同的结论：虚假评论通常比真实评论包含更详尽的临床细节、情感表达更为克制，且具有更优的结构组织与语法规范。
