# Identification of Knowledge Neurons in Protein Language Models

链接: http://arxiv.org/abs/2312.10770v1

原文摘要:
Neural language models have become powerful tools for learning complex
representations of entities in natural language processing tasks. However,
their interpretability remains a significant challenge, particularly in domains
like computational biology where trust in model predictions is crucial. In this
work, we aim to enhance the interpretability of protein language models,
specifically the state-of-the-art ESM model, by identifying and characterizing
knowledge neurons - components that express understanding of key information.
After fine-tuning the ESM model for the task of enzyme sequence classification,
we compare two knowledge neuron selection methods that preserve a subset of
neurons from the original model. The two methods, activation-based and
integrated gradient-based selection, consistently outperform a random baseline.
In particular, these methods show that there is a high density of knowledge
neurons in the key vector prediction networks of self-attention modules. Given
that key vectors specialize in understanding different features of input
sequences, these knowledge neurons could capture knowledge of different enzyme
sequence motifs. In the future, the types of knowledge captured by each neuron
could be characterized.

中文翻译:
神经语言模型已成为自然语言处理任务中学习实体复杂表征的强大工具。然而其可解释性仍面临重大挑战，尤其在计算生物学等需要高度信任模型预测的领域。本研究旨在通过识别和表征知识神经元——那些表达关键信息理解能力的组件，来增强蛋白质语言模型（特别是最先进的ESM模型）的可解释性。在对ESM模型进行酶序列分类任务的微调后，我们比较了两种保留原始模型神经元子集的知识神经元选择方法。基于激活度和基于积分梯度的选择方法均显著优于随机基线，尤其揭示了自注意力模块中关键向量预测网络存在高密度的知识神经元。鉴于关键向量专门用于理解输入序列的不同特征，这些知识神经元可能捕获了不同酶序列模式的知识。未来可进一步表征每个神经元所捕获的知识类型。
