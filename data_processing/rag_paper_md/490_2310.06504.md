# Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task

链接: http://arxiv.org/abs/2310.06504v1

原文摘要:
With the increasing capabilities of large language models (LLMs), these
high-performance models have achieved state-of-the-art results on a wide range
of natural language processing (NLP) tasks. However, the models' performance on
commonly-used benchmark datasets often fails to accurately reflect their
reliability and robustness when applied to real-world noisy data. To address
these challenges, we propose a unified robustness evaluation framework based on
the slot-filling task to systematically evaluate the dialogue understanding
capability of LLMs in diverse input perturbation scenarios. Specifically, we
construct a input perturbation evaluation dataset, Noise-LLM, which contains
five types of single perturbation and four types of mixed perturbation data.
Furthermore, we utilize a multi-level data augmentation method (character,
word, and sentence levels) to construct a candidate data pool, and carefully
design two ways of automatic task demonstration construction strategies
(instance-level and entity-level) with various prompt templates. Our aim is to
assess how well various robustness methods of LLMs perform in real-world noisy
scenarios. The experiments have demonstrated that the current open-source LLMs
generally achieve limited perturbation robustness performance. Based on these
experimental observations, we make some forward-looking suggestions to fuel the
research in this direction.

中文翻译:
随着大语言模型(LLMs)能力的不断提升，这些高性能模型在各类自然语言处理任务中取得了最先进的成果。然而，这些模型在常用基准数据集上的表现往往无法准确反映其应用于现实世界噪声数据时的可靠性和鲁棒性。针对这些问题，我们提出了基于槽填充任务的统一鲁棒性评估框架，系统性地评估LLMs在多样化输入扰动场景下的对话理解能力。具体而言，我们构建了包含五类单一扰动和四类混合扰动数据的输入扰动评估数据集Noise-LLM，并采用字符级、词语级和句子级的多层次数据增强方法构建候选数据池。此外，我们精心设计了两类自动任务演示构建策略（实例级和实体级）及多种提示模板，旨在评估LLMs各类鲁棒性方法在真实噪声场景中的表现。实验表明当前开源LLMs普遍取得的扰动鲁棒性表现有限。基于这些实验观察，我们提出了若干前瞻性建议以推动该方向的研究发展。
