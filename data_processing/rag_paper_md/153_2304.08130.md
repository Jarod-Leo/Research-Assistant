# A Survey on Few-Shot Class-Incremental Learning

链接: http://arxiv.org/abs/2304.08130v1

原文摘要:
Large deep learning models are impressive, but they struggle when real-time
data is not available. Few-shot class-incremental learning (FSCIL) poses a
significant challenge for deep neural networks to learn new tasks from just a
few labeled samples without forgetting the previously learned ones. This setup
easily leads to catastrophic forgetting and overfitting problems, severely
affecting model performance. Studying FSCIL helps overcome deep learning model
limitations on data volume and acquisition time, while improving practicality
and adaptability of machine learning models. This paper provides a
comprehensive survey on FSCIL. Unlike previous surveys, we aim to synthesize
few-shot learning and incremental learning, focusing on introducing FSCIL from
two perspectives, while reviewing over 30 theoretical research studies and more
than 20 applied research studies. From the theoretical perspective, we provide
a novel categorization approach that divides the field into five subcategories,
including traditional machine learning methods, meta-learning based methods,
feature and feature space-based methods, replay-based methods, and dynamic
network structure-based methods. We also evaluate the performance of recent
theoretical research on benchmark datasets of FSCIL. From the application
perspective, FSCIL has achieved impressive achievements in various fields of
computer vision such as image classification, object detection, and image
segmentation, as well as in natural language processing and graph. We summarize
the important applications. Finally, we point out potential future research
directions, including applications, problem setups, and theory development.
Overall, this paper offers a comprehensive analysis of the latest advances in
FSCIL from a methodological, performance, and application perspective.

中文翻译:
大规模深度学习模型表现卓越，但在实时数据缺失时往往表现不佳。小样本类增量学习（FSCIL）对深度神经网络提出了重大挑战——要求仅用少量标注样本学习新任务的同时不遗忘已学知识。这种设定极易引发灾难性遗忘和过拟合问题，严重影响模型性能。研究FSCIL有助于克服深度学习模型在数据量和获取时间上的局限，同时提升机器学习模型的实用性和适应性。本文对FSCIL进行了全面综述：不同于以往综述，我们旨在融合小样本学习与增量学习，重点从两个视角切入介绍FSCIL，同时回顾了30余项理论研究和20余项应用研究。从理论视角，我们提出新颖的分类方法，将该领域划分为传统机器学习方法、基于元学习的方法、基于特征与特征空间的方法、基于回放的方法和基于动态网络结构的方法五大子类，并评估了近期理论研究在FSCIL基准数据集上的性能表现。从应用视角，FSCIL在图像分类、目标检测、图像分割等计算机视觉各领域，以及自然语言处理和图结构领域均取得显著成果，我们对此进行了重点应用总结。最后我们指出未来潜在研究方向，包括应用场景、问题设定和理论发展等方面。总体而言，本文从方法、性能和应用三个维度对FSCIL的最新进展进行了全面解析。
