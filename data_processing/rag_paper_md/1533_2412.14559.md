# ScaMo: Exploring the Scaling Law in Autoregressive Motion Generation Model

链接: http://arxiv.org/abs/2412.14559v1

原文摘要:
The scaling law has been validated in various domains, such as natural
language processing (NLP) and massive computer vision tasks; however, its
application to motion generation remains largely unexplored. In this paper, we
introduce a scalable motion generation framework that includes the motion
tokenizer Motion FSQ-VAE and a text-prefix autoregressive transformer. Through
comprehensive experiments, we observe the scaling behavior of this system. For
the first time, we confirm the existence of scaling laws within the context of
motion generation. Specifically, our results demonstrate that the normalized
test loss of our prefix autoregressive models adheres to a logarithmic law in
relation to compute budgets. Furthermore, we also confirm the power law between
Non-Vocabulary Parameters, Vocabulary Parameters, and Data Tokens with respect
to compute budgets respectively. Leveraging the scaling law, we predict the
optimal transformer size, vocabulary size, and data requirements for a compute
budget of $1e18$. The test loss of the system, when trained with the optimal
model size, vocabulary size, and required data, aligns precisely with the
predicted test loss, thereby validating the scaling law.

中文翻译:
尺度定律已在自然语言处理（NLP）和大规模计算机视觉任务等多个领域得到验证，但其在动作生成中的应用仍鲜有探索。本文提出一个可扩展的动作生成框架，包含动作分词器Motion FSQ-VAE和文本前缀自回归变换器。通过系统性实验，我们观察到该框架的尺度化规律，首次证实了动作生成领域存在尺度定律。具体而言，结果表明：1）前缀自回归模型的归一化测试损失与计算预算呈对数规律；2）非词汇参数量、词汇参数量和数据令牌量分别与计算预算之间存在幂律关系。基于尺度定律，我们预测了1e18计算预算下最优变换器规模、词汇表大小及数据需求。当采用最优模型规模、词汇量及对应数据训练时，系统测试损失与预测值完全吻合，从而验证了尺度定律的有效性。
