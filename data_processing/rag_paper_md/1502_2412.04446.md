# DiCoDe: Diffusion-Compressed Deep Tokens for Autoregressive Video Generation with Language Models

链接: http://arxiv.org/abs/2412.04446v1

原文摘要:
Videos are inherently temporal sequences by their very nature. In this work,
we explore the potential of modeling videos in a chronological and scalable
manner with autoregressive (AR) language models, inspired by their success in
natural language processing. We introduce DiCoDe, a novel approach that
leverages Diffusion-Compressed Deep Tokens to generate videos with a language
model in an autoregressive manner. Unlike existing methods that employ
low-level representations with limited compression rates, DiCoDe utilizes deep
tokens with a considerable compression rate (a 1000x reduction in token count).
This significant compression is made possible by a tokenizer trained through
leveraging the prior knowledge of video diffusion models. Deep tokens enable
DiCoDe to employ vanilla AR language models for video generation, akin to
translating one visual "language" into another. By treating videos as temporal
sequences, DiCoDe fully harnesses the capabilities of language models for
autoregressive generation. DiCoDe is scalable using readily available AR
architectures, and is capable of generating videos ranging from a few seconds
to one minute using only 4 A100 GPUs for training. We evaluate DiCoDe both
quantitatively and qualitatively, demonstrating that it performs comparably to
existing methods in terms of quality while ensuring efficient training. To
showcase its scalability, we release a series of DiCoDe configurations with
varying parameter sizes and observe a consistent improvement in performance as
the model size increases from 100M to 3B. We believe that DiCoDe's exploration
in academia represents a promising initial step toward scalable video modeling
with AR language models, paving the way for the development of larger and more
powerful video generation models.

中文翻译:
视频本质上是时间序列的载体。本研究受自回归（AR）语言模型在自然语言处理领域的成功启发，探索了按时间顺序、可扩展建模视频的潜力。我们提出DiCoDe这一创新方法，通过扩散压缩深度令牌（Diffusion-Compressed Deep Tokens）实现语言模型的自回归视频生成。与现有采用低压缩率低级表示的方法不同，DiCoDe利用具有显著压缩率（令牌数量减少1000倍）的深度令牌，这种高效压缩通过结合视频扩散模型先验知识训练的令牌生成器实现。深度令牌使DiCoDe能像转换视觉"语言"般，使用标准AR语言模型进行视频生成。通过将视频视为时间序列，DiCoDe充分发挥了语言模型的自回归生成能力。该方法具有高度可扩展性，仅需4块A100 GPU即可训练生成数秒至一分钟的视频。定量与定性评估表明，DiCoDe在保证训练效率的同时，生成质量与现有方法相当。为验证其扩展性，我们发布了参数规模从1亿到30亿不等的系列配置，观察到模型性能随规模增长持续提升。我们认为DiCoDe在学术界的探索标志着AR语言模型迈向可扩展视频建模的重要第一步，为开发更强大视频生成模型开辟了新路径。
