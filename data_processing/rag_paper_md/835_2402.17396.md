# Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies

链接: http://arxiv.org/abs/2402.17396v1

原文摘要:
Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing thanks to their ability to reuse knowledge acquired on
massive text corpora on a wide variety of downstream tasks, with minimal (if
any) tuning steps. At the same time, it has been repeatedly shown that LLMs
lack systematic generalization, which allows to extrapolate the learned
statistical regularities outside the training distribution. In this work, we
offer a systematic benchmarking of GPT-4, one of the most advanced LLMs
available, on three algorithmic tasks characterized by the possibility to
control the problem difficulty with two parameters. We compare the performance
of GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the
Transformer-Encoder architecture recently introduced to solve similar tasks,
the Neural Data Router. We find that the deployment of advanced prompting
techniques allows GPT-4 to reach superior accuracy on all tasks, demonstrating
that state-of-the-art LLMs constitute a very strong baseline also in
challenging tasks that require systematic generalization.

中文翻译:
大型语言模型（LLMs）通过其在大规模文本语料库上获取的知识能够广泛迁移至各类下游任务，且仅需极少（甚至无需）调优步骤，从而彻底改变了自然语言处理领域。然而，研究也多次表明LLMs缺乏系统性泛化能力，即无法将习得的统计规律外推至训练分布之外。本研究针对当前最先进的LLM之一GPT-4，在三个可通过双参数控制问题难度的算法任务上进行了系统性基准测试。我们将GPT-4的表现与其前代模型（GPT-3.5）以及专为类似任务设计的Transformer-Encoder架构变体——神经数据路由器（Neural Data Router）进行对比。研究发现，采用先进提示技术后，GPT-4在所有任务上均展现出更高的准确率，这表明即使在需要系统性泛化的挑战性任务中，最先进的LLMs也能成为极具竞争力的基准模型。
