# Transformers in Speech Processing: A Survey

链接: http://arxiv.org/abs/2303.11607v1

原文摘要:
The remarkable success of transformers in the field of natural language
processing has sparked the interest of the speech-processing community, leading
to an exploration of their potential for modeling long-range dependencies
within speech sequences. Recently, transformers have gained prominence across
various speech-related domains, including automatic speech recognition, speech
synthesis, speech translation, speech para-linguistics, speech enhancement,
spoken dialogue systems, and numerous multimodal applications. In this paper,
we present a comprehensive survey that aims to bridge research studies from
diverse subfields within speech technology. By consolidating findings from
across the speech technology landscape, we provide a valuable resource for
researchers interested in harnessing the power of transformers to advance the
field. We identify the challenges encountered by transformers in speech
processing while also offering insights into potential solutions to address
these issues.

中文翻译:
Transformer模型在自然语言处理领域的显著成功激发了语音处理界的广泛兴趣，促使研究者探索其建模语音序列长程依赖关系的潜力。近年来，该架构已在自动语音识别、语音合成、语音翻译、副语言学分析、语音增强、口语对话系统及多模态应用等众多语音相关领域崭露头角。本文通过系统梳理语音技术各子领域的研究成果，旨在构建跨学科的研究桥梁，为致力于运用Transformer推动领域发展的学者提供重要参考。我们在剖析Transformer应用于语音处理所面临挑战的同时，也针对性地提出了解决这些关键问题的潜在路径。
