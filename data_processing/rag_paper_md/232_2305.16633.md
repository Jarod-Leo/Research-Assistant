# Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks

链接: http://arxiv.org/abs/2305.16633v1

原文摘要:
Recently large language models (LLMs) like ChatGPT have shown impressive
performance on many natural language processing tasks with zero-shot. In this
paper, we investigate the effectiveness of zero-shot LLMs in the financial
domain. We compare the performance of ChatGPT along with some open-source
generative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We
address three inter-related research questions on data annotation, performance
gaps, and the feasibility of employing generative models in the finance domain.
Our findings demonstrate that ChatGPT performs well even without labeled data
but fine-tuned models generally outperform it. Our research also highlights how
annotating with generative models can be time-intensive. Our codebase is
publicly available on GitHub under CC BY-NC 4.0 license.

中文翻译:
近期，以ChatGPT为代表的大语言模型（LLM）在零样本学习场景下展现出卓越的自然语言处理能力。本文针对金融领域，系统评估了零样本模式下生成式大语言模型的实际效能。我们对比了ChatGPT及若干开源生成式LLM与基于标注数据微调的RoBERTa模型的表现，重点探究了三大核心问题：数据标注机制、性能差异成因，以及生成式模型在金融领域的适用性。实验结果表明，ChatGPT在无标注数据条件下表现优异，但微调模型仍普遍占据优势。研究同时揭示了使用生成式模型进行数据标注存在耗时较长的局限性。本研究成果代码库已在GitHub平台公开，采用CC BY-NC 4.0许可协议。
