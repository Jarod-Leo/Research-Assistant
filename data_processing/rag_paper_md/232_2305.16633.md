# Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for Financial Tasks

链接: http://arxiv.org/abs/2305.16633v1

原文摘要:
Recently large language models (LLMs) like ChatGPT have shown impressive
performance on many natural language processing tasks with zero-shot. In this
paper, we investigate the effectiveness of zero-shot LLMs in the financial
domain. We compare the performance of ChatGPT along with some open-source
generative LLMs in zero-shot mode with RoBERTa fine-tuned on annotated data. We
address three inter-related research questions on data annotation, performance
gaps, and the feasibility of employing generative models in the finance domain.
Our findings demonstrate that ChatGPT performs well even without labeled data
but fine-tuned models generally outperform it. Our research also highlights how
annotating with generative models can be time-intensive. Our codebase is
publicly available on GitHub under CC BY-NC 4.0 license.

中文翻译:
近期，以ChatGPT为代表的大语言模型（LLM）在零样本设定下展现出卓越的自然语言处理能力。本文聚焦金融领域，系统评估了零样本LLM的实际应用效果。通过对比ChatGPT及开源生成式LLM在零样本模式下的表现与基于标注数据微调的RoBERTa模型，我们深入探讨了三个核心问题：数据标注效率、性能差距成因以及生成式模型在金融领域的适用性。研究发现：1）ChatGPT在无标注数据时表现良好，但微调模型普遍更优；2）利用生成式模型进行数据标注存在显著的时间成本。本研究代码库已依据CC BY-NC 4.0协议在GitHub开源。
