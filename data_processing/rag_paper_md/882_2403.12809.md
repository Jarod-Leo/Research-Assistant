# Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models

链接: http://arxiv.org/abs/2403.12809v1

原文摘要:
In many real natural language processing application scenarios, practitioners
not only aim to maximize predictive performance but also seek faithful
explanations for the model predictions. Rationales and importance distribution
given by feature attribution methods (FAs) provide insights into how different
parts of the input contribute to a prediction. Previous studies have explored
how different factors affect faithfulness, mainly in the context of monolingual
English models. On the other hand, the differences in FA faithfulness between
multilingual and monolingual models have yet to be explored. Our extensive
experiments, covering five languages and five popular FAs, show that FA
faithfulness varies between multilingual and monolingual models. We find that
the larger the multilingual model, the less faithful the FAs are compared to
its counterpart monolingual models.Our further analysis shows that the
faithfulness disparity is potentially driven by the differences between model
tokenizers. Our code is available:
https://github.com/casszhao/multilingual-faith.

中文翻译:
在许多现实的自然语言处理应用场景中，实践者不仅追求预测性能的最大化，同时也需要为模型预测寻求可信的解释。特征归因方法（FAs）提供的依据和重要性分布，能够揭示输入文本的不同部分如何影响预测结果。先前的研究主要针对单语英语模型，探讨了不同因素对解释可信度的影响。然而，多语言模型与单语模型在特征归因可信度方面的差异尚未得到充分研究。我们通过涵盖五种语言和五种主流特征归因方法的大规模实验发现：多语言模型的特征归因可信度与单语模型存在显著差异。研究结果表明，多语言模型的规模越大，其特征归因可信度相较于同类单语模型就越低。进一步分析表明，这种可信度差异可能源于模型分词器的特性差异。代码已开源：
https://github.com/casszhao/multilingual-faith

（翻译说明：
1. 专业术语处理："faithfulness"译为"可信度"以符合机器学习领域表述，"tokenizers"统一译为"分词器"
2. 句式重构：将原文复合长句拆分为符合中文表达习惯的短句，如将"Rationales and importance distribution..."处理为因果句式
3. 逻辑显化：通过"研究结果表明"等过渡词明确原文隐含的因果关系
4. 被动语态转换："have yet to be explored"主动化为"尚未得到充分研究"
5. 数据呈现：精确保留"五种语言和五种主流特征归因方法"的量化信息
6. 技术概念一致性：保持"特征归因方法（FAs）"的术语统一性）
