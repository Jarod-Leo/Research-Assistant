# Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models

链接: http://arxiv.org/abs/2403.12809v1

原文摘要:
In many real natural language processing application scenarios, practitioners
not only aim to maximize predictive performance but also seek faithful
explanations for the model predictions. Rationales and importance distribution
given by feature attribution methods (FAs) provide insights into how different
parts of the input contribute to a prediction. Previous studies have explored
how different factors affect faithfulness, mainly in the context of monolingual
English models. On the other hand, the differences in FA faithfulness between
multilingual and monolingual models have yet to be explored. Our extensive
experiments, covering five languages and five popular FAs, show that FA
faithfulness varies between multilingual and monolingual models. We find that
the larger the multilingual model, the less faithful the FAs are compared to
its counterpart monolingual models.Our further analysis shows that the
faithfulness disparity is potentially driven by the differences between model
tokenizers. Our code is available:
https://github.com/casszhao/multilingual-faith.

中文翻译:
在许多实际的自然语言处理应用场景中，从业者不仅追求预测性能的最大化，同时也需要为模型预测寻求可信的解释。特征归因方法（FAs）提供的依据和重要性分布，揭示了输入的不同部分如何影响预测结果。先前的研究主要针对单语英语模型，探讨了不同因素如何影响解释的忠实性。然而，多语言模型与单语模型在特征归因忠实性上的差异尚未得到充分探索。我们通过涵盖五种语言和五种流行特征归因方法的大量实验发现，多语言模型与单语模型在特征归因忠实性上存在显著差异。具体表现为：多语言模型规模越大，其特征归因的忠实性相较于对应的单语模型就越低。进一步分析表明，这种忠实性差异可能源于模型分词器的不同特性。相关代码已开源：https://github.com/casszhao/multilingual-faith。
