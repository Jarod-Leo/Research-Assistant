# Zero-Shot Load Forecasting with Large Language Models

链接: http://arxiv.org/abs/2411.11350v1

原文摘要:
Deep learning models have shown strong performance in load forecasting, but
they generally require large amounts of data for model training before being
applied to new scenarios, which limits their effectiveness in data-scarce
scenarios. Inspired by the great success of pre-trained language models (LLMs)
in natural language processing, this paper proposes a zero-shot load
forecasting approach using an advanced LLM framework denoted as the Chronos
model. By utilizing its extensive pre-trained knowledge, the Chronos model
enables accurate load forecasting in data-scarce scenarios without the need for
extensive data-specific training. Simulation results across five real-world
datasets demonstrate that the Chronos model significantly outperforms nine
popular baseline models for both deterministic and probabilistic load
forecasting with various forecast horizons (e.g., 1 to 48 hours), even though
the Chronos model is neither tailored nor fine-tuned to these specific load
datasets. Notably, Chronos reduces root mean squared error (RMSE), continuous
ranked probability score (CRPS), and quantile score (QS) by approximately
7.34%-84.30%, 19.63%-60.06%, and 22.83%-54.49%, respectively, compared to
baseline models. These results highlight the superiority and flexibility of the
Chronos model, positioning it as an effective solution in data-scarce
scenarios.

中文翻译:
深度学习模型在负荷预测中表现出强大的性能，但通常需要大量数据进行模型训练才能应用于新场景，这限制了其在数据稀缺场景下的有效性。受预训练语言模型（LLMs）在自然语言处理领域巨大成功的启发，本文提出了一种基于先进LLM框架（称为Chronos模型）的零样本负荷预测方法。通过利用其广泛的预训练知识，Chronos模型无需针对特定数据进行大量训练，即可在数据稀缺场景下实现精准负荷预测。在五个真实数据集上的仿真结果表明：尽管Chronos模型未针对这些特定负荷数据集进行定制或微调，但在不同预测时域（如1至48小时）的确定性和概率性负荷预测中，其性能显著优于九种主流基线模型。值得注意的是，与基线模型相比，Chronos将均方根误差（RMSE）、连续排序概率得分（CRPS）和分位数得分（QS）分别降低了约7.34%-84.30%、19.63%-60.06%和22.83%-54.49%。这些结果凸显了Chronos模型的优越性和灵活性，使其成为数据稀缺场景下的有效解决方案。

（翻译说明：
1. 专业术语处理："zero-shot"译为"零样本"，"deterministic and probabilistic load forecasting"译为"确定性和概率性负荷预测"，保持学术规范性
2. 长句拆分：将原文复合长句拆分为符合中文表达习惯的短句，如将"Simulation results..."长句分解为两个逻辑清晰的短句
3. 被动语态转换："the Chronos model is neither tailored nor fine-tuned"处理为主动式"未针对...进行定制或微调"
4. 数据呈现优化：百分比范围保留原文精确度，采用中文惯用的"约"字衔接
5. 逻辑衔接增强：添加"值得注意的是"等过渡词，提升行文流畅性
6. 术语统一性：全篇统一"Chronos模型"的译名，避免歧义）
