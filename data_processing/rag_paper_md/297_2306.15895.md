# Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias

链接: http://arxiv.org/abs/2306.15895v1

原文摘要:
Large language models (LLMs) have been recently leveraged as training data
generators for various natural language processing (NLP) tasks. While previous
research has explored different approaches to training models using generated
data, they generally rely on simple class-conditional prompts, which may limit
the diversity of the generated data and inherit systematic biases of LLM. Thus,
we investigate training data generation with diversely attributed prompts
(e.g., specifying attributes like length and style), which have the potential
to yield diverse and attributed generated data. Our investigation focuses on
datasets with high cardinality and diverse domains, wherein we demonstrate that
attributed prompts outperform simple class-conditional prompts in terms of the
resulting model's performance. Additionally, we present a comprehensive
empirical study on data generation encompassing vital aspects like bias,
diversity, and efficiency, and highlight three key observations: firstly,
synthetic datasets generated by simple prompts exhibit significant biases, such
as regional bias; secondly, attribute diversity plays a pivotal role in
enhancing model performance; lastly, attributed prompts achieve the performance
of simple class-conditional prompts while utilizing only 5\% of the querying
cost of ChatGPT associated with the latter. The data and code are available on
\url{https://github.com/yueyu1030/AttrPrompt}.

中文翻译:
近期，大型语言模型（LLMs）被广泛用作各类自然语言处理（NLP）任务的训练数据生成器。尽管已有研究探索了利用生成数据训练模型的不同方法，但这些方法通常依赖于简单的类别条件提示，这既可能限制生成数据的多样性，又会继承LLM的系统性偏差。为此，我们研究了基于多样化属性提示（如指定文本长度、风格等属性）的训练数据生成方法，这类提示有望产生具有差异性且属性可控的生成数据。我们的实验聚焦于高基数、多领域的真实数据集，结果表明：采用属性提示所训练模型的性能显著优于简单类别条件提示。此外，我们围绕数据生成中的偏差、多样性和效率等核心维度展开了全面实证研究，并揭示出三项关键发现：其一，简单提示生成的合成数据集存在明显偏差（如地域偏见）；其二，属性多样性对提升模型性能具有决定性作用；其三，属性提示仅需消耗ChatGPT在类别条件提示下5%的查询成本，即可达到同等模型性能。相关数据和代码已开源于\url{https://github.com/yueyu1030/AttrPrompt}。
