# Chain of Thought Prompt Tuning in Vision Language Models

链接: http://arxiv.org/abs/2304.07919v1

原文摘要:
Language-Image Pre-training has demonstrated promising results on zero-shot
and few-shot downstream tasks by prompting visual models with natural language
prompts. However, most recent studies only use a single prompt for tuning,
neglecting the inherent step-to-step cognitive reasoning process that humans
conduct in complex task settings, for example, when processing images from
unfamiliar domains. Chain of Thought is a simple and effective approximation to
human reasoning process and has been proven useful for natural language
processing (NLP) tasks. Based on this cognitive intuition, we believe that
conducting effective reasoning is also an important problem in visual tasks,
and a chain of thought could be a solution to this problem. In this work, we
propose a novel chain of thought prompt tuning for vision-language modeling.
Extensive experiments show that our method not only generalizes better in image
classification tasks, has greater transferability beyond a single dataset, and
has stronger domain generalization performance, but also performs much better
in imagetext retrieval and visual question answering, which require more
reasoning capabilities. We are the first to successfully adapt chain-of-thought
prompting that combines visual and textual embeddings. We will release our
codes

中文翻译:
语言-图像预训练技术通过自然语言提示引导视觉模型，在零样本和小样本下游任务中展现出优异性能。然而当前研究多采用单一提示进行调优，忽视了人类处理复杂任务（如陌生领域图像理解）时固有的分步认知推理过程。思维链作为对人类推理过程的简易有效模拟，已在自然语言处理任务中得到验证。基于这一认知直觉，我们认为有效的推理机制同样是视觉任务中的关键问题，而思维链可能成为解决之道。本研究提出了一种创新的视觉语言建模思维链提示调优方法。大量实验表明，该方法不仅在图像分类任务中具有更好的泛化能力、更强的跨数据集迁移性和领域泛化性能，在需要深度推理能力的图文检索和视觉问答任务上表现尤为突出。我们首次成功实现了视觉与文本嵌入相结合的思维链提示技术，相关代码将开源发布。
