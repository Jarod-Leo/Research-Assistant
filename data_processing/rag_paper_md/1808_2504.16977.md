# Tokenization Matters: Improving Zero-Shot NER for Indic Languages

链接: http://arxiv.org/abs/2504.16977v1

原文摘要:
Tokenization is a critical component of Natural Language Processing (NLP),
especially for low resource languages, where subword segmentation influences
vocabulary structure and downstream task accuracy. Although Byte Pair Encoding
(BPE) is a standard tokenization method in multilingual language models, its
suitability for Named Entity Recognition (NER) in low resource Indic languages
remains underexplored due to its limitations in handling morphological
complexity. In this work, we systematically compare BPE, SentencePiece, and
Character Level tokenization strategies using IndicBERT for NER tasks in low
resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as
extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We
assess both intrinsic linguistic properties tokenization efficiency, out of
vocabulary (OOV) rates, and morphological preservation as well as extrinsic
downstream performance, including fine tuning and zero shot cross lingual
transfer.
  Our experiments show that SentencePiece is a consistently better performing
approach than BPE for NER in low resource Indic Languages, particularly in zero
shot cross lingual settings, as it better preserves entity consistency. While
BPE provides the most compact tokenization form, it is not capable of
generalization because it misclassifies or even fails to recognize entity
labels when tested on unseen languages. In contrast, SentencePiece constitutes
a better linguistic structural preservation model, benefiting extremely low
resource and morphologically rich Indic languages, such as Santali and
Manipuri, for superior entity recognition, as well as high generalization
across scripts, such as Sindhi, written in Arabic. The results point to
SentencePiece as the more effective tokenization strategy for NER within
multilingual and low resource Indic NLP applications.

中文翻译:
分词是自然语言处理（NLP）中的关键环节，尤其对资源稀缺语言而言，子词切分直接影响词汇结构与下游任务准确率。尽管字节对编码（BPE）是多语言模型的标准化分词方案，但其在处理形态复杂性方面的局限，导致其在低资源印度语系语言命名实体识别（NER）中的适用性仍待验证。本研究系统比较了BPE、SentencePiece和字符级分词策略在阿萨姆语、孟加拉语、马拉地语、奥里亚语等低资源印度语言，以及桑塔利语、曼尼普尔语、信德语等极低资源印度语言NER任务中的表现，基于IndicBERT模型评估了分词效率、未登录词率、形态保持等内在语言特性，以及微调与零样本跨语言迁移等下游性能。

实验表明，在低资源印度语言NER任务中，SentencePiece因其更好的实体一致性保持能力，尤其在零样本跨语言场景下，始终优于BPE方案。虽然BPE能生成最紧凑的分词形式，但其在未知语言测试时会出现实体标签误判甚至无法识别的问题，泛化能力不足。相比之下，SentencePiece凭借更优的语言结构保持特性，不仅显著提升了桑塔利语、曼尼普尔语等极低资源且形态复杂语言的实体识别效果，对阿拉伯文书写的信德语等跨文字体系语言也展现出卓越的泛化能力。研究结果证明，在多语言及低资源印度语系NLP应用中，SentencePiece是更高效的NER分词策略。
