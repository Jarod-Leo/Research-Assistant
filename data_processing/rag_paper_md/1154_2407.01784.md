# Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language Models with Paraphrase Enrichment

链接: http://arxiv.org/abs/2407.01784v1

原文摘要:
This paper describes our approach to hierarchical multi-label detection of
persuasion techniques in meme texts. Our model, developed as a part of the
recent SemEval task, is based on fine-tuning individual language models (BERT,
XLM-RoBERTa, and mBERT) and leveraging a mean-based ensemble model in addition
to dataset augmentation through paraphrase generation from ChatGPT. The scope
of the study encompasses enhancing model performance through innovative
training techniques and data augmentation strategies. The problem addressed is
the effective identification and classification of multiple persuasive
techniques in meme texts, a task complicated by the diversity and complexity of
such content. The objective of the paper is to improve detection accuracy by
refining model training methods and examining the impact of balanced versus
unbalanced training datasets. Novelty in the results and discussion lies in the
finding that training with paraphrases enhances model performance, yet a
balanced training set proves more advantageous than a larger unbalanced one.
Additionally, the analysis reveals the potential pitfalls of indiscriminate
incorporation of paraphrases from diverse distributions, which can introduce
substantial noise. Results with the SemEval 2024 data confirm these insights,
demonstrating improved model efficacy with the proposed methods.

中文翻译:
本文阐述了我们在模因文本中说服技术分层多标签检测的方法。作为近期SemEval任务的一部分，我们开发的模型基于对个体语言模型（BERT、XLM-RoBERTa和mBERT）的微调，并采用均值集成模型，同时通过ChatGPT生成释义实现数据集增强。研究范围涵盖通过创新训练技术和数据增强策略提升模型性能，核心问题是解决模因文本中多种说服技术的高效识别与分类——该任务因内容多样性和复杂性而颇具挑战。论文目标是通过优化模型训练方法，并考察平衡与非平衡训练数据集的影响来提高检测准确率。研究结果与讨论的创新点在于：发现使用释义训练能提升模型表现，但平衡训练集比规模更大但不平衡的数据集更具优势；同时分析揭示了不加选择地纳入不同分布的释义可能引入显著噪声的潜在缺陷。SemEval 2024数据实验结果验证了这些发现，证实所提方法能有效提升模型效能。
