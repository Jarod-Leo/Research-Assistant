# Sadeed: Advancing Arabic Diacritization Through Small Language Model

链接: http://arxiv.org/abs/2504.21635v1

原文摘要:
Arabic text diacritization remains a persistent challenge in natural language
processing due to the language's morphological richness. In this paper, we
introduce Sadeed, a novel approach based on a fine-tuned decoder-only language
model adapted from Kuwain 1.5B Hennara et al. [2025], a compact model
originally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully
curated, high-quality diacritized datasets, constructed through a rigorous
data-cleaning and normalization pipeline. Despite utilizing modest
computational resources, Sadeed achieves competitive results compared to
proprietary large language models and outperforms traditional models trained on
similar domains. Additionally, we highlight key limitations in current
benchmarking practices for Arabic diacritization. To address these issues, we
introduce SadeedDiac-25, a new benchmark designed to enable fairer and more
comprehensive evaluation across diverse text genres and complexity levels.
Together, Sadeed and SadeedDiac-25 provide a robust foundation for advancing
Arabic NLP applications, including machine translation, text-to-speech, and
language learning tools.

中文翻译:
阿拉伯语文本标注因其形态复杂性，始终是自然语言处理领域的持续挑战。本文提出Sadeed——一种基于Kuwain 1.5B Hennara等人[2025]微调的解码器专用语言模型新方法。该紧凑模型最初在多样化阿拉伯语语料库上训练，我们通过严格的数据清洗与标准化流程构建高质量标注数据集进行微调。尽管采用适中计算资源，Sadeed相比商业大语言模型取得可比结果，并超越同领域传统模型。同时，我们揭示了当前阿拉伯语标注基准测试的关键局限，为此推出SadeedDiac-25新基准，旨在实现对不同文本类型与复杂度更公平全面的评估。Sadeed与SadeedDiac-25共同为推进阿拉伯语机器翻译、语音合成及语言学习工具等NLP应用奠定了坚实基础。
