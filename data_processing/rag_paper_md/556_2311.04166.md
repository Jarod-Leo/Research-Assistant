# Perturbed examples reveal invariances shared by language models

链接: http://arxiv.org/abs/2311.04166v1

原文摘要:
The rapid growth in natural language processing (NLP) research has led to
numerous new models, outpacing our understanding of how they compare to
established ones. One major reason for this difficulty is saturating
benchmarks, which may not well reflect differences in model performance in the
wild. In this work, we introduce a novel framework to compare two NLP models by
revealing their shared invariance to interpretable input perturbations
targeting a specific linguistic capability. Via experiments on models from the
same and different architecture families, this framework offers insights about
how changes in models (e.g., distillation, size increase) affect linguistic
capabilities. Furthermore, our framework enables evaluation of invariances
between commercial black-box models (e.g., InstructGPT family) and models that
are better understood (e.g., GPT-2). Across experiments, we observe that large
language models share many invariances encoded by models of various sizes,
whereas the invariances by large models are only shared by other large models.
Possessing a wide variety of invariances may be key to the recent successes of
large language models, and our framework can shed light on the types of
invariances retained or emerging in new models. We make the code publicly
available.

中文翻译:
自然语言处理（NLP）研究的迅猛发展催生了大量新模型，其涌现速度已超越了我们对其与传统模型差异的认知。造成这一困境的主因在于现有基准测试趋于饱和，难以真实反映模型在实际应用中的性能差异。本研究提出了一种创新框架，通过分析两种NLP模型对特定语言能力靶向的可解释输入扰动的共享不变性来进行比较。通过对同架构与跨架构家族模型的实验，该框架揭示了模型变化（如知识蒸馏、规模扩大）对语言能力的影响机制。更重要的是，我们的框架能够评估商业黑箱模型（如InstructGPT系列）与可解释性更强的模型（如GPT-2）之间的不变性特征。实验表明：大型语言模型普遍继承了各类规模模型编码的不变性特征，而大型模型特有的不变性仅存在于同类大模型中。拥有广泛的不变性特征可能是大语言模型近期成功的关键因素，我们的框架可有效揭示新模型保留或涌现的不变性类型。相关代码已开源发布。
