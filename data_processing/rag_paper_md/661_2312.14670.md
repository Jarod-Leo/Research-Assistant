# Zero-shot Causal Graph Extrapolation from Text via LLMs

链接: http://arxiv.org/abs/2312.14670v1

原文摘要:
We evaluate the ability of large language models (LLMs) to infer causal
relations from natural language. Compared to traditional natural language
processing and deep learning techniques, LLMs show competitive performance in a
benchmark of pairwise relations without needing (explicit) training samples.
This motivates us to extend our approach to extrapolating causal graphs through
iterated pairwise queries. We perform a preliminary analysis on a benchmark of
biomedical abstracts with ground-truth causal graphs validated by experts. The
results are promising and support the adoption of LLMs for such a crucial step
in causal inference, especially in medical domains, where the amount of
scientific text to analyse might be huge, and the causal statements are often
implicit.

中文翻译:
我们评估了大型语言模型（LLM）从自然语言中推断因果关系的能力。与传统自然语言处理和深度学习技术相比，LLM在无需（显式）训练样本的情况下，在成对关系基准测试中展现出竞争力。这促使我们将方法扩展至通过迭代成对查询来推断因果图。我们在一个由专家验证真实因果图的生物医学摘要基准上进行了初步分析，结果显示出良好前景，支持采用LLM进行因果推理中的这一关键步骤，特别是在医学领域——待分析的科学文本可能极为庞大，且因果陈述往往隐含其中。
