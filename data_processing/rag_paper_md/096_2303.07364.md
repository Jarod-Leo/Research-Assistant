# Learning the language of QCD jets with transformers

链接: http://arxiv.org/abs/2303.07364v1

原文摘要:
Transformers have become the primary architecture for natural language
processing. In this study, we explore their use for auto-regressive density
estimation in high-energy jet physics, which involves working with a
high-dimensional space. We draw an analogy between sentences and words in
natural language and jets and their constituents in high-energy physics.
Specifically, we investigate density estimation for light QCD jets and
hadronically decaying boosted top jets. Since transformers allow easy sampling
from learned densities, we exploit their generative capability to assess the
quality of the density estimate. Our results indicate that the generated data
samples closely resemble the original data, as evidenced by the excellent
agreement of distributions such as particle multiplicity or jet mass.
Furthermore, the generated samples are difficult to distinguish from the
original data, even by a powerful supervised classifier. Given their
exceptional data processing capabilities, transformers could potentially be
trained directly on the massive LHC data sets to learn the probability
densities in high-energy jet physics.

中文翻译:
Transformer已成为自然语言处理的主流架构。本研究探讨其在高能喷注物理自回归密度估计中的应用，该领域涉及高维空间数据处理。我们将自然语言中的句子-单词关系类比为高能物理中的喷注-组分关系，重点研究轻夸克喷注与强子化衰变boosted顶夸克喷注的密度估计。由于Transformer能便捷地从学习到的密度中进行采样，我们利用其生成能力评估密度估计质量。结果表明，生成数据样本与原始数据高度吻合，粒子多重性、喷注质量等分布曲线展现出极佳的一致性。即使采用强大的监督分类器，生成样本与原始数据也难以区分。鉴于Transformer卓越的数据处理能力，未来或可直接利用大型强子对撞机海量数据集进行训练，以学习高能喷注物理中的概率密度分布。
