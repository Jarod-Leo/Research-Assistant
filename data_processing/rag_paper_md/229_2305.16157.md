# Training Data Extraction From Pre-trained Language Models: A Survey

链接: http://arxiv.org/abs/2305.16157v1

原文摘要:
As the deployment of pre-trained language models (PLMs) expands, pressing
security concerns have arisen regarding the potential for malicious extraction
of training data, posing a threat to data privacy. This study is the first to
provide a comprehensive survey of training data extraction from PLMs. Our
review covers more than 100 key papers in fields such as natural language
processing and security. First, preliminary knowledge is recapped and a
taxonomy of various definitions of memorization is presented. The approaches
for attack and defense are then systemized. Furthermore, the empirical findings
of several quantitative studies are highlighted. Finally, future research
directions based on this review are suggested.

中文翻译:
随着预训练语言模型（PLMs）的广泛应用，其训练数据可能被恶意提取的安全隐患引发了严峻的数据隐私担忧。本研究首次对PLMs训练数据提取问题进行了全面综述。我们系统梳理了自然语言处理与安全领域逾百篇核心文献：首先回顾基础知识，对记忆性概念的不同定义进行类型学划分；继而系统化梳理攻击与防御方法；随后重点呈现多项定量研究的实证发现；最后基于综述结论提出未来研究方向建议。

（翻译说明：采用学术论文摘要的简洁风格，通过分号与冒号构建逻辑层次。将"taxonomy"译为"类型学划分"体现学术严谨性，"systemized"译为"系统化梳理"保持动词动态感。将长句拆分为符合中文表达习惯的短句结构，如将"posing a threat..."转换为因果句式。术语如"PLMs"保留英文缩写并在首次出现时补全中文译名，符合计算机领域论文惯例。）
