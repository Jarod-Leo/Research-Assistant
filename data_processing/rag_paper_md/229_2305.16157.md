# Training Data Extraction From Pre-trained Language Models: A Survey

链接: http://arxiv.org/abs/2305.16157v1

原文摘要:
As the deployment of pre-trained language models (PLMs) expands, pressing
security concerns have arisen regarding the potential for malicious extraction
of training data, posing a threat to data privacy. This study is the first to
provide a comprehensive survey of training data extraction from PLMs. Our
review covers more than 100 key papers in fields such as natural language
processing and security. First, preliminary knowledge is recapped and a
taxonomy of various definitions of memorization is presented. The approaches
for attack and defense are then systemized. Furthermore, the empirical findings
of several quantitative studies are highlighted. Finally, future research
directions based on this review are suggested.

中文翻译:
随着预训练语言模型(PLMs)的广泛应用，其训练数据可能被恶意提取的安全隐患日益凸显，对数据隐私构成严重威胁。本研究首次系统综述了PLMs训练数据提取领域的研究进展。通过梳理自然语言处理与安全领域的100余篇核心文献，我们首先回顾了基础知识，并对各类记忆性定义进行了分类学归纳；继而系统化整理了攻击与防御方法；重点剖析了多项定量研究的实证发现；最后基于综述结论提出了未来研究方向。
