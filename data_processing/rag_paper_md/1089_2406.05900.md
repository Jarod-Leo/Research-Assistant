# Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research

链接: http://arxiv.org/abs/2406.05900v1

原文摘要:
The astonishing success of Large Language Models (LLMs) in Natural Language
Processing (NLP) has spurred their use in many application domains beyond text
analysis, including wearable sensor-based Human Activity Recognition (HAR). In
such scenarios, often sensor data are directly fed into an LLM along with text
instructions for the model to perform activity classification. Seemingly
remarkable results have been reported for such LLM-based HAR systems when they
are evaluated on standard benchmarks from the field. Yet, we argue, care has to
be taken when evaluating LLM-based HAR systems in such a traditional way. Most
contemporary LLMs are trained on virtually the entire (accessible) internet --
potentially including standard HAR datasets. With that, it is not unlikely that
LLMs actually had access to the test data used in such benchmark
experiments.The resulting contamination of training data would render these
experimental evaluations meaningless. In this paper we investigate whether LLMs
indeed have had access to standard HAR datasets during training. We apply
memorization tests to LLMs, which involves instructing the models to extend
given snippets of data. When comparing the LLM-generated output to the original
data we found a non-negligible amount of matches which suggests that the LLM
under investigation seems to indeed have seen wearable sensor data from the
benchmark datasets during training. For the Daphnet dataset in particular,
GPT-4 is able to reproduce blocks of sensor readings. We report on our
investigations and discuss potential implications on HAR research, especially
with regards to reporting results on experimental evaluation

中文翻译:
以下是符合您要求的中文翻译：

大型语言模型（LLM）在自然语言处理（NLP）领域的惊人成功，推动了其在文本分析之外的诸多应用领域的使用，包括基于可穿戴传感器的人类活动识别（HAR）。在此类场景中，传感器数据通常与文本指令一起直接输入LLM，由模型执行活动分类任务。当基于LLM的HAR系统在领域标准基准测试中进行评估时，已有研究报道了看似卓越的结果。然而我们认为，以这种传统方式评估基于LLM的HAR系统时需要格外谨慎。

当代大多数LLM的训练数据几乎覆盖了整个（可访问的）互联网——其中很可能包含标准HAR数据集。这意味着LLM实际上可能已经接触过这些基准实验所使用的测试数据。由此导致的训练数据污染将使这些实验评估失去意义。本文通过记忆测试方法探究LLM是否在训练过程中确实接触过标准HAR数据集，具体操作包括指示模型续写给定的数据片段。通过对比LLM生成输出与原始数据，我们发现存在不可忽视的匹配情况，这表明被测试的LLM似乎在训练过程中已经见过基准数据集中的可穿戴传感器数据。特别是在Daphnet数据集上，GPT-4能够复现完整的传感器读数数据块。

我们详细报告了相关研究结果，并讨论了其对HAR研究领域的潜在影响，特别是在实验评估结果报告方面需要关注的问题。
