/workspace/Research-Assistant/Built_RAG.py:2: LangChainDeprecationWarning: Importing DirectoryLoader from langchain.document_loaders is deprecated. Please replace deprecated imports:

>> from langchain.document_loaders import DirectoryLoader

with new imports of:

>> from langchain_community.document_loaders import DirectoryLoader
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.document_loaders import DirectoryLoader
/workspace/Research-Assistant/Built_RAG.py:19: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:

>> from langchain.embeddings import HuggingFaceEmbeddings

with new imports of:

>> from langchain_community.embeddings import HuggingFaceEmbeddings
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.embeddings import HuggingFaceEmbeddings
/workspace/Research-Assistant/Built_RAG.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embedding_model = HuggingFaceEmbeddings(
No sentence-transformers model found with name GanymedeNil/text2vec-large-chinese. Creating a new one with mean pooling.
/workspace/Research-Assistant/Built_RAG.py:27: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:

>> from langchain.vectorstores import FAISS

with new imports of:

>> from langchain_community.vectorstores import FAISS
You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>
  from langchain.vectorstores import FAISS
已检测到向量数据库，直接加载...
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
/venv/main/lib/python3.12/site-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:

`from langchain_community.llms import HuggingFacePipeline`.

To install langchain-community run `pip install -U langchain-community`.
  warnings.warn(
Device set to use cuda:0
/workspace/Research-Assistant/Built_RAG.py:66: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.
  llm = HuggingFacePipeline(pipeline=pipe)
/workspace/Research-Assistant/Built_RAG.py:99: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.
  result = qa_chain({"query": question})
/venv/main/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/venv/main/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
你是一个专业的中文科研助手，请根据以下上下文信息回答问题。
如果不知道答案，就回答不知道，不要编造答案。

上下文：
中文翻译: Transformer模型已在自然语言处理领域的实证机器学习模型中占据主导地位。本文系统介绍了Transformer的基础概念，并阐述了推动这类模型近期发展的关键技术体系。主要内容包括：标准Transformer架构解析、一系列模型优化方法以及典型应用场景。鉴于Transformer及相关深度学习技术可能正以我们前所未见的方式演进，本文无法穷尽所有模型细节或覆盖全部技术领域，而是聚焦于那些真正有助于深入理解Transformer及其变体的核心概念。同时，我们对影响该领域发展的关键思想进行提炼，从而揭示这类模型的内在优势与固有局限性。

中文翻译: 以下是符合要求的学术性中文翻译：

自然语言处理领域中Transformer模型的显著成功引发了语音处理学界的研究兴趣，促使学者们探索其在建模语音序列长程依赖性方面的潜力。近年来，Transformer模型已在多个语音相关领域崭露头角，包括自动语音识别、语音合成、语音翻译、语音副语言学、语音增强、口语对话系统以及众多多模态应用。本文通过系统性综述，旨在整合语音技术各子领域的研究成果，为希望利用Transformer推动学科发展的研究者提供重要参考资源。我们在剖析Transformer应用于语音处理时所面临挑战的同时，也针对这些问题提出了潜在的解决方案。

中文翻译: 文档摘要是指通过提取与主题相关的关键信息，生成既简洁又能准确反映原文内容的概括性文本。目前主要存在两种技术路径：其一是从原文直接抽取最具代表性的语句组成摘要（抽取式摘要），其二是通过语义理解生成全新语句形成摘要（生成式摘要）。在机器学习领域，如何训练模型完成那些耗时且人工评估困难的任务始终是重大挑战，书籍摘要生成正是此类复杂任务的典型代表。随着预训练Transformer模型的发展，传统机器学习方法正在经历革新。基于Transformer架构、采用自监督训练方式的语言模型，经过自然语言处理（NLP）下游任务（如文本摘要）的微调后，已展现出显著优势。本研究旨在探索基于Transformer技术的摘要生成方法。

问题：Transformer在文本摘要中有哪些应用？
专业回答：基于Transformer架构、采用自监督训练方式的语言模型，经过自然语言处理（NLP）下游任务（如文本摘要）的微调后，已展现出显著优势。 
